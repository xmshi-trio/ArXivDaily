<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-09-26T01:30:00Z">09-26</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Applying BioBERT to Extract Germline Gene-Disease Associations for Building a Knowledge Graph from the Biomedical Literature. (arXiv:2309.13061v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13061">
<div class="article-summary-box-inner">
<span><p>Published biomedical information has and continues to rapidly increase. The
recent advancements in Natural Language Processing (NLP), have generated
considerable interest in automating the extraction, normalization, and
representation of biomedical knowledge about entities such as genes and
diseases. Our study analyzes germline abstracts in the construction of
knowledge graphs of the of the immense work that has been done in this area for
genes and diseases. This paper presents SimpleGermKG, an automatic knowledge
graph construction approach that connects germline genes and diseases. For the
extraction of genes and diseases, we employ BioBERT, a pre-trained BERT model
on biomedical corpora. We propose an ontology-based and rule-based algorithm to
standardize and disambiguate medical terms. For semantic relationships between
articles, genes, and diseases, we implemented a part-whole relation approach to
connect each entity with its data source and visualize them in a graph-based
knowledge representation. Lastly, we discuss the knowledge graph applications,
limitations, and challenges to inspire the future research of germline corpora.
Our knowledge graph contains 297 genes, 130 diseases, and 46,747 triples.
Graph-based visualizations are used to show the results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Large Language Models to Generate, Validate, and Apply User Intent Taxonomies. (arXiv:2309.13063v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13063">
<div class="article-summary-box-inner">
<span><p>Log data can reveal valuable information about how users interact with web
search services, what they want, and how satisfied they are. However, analyzing
user intents in log data is not easy, especially for new forms of web search
such as AI-driven chat. To understand user intents from log data, we need a way
to label them with meaningful categories that capture their diversity and
dynamics. Existing methods rely on manual or ML-based labeling, which are
either expensive or inflexible for large and changing datasets. We propose a
novel solution using large language models (LLMs), which can generate rich and
relevant concepts, descriptions, and examples for user intents. However, using
LLMs to generate a user intent taxonomy and apply it to do log analysis can be
problematic for two main reasons: such a taxonomy is not externally validated,
and there may be an undesirable feedback loop. To overcome these issues, we
propose a new methodology with human experts and assessors to verify the
quality of the LLM-generated taxonomy. We also present an end-to-end pipeline
that uses an LLM with human-in-the-loop to produce, refine, and use labels for
user intent analysis in log data. Our method offers a scalable and adaptable
way to analyze user intents in web-scale log data with minimal human effort. We
demonstrate its effectiveness by uncovering new insights into user intents from
search and chat logs from Bing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Personality Profiling: How informative are social media profiles in predicting personal information?. (arXiv:2309.13065v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13065">
<div class="article-summary-box-inner">
<span><p>Personality profiling has been utilised by companies for targeted
advertising, political campaigns and vaccine campaigns. However, the accuracy
and versatility of such models still remains relatively unknown. Consequently,
we aim to explore the extent to which peoples' online digital footprints can be
used to profile their Myers-Briggs personality type. We analyse and compare the
results of four models: logistic regression, naive Bayes, support vector
machines (SVMs) and random forests. We discover that a SVM model achieves the
best accuracy of 20.95% for predicting someones complete personality type.
However, logistic regression models perform only marginally worse and are
significantly faster to train and perform predictions. We discover that many
labelled datasets present substantial class imbalances of personal
characteristics on social media, including our own. As a result, we highlight
the need for attentive consideration when reporting model performance on these
datasets and compare a number of methods for fixing the class-imbalance
problems. Moreover, we develop a statistical framework for assessing the
importance of different sets of features in our models. We discover some
features to be more informative than others in the Intuitive/Sensory (p =
0.032) and Thinking/Feeling (p = 0.019) models. While we apply these methods to
Myers-Briggs personality profiling, they could be more generally used for any
labelling of individuals on social media.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Learning Technique Based Fake News Detection. (arXiv:2309.13069v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13069">
<div class="article-summary-box-inner">
<span><p>False news has received attention from both the general public and the
scholarly world. Such false information has the ability to affect public
perception, giving nefarious groups the chance to influence the results of
public events like elections. Anyone can share fake news or facts about anyone
or anything for their personal gain or to cause someone trouble. Also,
information varies depending on the part of the world it is shared on. Thus, in
this paper, we have trained a model to classify fake and true news by utilizing
the 1876 news data from our collected dataset. We have preprocessed the data to
get clean and filtered texts by following the Natural Language Processing
approaches. Our research conducts 3 popular Machine Learning (Stochastic
gradient descent, Na\"ive Bayes, Logistic Regression,) and 2 Deep Learning
(Long-Short Term Memory, ASGD Weight-Dropped LSTM, or AWD-LSTM) algorithms.
After we have found our best Naive Bayes classifier with 56% accuracy and an
F1-macro score of an average of 32%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Reasoning by Neuro-Symbolic Approaches. (arXiv:2309.13072v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13072">
<div class="article-summary-box-inner">
<span><p>Deep learning has largely improved the performance of various natural
language processing (NLP) tasks. However, most deep learning models are
black-box machinery, and lack explicit interpretation. In this chapter, we will
introduce our recent progress on neuro-symbolic approaches to NLP, which
combines different schools of AI, namely, symbolism and connectionism.
Generally, we will design a neural system with symbolic latent structures for
an NLP task, and apply reinforcement learning or its relaxation to perform
weakly supervised reasoning in the downstream task. Our framework has been
successfully applied to various tasks, including table query reasoning,
syntactic structure reasoning, information extraction reasoning, and rule
reasoning. For each application, we will introduce the background, our
approach, and experimental results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SCREWS: A Modular Framework for Reasoning with Revisions. (arXiv:2309.13075v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13075">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) can improve their accuracy on various tasks
through iteratively refining and revising their output based on feedback. We
observe that these revisions can introduce errors, in which case it is better
to roll back to a previous result. Further, revisions are typically
homogeneous: they use the same reasoning method that produced the initial
answer, which may not correct errors. To enable exploration in this space, we
present SCREWS, a modular framework for reasoning with revisions. It is
comprised of three main modules: Sampling, Conditional Resampling, and
Selection, each consisting of sub-modules that can be hand-selected per task.
We show that SCREWS not only unifies several previous approaches under a common
framework, but also reveals several novel strategies for identifying improved
reasoning chains. We evaluate our framework with state-of-the-art LLMs (ChatGPT
and GPT-4) on a diverse set of reasoning tasks and uncover useful new reasoning
strategies for each: arithmetic word problems, multi-hop question answering,
and code debugging. Heterogeneous revision strategies prove to be important, as
does selection between original and revised candidates.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific Large Models. (arXiv:2309.13079v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13079">
<div class="article-summary-box-inner">
<span><p>With the advancement of deep learning technologies, general-purpose large
models such as GPT-4 have demonstrated exceptional capabilities across various
domains. Nevertheless, there remains a demand for high-quality, domain-specific
outputs in areas like healthcare, law, and finance. This paper first evaluates
the existing large models for specialized domains and discusses their
limitations. To cater to the specific needs of certain domains, we introduce
the ``MiChao-HuaFen 1.0'' pre-trained corpus dataset, tailored for the news and
governmental sectors. The dataset, sourced from publicly available internet
data from 2022, underwent multiple rounds of cleansing and processing to ensure
high quality and reliable origins, with provisions for consistent and stable
updates. This dataset not only supports the pre-training of large models for
Chinese vertical domains but also aids in propelling deep learning research and
applications in related fields.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SPICED: News Similarity Detection Dataset with Multiple Topics and Complexity Levels. (arXiv:2309.13080v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13080">
<div class="article-summary-box-inner">
<span><p>Nowadays, the use of intelligent systems to detect redundant information in
news articles has become especially prevalent with the proliferation of news
media outlets in order to enhance user experience. However, the heterogeneous
nature of news can lead to spurious findings in these systems: Simple
heuristics such as whether a pair of news are both about politics can provide
strong but deceptive downstream performance. Segmenting news similarity
datasets into topics improves the training of these models by forcing them to
learn how to distinguish salient characteristics under more narrow domains.
However, this requires the existence of topic-specific datasets, which are
currently lacking. In this article, we propose a new dataset of similar news,
SPICED, which includes seven topics: Crime &amp; Law, Culture &amp; Entertainment,
Disasters &amp; Accidents, Economy &amp; Business, Politics &amp; Conflicts, Science &amp;
Technology, and Sports. Futhermore, we present four distinct approaches for
generating news pairs, which are used in the creation of datasets specifically
designed for news similarity detection task. We benchmarked the created
datasets using MinHash, BERT, SBERT, and SimCSE models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Lexical Analysis of Dog Vocalizations via Online Videos. (arXiv:2309.13086v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13086">
<div class="article-summary-box-inner">
<span><p>Deciphering the semantics of animal language has been a grand challenge. This
study presents a data-driven investigation into the semantics of dog
vocalizations via correlating different sound types with consistent semantics.
We first present a new dataset of Shiba Inu sounds, along with contextual
information such as location and activity, collected from YouTube with a
well-constructed pipeline. The framework is also applicable to other animal
species. Based on the analysis of conditioned probability between dog
vocalizations and corresponding location and activity, we discover supporting
evidence for previous heuristic research on the semantic meaning of various dog
sounds. For instance, growls can signify interactions. Furthermore, our study
yields new insights that existing word types can be subdivided into
finer-grained subtypes and minimal semantic unit for Shiba Inu is word-related.
For example, whimper can be subdivided into two types, attention-seeking and
discomfort.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cardiovascular Disease Risk Prediction via Social Media. (arXiv:2309.13147v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13147">
<div class="article-summary-box-inner">
<span><p>Researchers utilize Twitter and sentiment analysis to forecast the risk of
Cardiovascular Disease (CVD). We have introduced a novel CVD-related keyword
dictionary by scrutinizing the emotions conveyed in tweets. We gathered tweets
from eighteen U.S. states, encompassing the Appalachian region. Employing the
VADER model for sentiment analysis, we categorized users as potentially at risk
for CVD. Machine Learning (ML) models were employed to assess individuals' CVD
risk and were subsequently applied to a CDC dataset containing demographic
information for comparison. We considered various performance evaluation
metrics, including Test Accuracy, Precision, Recall, F1 score, Mathew's
Correlation Coefficient (MCC), and Cohen's Kappa (CK) score. Our findings
demonstrate that analyzing the emotional content of tweets outperforms the
predictive capabilities of demographic data alone, enabling the identification
of individuals at potential risk of developing CVD. This research underscores
the potential of Natural Language Processing (NLP) and ML techniques in
leveraging tweets to identify individuals with CVD risks, offering an
alternative approach to traditional demographic information for public health
monitoring.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Are Also Good Prototypical Commonsense Reasoners. (arXiv:2309.13165v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13165">
<div class="article-summary-box-inner">
<span><p>Commonsense reasoning is a pivotal skill for large language models, yet it
presents persistent challenges in specific tasks requiring this competence.
Traditional fine-tuning approaches can be resource-intensive and potentially
compromise a model's generalization capacity. Furthermore, state-of-the-art
language models like GPT-3.5 and Claude are primarily accessible through API
calls, which makes fine-tuning models challenging. To address these challenges,
we draw inspiration from the outputs of large models for tailored tasks and
semi-automatically developed a set of novel prompts from several perspectives,
including task-relevance, supportive evidence generation (e.g. chain-of-thought
and knowledge), diverse path decoding to aid the model. Experimental results on
ProtoQA dataset demonstrate that with better designed prompts we can achieve
the new state-of-art(SOTA) on the ProtoQA leaderboard, improving the Max
Answer@1 score by 8%, Max Incorrect@1 score by 4% (breakthrough 50% for the
first time) compared to the previous SOTA model and achieved an improvement on
StrategyQA and CommonsenseQA2.0 (3% and 1%, respectively). Furthermore, with
the generated Chain-of-Thought and knowledge, we can improve the
interpretability of the model while also surpassing the previous SOTA models.
We hope that our work can provide insight for the NLP community to develop
better prompts and explore the potential of large language models for more
complex reasoning tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BenLLMEval: A Comprehensive Evaluation into the Potentials and Pitfalls of Large Language Models on Bengali NLP. (arXiv:2309.13173v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13173">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have emerged as one of the most important
breakthroughs in natural language processing (NLP) for their impressive skills
in language generation and other language-specific tasks. Though LLMs have been
evaluated in various tasks, mostly in English, they have not yet undergone
thorough evaluation in under-resourced languages such as Bengali (Bangla). In
this paper, we evaluate the performance of LLMs for the low-resourced Bangla
language. We select various important and diverse Bangla NLP tasks, such as
abstractive summarization, question answering, paraphrasing, natural language
inference, text classification, and sentiment analysis for zero-shot evaluation
with ChatGPT, LLaMA-2, and Claude-2 and compare the performance with
state-of-the-art fine-tuned models. Our experimental results demonstrate an
inferior performance of LLMs for different Bangla NLP tasks, calling for
further effort to develop better understanding of LLMs in low-resource
languages like Bangla.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effective Distillation of Table-based Reasoning Ability from LLMs. (arXiv:2309.13182v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13182">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have demonstrated remarkable performance across
a wide range of natural language processing tasks. However, their remarkable
parameter size and their impressive high requirement of computing resources
pose challenges for their practical deployment. Recent research has revealed
that specific capabilities of LLMs, such as numerical reasoning, can be
transferred to smaller models through distillation. Some studies explore the
potential of leveraging LLMs to perform table-based reasoning. Nevertheless,
prior to our work, there has been no investigation into the prospect of
specialising table reasoning skills in smaller models specifically tailored for
table-to-text generation tasks. In this paper, we propose a novel table-based
reasoning distillation, with the aim of distilling distilling LLMs into
tailored, smaller models specifically designed for table-based reasoning task.
Experimental results have shown that a 0.22 billion parameter model
(Flan-T5-base) fine-tuned using distilled data, not only achieves a significant
improvement compared to traditionally fine-tuned baselines but also surpasses
specific LLMs like gpt-3.5-turbo on the scientific table-to-text generation
dataset (SciGen). The code and data are released in
https://github.com/Bernard-Yang/TableDistill.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Document Understanding for Healthcare Referrals. (arXiv:2309.13184v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13184">
<div class="article-summary-box-inner">
<span><p>Reliance on scanned documents and fax communication for healthcare referrals
leads to high administrative costs and errors that may affect patient care. In
this work we propose a hybrid model leveraging LayoutLMv3 along with
domain-specific rules to identify key patient, physician, and exam-related
entities in faxed referral documents. We explore some of the challenges in
applying a document understanding model to referrals, which have formats
varying by medical practice, and evaluate model performance using MUC-5 metrics
to obtain appropriate metrics for the practical use case. Our analysis shows
the addition of domain-specific rules to the transformer model yields greatly
increased precision and F1 scores, suggesting a hybrid model trained on a
curated dataset can increase efficiency in referral management.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models and Control Mechanisms Improve Text Readability of Biomedical Abstracts. (arXiv:2309.13202v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13202">
<div class="article-summary-box-inner">
<span><p>Biomedical literature often uses complex language and inaccessible
professional terminologies. That is why simplification plays an important role
in improving public health literacy. Applying Natural Language Processing (NLP)
models to automate such tasks allows for quick and direct accessibility for lay
readers. In this work, we investigate the ability of state-of-the-art large
language models (LLMs) on the task of biomedical abstract simplification, using
the publicly available dataset for plain language adaptation of biomedical
abstracts (\textbf{PLABA}). The methods applied include domain fine-tuning and
prompt-based learning (PBL) on: 1) Encoder-decoder models (T5, SciFive, and
BART), 2) Decoder-only GPT models (GPT-3.5 and GPT-4) from OpenAI and BioGPT,
and 3) Control-token mechanisms on BART-based models. We used a range of
automatic evaluation metrics, including BLEU, ROUGE, SARI, and BERTscore, and
also conducted human evaluations. BART-Large with Control Token (BART-L-w-CT)
mechanisms reported the highest SARI score of 46.54 and T5-base reported the
highest BERTscore 72.62. In human evaluation, BART-L-w-CTs achieved a better
simplicity score over T5-Base (2.9 vs. 2.2), while T5-Base achieved a better
meaning preservation score over BART-L-w-CTs (3.1 vs. 2.6). We also categorised
the system outputs with examples, hoping this will shed some light for future
research on this task. Our code, fine-tuned models, and data splits are
available at \url{https://github.com/HECTA-UoM/PLABA-MU}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Practical Survey on Zero-shot Prompt Design for In-context Learning. (arXiv:2309.13205v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13205">
<div class="article-summary-box-inner">
<span><p>The remarkable advancements in large language models (LLMs) have brought
about significant improvements in Natural Language Processing(NLP) tasks. This
paper presents a comprehensive review of in-context learning techniques,
focusing on different types of prompts, including discrete, continuous,
few-shot, and zero-shot, and their impact on LLM performance. We explore
various approaches to prompt design, such as manual design, optimization
algorithms, and evaluation methods, to optimize LLM performance across diverse
tasks. Our review covers key research studies in prompt engineering, discussing
their methodologies and contributions to the field. We also delve into the
challenges faced in evaluating prompt performance, given the absence of a
single "best" prompt and the importance of considering multiple metrics. In
conclusion, the paper highlights the critical role of prompt design in
harnessing the full potential of LLMs and provides insights into the
combination of manual design, optimization techniques, and rigorous evaluation
for more effective and efficient use of LLMs in various NLP tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hindi to English: Transformer-Based Neural Machine Translation. (arXiv:2309.13222v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13222">
<div class="article-summary-box-inner">
<span><p>Machine Translation (MT) is one of the most prominent tasks in Natural
Language Processing (NLP) which involves the automatic conversion of texts from
one natural language to another while preserving its meaning and fluency.
Although the research in machine translation has been going on since multiple
decades, the newer approach of integrating deep learning techniques in natural
language processing has led to significant improvements in the translation
quality. In this paper, we have developed a Neural Machine Translation (NMT)
system by training the Transformer model to translate texts from Indian
Language Hindi to English. Hindi being a low resource language has made it
difficult for neural networks to understand the language thereby leading to a
slow growth in the development of neural machine translators. Thus, to address
this gap, we implemented back-translation to augment the training data and for
creating the vocabulary, we experimented with both word and subword level
tokenization using Byte Pair Encoding (BPE) thereby ending up training the
Transformer in 10 different configurations. This led us to achieve a
state-of-the-art BLEU score of 24.53 on the test set of IIT Bombay
English-Hindi Corpus in one of the configurations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NJUNLP's Participation for the WMT2023 Quality Estimation Shared Task. (arXiv:2309.13230v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13230">
<div class="article-summary-box-inner">
<span><p>We introduce the submissions of the NJUNLP team to the WMT 2023 Quality
Estimation (QE) shared task. Our team submitted predictions for the
English-German language pair on all two sub-tasks: (i) sentence- and word-level
quality prediction; and (ii) fine-grained error span detection. This year, we
further explore pseudo data methods for QE based on NJUQE framework
(https://github.com/NJUNLP/njuqe). We generate pseudo MQM data using parallel
data from the WMT translation task. We pre-train the XLMR large model on pseudo
QE data, then fine-tune it on real QE data. At both stages, we jointly learn
sentence-level scores and word-level tags. Empirically, we conduct experiments
to find the key hyper-parameters that improve the performance. Technically, we
propose a simple method that covert the word-level outputs to fine-grained
error span results. Overall, our models achieved the best results in
English-German for both word-level and fine-grained error span detection
sub-tasks by a considerable margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">User Simulation with Large Language Models for Evaluating Task-Oriented Dialogue. (arXiv:2309.13233v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13233">
<div class="article-summary-box-inner">
<span><p>One of the major impediments to the development of new task-oriented dialogue
(TOD) systems is the need for human evaluation at multiple stages and
iterations of the development process. In an effort to move toward automated
evaluation of TOD, we propose a novel user simulator built using recently
developed large pretrained language models (LLMs). In order to increase the
linguistic diversity of our system relative to the related previous work, we do
not fine-tune the LLMs used by our system on existing TOD datasets; rather we
use in-context learning to prompt the LLMs to generate robust and
linguistically diverse output with the goal of simulating the behavior of human
interlocutors. Unlike previous work, which sought to maximize goal success rate
(GSR) as the primary metric of simulator performance, our goal is a system
which achieves a GSR similar to that observed in human interactions with TOD
systems. Using this approach, our current simulator is effectively able to
interact with several TOD systems, especially on single-intent conversational
goals, while generating lexically and syntactically diverse output relative to
previous simulators that rely upon fine-tuned models. Finally, we collect a
Human2Bot dataset of humans interacting with the same TOD systems with which we
experimented in order to better quantify these achievements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChEDDAR: Student-ChatGPT Dialogue in EFL Writing Education. (arXiv:2309.13243v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13243">
<div class="article-summary-box-inner">
<span><p>The integration of generative AI in education is expanding, yet empirical
analyses of large-scale, real-world interactions between students and AI
systems still remain limited. In this study, we present ChEDDAR, ChatGPT &amp; EFL
Learner's Dialogue Dataset As Revising an essay, which is collected from a
semester-long longitudinal experiment involving 212 college students enrolled
in English as Foreign Langauge (EFL) writing courses. The students were asked
to revise their essays through dialogues with ChatGPT. ChEDDAR includes a
conversation log, utterance-level essay edit history, self-rated satisfaction,
and students' intent, in addition to session-level pre-and-post surveys
documenting their objectives and overall experiences. We analyze students'
usage patterns and perceptions regarding generative AI with respect to their
intent and satisfaction. As a foundational step, we establish baseline results
for two pivotal tasks in task-oriented dialogue systems within educational
contexts: intent detection and satisfaction estimation. We finally suggest
further research to refine the integration of generative AI into education
settings, outlining potential scenarios utilizing ChEDDAR. ChEDDAR is publicly
available at https://github.com/zeunie/ChEDDAR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Document-Level Information Extraction. (arXiv:2309.13249v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13249">
<div class="article-summary-box-inner">
<span><p>Document-level information extraction (IE) is a crucial task in natural
language processing (NLP). This paper conducts a systematic review of recent
document-level IE literature. In addition, we conduct a thorough error analysis
with current state-of-the-art algorithms and identify their limitations as well
as the remaining challenges for the task of document-level IE. According to our
findings, labeling noises, entity coreference resolution, and lack of
reasoning, severely affect the performance of document-level IE. The objective
of this survey paper is to provide more insights and help NLP researchers to
further enhance document-level IE performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Natural Language Processing for Requirements Formalization: How to Derive New Approaches?. (arXiv:2309.13272v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13272">
<div class="article-summary-box-inner">
<span><p>It is a long-standing desire of industry and research to automate the
software development and testing process as much as possible. In this process,
requirements engineering (RE) plays a fundamental role for all other steps that
build on it. Model-based design and testing methods have been developed to
handle the growing complexity and variability of software systems. However,
major effort is still required to create specification models from a large set
of functional requirements provided in natural language. Numerous approaches
based on natural language processing (NLP) have been proposed in the literature
to generate requirements models using mainly syntactic properties. Recent
advances in NLP show that semantic quantities can also be identified and used
to provide better assistance in the requirements formalization process. In this
work, we present and discuss principal ideas and state-of-the-art methodologies
from the field of NLP in order to guide the readers on how to create a set of
rules and methods for the semi-automated formalization of requirements
according to their specific use case and needs. We discuss two different
approaches in detail and highlight the iterative development of rule sets. The
requirements models are represented in a human- and machine-readable format in
the form of pseudocode. The presented methods are demonstrated on two
industrial use cases from the automotive and railway domains. It shows that
using current pre-trained NLP models requires less effort to create a set of
rules and can be easily adapted to specific use cases and domains. In addition,
findings and shortcomings of this research area are highlighted and an outlook
on possible future developments is given.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OATS: Opinion Aspect Target Sentiment Quadruple Extraction Dataset for Aspect-Based Sentiment Analysis. (arXiv:2309.13297v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13297">
<div class="article-summary-box-inner">
<span><p>Aspect-based sentiment Analysis (ABSA) delves into understanding sentiments
specific to distinct elements within textual content. It aims to analyze
user-generated reviews to determine a) the target entity being reviewed, b) the
high-level aspect to which it belongs, c) the sentiment words used to express
the opinion, and d) the sentiment expressed toward the targets and the aspects.
While various benchmark datasets have fostered advancements in ABSA, they often
come with domain limitations and data granularity challenges. Addressing these,
we introduce the OATS dataset, which encompasses three fresh domains and
consists of 20,000 sentence-level quadruples and 13,000 review-level tuples.
Our initiative seeks to bridge specific observed gaps: the recurrent focus on
familiar domains like restaurants and laptops, limited data for intricate
quadruple extraction tasks, and an occasional oversight of the synergy between
sentence and review-level sentiments. Moreover, to elucidate OATS's potential
and shed light on various ABSA subtasks that OATS can solve, we conducted
in-domain and cross-domain experiments, establishing initial baselines. We hope
the OATS dataset augments current resources, paving the way for an encompassing
exploration of ABSA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Calibrating LLM-Based Evaluator. (arXiv:2309.13308v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13308">
<div class="article-summary-box-inner">
<span><p>Recent advancements in large language models (LLMs) on language modeling and
emergent capabilities make them a promising reference-free evaluator of natural
language generation quality, and a competent alternative to human evaluation.
However, hindered by the closed-source or high computational demand to host and
tune, there is a lack of practice to further calibrate an off-the-shelf
LLM-based evaluator towards better human alignment. In this work, we propose
AutoCalibrate, a multi-stage, gradient-free approach to automatically calibrate
and align an LLM-based evaluator toward human preference. Instead of explicitly
modeling human preferences, we first implicitly encompass them within a set of
human labels. Then, an initial set of scoring criteria is drafted by the
language model itself, leveraging in-context learning on different few-shot
examples. To further calibrate this set of criteria, we select the best
performers and re-draft them with self-refinement. Our experiments on multiple
text quality evaluation datasets illustrate a significant improvement in
correlation with expert evaluation through calibration. Our comprehensive
qualitative analysis conveys insightful intuitions and observations on the
essence of effective scoring criteria.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BLM-17m: A Large-Scale Dataset for Black Lives Matter Topic Detection on Twitter. (arXiv:2105.01331v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01331">
<div class="article-summary-box-inner">
<span><p>Protection of human rights is one of the most important problems of our
world. In this paper, our aim is to provide a dataset which covers one of the
most significant human rights contradiction in recent months affected the whole
world, George Floyd incident. We propose a labeled dataset for topic detection
that contains 17 million tweets. These Tweets are collected from 25 May 2020 to
21 August 2020 that covers 89 days from start of this incident. We labeled the
dataset by monitoring most trending news topics from global and local
newspapers. Apart from that, we present two baselines, TF-IDF and LDA. We
evaluated the results of these two methods with three different k values for
metrics of precision, recall and f1-score. The collected dataset is available
at https://github.com/MeysamAsgariC/BLMT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Crime Hot-Spot Modeling via Topic Modeling and Relative Density Estimation. (arXiv:2202.04176v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04176">
<div class="article-summary-box-inner">
<span><p>We present a method to capture groupings of similar calls and determine their
relative spatial distribution from a collection of crime record narratives. We
first obtain a topic distribution for each narrative, and then propose a
nearest neighbors relative density estimation (kNN-RDE) approach to obtain
spatial relative densities per topic. Experiments over a large corpus
($n=475,019$) of narrative documents from the Atlanta Police Department
demonstrate the viability of our method in capturing geographic hot-spot trends
which call dispatchers do not initially pick up on and which go unnoticed due
to conflation with elevated event density in general.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Actuarial Applications of Natural Language Processing Using Transformers: Case Studies for Using Text Features in an Actuarial Context. (arXiv:2206.02014v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02014">
<div class="article-summary-box-inner">
<span><p>This tutorial demonstrates workflows to incorporate text data into actuarial
classification and regression tasks. The main focus is on methods employing
transformer-based models. A dataset of car accident descriptions with an
average length of 400 words, available in English and German, and a dataset
with short property insurance claims descriptions are used to demonstrate these
techniques. The case studies tackle challenges related to a multi-lingual
setting and long input sequences. They also show ways to interpret model
output, to assess and improve model performance, by fine-tuning the models to
the domain of application or to a specific prediction task. Finally, the
tutorial provides practical approaches to handle classification tasks in
situations with no or only few labeled data, including but not limited to
ChatGPT. The results achieved by using the language-understanding skills of
off-the-shelf natural language processing (NLP) models with only minimal
pre-processing and fine-tuning clearly demonstrate the power of transfer
learning for practical applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explainable and High-Performance Hate and Offensive Speech Detection. (arXiv:2206.12983v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12983">
<div class="article-summary-box-inner">
<span><p>The spread of information through social media platforms can create
environments possibly hostile to vulnerable communities and silence certain
groups in society. To mitigate such instances, several models have been
developed to detect hate and offensive speech. Since detecting hate and
offensive speech in social media platforms could incorrectly exclude
individuals from social media platforms, which can reduce trust, there is a
need to create explainable and interpretable models. Thus, we build an
explainable and interpretable high performance model based on the XGBoost
algorithm, trained on Twitter data. For unbalanced Twitter data, XGboost
outperformed the LSTM, AutoGluon, and ULMFiT models on hate speech detection
with an F1 score of 0.75 compared to 0.38 and 0.37, and 0.38 respectively. When
we down-sampled the data to three separate classes of approximately 5000
tweets, XGBoost performed better than LSTM, AutoGluon, and ULMFiT; with F1
scores for hate speech detection of 0.79 vs 0.69, 0.77, and 0.66 respectively.
XGBoost also performed better than LSTM, AutoGluon, and ULMFiT in the
down-sampled version for offensive speech detection with F1 score of 0.83 vs
0.88, 0.82, and 0.79 respectively. We use Shapley Additive Explanations (SHAP)
on our XGBoost models' outputs to makes it explainable and interpretable
compared to LSTM, AutoGluon and ULMFiT that are black-box models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CC-Riddle: A Question Answering Dataset of Chinese Character Riddles. (arXiv:2206.13778v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13778">
<div class="article-summary-box-inner">
<span><p>The Chinese character riddle is a unique form of cultural entertainment
specific to the Chinese language. It typically comprises two parts: the riddle
description and the solution. The solution to the riddle is a single character,
while the riddle description primarily describes the glyph of the solution,
occasionally supplemented with its explanation and pronunciation. Solving
Chinese character riddles is a challenging task that demands understanding of
character glyph, general knowledge, and a grasp of figurative language. In this
paper, we construct a \textbf{C}hinese \textbf{C}haracter riddle dataset named
CC-Riddle, which covers the majority of common simplified Chinese characters.
The construction process is a combination of web crawling, language model
generation and manual filtering. In generation stage, we input the Chinese
phonetic alphabet, glyph and meaning of the solution character into the
generation model, which then produces multiple riddle descriptions. The
generated riddles are then manually filtered and the final CC-Riddle dataset is
composed of both human-written riddles and these filtered, generated riddles.
In order to assess the performance of language models on the task of solving
character riddles, we use retrieval-based, generative and multiple-choice QA
strategies to test three language models: BERT, ChatGPT and ChatGLM. The test
results reveal that current language models still struggle to solve Chinese
character riddles. CC-Riddle is publicly available at
\url{https://github.com/pku0xff/CC-Riddle}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Nano: Nested Human-in-the-Loop Reward Learning for Few-shot Language Model Control. (arXiv:2211.05750v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.05750">
<div class="article-summary-box-inner">
<span><p>Pretrained language models have demonstrated extraordinary capabilities in
language generation. However, real-world tasks often require controlling the
distribution of generated text in order to mitigate bias, promote fairness, and
achieve personalization. Existing techniques for controlling the distribution
of generated text only work with quantified distributions, which require
pre-defined categories, proportions of the distribution, or an existing corpus
following the desired distributions. However, many important distributions,
such as personal preferences, are unquantified. In this work, we tackle the
problem of generating text following arbitrary distributions (quantified and
unquantified) by proposing Nano, a few-shot human-in-the-loop training
algorithm that continuously learns from human feedback. Nano achieves
state-of-the-art results on single topic/attribute as well as quantified
distribution control compared to previous works. We also show that Nano is able
to learn unquantified distributions, achieves personalization, and captures
differences between different individuals' personal preferences with high
sample efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust and Explainable Identification of Logical Fallacies in Natural Language Arguments. (arXiv:2212.07425v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.07425">
<div class="article-summary-box-inner">
<span><p>The spread of misinformation, propaganda, and flawed argumentation has been
amplified in the Internet era. Given the volume of data and the subtlety of
identifying violations of argumentation norms, supporting information analytics
tasks, like content moderation, with trustworthy methods that can identify
logical fallacies is essential. In this paper, we formalize prior theoretical
work on logical fallacies into a comprehensive three-stage evaluation framework
of detection, coarse-grained, and fine-grained classification. We adapt
existing evaluation datasets for each stage of the evaluation. We employ three
families of robust and explainable methods based on prototype reasoning,
instance-based reasoning, and knowledge injection. The methods combine language
models with background knowledge and explainable mechanisms. Moreover, we
address data sparsity with strategies for data augmentation and curriculum
learning. Our three-stage framework natively consolidates prior datasets and
methods from existing tasks, like propaganda detection, serving as an
overarching evaluation testbed. We extensively evaluate these methods on our
datasets, focusing on their robustness and explainability. Our results provide
insight into the strengths and weaknesses of the methods on different
components and fallacy classes, indicating that fallacy identification is a
challenging task that may require specialized forms of reasoning to capture
various classes. We share our open-source code and data on GitHub to support
further work on logical fallacy identification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A comprehensive review of automatic text summarization techniques: method, data, evaluation and coding. (arXiv:2301.03403v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.03403">
<div class="article-summary-box-inner">
<span><p>We provide a literature review about Automatic Text Summarization (ATS)
systems. We consider a citation-based approach. We start with some popular and
well-known papers that we have in hand about each topic we want to cover and we
have tracked the "backward citations" (papers that are cited by the set of
papers we knew beforehand) and the "forward citations" (newer papers that cite
the set of papers we knew beforehand). In order to organize the different
methods, we present the diverse approaches to ATS guided by the mechanisms they
use to generate a summary. Besides presenting the methods, we also present an
extensive review of the datasets available for summarization tasks and the
methods used to evaluate the quality of the summaries. Finally, we present an
empirical exploration of these methods using the CNN Corpus dataset that
provides golden summaries for extractive and abstractive methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Large Language Models to Power Chatbots for Collecting User Self-Reported Data. (arXiv:2301.05843v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.05843">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) provide a new way to build chatbots by accepting
natural language prompts. Yet, it is unclear how to design prompts to power
chatbots to carry on naturalistic conversations while pursuing a given goal,
such as collecting self-report data from users. We explore what design factors
of prompts can help steer chatbots to talk naturally and collect data reliably.
To this aim, we formulated four prompt designs with different structures and
personas. Through an online study (N = 48) where participants conversed with
chatbots driven by different designs of prompts, we assessed how prompt designs
and conversation topics affected the conversation flows and users' perceptions
of chatbots. Our chatbots covered 79% of the desired information slots during
conversations, and the designs of prompts and topics significantly influenced
the conversation flows and the data collection performance. We discuss the
opportunities and challenges of building chatbots with LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HL Dataset: Visually-grounded Description of Scenes, Actions and Rationales. (arXiv:2302.12189v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12189">
<div class="article-summary-box-inner">
<span><p>Current captioning datasets focus on object-centric captions, describing the
visible objects in the image, e.g. "people eating food in a park". Although
these datasets are useful to evaluate the ability of Vision &amp; Language models
to recognize and describe visual content, they do not support controlled
experiments involving model testing or fine-tuning, with more high-level
captions, which humans find easy and natural to produce. For example, people
often describe images based on the type of scene they depict ('people at a
holiday resort') and the actions they perform ('people having a picnic'). Such
descriptions draw on personal experience and commonsense assumptions. We
present the High-Level Dataset a dataset extending 14997 images from the COCO
dataset, aligned with a new set of 134,973 human-annotated (high-level)
captions collected along three axes: scenes, actions, and rationales. We
further extend this dataset with confidence scores collected from an
independent set of readers, as well as a set of narrative captions generated
synthetically, by combining each of the three axes. We describe this dataset
and analyse it extensively. We also present baseline results for the High-Level
Captioning task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages. (arXiv:2303.01037v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01037">
<div class="article-summary-box-inner">
<span><p>We introduce the Universal Speech Model (USM), a single large model that
performs automatic speech recognition (ASR) across 100+ languages. This is
achieved by pre-training the encoder of the model on a large unlabeled
multilingual dataset of 12 million (M) hours spanning over 300 languages, and
fine-tuning on a smaller labeled dataset. We use multilingual pre-training with
random-projection quantization and speech-text modality matching to achieve
state-of-the-art performance on downstream multilingual ASR and speech-to-text
translation tasks. We also demonstrate that despite using a labeled training
set 1/7-th the size of that used for the Whisper model, our model exhibits
comparable or better performance on both in-domain and out-of-domain speech
recognition tasks across many languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Text Generation with Cooperative Training. (arXiv:2303.09075v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09075">
<div class="article-summary-box-inner">
<span><p>Recently, there has been a surge in the use of generated data to enhance the
performance of downstream models, largely due to the advancements in
pre-trained language models. However, most prevailing methods trained
generative and discriminative models in isolation, which left them unable to
adapt to changes in each other. These approaches lead to generative models that
are prone to deviating from the true data distribution and providing limited
benefits to discriminative models. While some works have proposed jointly
training generative and discriminative language models, their methods remain
challenging due to the non-differentiable nature of discrete data. To overcome
these issues, we introduce a \textit{self-consistent learning} framework in the
text field that involves training a discriminator and generator cooperatively
in a closed-loop manner until a scoring consensus is reached. By learning
directly from selected samples, our framework are able to mitigate training
instabilities such as mode collapse and non-convergence. Extensive experiments
on four downstream benchmarks, including AFQMC, CHIP-STS, QQP, and MRPC,
demonstrate the efficacy of the proposed framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language-Guided Audio-Visual Source Separation via Trimodal Consistency. (arXiv:2303.16342v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.16342">
<div class="article-summary-box-inner">
<span><p>We propose a self-supervised approach for learning to perform audio source
separation in videos based on natural language queries, using only unlabeled
video and audio pairs as training data. A key challenge in this task is
learning to associate the linguistic description of a sound-emitting object to
its visual features and the corresponding components of the audio waveform, all
without access to annotations during training. To overcome this challenge, we
adapt off-the-shelf vision-language foundation models to provide pseudo-target
supervision via two novel loss functions and encourage a stronger alignment
between the audio, visual and natural language modalities. During inference,
our approach can separate sounds given text, video and audio input, or given
text and audio input alone. We demonstrate the effectiveness of our
self-supervised approach on three audio-visual separation datasets, including
MUSIC, SOLOS and AudioSet, where we outperform state-of-the-art strongly
supervised approaches despite not using object detectors or text labels during
training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controllable Textual Inversion for Personalized Text-to-Image Generation. (arXiv:2304.05265v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.05265">
<div class="article-summary-box-inner">
<span><p>The recent large-scale generative modeling has attained unprecedented
performance especially in producing high-fidelity images driven by text
prompts. Text inversion (TI), alongside the text-to-image model backbones, is
proposed as an effective technique in personalizing the generation when the
prompts contain user-defined, unseen or long-tail concept tokens. Despite that,
we find and show that the deployment of TI remains full of "dark-magics" -- to
name a few, the harsh requirement of additional datasets, arduous human efforts
in the loop and lack of robustness. In this work, we propose a much-enhanced
version of TI, dubbed Controllable Textual Inversion (COTI), in resolving all
the aforementioned problems and in turn delivering a robust, data-efficient and
easy-to-use framework. The core to COTI is a theoretically-guided loss
objective instantiated with a comprehensive and novel weighted scoring
mechanism, encapsulated by an active-learning paradigm. The extensive results
show that COTI significantly outperforms the prior TI-related approaches with a
26.05 decrease in the FID score and a 23.00% boost in the R-precision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ArguGPT: evaluating, understanding and identifying argumentative essays generated by GPT models. (arXiv:2304.07666v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07666">
<div class="article-summary-box-inner">
<span><p>AI generated content (AIGC) presents considerable challenge to educators
around the world. Instructors need to be able to detect such text generated by
large language models, either with the naked eye or with the help of some
tools. There is also growing need to understand the lexical, syntactic and
stylistic features of AIGC. To address these challenges in English language
teaching, we first present ArguGPT, a balanced corpus of 4,038 argumentative
essays generated by 7 GPT models in response to essay prompts from three
sources: (1) in-class or homework exercises, (2) TOEFL and (3) GRE writing
tasks. Machine-generated texts are paired with roughly equal number of
human-written essays with three score levels matched in essay prompts. We then
hire English instructors to distinguish machine essays from human ones. Results
show that when first exposed to machine-generated essays, the instructors only
have an accuracy of 61% in detecting them. But the number rises to 67% after
one round of minimal self-training. Next, we perform linguistic analyses of
these essays, which show that machines produce sentences with more complex
syntactic structures while human essays tend to be lexically more complex.
Finally, we test existing AIGC detectors and build our own detectors using SVMs
and RoBERTa. Results suggest that a RoBERTa fine-tuned with the training set of
ArguGPT achieves above 90% accuracy in both essay- and sentence-level
classification. To the best of our knowledge, this is the first comprehensive
analysis of argumentative essays produced by generative large language models.
Machine-authored essays in ArguGPT and our models will be made publicly
available at https://github.com/huhailinguist/ArguGPT
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GenQ: Automated Question Generation to Support Caregivers While Reading Stories with Children. (arXiv:2305.16809v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16809">
<div class="article-summary-box-inner">
<span><p>When caregivers ask open--ended questions to motivate dialogue with children,
it facilitates the child's reading comprehension skills.Although there is scope
for use of technological tools, referred here as "intelligent tutoring
systems", to scaffold this process, it is currently unclear whether existing
intelligent systems that generate human--language like questions is beneficial.
Additionally, training data used in the development of these automated question
generation systems is typically sourced without attention to demographics, but
people with different cultural backgrounds may ask different questions. As a
part of a broader project to design an intelligent reading support app for
Latinx children, we crowdsourced questions from Latinx caregivers and
noncaregivers as well as caregivers and noncaregivers from other demographics.
We examine variations in question--asking within this dataset mediated by
individual, cultural, and contextual factors. We then design a system that
automatically extracts templates from this data to generate open--ended
questions that are representative of those asked by Latinx caregivers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Auxiliary Domain Parallel Data in Intermediate Task Fine-tuning for Low-resource Translation. (arXiv:2306.01382v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01382">
<div class="article-summary-box-inner">
<span><p>NMT systems trained on Pre-trained Multilingual Sequence-Sequence (PMSS)
models flounder when sufficient amounts of parallel data is not available for
fine-tuning. This specifically holds for languages missing/under-represented in
these models. The problem gets aggravated when the data comes from different
domains. In this paper, we show that intermediate-task fine-tuning (ITFT) of
PMSS models is extremely beneficial for domain-specific NMT, especially when
target domain data is limited/unavailable and the considered languages are
missing or under-represented in the PMSS model. We quantify the domain-specific
results variations using a domain-divergence test, and show that ITFT can
mitigate the impact of domain divergence to some extent.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and Multi-Dialect Corpus for Speech Representation Disentanglement. (arXiv:2306.15354v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15354">
<div class="article-summary-box-inner">
<span><p>Disentangling uncorrelated information in speech utterances is a crucial
research topic within speech community. Different speech-related tasks focus on
extracting distinct speech representations while minimizing the affects of
other uncorrelated information. We present a large-scale speech corpus to
facilitate the research of speech representation disentanglement. 3D-Speaker
contains over 10,000 speakers, each of whom are simultaneously recorded by
multiple Devices, locating at different Distances, and some speakers are
speaking multiple Dialects. The controlled combinations of multi-dimensional
audio data yield a matrix of a diverse blend of speech representation
entanglement, thereby motivating intriguing methods to untangle them. The
multi-domain nature of 3D-Speaker also makes it a suitable resource to evaluate
large universal speech models and experiment methods of out-of-domain learning
and self-supervised learning. https://3dspeaker.github.io/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CARE-MI: Chinese Benchmark for Misinformation Evaluation in Maternity and Infant Care. (arXiv:2307.01458v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.01458">
<div class="article-summary-box-inner">
<span><p>The recent advances in natural language processing (NLP), have led to a new
trend of applying large language models (LLMs) to real-world scenarios. While
the latest LLMs are astonishingly fluent when interacting with humans, they
suffer from the misinformation problem by unintentionally generating factually
false statements. This can lead to harmful consequences, especially when
produced within sensitive contexts, such as healthcare. Yet few previous works
have focused on evaluating misinformation in the long-form (LF) generation of
LLMs, especially for knowledge-intensive topics. Moreover, although LLMs have
been shown to perform well in different languages, misinformation evaluation
has been mostly conducted in English. To this end, we present a benchmark,
CARE-MI, for evaluating LLM misinformation in: 1) a sensitive topic,
specifically the maternity and infant care domain; and 2) a language other than
English, namely Chinese. Most importantly, we provide an innovative paradigm
for building LF generation evaluation benchmarks that can be transferred to
other knowledge-intensive domains and low-resourced languages. Our proposed
benchmark fills the gap between the extensive usage of LLMs and the lack of
datasets for assessing the misinformation generated by these models. It
contains 1,612 expert-checked questions, accompanied with human-selected
references. Using our benchmark, we conduct extensive experiments and found
that current Chinese LLMs are far from perfect in the topic of maternity and
infant care. In an effort to minimize the reliance on human resources for
performance evaluation, we offer off-the-shelf judgment models for
automatically assessing the LF output of LLMs given benchmark questions.
Moreover, we compare potential solutions for LF generation evaluation and
provide insights for building better automated metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Domain Adaptation of Sentence Embeddings Using Adapters. (arXiv:2307.03104v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03104">
<div class="article-summary-box-inner">
<span><p>Sentence embeddings enable us to capture the semantic similarity of short
texts. Most sentence embedding models are trained for general semantic textual
similarity tasks. Therefore, to use sentence embeddings in a particular domain,
the model must be adapted to it in order to achieve good results. Usually, this
is done by fine-tuning the entire sentence embedding model for the domain of
interest. While this approach yields state-of-the-art results, all of the
model's weights are updated during fine-tuning, making this method
resource-intensive. Therefore, instead of fine-tuning entire sentence embedding
models for each target domain individually, we propose to train lightweight
adapters. These domain-specific adapters do not require fine-tuning all
underlying sentence embedding model parameters. Instead, we only train a small
number of additional parameters while keeping the weights of the underlying
sentence embedding model fixed. Training domain-specific adapters allows always
using the same base model and only exchanging the domain-specific adapters to
adapt sentence embeddings to a specific domain. We show that using adapters for
parameter-efficient domain adaptation of sentence embeddings yields competitive
performance within 1% of a domain-adapted, entirely fine-tuned sentence
embedding model while only training approximately 3.6% of the parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Named entity recognition using GPT for identifying comparable companies. (arXiv:2307.07420v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.07420">
<div class="article-summary-box-inner">
<span><p>For both public and private firms, comparable companies' analysis is widely
used as a method for company valuation. In particular, the method is of great
value for valuation of private equity companies. The several approaches to the
comparable companies' method usually rely on a qualitative approach to
identifying similar peer companies, which tend to use established industry
classification schemes and/or analyst intuition and knowledge. However, more
quantitative methods have started being used in the literature and in the
private equity industry, in particular, machine learning clustering, and
natural language processing (NLP). For NLP methods, the process consists of
extracting product entities from e.g., the company's website or company
descriptions from some financial database system and then to perform similarity
analysis. Here, using companies' descriptions/summaries from publicly available
companies' Wikipedia websites, we show that using large language models (LLMs),
such as GPT from OpenAI, has a much higher precision and success rate than
using the standard named entity recognition (NER) methods which use manual
annotation. We demonstrate quantitatively a higher precision rate, and show
that, qualitatively, it can be used to create appropriate comparable companies
peer groups which could then be used for equity valuation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity Using Contrastive Learning and Structured Knowledge. (arXiv:2307.07851v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.07851">
<div class="article-summary-box-inner">
<span><p>Generic sentence embeddings provide a coarse-grained approximation of
semantic textual similarity but ignore specific aspects that make texts
similar. Conversely, aspect-based sentence embeddings provide similarities
between texts based on certain predefined aspects. Thus, similarity predictions
of texts are more targeted to specific requirements and more easily
explainable. In this paper, we present AspectCSE, an approach for aspect-based
contrastive learning of sentence embeddings. Results indicate that AspectCSE
achieves an average improvement of 3.97% on information retrieval tasks across
multiple aspects compared to the previous best results. We also propose using
Wikidata knowledge graph properties to train models of multi-aspect sentence
embeddings in which multiple specific aspects are simultaneously considered
during similarity predictions. We demonstrate that multi-aspect embeddings
outperform single-aspect embeddings on aspect-specific information retrieval
tasks. Finally, we examine the aspect-based sentence embedding space and
demonstrate that embeddings of semantically similar aspect labels are often
close, even without explicit similarity training between different aspect
labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the Landscape of Natural Language Processing Research. (arXiv:2307.10652v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.10652">
<div class="article-summary-box-inner">
<span><p>As an efficient approach to understand, generate, and process natural
language texts, research in natural language processing (NLP) has exhibited a
rapid spread and wide adoption in recent years. Given the increasing research
work in this area, several NLP-related approaches have been surveyed in the
research community. However, a comprehensive study that categorizes established
topics, identifies trends, and outlines areas for future research remains
absent. Contributing to closing this gap, we have systematically classified and
analyzed research papers in the ACL Anthology. As a result, we present a
structured overview of the research landscape, provide a taxonomy of fields of
study in NLP, analyze recent developments in NLP, summarize our findings, and
highlight directions for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MASR: Multi-label Aware Speech Representation. (arXiv:2307.10982v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.10982">
<div class="article-summary-box-inner">
<span><p>In the recent years, speech representation learning is constructed primarily
as a self-supervised learning (SSL) task, using the raw audio signal alone,
while ignoring the side-information that is often available for a given speech
recording. In this paper, we propose MASR, a Multi-label Aware Speech
Representation learning framework, which addresses the aforementioned
limitations. MASR enables the inclusion of multiple external knowledge sources
to enhance the utilization of meta-data information. The external knowledge
sources are incorporated in the form of sample-level pair-wise similarity
matrices that are useful in a hard-mining loss. A key advantage of the MASR
framework is that it can be combined with any choice of SSL method. Using MASR
representations, we perform evaluations on several downstream tasks such as
language identification, speech recognition and other non-semantic tasks such
as speaker and emotion recognition. In these experiments, we illustrate
significant performance improvements for the MASR over other established
benchmarks. We perform a detailed analysis on the language identification task
to provide insights on how the proposed loss function enables the
representations to separate closely related languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Challenging the Machinery of Generative AI with Fact-Checking: Ontology-Driven Biological Graphs for Verifying Human Disease-Gene Links. (arXiv:2308.03929v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.03929">
<div class="article-summary-box-inner">
<span><p>Background: Since the launch of various generative AI tools, scientists have
been striving to evaluate their capabilities and contents, in the hope of
establishing trust in their generative abilities. Regulations and guidelines
are emerging to verify generated contents and identify novel uses. Objective:
we aspire to demonstrate how ChatGPT claims are checked computationally using
the rigor of network models. We aim to achieve fact-checking of the knowledge
embedded in biological graphs that were contrived from ChatGPT contents at the
aggregate level. Methods: We adopted a biological networks approach that
enables the systematic interrogation of ChatGPT's linked entities. We designed
an ontology-driven fact-checking algorithm that compares biological graphs
constructed from approximately 200,000 PubMed abstracts with counterparts
constructed from a dataset generated using the ChatGPT-3.5 Turbo model.
Results: in 10-samples of 250 randomly selected records a ChatGPT dataset of
1000 "simulated" articles, the fact-checking link accuracy ranged from 70% to
86%. The computational process was followed by a manual process using IntAct
Interaction database and the Gene regulatory network database (GRNdb) to
confirm the validity of the links identified computationally. We also found
that the proximity of the edges of ChatGPT graphs were significantly shorter
(90 -- 153) while literature distances were (236 -- 765). This pattern held
true in all 10-samples. Conclusion: This study demonstrated high accuracy of
aggregate disease-gene links relationships found in ChatGPT-generated texts.
The strikingly consistent pattern offers an illuminate new biological pathways
that may open the door for new research opportunities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Objective Evaluation of Socially-Situated Conversational Robots: Assessing Human-Likeness through Multimodal User Behaviors. (arXiv:2308.11020v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.11020">
<div class="article-summary-box-inner">
<span><p>This paper tackles the challenging task of evaluating socially situated
conversational robots and presents a novel objective evaluation approach that
relies on multimodal user behaviors. In this study, our main focus is on
assessing the human-likeness of the robot as the primary evaluation metric.
While previous research often relied on subjective evaluations from users, our
approach aims to evaluate the robot's human-likeness based on observable user
behaviors indirectly, thus enhancing objectivity and reproducibility. To begin,
we created an annotated dataset of human-likeness scores, utilizing user
behaviors found in an attentive listening dialogue corpus. We then conducted an
analysis to determine the correlation between multimodal user behaviors and
human-likeness scores, demonstrating the feasibility of our proposed
behavior-based evaluation method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text Style Transfer Evaluation Using Large Language Models. (arXiv:2308.13577v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13577">
<div class="article-summary-box-inner">
<span><p>Evaluating Text Style Transfer (TST) is a complex task due to its
multifaceted nature. The quality of the generated text is measured based on
challenging factors, such as style transfer accuracy, content preservation, and
overall fluency. While human evaluation is considered to be the gold standard
in TST assessment, it is costly and often hard to reproduce. Therefore,
automated metrics are prevalent in these domains. Nevertheless, it remains
unclear whether these automated metrics correlate with human evaluations.
Recent strides in Large Language Models (LLMs) have showcased their capacity to
match and even exceed average human performance across diverse, unseen tasks.
This suggests that LLMs could be a feasible alternative to human evaluation and
other automated metrics in TST evaluation. We compare the results of different
LLMs in TST using multiple input prompts. Our findings highlight a strong
correlation between (even zero-shot) prompting and human evaluation, showing
that LLMs often outperform traditional automated metrics. Furthermore, we
introduce the concept of prompt ensembling, demonstrating its ability to
enhance the robustness of TST evaluation. This research contributes to the
ongoing evaluation of LLMs in diverse tasks, offering insights into successful
outcomes and areas of limitation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CPSP: Learning Speech Concepts From Phoneme Supervision. (arXiv:2309.00424v3 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00424">
<div class="article-summary-box-inner">
<span><p>For fine-grained generation and recognition tasks such as
minimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic
speech recognition (ASR), the intermediate representations extracted from
speech should serve as a "bridge" between text and acoustic information,
containing information from both modalities. The semantic content is
emphasized, while the paralinguistic information such as speaker identity and
acoustic details should be de-emphasized. However, existing methods for
extracting fine-grained intermediate representations from speech suffer from
issues of excessive redundancy and dimension explosion. Contrastive learning is
a good method for modeling intermediate representations from two modalities.
However, existing contrastive learning methods in the audio field focus on
extracting global descriptive information for downstream audio classification
tasks, making them unsuitable for TTS, VC, and ASR tasks. To address these
issues, we propose a method named "Contrastive Token-Acoustic Pretraining
(CTAP)", which uses two encoders to bring phoneme and speech into a joint
multimodal space, learning how to connect phoneme and speech at the frame
level. The CTAP model is trained on 210k speech and phoneme text pairs,
achieving minimally-supervised TTS, VC, and ASR. The proposed CTAP method
offers a promising solution for fine-grained generation and recognition
downstream tasks in speech processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models. (arXiv:2309.01219v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.01219">
<div class="article-summary-box-inner">
<span><p>While large language models (LLMs) have demonstrated remarkable capabilities
across a range of downstream tasks, a significant concern revolves around their
propensity to exhibit hallucinations: LLMs occasionally generate content that
diverges from the user input, contradicts previously generated context, or
misaligns with established world knowledge. This phenomenon poses a substantial
challenge to the reliability of LLMs in real-world scenarios. In this paper, we
survey recent efforts on the detection, explanation, and mitigation of
hallucination, with an emphasis on the unique challenges posed by LLMs. We
present taxonomies of the LLM hallucination phenomena and evaluation
benchmarks, analyze existing approaches aiming at mitigating LLM hallucination,
and discuss potential directions for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models. (arXiv:2309.02706v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.02706">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) trained on massive corpora demonstrate
impressive capabilities in a wide range of tasks. While there are ongoing
efforts to adapt these models to languages beyond English, the attention given
to their evaluation methodologies remains limited. Current multilingual
benchmarks often rely on back translations or re-implementations of English
tests, limiting their capacity to capture unique cultural and linguistic
nuances. To bridge this gap for the Korean language, we introduce HAE-RAE
Bench, a dataset curated to challenge models lacking Korean cultural and
contextual depth. The dataset encompasses six downstream tasks across four
domains: vocabulary, history, general knowledge, and reading comprehension.
Contrary to traditional evaluation suites focused on token or sequence
classification and specific mathematical or logical reasoning, HAE-RAE Bench
emphasizes a model's aptitude for recalling Korean-specific knowledge and
cultural contexts. Comparative analysis with prior Korean benchmarks indicates
that the HAE-RAE Bench presents a greater challenge to non-native models, by
disturbing abilities and knowledge learned from English being transferred.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models as Black-Box Optimizers for Vision-Language Models. (arXiv:2309.05950v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.05950">
<div class="article-summary-box-inner">
<span><p>Vision-language models (VLMs) pre-trained on web-scale datasets have
demonstrated remarkable capabilities across a variety of vision and multimodal
tasks. Currently, fine-tuning methods for VLMs mainly operate in a white-box
setting, requiring access to model parameters for backpropagation. However,
many VLMs rely on proprietary data and are not open-source, which restricts the
use of white-box approaches for fine-tuning. Given that popular private large
language models (LLMs) like ChatGPT still offer a language-based user
interface, we aim to develop a novel fine-tuning approach for VLMs through
natural language prompts, thereby avoiding the need to access model parameters,
feature embeddings, or output logits. In this setup, we propose employing
chat-based LLMs as black-box optimizers to search for the best text prompt on
the illustrative task of few-shot image classification using CLIP.
Specifically, we adopt an automatic "hill-climbing" procedure that converges on
an effective prompt by evaluating the accuracy of current prompts and asking
LLMs to refine them based on textual feedback, all within a conversational
process without human-in-the-loop. In a challenging 1-shot learning setup, our
simple approach surpasses the white-box continuous prompting method (CoOp) by
an average of 1.5% across 11 datasets including ImageNet. Our approach also
outperforms OpenAI's manually crafted prompts. Additionally, we highlight the
advantage of conversational feedback that incorporates both positive and
negative prompts, suggesting that LLMs can utilize the implicit "gradient"
direction in textual feedback for a more efficient search. Lastly, we find that
the text prompts generated through our strategy are not only more interpretable
but also transfer well across different CLIP architectures in a black-box
manner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human Action Co-occurrence in Lifestyle Vlogs using Graph Link Prediction. (arXiv:2309.06219v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.06219">
<div class="article-summary-box-inner">
<span><p>We introduce the task of automatic human action co-occurrence identification,
i.e., determine whether two human actions can co-occur in the same interval of
time. We create and make publicly available the ACE (Action Co-occurrencE)
dataset, consisting of a large graph of ~12k co-occurring pairs of visual
actions and their corresponding video clips. We describe graph link prediction
models that leverage visual and textual information to automatically infer if
two actions are co-occurring. We show that graphs are particularly well suited
to capture relations between human actions, and the learned graph
representations are effective for our task and capture novel and relevant
information across different data domains. The ACE dataset and the code
introduced in this paper are publicly available at
https://github.com/MichiganNLP/vlog_action_co-occurrence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DBLPLink: An Entity Linker for the DBLP Scholarly Knowledge Graph. (arXiv:2309.07545v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.07545">
<div class="article-summary-box-inner">
<span><p>In this work, we present a web application named DBLPLink, which performs
entity linking over the DBLP scholarly knowledge graph. DBLPLink uses
text-to-text pre-trained language models, such as T5, to produce entity label
spans from an input text question. Entity candidates are fetched from a
database based on the labels, and an entity re-ranker sorts them based on
entity embeddings, such as TransE, DistMult and ComplEx. The results are
displayed so that users may compare and contrast the results between T5-small,
T5-base and the different KG embeddings used. The demo can be accessed at
https://ltdemos.informatik.uni-hamburg.de/dblplink/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions. (arXiv:2309.07875v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.07875">
<div class="article-summary-box-inner">
<span><p>Training large language models to follow instructions makes them perform
better on a wide range of tasks, generally becoming more helpful. However, a
perfectly helpful model will follow even the most malicious instructions and
readily generate harmful content. In this paper, we raise concerns over the
safety of models that only emphasize helpfulness, not safety, in their
instruction-tuning. We show that several popular instruction-tuned models are
highly unsafe. Moreover, we show that adding just 3% safety examples (a few
hundred demonstrations) in the training set when fine-tuning a model like LLaMA
can substantially improve their safety. Our safety-tuning does not make models
significantly less capable or helpful as measured by standard benchmarks.
However, we do find a behavior of exaggerated safety, where too much
safety-tuning makes models refuse to respond to reasonable prompts that
superficially resemble unsafe ones. Our study sheds light on trade-offs in
training LLMs to follow instructions and exhibit safe behavior.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recovering from Privacy-Preserving Masking with Large Language Models. (arXiv:2309.08628v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.08628">
<div class="article-summary-box-inner">
<span><p>Model adaptation is crucial to handle the discrepancy between proxy training
data and actual users data received. To effectively perform adaptation, textual
data of users is typically stored on servers or their local devices, where
downstream natural language processing (NLP) models can be directly trained
using such in-domain data. However, this might raise privacy and security
concerns due to the extra risks of exposing user information to adversaries.
Replacing identifying information in textual data with a generic marker has
been recently explored. In this work, we leverage large language models (LLMs)
to suggest substitutes of masked tokens and have their effectiveness evaluated
on downstream language modeling tasks. Specifically, we propose multiple
pre-trained and fine-tuned LLM-based approaches and perform empirical studies
on various datasets for the comparison of these methods. Experimental results
show that models trained on the obfuscation corpora are able to achieve
comparable performance with the ones trained on the original data without
privacy-preserving token masking.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DISC-LawLLM: Fine-tuning Large Language Models for Intelligent Legal Services. (arXiv:2309.11325v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.11325">
<div class="article-summary-box-inner">
<span><p>We propose DISC-LawLLM, an intelligent legal system utilizing large language
models (LLMs) to provide a wide range of legal services. We adopt legal
syllogism prompting strategies to construct supervised fine-tuning datasets in
the Chinese Judicial domain and fine-tune LLMs with legal reasoning capability.
We augment LLMs with a retrieval module to enhance models' ability to access
and utilize external legal knowledge. A comprehensive legal benchmark,
DISC-Law-Eval, is presented to evaluate intelligent legal systems from both
objective and subjective dimensions. Quantitative and qualitative results on
DISC-Law-Eval demonstrate the effectiveness of our system in serving various
users across diverse legal scenarios. The detailed resources are available at
https://github.com/FudanDISC/DISC-LawLLM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Data Collection and Unsupervised Learning for Code-switched Tunisian Arabic Automatic Speech Recognition. (arXiv:2309.11327v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.11327">
<div class="article-summary-box-inner">
<span><p>Crafting an effective Automatic Speech Recognition (ASR) solution for
dialects demands innovative approaches that not only address the data scarcity
issue but also navigate the intricacies of linguistic diversity. In this paper,
we address the aforementioned ASR challenge, focusing on the Tunisian dialect.
First, textual and audio data is collected and in some cases annotated. Second,
we explore self-supervision, semi-supervision and few-shot code-switching
approaches to push the state-of-the-art on different Tunisian test sets;
covering different acoustic, linguistic and prosodic conditions. Finally, and
given the absence of conventional spelling, we produce a human evaluation of
our transcripts to avoid the noise coming from spelling inadequacies in our
testing references. Our models, allowing to transcribe audio samples in a
linguistic mix involving Tunisian Arabic, English and French, and all the data
used during training and testing are released for public use and further
improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chain-of-Verification Reduces Hallucination in Large Language Models. (arXiv:2309.11495v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.11495">
<div class="article-summary-box-inner">
<span><p>Generation of plausible yet incorrect factual information, termed
hallucination, is an unsolved issue in large language models. We study the
ability of language models to deliberate on the responses they give in order to
correct their mistakes. We develop the Chain-of-Verification (CoVe) method
whereby the model first (i) drafts an initial response; then (ii) plans
verification questions to fact-check its draft; (iii) answers those questions
independently so the answers are not biased by other responses; and (iv)
generates its final verified response. In experiments, we show CoVe decreases
hallucinations across a variety of tasks, from list-based questions from
Wikidata, closed book MultiSpanQA and longform text generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Cambridge Law Corpus: A Corpus for Legal AI Research. (arXiv:2309.12269v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.12269">
<div class="article-summary-box-inner">
<span><p>We introduce the Cambridge Law Corpus (CLC), a corpus for legal AI research.
It consists of over 250 000 court cases from the UK. Most cases are from the
21st century, but the corpus includes cases as old as the 16th century. This
paper presents the first release of the corpus, containing the raw text and
meta-data. Together with the corpus, we provide annotations on case outcomes
for 638 cases, done by legal experts. Using our annotated data, we have trained
and evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to
provide benchmarks. We include an extensive legal and ethical discussion to
address the potentially sensitive nature of this material. As a consequence,
the corpus will only be released for research purposes under certain
restrictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A". (arXiv:2309.12288v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.12288">
<div class="article-summary-box-inner">
<span><p>We expose a surprising failure of generalization in auto-regressive large
language models (LLMs). If a model is trained on a sentence of the form "A is
B", it will not automatically generalize to the reverse direction "B is A".
This is the Reversal Curse. For instance, if a model is trained on "Olaf Scholz
was the ninth Chancellor of Germany", it will not automatically be able to
answer the question, "Who was the ninth Chancellor of Germany?". Moreover, the
likelihood of the correct answer ("Olaf Scholz") will not be higher than for a
random name. Thus, models exhibit a basic failure of logical deduction and do
not generalize a prevalent pattern in their training set (i.e. if "A is B''
occurs, "B is A" is more likely to occur). We provide evidence for the Reversal
Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as "Uriah
Hawthorne is the composer of 'Abyssal Melodies'" and showing that they fail to
correctly answer "Who composed 'Abyssal Melodies?'". The Reversal Curse is
robust across model sizes and model families and is not alleviated by data
augmentation. We also evaluate ChatGPT (GPT-3.5 and GPT-4) on questions about
real-world celebrities, such as "Who is Tom Cruise's mother? [A: Mary Lee
Pfeiffer]" and the reverse "Who is Mary Lee Pfeiffer's son?". GPT-4 correctly
answers questions like the former 79% of the time, compared to 33% for the
latter. This shows a failure of logical deduction that we hypothesize is caused
by the Reversal Curse. Code is available at
https://github.com/lukasberglund/reversal_curse.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers. (arXiv:2309.12570v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.12570">
<div class="article-summary-box-inner">
<span><p>The development of large language models (LLMs) capable of following
instructions and engaging in conversational interactions sparked increased
interest in their utilization across various support tools. We investigate the
utility of modern LLMs in assisting professional writers via an empirical user
study (n=30). The design of our collaborative writing interface is grounded in
the cognitive process model of writing that views writing as a goal-oriented
thinking process encompassing non-linear cognitive activities: planning,
translating, and reviewing. Participants are asked to submit a post-completion
survey to provide feedback on the potential and pitfalls of LLMs as writing
collaborators. Upon analyzing the writer-LLM interactions, we find that while
writers seek LLM's help across all three types of cognitive activities, they
find LLMs more helpful in translation and reviewing. Our findings from
analyzing both the interactions and the survey responses highlight future
research directions in creative writing assistance using LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatPRCS: A Personalized Support System for English Reading Comprehension based on ChatGPT. (arXiv:2309.12808v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.12808">
<div class="article-summary-box-inner">
<span><p>As a common approach to learning English, reading comprehension primarily
entails reading articles and answering related questions. However, the
complexity of designing effective exercises results in students encountering
standardized questions, making it challenging to align with individualized
learners' reading comprehension ability. By leveraging the advanced
capabilities offered by large language models, exemplified by ChatGPT, this
paper presents a novel personalized support system for reading comprehension,
referred to as ChatPRCS, based on the Zone of Proximal Development theory.
ChatPRCS employs methods including reading comprehension proficiency
prediction, question generation, and automatic evaluation, among others, to
enhance reading comprehension instruction. First, we develop a new algorithm
that can predict learners' reading comprehension abilities using their
historical data as the foundation for generating questions at an appropriate
level of difficulty. Second, a series of new ChatGPT prompt patterns is
proposed to address two key aspects of reading comprehension objectives:
question generation, and automated evaluation. These patterns further improve
the quality of generated questions. Finally, by integrating personalized
ability and reading comprehension prompt patterns, ChatPRCS is systematically
validated through experiments. Empirical results demonstrate that it provides
learners with high-quality reading comprehension questions that are broadly
aligned with expert-crafted questions at a statistical level.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-09-26 23:10:41.517323494 UTC">2023-09-26 23:10:41 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>