<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-03-06T01:30:00Z">03-06</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">INO at Factify 2: Structure Coherence based Multi-Modal Fact Verification. (arXiv:2303.01510v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01510">
<div class="article-summary-box-inner">
<span><p>This paper describes our approach to the multi-modal fact verification
(FACTIFY) challenge at AAAI2023. In recent years, with the widespread use of
social media, fake news can spread rapidly and negatively impact social
security. Automatic claim verification becomes more and more crucial to combat
fake news. In fact verification involving multiple modal data, there should be
a structural coherence between claim and document. Therefore, we proposed a
structure coherence-based multi-modal fact verification scheme to classify fake
news. Our structure coherence includes the following four aspects: sentence
length, vocabulary similarity, semantic similarity, and image similarity.
Specifically, CLIP and Sentence BERT are combined to extract text features, and
ResNet50 is used to extract image features. In addition, we also extract the
length of the text as well as the lexical similarity. Then the features were
concatenated and passed through the random forest classifier. Finally, our
weighted average F1 score has reached 0.8079, achieving 2nd place in FACTIFY2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mixture of Soft Prompts for Controllable Data Generation. (arXiv:2303.01580v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01580">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) effectively generate fluent text when the target
output follows natural language patterns. However, structured prediction tasks
confine the output format to a limited ontology, causing even very large models
to struggle since they were never trained with such restrictions in mind. The
difficulty of using LLMs for direct prediction is exacerbated in few-shot
learning scenarios, which commonly arise due to domain shift and resource
limitations. We flip the problem on its head by leveraging the LLM as a tool
for data augmentation rather than direct prediction. Our proposed Mixture of
Soft Prompts (MSP) serves as a parameter-efficient procedure for generating
data in a controlled manner. Denoising mechanisms are further applied to
improve the quality of synthesized data. Automatic metrics show our method is
capable of producing diverse and natural text, while preserving label
semantics. Moreover, MSP achieves state-of-the-art results on three benchmarks
when compared against strong baselines. Our method offers an alternate
data-centric approach for applying LLMs to complex prediction tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Technical report: Graph Neural Networks go Grammatical. (arXiv:2303.01590v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01590">
<div class="article-summary-box-inner">
<span><p>This paper proposes a new GNN design strategy. This strategy relies on
Context-Free Grammars (CFG) generating the matrix language MATLANG. It enables
us to ensure both WL-expressive power, substructure counting abilities and
spectral properties. Applying our strategy, we design Grammatical Graph Neural
Network G$ ^2$N$^2$, a provably 3-WL GNN able to count at edge-level cycles of
length up to 6 and able to reach band-pass filters. A large number of
experiments covering these properties corroborate the presented theoretical
results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QAID: Question Answering Inspired Few-shot Intent Detection. (arXiv:2303.01593v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01593">
<div class="article-summary-box-inner">
<span><p>Intent detection with semantically similar fine-grained intents is a
challenging task. To address it, we reformulate intent detection as a
question-answering retrieval task by treating utterances and intent names as
questions and answers. To that end, we utilize a question-answering retrieval
architecture and adopt a two stages training schema with batch contrastive
loss. In the pre-training stage, we improve query representations through
self-supervised training. Then, in the fine-tuning stage, we increase
contextualized token-level similarity scores between queries and answers from
the same intent. Our results on three few-shot intent detection benchmarks
achieve state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">APIContext2Com: Code Comment Generation by Incorporating Pre-Defined API Documentation. (arXiv:2303.01645v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01645">
<div class="article-summary-box-inner">
<span><p>Code comments are significantly helpful in comprehending software programs
and also aid developers to save a great deal of time in software maintenance.
Code comment generation aims to automatically predict comments in natural
language given a code snippet. Several works investigate the effect of
integrating external knowledge on the quality of generated comments. In this
study, we propose a solution, namely APIContext2Com, to improve the
effectiveness of generated comments by incorporating the pre-defined
Application Programming Interface (API) context. The API context includes the
definition and description of the pre-defined APIs that are used within the
code snippets. As the detailed API information expresses the functionality of a
code snippet, it can be helpful in better generating the code summary. We
introduce a seq-2-seq encoder-decoder neural network model with different sets
of multiple encoders to effectively transform distinct inputs into target
comments. A ranking mechanism is also developed to exclude non-informative
APIs, so that we can filter out unrelated APIs. We evaluate our approach using
the Java dataset from CodeSearchNet. The findings reveal that the proposed
model improves the best baseline by 1.88 (8.24 %), 2.16 (17.58 %), 1.38 (18.3
%), 0.73 (14.17 %), 1.58 (14.98 %) and 1.9 (6.92 %) for BLEU1, BLEU2, BLEU3,
BLEU4, METEOR, ROUGE-L respectively. Human evaluation and ablation studies
confirm the quality of the generated comments and the effect of architecture
and ranking APIs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DWFormer: Dynamic Window transFormer for Speech Emotion Recognition. (arXiv:2303.01694v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01694">
<div class="article-summary-box-inner">
<span><p>Speech emotion recognition is crucial to human-computer interaction. The
temporal regions that represent different emotions scatter in different parts
of the speech locally. Moreover, the temporal scales of important information
may vary over a large range within and across speech segments. Although
transformer-based models have made progress in this field, the existing models
could not precisely locate important regions at different temporal scales. To
address the issue, we propose Dynamic Window transFormer (DWFormer), a new
architecture that leverages temporal importance by dynamically splitting
samples into windows. Self-attention mechanism is applied within windows for
capturing temporal important information locally in a fine-grained way.
Cross-window information interaction is also taken into account for global
communication. DWFormer is evaluated on both the IEMOCAP and the MELD datasets.
Experimental results show that the proposed model achieves better performance
than the previous state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NCL: Textual Backdoor Defense Using Noise-augmented Contrastive Learning. (arXiv:2303.01742v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01742">
<div class="article-summary-box-inner">
<span><p>At present, backdoor attacks attract attention as they do great harm to deep
learning models. The adversary poisons the training data making the model being
injected with a backdoor after being trained unconsciously by victims using the
poisoned dataset. In the field of text, however, existing works do not provide
sufficient defense against backdoor attacks. In this paper, we propose a
Noise-augmented Contrastive Learning (NCL) framework to defend against textual
backdoor attacks when training models with untrustworthy data. With the aim of
mitigating the mapping between triggers and the target label, we add
appropriate noise perturbing possible backdoor triggers, augment the training
dataset, and then pull homology samples in the feature space utilizing
contrastive learning objective. Experiments demonstrate the effectiveness of
our method in defending three types of textual backdoor attacks, outperforming
the prior works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meme Sentiment Analysis Enhanced with Multimodal Spatial Encoding and Facial Embedding. (arXiv:2303.01781v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01781">
<div class="article-summary-box-inner">
<span><p>Internet memes are characterised by the interspersing of text amongst visual
elements. State-of-the-art multimodal meme classifiers do not account for the
relative positions of these elements across the two modalities, despite the
latent meaning associated with where text and visual elements are placed.
Against two meme sentiment classification datasets, we systematically show
performance gains from incorporating the spatial position of visual objects,
faces, and text clusters extracted from memes. In addition, we also present
facial embedding as an impactful enhancement to image representation in a
multimodal meme classifier. Finally, we show that incorporating this spatial
information allows our fully automated approaches to outperform their
corresponding baselines that rely on additional human validation of
OCR-extracted text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploiting Language Relatedness in Machine Translation Through Domain Adaptation Techniques. (arXiv:2303.01793v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01793">
<div class="article-summary-box-inner">
<span><p>One of the significant challenges of Machine Translation (MT) is the scarcity
of large amounts of data, mainly parallel sentence aligned corpora. If the
evaluation is as rigorous as resource-rich languages, both Neural Machine
Translation (NMT) and Statistical Machine Translation (SMT) can produce good
results with such large amounts of data. However, it is challenging to improve
the quality of MT output for low resource languages, especially in NMT and SMT.
In order to tackle the challenges faced by MT, we present a novel approach of
using a scaled similarity score of sentences, especially for related languages
based on a 5-gram KenLM language model with Kneser-ney smoothing technique for
filtering in-domain data from out-of-domain corpora that boost the translation
quality of MT. Furthermore, we employ other domain adaptation techniques such
as multi-domain, fine-tuning and iterative back-translation approach to compare
our novel approach on the Hindi-Nepali language pair for NMT and SMT. Our
approach succeeds in increasing ~2 BLEU point on multi-domain approach, ~3 BLEU
point on fine-tuning for NMT and ~2 BLEU point on iterative back-translation
approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Team Hitachi at SemEval-2023 Task 3: Exploring Cross-lingual Multi-task Strategies for Genre and Framing Detection in Online News. (arXiv:2303.01794v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01794">
<div class="article-summary-box-inner">
<span><p>This paper explains the participation of team Hitachi to SemEval-2023 Task 3
"Detecting the genre, the framing, and the persuasion techniques in online news
in a multi-lingual setup." Based on the multilingual, multi-task nature of the
task and the setting that training data is limited, we investigated different
strategies for training the pretrained language models under low resource
settings. Through extensive experiments, we found that (a)
cross-lingual/multi-task training, and (b) collecting an external balanced
dataset, can benefit the genre and framing detection. We constructed ensemble
models from the results and achieved the highest macro-averaged F1 scores in
Italian and Russian genre categorization subtasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PAGE: A Position-Aware Graph-Based Model for Emotion Cause Entailment in Conversation. (arXiv:2303.01795v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01795">
<div class="article-summary-box-inner">
<span><p>Conversational Causal Emotion Entailment (C2E2) is a task that aims at
recognizing the causes corresponding to a target emotion in a conversation. The
order of utterances in the conversation affects the causal inference. However,
most current position encoding strategies ignore the order relation among
utterances and speakers. To address the issue, we devise a novel position-aware
graph to encode the entire conversation, fully modeling causal relations among
utterances. The comprehensive experiments show that our method consistently
achieves state-of-the-art performance on two challenging test sets, proving the
effectiveness of our model. Our source code is available on Github:
https://github.com/XiaojieGu/PAGE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mapping Wordnets on the Fly with Permanent Sense Keys. (arXiv:2303.01847v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01847">
<div class="article-summary-box-inner">
<span><p>Most of the major databases on the semantic web have links to Princeton
WordNet (PWN) synonym set (synset) identifiers, which differ for each PWN
release, and are thus incompatible between versions. On the other hand, both
PWN and the more recent Open English Wordnet (OEWN) provide permanent word
sense identifiers (the sense keys), which can solve this interoperability
problem.
</p>
<p>We present an algorithm that runs in linear time, to automatically derive a
synset mapping between any pair of Wordnet versions that use PWN sense keys.
This allows to update old WordNet links, and seamlessly interoperate with newer
English Wordnet versions for which no prior mapping exists.
</p>
<p>By applying the proposed algorithm on the fly, at load time, we combine the
Open Multilingual Wordnet (OMW 1.4, which uses old PWN 3.0 identifiers) with
OEWN Edition 2021, and obtain almost perfect precision and recall. We compare
the results of our approach using respectively synset offsets, versus the
Collaborative InterLingual Index (CILI version 1.0) as synset identifiers, and
find that the synset offsets perform better than CILI 1.0 in all cases, except
a few ties.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering. (arXiv:2303.01903v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01903">
<div class="article-summary-box-inner">
<span><p>Knowledge-based visual question answering (VQA) requires external knowledge
beyond the image to answer the question. Early studies retrieve required
knowledge from explicit knowledge bases (KBs), which often introduces
irrelevant information to the question, hence restricting the performance of
their models. Recent works have sought to use a large language model (i.e.,
GPT-3) as an implicit knowledge engine to acquire the necessary knowledge for
answering. Despite the encouraging results achieved by these methods, we argue
that they have not fully activated the capacity of GPT-3 as the provided input
information is insufficient. In this paper, we present Prophet -- a
conceptually simple framework designed to prompt GPT-3 with answer heuristics
for knowledge-based VQA. Specifically, we first train a vanilla VQA model on a
specific knowledge-based VQA dataset without external knowledge. After that, we
extract two types of complementary answer heuristics from the model: answer
candidates and answer-aware examples. Finally, the two types of answer
heuristics are encoded into the prompts to enable GPT-3 to better comprehend
the task thus enhancing its capacity. Prophet significantly outperforms all
existing state-of-the-art methods on two challenging knowledge-based VQA
datasets, OK-VQA and A-OKVQA, delivering 61.1% and 55.7% accuracies on their
testing sets, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating the Translation Performance of a Large Multilingual Language Model: the Case of BLOOM. (arXiv:2303.01911v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01911">
<div class="article-summary-box-inner">
<span><p>The NLP community recently saw the release of a new large open-access
multilingual language model, BLOOM (BigScience et al., 2022) covering 46
languages. We focus on BLOOM's multilingual ability by evaluating its machine
translation performance across several datasets (WMT, Flores-101 and DiaBLa)
and language pairs (high- and low-resourced). Our results show that 0-shot
performance suffers from overgeneration and generating in the wrong language,
but this is greatly improved in the few-shot setting, with very good results
for a number of language pairs. We study several aspects including prompt
design, model sizes, cross-lingual transfer and the use of discursive context.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ancient Chinese Word Segmentation and Part-of-Speech Tagging Using Distant Supervision. (arXiv:2303.01912v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01912">
<div class="article-summary-box-inner">
<span><p>Ancient Chinese word segmentation (WSG) and part-of-speech tagging (POS) are
important to study ancient Chinese, but the amount of ancient Chinese WSG and
POS tagging data is still rare. In this paper, we propose a novel augmentation
method of ancient Chinese WSG and POS tagging data using distant supervision
over parallel corpus. However, there are still mislabeled and unlabeled ancient
Chinese words inevitably in distant supervision. To address this problem, we
take advantage of the memorization effects of deep neural networks and a small
amount of annotated data to get a model with much knowledge and a little noise,
and then we use this model to relabel the ancient Chinese sentences in parallel
corpus. Experiments show that the model trained over the relabeled data
outperforms the model trained over the data generated from distant supervision
and the annotated data. Our code is available at
https://github.com/farlit/ACDS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Less is More: Mitigate Spurious Correlations for Open-Domain Dialogue Response Generation Models by Causal Discovery. (arXiv:2303.01962v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01962">
<div class="article-summary-box-inner">
<span><p>In this paper, we conduct the first study on spurious correlations for
open-domain response generation models based on a corpus CGDIALOG curated in
our work. The cur rent models indeed suffer from spurious correlations and have
a tendency of generating irrelevant and generic responses. Inspired by causal
discovery algorithms, we propose a novel model-agnostic method for training and
inference of response generation model using a conditional independence
classifier. The classifier is trained by a constrained self-training method,
coined CONSTRAIN, to overcome data scarcity. The experimental results based on
both human and automatic evaluation show that our method significantly
outperforms the competitive baselines in terms of relevance, informativeness,
and fluency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Who could be behind QAnon? Authorship attribution with supervised machine-learning. (arXiv:2303.02078v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.02078">
<div class="article-summary-box-inner">
<span><p>A series of social media posts signed under the pseudonym "Q", started a
movement known as QAnon, which led some of its most radical supporters to
violent and illegal actions. To identify the person(s) behind Q, we evaluate
the coincidence between the linguistic properties of the texts written by Q and
to those written by a list of suspects provided by journalistic investigation.
To identify the authors of these posts, serious challenges have to be
addressed. The "Q drops" are very short texts, written in a way that constitute
a sort of literary genre in itself, with very peculiar features of style. These
texts might have been written by different authors, whose other writings are
often hard to find. After an online ethnology of the movement, necessary to
collect enough material written by these thirteen potential authors, we use
supervised machine learning to build stylistic profiles for each of them. We
then performed a rolling analysis on Q's writings, to see if any of those
linguistic profiles match the so-called 'QDrops' in part or entirety. We
conclude that two different individuals, Paul F. and Ron W., are the closest
match to Q's linguistic signature, and they could have successively written Q's
texts. These potential authors are not high-ranked personality from the U.S.
administration, but rather social media activists.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners. (arXiv:2303.02151v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.02151">
<div class="article-summary-box-inner">
<span><p>Visual recognition in low-data regimes requires deep neural networks to learn
generalized representations from limited training samples. Recently, CLIP-based
methods have shown promising few-shot performance benefited from the
contrastive language-image pre-training. We then question, if the more diverse
pre-training knowledge can be cascaded to further assist few-shot
representation learning. In this paper, we propose CaFo, a Cascade of
Foundation models that incorporates diverse prior knowledge of various
pre-training paradigms for better few-shot learning. Our CaFo incorporates
CLIP's language-contrastive knowledge, DINO's vision-contrastive knowledge,
DALL-E's vision-generative knowledge, and GPT-3's language-generative
knowledge. Specifically, CaFo works by 'Prompt, Generate, then Cache'. Firstly,
we leverage GPT-3 to produce textual inputs for prompting CLIP with rich
downstream linguistic semantics. Then, we generate synthetic images via DALL-E
to expand the few-shot training data without any manpower. At last, we
introduce a learnable cache model to adaptively blend the predictions from CLIP
and DINO. By such collaboration, CaFo can fully unleash the potential of
different pre-training methods and unify them to perform state-of-the-art for
few-shot classification. Code is available at
https://github.com/ZrrSkywalker/CaFo.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic-Preserving Adversarial Text Attacks. (arXiv:2108.10015v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10015">
<div class="article-summary-box-inner">
<span><p>Deep neural networks (DNNs) are known to be vulnerable to adversarial images,
while their robustness in text classification is rarely studied. Several lines
of text attack methods have been proposed in the literature, including
character-level, word-level, and sentence-level attacks. However, it is still a
challenge to minimize the number of word changes necessary to induce
misclassification, while simultaneously ensuring lexical correctness, syntactic
soundness, and semantic similarity. In this paper, we propose a Bigram and
Unigram based adaptive Semantic Preservation Optimization (BU-SPO) method to
examine the vulnerability of deep models. Our method has four major merits.
Firstly, we propose to attack text documents not only at the unigram word level
but also at the bigram level which better keeps semantics and avoids producing
meaningless outputs. Secondly, we propose a hybrid method to replace the input
words with options among both their synonyms candidates and sememe candidates,
which greatly enriches the potential substitutions compared to only using
synonyms. Thirdly, we design an optimization algorithm, i.e., Semantic
Preservation Optimization (SPO), to determine the priority of word
replacements, aiming to reduce the modification cost. Finally, we further
improve the SPO with a semantic Filter (named SPOF) to find the adversarial
example with the highest semantic similarity. We evaluate the effectiveness of
our BU-SPO and BU-SPOF on IMDB, AG's News, and Yahoo! Answers text datasets by
attacking four popular DNNs models. Results show that our methods achieve the
highest attack success rates and semantics rates by changing the smallest
number of words compared with existing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are We Really Making Much Progress? Bag-of-Words vs. Sequence vs. Graph vs. Hierarchy for Single- and Multi-Label Text Classification. (arXiv:2204.03954v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.03954">
<div class="article-summary-box-inner">
<span><p>The popularity of graph neural networks has triggered a resurgence of
graph-based methods for single-label and multi-label text classification.
However, it is unclear whether these graph-based methods are beneficial
compared to standard machine learning methods and modern pretrained language
models. We compare a rich selection of bag-of-words, sequence-based,
graph-based, and hierarchical methods for text classification. We aggregate
results from the literature over 5 single-label and 7 multi-label datasets and
run our own experiments. Our findings unambiguously demonstrate that for
single-label and multi-label classification tasks, the graph-based methods fail
to outperform fine-tuned language models and sometimes even perform worse than
standard machine learning methods like multilayer perceptron (MLP) on a
bag-of-words. This questions the enormous amount of effort put into the
development of new graph-based methods in the last years and the promises they
make for text classification. Given our extensive experiments, we confirm that
pretrained language models remain state-of-the-art in text classification
despite all recent specialized advances. We argue that future work in text
classification should thoroughly test against strong baselines like MLPs to
properly assess the true scientific progress.
</p>
<p>The source code is available: https://github.com/drndr/multilabel-text-clf
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FashionCLIP: Connecting Language and Images for Product Representations. (arXiv:2204.03972v3 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.03972">
<div class="article-summary-box-inner">
<span><p>The steady rise of online shopping goes hand in hand with the development of
increasingly complex ML and NLP models. While most use cases are cast as
specialized supervised learning problems, we argue that practitioners would
greatly benefit from more transferable representations of products. In this
work, we build on recent developments in contrastive learning to train
FashionCLIP, a CLIP-like model for the fashion industry. We showcase its
capabilities for retrieval, classification and grounding, and release our model
and code to the community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Better Masking for Better Language Model Pre-training. (arXiv:2208.10806v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.10806">
<div class="article-summary-box-inner">
<span><p>Masked Language Modeling (MLM) has been widely used as the denoising
objective in pre-training language models (PrLMs). Existing PrLMs commonly
adopt a Random-Token Masking strategy where a fixed masking ratio is applied
and different contents are masked by an equal probability throughout the entire
training. However, the model may receive complicated impact from pre-training
status, which changes accordingly as training time goes on. In this paper, we
show that such time-invariant MLM settings on masking ratio and masked content
are unlikely to deliver an optimal outcome, which motivates us to explore the
influence of time-variant MLM settings. We propose two scheduled masking
approaches that adaptively tune the masking ratio and masked content in
different training stages, which improves the pre-training efficiency and
effectiveness verified on the downstream tasks. Our work is a pioneer study on
time-variant masking strategy on ratio and content and gives a better
understanding of how masking ratio and masked content influence the MLM
pre-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LED: Lexicon-Enlightened Dense Retriever for Large-Scale Retrieval. (arXiv:2208.13661v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.13661">
<div class="article-summary-box-inner">
<span><p>Retrieval models based on dense representations in semantic space have become
an indispensable branch for first-stage retrieval. These retrievers benefit
from surging advances in representation learning towards compressive global
sequence-level embeddings. However, they are prone to overlook local salient
phrases and entity mentions in texts, which usually play pivot roles in
first-stage retrieval. To mitigate this weakness, we propose to make a dense
retriever align a well-performing lexicon-aware representation model. The
alignment is achieved by weakened knowledge distillations to enlighten the
retriever via two aspects -- 1) a lexicon-augmented contrastive objective to
challenge the dense encoder and 2) a pair-wise rank-consistent regularization
to make dense model's behavior incline to the other. We evaluate our model on
three public benchmarks, which shows that with a comparable lexicon-aware
retriever as the teacher, our proposed dense one can bring consistent and
significant improvements, and even outdo its teacher. In addition, we found our
improvement on the dense retriever is complementary to the standard ranker
distillation, which can further lift state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Linearly Mapping from Image to Text Space. (arXiv:2209.15162v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.15162">
<div class="article-summary-box-inner">
<span><p>The extent to which text-only language models (LMs) learn to represent
features of the non-linguistic world is an open question. Prior work has shown
that pretrained LMs can be taught to caption images when a vision model's
parameters are optimized to encode images in the language space. We test a
stronger hypothesis: that the conceptual representations learned by frozen
text-only models and vision-only models are similar enough that this can be
achieved with a linear map. We show that the image representations from vision
models can be transferred as continuous prompts to frozen LMs by training only
a single linear projection. Using these to prompt the LM achieves competitive
performance on captioning and visual question answering tasks compared to
models that tune both the image encoder and text decoder (such as the MAGMA
model). We compare three image encoders with increasing amounts of linguistic
supervision seen during pretraining: BEIT (no linguistic information),
NF-ResNET (lexical category information), and CLIP (full natural language
descriptions). We find that all three encoders perform equally well at
transferring visual property information to the language model (e.g., whether
an animal is large or small), but that image encoders pretrained with
linguistic supervision more saliently encode category information (e.g.,
distinguishing hippo vs. elephant) and thus perform significantly better on
benchmark language-and-vision tasks. Our results indicate that LMs encode
conceptual information structurally similarly to vision-based models, even
those that are solely trained on images. Code is available here:
https://github.com/jmerullo/limber
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Security Vulnerabilities of Text-to-SQL Models. (arXiv:2211.15363v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.15363">
<div class="article-summary-box-inner">
<span><p>Although it has been demonstrated that Natural Language Processing (NLP)
algorithms are vulnerable to deliberate attacks, the question of whether such
weaknesses can lead to software security threats is under-explored. To bridge
this gap, we conducted vulnerability tests on Text-to-SQL systems that are
commonly used to create natural language interfaces to databases. We showed
that the Text-to-SQL modules within six commercial applications can be
manipulated to produce malicious code, potentially leading to data breaches and
Denial of Service attacks. This is the first demonstration that NLP models can
be exploited as attack vectors in the wild. In addition, experiments using four
open-source language models verified that straightforward backdoor attacks on
Text-to-SQL systems achieve a 100% success rate without affecting their
performance. The aim of this work is to draw the community's attention to
potential software security issues associated with NLP algorithms and encourage
exploration of methods to mitigate against them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Qualitative Analysis of a Graph Transformer Approach to Addressing Hate Speech: Adapting to Dynamically Changing Content. (arXiv:2301.10871v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10871">
<div class="article-summary-box-inner">
<span><p>Our work advances an approach for predicting hate speech in social media,
drawing out the critical need to consider the discussions that follow a post to
successfully detect when hateful discourse may arise. Using graph transformer
networks, coupled with modelling attention and BERT-level natural language
processing, our approach can capture context and anticipate upcoming
anti-social behaviour. In this paper, we offer a detailed qualitative analysis
of this solution for hate speech detection in social networks, leading to
insights into where the method has the most impressive outcomes in comparison
with competitors and identifying scenarios where there are challenges to
achieving ideal performance. Included is an exploration of the kinds of posts
that permeate social media today, including the use of hateful images. This
suggests avenues for extending our model to be more comprehensive. A key
insight is that the focus on reasoning about the concept of context positions
us well to be able to support multi-modal analysis of online posts. We conclude
with a reflection on how the problem we are addressing relates especially well
to the theme of dynamic change, a critical concern for all AI solutions for
social impact. We also comment briefly on how mental health well-being can be
advanced with our work, through curated content attuned to the extent of hate
in posts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continual Learning of Language Models. (arXiv:2302.03241v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03241">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) have been instrumental for the rapid advance of natural
language processing. This paper studies continual learning of LMs, in
particular, continual domain-adaptive pre-training (or continual DAP-training).
Existing research has shown that further pre-training an LM using a domain
corpus to adapt the LM to the domain can improve the end-task performance in
the domain. This paper proposes a novel method to continually DAP-train an LM
with a sequence of unlabeled domain corpora to adapt the LM to these domains to
improve their end-task performances. The key novelty of our method is a
soft-masking mechanism that directly controls the update to the LM. A novel
proxy is also proposed to preserve the general knowledge in the original LM.
Additionally, it contrasts the representations of the previously learned domain
knowledge (including the general knowledge in the pre-trained LM) and the
knowledge from the current full network to achieve knowledge integration. The
method not only overcomes catastrophic forgetting, but also achieves knowledge
transfer to improve end-task performances. Empirical evaluation demonstrates
the effectiveness of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NL2CMD: An Updated Workflow for Natural Language to Bash Commands Translation. (arXiv:2302.07845v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07845">
<div class="article-summary-box-inner">
<span><p>Translating natural language into Bash Commands is an emerging research field
that has gained attention in recent years. Most efforts have focused on
producing more accurate translation models. To the best of our knowledge, only
two datasets are available, with one based on the other. Both datasets involve
scraping through known data sources (through platforms like stack overflow,
crowdsourcing, etc.) and hiring experts to validate and correct either the
English text or Bash Commands. This paper provides two contributions to
research on synthesizing Bash Commands from scratch. First, we describe a
state-of-the-art translation model used to generate Bash Commands from the
corresponding English text. Second, we introduce a new NL2CMD dataset that is
automatically generated, involves minimal human intervention, and is over six
times larger than prior datasets. Since the generation pipeline does not rely
on existing Bash Commands, the distribution and types of commands can be custom
adjusted. We evaluate the performance of ChatGPT on this task and discuss the
potential of using it as a data generator. Our empirical results show how the
scale and diversity of our dataset can offer unique opportunities for semantic
parsing researchers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models are Few-shot Learners for Prognostic Prediction. (arXiv:2302.12692v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12692">
<div class="article-summary-box-inner">
<span><p>Clinical prediction is an essential task in the healthcare industry. However,
the recent success of transformers, on which large language models are built,
has not been extended to this domain. In this research, we explore the use of
transformers and language models in prognostic prediction for immunotherapy
using real-world patients' clinical data and molecular profiles. This paper
investigates the potential of transformers to improve clinical prediction
compared to conventional machine learning approaches and addresses the
challenge of few-shot learning in predicting rare disease areas. The study
benchmarks the efficacy of baselines and language models on prognostic
prediction across multiple cancer types and investigates the impact of
different pretrained language models under few-shot regimes. The results
demonstrate significant improvements in accuracy and highlight the potential of
NLP in clinical research to improve early detection and intervention for
different diseases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages. (arXiv:2303.01037v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01037">
<div class="article-summary-box-inner">
<span><p>We introduce the Universal Speech Model (USM), a single large model that
performs automatic speech recognition (ASR) across 100+ languages. This is
achieved by pre-training the encoder of the model on a large unlabeled
multilingual dataset of 12 million (M) hours spanning over 300 languages, and
fine-tuning on a smaller labeled dataset. We use multilingual pre-training with
random-projection quantization and speech-text modality matching to achieve
state-of-the-art performance on downstream multilingual ASR and speech-to-text
translation tasks. We also demonstrate that despite using a labeled training
set 1/7-th the size of that used for the Whisper model, our model exhibits
comparable or better performance on both in-domain and out-of-domain speech
recognition tasks across many languages.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-03-06 23:13:41.804599732 UTC">2023-03-06 23:13:41 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>