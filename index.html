<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-06-28T01:30:00Z">06-28</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Detect Depression from Social Networks with Sentiment Knowledge Sharing. (arXiv:2306.14903v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14903">
<div class="article-summary-box-inner">
<span><p>Social network plays an important role in propagating people's viewpoints,
emotions, thoughts, and fears. Notably, following lockdown periods during the
COVID-19 pandemic, the issue of depression has garnered increasing attention,
with a significant portion of individuals resorting to social networks as an
outlet for expressing emotions. Using deep learning techniques to discern
potential signs of depression from social network messages facilitates the
early identification of mental health conditions. Current efforts in detecting
depression through social networks typically rely solely on analyzing the
textual content, overlooking other potential information. In this work, we
conduct a thorough investigation that unveils a strong correlation between
depression and negative emotional states. The integration of such associations
as external knowledge can provide valuable insights for detecting depression.
Accordingly, we propose a multi-task training framework, DeSK, which utilizes
shared sentiment knowledge to enhance the efficacy of depression detection.
Experiments conducted on both Chinese and English datasets demonstrate the
cross-lingual effectiveness of DeSK.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PRISMA-DFLLM: An Extension of PRISMA for Systematic Literature Reviews using Domain-specific Finetuned Large Language Models. (arXiv:2306.14905v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14905">
<div class="article-summary-box-inner">
<span><p>With the proliferation of open-sourced Large Language Models (LLMs) and
efficient finetuning techniques, we are on the cusp of the emergence of
numerous domain-specific LLMs that have been finetuned for expertise across
specialized fields and applications for which the current general-purpose LLMs
are unsuitable. In academia, this technology has the potential to revolutionize
the way we conduct systematic literature reviews (SLRs), access knowledge and
generate new insights. This paper proposes an AI-enabled methodological
framework that combines the power of LLMs with the rigorous reporting
guidelines of the Preferred Reporting Items for Systematic Reviews and
Meta-Analyses (PRISMA). By finetuning LLMs on domain-specific academic papers
that have been selected as a result of a rigorous SLR process, the proposed
PRISMA-DFLLM (for Domain-specific Finetuned LLMs) reporting guidelines offer
the potential to achieve greater efficiency, reusability and scalability, while
also opening the potential for conducting incremental living systematic reviews
with the aid of LLMs. Additionally, the proposed approach for leveraging LLMs
for SLRs enables the dissemination of finetuned models, empowering researchers
to accelerate advancements and democratize cutting-edge research. This paper
presents the case for the feasibility of finetuned LLMs to support rigorous
SLRs and the technical requirements for realizing this. This work then proposes
the extended PRISMA-DFLLM checklist of reporting guidelines as well as the
advantages, challenges, and potential implications of implementing
PRISMA-DFLLM. Finally, a future research roadmap to develop this line of
AI-enabled SLRs is presented, paving the way for a new era of evidence
synthesis and knowledge discovery.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Clickbait Classification and Spoiling Using Natural Language Processing. (arXiv:2306.14907v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14907">
<div class="article-summary-box-inner">
<span><p>Clickbait is the practice of engineering titles to incentivize readers to
click through to articles. Such titles with sensationalized language reveal as
little information as possible. Occasionally, clickbait will be intentionally
misleading, so natural language processing (NLP) can scan the article and
answer the question posed by the clickbait title, or spoil it. We tackle two
tasks: classifying the clickbait into one of 3 types (Task 1), and spoiling the
clickbait (Task 2). For Task 1, we propose two binary classifiers to determine
the final spoiler type. For Task 2, we experiment with two approaches: using a
question-answering model to identify the span of text of the spoiler, and using
a large language model (LLM) to generate the spoiler. Because the spoiler is
contained in the article, we frame the second task as a question-answering
approach for identifying the starting and ending positions of the spoiler. We
created models for Task 1 that were better than the baselines proposed by the
dataset authors and engineered prompts for Task 2 that did not perform as well
as the baselines proposed by the dataset authors due to the evaluation metric
performing worse when the output text is from a generative model as opposed to
an extractive model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Importance of Human-Labeled Data in the Era of LLMs. (arXiv:2306.14910v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14910">
<div class="article-summary-box-inner">
<span><p>The advent of large language models (LLMs) has brought about a revolution in
the development of tailored machine learning models and sparked debates on
redefining data requirements. The automation facilitated by the training and
implementation of LLMs has led to discussions and aspirations that human-level
labeling interventions may no longer hold the same level of importance as in
the era of supervised learning. This paper presents compelling arguments
supporting the ongoing relevance of human-labeled data in the era of LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"You might think about slightly revising the title": identifying hedges in peer-tutoring interactions. (arXiv:2306.14911v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14911">
<div class="article-summary-box-inner">
<span><p>Hedges play an important role in the management of conversational
interaction. In peer tutoring, they are notably used by tutors in dyads (pairs
of interlocutors) experiencing low rapport to tone down the impact of
instructions and negative feedback. Pursuing the objective of building a
tutoring agent that manages rapport with students in order to improve learning,
we used a multimodal peer-tutoring dataset to construct a computational
framework for identifying hedges. We compared approaches relying on pre-trained
resources with others that integrate insights from the social science
literature. Our best performance involved a hybrid approach that outperforms
the existing baseline while being easier to interpret. We employ a model
explainability tool to explore the features that characterize hedges in
peer-tutoring conversations, and we identify some novel features, and the
benefits of such a hybrid model approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FSUIE: A Novel Fuzzy Span Mechanism for Universal Information Extraction. (arXiv:2306.14913v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14913">
<div class="article-summary-box-inner">
<span><p>Universal Information Extraction (UIE) has been introduced as a unified
framework for various Information Extraction (IE) tasks and has achieved
widespread success. Despite this, UIE models have limitations. For example,
they rely heavily on span boundaries in the data during training, which does
not reflect the reality of span annotation challenges. Slight adjustments to
positions can also meet requirements. Additionally, UIE models lack attention
to the limited span length feature in IE. To address these deficiencies, we
propose the Fuzzy Span Universal Information Extraction (FSUIE) framework.
Specifically, our contribution consists of two concepts: fuzzy span loss and
fuzzy span attention. Our experimental results on a series of main IE tasks
show significant improvement compared to the baseline, especially in terms of
fast convergence and strong performance with small amounts of data and training
epochs. These results demonstrate the effectiveness and generalization of FSUIE
in different tasks, settings, and scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Enriched Controllability for Educational Question Generation. (arXiv:2306.14917v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14917">
<div class="article-summary-box-inner">
<span><p>Question Generation (QG) is a task within Natural Language Processing (NLP)
that involves automatically generating questions given an input, typically
composed of a text and a target answer. Recent work on QG aims to control the
type of generated questions so that they meet educational needs. A remarkable
example of controllability in educational QG is the generation of questions
underlying certain narrative elements, e.g., causal relationship, outcome
resolution, or prediction. This study aims to enrich controllability in QG by
introducing a new guidance attribute: question explicitness. We propose to
control the generation of explicit and implicit wh-questions from
children-friendly stories. We show preliminary evidence of controlling QG via
question explicitness alone and simultaneously with another target attribute:
the question's narrative element. The code is publicly available at
github.com/bernardoleite/question-generation-control.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Utilizing Natural Language Processing for Automated Assessment of Classroom Discussion. (arXiv:2306.14918v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14918">
<div class="article-summary-box-inner">
<span><p>Rigorous and interactive class discussions that support students to engage in
high-level thinking and reasoning are essential to learning and are a central
component of most teaching interventions. However, formally assessing
discussion quality 'at scale' is expensive and infeasible for most researchers.
In this work, we experimented with various modern natural language processing
(NLP) techniques to automatically generate rubric scores for individual
dimensions of classroom text discussion quality. Specifically, we worked on a
dataset of 90 classroom discussion transcripts consisting of over 18000 turns
annotated with fine-grained Analyzing Teaching Moves (ATM) codes and focused on
four Instructional Quality Assessment (IQA) rubrics. Despite the limited amount
of data, our work shows encouraging results in some of the rubrics while
suggesting that there is room for improvement in the others. We also found that
certain NLP approaches work better for certain rubrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Product Information Extraction using ChatGPT. (arXiv:2306.14921v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14921">
<div class="article-summary-box-inner">
<span><p>Structured product data in the form of attribute/value pairs is the
foundation of many e-commerce applications such as faceted product search,
product comparison, and product recommendation. Product offers often only
contain textual descriptions of the product attributes in the form of titles or
free text. Hence, extracting attribute/value pairs from textual product
descriptions is an essential enabler for e-commerce applications. In order to
excel, state-of-the-art product information extraction methods require large
quantities of task-specific training data. The methods also struggle with
generalizing to out-of-distribution attributes and attribute values that were
not a part of the training data. Due to being pre-trained on huge amounts of
text as well as due to emergent effects resulting from the model size, Large
Language Models like ChatGPT have the potential to address both of these
shortcomings. This paper explores the potential of ChatGPT for extracting
attribute/value pairs from product descriptions. We experiment with different
zero-shot and few-shot prompt designs. Our results show that ChatGPT achieves a
performance similar to a pre-trained language model but requires much smaller
amounts of training data and computation for fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM-Assisted Content Analysis: Using Large Language Models to Support Deductive Coding. (arXiv:2306.14924v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14924">
<div class="article-summary-box-inner">
<span><p>Deductive coding is a widely used qualitative research method for determining
the prevalence of themes across documents. While useful, deductive coding is
often burdensome and time consuming since it requires researchers to read,
interpret, and reliably categorize a large body of unstructured text documents.
Large language models (LLMs), like ChatGPT, are a class of quickly evolving AI
tools that can perform a range of natural language processing and reasoning
tasks. In this study, we explore the use of LLMs to reduce the time it takes
for deductive coding while retaining the flexibility of a traditional content
analysis. We outline the proposed approach, called LLM-assisted content
analysis (LACA), along with an in-depth case study using GPT-3.5 for LACA on a
publicly available deductive coding data set. Additionally, we conduct an
empirical benchmark using LACA on 4 publicly available data sets to assess the
broader question of how well GPT-3.5 performs across a range of deductive
coding tasks. Overall, we find that GPT-3.5 can often perform deductive coding
at levels of agreement comparable to human coders. Additionally, we demonstrate
that LACA can help refine prompts for deductive coding, identify codes for
which an LLM is randomly guessing, and help assess when to use LLMs vs. human
coders for deductive coding. We conclude with several implications for future
practice of deductive coding and related research methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integrating Bidirectional Long Short-Term Memory with Subword Embedding for Authorship Attribution. (arXiv:2306.14933v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14933">
<div class="article-summary-box-inner">
<span><p>The problem of unveiling the author of a given text document from multiple
candidate authors is called authorship attribution. Manifold word-based
stylistic markers have been successfully used in deep learning methods to deal
with the intrinsic problem of authorship attribution. Unfortunately, the
performance of word-based authorship attribution systems is limited by the
vocabulary of the training corpus. Literature has recommended character-based
stylistic markers as an alternative to overcome the hidden word problem.
However, character-based methods often fail to capture the sequential
relationship of words in texts which is a chasm for further improvement. The
question addressed in this paper is whether it is possible to address the
ambiguity of hidden words in text documents while preserving the sequential
context of words. Consequently, a method based on bidirectional long short-term
memory (BLSTM) with a 2-dimensional convolutional neural network (CNN) is
proposed to capture sequential writing styles for authorship attribution. The
BLSTM was used to obtain the sequential relationship among characteristics
using subword information. The 2-dimensional CNN was applied to understand the
local syntactical position of the style from unlabeled input text. The proposed
method was experimentally evaluated against numerous state-of-the-art methods
across the public corporal of CCAT50, IMDb62, Blog50, and Twitter50.
Experimental results indicate accuracy improvement of 1.07\%, and 0.96\% on
CCAT50 and Twitter, respectively, and produce comparable results on the
remaining datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Art of Embedding Fusion: Optimizing Hate Speech Detection. (arXiv:2306.14939v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14939">
<div class="article-summary-box-inner">
<span><p>Hate speech detection is a challenging natural language processing task that
requires capturing linguistic and contextual nuances. Pre-trained language
models (PLMs) offer rich semantic representations of text that can improve this
task. However there is still limited knowledge about ways to effectively
combine representations across PLMs and leverage their complementary strengths.
In this work, we shed light on various combination techniques for several PLMs
and comprehensively analyze their effectiveness. Our findings show that
combining embeddings leads to slight improvements but at a high computational
cost and the choice of combination has marginal effect on the final outcome. We
also make our codebase public at
https://github.com/aflah02/The-Art-of-Embedding-Fusion-Optimizing-Hate-Speech-Detection .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome. (arXiv:2306.15006v1 [q-bio.GN])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15006">
<div class="article-summary-box-inner">
<span><p>Decoding the linguistic intricacies of the genome is a crucial problem in
biology, and pre-trained foundational models such as DNABERT and Nucleotide
Transformer have made significant strides in this area. Existing works have
largely hinged on k-mer, fixed-length permutations of A, T, C, and G, as the
token of the genome language due to its simplicity. However, we argue that the
computation and sample inefficiencies introduced by k-mer tokenization are
primary obstacles in developing large genome foundational models. We provide
conceptual and empirical insights into genome tokenization, building on which
we propose to replace k-mer tokenization with Byte Pair Encoding (BPE), a
statistics-based data compression algorithm that constructs tokens by
iteratively merging the most frequent co-occurring genome segment in the
corpus. We demonstrate that BPE not only overcomes the limitations of k-mer
tokenization but also benefits from the computational efficiency of
non-overlapping tokenization. Based on these insights, we introduce DNABERT-2,
a refined genome foundation model that adapts an efficient tokenizer and
employs multiple strategies to overcome input length constraints, reduce time
and memory expenditure, and enhance model capability. Furthermore, we identify
the absence of a comprehensive and standardized benchmark for genome
understanding as another significant impediment to fair comparative analysis.
In response, we propose the Genome Understanding Evaluation (GUE), a
comprehensive multi-species genome classification dataset that amalgamates $28$
distinct datasets across $7$ tasks, with input lengths ranging from $70$ to
$1000$. Through comprehensive experiments on the GUE benchmark, we demonstrate
that DNABERT-2 achieves comparable performance to the state-of-the-art model
with $21 \times$ fewer parameters and approximately $56 \times$ less GPU time
in pre-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pretraining task diversity and the emergence of non-Bayesian in-context learning for regression. (arXiv:2306.15063v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15063">
<div class="article-summary-box-inner">
<span><p>Pretrained transformers exhibit the remarkable ability of in-context learning
(ICL): they can learn tasks from just a few examples provided in the prompt
without updating any weights. This raises a foundational question: can ICL
solve fundamentally $\textit{new}$ tasks that are very different from those
seen during pretraining? To probe this question, we examine ICL's performance
on linear regression while varying the diversity of tasks in the pretraining
dataset. We empirically demonstrate a $\textit{task diversity threshold}$ for
the emergence of ICL. Below this threshold, the pretrained transformer cannot
solve unseen regression tasks as it behaves like a Bayesian estimator with the
$\textit{non-diverse pretraining task distribution}$ as the prior. Beyond this
threshold, the transformer significantly outperforms this estimator; its
behavior aligns with that of ridge regression, corresponding to a Gaussian
prior over $\textit{all tasks}$, including those not seen during pretraining.
These results highlight that, when pretrained on data with task diversity
greater than the threshold, transformers $\textit{can}$ solve fundamentally new
tasks in-context. Importantly, this capability hinges on it deviating from the
Bayes optimal estimator with the pretraining distribution as the prior. This
study underscores, in a concrete example, the critical role of task diversity,
alongside data and model scale, in the emergence of ICL. Code is available at
https://github.com/mansheej/icl-task-diversity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models. (arXiv:2306.15087v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15087">
<div class="article-summary-box-inner">
<span><p>We present WinoQueer: a benchmark specifically designed to measure whether
large language models (LLMs) encode biases that are harmful to the LGBTQ+
community. The benchmark is community-sourced, via application of a novel
method that generates a bias benchmark from a community survey. We apply our
benchmark to several popular LLMs and find that off-the-shelf models generally
do exhibit considerable anti-queer bias. Finally, we show that LLM bias against
a marginalized community can be somewhat mitigated by finetuning on data
written about or by members of that community, and that social media text
written by community members is more effective than news text written about the
community by non-members. Our method for community-in-the-loop benchmark
development provides a blueprint for future researchers to develop
community-driven, harms-grounded LLM benchmarks for other marginalized
communities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding In-Context Learning via Supportive Pretraining Data. (arXiv:2306.15091v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15091">
<div class="article-summary-box-inner">
<span><p>In-context learning (ICL) improves language models' performance on a variety
of NLP tasks by simply demonstrating a handful of examples at inference time.
It is not well understood why ICL ability emerges, as the model has never been
specifically trained on such demonstrations. Unlike prior work that explores
implicit mechanisms behind ICL, we study ICL via investigating the pretraining
data. Specifically, we first adapt an iterative, gradient-based approach to
find a small subset of pretraining data that supports ICL. We observe that a
continued pretraining on this small subset significantly improves the model's
ICL ability, by up to 18%. We then compare the supportive subset constrastively
with random subsets of pretraining data and discover: (1) The supportive
pretraining data to ICL do not have a higher domain relevance to downstream
tasks. (2) The supportive pretraining data have a higher mass of rarely
occurring, long-tail tokens. (3) The supportive pretraining data are
challenging examples where the information gain from long-range context is
below average, indicating learning to incorporate difficult long-range context
encourages ICL. Our work takes a first step towards understanding ICL via
analyzing instance-level pretraining data. Our insights have a potential to
enhance the ICL ability of language models by actively guiding the construction
of pretraining data in the future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structured Dialogue Discourse Parsing. (arXiv:2306.15103v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15103">
<div class="article-summary-box-inner">
<span><p>Dialogue discourse parsing aims to uncover the internal structure of a
multi-participant conversation by finding all the discourse~\emph{links} and
corresponding~\emph{relations}. Previous work either treats this task as a
series of independent multiple-choice problems, in which the link existence and
relations are decoded separately, or the encoding is restricted to only local
interaction, ignoring the holistic structural information. In contrast, we
propose a principled method that improves upon previous work from two
perspectives: encoding and decoding. From the encoding side, we perform
structured encoding on the adjacency matrix followed by the matrix-tree
learning algorithm, where all discourse links and relations in the dialogue are
jointly optimized based on latent tree-level distribution. From the decoding
side, we perform structured inference using the modified Chiu-Liu-Edmonds
algorithm, which explicitly generates the labeled multi-root non-projective
spanning tree that best captures the discourse structure. In addition, unlike
in previous work, we do not rely on hand-crafted features; this improves the
model's robustness. Experiments show that our method achieves new
state-of-the-art, surpassing the previous model by 2.3 on STAC and 1.5 on
Molweni (F1 scores). \footnote{Code released
at~\url{https://github.com/chijames/structured_dialogue_discourse_parsing}.}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FeedbackMap: a tool for making sense of open-ended survey responses. (arXiv:2306.15112v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15112">
<div class="article-summary-box-inner">
<span><p>Analyzing open-ended survey responses is a crucial yet challenging task for
social scientists, non-profit organizations, and educational institutions, as
they often face the trade-off between obtaining rich data and the burden of
reading and coding textual responses. This demo introduces FeedbackMap, a
web-based tool that uses natural language processing techniques to facilitate
the analysis of open-ended survey responses. FeedbackMap lets researchers
generate summaries at multiple levels, identify interesting response examples,
and visualize the response space through embeddings. We discuss the importance
of examining survey results from multiple perspectives and the potential biases
introduced by summarization methods, emphasizing the need for critical
evaluation of the representation and omission of respondent voices.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Cross-Domain Behaviors of BERT in Review Understanding. (arXiv:2306.15123v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15123">
<div class="article-summary-box-inner">
<span><p>Review score prediction requires review text understanding, a critical
real-world application of natural language processing. Due to dissimilar text
domains in product reviews, a common practice is fine-tuning BERT models upon
reviews of differing domains. However, there has not yet been an empirical
study of cross-domain behaviors of BERT models in the various tasks of product
review understanding. In this project, we investigate text classification BERT
models fine-tuned on single-domain and multi-domain Amazon review data. In our
findings, though single-domain models achieved marginally improved performance
on their corresponding domain compared to multi-domain models, multi-domain
models outperformed single-domain models when evaluated on multi-domain data,
single-domain data the single-domain model was not fine-tuned on, and on
average when considering all tests. Though slight increases in accuracy can be
achieved through single-domain model fine-tuning, computational resources and
costs can be reduced by utilizing multi-domain models that perform well across
domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">YouTube-ASL: A Large-Scale, Open-Domain American Sign Language-English Parallel Corpus. (arXiv:2306.15162v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15162">
<div class="article-summary-box-inner">
<span><p>Machine learning for sign languages is bottlenecked by data. In this paper,
we present YouTube-ASL, a large-scale, open-domain corpus of American Sign
Language (ASL) videos and accompanying English captions drawn from YouTube.
With ~1000 hours of videos and &gt;2500 unique signers, YouTube-ASL is ~3x as
large and has ~10x as many unique signers as the largest prior ASL dataset. We
train baseline models for ASL to English translation on YouTube-ASL and
evaluate them on How2Sign, where we achieve a new finetuned state of the art of
12.39 BLEU and, for the first time, report zero-shot results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DSRM: Boost Textual Adversarial Training with Distribution Shift Risk Minimization. (arXiv:2306.15164v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15164">
<div class="article-summary-box-inner">
<span><p>Adversarial training is one of the best-performing methods in improving the
robustness of deep language models. However, robust models come at the cost of
high time consumption, as they require multi-step gradient ascents or word
substitutions to obtain adversarial samples. In addition, these generated
samples are deficient in grammatical quality and semantic consistency, which
impairs the effectiveness of adversarial training. To address these problems,
we introduce a novel, effective procedure for instead adversarial training with
only clean data. Our procedure, distribution shift risk minimization (DSRM),
estimates the adversarial loss by perturbing the input data's probability
distribution rather than their embeddings. This formulation results in a robust
model that minimizes the expected global loss under adversarial attacks. Our
approach requires zero adversarial samples for training and reduces time
consumption by up to 70\% compared to current best-performing adversarial
training methods. Experiments demonstrate that DSRM considerably improves
BERT's resistance to textual adversarial attacks and achieves state-of-the-art
robust accuracy on various benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reducing the gap between streaming and non-streaming Transducer-based ASR by adaptive two-stage knowledge distillation. (arXiv:2306.15171v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15171">
<div class="article-summary-box-inner">
<span><p>Transducer is one of the mainstream frameworks for streaming speech
recognition. There is a performance gap between the streaming and non-streaming
transducer models due to limited context. To reduce this gap, an effective way
is to ensure that their hidden and output distributions are consistent, which
can be achieved by hierarchical knowledge distillation. However, it is
difficult to ensure the distribution consistency simultaneously because the
learning of the output distribution depends on the hidden one. In this paper,
we propose an adaptive two-stage knowledge distillation method consisting of
hidden layer learning and output layer learning. In the former stage, we learn
hidden representation with full context by applying mean square error loss
function. In the latter stage, we design a power transformation based adaptive
smoothness method to learn stable output distribution. It achieved 19\%
relative reduction in word error rate, and a faster response for the first
token compared with the original streaming model in LibriSpeech corpus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Rank in Generative Retrieval. (arXiv:2306.15222v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15222">
<div class="article-summary-box-inner">
<span><p>Generative retrieval is a promising new paradigm in text retrieval that
generates identifier strings of relevant passages as the retrieval target. This
paradigm leverages powerful generation models and represents a new paradigm
distinct from traditional learning-to-rank methods. However, despite its rapid
development, current generative retrieval methods are still limited. They
typically rely on a heuristic function to transform predicted identifiers into
a passage rank list, which creates a gap between the learning objective of
generative retrieval and the desired passage ranking target. Moreover, the
inherent exposure bias problem of text generation also persists in generative
retrieval. To address these issues, we propose a novel framework, called LTRGR,
that combines generative retrieval with the classical learning-to-rank
paradigm. Our approach involves training an autoregressive model using a
passage rank loss, which directly optimizes the autoregressive model toward the
optimal passage ranking. This framework only requires an additional training
step to enhance current generative retrieval systems and does not add any
burden to the inference stage. We conducted experiments on three public
datasets, and our results demonstrate that LTRGR achieves state-of-the-art
performance among generative retrieval methods, indicating its effectiveness
and robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emulating Reader Behaviors for Fake News Detection. (arXiv:2306.15231v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15231">
<div class="article-summary-box-inner">
<span><p>The wide dissemination of fake news has affected our lives in many aspects,
making fake news detection important and attracting increasing attention.
Existing approaches make substantial contributions in this field by modeling
news from a single-modal or multi-modal perspective. However, these modal-based
methods can result in sub-optimal outcomes as they ignore reader behaviors in
news consumption and authenticity verification. For instance, they haven't
taken into consideration the component-by-component reading process: from the
headline, images, comments, to the body, which is essential for modeling news
with more granularity. To this end, we propose an approach of Emulating the
behaviors of readers (Ember) for fake news detection on social media,
incorporating readers' reading and verificating process to model news from the
component perspective thoroughly. Specifically, we first construct
intra-component feature extractors to emulate the behaviors of semantic
analyzing on each component. Then, we design a module that comprises
inter-component feature extractors and a sequence-based aggregator. This module
mimics the process of verifying the correlation between components and the
overall reading and verification sequence. Thus, Ember can handle the news with
various components by emulating corresponding sequences. We conduct extensive
experiments on nine real-world datasets, and the results demonstrate the
superiority of Ember.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">C-PMI: Conditional Pointwise Mutual Information for Turn-level Dialogue Evaluation. (arXiv:2306.15245v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15245">
<div class="article-summary-box-inner">
<span><p>Existing reference-free turn-level evaluation metrics for chatbots
inadequately capture the interaction between the user and the system.
Consequently, they often correlate poorly with human evaluations. To address
this issue, we propose a novel model-agnostic approach that leverages
Conditional Pointwise Mutual Information (C-PMI) to measure the turn-level
interaction between the system and the user based on a given evaluation
dimension. Experimental results on the widely used FED dialogue evaluation
dataset demonstrate that our approach significantly improves the correlation
with human judgment compared with existing evaluation systems. By replacing the
negative log-likelihood-based scorer with our proposed C-PMI scorer, we achieve
a relative 60.5% higher Spearman correlation on average for the FED evaluation
metric. Our code is publicly available at https://github.com/renll/C-PMI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MindDial: Belief Dynamics Tracking with Theory-of-Mind Modeling for Situated Neural Dialogue Generation. (arXiv:2306.15253v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15253">
<div class="article-summary-box-inner">
<span><p>Humans talk in free-form while negotiating the expressed meanings or common
ground. Despite the impressive conversational abilities of the large generative
language models, they do not consider the individual differences in contextual
understanding in a shared situated environment. In this work, we propose
MindDial, a novel conversational framework that can generate situated free-form
responses to negotiate common ground. We design an explicit mind module that
can track three-level beliefs -- the speaker's belief, the speaker's prediction
of the listener's belief, and the common belief based on the gap between the
first two. Then the speaking act classification head will decide to continue to
talk, end this turn, or take task-related action. We augment a common ground
alignment dataset MutualFriend with belief dynamics annotation, of which the
goal is to find a single mutual friend based on the free chat between two
agents. Experiments show that our model with mental state modeling can resemble
human responses when aligning common ground meanwhile mimic the natural human
conversation flow. The ablation study further validates the third-level common
belief can aggregate information of the first and second-order beliefs and
align common ground more efficiently.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GroundNLQ @ Ego4D Natural Language Queries Challenge 2023. (arXiv:2306.15255v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15255">
<div class="article-summary-box-inner">
<span><p>In this report, we present our champion solution for Ego4D Natural Language
Queries (NLQ) Challenge in CVPR 2023. Essentially, to accurately ground in a
video, an effective egocentric feature extractor and a powerful grounding model
are required. Motivated by this, we leverage a two-stage pre-training strategy
to train egocentric feature extractors and the grounding model on video
narrations, and further fine-tune the model on annotated data. In addition, we
introduce a novel grounding model GroundNLQ, which employs a multi-modal
multi-scale grounding module for effective video and text fusion and various
temporal intervals, especially for long videos. On the blind test set,
GroundNLQ achieves 25.67 and 18.18 for R1@IoU=0.3 and R1@IoU=0.5, respectively,
and surpasses all other teams by a noticeable margin. Our code will be released
at\url{https://github.com/houzhijian/GroundNLQ}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Out-of-Distribution Evaluation of Neural NLP Models. (arXiv:2306.15261v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15261">
<div class="article-summary-box-inner">
<span><p>Adversarial robustness, domain generalization and dataset biases are three
active lines of research contributing to out-of-distribution (OOD) evaluation
on neural NLP models. However, a comprehensive, integrated discussion of the
three research lines is still lacking in the literature. In this survey, we 1)
compare the three lines of research under a unifying definition; 2) summarize
the data-generating processes and evaluation protocols for each line of
research; and 3) emphasize the challenges and opportunities for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Pretrained Language Models Derive Correct Semantics from Corrupt Subwords under Noise?. (arXiv:2306.15268v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15268">
<div class="article-summary-box-inner">
<span><p>For Pretrained Language Models (PLMs), their susceptibility to noise has
recently been linked to subword segmentation. However, it is unclear which
aspects of segmentation affect their understanding. This study assesses the
robustness of PLMs against various disrupted segmentation caused by noise. An
evaluation framework for subword segmentation, named Contrastive Lexical
Semantic (CoLeS) probe, is proposed. It provides a systematic categorization of
segmentation corruption under noise and evaluation protocols by generating
contrastive datasets with canonical-noisy word pairs. Experimental results
indicate that PLMs are unable to accurately compute word meanings if the noise
introduces completely different subwords, small subword fragments, or a large
number of additional subwords, particularly when they are inserted within other
subwords.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IDOL: Indicator-oriented Logic Pre-training for Logical Reasoning. (arXiv:2306.15273v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15273">
<div class="article-summary-box-inner">
<span><p>In the field of machine reading comprehension (MRC), existing systems have
surpassed the average performance of human beings in many tasks like SQuAD.
However, there is still a long way to go when it comes to logical reasoning.
Although some methods for it have been put forward, they either are designed in
a quite complicated way or rely too much on external structures. In this paper,
we proposed IDOL (InDicator-Oriented Logic Pre-training), an easy-to-understand
but highly effective further pre-training task which logically strengthens the
pre-trained models with the help of 6 types of logical indicators and a
logically rich dataset LGP (LoGic Pre-training). IDOL achieves state-of-the-art
performance on ReClor and LogiQA, the two most representative benchmarks in
logical reasoning MRC, and is proven to be capable of generalizing to different
pre-trained models and other types of MRC benchmarks like RACE and SQuAD 2.0
while keeping competitive general language understanding ability through
testing on tasks in GLUE. Besides, at the beginning of the era of large
language models, we take several of them like ChatGPT into comparison and find
that IDOL still shows its advantage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gender Bias in BERT -- Measuring and Analysing Biases through Sentiment Rating in a Realistic Downstream Classification Task. (arXiv:2306.15298v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15298">
<div class="article-summary-box-inner">
<span><p>Pretrained language models are publicly available and constantly finetuned
for various real-life applications. As they become capable of grasping complex
contextual information, harmful biases are likely increasingly intertwined with
those models. This paper analyses gender bias in BERT models with two main
contributions: First, a novel bias measure is introduced, defining biases as
the difference in sentiment valuation of female and male sample versions.
Second, we comprehensively analyse BERT's biases on the example of a realistic
IMDB movie classifier. By systematically varying elements of the training
pipeline, we can conclude regarding their impact on the final model bias. Seven
different public BERT models in nine training conditions, i.e. 63 models in
total, are compared. Almost all conditions yield significant gender biases.
Results indicate that reflected biases stem from public BERT models rather than
task-specific data, emphasising the weight of responsible usage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Client Reactions in Online Mental Health Counseling. (arXiv:2306.15334v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15334">
<div class="article-summary-box-inner">
<span><p>Communication success relies heavily on reading participants' reactions. Such
feedback is especially important for mental health counselors, who must
carefully consider the client's progress and adjust their approach accordingly.
However, previous NLP research on counseling has mainly focused on studying
counselors' intervention strategies rather than their clients' reactions to the
intervention. This work aims to fill this gap by developing a theoretically
grounded annotation framework that encompasses counselors' strategies and
client reaction behaviors. The framework has been tested against a large-scale,
high-quality text-based counseling dataset we collected over the past two years
from an online welfare counseling platform. Our study shows how clients react
to counselors' strategies, how such reactions affect the final counseling
outcomes, and how counselors can adjust their strategies in response to these
reactions. We also demonstrate that this study can help counselors
automatically predict their clients' states.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and Multi-Dialect Corpus for Speech Representation Disentanglement. (arXiv:2306.15354v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15354">
<div class="article-summary-box-inner">
<span><p>Disentangling uncorrelated information in speech utterances is a crucial
research topic within speech community. Different speech-related tasks focus on
extracting distinct speech representations while minimizing the affects of
other uncorrelated information. We present a large-scale speech corpus to
facilitate the research of speech representation disentanglement. 3D-Speaker
contains over 10,000 speakers, each of whom are simultaneously recorded by
multiple Devices, locating at different Distances, and some speakers are
speaking multiple Dialects. The controlled combinations of multi-dimensional
audio data yield a matrix of a diverse blend of speech representation
entanglement, thereby motivating intriguing methods to untangle them. The
multi-domain nature of 3D-Speaker also makes it a suitable resource to evaluate
large universal speech models and experiment methods of out-of-domain learning
and self-supervised learning. https://3dspeaker.github.io/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Architecture of a Biologically Plausible Language Organ. (arXiv:2306.15364v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15364">
<div class="article-summary-box-inner">
<span><p>We present a simulated biologically plausible language organ, made up of
stylized but realistic neurons, synapses, brain areas, plasticity, and a
simplified model of sensory perception. We show through experiments that this
model succeeds in an important early step in language acquisition: the learning
of nouns, verbs, and their meanings, from the grounded input of only a modest
number of sentences. Learning in this system is achieved through Hebbian
plasticity, and without backpropagation. Our model goes beyond a parser
previously designed in a similar environment, with the critical addition of a
biologically plausible account for how language can be acquired in the infant's
brain, not just processed by a mature brain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploiting Pseudo Future Contexts for Emotion Recognition in Conversations. (arXiv:2306.15376v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15376">
<div class="article-summary-box-inner">
<span><p>With the extensive accumulation of conversational data on the Internet,
emotion recognition in conversations (ERC) has received increasing attention.
Previous efforts of this task mainly focus on leveraging contextual and
speaker-specific features, or integrating heterogeneous external commonsense
knowledge. Among them, some heavily rely on future contexts, which, however,
are not always available in real-life scenarios. This fact inspires us to
generate pseudo future contexts to improve ERC. Specifically, for an utterance,
we generate its future context with pre-trained language models, potentially
containing extra beneficial knowledge in a conversational form homogeneous with
the historical ones. These characteristics make pseudo future contexts easily
fused with historical contexts and historical speaker-specific contexts,
yielding a conceptually simple framework systematically integrating
multi-contexts. Experimental results on four ERC datasets demonstrate our
method's superiority. Further in-depth analyses reveal that pseudo future
contexts can rival real ones to some extent, especially in relatively
context-independent conversations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quality Estimation of Machine Translated Texts based on Direct Evidence from Training Data. (arXiv:2306.15399v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15399">
<div class="article-summary-box-inner">
<span><p>Current Machine Translation systems achieve very good results on a growing
variety of language pairs and data sets. However, it is now well known that
they produce fluent translation outputs that often can contain important
meaning errors. Quality Estimation task deals with the estimation of quality of
translations produced by a Machine Translation system without depending on
Reference Translations. A number of approaches have been suggested over the
years. In this paper we show that the parallel corpus used as training data for
training the MT system holds direct clues for estimating the quality of
translations produced by the MT system. Our experiments show that this simple
and direct method holds promise for quality estimation of translations produced
by any purely data driven machine translation system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Phase Space Analysis of Cardiac Spectra. (arXiv:2306.15425v1 [physics.med-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15425">
<div class="article-summary-box-inner">
<span><p>Cardiac diseases are one of the main reasons of mortality in modern,
industrialized societies, and they cause high expenses in public health
systems. Therefore, it is important to develop analytical methods to improve
cardiac diagnostics. Electric activity of heart was first modeled by using a
set of nonlinear differential equations. Latter, variations of cardiac spectra
originated from deterministic dynamics are investigated. Analyzing the power
spectra of a normal human heart presents His-Purkinje network, possessing a
fractal like structure. Phase space trajectories are extracted from the time
series graph of ECG. Lower values of fractal dimension, D indicate dynamics
that are more coherent. If D has non-integer values greater than two when the
system becomes chaotic or strange attractor. Recently, the development of a
fast and robust method, which can be applied to multichannel physiologic
signals, was reported. This manuscript investigates two different ECG systems
produced from normal and abnormal human hearts to introduce an auxiliary phase
space method in conjunction with ECG signals for diagnoses of heart diseases.
Here, the data for each person includes two signals based on V_4 and modified
lead III (MLIII) respectively. Fractal analysis method is employed on the
trajectories constructed in phase space, from which the fractal dimension D is
obtained using the box counting method. It is observed that, MLIII signals have
larger D values than the first signals (V_4), predicting more randomness yet
more information. The lowest value of D (1.708) indicates the perfect
oscillation of the normal heart and the highest value of D (1.863) presents the
randomness of the abnormal heart. Our significant finding is that the phase
space picture presents the distribution of the peak heights from the ECG
spectra, giving valuable information about heart activities in conjunction with
ECG.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KnowPrefix-Tuning: A Two-Stage Prefix-Tuning Framework for Knowledge-Grounded Dialogue Generation. (arXiv:2306.15430v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15430">
<div class="article-summary-box-inner">
<span><p>Existing knowledge-grounded conversation systems generate responses typically
in a retrieve-then-generate manner. They require a large knowledge base and a
strong knowledge retrieval component, which is time- and resource-consuming. In
this paper, we address the challenge by leveraging the inherent knowledge
encoded in the pre-trained language models (PLMs). We propose Knowledgeable
Prefix Tuning (KnowPrefix-Tuning), a two-stage tuning framework, bypassing the
retrieval process in a knowledge-grounded conversation system by injecting
prior knowledge into the lightweight knowledge prefix. The knowledge prefix is
a sequence of continuous knowledge-specific vectors that can be learned during
training. In addition, we propose a novel interactive re-parameterization
mechanism that allows the prefix to interact fully with the PLM during the
optimization of response generation. Experimental results demonstrate that
KnowPrefix-Tuning outperforms fine-tuning and other lightweight tuning
approaches, and performs comparably with strong retrieval-based baselines while
being $3\times$ faster during inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are aligned neural networks adversarially aligned?. (arXiv:2306.15447v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15447">
<div class="article-summary-box-inner">
<span><p>Large language models are now tuned to align with the goals of their
creators, namely to be "helpful and harmless." These models should respond
helpfully to user questions, but refuse to answer requests that could cause
harm. However, adversarial users can construct inputs which circumvent attempts
at alignment. In this work, we study to what extent these models remain
aligned, even when interacting with an adversarial user who constructs
worst-case inputs (adversarial examples). These inputs are designed to cause
the model to emit harmful content that would otherwise be prohibited. We show
that existing NLP-based optimization attacks are insufficiently powerful to
reliably attack aligned text models: even when current NLP-based attacks fail,
we can find adversarial inputs with brute force. As a result, the failure of
current attacks should not be seen as proof that aligned text models remain
aligned under adversarial inputs.
</p>
<p>However the recent trend in large-scale ML models is multimodal models that
allow users to provide images that influence the text that is generated. We
show these models can be easily attacked, i.e., induced to perform arbitrary
un-aligned behavior through adversarial perturbation of the input image. We
conjecture that improved NLP attacks may demonstrate this same level of
adversarial control over text-only models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Social Reasoning in Language Models with Language Models. (arXiv:2306.15448v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15448">
<div class="article-summary-box-inner">
<span><p>As Large Language Models (LLMs) become increasingly integrated into our
everyday lives, understanding their ability to comprehend human mental states
becomes critical for ensuring effective interactions. However, despite the
recent attempts to assess the Theory-of-Mind (ToM) reasoning capabilities of
LLMs, the degree to which these models can align with human ToM remains a
nuanced topic of exploration. This is primarily due to two distinct challenges:
(1) the presence of inconsistent results from previous evaluations, and (2)
concerns surrounding the validity of existing evaluation methodologies. To
address these challenges, we present a novel framework for procedurally
generating evaluations with LLMs by populating causal templates. Using our
framework, we create a new social reasoning benchmark (BigToM) for LLMs which
consists of 25 controls and 5,000 model-written evaluations. We find that human
participants rate the quality of our benchmark higher than previous
crowd-sourced evaluations and comparable to expert-written evaluations. Using
BigToM, we evaluate the social reasoning capabilities of a variety of LLMs and
compare model performances with human performance. Our results suggest that
GPT4 has ToM capabilities that mirror human inference patterns, though less
reliable, while other LLMs struggle.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Large Language Models to Provide Explanatory Feedback to Human Tutors. (arXiv:2306.15498v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15498">
<div class="article-summary-box-inner">
<span><p>Research demonstrates learners engaging in the process of producing
explanations to support their reasoning, can have a positive impact on
learning. However, providing learners real-time explanatory feedback often
presents challenges related to classification accuracy, particularly in
domain-specific environments, containing situationally complex and nuanced
responses. We present two approaches for supplying tutors real-time feedback
within an online lesson on how to give students effective praise. This
work-in-progress demonstrates considerable accuracy in binary classification
for corrective feedback of effective, or effort-based (F1 score = 0.811), and
ineffective, or outcome-based (F1 score = 0.350), praise responses. More
notably, we introduce progress towards an enhanced approach of providing
explanatory feedback using large language model-facilitated named entity
recognition, which can provide tutors feedback, not only while engaging in
lessons, but can potentially suggest real-time tutor moves. Future work
involves leveraging large language models for data augmentation to improve
accuracy, while also developing an explanatory feedback interface.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Paradigm Shift in Sustainability Disclosure Analysis: Empowering Stakeholders with CHATREPORT, a Language Model-Based Tool. (arXiv:2306.15518v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15518">
<div class="article-summary-box-inner">
<span><p>This paper introduces a novel approach to enhance Large Language Models
(LLMs) with expert knowledge to automate the analysis of corporate
sustainability reports by benchmarking them against the Task Force for
Climate-Related Financial Disclosures (TCFD) recommendations. Corporate
sustainability reports are crucial in assessing organizations' environmental
and social risks and impacts. However, analyzing these reports' vast amounts of
information makes human analysis often too costly. As a result, only a few
entities worldwide have the resources to analyze these reports, which could
lead to a lack of transparency. While AI-powered tools can automatically
analyze the data, they are prone to inaccuracies as they lack domain-specific
expertise. This paper introduces a novel approach to enhance LLMs with expert
knowledge to automate the analysis of corporate sustainability reports. We
christen our tool CHATREPORT, and apply it in a first use case to assess
corporate climate risk disclosures following the TCFD recommendations.
CHATREPORT results from collaborating with experts in climate science, finance,
economic policy, and computer science, demonstrating how domain experts can be
involved in developing AI tools. We make our prompt templates, generated data,
and scores available to the public to encourage transparency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unleashing the Power of User Reviews: Exploring Airline Choices at Catania Airport, Italy. (arXiv:2306.15541v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15541">
<div class="article-summary-box-inner">
<span><p>This study aims to investigate the possible relationship between the
mechanisms of social influence and the choice of airline, through the use of
new tools, with the aim of understanding whether they can contribute to a
better understanding of the factors influencing the decisions of consumers in
the aviation sector. We have chosen to extract user reviews from well-known
platforms: Trustpilot, Google, and Twitter. By combining web scraping
techniques, we have been able to collect a comprehensive dataset comprising a
wide range of user opinions, feedback, and ratings. We then refined the BERT
model to focus on insightful sentiment in the context of airline reviews.
Through our analysis, we observed an intriguing trend of average negative
sentiment scores across various airlines, giving us deeper insight into the
dynamics between airlines and helping us identify key partnerships, popular
routes, and airlines that play a central role in the aeronautical ecosystem of
Catania airport during the specified period. Our investigation led us to find
that, despite an airline having received prestigious awards as a low-cost
leader in Europe for two consecutive years 2021 and 2022, the "Catanese" user
tends to suffer the dominant position of other companies. Understanding the
impact of positive reviews and leveraging sentiment analysis can help airlines
improve their reputation, attract more customers, and ultimately gain a
competitive edge in the marketplace.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CamemBERT-bio: a Tasty French Language Model Better for your Health. (arXiv:2306.15550v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15550">
<div class="article-summary-box-inner">
<span><p>Clinical data in hospitals are increasingly accessible for research through
clinical data warehouses, however these documents are unstructured. It is
therefore necessary to extract information from medical reports to conduct
clinical studies. Transfer learning with BERT-like models such as CamemBERT has
allowed major advances, especially for named entity recognition. However, these
models are trained for plain language and are less efficient on biomedical
data. This is why we propose a new French public biomedical dataset on which we
have continued the pre-training of CamemBERT. Thus, we introduce a first
version of CamemBERT-bio, a specialized public model for the French biomedical
domain that shows 2.54 points of F1 score improvement on average on different
biomedical named entity recognition tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CrunchGPT: A chatGPT assisted framework for scientific machine learning. (arXiv:2306.15551v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15551">
<div class="article-summary-box-inner">
<span><p>Scientific Machine Learning (SciML) has advanced recently across many
different areas in computational science and engineering. The objective is to
integrate data and physics seamlessly without the need of employing elaborate
and computationally taxing data assimilation schemes. However, preprocessing,
problem formulation, code generation, postprocessing and analysis are still
time consuming and may prevent SciML from wide applicability in industrial
applications and in digital twin frameworks. Here, we integrate the various
stages of SciML under the umbrella of ChatGPT, to formulate CrunchGPT, which
plays the role of a conductor orchestrating the entire workflow of SciML based
on simple prompts by the user. Specifically, we present two examples that
demonstrate the potential use of CrunchGPT in optimizing airfoils in
aerodynamics, and in obtaining flow fields in various geometries in interactive
mode, with emphasis on the validation stage. To demonstrate the flow of the
CrunchGPT, and create an infrastructure that can facilitate a broader vision,
we built a webapp based guided user interface, that includes options for a
comprehensive summary report. The overall objective is to extend CrunchGPT to
handle diverse problems in computational mechanics, design, optimization and
controls, and general scientific computing tasks involved in SciML, hence using
it as a research assistant tool but also as an educational tool. While here the
examples focus in fluid mechanics, future versions will target solid mechanics
and materials science, geophysics, systems biology and bioinformatics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extending Context Window of Large Language Models via Positional Interpolation. (arXiv:2306.15595v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15595">
<div class="article-summary-box-inner">
<span><p>We present Position Interpolation (PI) that extends the context window sizes
of RoPE-based pretrained LLMs such as LLaMA models to up to 32768 with minimal
fine-tuning (within 1000 steps), while demonstrating strong empirical results
on various tasks that require long context, including passkey retrieval,
language modeling, and long document summarization from LLaMA 7B to 65B.
Meanwhile, the extended model by Position Interpolation preserve quality
relatively well on tasks within its original context window. To achieve this
goal, Position Interpolation linearly down-scales the input position indices to
match the original context window size, rather than extrapolating beyond the
trained context length which may lead to catastrophically high attention scores
that completely ruin the self-attention mechanism. Our theoretical study shows
that the upper bound of interpolation is at least $\sim 600 \times$ smaller
than that of extrapolation, further demonstrating its stability. Models
extended via Position Interpolation retain its original architecture and can
reuse most pre-existing optimization and infrastructure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Constructing Multilingual Code Search Dataset Using Neural Machine Translation. (arXiv:2306.15604v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15604">
<div class="article-summary-box-inner">
<span><p>Code search is a task to find programming codes that semantically match the
given natural language queries. Even though some of the existing datasets for
this task are multilingual on the programming language side, their query data
are only in English. In this research, we create a multilingual code search
dataset in four natural and four programming languages using a neural machine
translation model. Using our dataset, we pre-train and fine-tune the
Transformer-based models and then evaluate them on multiple code search test
sets. Our results show that the model pre-trained with all natural and
programming language data has performed best in most cases. By applying
back-translation data filtering to our dataset, we demonstrate that the
translation quality affects the model's performance to a certain extent, but
the data size matters more.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Annotation of Direct Speech in Written French Narratives. (arXiv:2306.15634v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15634">
<div class="article-summary-box-inner">
<span><p>The automatic annotation of direct speech (AADS) in written text has been
often used in computational narrative understanding. Methods based on either
rules or deep neural networks have been explored, in particular for English or
German languages. Yet, for French, our target language, not many works exist.
Our goal is to create a unified framework to design and evaluate AADS models in
French. For this, we consolidated the largest-to-date French narrative dataset
annotated with DS per word; we adapted various baselines for sequence labelling
or from AADS in other languages; and we designed and conducted an extensive
evaluation focused on generalisation. Results show that the task still requires
substantial efforts and emphasise characteristics of each baseline. Although
this framework could be improved, it is a step further to encourage more
research on the topic.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Style-transfer based Speech and Audio-visual Scene Understanding for Robot Action Sequence Acquisition from Videos. (arXiv:2306.15644v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15644">
<div class="article-summary-box-inner">
<span><p>To realize human-robot collaboration, robots need to execute actions for new
tasks according to human instructions given finite prior knowledge. Human
experts can share their knowledge of how to perform a task with a robot through
multi-modal instructions in their demonstrations, showing a sequence of
short-horizon steps to achieve a long-horizon goal. This paper introduces a
method for robot action sequence generation from instruction videos using (1)
an audio-visual Transformer that converts audio-visual features and instruction
speech to a sequence of robot actions called dynamic movement primitives (DMPs)
and (2) style-transfer-based training that employs multi-task learning with
video captioning and weakly-supervised learning with a semantic classifier to
exploit unpaired video-action data. We built a system that accomplishes various
cooking actions, where an arm robot executes a DMP sequence acquired from a
cooking video using the audio-visual Transformer. Experiments with
Epic-Kitchen-100, YouCookII, QuerYD, and in-house instruction video datasets
show that the proposed method improves the quality of DMP sequences by 2.3
times the METEOR score obtained with a baseline video-to-action Transformer.
The model achieved 32% of the task success rate with the task knowledge of the
object.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate through Compiler Co-design. (arXiv:2306.15656v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15656">
<div class="article-summary-box-inner">
<span><p>This paper introduces SparseOptimizer, a novel deep learning optimizer that
exploits Moreau-Yosida regularization to naturally induce sparsity in large
language models such as BERT, ALBERT and GPT. Key to the design of
SparseOptimizer is an embedded shrinkage operator, which imparts sparsity
directly within the optimization process. This operator, backed by a sound
theoretical framework, includes an analytical solution, thereby reinforcing the
optimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play
functionality eradicates the need for code modifications, making it a
universally adaptable tool for a wide array of large language models. Empirical
evaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2
confirm that SparseBERT and SparseALBERT, when sparsified using
SparseOptimizer, achieve performance comparable to their dense counterparts,
BERT and ALBERT, while significantly reducing their parameter count. Further,
this work proposes an innovative optimizer-compiler co-design strategy,
demonstrating the potential of inference acceleration (\textbf{3.37x},
\textbf{6.30x}, and \textbf{7.15x} in comparison with Pytorch, TensorFlow, and
LLVM generic compile, respectively) in SparseBERT when paired with an
appropriately designed compiler. This study represents a significant step
forward in the evolution of efficient, scalable, and high-performing large
language models, setting a precedent for future exploration and optimization in
this domain. The SparseOptimizer code and SparseALBERT model will be made
available upon paper acceptance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Testing of Detection Tools for AI-Generated Text. (arXiv:2306.15666v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15666">
<div class="article-summary-box-inner">
<span><p>Recent advances in generative pre-trained transformer large language models
have emphasised the potential risks of unfair use of artificial intelligence
(AI) generated content in an academic environment and intensified efforts in
searching for solutions to detect such content. The paper examines the general
functionality of detection tools for artificial intelligence generated text and
evaluates them based on accuracy and error type analysis. Specifically, the
study seeks to answer research questions about whether existing detection tools
can reliably differentiate between human-written text and ChatGPT-generated
text, and whether machine translation and content obfuscation techniques affect
the detection of AIgenerated text. The research covers 12 publicly available
tools and two commercial systems (Turnitin and PlagiarismCheck) that are widely
used in the academic setting. The researchers conclude that the available
detection tools are neither accurate nor reliable and have a main bias towards
classifying the output as human-written rather than detecting AIgenerated text.
Furthermore, content obfuscation techniques significantly worsen the
performance of tools. The study makes several significant contributions. First,
it summarises up-to-date similar scientific and non-scientific efforts in the
field. Second, it presents the result of one of the most comprehensive tests
conducted so far, based on a rigorous research methodology, an original
document set, and a broad coverage of tools. Third, it discusses the
implications and drawbacks of using detection tools for AI-generated text in
academic settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explainable and Discourse Topic-aware Neural Language Understanding. (arXiv:2006.10632v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10632">
<div class="article-summary-box-inner">
<span><p>Marrying topic models and language models exposes language understanding to a
broader source of document-level context beyond sentences via topics. While
introducing topical semantics in language models, existing approaches
incorporate latent document topic proportions and ignore topical discourse in
sentences of the document. This work extends the line of research by
additionally introducing an explainable topic representation in language
understanding, obtained from a set of key terms correspondingly for each latent
topic of the proportion. Moreover, we retain sentence-topic associations along
with document-topic association by modeling topical discourse for every
sentence in the document. We present a novel neural composite language model
that exploits both the latent and explainable topics along with topical
discourse at sentence-level in a joint learning framework of topic and language
models. Experiments over a range of tasks such as language modeling, word sense
disambiguation, document classification, retrieval and text generation
demonstrate ability of the proposed model in improving language understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Topic Modeling with Continual Lifelong Learning. (arXiv:2006.10909v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10909">
<div class="article-summary-box-inner">
<span><p>Lifelong learning has recently attracted attention in building machine
learning systems that continually accumulate and transfer knowledge to help
future learning. Unsupervised topic modeling has been popularly used to
discover topics from document collections. However, the application of topic
modeling is challenging due to data sparsity, e.g., in a small collection of
(short) documents and thus, generate incoherent topics and sub-optimal document
representations. To address the problem, we propose a lifelong learning
framework for neural topic modeling that can continuously process streams of
document collections, accumulate topics and guide future topic modeling tasks
by knowledge transfer from several sources to better deal with the sparse data.
In the lifelong process, we particularly investigate jointly: (1) sharing
generative homologies (latent topics) over lifetime to transfer prior
knowledge, and (2) minimizing catastrophic forgetting to retain the past
learning via novel selective data augmentation, co-training and topic
regularization approaches. Given a stream of document collections, we apply the
proposed Lifelong Neural Topic Modeling (LNTM) framework in modeling three
sparse document collections as future tasks and demonstrate improved
performance quantified by perplexity, topic coherence and information retrieval
task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Does Translation Require Context? A Data-driven, Multilingual Exploration. (arXiv:2109.07446v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07446">
<div class="article-summary-box-inner">
<span><p>Although proper handling of discourse significantly contributes to the
quality of machine translation (MT), these improvements are not adequately
measured in common translation quality metrics. Recent works in context-aware
MT attempt to target a small set of discourse phenomena during evaluation,
however not in a fully systematic way. In this paper, we develop the
Multilingual Discourse-Aware (MuDA) benchmark, a series of taggers that
identify and evaluate model performance on discourse phenomena in any given
dataset. The choice of phenomena is inspired by a novel methodology to
systematically identify translations requiring context. We confirm the
difficulty of previously studied phenomena while uncovering others that were
previously unaddressed. We find that common context-aware MT models make only
marginal improvements over context-agnostic models, which suggests these models
do not handle these ambiguities effectively. We release code and data for 14
language pairs to encourage the MT community to focus on accurately capturing
discourse phenomena.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-Shot Dialogue Disentanglement by Self-Supervised Entangled Response Selection. (arXiv:2110.12646v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.12646">
<div class="article-summary-box-inner">
<span><p>Dialogue disentanglement aims to group utterances in a long and
multi-participant dialogue into threads. This is useful for discourse analysis
and downstream applications such as dialogue response selection, where it can
be the first step to construct a clean context/response set. Unfortunately,
labeling all~\emph{reply-to} links takes quadratic effort w.r.t the number of
utterances: an annotator must check all preceding utterances to identify the
one to which the current utterance is a reply. In this paper, we are the first
to propose a~\textbf{zero-shot} dialogue disentanglement solution. Firstly, we
train a model on a multi-participant response selection dataset harvested from
the web which is not annotated; we then apply the trained model to perform
zero-shot dialogue disentanglement. Without any labeled data, our model can
achieve a cluster F1 score of 25. We also fine-tune the model using various
amounts of labeled data. Experiments show that with only 10\% of the data, we
achieve nearly the same performance of using the full dataset\footnote{Code is
released at
\url{https://github.com/chijames/zero_shot_dialogue_disentanglement}}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What Do Compressed Multilingual Machine Translation Models Forget?. (arXiv:2205.10828v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10828">
<div class="article-summary-box-inner">
<span><p>Recently, very large pre-trained models achieve state-of-the-art results in
various natural language processing (NLP) tasks, but their size makes it more
challenging to apply them in resource-constrained environments. Compression
techniques allow to drastically reduce the size of the models and therefore
their inference time with negligible impact on top-tier metrics. However, the
general performance averaged across multiple tasks and/or languages may hide a
drastic performance drop on under-represented features, which could result in
the amplification of biases encoded by the models. In this work, we assess the
impact of compression methods on Multilingual Neural Machine Translation models
(MNMT) for various language groups, gender, and semantic biases by extensive
analysis of compressed models on different machine translation benchmarks, i.e.
FLORES-101, MT-Gender, and DiBiMT. We show that the performance of
under-represented languages drops significantly, while the average BLEU metric
only slightly decreases. Interestingly, the removal of noisy memorization with
compression leads to a significant improvement for some medium-resource
languages. Finally, we demonstrate that compression amplifies intrinsic gender
and semantic biases, even in high-resource languages. Code:
https://github.com/alirezamshi/bias-compressedMT
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Blank Collapse: Compressing CTC emission for the faster decoding. (arXiv:2210.17017v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.17017">
<div class="article-summary-box-inner">
<span><p>Connectionist Temporal Classification (CTC) model is a very efficient method
for modeling sequences, especially for speech data. In order to use CTC model
as an Automatic Speech Recognition (ASR) task, the beam search decoding with an
external language model like n-gram LM is necessary to obtain reasonable
results. In this paper we analyze the blank label in CTC beam search deeply and
propose a very simple method to reduce the amount of calculation resulting in
faster beam search decoding speed. With this method, we can get up to 78%
faster decoding speed than ordinary beam search decoding with a very small loss
of accuracy in LibriSpeech datasets. We prove this method is effective not only
practically by experiments but also theoretically by mathematical reasoning. We
also observe that this reduction is more obvious if the accuracy of the model
is higher.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control. (arXiv:2210.17432v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.17432">
<div class="article-summary-box-inner">
<span><p>Despite the growing success of diffusion models in continuous-valued domains
(e.g., images), similar efforts for discrete domains such as text have yet to
match the performance of autoregressive language models. In this work, we
present SSD-LM -- a diffusion-based language model with two key design choices.
First, SSD-LM is semi-autoregressive, iteratively generating blocks of text,
allowing for flexible output length at decoding time while enabling local
bidirectional context updates. Second, it is simplex-based, performing
diffusion on the natural vocabulary space rather than a learned latent space,
allowing us to incorporate classifier guidance and modular control using
off-the-shelf classifiers without any adaptation. We evaluate SSD-LM on
unconstrained text generation benchmarks, and show that it matches or
outperforms strong autoregressive GPT-2 models across standard quality and
diversity metrics, while vastly outperforming diffusion-based baselines. On
controlled text generation, SSD-LM also outperforms competitive baselines, with
an extra advantage in modularity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BLOOM: A 176B-Parameter Open-Access Multilingual Language Model. (arXiv:2211.05100v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.05100">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have been shown to be able to perform new tasks
based on a few demonstrations or natural language instructions. While these
capabilities have led to widespread adoption, most LLMs are developed by
resource-rich organizations and are frequently kept from the public. As a step
towards democratizing this powerful technology, we present BLOOM, a
176B-parameter open-access language model designed and built thanks to a
collaboration of hundreds of researchers. BLOOM is a decoder-only Transformer
language model that was trained on the ROOTS corpus, a dataset comprising
hundreds of sources in 46 natural and 13 programming languages (59 in total).
We find that BLOOM achieves competitive performance on a wide variety of
benchmarks, with stronger results after undergoing multitask prompted
finetuning. To facilitate future research and applications using LLMs, we
publicly release our models and code under the Responsible AI License.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Imagination is All You Need! Curved Contrastive Learning for Abstract Sequence Modeling Utilized on Long Short-Term Dialogue Planning. (arXiv:2211.07591v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.07591">
<div class="article-summary-box-inner">
<span><p>Inspired by the curvature of space-time (Einstein, 1921), we introduce Curved
Contrastive Learning (CCL), a novel representation learning technique for
learning the relative turn distance between utterance pairs in multi-turn
dialogues. The resulting bi-encoder models can guide transformers as a response
ranking model towards a goal in a zero-shot fashion by projecting the goal
utterance and the corresponding reply candidates into a latent space. Here the
cosine similarity indicates the distance/reachability of a candidate utterance
toward the corresponding goal. Furthermore, we explore how these
forward-entailing language representations can be utilized for assessing the
likelihood of sequences by the entailment strength i.e. through the cosine
similarity of its individual members (encoded separately) as an emergent
property in the curved space. These non-local properties allow us to imagine
the likelihood of future patterns in dialogues, specifically by
ordering/identifying future goal utterances that are multiple turns away, given
a dialogue context. As part of our analysis, we investigate characteristics
that make conversations (un)plannable and find strong evidence of planning
capability over multiple turns (in 61.56% over 3 turns) in conversations from
the DailyDialog (Li et al., 2017) dataset. Finally, we show how we achieve
higher efficiency in sequence modeling tasks compared to previous work thanks
to our relativistic approach, where only the last utterance needs to be encoded
and computed during inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WACO: Word-Aligned Contrastive Learning for Speech Translation. (arXiv:2212.09359v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09359">
<div class="article-summary-box-inner">
<span><p>End-to-end Speech Translation (E2E ST) aims to directly translate source
speech into target text. Existing ST methods perform poorly when only extremely
small speech-text data are available for training. We observe that an ST
model's performance closely correlates with its embedding similarity between
speech and source transcript. In this paper, we propose Word-Aligned
COntrastive learning (WACO), a simple and effective method for extremely
low-resource speech-to-text translation. Our key idea is bridging word-level
representations for both speech and text modalities via contrastive learning.
We evaluate WACO and other methods on the MuST-C dataset, a widely used ST
benchmark, and on a low-resource direction Maltese-English from IWSLT 2023. Our
experiments demonstrate that WACO outperforms the best baseline by 9+ BLEU
points with only 1-hour parallel ST data. Code is available at
https://github.com/owaski/WACO.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mu$^{2}$SLAM: Multitask, Multilingual Speech and Language Models. (arXiv:2212.09553v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09553">
<div class="article-summary-box-inner">
<span><p>We present Mu$^{2}$SLAM, a multilingual sequence-to-sequence model
pre-trained jointly on unlabeled speech, unlabeled text and supervised data
spanning Automatic Speech Recognition (ASR), Automatic Speech Translation (AST)
and Machine Translation (MT), in over 100 languages. By leveraging a quantized
representation of speech as a target, Mu$^{2}$SLAM trains the speech-text
models with a sequence-to-sequence masked denoising objective similar to T5 on
the decoder and a masked language modeling (MLM) objective on the encoder, for
both unlabeled speech and text, while utilizing the supervised tasks to improve
cross-lingual and cross-modal representation alignment within the model. On
CoVoST AST, Mu$^{2}$SLAM establishes a new state-of-the-art for models trained
on public datasets, improving on xx-en translation over the previous best by
1.9 BLEU points and on en-xx translation by 1.1 BLEU points. On Voxpopuli ASR,
our model matches the performance of an mSLAM model fine-tuned with an RNN-T
decoder, despite using a relatively weaker sequence-to-sequence architecture.
On text understanding tasks, our model improves by more than 6\% over mSLAM on
XNLI, getting closer to the performance of mT5 models of comparable capacity on
XNLI and TydiQA, paving the way towards a single model for all speech and text
understanding tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Auditing large language models: a three-layered approach. (arXiv:2302.08500v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08500">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) represent a major advance in artificial
intelligence (AI) research. However, the widespread use of LLMs is also coupled
with significant ethical and social challenges. Previous research has pointed
towards auditing as a promising governance mechanism to help ensure that AI
systems are designed and deployed in ways that are ethical, legal, and
technically robust. However, existing auditing procedures fail to address the
governance challenges posed by LLMs, which display emergent capabilities and
are adaptable to a wide range of downstream tasks. In this article, we address
that gap by outlining a novel blueprint for how to audit LLMs. Specifically, we
propose a three-layered approach, whereby governance audits (of technology
providers that design and disseminate LLMs), model audits (of LLMs after
pre-training but prior to their release), and application audits (of
applications based on LLMs) complement and inform each other. We show how
audits, when conducted in a structured and coordinated manner on all three
levels, can be a feasible and effective mechanism for identifying and managing
some of the ethical and social risks posed by LLMs. However, it is important to
remain realistic about what auditing can reasonably be expected to achieve.
Therefore, we discuss the limitations not only of our three-layered approach
but also of the prospect of auditing LLMs at all. Ultimately, this article
seeks to expand the methodological toolkit available to technology providers
and policymakers who wish to analyse and evaluate LLMs from technical, ethical,
and legal perspectives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks. (arXiv:2302.13939v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.13939">
<div class="article-summary-box-inner">
<span><p>As the size of large language models continue to scale, so does the
computational resources required to run it. Spiking Neural Networks (SNNs) have
emerged as an energy-efficient approach to deep learning that leverage sparse
and event-driven activations to reduce the computational overhead associated
with model inference. While they have become competitive with non-spiking
models on many computer vision tasks, SNNs have also proven to be more
challenging to train. As a result, their performance lags behind modern deep
learning, and we are yet to see the effectiveness of SNNs in language
generation. In this paper, inspired by the Receptance Weighted Key Value (RWKV)
language model, we successfully implement `SpikeGPT', a generative language
model with binary, event-driven spiking activation units. We train the proposed
model on two model variants: 45M and 216M parameters. To the best of our
knowledge, SpikeGPT is the largest backpropagation-trained SNN model to date,
rendering it suitable for both the generation and comprehension of natural
language. We achieve this by modifying the transformer block to replace
multi-head self attention to reduce quadratic computational complexity O(N^2)
to linear complexity O(N) with increasing sequence length. Input tokens are
instead streamed in sequentially to our attention mechanism (as with typical
SNNs). Our preliminary experiments show that SpikeGPT remains competitive with
non-spiking models on tested benchmarks, while maintaining 20x fewer operations
when processed on neuromorphic hardware that can leverage sparse, event-driven
activations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extracting Accurate Materials Data from Research Papers with Conversational Language Models and Prompt Engineering. (arXiv:2303.05352v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.05352">
<div class="article-summary-box-inner">
<span><p>There has been a growing effort to replace hand extraction of data from
research papers with automated data extraction based on natural language
processing, language models, and recently, large language models (LLMs).
Although these methods enable efficient extraction of data from large sets of
research papers, they require a significant amount of up-front effort,
expertise, and coding. In this work we propose the ChatExtract method that can
fully automate very accurate data extraction with minimal initial effort and
background, using an advanced conversational LLM. ChatExtract consists of a set
of engineered prompts applied to a conversational LLM that both identify
sentences with data, extract that data, and assure the data's correctness
through a series of follow-up questions. These follow-up questions largely
overcome known issues with LLMs providing factually inaccurate responses.
ChatExtract can be applied with any conversational LLMs and yields very high
quality data extraction. In tests on materials data we find precision and
recall both close to 90% from the best conversational LLMs, like ChatGPT-4. We
demonstrate that the exceptional performance is enabled by the information
retention in a conversational model combined with purposeful redundancy and
introducing uncertainty through follow-up prompts. These results suggest that
approaches similar to ChatExtract, due to their simplicity, transferability,
and accuracy are likely to become powerful tools for data extraction in the
near future. Finally, databases for critical cooling rates of metallic glasses
and yield strengths of high entropy alloys are developed using ChatExtract.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">mCPT at SemEval-2023 Task 3: Multilingual Label-Aware Contrastive Pre-Training of Transformers for Few- and Zero-shot Framing Detection. (arXiv:2303.09901v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09901">
<div class="article-summary-box-inner">
<span><p>This paper presents the winning system for the zero-shot Spanish framing
detection task, which also achieves competitive places in eight additional
languages. The challenge of the framing detection task lies in identifying a
set of 14 frames when only a few or zero samples are available, i.e., a
multilingual multi-label few- or zero-shot setting. Our developed solution
employs a pre-training procedure based on multilingual Transformers using a
label-aware contrastive loss function. In addition to describing the system, we
perform an embedding space analysis and ablation study to demonstrate how our
pre-training procedure supports framing detection to advance computational
framing analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers. (arXiv:2305.07011v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07011">
<div class="article-summary-box-inner">
<span><p>We present Region-aware Open-vocabulary Vision Transformers (RO-ViT) - a
contrastive image-text pretraining recipe to bridge the gap between image-level
pretraining and open-vocabulary object detection. At the pretraining phase, we
propose to randomly crop and resize regions of positional embeddings instead of
using the whole image positional embeddings. This better matches the use of
positional embeddings at region-level in the detection finetuning phase. In
addition, we replace the common softmax cross entropy loss in contrastive
learning with focal loss to better learn the informative yet difficult
examples. Finally, we leverage recent advances in novel object proposals to
improve open-vocabulary detection finetuning. We evaluate our full model on the
LVIS and COCO open-vocabulary detection benchmarks and zero-shot transfer.
RO-ViT achieves a state-of-the-art 32.4 $AP_r$ on LVIS, surpassing the best
existing approach by +6.1 points in addition to competitive zero-shot transfer
detection. Surprisingly, RO-ViT improves the image-level representation as well
and achieves the state of the art on 9 out of 12 metrics on COCO and Flickr
image-text retrieval benchmarks, outperforming competitive approaches with
larger models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Constructing Word-Context-Coupled Space Aligned with Associative Knowledge Relations for Interpretable Language Modeling. (arXiv:2305.11543v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11543">
<div class="article-summary-box-inner">
<span><p>As the foundation of current natural language processing methods, pre-trained
language model has achieved excellent performance. However, the black-box
structure of the deep neural network in pre-trained language models seriously
limits the interpretability of the language modeling process. After revisiting
the coupled requirement of deep neural representation and semantics logic of
language modeling, a Word-Context-Coupled Space (W2CSpace) is proposed by
introducing the alignment processing between uninterpretable neural
representation and interpretable statistical logic. Moreover, a clustering
process is also designed to connect the word- and context-level semantics.
Specifically, an associative knowledge network (AKN), considered interpretable
statistical logic, is introduced in the alignment process for word-level
semantics. Furthermore, the context-relative distance is employed as the
semantic feature for the downstream classifier, which is greatly different from
the current uninterpretable semantic representations of pre-trained models. Our
experiments for performance evaluation and interpretable analysis are executed
on several types of datasets, including SIGHAN, Weibo, and ChnSenti. Wherein a
novel evaluation strategy for the interpretability of machine learning models
is first proposed. According to the experimental results, our language model
can achieve better performance and highly credible interpretable ability
compared to related state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Debiased Automatic Speech Recognition for Dysarthric Speech via Sample Reweighting with Sample Affinity Test. (arXiv:2305.13108v3 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.13108">
<div class="article-summary-box-inner">
<span><p>Automatic speech recognition systems based on deep learning are mainly
trained under empirical risk minimization (ERM). Since ERM utilizes the
averaged performance on the data samples regardless of a group such as healthy
or dysarthric speakers, ASR systems are unaware of the performance disparities
across the groups. This results in biased ASR systems whose performance
differences among groups are severe. In this study, we aim to improve the ASR
system in terms of group robustness for dysarthric speakers. To achieve our
goal, we present a novel approach, sample reweighting with sample affinity test
(Re-SAT). Re-SAT systematically measures the debiasing helpfulness of the given
data sample and then mitigates the bias by debiasing helpfulness-based sample
reweighting. Experimental results demonstrate that Re-SAT contributes to
improved ASR performance on dysarthric speech without performance degradation
on healthy speech.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Attention is Not Enough: Incongruity-Aware Hierarchical Multimodal Sentiment Analysis and Emotion Recognition. (arXiv:2305.13583v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.13583">
<div class="article-summary-box-inner">
<span><p>Fusing multiple modalities for affective computing tasks has proven effective
for performance improvement. However, how multimodal fusion works is not well
understood, and its use in the real world usually results in large model sizes.
In this work, on sentiment and emotion analysis, we first analyze how the
salient affective information in one modality can be affected by the other in
crossmodal attention. We find that inter-modal incongruity exists at the latent
level due to crossmodal attention. Based on this finding, we propose a
lightweight model via Hierarchical Crossmodal Transformer with Modality Gating
(HCT-MG), which determines a primary modality according to its contribution to
the target task and then hierarchically incorporates auxiliary modalities to
alleviate inter-modal incongruity and reduce information redundancy. The
experimental evaluation on three benchmark datasets: CMU-MOSI, CMU-MOSEI, and
IEMOCAP verifies the efficacy of our approach, showing that it: 1) achieves
better performance than prior work as well as manual selection of the primary
modality; 2) can recognize hard samples whose emotions are hard to tell; 3)
mitigates the inter-modal incongruity at the latent level when modalities have
mismatched affective tendencies; 4) reduces model size to less than 1M
parameters while outperforming existing models of similar sizes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models are Bounded Pragmatic Speakers. (arXiv:2305.17760v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17760">
<div class="article-summary-box-inner">
<span><p>How do language models "think"? This paper formulates a probabilistic
cognitive model called the bounded pragmatic speaker, which can characterize
the operation of different variations of language models. Specifically, we
demonstrate that large language models fine-tuned with reinforcement learning
from human feedback (Ouyang et al., 2022) embody a model of thought that
conceptually resembles a fast-and-slow model (Kahneman, 2011), which
psychologists have attributed to humans. We discuss the limitations of
reinforcement learning from human feedback as a fast-and-slow model of thought
and propose avenues for expanding this framework. In essence, our research
highlights the value of adopting a cognitive probabilistic modeling approach to
gain insights into the comprehension, evaluation, and advancement of language
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLMZip: Lossless Text Compression using Large Language Models. (arXiv:2306.04050v2 [cs.IT] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.04050">
<div class="article-summary-box-inner">
<span><p>We provide new estimates of an asymptotic upper bound on the entropy of
English using the large language model LLaMA-7B as a predictor for the next
token given a window of past tokens. This estimate is significantly smaller
than currently available estimates in \cite{cover1978convergent},
\cite{lutati2023focus}. A natural byproduct is an algorithm for lossless
compression of English text which combines the prediction from the large
language model with a lossless compression scheme. Preliminary results from
limited experiments suggest that our scheme outperforms state-of-the-art text
compression schemes such as BSC, ZPAQ, and paq8h.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey on Sociodemographic Bias in Natural Language Processing. (arXiv:2306.08158v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08158">
<div class="article-summary-box-inner">
<span><p>Deep neural networks often learn unintended biases during training, which
might have harmful effects when deployed in real-world settings. This paper
surveys 209 papers on bias in NLP models, most of which address
sociodemographic bias. To better understand the distinction between bias and
real-world harm, we turn to ideas from psychology and behavioral economics to
propose a definition for sociodemographic bias. We identify three main
categories of NLP bias research: types of bias, quantifying bias, and
debiasing. We conclude that current approaches on quantifying bias face
reliability issues, that many of the bias metrics do not relate to real-world
biases, and that current debiasing techniques are superficial and hide bias
rather than removing it. Finally, we provide recommendations for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models. (arXiv:2306.08952v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08952">
<div class="article-summary-box-inner">
<span><p>Reasoning about time is of fundamental importance. Many facts are
time-dependent. For example, athletes change teams from time to time, and
different government officials are elected periodically. Previous
time-dependent question answering (QA) datasets tend to be biased in either
their coverage of time spans or question types. In this paper, we introduce a
comprehensive probing dataset \tempreason to evaluate the temporal reasoning
capability of large language models. Our dataset includes questions of three
temporal reasoning levels. In addition, we also propose a novel learning
framework to improve the temporal reasoning capability of large language
models, based on temporal span extraction and time-sensitive reinforcement
learning. We conducted experiments in closed book QA, open book QA, and
reasoning QA settings and demonstrated the effectiveness of our approach. Our
code and data are released on https://github.com/DAMO-NLP-SG/TempReason.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiversiGATE: A Comprehensive Framework for Reliable Large Language Models. (arXiv:2306.13230v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13230">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce DiversiGATE, a unified framework that
consolidates diverse methodologies for LLM verification. The proposed framework
comprises two main components: Diversification and Aggregation which provide a
holistic perspective on existing verification approaches, such as
Self-Consistency, Math Prompter and WebGPT. Furthermore, we propose a novel
`SelfLearner' model that conforms to the DiversiGATE framework which can learn
from its own outputs and refine its performance over time, leading to improved
accuracy. To evaluate the effectiveness of SelfLearner, we conducted a rigorous
series of experiments, including tests on synthetic data as well as on popular
arithmetic reasoning benchmarks such as GSM8K. Our results demonstrate that our
approach outperforms traditional LLMs, achieving a considerable 54.8% -&gt; 61.8%
improvement on the GSM8K benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Descriptive Image Captioning via Semipermeable Maximum Likelihood Estimation. (arXiv:2306.13460v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13460">
<div class="article-summary-box-inner">
<span><p>Image captioning aims to describe visual content in natural language. As 'a
picture is worth a thousand words', there could be various correct descriptions
for an image. However, with maximum likelihood estimation as the training
objective, the captioning model is penalized whenever its prediction mismatches
with the label. For instance, when the model predicts a word expressing richer
semantics than the label, it will be penalized and optimized to prefer more
concise expressions, referred to as conciseness optimization. In contrast,
predictions that are more concise than labels lead to richness optimization.
Such conflicting optimization directions could eventually result in the model
generating general descriptions. In this work, we introduce Semipermeable
MaxImum Likelihood Estimation (SMILE), which allows richness optimization while
blocking conciseness optimization, thus encouraging the model to generate
longer captions with more details. Extensive experiments on two mainstream
image captioning datasets MSCOCO and Flickr30K demonstrate that SMILE
significantly enhances the descriptiveness of generated captions. We further
provide in-depth investigations to facilitate a better understanding of how
SMILE works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Max-Margin Token Selection in Attention Mechanism. (arXiv:2306.13596v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13596">
<div class="article-summary-box-inner">
<span><p>Attention mechanism is a central component of the transformer architecture
which led to the phenomenal success of large language models. However, the
theoretical principles underlying the attention mechanism are poorly
understood, especially its nonconvex optimization dynamics. In this work, we
explore the seminal softmax-attention model $f(\boldsymbol{X})=\langle
\boldsymbol{Xv}, \texttt{softmax}(\boldsymbol{XWp})\rangle$, where
$\boldsymbol{X}$ is the token sequence and
$(\boldsymbol{v},\boldsymbol{W},\boldsymbol{p})$ are trainable parameters. We
prove that running gradient descent on $\boldsymbol{p}$, or equivalently
$\boldsymbol{W}$, converges in direction to a max-margin solution that
separates $\textit{locally-optimal}$ tokens from non-optimal ones. This clearly
formalizes attention as an optimal token selection mechanism. Remarkably, our
results are applicable to general data and precisely characterize
$\textit{optimality}$ of tokens in terms of the value embeddings
$\boldsymbol{Xv}$ and problem geometry. We also provide a broader
regularization path analysis that establishes the margin maximizing nature of
attention even for nonlinear prediction heads. When optimizing $\boldsymbol{v}$
and $\boldsymbol{p}$ simultaneously with logistic loss, we identify conditions
under which the regularization paths directionally converge to their respective
hard-margin SVM solutions where $\boldsymbol{v}$ separates the input features
based on their labels. Interestingly, the SVM formulation of $\boldsymbol{p}$
is influenced by the support vector geometry of $\boldsymbol{v}$. Finally, we
verify our theoretical findings via numerical experiments and provide insights.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Language Speech Emotion Recognition Using Multimodal Dual Attention Transformers. (arXiv:2306.13804v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13804">
<div class="article-summary-box-inner">
<span><p>Despite the recent progress in speech emotion recognition (SER),
state-of-the-art systems are unable to achieve improved performance in
cross-language settings. In this paper, we propose a Multimodal Dual Attention
Transformer (MDAT) model to improve cross-language SER. Our model utilises
pre-trained models for multimodal feature extraction and is equipped with a
dual attention mechanism including graph attention and co-attention to capture
complex dependencies across different modalities and achieve improved
cross-language SER results using minimal target language data. In addition, our
model also exploits a transformer encoder layer for high-level feature
representation to improve emotion classification accuracy. In this way, MDAT
performs refinement of feature representation at various stages and provides
emotional salient features to the classification layer. This novel approach
also ensures the preservation of modality-specific emotional information while
enhancing cross-modality and cross-language interactions. We assess our model's
performance on four publicly available SER datasets and establish its superior
effectiveness compared to recent approaches and baseline models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-Driven Approach for Formality-Sensitive Machine Translation: Language-Specific Handling and Synthetic Data Generation. (arXiv:2306.14514v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14514">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce a data-driven approach for Formality-Sensitive
Machine Translation (FSMT) that caters to the unique linguistic properties of
four target languages. Our methodology centers on two core strategies: 1)
language-specific data handling, and 2) synthetic data generation using
large-scale language models and empirical prompt engineering. This approach
demonstrates a considerable improvement over the baseline, highlighting the
effectiveness of data-centric techniques. Our prompt engineering strategy
further improves performance by producing superior synthetic translation
examples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Kosmos-2: Grounding Multimodal Large Language Models to the World. (arXiv:2306.14824v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14824">
<div class="article-summary-box-inner">
<span><p>We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling new
capabilities of perceiving object descriptions (e.g., bounding boxes) and
grounding text to the visual world. Specifically, we represent refer
expressions as links in Markdown, i.e., ``[text span](bounding boxes)'', where
object descriptions are sequences of location tokens. Together with multimodal
corpora, we construct large-scale data of grounded image-text pairs (called
GrIT) to train the model. In addition to the existing capabilities of MLLMs
(e.g., perceiving general modalities, following instructions, and performing
in-context learning), Kosmos-2 integrates the grounding capability into
downstream applications. We evaluate Kosmos-2 on a wide range of tasks,
including (i) multimodal grounding, such as referring expression comprehension,
and phrase grounding, (ii) multimodal referring, such as referring expression
generation, (iii) perception-language tasks, and (iv) language understanding
and generation. This work lays out the foundation for the development of
Embodiment AI and sheds light on the big convergence of language, multimodal
perception, action, and world modeling, which is a key step toward artificial
general intelligence. Data, demo, and pretrained models are available at
https://aka.ms/kosmos-2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback. (arXiv:2306.14898v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14898">
<div class="article-summary-box-inner">
<span><p>Humans write code in a fundamentally interactive manner and rely on constant
execution feedback to correct errors, resolve ambiguities, and decompose tasks.
While LLMs have recently exhibited promising coding capabilities, current
coding benchmarks mostly consider a static instruction-to-code sequence
transduction process, which has the potential for error propagation and a
disconnect between the generated code and its final execution environment. To
address this gap, we introduce InterCode, a lightweight, flexible, and
easy-to-use framework of interactive coding as a standard reinforcement
learning (RL) environment, with code as actions and execution feedback as
observations. Our framework is language and platform agnostic, uses
self-contained Docker environments to provide safe and reproducible execution,
and is compatible out-of-the-box with traditional seq2seq coding methods, while
enabling the development of new methods for interactive code generation. We use
InterCode to create two interactive code environments with Bash and SQL as
action spaces, leveraging data from the static Spider and NL2Bash datasets. We
demonstrate InterCode's viability as a testbed by evaluating multiple
state-of-the-art LLMs configured with different prompting strategies such as
ReAct and Plan &amp; Solve. Our results showcase the benefits of interactive code
generation and demonstrate that InterCode can serve as a challenging benchmark
for advancing code understanding and generation capabilities. InterCode is
designed to be easily extensible and can even be used to incorporate new tasks
such as Capture the Flag, a popular coding puzzle that is inherently multi-step
and involves multiple programming languages. Project site with code and data:
https://intercode-benchmark.github.io
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-06-28 23:12:58.708824016 UTC">2023-06-28 23:12:58 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>