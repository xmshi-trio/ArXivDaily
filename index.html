<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-05-03T01:30:00Z">05-03</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion Synthesis. (arXiv:2305.00976v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.00976">
<div class="article-summary-box-inner">
<span><p>In this paper, we present TMR, a simple yet effective approach for text to 3D
human motion retrieval. While previous work has only treated retrieval as a
proxy evaluation metric, we tackle it as a standalone task. Our method extends
the state-of-the-art text-to-motion synthesis model TEMOS, and incorporates a
contrastive loss to better structure the cross-modal latent space. We show that
maintaining the motion generation loss, along with the contrastive training, is
crucial to obtain good performance. We introduce a benchmark for evaluation and
provide an in-depth analysis by reporting results on several protocols. Our
extensive experiments on the KIT-ML and HumanML3D datasets show that TMR
outperforms the prior work by a significant margin, for example reducing the
median rank from 54 to 19. Finally, we showcase the potential of our approach
on moment retrieval. Our code and models are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deception Detection with Feature-Augmentation by soft Domain Transfer. (arXiv:2305.01011v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01011">
<div class="article-summary-box-inner">
<span><p>In this era of information explosion, deceivers use different domains or
mediums of information to exploit the users, such as News, Emails, and Tweets.
Although numerous research has been done to detect deception in all these
domains, information shortage in a new event necessitates these domains to
associate with each other to battle deception. To form this association, we
propose a feature augmentation method by harnessing the intermediate layer
representation of neural models. Our approaches provide an improvement over the
self-domain baseline models by up to 6.60%. We find Tweets to be the most
helpful information provider for Fake News and Phishing Email detection,
whereas News helps most in Tweet Rumor detection. Our analysis provides a
useful insight for domain knowledge transfer which can help build a stronger
deception detection system than the existing literature.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating statistical language models as pragmatic reasoners. (arXiv:2305.01020v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01020">
<div class="article-summary-box-inner">
<span><p>The relationship between communicated language and intended meaning is often
probabilistic and sensitive to context. Numerous strategies attempt to estimate
such a mapping, often leveraging recursive Bayesian models of communication. In
parallel, large language models (LLMs) have been increasingly applied to
semantic parsing applications, tasked with inferring logical representations
from natural language. While existing LLM explorations have been largely
restricted to literal language use, in this work, we evaluate the capacity of
LLMs to infer the meanings of pragmatic utterances. Specifically, we explore
the case of threshold estimation on the gradable adjective ``strong'',
contextually conditioned on a strength prior, then extended to composition with
qualification, negation, polarity inversion, and class comparison. We find that
LLMs can derive context-grounded, human-like distributions over the
interpretations of several complex pragmatic utterances, yet struggle composing
with negation. These results inform the inferential capacity of statistical
language models, and their use in pragmatic and semantic parsing applications.
All corresponding code is made publicly available
(https://github.com/benlipkin/probsem/tree/CogSci2023).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Company classification using zero-shot learning. (arXiv:2305.01028v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01028">
<div class="article-summary-box-inner">
<span><p>In recent years, natural language processing (NLP) has become increasingly
important in a variety of business applications, including sentiment analysis,
text classification, and named entity recognition. In this paper, we propose an
approach for company classification using NLP and zero-shot learning. Our
method utilizes pre-trained transformer models to extract features from company
descriptions, and then applies zero-shot learning to classify companies into
relevant categories without the need for specific training data for each
category. We evaluate our approach on publicly available datasets of textual
descriptions of companies, and demonstrate that it can streamline the process
of company classification, thereby reducing the time and resources required in
traditional approaches such as the Global Industry Classification Standard
(GICS). The results show that this method has potential for automation of
company classification, making it a promising avenue for future research in
this area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SafeWebUH at SemEval-2023 Task 11: Learning Annotator Disagreement in Derogatory Text: Comparison of Direct Training vs Aggregation. (arXiv:2305.01050v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01050">
<div class="article-summary-box-inner">
<span><p>Subjectivity and difference of opinion are key social phenomena, and it is
crucial to take these into account in the annotation and detection process of
derogatory textual content. In this paper, we use four datasets provided by
SemEval-2023 Task 11 and fine-tune a BERT model to capture the disagreement in
the annotation. We find individual annotator modeling and aggregation lowers
the Cross-Entropy score by an average of 0.21, compared to the direct training
on the soft labels. Our findings further demonstrate that annotator metadata
contributes to the average 0.029 reduction in the Cross-Entropy score.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextual Multilingual Spellchecker for User Queries. (arXiv:2305.01082v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01082">
<div class="article-summary-box-inner">
<span><p>Spellchecking is one of the most fundamental and widely used search features.
Correcting incorrectly spelled user queries not only enhances the user
experience but is expected by the user. However, most widely available
spellchecking solutions are either lower accuracy than state-of-the-art
solutions or too slow to be used for search use cases where latency is a key
requirement. Furthermore, most innovative recent architectures focus on English
and are not trained in a multilingual fashion and are trained for spell
correction in longer text, which is a different paradigm from spell correction
for user queries, where context is sparse (most queries are 1-2 words long).
Finally, since most enterprises have unique vocabularies such as product names,
off-the-shelf spelling solutions fall short of users' needs. In this work, we
build a multilingual spellchecker that is extremely fast and scalable and that
adapts its vocabulary and hence speller output based on a specific product's
needs. Furthermore, our speller out-performs general purpose spellers by a wide
margin on in-domain datasets. Our multilingual speller is used in search in
Adobe products, powering autocomplete in various applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Logion: Machine Learning for Greek Philology. (arXiv:2305.01099v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01099">
<div class="article-summary-box-inner">
<span><p>This paper presents machine-learning methods to address various problems in
Greek philology. After training a BERT model on the largest premodern Greek
dataset used for this purpose to date, we identify and correct previously
undetected errors made by scribes in the process of textual transmission, in
what is, to our knowledge, the first successful identification of such errors
via machine learning. Additionally, we demonstrate the model's capacity to fill
gaps caused by material deterioration of premodern manuscripts and compare the
model's performance to that of a domain expert. We find that best performance
is achieved when the domain expert is provided with model suggestions for
inspiration. With such human-computer collaborations in mind, we explore the
model's interpretability and find that certain attention heads appear to encode
select grammatical features of premodern Greek.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ADVISE: AI-accelerated Design of Evidence Synthesis for Global Development. (arXiv:2305.01145v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01145">
<div class="article-summary-box-inner">
<span><p>When designing evidence-based policies and programs, decision-makers must
distill key information from a vast and rapidly growing literature base.
Identifying relevant literature from raw search results is time and resource
intensive, and is often done by manual screening. In this study, we develop an
AI agent based on a bidirectional encoder representations from transformers
(BERT) model and incorporate it into a human team designing an evidence
synthesis product for global development. We explore the effectiveness of the
human-AI hybrid team in accelerating the evidence synthesis process. To further
improve team efficiency, we enhance the human-AI hybrid team through active
learning (AL). Specifically, we explore different sampling strategies,
including random sampling, least confidence (LC) sampling, and highest priority
(HP) sampling, to study their influence on the collaborative screening process.
Results show that incorporating the BERT-based AI agent into the human team can
reduce the human screening effort by 68.5% compared to the case of no AI
assistance and by 16.8% compared to the case of using a support vector machine
(SVM)-based AI agent for identifying 80% of all relevant documents. When we
apply the HP sampling strategy for AL, the human screening effort can be
reduced even more: by 78.3% for identifying 80% of all relevant documents
compared to no AI assistance. We apply the AL-enhanced human-AI hybrid teaming
workflow in the design process of three evidence gap maps (EGMs) for USAID and
find it to be highly effective. These findings demonstrate how AI can
accelerate the development of evidence synthesis products and promote timely
evidence-based decision making in global development in a human-AI hybrid
teaming context.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models. (arXiv:2305.01146v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01146">
<div class="article-summary-box-inner">
<span><p>We systematically investigate lightweight strategies to adapt large language
models (LLMs) for the task of radiology report summarization (RRS).
Specifically, we focus on domain adaptation via pretraining (on natural
language, biomedical text, and clinical text) and via prompting (zero-shot,
in-context learning) or parameter-efficient fine-tuning (prefix tuning, LoRA).
Our results on the MIMIC-III dataset consistently demonstrate best performance
by maximally adapting to the task via pretraining on clinical text and
parameter-efficient fine-tuning on RRS examples. Importantly, this method
fine-tunes a mere 0.32% of parameters throughout the model, in contrast to
end-to-end fine-tuning (100% of parameters). Additionally, we study the effect
of in-context examples and out-of-distribution (OOD) training before concluding
with a radiologist reader study and qualitative analysis. Our findings
highlight the importance of domain adaptation in RRS and provide valuable
insights toward developing effective natural language processing solutions for
clinical tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lessons Learned in ATCO2: 5000 hours of Air Traffic Control Communications for Robust Automatic Speech Recognition and Understanding. (arXiv:2305.01155v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01155">
<div class="article-summary-box-inner">
<span><p>Voice communication between air traffic controllers (ATCos) and pilots is
critical for ensuring safe and efficient air traffic control (ATC). This task
requires high levels of awareness from ATCos and can be tedious and
error-prone. Recent attempts have been made to integrate artificial
intelligence (AI) into ATC in order to reduce the workload of ATCos. However,
the development of data-driven AI systems for ATC demands large-scale annotated
datasets, which are currently lacking in the field. This paper explores the
lessons learned from the ATCO2 project, a project that aimed to develop a
unique platform to collect and preprocess large amounts of ATC data from
airspace in real time. Audio and surveillance data were collected from publicly
accessible radio frequency channels with VHF receivers owned by a community of
volunteers and later uploaded to Opensky Network servers, which can be
considered an "unlimited source" of data. In addition, this paper reviews
previous work from ATCO2 partners, including (i) robust automatic speech
recognition, (ii) natural language processing, (iii) English language
identification of ATC communications, and (iv) the integration of surveillance
data such as ADS-B. We believe that the pipeline developed during the ATCO2
project, along with the open-sourcing of its data, will encourage research in
the ATC field. A sample of the ATCO2 corpus is available on the following
website: https://www.atco2.org/data, while the full corpus can be purchased
through ELDA at <a href="http://catalog.elra.info/en-us/repository/browse/ELRA-S0484.">this http URL</a> We
demonstrated that ATCO2 is an appropriate dataset to develop ASR engines when
little or near to no ATC in-domain data is available. For instance, with the
CNN-TDNNf kaldi model, we reached the performance of as low as 17.9% and 24.9%
WER on public ATC datasets which is 6.6/7.6% better than "out-of-domain" but
supervised CNN-TDNNf model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. (arXiv:2305.01181v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01181">
<div class="article-summary-box-inner">
<span><p>Machine Translation (MT) has made significant progress in recent years using
deep learning, especially after the emergence of large language models (LLMs)
such as GPT-3 and ChatGPT. This brings new challenges and opportunities for MT
using LLMs. In this paper, we brainstorm some interesting directions for MT
using LLMs, including stylized MT, interactive MT, and Translation Memory-based
MT, as well as a new evaluation paradigm using LLMs. We also discuss the
privacy concerns in MT using LLMs and a basic privacy-preserving method to
mitigate such risks. To illustrate the potential of our proposed directions, we
present several examples for the new directions mentioned above, demonstrating
the feasibility of the proposed directions and highlight the opportunities and
challenges for future research in MT using LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Pipeline System of ASR and NLU with MLM-based Data Augmentation toward STOP Low-resource Challenge. (arXiv:2305.01194v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01194">
<div class="article-summary-box-inner">
<span><p>This paper describes our system for the low-resource domain adaptation track
(Track 3) in Spoken Language Understanding Grand Challenge, which is a part of
ICASSP Signal Processing Grand Challenge 2023. In the track, we adopt a
pipeline approach of ASR and NLU. For ASR, we fine-tune Whisper for each domain
with upsampling. For NLU, we fine-tune BART on all the Track3 data and then on
low-resource domain data. We apply masked LM (MLM) -based data augmentation,
where some of input tokens and corresponding target labels are replaced using
MLM. We also apply a retrieval-based approach, where model input is augmented
with similar training samples. As a result, we achieved exact match (EM)
accuracy 63.3/75.0 (average: 69.15) for reminder/weather domain, and won the
1st place at the challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topic Shift Detection in Chinese Dialogues: Corpus and Benchmark. (arXiv:2305.01195v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01195">
<div class="article-summary-box-inner">
<span><p>Dialogue topic shift detection is to detect whether an ongoing topic has
shifted or should shift in a dialogue, which can be divided into two
categories, i.e., response-known task and response-unknown task. Currently,
only a few investigated the latter, because it is still a challenge to predict
the topic shift without the response information. In this paper, we first
annotate a Chinese Natural Topic Dialogue (CNTD) corpus consisting of 1308
dialogues to fill the gap in the Chinese natural conversation topic corpus. And
then we focus on the response-unknown task and propose a teacher-student
framework based on hierarchical contrastive learning to predict the topic shift
without the response. Specifically, the response at high-level teacher-student
is introduced to build the contrastive learning between the response and the
context, while the label contrastive learning is constructed at low-level
student. The experimental results on our Chinese CNTD and English TIAGE show
the effectiveness of our proposed model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation. (arXiv:2305.01210v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01210">
<div class="article-summary-box-inner">
<span><p>Program synthesis has been long studied with recent approaches focused on
directly using the power of Large Language Models (LLMs) to generate code
according to user intent written in natural language. Code evaluation datasets,
containing curated synthesis problems with input/output test-cases, are used to
measure the performance of various LLMs on code synthesis. However, test-cases
in these datasets can be limited in both quantity and quality for fully
assessing the functional correctness of the generated code. Such limitation in
the existing benchmarks begs the following question: In the era of LLMs, is the
code generated really correct? To answer this, we propose EvalPlus -- a code
synthesis benchmarking framework to rigorously evaluate the functional
correctness of LLM-synthesized code. In short, EvalPlus takes in the base
evaluation dataset and uses an automatic input generation step to produce and
diversify large amounts of new test inputs using both LLM-based and
mutation-based input generators to further validate the synthesized code. We
extend the popular HUMANEVAL benchmark and build HUMANEVAL+ with 81x
additionally generated tests. Our extensive evaluation across 14 popular LLMs
demonstrates that HUMANEVAL+ is able to catch significant amounts of previously
undetected wrong code synthesized by LLMs, reducing the pass@k by 15.1% on
average! Moreover, we even found several incorrect ground-truth implementations
in HUMANEVAL. Our work not only indicates that prior popular code synthesis
evaluation results do not accurately reflect the true performance of LLMs for
code synthesis but also opens up a new direction to improve programming
benchmarks through automated test input generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MultiLegalSBD: A Multilingual Legal Sentence Boundary Detection Dataset. (arXiv:2305.01211v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01211">
<div class="article-summary-box-inner">
<span><p>Sentence Boundary Detection (SBD) is one of the foundational building blocks
of Natural Language Processing (NLP), with incorrectly split sentences heavily
influencing the output quality of downstream tasks. It is a challenging task
for algorithms, especially in the legal domain, considering the complex and
different sentence structures used. In this work, we curated a diverse
multilingual legal dataset consisting of over 130'000 annotated sentences in 6
languages. Our experimental results indicate that the performance of existing
SBD models is subpar on multilingual legal data. We trained and tested
monolingual and multilingual models based on CRF, BiLSTM-CRF, and transformers,
demonstrating state-of-the-art performance. We also show that our multilingual
models outperform all baselines in the zero-shot setting on a Portuguese test
set. To encourage further research and development by the community, we have
made our dataset, models, and code publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models. (arXiv:2305.01219v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01219">
<div class="article-summary-box-inner">
<span><p>The prompt-based learning paradigm, which bridges the gap between
pre-training and fine-tuning, achieves state-of-the-art performance on several
NLP tasks, particularly in few-shot settings. Despite being widely applied,
prompt-based learning is vulnerable to backdoor attacks. Textual backdoor
attacks are designed to introduce targeted vulnerabilities into models by
poisoning a subset of training samples through trigger injection and label
modification. However, they suffer from flaws such as abnormal natural language
expressions resulting from the trigger and incorrect labeling of poisoned
samples. In this study, we propose {\bf ProAttack}, a novel and efficient
method for performing clean-label backdoor attacks based on the prompt, which
uses the prompt itself as a trigger. Our method does not require external
triggers and ensures correct labeling of poisoned samples, improving the
stealthy nature of the backdoor attack. With extensive experiments on
rich-resource and few-shot text classification tasks, we empirically validate
ProAttack's competitive performance in textual backdoor attacks. Notably, in
the rich-resource setting, ProAttack achieves state-of-the-art attack success
rates in the clean-label backdoor attack benchmark without external triggers.
All data and code used in our models are publically
available\footnote{\url{https://github.com/shuaizhao95/Prompt_attack}}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Role of Summarization in Generative Agents: A Preliminary Perspective. (arXiv:2305.01253v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01253">
<div class="article-summary-box-inner">
<span><p>Generative agents that simulate human society show tremendous potential for
further research and practical applications. Specifically, the generative agent
architecture comprising several meticulously designed modules constitutes the
most critical component. To facilitate progress in this research, this report
presents our integrated perspective on comprehending generative agents through
summarization, since we believe summarization is the most fundamental and
indispensable capacity of generative agents manifested across diverse
scenarios. We hope this report can provide insight into understanding the
importance of summarization capacity in generative agents and motivate future
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transfer Visual Prompt Generator across LLMs. (arXiv:2305.01278v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01278">
<div class="article-summary-box-inner">
<span><p>While developing a new vision-language LLM (VL-LLM) by pre-training on
tremendous image-text pairs from scratch can be exceedingly resource-consuming,
connecting an existing LLM with a comparatively lightweight visual prompt
generator (VPG) becomes a feasible paradigm. However, further tuning the VPG
part of the VL-LLM still suffers from indispensable computational costs, i.e.,
requiring thousands of GPU hours and millions of training data. One alternative
solution is to transfer an existing VPG from any existing VL-LLMs for the
target VL-LLM.
</p>
<p>In this work, we for the first time investigate the VPG transferability
across LLMs, and explore a solution to reduce the cost of VPG transfer. We
first study the VPG transfer across different LLM sizes (e.g., small-to-large),
and across different LLM types, through which we diagnose the key factors to
maximize the transfer efficiency. Based on our observation, we design a
two-stage transfer framework named VPGTrans, which is simple yet highly
effective. Through extensive experiments, we demonstrate that VPGTrans helps
significantly speed up the transfer learning process without compromising
performance. Remarkably, it helps achieve the VPG transfer from BLIP-2
OPT$_\text{2.7B}$ to BLIP-2 OPT$_\text{6.7B}$ with over 10 times speed-up and
10.7% training data compared with connecting a VPG to OPT$_\text{6.7B}$ from
scratch. Further, a series of intriguing findings and potential rationales
behind them are provided and discussed. Finally, we showcase the practical
value of our VPGTrans approach, by customizing two novel VL-LLMs, including
VL-LLaMA and VL-Vicuna, with recently released LLaMA and Vicuna LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Turning Flowchart into Dialog: Plan-based Data Augmentation for Low-Resource Flowchart-grounded Troubleshooting Dialogs. (arXiv:2305.01323v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01323">
<div class="article-summary-box-inner">
<span><p>Flowchart-grounded troubleshooting dialogue (FTD) systems, which follow the
instructions of a flowchart to diagnose users' problems in specific domains
(eg., vehicle, laptop), have been gaining research interest in recent years.
However, collecting sufficient dialogues that are naturally grounded on
flowcharts is costly, thus FTD systems are impeded by scarce training data. To
mitigate the data sparsity issue, we propose a plan-based data augmentation
(PlanDA) approach that generates diverse synthetic dialog data at scale by
transforming concise flowchart into dialogues. Specifically, its generative
model employs a variational-base framework with a hierarchical planning
strategy that includes global and local latent planning variables. Experiments
on the FloDial dataset show that synthetic dialogue produced by PlanDA improves
the performance of downstream tasks, including flowchart path retrieval and
response generation, in particular on the Out-of-Flowchart settings. In
addition, further analysis demonstrate the quality of synthetic data generated
by PlanDA in paths that are covered by current sample dialogues and paths that
are not covered.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Class based Influence Functions for Error Detection. (arXiv:2305.01384v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01384">
<div class="article-summary-box-inner">
<span><p>Influence functions (IFs) are a powerful tool for detecting anomalous
examples in large scale datasets. However, they are unstable when applied to
deep networks. In this paper, we provide an explanation for the instability of
IFs and develop a solution to this problem. We show that IFs are unreliable
when the two data points belong to two different classes. Our solution
leverages class information to improve the stability of IFs. Extensive
experiments show that our modification significantly improves the performance
and stability of IFs while incurring no additional computational cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Local to Global: Navigating Linguistic Diversity in the African Context. (arXiv:2305.01427v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01427">
<div class="article-summary-box-inner">
<span><p>The focus is on critical problems in NLP related to linguistic diversity and
variation across the African continent, specifically with regards to African
local dialects and Arabic dialects that have received little attention. We
evaluated our various approaches, demonstrating their effectiveness while
highlighting the potential impact of the proposed approach on businesses
seeking to improve customer experience and product development in African local
dialects. The idea of using the model as a teaching tool for product-based
instruction is interesting, as it could potentially stimulate interest in
learners and trigger techno entrepreneurship. Overall, our modified approach
offers a promising analysis of the challenges of dealing with African local
dialects. Particularly Arabic dialects, which could have a significant impact
on businesses seeking to improve customer experience and product development.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentiment Perception Adversarial Attacks on Neural Machine Translation Systems. (arXiv:2305.01437v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01437">
<div class="article-summary-box-inner">
<span><p>With the advent of deep learning methods, Neural Machine Translation (NMT)
systems have become increasingly powerful. However, deep learning based systems
are susceptible to adversarial attacks, where imperceptible changes to the
input can cause undesirable changes at the output of the system. To date there
has been little work investigating adversarial attacks on sequence-to-sequence
systems, such as NMT models. Previous work in NMT has examined attacks with the
aim of introducing target phrases in the output sequence. In this work,
adversarial attacks for NMT systems are explored from an output perception
perspective. Thus the aim of an attack is to change the perception of the
output sequence, without altering the perception of the input sequence. For
example, an adversary may distort the sentiment of translated reviews to have
an exaggerated positive sentiment. In practice it is challenging to run
extensive human perception experiments, so a proxy deep-learning classifier
applied to the NMT output is used to measure perception changes. Experiments
demonstrate that the sentiment perception of NMT systems' output sequences can
be changed significantly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Neural Databases. (arXiv:2305.01447v1 [cs.MM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01447">
<div class="article-summary-box-inner">
<span><p>The rise in loosely-structured data available through text, images, and other
modalities has called for new ways of querying them. Multimedia Information
Retrieval has filled this gap and has witnessed exciting progress in recent
years. Tasks such as search and retrieval of extensive multimedia archives have
undergone massive performance improvements, driven to a large extent by recent
developments in multimodal deep learning. However, methods in this field remain
limited in the kinds of queries they support and, in particular, their
inability to answer database-like queries. For this reason, inspired by recent
work on neural databases, we propose a new framework, which we name Multimodal
Neural Databases (MMNDBs). MMNDBs can answer complex database-like queries that
involve reasoning over different input modalities, such as text and images, at
scale. In this paper, we present the first architecture able to fulfill this
set of requirements and test it with several baselines, showing the limitations
of currently available models. The results show the potential of these new
techniques to process unstructured data coming from different modalities,
paving the way for future research in the area. Code to replicate the
experiments will be released at
https://github.com/GiovanniTRA/MultimodalNeuralDatabases
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Summarizing Multiple Documents with Hierarchical Relationships. (arXiv:2305.01498v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01498">
<div class="article-summary-box-inner">
<span><p>Most existing multi-document summarization (MDS) datasets lack
human-generated and genuine (i.e., not synthetic) summaries or source documents
with explicit inter-document relationships that a summary must capture. To
enhance the capabilities of MDS systems we present PeerSum, a novel dataset for
generating meta-reviews of scientific papers, where the meta-reviews are highly
abstractive and genuine summaries of reviews and corresponding discussions.
These source documents have rich inter-document relationships of an explicit
hierarchical structure with cross-references and often feature conflicts. As
there is a scarcity of research that incorporates hierarchical relationships
into MDS systems through attention manipulation on pre-trained language models,
we additionally present Rammer (Relationship-aware Multi-task Meta-review
Generator), a meta-review generation model that uses sparse attention based on
the hierarchical relationships and a multi-task objective that predicts several
metadata features in addition to the standard text generation objective. Our
experimental results show that PeerSum is a challenging dataset, and Rammer
outperforms other strong baseline MDS models under various evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NewsPanda: Media Monitoring for Timely Conservation Action. (arXiv:2305.01503v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01503">
<div class="article-summary-box-inner">
<span><p>Non-governmental organizations for environmental conservation have a
significant interest in monitoring conservation-related media and getting
timely updates about infrastructure construction projects as they may cause
massive impact to key conservation areas. Such monitoring, however, is
difficult and time-consuming. We introduce NewsPanda, a toolkit which
automatically detects and analyzes online articles related to environmental
conservation and infrastructure construction. We fine-tune a BERT-based model
using active learning methods and noise correction algorithms to identify
articles that are relevant to conservation and infrastructure construction. For
the identified articles, we perform further analysis, extracting keywords and
finding potentially related sources. NewsPanda has been successfully deployed
by the World Wide Fund for Nature teams in the UK, India, and Nepal since
February 2022. It currently monitors over 80,000 websites and 1,074
conservation sites across India and Nepal, saving more than 30 hours of human
efforts weekly. We have now scaled it up to cover 60,000 conservation sites
globally.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Classification: Financial Reasoning in State-of-the-Art Language Models. (arXiv:2305.01505v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01505">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs), consisting of 100 billion or more parameters,
have demonstrated remarkable ability in complex multi-step reasoning tasks.
However, the application of such generic advancements has been limited to a few
fields, such as clinical or legal, with the field of financial reasoning
remaining largely unexplored. To the best of our knowledge, the ability of LLMs
to solve financial reasoning problems has never been dealt with, and whether it
can be performed at any scale remains unknown. To address this knowledge gap,
this research presents a comprehensive investigation into the potential
application of LLMs in the financial domain. The investigation includes a
detailed exploration of a range of subjects, including task formulation,
synthetic data generation, prompting methods, and evaluation capability.
Furthermore, the study benchmarks various GPT variants with parameter scales
ranging from 2.8B to 13B, with and without instruction tuning, on diverse
dataset sizes. By analyzing the results, we reveal that the ability to generate
coherent financial reasoning first emerges at 6B parameters, and continues to
improve with better instruction-tuning or larger datasets. Additionally, the
study provides a publicly accessible dataset named sFIOG (Synthetic-Financial
Investment Opinion Generation), consisting of 11,802 synthetic investment
thesis samples, to support further research in the field of financial
reasoning. Overall, this research seeks to contribute to the understanding of
the efficacy of language models in the field of finance, with a particular
emphasis on their ability to engage in sophisticated reasoning and analysis
within the context of investment decision-making.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Huatuo-26M, a Large-scale Chinese Medical QA Dataset. (arXiv:2305.01526v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01526">
<div class="article-summary-box-inner">
<span><p>In this paper, we release a largest ever medical Question Answering (QA)
dataset with 26 million QA pairs. We benchmark many existing approaches in our
dataset in terms of both retrieval and generation. Experimental results show
that the existing models perform far lower than expected and the released
dataset is still challenging in the pre-trained language model era. Moreover,
we also experimentally show the benefit of the proposed dataset in many
aspects: (i) trained models for other QA datasets in a zero-shot fashion; and
(ii) as external knowledge for retrieval-augmented generation (RAG); and (iii)
improving existing pre-trained language models by using the QA pairs as a
pre-training corpus in continued training manner. We believe that this dataset
will not only contribute to medical research but also facilitate both the
patients and clinical doctors. See
\url{https://github.com/FreedomIntelligence/Huatuo-26M}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information. (arXiv:2305.01528v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01528">
<div class="article-summary-box-inner">
<span><p>Dungeons &amp; Dragons (D&amp;D) is a tabletop roleplaying game with complex natural
language interactions between players and hidden state information. Recent work
has shown that large language models (LLMs) that have access to state
information can generate higher quality game turns than LLMs that use dialog
history alone. However, previous work used game state information that was
heuristically created and was not a true gold standard game state. We present
FIREBALL, a large dataset containing nearly 25,000 unique sessions from real
D\&amp;D gameplay on Discord with true game state info. We recorded game play
sessions of players who used the Avrae bot, which was developed to aid people
in playing D&amp;D online, capturing language, game commands and underlying game
state information. We demonstrate that FIREBALL can improve natural language
generation (NLG) by using Avrae state information, improving both automated
metrics and human judgments of quality. Additionally, we show that LLMs can
generate executable Avrae commands, particularly after finetuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mitigating Approximate Memorization in Language Models via Dissimilarity Learned Policy. (arXiv:2305.01550v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01550">
<div class="article-summary-box-inner">
<span><p>Large Language models (LLMs) are trained on large amounts of data, which can
include sensitive information that may compromise personal privacy. LLMs showed
to memorize parts of the training data and emit those data verbatim when an
adversary prompts appropriately. Previous research has primarily focused on
data preprocessing and differential privacy techniques to address memorization
or prevent verbatim memorization exclusively, which can give a false sense of
privacy. However, these methods rely on explicit and implicit assumptions about
the structure of the data to be protected, which often results in an incomplete
solution to the problem. To address this, we propose a novel framework that
utilizes a reinforcement learning approach (PPO) to fine-tune LLMs to mitigate
approximate memorization. Our approach utilizes a negative similarity score,
such as BERTScore or SacreBLEU, as a reward signal to learn a dissimilarity
policy. Our results demonstrate that this framework effectively mitigates
approximate memorization while maintaining high levels of coherence and fluency
in the generated samples. Furthermore, our framework is robust in mitigating
approximate memorization across various circumstances, including longer
context, which is known to increase memorization in LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?. (arXiv:2305.01555v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01555">
<div class="article-summary-box-inner">
<span><p>Scaling language models have revolutionized widespread NLP tasks, yet little
comprehensively explored few-shot relation extraction with large language
models. In this paper, we investigate principal methodologies, in-context
learning and data generation, for few-shot relation extraction via GPT-3.5
through exhaustive experiments. To enhance few-shot performance, we further
propose task-related instructions and schema-constrained data generation. We
observe that in-context learning can achieve performance on par with previous
prompt learning approaches, and data generation with the large language model
can boost previous solutions to obtain new state-of-the-art few-shot results on
four widely-studied relation extraction datasets. We hope our work can inspire
future research for the capabilities of large language models in few-shot
relation extraction. Code is available in
\url{https://github.com/zjunlp/DeepKE/tree/main/example/llm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Type-enhanced Ensemble Triple Representation via Triple-aware Attention for Cross-lingual Entity Alignment. (arXiv:2305.01556v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01556">
<div class="article-summary-box-inner">
<span><p>Entity alignment(EA) is a crucial task for integrating cross-lingual and
cross-domain knowledge graphs(KGs), which aims to discover entities referring
to the same real-world object from different KGs. Most existing methods
generate aligning entity representation by mining the relevance of triple
elements via embedding-based methods, paying little attention to triple
indivisibility and entity role diversity. In this paper, a novel framework
named TTEA -- Type-enhanced Ensemble Triple Representation via Triple-aware
Attention for Cross-lingual Entity Alignment is proposed to overcome the above
issues considering ensemble triple specificity and entity role features.
Specifically, the ensemble triple representation is derived by regarding
relation as information carrier between semantic space and type space, and
hence the noise influence during spatial transformation and information
propagation can be smoothly controlled via specificity-aware triple attention.
Moreover, our framework uses triple-ware entity enhancement to model the role
diversity of triple elements. Extensive experiments on three real-world
cross-lingual datasets demonstrate that our framework outperforms
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OTIEA:Ontology-enhanced Triple Intrinsic-Correlation for Cross-lingual Entity Alignment. (arXiv:2305.01561v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01561">
<div class="article-summary-box-inner">
<span><p>Cross-lingual and cross-domain knowledge alignment without sufficient
external resources is a fundamental and crucial task for fusing irregular data.
As the element-wise fusion process aiming to discover equivalent objects from
different knowledge graphs (KGs), entity alignment (EA) has been attracting
great interest from industry and academic research recent years. Most of
existing EA methods usually explore the correlation between entities and
relations through neighbor nodes, structural information and external
resources. However, the complex intrinsic interactions among triple elements
and role information are rarely modeled in these methods, which may lead to the
inadequate illustration for triple. In addition, external resources are usually
unavailable in some scenarios especially cross-lingual and cross-domain
applications, which reflects the little scalability of these methods. To tackle
the above insufficiency, a novel universal EA framework (OTIEA) based on
ontology pair and role enhancement mechanism via triple-aware attention is
proposed in this paper without introducing external resources. Specifically, an
ontology-enhanced triple encoder is designed via mining intrinsic correlations
and ontology pair information instead of independent elements. In addition, the
EA-oriented representations can be obtained in triple-aware entity decoder by
fusing role diversity. Finally, a bidirectional iterative alignment strategy is
deployed to expand seed entity pairs. The experimental results on three
real-world datasets show that our framework achieves a competitive performance
compared with baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised learning for infant cry analysis. (arXiv:2305.01578v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01578">
<div class="article-summary-box-inner">
<span><p>In this paper, we explore self-supervised learning (SSL) for analyzing a
first-of-its-kind database of cry recordings containing clinical indications of
more than a thousand newborns. Specifically, we target cry-based detection of
neurological injury as well as identification of cry triggers such as pain,
hunger, and discomfort. Annotating a large database in the medical setting is
expensive and time-consuming, typically requiring the collaboration of several
experts over years. Leveraging large amounts of unlabeled audio data to learn
useful representations can lower the cost of building robust models and,
ultimately, clinical solutions. In this work, we experiment with
self-supervised pre-training of a convolutional neural network on large audio
datasets. We show that pre-training with SSL contrastive loss (SimCLR) performs
significantly better than supervised pre-training for both neuro injury and cry
triggers. In addition, we demonstrate further performance gains through
SSL-based domain adaptation using unlabeled infant cries. We also show that
using such SSL-based pre-training for adaptation to cry sounds decreases the
need for labeled data of the overall system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discern and Answer: Mitigating the Impact of Misinformation in Retrieval-Augmented Models with Discriminators. (arXiv:2305.01579v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01579">
<div class="article-summary-box-inner">
<span><p>Most existing retrieval-augmented language models (LMs) for question
answering assume all retrieved information is factually correct. In this work,
we study a more realistic scenario in which retrieved documents may contain
misinformation, causing conflicts among them. We observe that the existing
models are highly brittle to such information in both fine-tuning and
in-context few-shot learning settings. We propose approaches to make
retrieval-augmented LMs robust to misinformation by explicitly fine-tuning a
discriminator or prompting to elicit discrimination capability in GPT-3. Our
empirical results on open-domain question answering show that these approaches
significantly improve LMs' robustness to knowledge conflicts. We also provide
our findings on interleaving the fine-tuned model's decision with the
in-context learning process, paving a new path to leverage the best of both
worlds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FreeLM: Fine-Tuning-Free Language Model. (arXiv:2305.01616v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01616">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PLMs) have achieved remarkable success in NLP
tasks. Despite the great success, mainstream solutions largely follow the
pre-training then finetuning paradigm, which brings in both high deployment
costs and low training efficiency. Nevertheless, fine-tuning on a specific task
is essential because PLMs are only pre-trained with language signal from large
raw data. In this paper, we propose a novel fine-tuning-free strategy for
language models, to consider both language signal and teacher signal. Teacher
signal is an abstraction of a battery of downstream tasks, provided in a
unified proposition format. Trained with both language and strong task-aware
teacher signals in an interactive manner, our FreeLM model demonstrates strong
generalization and robustness. FreeLM outperforms large models e.g., GPT-3 and
InstructGPT, on a range of language understanding tasks in experiments. FreeLM
is much smaller with 0.3B parameters, compared to 175B in these models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Study on the Integration of Pipeline and E2E SLU systems for Spoken Semantic Parsing toward STOP Quality Challenge. (arXiv:2305.01620v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01620">
<div class="article-summary-box-inner">
<span><p>Recently there have been efforts to introduce new benchmark tasks for spoken
language understanding (SLU), like semantic parsing. In this paper, we describe
our proposed spoken semantic parsing system for the quality track (Track 1) in
Spoken Language Understanding Grand Challenge which is part of ICASSP Signal
Processing Grand Challenge 2023. We experiment with both end-to-end and
pipeline systems for this task. Strong automatic speech recognition (ASR)
models like Whisper and pretrained Language models (LM) like BART are utilized
inside our SLU framework to boost performance. We also investigate the output
level combination of various models to get an exact match accuracy of 80.8,
which won the 1st place at the challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UNTER: A Unified Knowledge Interface for Enhancing Pre-trained Language Models. (arXiv:2305.01624v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01624">
<div class="article-summary-box-inner">
<span><p>Recent research demonstrates that external knowledge injection can advance
pre-trained language models (PLMs) in a variety of downstream NLP tasks.
However, existing knowledge injection methods are either applicable to
structured knowledge or unstructured knowledge, lacking a unified usage. In
this paper, we propose a UNified knowledge inTERface, UNTER, to provide a
unified perspective to exploit both structured knowledge and unstructured
knowledge. In UNTER, we adopt the decoder as a unified knowledge interface,
aligning span representations obtained from the encoder with their
corresponding knowledge. This approach enables the encoder to uniformly invoke
span-related knowledge from its parameters for downstream applications.
Experimental results show that, with both forms of knowledge injected, UNTER
gains continuous improvements on a series of knowledge-driven NLP tasks,
including entity typing, named entity recognition and relation extraction,
especially in low-resource scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unlimiformer: Long-Range Transformers with Unlimited Length Input. (arXiv:2305.01625v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01625">
<div class="article-summary-box-inner">
<span><p>Transformer-based models typically have a predefined bound to their input
length, because of their need to potentially attend to every token in the
input. In this work, we propose Unlimiformer: a general approach that can wrap
any existing pretrained encoder-decoder transformer, and offload the attention
computation across all layers to a single $k$-nearest-neighbor index; this
index can be kept on either the GPU or CPU memory and queried in sub-linear
time. This way, we can index extremely long input sequences, while every
attention head in every decoder layer retrieves its top-$k$ keys, instead of
attending to every key. We demonstrate Unlimiformers's efficacy on several
long-document and multi-document summarization benchmarks, showing that it can
summarize even 350k token-long inputs from the BookSum dataset, without any
input truncation at test time. Unlimiformer improves pretrained models such as
BART and Longformer by extending them to unlimited inputs without additional
learned weights and without modifying their code. We make our code and models
publicly available at https://github.com/abertsch72/unlimiformer .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Basic syntax from speech: Spontaneous concatenation in unsupervised deep neural networks. (arXiv:2305.01626v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01626">
<div class="article-summary-box-inner">
<span><p>Computational models of syntax are predominantly text-based. Here we propose
that basic syntax can be modeled directly from raw speech in a fully
unsupervised way. We focus on one of the most ubiquitous and basic properties
of syntax -- concatenation. We introduce spontaneous concatenation: a
phenomenon where convolutional neural networks (CNNs) trained on acoustic
recordings of individual words start generating outputs with two or even three
words concatenated without ever accessing data with multiple words in the
input. Additionally, networks trained on two words learn to embed words into
novel unobserved word combinations. To our knowledge, this is a previously
unreported property of CNNs trained on raw speech in the Generative Adversarial
Network setting and has implications both for our understanding of how these
architectures learn as well as for modeling syntax and its evolution from raw
acoustic inputs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Benefits of Bad Advice: Autocontrastive Decoding across Model Layers. (arXiv:2305.01628v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01628">
<div class="article-summary-box-inner">
<span><p>Applying language models to natural language processing tasks typically
relies on the representations in the final model layer, as intermediate hidden
layer representations are presumed to be less informative. In this work, we
argue that due to the gradual improvement across model layers, additional
information can be gleaned from the contrast between higher and lower layers
during inference. Specifically, in choosing between the probable next token
predictions of a generative model, the predictions of lower layers can be used
to highlight which candidates are best avoided. We propose a novel approach
that utilizes the contrast between layers to improve text generation outputs,
and show that it mitigates degenerative behaviors of the model in open-ended
generation, significantly improving the quality of generated texts.
Furthermore, our results indicate that contrasting between model layers at
inference time can yield substantial benefits to certain aspects of general
language model capabilities, more effectively extracting knowledge during
inference from a given set of model parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Missing Information, Unresponsive Authors, Experimental Flaws: The Impossibility of Assessing the Reproducibility of Previous Human Evaluations in NLP. (arXiv:2305.01633v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01633">
<div class="article-summary-box-inner">
<span><p>We report our efforts in identifying a set of previous human evaluations in
NLP that would be suitable for a coordinated study examining what makes human
evaluations in NLP more/less reproducible. We present our results and findings,
which include that just 13\% of papers had (i) sufficiently low barriers to
reproduction, and (ii) enough obtainable information, to be considered for
reproduction, and that all but one of the experiments we selected for
reproduction was discovered to have flaws that made the meaningfulness of
conducting a reproduction questionable. As a result, we had to change our
coordinated study design from a reproduce approach to a
standardise-then-reproduce-twice approach. Our overall (negative) finding that
the great majority of human evaluations in NLP is not repeatable and/or not
reproducible and/or too flawed to justify reproduction, paints a dire picture,
but presents an opportunity for a rethink about how to design and report human
evaluations in NLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distill or Annotate? Cost-Efficient Fine-Tuning of Compact Models. (arXiv:2305.01645v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01645">
<div class="article-summary-box-inner">
<span><p>Fine-tuning large models is highly effective, however, inference using these
models can be expensive and produces carbon emissions. Knowledge distillation
has been shown to be a practical solution to reduce inference costs, but the
distillation process itself requires significant computational resources.
Rather than buying or renting GPUs to fine-tune, then distill a large model, an
NLP practitioner who needs a compact model might also choose to simply allocate
an available budget to hire annotators and manually label additional
fine-tuning data. In this paper, we investigate how to most efficiently use a
fixed budget to build a compact model. Through our extensive experiments on six
diverse NLP tasks, we find that distilling from T5-XXL (11B) to T5-Small (60M)
leads to almost always a cost-efficient option compared to annotating more data
to directly train a compact model (T5-Small (60M)). We further demonstrate that
the optimal amount of distillation that maximizes utility varies across
different budgetary scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can LMs Learn New Entities from Descriptions? Challenges in Propagating Injected Knowledge. (arXiv:2305.01651v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01651">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (LMs) are used for knowledge intensive tasks like
question answering, but their knowledge gets continuously outdated as the world
changes. Prior work has studied targeted updates to LMs, injecting individual
facts and evaluating whether the model learns these facts while not changing
predictions on other contexts. We take a step forward and study LMs' abilities
to make inferences based on injected facts (or propagate those facts): for
example, after learning that something is a TV show, does an LM predict that
you can watch it? We study this with two cloze-style tasks: an existing dataset
of real-world sentences about novel entities (ECBD) as well as a new controlled
benchmark with manually designed templates requiring varying levels of
inference about injected knowledge. Surprisingly, we find that existing methods
for updating knowledge (gradient-based fine-tuning and modifications of this
approach) show little propagation of injected knowledge. These methods improve
performance on cloze instances only when there is lexical overlap between
injected facts and target inferences. Yet, prepending entity definitions in an
LM's context improves performance across all settings, suggesting that there is
substantial headroom for parameter-updating approaches for knowledge injection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Word Embeddings: A Survey. (arXiv:1901.09069v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1901.09069">
<div class="article-summary-box-inner">
<span><p>This work lists and describes the main recent strategies for building
fixed-length, dense and distributed representations for words, based on the
distributional hypothesis. These representations are now commonly called word
embeddings and, in addition to encoding surprisingly good syntactic and
semantic information, have been proven useful as extra features in many
downstream NLP tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Learning to Speak and Hear Through Multi-Agent Communication over a Continuous Acoustic Channel. (arXiv:2111.02827v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02827">
<div class="article-summary-box-inner">
<span><p>Multi-agent reinforcement learning has been used as an effective means to
study emergent communication between agents, yet little focus has been given to
continuous acoustic communication. This would be more akin to human language
acquisition; human infants acquire language in large part through continuous
signalling with their caregivers. We therefore ask: Are we able to observe
emergent language between agents with a continuous communication channel? Our
goal is to provide a platform to begin bridging the gap between human and agent
communication, allowing us to analyse continuous signals, how they emerge,
their characteristics, and how they relate to human language acquisition. We
propose a messaging environment where a Speaker agent needs to convey a set of
attributes to a Listener over a noisy acoustic channel. Using DQN to train our
agents, we show that: (1) unlike the discrete case, the acoustic Speaker learns
redundancy to improve Listener coherency, (2) the acoustic Speaker develops
more compositional communication protocols which implicitly compensates for
transmission errors over a noisy channel, and (3) DQN has significant
performance gains and increased compositionality when compared to previous
methods optimised using REINFORCE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Training for Back-Translation with Categorical Reparameterization Trick. (arXiv:2202.08465v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.08465">
<div class="article-summary-box-inner">
<span><p>Back-translation is an effective semi-supervised learning framework in neural
machine translation (NMT). A pre-trained NMT model translates monolingual
sentences and makes synthetic bilingual sentence pairs for the training of the
other NMT model, and vice versa. Understanding the two NMT models as inference
and generation models, respectively, previous works applied the training
framework of variational auto-encoder (VAE). However, the discrete property of
translated sentences prevents gradient information from flowing between the two
NMT models. In this paper, we propose a categorical reparameterization trick
that makes NMT models generate differentiable sentences so that the VAE's
training framework can work in the end-to-end fashion. Our experiments
demonstrate that our method effectively trains the NMT models and achieves
better BLEU scores than the previous baseline on the datasets of the WMT
translation task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Know your audience: specializing grounded language models with listener subtraction. (arXiv:2206.08349v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08349">
<div class="article-summary-box-inner">
<span><p>Effective communication requires adapting to the idiosyncrasies of each
communicative context--such as the common ground shared with each partner.
Humans demonstrate this ability to specialize to their audience in many
contexts, such as the popular game Dixit. We take inspiration from Dixit to
formulate a multi-agent image reference game where a (trained) speaker model is
rewarded for describing a target image such that one (pretrained) listener
model can correctly identify it among distractors, but another listener cannot.
To adapt, the speaker must exploit differences in the knowledge it shares with
the different listeners. We show that finetuning an attention-based adapter
between a CLIP vision encoder and a large language model in this contrastive,
multi-agent setting gives rise to context-dependent natural language
specialization from rewards only, without direct supervision. Through
controlled experiments, we show that training a speaker with two listeners that
perceive differently, using our method, allows the speaker to adapt to the
idiosyncracies of the listeners. Furthermore, we show zero-shot transfer of the
specialization to real-world data. Our experiments demonstrate a method for
specializing grounded language models without direct supervision and highlight
the interesting research challenges posed by complex multi-agent communication.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large scale analysis of gender bias and sexism in song lyrics. (arXiv:2208.02052v5 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.02052">
<div class="article-summary-box-inner">
<span><p>We employ Natural Language Processing techniques to analyse 377808 English
song lyrics from the "Two Million Song Database" corpus, focusing on the
expression of sexism across five decades (1960-2010) and the measurement of
gender biases. Using a sexism classifier, we identify sexist lyrics at a larger
scale than previous studies using small samples of manually annotated popular
songs. Furthermore, we reveal gender biases by measuring associations in word
embeddings learned on song lyrics. We find sexist content to increase across
time, especially from male artists and for popular songs appearing in Billboard
charts. Songs are also shown to contain different language biases depending on
the gender of the performer, with male solo artist songs containing more and
stronger biases. This is the first large scale analysis of this type, giving
insights into language usage in such an influential part of popular culture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Executable Action Plans with Environmentally-Aware Language Models. (arXiv:2210.04964v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04964">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) trained using massive text datasets have
recently shown promise in generating action plans for robotic agents from high
level text queries. However, these models typically do not consider the robot's
environment, resulting in generated plans that may not actually be executable,
due to ambiguities in the planned actions or environmental constraints. In this
paper, we propose an approach to generate environmentally-aware action plans
that agents are better able to execute. Our approach involves integrating
environmental objects and object relations as additional inputs into LLM action
plan generation to provide the system with an awareness of its surroundings,
resulting in plans where each generated action is mapped to objects present in
the scene. We also design a novel scoring function that, along with generating
the action steps and associating them with objects, helps the system
disambiguate among object instances and take into account their states. We
evaluated our approach using the VirtualHome simulator and the ActivityPrograms
knowledge base and found that action plans generated from our system had a 310%
improvement in executability and a 147% improvement in correctness over prior
work. The complete code and a demo of our method is publicly available at
https://github.com/hri-ironlab/scene_aware_language_planner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmarking Long-tail Generalization with Likelihood Splits. (arXiv:2210.06799v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06799">
<div class="article-summary-box-inner">
<span><p>In order to reliably process natural language, NLP systems must generalize to
the long tail of rare utterances. We propose a method to create challenging
benchmarks that require generalizing to the tail of the distribution by
re-splitting existing datasets. We create 'Likelihood Splits' where examples
that are assigned lower likelihood by a pre-trained language model (LM) are
placed in the test set, and more likely examples are in the training set. This
simple approach can be customized to construct meaningful train-test splits for
a wide range of tasks. Likelihood Splits surface more challenges than random
splits: relative error rates of state-of-the-art models increase by 59% for
semantic parsing on Spider, 93% for natural language inference on SNLI, and 33%
for yes/no question answering on BoolQ, on our splits compared with the
corresponding random splits. Moreover, Likelihood Splits create fairer
benchmarks than adversarial filtering; when the LM used to create the splits is
also employed as the task model, our splits do not unfairly penalize the LM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Characterizing Verbatim Short-Term Memory in Neural Language Models. (arXiv:2210.13569v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.13569">
<div class="article-summary-box-inner">
<span><p>When a language model is trained to predict natural language sequences, its
prediction at each moment depends on a representation of prior context. What
kind of information about the prior context can language models retrieve? We
tested whether language models could retrieve the exact words that occurred
previously in a text. In our paradigm, language models (transformers and an
LSTM) processed English text in which a list of nouns occurred twice. We
operationalized retrieval as the reduction in surprisal from the first to the
second list. We found that the transformers retrieved both the identity and
ordering of nouns from the first list. Further, the transformers' retrieval was
markedly enhanced when they were trained on a larger corpus and with greater
model depth. Lastly, their ability to index prior tokens was dependent on
learned attention patterns. In contrast, the LSTM exhibited less precise
retrieval, which was limited to list-initial tokens and to short intervening
texts. The LSTM's retrieval was not sensitive to the order of nouns and it
improved when the list was semantically coherent. We conclude that transformers
implemented something akin to a working memory system that could flexibly
retrieve individual token representations across arbitrary delays; conversely,
the LSTM maintained a coarser and more rapidly-decaying semantic gist of prior
tokens, weighted toward the earliest items.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Frustratingly Easy Label Projection for Cross-lingual Transfer. (arXiv:2211.15613v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.15613">
<div class="article-summary-box-inner">
<span><p>Translating training data into many languages has emerged as a practical
solution for improving cross-lingual transfer. For tasks that involve
span-level annotations, such as information extraction or question answering,
an additional label projection step is required to map annotated spans onto the
translated texts. Recently, a few efforts have utilized a simple
mark-then-translate method to jointly perform translation and projection by
inserting special markers around the labeled spans in the original sentence.
However, as far as we are aware, no empirical analysis has been conducted on
how this approach compares to traditional annotation projection based on word
alignment. In this paper, we present an extensive empirical study across 57
languages and three tasks (QA, NER, and Event Extraction) to evaluate the
effectiveness and limitations of both methods, filling an important gap in the
literature. Experimental results show that our optimized version of
mark-then-translate, which we call EasyProject, is easily applied to many
languages and works surprisingly well, outperforming the more complex word
alignment-based methods. We analyze several key factors that affect the
end-task performance, and show EasyProject works well because it can accurately
preserve label span boundaries after translation. We will publicly release all
our code and data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoRRPUS: Codex-Leveraged Structured Representations for Neurosymbolic Story Understanding. (arXiv:2212.10754v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10754">
<div class="article-summary-box-inner">
<span><p>Story generation and understanding -- as with all NLG/NLU tasks -- has seen a
surge in neurosymbolic work. Researchers have recognized that, while large
language models (LLMs) have tremendous utility, they can be augmented with
symbolic means to be even better and to make up for any flaws that the neural
networks might have. However, symbolic methods are extremely costly in terms of
the amount of time and expertise needed to create them. In this work, we
capitalize on state-of-the-art Code-LLMs, such as Codex, to bootstrap the use
of symbolic methods for tracking the state of stories and aiding in story
understanding. We show that our CoRRPUS system and abstracted prompting
procedures can beat current state-of-the-art structured LLM techniques on
pre-existing story understanding tasks (bAbI task 2 and Re^3) with minimal hand
engineering. We hope that this work can help highlight the importance of
symbolic representations and specialized prompting for LLMs as these models
require some guidance for performing reasoning tasks properly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Model Analysis for Ontology Subsumption Inference. (arXiv:2302.06761v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.06761">
<div class="article-summary-box-inner">
<span><p>Investigating whether pre-trained language models (LMs) can function as
knowledge bases (KBs) has raised wide research interests recently. However,
existing works focus on simple, triple-based, relational KBs, but omit more
sophisticated, logic-based, conceptualised KBs such as OWL ontologies. To
investigate an LM's knowledge of ontologies, we propose OntoLAMA, a set of
inference-based probing tasks and datasets from ontology subsumption axioms
involving both atomic and complex concepts. We conduct extensive experiments on
ontologies of different domains and scales, and our results demonstrate that
LMs encode relatively less background knowledge of Subsumption Inference (SI)
than traditional Natural Language Inference (NLI) but can improve on SI
significantly when a small number of samples are given. We will open-source our
code and datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AUTODIAL: Efficient Asynchronous Task-Oriented Dialogue Model. (arXiv:2303.06245v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.06245">
<div class="article-summary-box-inner">
<span><p>As large dialogue models become commonplace in practice, the problems
surrounding high compute requirements for training, inference and larger memory
footprint still persists. In this work, we present AUTODIAL, a multi-task
dialogue model that addresses the challenges of deploying dialogue model.
AUTODIAL utilizes parallel decoders to perform tasks such as dialogue act
prediction, domain prediction, intent prediction, and dialogue state tracking.
Using classification decoders over generative decoders allows AUTODIAL to
significantly reduce memory footprint and achieve faster inference times
compared to existing generative approach namely SimpleTOD. We demonstrate that
AUTODIAL provides 3-6x speedups during inference while having 11x fewer
parameters on three dialogue tasks compared to SimpleTOD. Our results show that
extending current dialogue models to have parallel decoders can be a viable
alternative for deploying them in resource-constrained environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning. (arXiv:2303.10475v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10475">
<div class="article-summary-box-inner">
<span><p>Task semantics can be expressed by a set of input-to-output examples or a
piece of textual instruction. Conventional machine learning approaches for
natural language processing (NLP) mainly rely on the availability of
large-scale sets of task-specific examples. Two issues arise: first, collecting
task-specific labeled examples does not apply to scenarios where tasks may be
too complicated or costly to annotate, or the system is required to handle a
new task immediately; second, this is not user-friendly since end-users are
probably more willing to provide task description rather than a set of examples
before using the system. Therefore, the community is paying increasing interest
in a new supervision-seeking paradigm for NLP: learning from task instructions.
Despite its impressive progress, there are some common issues that the
community struggles with. This survey paper tries to summarize the current
research on instruction learning, particularly, by answering the following
questions: (i) what is task instruction, and what instruction types exist? (ii)
how to model instructions? (iii) what factors influence and explain the
instructions' performance? (iv) what challenges remain in instruction learning?
To our knowledge, this is the first comprehensive survey about textual
instructions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark. (arXiv:2304.03279v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.03279">
<div class="article-summary-box-inner">
<span><p>Artificial agents have traditionally been trained to maximize reward, which
may incentivize power-seeking and deception, analogous to how next-token
prediction in language models (LMs) may incentivize toxicity. So do agents
naturally learn to be Machiavellian? And how do we measure these behaviors in
general-purpose models such as GPT-4? Towards answering these questions, we
introduce MACHIAVELLI, a benchmark of 134 Choose-Your-Own-Adventure games
containing over half a million rich, diverse scenarios that center on social
decision-making. Scenario labeling is automated with LMs, which are more
performant than human annotators. We mathematize dozens of harmful behaviors
and use our annotations to evaluate agents' tendencies to be power-seeking,
cause disutility, and commit ethical violations. We observe some tension
between maximizing reward and behaving ethically. To improve this trade-off, we
investigate LM-based methods to steer agents' towards less harmful behaviors.
Our results show that agents can both act competently and morally, so concrete
progress can currently be made in machine ethics--designing agents that are
Pareto improvements in both safety and capabilities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis. (arXiv:2304.04675v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.04675">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have demonstrated remarkable potential in
handling multilingual machine translation (MMT). In this paper, we
systematically investigate the advantages and challenges of LLMs for MMT by
answering two questions: 1) How well do LLMs perform in translating a massive
number of languages? 2) Which factors affect LLMs' performance in translation?
We evaluate popular LLMs, including XGLM, OPT, BLOOMZ, and ChatGPT, on 102
languages. Our empirical results show that even the best model ChatGPT still
lags behind the supervised baseline NLLB in 83.33% of translation directions.
Through further analysis, we discover that LLMs exhibit new working patterns
when used for MMT. First, prompt semantics can surprisingly be ignored when
given in-context exemplars, where LLMs still show strong performance even with
unreasonable prompts. Second, cross-lingual exemplars can provide better task
instruction for low-resource translation than exemplars in the same language
pairs. Third, we observe the overestimated performance of BLOOMZ on dataset
Flores-101, indicating the potential risk when using public datasets for
evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sebis at SemEval-2023 Task 7: A Joint System for Natural Language Inference and Evidence Retrieval from Clinical Trial Reports. (arXiv:2304.13180v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.13180">
<div class="article-summary-box-inner">
<span><p>With the increasing number of clinical trial reports generated every day, it
is becoming hard to keep up with novel discoveries that inform evidence-based
healthcare recommendations. To help automate this process and assist medical
experts, NLP solutions are being developed. This motivated the SemEval-2023
Task 7, where the goal was to develop an NLP system for two tasks: evidence
retrieval and natural language inference from clinical trial data. In this
paper, we describe our two developed systems. The first one is a pipeline
system that models the two tasks separately, while the second one is a joint
system that learns the two tasks simultaneously with a shared representation
and a multi-task learning approach. The final system combines their outputs in
an ensemble system. We formalize the models, present their characteristics and
challenges, and provide an analysis of achieved results. Our system ranked 3rd
out of 40 participants with a final submission.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards autonomous system: flexible modular production system enhanced with large language model agents. (arXiv:2304.14721v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.14721">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a novel framework that combines large language
models (LLMs), digital twins and industrial automation system to enable
intelligent planning and control of production processes. We retrofit the
automation system for a modular production facility and create executable
control interfaces of fine-granular functionalities and coarse-granular skills.
Low-level functionalities are executed by automation components, and high-level
skills are performed by automation modules. Subsequently, a digital twin system
is developed, registering these interfaces and containing additional
descriptive information about the production system. Based on the retrofitted
automation system and the created digital twins, LLM-agents are designed to
interpret descriptive information in the digital twins and control the physical
system through service interfaces. These LLM-agents serve as intelligent agents
on different levels within an automation system, enabling autonomous planning
and control of flexible production. Given a task instruction as input, the
LLM-agents orchestrate a sequence of atomic functionalities and skills to
accomplish the task. We demonstrate how our implemented prototype can handle
un-predefined tasks, plan a production process, and execute the operations.
This research highlights the potential of integrating LLMs into industrial
automation systems in the context of smart factory for more agile, flexible,
and adaptive production processes, while it also underscores the critical
insights and limitations for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Still no evidence for an effect of the proportion of non-native speakers on language complexity -- A response to Kauhanen, Einhaus & Walkden (2023). (arXiv:2305.00217v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.00217">
<div class="article-summary-box-inner">
<span><p>In a recent paper published in the Journal of Language Evolution, Kauhanen,
Einhaus &amp; Walkden (https://doi.org/10.1093/jole/lzad005, KEW) challenge the
results presented in one of my papers (Koplenig, Royal Society Open Science, 6,
181274 (2019), https://doi.org/10.1098/rsos.181274), in which I tried to show
through a series of statistical analyses that large numbers of L2 (second
language) speakers do not seem to affect the (grammatical or statistical)
complexity of a language. To this end, I focus on the way in which the
Ethnologue assesses language status: a language is characterised as vehicular
if, in addition to being used by L1 (first language) speakers, it should also
have a significant number of L2 users. KEW criticise both the use of
vehicularity as a (binary) indicator of whether a language has a significant
number of L2 users and the idea of imputing a zero proportion of L2 speakers to
non-vehicular languages whenever a direct estimate of that proportion is
unavailable. While I recognise the importance of post-publication commentary on
published research, I show in this rejoinder that both points of criticism are
explicitly mentioned and analysed in my paper. In addition, I also comment on
other points raised by KEW and demonstrate that both alternative analyses
offered by KEW do not stand up to closer scrutiny.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding. (arXiv:2305.00633v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.00633">
<div class="article-summary-box-inner">
<span><p>We endow Large Language Models (LLMs) with fine-grained self-evaluation to
refine multi-step reasoning inference. We propose an effective prompting
approach that integrates self-evaluation guidance through stochastic beam
search. Our approach explores the reasoning search space using a
well-calibrated automatic criterion. This enables an efficient search to
produce higher-quality final predictions. With the self-evaluation guided
stochastic beam search, we also balance the quality-diversity trade-off in the
generation of reasoning chains. This allows our approach to adapt well with
majority voting and surpass the corresponding Codex-backboned baselines by
$6.34\%$, $9.56\%$, and $5.46\%$ on the GSM8K, AQuA, and StrategyQA benchmarks,
respectively, in few-shot accuracy. Analysis of our decompositional reasoning
finds it pinpoints logic failures and leads to higher consistency and
robustness. Our code is publicly available at
https://github.com/YuxiXie/SelfEval-Guided-Decoding.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-05-03 23:11:32.897751599 UTC">2023-05-03 23:11:32 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>