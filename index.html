<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-05-10T01:30:00Z">05-10</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting and Reasoning of Deleted Tweets before they are Posted. (arXiv:2305.04927v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04927">
<div class="article-summary-box-inner">
<span><p>Social media platforms empower us in several ways, from information
dissemination to consumption. While these platforms are useful in promoting
citizen journalism, public awareness etc., they have misuse potentials.
Malicious users use them to disseminate hate-speech, offensive content, rumor
etc. to gain social and political agendas or to harm individuals, entities and
organizations. Often times, general users unconsciously share information
without verifying it, or unintentionally post harmful messages. Some of such
content often get deleted either by the platform due to the violation of terms
and policies, or users themselves for different reasons, e.g., regrets. There
is a wide range of studies in characterizing, understanding and predicting
deleted content. However, studies which aims to identify the fine-grained
reasons (e.g., posts are offensive, hate speech or no identifiable reason)
behind deleted content, are limited. In this study we address this gap, by
identifying deleted tweets, particularly within the Arabic context, and
labeling them with a corresponding fine-grained disinformation category. We
then develop models that can predict the potentiality of tweets getting
deleted, as well as the potential reasons behind deletion. Such models can help
in moderating social media posts before even posting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A transformer-based method for zero and few-shot biomedical named entity recognition. (arXiv:2305.04928v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04928">
<div class="article-summary-box-inner">
<span><p>Supervised named entity recognition (NER) in the biomedical domain is
dependent on large sets of annotated texts with the given named entities, whose
creation can be time-consuming and expensive. Furthermore, the extraction of
new entities often requires conducting additional annotation tasks and
retraining the model. To address these challenges, this paper proposes a
transformer-based method for zero- and few-shot NER in the biomedical domain.
The method is based on transforming the task of multi-class token
classification into binary token classification (token contains the searched
entity or does not contain the searched entity) and pre-training on a larger
amount of datasets and biomedical entities, from where the method can learn
semantic relations between the given and potential classes. We have achieved
average F1 scores of 35.44% for zero-shot NER, 50.10% for one-shot NER, 69.94%
for 10-shot NER, and 79.51% for 100-shot NER on 9 diverse evaluated biomedical
entities with PubMedBERT fine-tuned model. The results demonstrate the
effectiveness of the proposed method for recognizing new entities with limited
examples, with comparable or better results from the state-of-the-art zero- and
few-shot NER methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The EarlyBIRD Catches the Bug: On Exploiting Early Layers of Encoder Models for More Efficient Code Classification. (arXiv:2305.04940v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04940">
<div class="article-summary-box-inner">
<span><p>The use of modern Natural Language Processing (NLP) techniques has shown to
be beneficial for software engineering tasks, such as vulnerability detection
and type inference. However, training deep NLP models requires significant
computational resources. This paper explores techniques that aim at achieving
the best usage of resources and available information in these models.
</p>
<p>We propose a generic approach, EarlyBIRD, to build composite representations
of code from the early layers of a pre-trained transformer model. We
empirically investigate the viability of this approach on the CodeBERT model by
comparing the performance of 12 strategies for creating composite
representations with the standard practice of only using the last encoder
layer.
</p>
<p>Our evaluation on four datasets shows that several early layer combinations
yield better performance on defect detection, and some combinations improve
multi-class classification. More specifically, we obtain a +2 average
improvement of detection accuracy on Devign with only 3 out of 12 layers of
CodeBERT and a 3.3x speed-up of fine-tuning. These findings show that early
layers can be used to obtain better results using the same resources, as well
as to reduce resource usage during fine-tuning and inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Moment Retrieval and Highlight Detection Via Natural Language Queries. (arXiv:2305.04961v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04961">
<div class="article-summary-box-inner">
<span><p>Video summarization has become an increasingly important task in the field of
computer vision due to the vast amount of video content available on the
internet. In this project, we propose a new method for natural language query
based joint video summarization and highlight detection using multi-modal
transformers. This approach will use both visual and audio cues to match a
user's natural language query to retrieve the most relevant and interesting
moments from a video. Our approach employs multiple recent techniques used in
Vision Transformers (ViTs) to create a transformer-like encoder-decoder model.
We evaluated our approach on multiple datasets such as YouTube Highlights and
TVSum to demonstrate the flexibility of our proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LABO: Towards Learning Optimal Label Regularization via Bi-level Optimization. (arXiv:2305.04971v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04971">
<div class="article-summary-box-inner">
<span><p>Regularization techniques are crucial to improving the generalization
performance and training efficiency of deep neural networks. Many deep learning
algorithms rely on weight decay, dropout, batch/layer normalization to converge
faster and generalize. Label Smoothing (LS) is another simple, versatile and
efficient regularization which can be applied to various supervised
classification tasks. Conventional LS, however, regardless of the training
instance assumes that each non-target class is equally likely. In this work, we
present a general framework for training with label regularization, which
includes conventional LS but can also model instance-specific variants. Based
on this formulation, we propose an efficient way of learning LAbel
regularization by devising a Bi-level Optimization (LABO) problem. We derive a
deterministic and interpretable solution of the inner loop as the optimal label
smoothing without the need to store the parameters or the output of a trained
model. Finally, we conduct extensive experiments and demonstrate our LABO
consistently yields improvement over conventional label regularization on
various fields, including seven machine translation and three image
classification tasks across various
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeuroComparatives: Neuro-Symbolic Distillation of Comparative Knowledge. (arXiv:2305.04978v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04978">
<div class="article-summary-box-inner">
<span><p>Comparative knowledge (e.g., steel is stronger and heavier than styrofoam) is
an essential component of our world knowledge, yet understudied in prior
literature. In this paper, we study the task of comparative knowledge
acquisition, motivated by the dramatic improvements in the capabilities of
extreme-scale language models like GPT-3, which have fueled efforts towards
harvesting their knowledge into knowledge bases. However, access to inference
API for such models is limited, thereby restricting the scope and the diversity
of the knowledge acquisition. We thus ask a seemingly implausible question:
whether more accessible, yet considerably smaller and weaker models such as
GPT-2, can be utilized to acquire comparative knowledge, such that the
resulting quality is on par with their large-scale counterparts?
</p>
<p>We introduce NeuroComparatives, a novel framework for comparative knowledge
distillation using lexically-constrained decoding, followed by stringent
filtering of generated knowledge. Our framework acquires comparative knowledge
between everyday objects and results in a corpus of 8.7M comparisons over 1.74M
entity pairs - 10X larger and 30% more diverse than existing resources.
Moreover, human evaluations show that NeuroComparatives outperform existing
resources (up to 32% absolute improvement), even including GPT-3, despite using
a 100X smaller model. Our results motivate neuro-symbolic manipulation of
smaller models as a cost-effective alternative to the currently dominant
practice of relying on extreme-scale language models with limited inference
access.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Graph Guided Semantic Evaluation of Language Models For User Trust. (arXiv:2305.04989v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04989">
<div class="article-summary-box-inner">
<span><p>A fundamental question in natural language processing is - what kind of
language structure and semantics is the language model capturing? Graph formats
such as knowledge graphs are easy to evaluate as they explicitly express
language semantics and structure. This study evaluates the semantics encoded in
the self-attention transformers by leveraging explicit knowledge graph
structures. We propose novel metrics to measure the reconstruction error when
providing graph path sequences from a knowledge graph and trying to
reproduce/reconstruct the same from the outputs of the self-attention
transformer models. The opacity of language models has an immense bearing on
societal issues of trust and explainable decision outcomes. Our findings
suggest that language models are models of stochastic control processes for
plausible language pattern generation. However, they do not ascribe object and
concept-level meaning and semantics to the learned stochastic patterns such as
those described in knowledge graphs. Furthermore, to enable robust evaluation
of concept understanding by language models, we construct and make public an
augmented language understanding benchmark built on the General Language
Understanding Evaluation (GLUE) benchmark. This has significant
application-level user trust implications as stochastic patterns without a
strong sense of meaning cannot be trusted in high-stakes applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explanation-based Finetuning Makes Models More Robust to Spurious Cues. (arXiv:2305.04990v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04990">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) are so powerful that they sometimes learn
correlations between labels and features that are irrelevant to the task,
leading to poor generalization on out-of-distribution data. We propose
explanation-based finetuning as a novel and general approach to mitigate LLMs'
reliance on spurious correlations. Unlike standard finetuning where the model
only predicts the answer given the input, we finetune the model to additionally
generate a free-text explanation supporting its answer. To evaluate our method,
we finetune the model on artificially constructed training sets containing
different types of spurious cues, and test it on a test set without these cues.
Compared to standard finetuning, our method makes models remarkably more robust
against spurious cues in terms of accuracy drop across four classification
tasks: ComVE (+1.2), CREAK (+9.1), e-SNLI (+15.4), and SBIC (+6.5). Moreover,
our method works equally well with explanations generated by the model,
implying its applicability to more datasets without human-written explanations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GersteinLab at MEDIQA-Chat 2023: Clinical Note Summarization from Doctor-Patient Conversations through Fine-tuning and In-context Learning. (arXiv:2305.05001v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05001">
<div class="article-summary-box-inner">
<span><p>This paper presents our contribution to the MEDIQA-2023 Dialogue2Note shared
task, encompassing both subtask A and subtask B. We approach the task as a
dialogue summarization problem and implement two distinct pipelines: (a) a
fine-tuning of a pre-trained dialogue summarization model and GPT-3, and (b)
few-shot in-context learning (ICL) using a large language model, GPT-4. Both
methods achieve excellent results in terms of ROUGE-1 F1, BERTScore F1
(deberta-xlarge-mnli), and BLEURT, with scores of 0.4011, 0.7058, and 0.5421,
respectively. Additionally, we predict the associated section headers using
RoBERTa and SciBERT based classification models. Our team ranked fourth among
all teams, while each team is allowed to submit three runs as part of their
submission. We also utilize expert annotations to demonstrate that the notes
generated through the ICL GPT-4 are better than all other baselines. The code
for our submission is available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Relation Extraction in the era of Large Language Models. (arXiv:2305.05003v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05003">
<div class="article-summary-box-inner">
<span><p>Relation extraction (RE) is the core NLP task of inferring semantic
relationships between entities from text. Standard supervised RE techniques
entail training modules to tag tokens comprising entity spans and then predict
the relationship between them. Recent work has instead treated the problem as a
\emph{sequence-to-sequence} task, linearizing relations between entities as
target strings to be generated conditioned on the input. Here we push the
limits of this approach, using larger language models (GPT-3 and Flan-T5 large)
than considered in prior work and evaluating their performance on standard RE
tasks under varying levels of supervision. We address issues inherent to
evaluating generative approaches to RE by doing human evaluations, in lieu of
relying on exact matching. Under this refined evaluation, we find that: (1)
Few-shot prompting with GPT-3 achieves near SOTA performance, i.e., roughly
equivalent to existing fully supervised models; (2) Flan-T5 is not as capable
in the few-shot setting, but supervising and fine-tuning it with
Chain-of-Thought (CoT) style explanations (generated via GPT-3) yields SOTA
results. We release this model as a new baseline for RE tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Not Blindly Imitate the Teacher: Using Perturbed Loss for Knowledge Distillation. (arXiv:2305.05010v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05010">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation is a popular technique to transfer knowledge from
large teacher models to a small student model. Typically, the student learns to
imitate the teacher by minimizing the KL divergence of its output distribution
with the teacher's output distribution. In this work, we argue that such a
learning objective is sub-optimal because there exists a discrepancy between
the teacher's output distribution and the ground truth label distribution.
Therefore, forcing the student to blindly imitate the unreliable teacher output
distribution leads to inferior performance. To this end, we propose a novel
knowledge distillation objective PTLoss by first representing the vanilla
KL-based distillation loss function via a Maclaurin series and then perturbing
the leading-order terms in this series. This perturbed loss implicitly
transforms the original teacher into a proxy teacher with a distribution closer
to the ground truth distribution. We establish the theoretical connection
between this "distribution closeness" and the student model generalizability,
which enables us to select the PTLoss's perturbation coefficients in a
principled way. Extensive experiments on five datasets demonstrate PTLoss can
significantly improve the distillation effectiveness for teachers of various
scales.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Web Content Filtering through knowledge distillation of Large Language Models. (arXiv:2305.05027v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05027">
<div class="article-summary-box-inner">
<span><p>We introduce a state-of-the-art approach for URL categorization that
leverages the power of Large Language Models (LLMs) to address the primary
objectives of web content filtering: safeguarding organizations from legal and
ethical risks, limiting access to high-risk or suspicious websites, and
fostering a secure and professional work environment. Our method utilizes LLMs
to generate accurate classifications and then employs established knowledge
distillation techniques to create smaller, more specialized student models
tailored for web content filtering. Distillation results in a student model
with a 9\% accuracy rate improvement in classifying websites, sourced from
customer telemetry data collected by a large security vendor, into 30 distinct
content categories based on their URLs, surpassing the current state-of-the-art
approach. Our student model matches the performance of the teacher LLM with 175
times less parameters, allowing the model to be used for in-line scanning of
large volumes of URLs, and requires 3 orders of magnitude less manually labeled
training data than the current state-of-the-art approach. Depending on the
specific use case, the output generated by our approach can either be directly
returned or employed as a pre-filter for more resource-intensive operations
involving website images or HTML.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ANALOGICAL -- A New Benchmark for Analogy of Long Text for Large Language Models. (arXiv:2305.05050v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05050">
<div class="article-summary-box-inner">
<span><p>Over the past decade, analogies, in the form of word-level analogies, have
played a significant role as an intrinsic measure of evaluating the quality of
word embedding methods such as word2vec. Modern large language models (LLMs),
however, are primarily evaluated on extrinsic measures based on benchmarks such
as GLUE and SuperGLUE, and there are only a few investigations on whether LLMs
can draw analogies between long texts. In this paper, we present ANALOGICAL, a
new benchmark to intrinsically evaluate LLMs across a taxonomy of analogies of
long text with six levels of complexity -- (i) word, (ii) word vs. sentence,
(iii) syntactic, (iv) negation, (v) entailment, and (vi) metaphor. Using
thirteen datasets and three different distance measures, we evaluate the
abilities of eight LLMs in identifying analogical pairs in the semantic vector
space (e.g., "I can speak two languages" should be closer to "I am bilingual"
while "I like chocolate" and "I do not like chocolate" should be orthogonal).
Our evaluation finds that it is increasingly challenging for LLMs to identify
analogies when going up the analogy taxonomy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dreams Are More "Predictable'' Than You Think. (arXiv:2305.05054v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05054">
<div class="article-summary-box-inner">
<span><p>A consistent body of evidence suggests that dream reports significantly vary
from other types of textual transcripts with respect to semantic content.
Furthermore, it appears to be a widespread belief in the dream/sleep research
community that dream reports constitute rather ``unique'' strings of text. This
might be a notable issue for the growing amount of approaches using natural
language processing (NLP) tools to automatically analyse dream reports, as they
largely rely on neural models trained on non-dream corpora scraped from the
web. In this work, I will adopt state-of-the-art (SotA) large language models
(LLMs), to study if and how dream reports deviate from other human-generated
text strings, such as Wikipedia. Results show that, taken as a whole, DreamBank
does not deviate from Wikipedia. Moreover, on average, single dream reports are
significantly more predictable than Wikipedia articles. Preliminary evidence
suggests that word count, gender, and visual impairment can significantly shape
how predictable a dream report can appear to the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coherent Wave Dynamics and Language Generation of a Generative Pre-trained Transformer. (arXiv:2305.05061v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05061">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs), such as the Generative Pretrained Transformer
(GPT), have achieved tremendous success in various language tasks, but their
emergent abilities have also raised many questions, concerns, and challenges
that need to be addressed. To gain a better understanding of the models' inner
mechanisms, we analyze the hidden state and channel wave dynamics in a small
GPT, focusing on the coherence of wave patterns in terms of cross-channel
correlation and individual auto-correlation. Our findings suggest that wave
dynamics offer consistent and repeatable intrinsic oscillation modes, along
with context-aware plasticity and expressiveness in language generation. By
analyzing wave patterns, coherence, and clustering, we provide a systematic way
to identify and interpret the functionality of the hidden state channels,
paving the way to understand and control higher-level language pattern
formation. In addition, we investigate the Poisson statistics of spelling
errors in text sequence generation across various levels of model training and
observe a phase-transition-like process. As coherence builds up, there is a
competition between the generation of correct and misspelled words. However,
once the model is adequately trained and significant coherence has emerged, the
coherent process becomes strong enough to effectively suppress spelling errors,
preventing the cascade amplification of defects. The distribution of correct
spellings transitions from Poissonian to Sub-Poissonian, while the distribution
of misspellings shows the opposite trend. By leveraging concepts and techniques
from quantum physics, we gain novel insights into the dynamics of the small
GPT. This approach can be extended to larger language models that exhibit more
complex coherent language patterns, opening up opportunities to interpret their
emergent capabilities and develop more specialized models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Unified Evaluation Framework for Novelty Detection and Accommodation in NLP with an Instantiation in Authorship Attribution. (arXiv:2305.05079v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05079">
<div class="article-summary-box-inner">
<span><p>State-of-the-art natural language processing models have been shown to
achieve remarkable performance in 'closed-world' settings where all the labels
in the evaluation set are known at training time. However, in real-world
settings, 'novel' instances that do not belong to any known class are often
observed. This renders the ability to deal with novelties crucial. To initiate
a systematic research in this important area of 'dealing with novelties', we
introduce 'NoveltyTask', a multi-stage task to evaluate a system's performance
on pipelined novelty 'detection' and 'accommodation' tasks. We provide
mathematical formulation of NoveltyTask and instantiate it with the authorship
attribution task that pertains to identifying the correct author of a given
text. We use Amazon reviews corpus and compile a large dataset (consisting of
250k instances across 200 authors/labels) for NoveltyTask. We conduct
comprehensive experiments and explore several baseline methods for the task.
Our results show that the methods achieve considerably low performance making
the task challenging and leaving sufficient room for improvement. Finally, we
believe our work will encourage research in this underexplored area of dealing
with novelties, an important step en route to developing robust systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-enhanced Agents for Interactive Text Games. (arXiv:2305.05091v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05091">
<div class="article-summary-box-inner">
<span><p>Communication via natural language is a crucial aspect of intelligence, and
it requires computational models to learn and reason about world concepts, with
varying levels of supervision. While there has been significant progress made
on fully-supervised non-interactive tasks, such as question-answering and
procedural text understanding, much of the community has turned to various
sequential interactive tasks, as in semi-Markov text-based games, which have
revealed limitations of existing approaches in terms of coherence, contextual
awareness, and their ability to learn effectively from the environment. In this
paper, we propose a framework for enabling improved functional grounding of
agents in text-based games. Specifically, we consider two forms of domain
knowledge that we inject into learning-based agents: memory of previous correct
actions and affordances of relevant objects in the environment. Our framework
supports three representative model classes: `pure' reinforcement learning (RL)
agents, RL agents enhanced with knowledge graphs, and agents equipped with
language models. Furthermore, we devise multiple injection strategies for the
above domain knowledge types and agent architectures, including injection via
knowledge graphs and augmentation of the existing input encoding strategies. We
perform all experiments on the ScienceWorld text-based game environment, to
illustrate the performance of various model configurations in challenging
science-related instruction-following tasks. Our findings provide crucial
insights on the development of effective natural language processing systems
for interactive contexts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interactive Concept Learning for Uncovering Latent Themes in Large Text Collections. (arXiv:2305.05094v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05094">
<div class="article-summary-box-inner">
<span><p>Experts across diverse disciplines are often interested in making sense of
large text collections. Traditionally, this challenge is approached either by
noisy unsupervised techniques such as topic models, or by following a manual
theme discovery process. In this paper, we expand the definition of a theme to
account for more than just a word distribution, and include generalized
concepts deemed relevant by domain experts. Then, we propose an interactive
framework that receives and encodes expert feedback at different levels of
abstraction. Our framework strikes a balance between automation and manual
coding, allowing experts to maintain control of their study while reducing the
manual effort required.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Who Needs Decoders? Efficient Estimation of Sequence-level Attributes. (arXiv:2305.05098v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05098">
<div class="article-summary-box-inner">
<span><p>State-of-the-art sequence-to-sequence models often require autoregressive
decoding, which can be highly expensive. However, for some downstream tasks
such as out-of-distribution (OOD) detection and resource allocation, the actual
decoding output is not needed just a scalar attribute of this sequence. In
these scenarios, where for example knowing the quality of a system's output to
predict poor performance prevails over knowing the output itself, is it
possible to bypass the autoregressive decoding? We propose Non-Autoregressive
Proxy (NAP) models that can efficiently predict general scalar-valued
sequence-level attributes. Importantly, NAPs predict these metrics directly
from the encodings, avoiding the expensive autoregressive decoding stage. We
consider two sequence-to-sequence task: Machine Translation (MT); and Automatic
Speech Recognition (ASR). In OOD for MT, NAPs outperform a deep ensemble while
being significantly faster. NAPs are also shown to be able to predict
performance metrics such as BERTScore (MT) or word error rate (ASR). For
downstream tasks, such as data filtering and resource optimization, NAPs
generate performance predictions that outperform predictive uncertainty while
being highly inference efficient.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Phishing Attacks using ChatGPT. (arXiv:2305.05133v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05133">
<div class="article-summary-box-inner">
<span><p>The ability of ChatGPT to generate human-like responses and understand
context has made it a popular tool for conversational agents, content creation,
data analysis, and research and innovation. However, its effectiveness and ease
of accessibility makes it a prime target for generating malicious content, such
as phishing attacks, that can put users at risk. In this work, we identify
several malicious prompts that can be provided to ChatGPT to generate
functional phishing websites. Through an iterative approach, we find that these
phishing websites can be made to imitate popular brands and emulate several
evasive tactics that have been known to avoid detection by anti-phishing
entities. These attacks can be generated using vanilla ChatGPT without the need
of any prior adversarial exploits (jailbreaking).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Read, Diagnose and Chat: Towards Explainable and Interactive LLMs-Augmented Depression Detection in Social Media. (arXiv:2305.05138v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05138">
<div class="article-summary-box-inner">
<span><p>This paper proposes a new depression detection system based on LLMs that is
both interpretable and interactive. It not only provides a diagnosis, but also
diagnostic evidence and personalized recommendations based on natural language
dialogue with the user. We address challenges such as the processing of large
amounts of text and integrate professional diagnostic criteria. Our system
outperforms traditional methods across various settings and is demonstrated
through case studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effective Medical Code Prediction via Label Internal Alignment. (arXiv:2305.05162v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05162">
<div class="article-summary-box-inner">
<span><p>The clinical notes are usually typed into the system by physicians. They are
typically required to be marked by standard medical codes, and each code
represents a diagnosis or medical treatment procedure. Annotating these notes
is time consuming and prone to error. In this paper, we proposed a multi-view
attention based Neural network to predict medical codes from clinical texts.
Our method incorporates three aspects of information, the semantic context of
the clinical text, the relationship among the label (medical codes) space, and
the alignment between each pair of a clinical text and medical code. Our method
is verified to be effective on the open source dataset. The experimental result
shows that our method achieves better performance against the prior
state-of-art on multiple metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">E2TIMT: Efficient and Effective Modal Adapter for Text Image Machine Translation. (arXiv:2305.05166v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05166">
<div class="article-summary-box-inner">
<span><p>Text image machine translation (TIMT) aims to translate texts embedded in
images from one source language to another target language. Existing methods,
both two-stage cascade and one-stage end-to-end architectures, suffer from
different issues. The cascade models can benefit from the large-scale optical
character recognition (OCR) and MT datasets but the two-stage architecture is
redundant. The end-to-end models are efficient but suffer from training data
deficiency. To this end, in our paper, we propose an end-to-end TIMT model
fully making use of the knowledge from existing OCR and MT datasets to pursue
both an effective and efficient framework. More specifically, we build a novel
modal adapter effectively bridging the OCR encoder and MT decoder. End-to-end
TIMT loss and cross-modal contrastive loss are utilized jointly to align the
feature distribution of the OCR and MT tasks. Extensive experiments show that
the proposed method outperforms the existing two-stage cascade models and
one-stage end-to-end models with a lighter and faster architecture.
Furthermore, the ablation studies verify the generalization of our method,
where the proposed modal adapter is effective to bridge various OCR and MT
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Summarization with Precise Length Control. (arXiv:2305.05171v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05171">
<div class="article-summary-box-inner">
<span><p>Many applications of text generation such as summarization benefit from
accurately controlling the text length. Existing approaches on
length-controlled summarization either result in degraded performance or can
only control the length approximately. In this work, we present a framework to
generate summaries with precisely the specified number of tokens or sentences,
while maintaining or even improving the text quality. In addition, we jointly
train the models to predict the lengths, so our model can generate summaries
with optimal length. We evaluate the proposed framework on the CNNDM dataset
and show improved performance compared to existing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance. (arXiv:2305.05176v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05176">
<div class="article-summary-box-inner">
<span><p>There is a rapidly growing number of large language models (LLMs) that users
can query for a fee. We review the cost associated with querying popular LLM
APIs, e.g. GPT-4, ChatGPT, J1-Jumbo, and find that these models have
heterogeneous pricing structures, with fees that can differ by two orders of
magnitude. In particular, using LLMs on large collections of queries and text
can be expensive. Motivated by this, we outline and discuss three types of
strategies that users can exploit to reduce the inference cost associated with
using LLMs: 1) prompt adaptation, 2) LLM approximation, and 3) LLM cascade. As
an example, we propose FrugalGPT, a simple yet flexible instantiation of LLM
cascade which learns which combinations of LLMs to use for different queries in
order to reduce cost and improve accuracy. Our experiments show that FrugalGPT
can match the performance of the best individual LLM (e.g. GPT-4) with up to
98% cost reduction or improve the accuracy over GPT-4 by 4% with the same cost.
The ideas and findings presented here lay a foundation for using LLMs
sustainably and efficiently.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MoT: Pre-thinking and Recalling Enable ChatGPT to Self-Improve with Memory-of-Thoughts. (arXiv:2305.05181v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05181">
<div class="article-summary-box-inner">
<span><p>Large Language Models have shown impressive abilities on various tasks.
However, fundamentally improving them depends on high-quality datasets or
computationally expensive fine-tuning. On the contrary, human can easily
improve themselves by thinking and memory, without external resources. In this
paper, we propose a framework, MoT, to let the LLM self-improve through Memory
of Thoughts, without annotated datasets and parameter updates. Specifically,
the framework is divided into two stages: 1. before the test stage, we let the
LLM pre-think on the unlabeled dataset and save the high-confidence thoughts as
external memory; 2. during inference, given a test question, we let the LLM
recall relevant memory to help itself reason and answer it. Experimental
results show that the proposed framework can help ChatGPT significantly improve
its abilities in math reasoning, commonsense reasoning, factual reasoning and
natural language inference. Further analyses show that each component
contributes critically to the improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CSED: A Chinese Semantic Error Diagnosis Corpus. (arXiv:2305.05183v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05183">
<div class="article-summary-box-inner">
<span><p>Recently, much Chinese text error correction work has focused on Chinese
Spelling Check (CSC) and Chinese Grammatical Error Diagnosis (CGED). In
contrast, little attention has been paid to the complicated problem of Chinese
Semantic Error Diagnosis (CSED), which lacks relevant datasets. The study of
semantic errors is important because they are very common and may lead to
syntactic irregularities or even problems of comprehension. To investigate
this, we build the CSED corpus, which includes two datasets. The one is for the
CSED-Recognition (CSED-R) task. The other is for the CSED-Correction (CSED-C)
task. Our annotation guarantees high-quality data through quality assurance
mechanisms. Our experiments show that powerful pre-trained models perform
poorly on this corpus. We also find that the CSED task is challenging, as
evidenced by the fact that even humans receive a low score. This paper proposes
syntax-aware models to specifically adapt to the CSED task. The experimental
results show that the introduction of the syntax-aware approach is meaningful.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models. (arXiv:2305.05189v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05189">
<div class="article-summary-box-inner">
<span><p>Diffusion models, which have emerged to become popular text-to-image
generation models, can produce high-quality and content-rich images guided by
textual prompts. However, there are limitations to semantic understanding and
commonsense reasoning in existing models when the input prompts are concise
narrative, resulting in low-quality image generation. To improve the capacities
for narrative prompts, we propose a simple-yet-effective parameter-efficient
fine-tuning approach called the Semantic Understanding and Reasoning adapter
(SUR-adapter) for pre-trained diffusion models. To reach this goal, we first
collect and annotate a new dataset SURD which consists of more than 57,000
semantically corrected multi-modal samples. Each sample contains a simple
narrative prompt, a complex keyword-based prompt, and a high-quality image.
Then, we align the semantic representation of narrative prompts to the complex
prompts and transfer knowledge of large language models (LLMs) to our
SUR-adapter via knowledge distillation so that it can acquire the powerful
semantic understanding and reasoning capabilities to build a high-quality
textual semantic representation for text-to-image generation. We conduct
experiments by integrating multiple LLMs and popular pre-trained diffusion
models to show the effectiveness of our approach in enabling diffusion models
to understand and reason concise natural language without image quality
degradation. Our approach can make text-to-image diffusion models easier to use
with better user experience, which demonstrates our approach has the potential
for further advancing the development of user-friendly text-to-image generation
models by bridging the semantic gap between simple narrative prompts and
complex keyword-based prompts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COLA: Contextualized Commonsense Causal Reasoning from the Causal Inference Perspective. (arXiv:2305.05191v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05191">
<div class="article-summary-box-inner">
<span><p>Detecting commonsense causal relations (causation) between events has long
been an essential yet challenging task. Given that events are complicated, an
event may have different causes under various contexts. Thus, exploiting
context plays an essential role in detecting causal relations. Meanwhile,
previous works about commonsense causation only consider two events and ignore
their context, simplifying the task formulation. This paper proposes a new task
to detect commonsense causation between two events in an event sequence (i.e.,
context), called contextualized commonsense causal reasoning. We also design a
zero-shot framework: COLA (Contextualized Commonsense Causality Reasoner) to
solve the task from the causal inference perspective. This framework obtains
rich incidental supervision from temporality and balances covariates from
multiple timestamps to remove confounding effects. Our extensive experiments
show that COLA can detect commonsense causality more accurately than baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploration of Language Dependency for Japanese Self-Supervised Speech Representation Models. (arXiv:2305.05201v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05201">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) has been dramatically successful not only in
monolingual but also in cross-lingual settings. However, since the two settings
have been studied individually in general, there has been little research
focusing on how effective a cross-lingual model is in comparison with a
monolingual model. In this paper, we investigate this fundamental question
empirically with Japanese automatic speech recognition (ASR) tasks. First, we
begin by comparing the ASR performance of cross-lingual and monolingual models
for two different language tasks while keeping the acoustic domain as identical
as possible. Then, we examine how much unlabeled data collected in Japanese is
needed to achieve performance comparable to a cross-lingual model pre-trained
with tens of thousands of hours of English and/or multilingual data. Finally,
we extensively investigate the effectiveness of SSL in Japanese and demonstrate
state-of-the-art performance on multiple ASR tasks. Since there is no
comprehensive SSL study for Japanese, we hope this study will guide Japanese
SSL research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Utilizing Lexical Similarity to Enable Zero-Shot Machine Translation for Extremely Low-resource Languages. (arXiv:2305.05214v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05214">
<div class="article-summary-box-inner">
<span><p>We address the task of machine translation from an extremely low-resource
language (LRL) to English using cross-lingual transfer from a closely related
high-resource language (HRL). For many of these languages, no parallel corpora
are available, even monolingual corpora are limited and representations in
pre-trained sequence-to-sequence models are absent. These factors limit the
benefits of cross-lingual transfer from shared embedding spaces in multilingual
models. However, many extremely LRLs have a high level of lexical similarity
with related HRLs. We utilize this property by injecting character and
character-span noise into the training data of the HRL prior to learning the
vocabulary. This serves as a regularizer which makes the model more robust to
lexical divergences between the HRL and LRL and better facilitates
cross-lingual transfer. On closely related HRL and LRL pairs from multiple
language families, we observe that our method significantly outperforms the
baseline MT as well as approaches proposed previously to address cross-lingual
transfer between closely related languages. We also show that the proposed
character-span noise injection performs better than the unigram-character noise
injection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Teacher Knowledge Distillation For Text Image Machine Translation. (arXiv:2305.05226v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05226">
<div class="article-summary-box-inner">
<span><p>Text image machine translation (TIMT) has been widely used in various
real-world applications, which translates source language texts in images into
another target language sentence. Existing methods on TIMT are mainly divided
into two categories: the recognition-then-translation pipeline model and the
end-to-end model. However, how to transfer knowledge from the pipeline model
into the end-to-end model remains an unsolved problem. In this paper, we
propose a novel Multi-Teacher Knowledge Distillation (MTKD) method to
effectively distillate knowledge into the end-to-end TIMT model from the
pipeline model. Specifically, three teachers are utilized to improve the
performance of the end-to-end TIMT model. The image encoder in the end-to-end
TIMT model is optimized with the knowledge distillation guidance from the
recognition teacher encoder, while the sequential encoder and decoder are
improved by transferring knowledge from the translation sequential and decoder
teacher models. Furthermore, both token and sentence-level knowledge
distillations are incorporated to better boost the translation performance.
Extensive experimental results show that our proposed MTKD effectively improves
the text image translation performance and outperforms existing end-to-end and
pipeline models with fewer parameters and less decoding time, illustrating that
MTKD can take advantage of both pipeline and end-to-end models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distilling Script Knowledge from Large Language Models for Constrained Language Planning. (arXiv:2305.05252v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05252">
<div class="article-summary-box-inner">
<span><p>In everyday life, humans often plan their actions by following step-by-step
instructions in the form of goal-oriented scripts. Previous work has exploited
language models (LMs) to plan for abstract goals of stereotypical activities
(e.g., "make a cake"), but leaves more specific goals with multi-facet
constraints understudied (e.g., "make a cake for diabetics"). In this paper, we
define the task of constrained language planning for the first time. We propose
an overgenerate-then-filter approach to improve large language models (LLMs) on
this task, and use it to distill a novel constrained language planning dataset,
CoScript, which consists of 55,000 scripts. Empirical results demonstrate that
our method significantly improves the constrained language planning ability of
LLMs, especially on constraint faithfulness. Furthermore, CoScript is
demonstrated to be quite effective in endowing smaller LMs with constrained
language planning ability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attack Named Entity Recognition by Entity Boundary Interference. (arXiv:2305.05253v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05253">
<div class="article-summary-box-inner">
<span><p>Named Entity Recognition (NER) is a cornerstone NLP task while its robustness
has been given little attention. This paper rethinks the principles of NER
attacks derived from sentence classification, as they can easily violate the
label consistency between the original and adversarial NER examples. This is
due to the fine-grained nature of NER, as even minor word changes in the
sentence can result in the emergence or mutation of any entities, resulting in
invalid adversarial examples. To this end, we propose a novel one-word
modification NER attack based on a key insight, NER models are always
vulnerable to the boundary position of an entity to make their decision. We
thus strategically insert a new boundary into the sentence and trigger the
Entity Boundary Interference that the victim model makes the wrong prediction
either on this boundary word or on other words in the sentence. We call this
attack Virtual Boundary Attack (ViBA), which is shown to be remarkably
effective when attacking both English and Chinese models with a 70%-90% attack
success rate on state-of-the-art language models (e.g. RoBERTa, DeBERTa) and
also significantly faster than previous methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Acoustic and Semantic Contextual Biasing in Neural Transducers for Speech Recognition. (arXiv:2305.05271v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05271">
<div class="article-summary-box-inner">
<span><p>Attention-based contextual biasing approaches have shown significant
improvements in the recognition of generic and/or personal rare-words in
End-to-End Automatic Speech Recognition (E2E ASR) systems like neural
transducers. These approaches employ cross-attention to bias the model towards
specific contextual entities injected as bias-phrases to the model. Prior
approaches typically relied on subword encoders for encoding the bias phrases.
However, subword tokenizations are coarse and fail to capture granular
pronunciation information which is crucial for biasing based on acoustic
similarity. In this work, we propose to use lightweight character
representations to encode fine-grained pronunciation features to improve
contextual biasing guided by acoustic similarity between the audio and the
contextual entities (termed acoustic biasing). We further integrate pretrained
neural language model (NLM) based encoders to encode the utterance's semantic
context along with contextual entities to perform biasing informed by the
utterance's semantic context (termed semantic biasing). Experiments using a
Conformer Transducer model on the Librispeech dataset show a 4.62% - 9.26%
relative WER improvement on different biasing list sizes over the baseline
contextual model when incorporating our proposed acoustic and semantic biasing
approach. On a large-scale in-house dataset, we observe 7.91% relative WER
improvement compared to our baseline model. On tail utterances, the
improvements are even more pronounced with 36.80% and 23.40% relative WER
improvements on Librispeech rare words and an in-house testset respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VCSUM: A Versatile Chinese Meeting Summarization Dataset. (arXiv:2305.05280v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05280">
<div class="article-summary-box-inner">
<span><p>Compared to news and chat summarization, the development of meeting
summarization is hugely decelerated by the limited data. To this end, we
introduce a versatile Chinese meeting summarization dataset, dubbed VCSum,
consisting of 239 real-life meetings, with a total duration of over 230 hours.
We claim our dataset is versatile because we provide the annotations of topic
segmentation, headlines, segmentation summaries, overall meeting summaries, and
salient sentences for each meeting transcript. As such, the dataset can adapt
to various summarization tasks or methods, including segmentation-based
summarization, multi-granularity summarization and retrieval-then-generate
summarization. Our analysis confirms the effectiveness and robustness of VCSum.
We also provide a set of benchmark models regarding different downstream
summarization tasks on VCSum to facilitate further research. The dataset and
code will be released at \url{https://github.com/hahahawu/VCSum}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dialogue Planning via Brownian Bridge Stochastic Process for Goal-directed Proactive Dialogue. (arXiv:2305.05290v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05290">
<div class="article-summary-box-inner">
<span><p>Goal-directed dialogue systems aim to proactively reach a pre-determined
target through multi-turn conversations. The key to achieving this task lies in
planning dialogue paths that smoothly and coherently direct conversations
towards the target. However, this is a challenging and under-explored task. In
this work, we propose a coherent dialogue planning approach that uses a
stochastic process to model the temporal dynamics of dialogue paths. We define
a latent space that captures the coherence of goal-directed behavior using a
Brownian bridge process, which allows us to incorporate user feedback flexibly
in dialogue planning. Based on the derived latent trajectories, we generate
dialogue paths explicitly using pre-trained language models. We finally employ
these paths as natural language prompts to guide dialogue generation. Our
experiments show that our approach generates more coherent utterances and
achieves the goal with a higher success rate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Zero-shot Cross-lingual Retrieval by Training on Artificially Code-Switched Data. (arXiv:2305.05295v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05295">
<div class="article-summary-box-inner">
<span><p>Transferring information retrieval (IR) models from a high-resource language
(typically English) to other languages in a zero-shot fashion has become a
widely adopted approach. In this work, we show that the effectiveness of
zero-shot rankers diminishes when queries and documents are present in
different languages. Motivated by this, we propose to train ranking models on
artificially code-switched data instead, which we generate by utilizing
bilingual lexicons. To this end, we experiment with lexicons induced from (1)
cross-lingual word embeddings and (2) parallel Wikipedia page titles. We use
the mMARCO dataset to extensively evaluate reranking models on 36 language
pairs spanning Monolingual IR (MoIR), Cross-lingual IR (CLIR), and Multilingual
IR (MLIR). Our results show that code-switching can yield consistent and
substantial gains of 5.1 MRR@10 in CLIR and 3.9 MRR@10 in MLIR, while
maintaining stable performance in MoIR. Encouragingly, the gains are especially
pronounced for distant languages (up to 2x absolute gain). We further show that
our approach is robust towards the ratio of code-switched tokens and also
extends to unseen languages. Our results demonstrate that training on
code-switched data is a cheap and effective way of generalizing zero-shot
rankers for cross-lingual and multilingual retrieval.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Perfect Victim: Computational Analysis of Judicial Attitudes towards Victims of Sexual Violence. (arXiv:2305.05302v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05302">
<div class="article-summary-box-inner">
<span><p>We develop computational models to analyze court statements in order to
assess judicial attitudes toward victims of sexual violence in the Israeli
court system. The study examines the resonance of "rape myths" in the criminal
justice system's response to sex crimes, in particular in judicial assessment
of victim's credibility. We begin by formulating an ontology for evaluating
judicial attitudes toward victim's credibility, with eight ordinal labels and
binary categorizations. Second, we curate a manually annotated dataset for
judicial assessments of victim's credibility in the Hebrew language, as well as
a model that can extract credibility labels from court cases. The dataset
consists of 855 verdict decision documents in sexual assault cases from
1990-2021, annotated with the help of legal experts and trained law students.
The model uses a combined approach of syntactic and latent structures to find
sentences that convey the judge's attitude towards the victim and classify them
according to the credibility label set. Our ontology, data, and models will be
made available upon request, in the hope they spur future progress in this
judicial important task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structured Sentiment Analysis as Transition-based Dependency Parsing. (arXiv:2305.05311v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05311">
<div class="article-summary-box-inner">
<span><p>Structured sentiment analysis (SSA) aims to automatically extract people's
opinions from a text in natural language and adequately represent that
information in a graph structure. One of the most accurate methods for
performing SSA was recently proposed and consists of approaching it as a
dependency parsing task. Although we can find in the literature how
transition-based algorithms excel in dependency parsing in terms of accuracy
and efficiency, all proposed attempts to tackle SSA following that approach
were based on graph-based models. In this article, we present the first
transition-based method to address SSA as dependency parsing. Specifically, we
design a transition system that processes the input text in a left-to-right
pass, incrementally generating the graph structure containing all identified
opinions. To effectively implement our final transition-based model, we resort
to a Pointer Network architecture as a backbone. From an extensive evaluation,
we demonstrate that our model offers the best performance to date in
practically all cases among prior dependency-based methods, and surpass recent
task-specific techniques on the most challenging datasets. We additionally
include an in-depth analysis and empirically prove that the overall
time-complexity cost of our approach is quadratic in the sentence length, being
more efficient than top-performing graph-based parsers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detection of depression on social networks using transformers and ensembles. (arXiv:2305.05325v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05325">
<div class="article-summary-box-inner">
<span><p>As the impact of technology on our lives is increasing, we witness increased
use of social media that became an essential tool not only for communication
but also for sharing information with community about our thoughts and
feelings. This can be observed also for people with mental health disorders
such as depression where they use social media for expressing their thoughts
and asking for help. This opens a possibility to automatically process social
media posts and detect signs of depression. We build several large pre-trained
language model based classifiers for depression detection from social media
posts. Besides fine-tuning BERT, RoBERTA, BERTweet, and mentalBERT were also
construct two types of ensembles. We analyze the performance of our models on
two data sets of posts from social platforms Reddit and Twitter, and
investigate also the performance of transfer learning across the two data sets.
The results show that transformer ensembles improve over the single
transformer-based classifiers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explainable Recommender with Geometric Information Bottleneck. (arXiv:2305.05331v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05331">
<div class="article-summary-box-inner">
<span><p>Explainable recommender systems can explain their recommendation decisions,
enhancing user trust in the systems. Most explainable recommender systems
either rely on human-annotated rationales to train models for explanation
generation or leverage the attention mechanism to extract important text spans
from reviews as explanations. The extracted rationales are often confined to an
individual review and may fail to identify the implicit features beyond the
review text. To avoid the expensive human annotation process and to generate
explanations beyond individual reviews, we propose to incorporate a geometric
prior learnt from user-item interactions into a variational network which
infers latent factors from user-item reviews. The latent factors from an
individual user-item pair can be used for both recommendation and explanation
generation, which naturally inherit the global characteristics encoded in the
prior knowledge. Experimental results on three e-commerce datasets show that
our model significantly improves the interpretability of a variational
recommender using the Wasserstein distance while achieving performance
comparable to existing content-based recommender systems in terms of
recommendation behaviours.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ArgU: A Controllable Factual Argument Generator. (arXiv:2305.05334v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05334">
<div class="article-summary-box-inner">
<span><p>Effective argumentation is essential towards a purposeful conversation with a
satisfactory outcome. For example, persuading someone to reconsider smoking
might involve empathetic, well founded arguments based on facts and expert
opinions about its ill-effects and the consequences on one's family. However,
the automatic generation of high-quality factual arguments can be challenging.
Addressing existing controllability issues can make the recent advances in
computational models for argument generation a potential solution. In this
paper, we introduce ArgU: a neural argument generator capable of producing
factual arguments from input facts and real-world concepts that can be
explicitly controlled for stance and argument structure using Walton's argument
scheme-based control codes. Unfortunately, computational argument generation is
a relatively new field and lacks datasets conducive to training. Hence, we have
compiled and released an annotated corpora of 69,428 arguments spanning six
topics and six argument schemes, making it the largest publicly available
corpus for identifying argument schemes; the paper details our annotation and
dataset creation framework. We further experiment with an argument generation
strategy that establishes an inference strategy by generating an ``argument
template'' before actual argument generation. Our results demonstrate that it
is possible to automatically generate diverse arguments exhibiting different
inference patterns for the same set of facts by using control codes based on
argument schemes and stance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rudolf Christoph Eucken at SemEval-2023 Task 4: An Ensemble Approach for Identifying Human Values from Arguments. (arXiv:2305.05335v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05335">
<div class="article-summary-box-inner">
<span><p>The subtle human values we acquire through life experiences govern our
thoughts and gets reflected in our speech. It plays an integral part in
capturing the essence of our individuality and making it imperative to identify
such values in computational systems that mimic human actions. Computational
argumentation is a field that deals with the argumentation capabilities of
humans and can benefit from identifying such values. Motivated by that, we
present an ensemble approach for detecting human values from argument text. Our
ensemble comprises three models: (i) An entailment-based model for determining
the human values based on their descriptions, (ii) A Roberta-based classifier
that predicts the set of human values from an argument. (iii) A Roberta-based
classifier to predict a reduced set of human values from an argument. We
experiment with different ways of combining the models and report our results.
Furthermore, our best combination achieves an overall F1 score of 0.48 on the
main test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Framework for Designing Foundation Model based Systems. (arXiv:2305.05352v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05352">
<div class="article-summary-box-inner">
<span><p>The recent release of large language model (LLM) based chatbots, such as
ChatGPT, has attracted significant attention on foundations models. It is
widely believed that foundation models will serve as the fundamental building
blocks for future AI systems. As foundation models are in their early stages,
the design of foundation model based systems has not yet been systematically
explored. There is little understanding about the impact of introducing
foundation models in software architecture. Therefore, in this paper, we
propose a taxonomy of foundation model based systems, which classifies and
compares the characteristics of foundation models and foundation model based
systems. Our taxonomy comprises three categories: foundation model pretraining
and fine-tuning, architecture design of foundation model based systems, and
responsible-AI-by-design. This taxonomy provides concrete guidance for making
major design decisions when designing foundation model based systems and
highlights trade-offs arising from design decisions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Model Programs. (arXiv:2305.05364v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05364">
<div class="article-summary-box-inner">
<span><p>In recent years, large pre-trained language models (LLMs) have demonstrated
the ability to follow instructions and perform novel tasks from a few examples.
The possibility to parameterise an LLM through such in-context examples widens
their capability at a much lower cost than finetuning. We extend this line of
reasoning and present a method which further expands the capabilities of an LLM
by embedding it within an algorithm or program. To demonstrate the benefits of
this approach, we present an illustrative example of evidence-supported
question-answering. We obtain a 6.4\% improvement over the chain of thought
baseline through a more algorithmic approach without any finetuning.
Furthermore, we highlight recent work from this perspective and discuss the
advantages and disadvantages in comparison to the standard approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PLM-GNN: A Webpage Classification Method based on Joint Pre-trained Language Model and Graph Neural Network. (arXiv:2305.05378v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05378">
<div class="article-summary-box-inner">
<span><p>The number of web pages is growing at an exponential rate, accumulating
massive amounts of data on the web. It is one of the key processes to classify
webpages in web information mining. Some classical methods are based on
manually building features of web pages and training classifiers based on
machine learning or deep learning. However, building features manually requires
specific domain knowledge and usually takes a long time to validate the
validity of features. Considering webpages generated by the combination of text
and HTML Document Object Model(DOM) trees, we propose a representation and
classification method based on a pre-trained language model and graph neural
network, named PLM-GNN. It is based on the joint encoding of text and HTML DOM
trees in the web pages. It performs well on the KI-04 and SWDE datasets and on
practical dataset AHS for the project of scholar's homepage crawling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Code Execution with Pre-trained Language Models. (arXiv:2305.05383v1 [cs.PL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05383">
<div class="article-summary-box-inner">
<span><p>Code execution is a fundamental aspect of programming language semantics that
reflects the exact behavior of the code. However, most pre-trained models for
code intelligence ignore the execution trace and only rely on source code and
syntactic structures. In this paper, we investigate how well pre-trained models
can understand and perform code execution. We develop a mutation-based data
augmentation technique to create a large-scale and realistic Python dataset and
task for code execution, which challenges existing models such as Codex. We
then present CodeExecutor, a Transformer model that leverages code execution
pre-training and curriculum learning to enhance its semantic comprehension. We
evaluate CodeExecutor on code execution and show its promising performance and
limitations. We also demonstrate its potential benefits for code intelligence
tasks such as zero-shot code-to-code search and text-to-code generation. Our
analysis provides insights into the learning and generalization abilities of
pre-trained models for code execution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COKE: A Cognitive Knowledge Graph for Machine Theory of Mind. (arXiv:2305.05390v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05390">
<div class="article-summary-box-inner">
<span><p>Theory of mind (ToM) refers to humans' ability to understand and infer the
desires, beliefs, and intentions of others. The acquisition of ToM plays a key
role in humans' social cognition and interpersonal relations. Though
indispensable for social intelligence, ToM is still lacking for modern AI and
NLP systems since they cannot access the human mental state and cognitive
process beneath the training corpus. To empower AI systems with the ToM ability
and narrow the gap between them and humans, in this paper, we propose COKE: the
first cognitive knowledge graph for machine theory of mind. Specifically, COKE
formalizes ToM as a collection of 45k+ manually verified cognitive chains that
characterize human mental activities and subsequent behavioral/affective
responses when facing specific social circumstances. Beyond that, we further
generalize COKE using pre-trained language models and build a powerful
cognitive generation model COKE+. Experimental results in both automatic and
human evaluation demonstrate the high quality of COKE and the superior ToM
ability of COKE+.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CaseEncoder: A Knowledge-enhanced Pre-trained Model for Legal Case Encoding. (arXiv:2305.05393v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05393">
<div class="article-summary-box-inner">
<span><p>Legal case retrieval is a critical process for modern legal information
systems. While recent studies have utilized pre-trained language models (PLMs)
based on the general domain self-supervised pre-training paradigm to build
models for legal case retrieval, there are limitations in using general domain
PLMs as backbones. Specifically, these models may not fully capture the
underlying legal features in legal case documents. To address this issue, we
propose CaseEncoder, a legal document encoder that leverages fine-grained legal
knowledge in both the data sampling and pre-training phases. In the data
sampling phase, we enhance the quality of the training data by utilizing
fine-grained law article information to guide the selection of positive and
negative examples. In the pre-training phase, we design legal-specific
pre-training tasks that align with the judging criteria of relevant legal
cases. Based on these tasks, we introduce an innovative loss function called
Biased Circle Loss to enhance the model's ability to recognize case relevance
in fine grains. Experimental results on multiple benchmarks demonstrate that
CaseEncoder significantly outperforms both existing general pre-training models
and legal-specific pre-training models in zero-shot legal case retrieval.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Consistent Text Categorization using Data Augmentation in e-Commerce. (arXiv:2305.05402v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05402">
<div class="article-summary-box-inner">
<span><p>The categorization of massive e-Commerce data is a crucial, well-studied
task, which is prevalent in industrial settings. In this work, we aim to
improve an existing product categorization model that is already in use by a
major web company, serving multiple applications. At its core, the product
categorization model is a text classification model that takes a product title
as an input and outputs the most suitable category out of thousands of
available candidates. Upon a closer inspection, we found inconsistencies in the
labeling of similar items. For example, minor modifications of the product
title pertaining to colors or measurements majorly impacted the model's output.
This phenomenon can negatively affect downstream recommendation or search
applications, leading to a sub-optimal user experience.
</p>
<p>To address this issue, we propose a new framework for consistent text
categorization. Our goal is to improve the model's consistency while
maintaining its production-level performance. We use a semi-supervised approach
for data augmentation and presents two different methods for utilizing
unlabeled samples. One method relies directly on existing catalogs, while the
other uses a generative model. We compare the pros and cons of each approach
and present our experimental results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Completeness, Recall, and Negation in Open-World Knowledge Bases: A Survey. (arXiv:2305.05403v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05403">
<div class="article-summary-box-inner">
<span><p>General-purpose knowledge bases (KBs) are a cornerstone of knowledge-centric
AI. Many of them are constructed pragmatically from Web sources, and are thus
far from complete. This poses challenges for the consumption as well as the
curation of their content. While several surveys target the problem of
completing incomplete KBs, the first problem is arguably to know whether and
where the KB is incomplete in the first place, and to which degree.
</p>
<p>In this survey we discuss how knowledge about completeness, recall, and
negation in KBs can be expressed, extracted, and inferred. We cover (i) the
logical foundations of knowledge representation and querying under partial
closed-world semantics; (ii) the estimation of this information via statistical
patterns; (iii) the extraction of information about recall from KBs and text;
(iv) the identification of interesting negative statements; and (v) relaxed
notions of relative recall.
</p>
<p>This survey is targeted at two types of audiences: (1) practitioners who are
interested in tracking KB quality, focusing extraction efforts, and building
quality-aware downstream applications; and (2) data management, knowledge base
and semantic web researchers who wish to understand the state of the art of
knowledge bases beyond the open-world assumption. Consequently, our survey
presents both fundamental methodologies and their working, and gives
practice-oriented recommendations on how to choose between different approaches
for a problem at hand.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Need Holistically Thought in Medical Conversational QA. (arXiv:2305.05410v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05410">
<div class="article-summary-box-inner">
<span><p>The medical conversational question answering (CQA) system aims at providing
a series of professional medical services to improve the efficiency of medical
care. Despite the success of large language models (LLMs) in complex reasoning
tasks in various fields, such as mathematics, logic, and commonsense QA, they
still need to improve with the increased complexity and specialization of the
medical field. This is because medical CQA tasks require not only strong
medical reasoning, but also the ability to think broadly and deeply. In this
paper, to address these challenges in medical CQA tasks that need to be
considered and understood in many aspects, we propose the Holistically Thought
(HoT) method, which is designed to guide the LLMs to perform the diffused and
focused thinking for generating high-quality medical responses. The proposed
HoT method has been evaluated through automated and manual assessments in three
different medical CQA datasets containing the English and Chinese languages.
The extensive experimental results show that our method can produce more
correctness, professional, and considerate answers than several
state-of-the-art (SOTA) methods, manifesting its effectiveness. Our code in
https://github.com/WENGSYX/HoT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Estimating related words computationally using language model from the Mahabharata -- an Indian epic. (arXiv:2305.05420v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05420">
<div class="article-summary-box-inner">
<span><p>'Mahabharata' is the most popular among many Indian pieces of literature
referred to in many domains for completely different purposes. This text itself
is having various dimension and aspects which is useful for the human being in
their personal life and professional life. This Indian Epic is originally
written in the Sanskrit Language. Now in the era of Natural Language
Processing, Artificial Intelligence, Machine Learning, and Human-Computer
interaction this text can be processed according to the domain requirement. It
is interesting to process this text and get useful insights from Mahabharata.
The limitation of the humans while analyzing Mahabharata is that they always
have a sentiment aspect towards the story narrated by the author. Apart from
that, the human cannot memorize statistical or computational details, like
which two words are frequently coming in one sentence? What is the average
length of the sentences across the whole literature? Which word is the most
popular word across the text, what are the lemmas of the words used across the
sentences? Thus, in this paper, we propose an NLP pipeline to get some
statistical and computational insights along with the most relevant word
searching method from the largest epic 'Mahabharata'. We stacked the different
text-processing approaches to articulate the best results which can be further
used in the various domain where Mahabharata needs to be referred.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WikiWeb2M: A Page-Level Multimodal Wikipedia Dataset. (arXiv:2305.05432v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05432">
<div class="article-summary-box-inner">
<span><p>Webpages have been a rich resource for language and vision-language tasks.
Yet only pieces of webpages are kept: image-caption pairs, long text articles,
or raw HTML, never all in one place. Webpage tasks have resultingly received
little attention and structured image-text data underused. To study multimodal
webpage understanding, we introduce the Wikipedia Webpage 2M (WikiWeb2M) suite;
the first to retain the full set of images, text, and structure data available
in a page. WikiWeb2M can be used for tasks like page description generation,
section summarization, and contextual image captioning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What is the best recipe for character-level encoder-only modelling?. (arXiv:2305.05461v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05461">
<div class="article-summary-box-inner">
<span><p>This paper aims to benchmark recent progress in language understanding models
that output contextualised representations at the character level. Many such
modelling architectures and methods to train those architectures have been
proposed, but it is currently unclear what the relative contributions of the
architecture vs. the pretraining objective are to final model performance. We
explore the design space of such models, comparing architectural innovations
and a variety of different pretraining objectives on a suite of evaluation
tasks with a fixed training procedure in order to find the currently optimal
way to build and train character-level BERT-like models. We find that our best
performing character-level model exceeds the performance of a token-based model
trained with the same settings on the same data, suggesting that
character-level models are ready for more widespread adoption. Unfortunately,
the best method to train character-level models still relies on a subword-level
tokeniser during pretraining, and final model performance is highly dependent
on tokeniser quality. We believe our results demonstrate the readiness of
character-level models for multilingual language representation, and encourage
NLP practitioners to try them as drop-in replacements for token-based models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Good Intentions: Reporting the Research Landscape of NLP for Social Good. (arXiv:2305.05471v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05471">
<div class="article-summary-box-inner">
<span><p>With the recent advances in natural language processing (NLP), a vast number
of applications have emerged across various use cases. Among the plethora of
NLP applications, many academic researchers are motivated to do work that has a
positive social impact, in line with the recent initiatives of NLP for Social
Good (NLP4SG). However, it is not always obvious to researchers how their
research efforts are tackling today's big social problems. Thus, in this paper,
we introduce NLP4SGPAPERS, a scientific dataset with three associated tasks
that can help identify NLP4SG papers and characterize the NLP4SG landscape by:
(1) identifying the papers that address a social problem, (2) mapping them to
the corresponding UN Sustainable Development Goals (SDGs), and (3) identifying
the task they are solving and the methods they are using. Using
state-of-the-art NLP models, we address each of these tasks and use them on the
entire ACL Anthology, resulting in a visualization workspace that gives
researchers a comprehensive overview of the field of NLP4SG. Our website is
available at https://nlp4sg.vercel.app . We released our data at
https://huggingface.co/datasets/feradauto/NLP4SGPapers and code at
https://github.com/feradauto/nlp4sg .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Going beyond research datasets: Novel intent discovery in the industry setting. (arXiv:2305.05474v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05474">
<div class="article-summary-box-inner">
<span><p>Novel intent discovery automates the process of grouping similar messages
(questions) to identify previously unknown intents. However, current research
focuses on publicly available datasets which have only the question field and
significantly differ from real-life datasets. This paper proposes methods to
improve the intent discovery pipeline deployed in a large e-commerce platform.
We show the benefit of pre-training language models on in-domain data: both
self-supervised and with weak supervision. We also devise the best method to
utilize the conversational structure (i.e., question and answer) of real-life
datasets during fine-tuning for clustering tasks, which we call Conv. All our
methods combined to fully utilize real-life datasets give up to 33pp
performance boost over state-of-the-art Constrained Deep Adaptive Clustering
(CDAC) model for question only. By comparison CDAC model for the question data
only gives only up to 13pp performance boost over the naive baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating the effect of sub-word segmentation on the performance of transformer language models. (arXiv:2305.05480v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05480">
<div class="article-summary-box-inner">
<span><p>We would like to explore how morphemes can affect the performance of a
language model. We trained GPT-2 and Bert model with StateMorph for both
Finnish and Russian, which is a morpheme segmenting algorithm. As a comparison,
we also trained a model with BPE and Morfessor. Our preliminary result shows
that StateMorph can help the model to converge more efficiently and achieve a
better validation score.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MAUPQA: Massive Automatically-created Polish Question Answering Dataset. (arXiv:2305.05486v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05486">
<div class="article-summary-box-inner">
<span><p>Recently, open-domain question answering systems have begun to rely heavily
on annotated datasets to train neural passage retrievers. However, manually
annotating such datasets is both difficult and time-consuming, which limits
their availability for less popular languages. In this work, we experiment with
several methods for automatically collecting weakly labeled datasets and show
how they affect the performance of the neural passage retrieval models. As a
result of our work, we publish the MAUPQA dataset, consisting of nearly 400,000
question-passage pairs for Polish, as well as the HerBERT-QA neural retriever.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploiting Pseudo Image Captions for Multimodal Summarization. (arXiv:2305.05496v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05496">
<div class="article-summary-box-inner">
<span><p>Cross-modal contrastive learning in vision language pretraining (VLP) faces
the challenge of (partial) false negatives. In this paper, we study this
problem from the perspective of Mutual Information (MI) optimization. It is
common sense that InfoNCE loss used in contrastive learning will maximize the
lower bound of MI between anchors and their positives, while we theoretically
prove that MI involving negatives also matters when noises commonly exist.
Guided by a more general lower bound form for optimization, we propose a
contrastive learning strategy regulated by progressively refined cross-modal
similarity, to more accurately optimize MI between an image/text anchor and its
negative texts/images instead of improperly minimizing it. Our method performs
competitively on four downstream cross-modal tasks and systematically balances
the beneficial and harmful effects of (partial) false negative samples under
theoretical guidance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Humanize Technology. (arXiv:2305.05576v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05576">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have made rapid progress in recent months and
weeks, garnering significant public attention. This has sparked concerns about
aligning these models with human values, their impact on labor markets, and the
potential need for regulation in further research and development. However, the
discourse often lacks a focus on the imperative to widely diffuse the societal
benefits of LLMs. To qualify this societal benefit, we assert that LLMs exhibit
emergent abilities to humanize technology more effectively than previous
technologies, and for people across language, occupation, and accessibility
divides. We argue that they do so by addressing three mechanizing bottlenecks
in today's computing technologies: creating diverse and accessible content,
learning complex digital tools, and personalizing machine learning algorithms.
We adopt a case-based approach and illustrate each bottleneck with two examples
where current technology imposes bottlenecks that LLMs demonstrate the ability
to address. Given this opportunity to humanize technology widely, we advocate
for more widespread understanding of LLMs, tools and methods to simplify use of
LLMs, and cross-cutting institutional capacity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StrAE: Autoencoding for Pre-Trained Embeddings using Explicit Structure. (arXiv:2305.05588v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05588">
<div class="article-summary-box-inner">
<span><p>This work explores the utility of explicit structure for representation
learning in NLP by developing StrAE -- an autoencoding framework that
faithfully leverages sentence structure to learn multi-level node embeddings in
an unsupervised fashion. We use StrAE to train models across different types of
sentential structure and objectives, including a novel contrastive loss over
structure, and evaluate the learnt embeddings on a series of both intrinsic and
extrinsic tasks. Our experiments indicate that leveraging explicit structure
through StrAE leads to improved embeddings over prior work, and that our novel
contrastive objective over structure outperforms the standard cross-entropy
objective. Moreover, in contrast to findings from prior work that weakly
leverages structure, we find that being completely faithful to structure does
enable disambiguation between types of structure based on the corresponding
model's performance. As further evidence of StrAE's utility, we develop a
simple proof-of-concept approach to simultaneously induce structure while
learning embeddings, rather than being given structure, and find that
performance is comparable to that of the best-performing models where structure
is given. Finally, we contextualise these results by comparing StrAE against
standard unstructured baselines learnt in similar settings, and show that
faithfully leveraging explicit structure can be beneficial in lexical and
sentence-level semantics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DomainInv: Domain Invariant Fine Tuning and Adversarial Label Correction For QA Domain Adaptation. (arXiv:2305.05589v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05589">
<div class="article-summary-box-inner">
<span><p>Existing Question Answering (QA) systems limited by the capability of
answering questions from unseen domain or any out-of-domain distributions
making them less reliable for deployment to real scenarios. Most importantly
all the existing QA domain adaptation methods are either based on generating
synthetic data or pseudo labeling the target domain data. The domain adaptation
methods based on synthetic data and pseudo labeling suffers either from the
requirement of computational resources or an extra overhead of carefully
selecting the confidence threshold to separate the noisy examples from being in
the training dataset. In this paper, we propose the unsupervised domain
adaptation for unlabeled target domain by transferring the target
representation near to source domain while still using the supervision from
source domain. Towards that we proposed the idea of domain invariant fine
tuning along with adversarial label correction to identify the target instances
which lie far apart from the source domain, so that the feature encoder can be
learnt to minimize the distance between such target instances and source
instances class wisely, removing the possibility of learning the features of
target domain which are still near to source support but are ambiguous.
Evaluation of our QA domain adaptation method namely, DomainInv on multiple
target QA dataset reveal the performance improvement over the strongest
baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Case Records of ChatGPT: Language Models and Complex Clinical Questions. (arXiv:2305.05609v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05609">
<div class="article-summary-box-inner">
<span><p>Background: Artificial intelligence language models have shown promise in
various applications, including assisting with clinical decision-making as
demonstrated by strong performance of large language models on medical
licensure exams. However, their ability to solve complex, open-ended cases,
which may be representative of clinical practice, remains unexplored. Methods:
In this study, the accuracy of large language AI models GPT4 and GPT3.5 in
diagnosing complex clinical cases was investigated using published Case Records
of the Massachusetts General Hospital. A total of 50 cases requiring a
diagnosis and diagnostic test published from January 1, 2022 to April 16, 2022
were identified. For each case, models were given a prompt requesting the top
three specific diagnoses and associated diagnostic tests, followed by case
text, labs, and figure legends. Model outputs were assessed in comparison to
the final clinical diagnosis and whether the model-predicted test would result
in a correct diagnosis. Results: GPT4 and GPT3.5 accurately provided the
correct diagnosis in 26% and 22% of cases in one attempt, and 46% and 42%
within three attempts, respectively. GPT4 and GPT3.5 provided a correct
essential diagnostic test in 28% and 24% of cases in one attempt, and 44% and
50% within three attempts, respectively. No significant differences were found
between the two models, and multiple trials with identical prompts using the
GPT3.5 model provided similar results. Conclusions: In summary, these models
demonstrate potential usefulness in generating differential diagnoses but
remain limited in their ability to provide a single unifying diagnosis in
complex, open-ended cases. Future research should focus on evaluating model
performance in larger datasets of open-ended clinical challenges and exploring
potential human-AI collaboration strategies to enhance clinical
decision-making.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Exploration of Encoder-Decoder Approaches to Multi-Label Classification for Legal and Biomedical Text. (arXiv:2305.05627v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05627">
<div class="article-summary-box-inner">
<span><p>Standard methods for multi-label text classification largely rely on
encoder-only pre-trained language models, whereas encoder-decoder models have
proven more effective in other classification tasks. In this study, we compare
four methods for multi-label classification, two based on an encoder only, and
two based on an encoder-decoder. We carry out experiments on four datasets --
two in the legal domain and two in the biomedical domain, each with two levels
of label granularity -- and always depart from the same pre-trained model, T5.
Our results show that encoder-decoder methods outperform encoder-only methods,
with a growing advantage on more complex datasets and labeling schemes of finer
granularity. Using encoder-decoder models in a non-autoregressive fashion, in
particular, yields the best performance overall, so we further study this
approach through ablations to better understand its strengths.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Representation Learning for Person or Entity-centric Knowledge Graphs: an application in Healthcare. (arXiv:2305.05640v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05640">
<div class="article-summary-box-inner">
<span><p>Knowledge graphs (KGs) are a popular way to organise information based on
ontologies or schemas and have been used across a variety of scenarios from
search to recommendation. Despite advances in KGs, representing knowledge
remains a non-trivial task across industries and it is especially challenging
in the biomedical and healthcare domains due to complex interdependent
relations between entities, heterogeneity, lack of standardization, and
sparseness of data. KGs are used to discover diagnoses or prioritize genes
relevant to disease, but they often rely on schemas that are not centred around
a node or entity of interest, such as a person. Entity-centric KGs are
relatively unexplored but hold promise in representing important facets
connected to a central node and unlocking downstream tasks beyond graph
traversal and reasoning, such as generating graph embeddings and training graph
neural networks for a wide range of predictive tasks. This paper presents an
end-to-end representation learning framework to extract entity-centric KGs from
structured and unstructured data. We introduce a star-shaped ontology to
represent the multiple facets of a person and use it to guide KG creation.
Compact representations of the graphs are created leveraging graph neural
networks and experiments are conducted using different levels of heterogeneity
or explicitness. A readmission prediction task is used to evaluate the results
of the proposed framework, showing a stable system, robust to missing data,
that outperforms a range of baseline machine learning classifiers. We highlight
that this approach has several potential applications across domains and is
open-sourced. Lastly, we discuss lessons learned, challenges, and next steps
for the adoption of the framework in practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Building the Federated GPT: Federated Instruction Tuning. (arXiv:2305.05644v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05644">
<div class="article-summary-box-inner">
<span><p>While ``instruction-tuned" generative large language models (LLMs) have
demonstrated an impressive ability to generalize to new tasks, the training
phases heavily rely on large amounts of diverse and high-quality instruction
data (such as ChatGPT and GPT-4). Unfortunately, acquiring high-quality data,
especially when it comes to human-written data, can pose significant challenges
both in terms of cost and accessibility. Moreover, concerns related to privacy
can further limit access to such data, making the process of obtaining it a
complex and nuanced undertaking. Consequently, this hinders the generality of
the tuned models and may restrict their effectiveness in certain contexts. To
tackle this issue, our study introduces a new approach called Federated
Instruction Tuning (FedIT), which leverages federated learning (FL) as the
learning framework for the instruction tuning of LLMs. This marks the first
exploration of FL-based instruction tuning for LLMs. This is especially
important since text data is predominantly generated by end users. Therefore,
it is imperative to design and adapt FL approaches to effectively leverage
these users' diverse instructions stored on local devices, while preserving
privacy and ensuring data security. In the current paper, by conducting widely
used GPT-4 auto-evaluation, we demonstrate that by exploiting the heterogeneous
and diverse sets of instructions on the client's end with the proposed
framework FedIT, we improved the performance of LLMs compared to centralized
training with only limited local instructions. Further, in this paper, we
developed a Github repository named Shepherd. This repository offers a
foundational framework for exploring federated fine-tuning of LLMs using
heterogeneous instructions across diverse categories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TidyBot: Personalized Robot Assistance with Large Language Models. (arXiv:2305.05658v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05658">
<div class="article-summary-box-inner">
<span><p>For a robot to personalize physical assistance effectively, it must learn
user preferences that can be generally reapplied to future scenarios. In this
work, we investigate personalization of household cleanup with robots that can
tidy up rooms by picking up objects and putting them away. A key challenge is
determining the proper place to put each object, as people's preferences can
vary greatly depending on personal taste or cultural background. For instance,
one person may prefer storing shirts in the drawer, while another may prefer
them on the shelf. We aim to build systems that can learn such preferences from
just a handful of examples via prior interactions with a particular person. We
show that robots can combine language-based planning and perception with the
few-shot summarization capabilities of large language models (LLMs) to infer
generalized user preferences that are broadly applicable to future
interactions. This approach enables fast adaptation and achieves 91.2% accuracy
on unseen objects in our benchmark dataset. We also demonstrate our approach on
a real-world mobile manipulator called TidyBot, which successfully puts away
85.0% of objects in real-world test scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A transfer learning based approach for pronunciation scoring. (arXiv:2111.00976v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00976">
<div class="article-summary-box-inner">
<span><p>Phone-level pronunciation scoring is a challenging task, with performance far
from that of human annotators. Standard systems generate a score for each phone
in a phrase using models trained for automatic speech recognition (ASR) with
native data only. Better performance has been shown when using systems that are
trained specifically for the task using non-native data. Yet, such systems face
the challenge that datasets labelled for this task are scarce and usually
small. In this paper, we present a transfer learning-based approach that
leverages a model trained for ASR, adapting it for the task of pronunciation
scoring. We analyze the effect of several design choices and compare the
performance with a state-of-the-art goodness of pronunciation (GOP) system. Our
final system is 20% better than the GOP system on EpaDB, a database for
pronunciation scoring research, for a cost function that prioritizes low rates
of unnecessary corrections.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vector Space Semantics for Lambek Calculus with Soft Subexponentials. (arXiv:2111.11331v2 [cs.LO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.11331">
<div class="article-summary-box-inner">
<span><p>We develop a vector space semantics for Lambek Calculus with Soft
Subexponentials, apply the calculus to construct compositional vector
interpretations for parasitic gap noun phrases and discourse units with
anaphora and ellipsis, and experiment with the constructions in a
distributional sentence similarity task. As opposed to previous work, which
used Lambek Calculus with a Relevant Modality the calculus used in this paper
uses a bounded version of the modality and is decidable. The vector space
semantics of this new modality allows us to meaningfully define contraction as
projection and provide a linear theory behind what we could previously only
achieve via nonlinear maps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERT WEAVER: Using WEight AVERaging to Enable Lifelong Learning for Transformer-based Models in the Biomedical Domain. (arXiv:2202.10101v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10101">
<div class="article-summary-box-inner">
<span><p>Recent developments in transfer learning have boosted the advancements in
natural language processing tasks. The performance is, however, dependent on
high-quality, manually annotated training data. Especially in the biomedical
domain, it has been shown that one training corpus is not enough to learn
generic models that are able to efficiently predict on new data. Therefore,
state-of-the-art models need the ability of lifelong learning in order to
improve performance as soon as new data are available - without the need of
re-training the whole model from scratch. We present WEAVER, a simple, yet
efficient post-processing method that infuses old knowledge into the new model,
thereby reducing catastrophic forgetting. We show that applying WEAVER in a
sequential manner results in similar word embedding distributions as doing a
combined training on all data at once, while being computationally more
efficient. Because there is no need of data sharing, the presented method is
also easily applicable to federated learning settings and can for example be
beneficial for the mining of electronic health records from different clinics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multimodal Transformer: Fusing Clinical Notes with Structured EHR Data for Interpretable In-Hospital Mortality Prediction. (arXiv:2208.10240v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.10240">
<div class="article-summary-box-inner">
<span><p>Deep-learning-based clinical decision support using structured electronic
health records (EHR) has been an active research area for predicting risks of
mortality and diseases. Meanwhile, large amounts of narrative clinical notes
provide complementary information, but are often not integrated into predictive
models. In this paper, we provide a novel multimodal transformer to fuse
clinical notes and structured EHR data for better prediction of in-hospital
mortality. To improve interpretability, we propose an integrated gradients (IG)
method to select important words in clinical notes and discover the critical
structured EHR features with Shapley values. These important words and clinical
features are visualized to assist with interpretation of the prediction
outcomes. We also investigate the significance of domain adaptive pretraining
and task adaptive fine-tuning on the Clinical BERT, which is used to learn the
representations of clinical notes. Experiments demonstrated that our model
outperforms other methods (AUCPR: 0.538, AUCROC: 0.877, F1:0.490).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Reality and the Limits of Language Data: Aligning LLMs with Human Norms. (arXiv:2208.11981v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.11981">
<div class="article-summary-box-inner">
<span><p>Recent advancements in Large Language Models (LLMs) harness linguistic
associations in vast natural language data for practical applications. However,
their ability to understand the physical world using only language data remains
a question. After reviewing existing protocols, we explore this question using
a novel and tightly controlled reasoning test (ART) and compare human norms
against versions of GPT-3. Our findings highlight the categories of
common-sense relations models that could learn directly from data and areas of
weakness. GPT-3 offers evidence for verbal reasoning on a par with human
subjects for several relations including Synonymy, Antonymy, and Default
inheritance, Without reinforcement learning from human judgements, it appears
GPT-3 performs at the lower end of the reference interval for Has-part and
Contained-in. Weaknesses were observed also in affordance characteristics
through Necessary-quality, Order-of-size and Order-of-intensity. Combining LLMs
with symbolic world grounding is a promising direction to address associative
learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cold-Start Data Selection for Few-shot Language Model Fine-tuning: A Prompt-Based Uncertainty Propagation Approach. (arXiv:2209.06995v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.06995">
<div class="article-summary-box-inner">
<span><p>Large Language Models have demonstrated remarkable few-shot performance, but
the performance can be sensitive to the selection of few-shot instances. We
propose PATRON, a new method that uses prompt-based uncertainty estimation for
data selection for pre-trained language model fine-tuning under cold-start
scenarios, i.e., no initial labeled data are available. In PATRON, we design
(1) a prompt-based uncertainty propagation approach to estimate the importance
of data points and (2) a partition-then-rewrite (PTR) strategy to promote
sample diversity when querying for annotations. Experiments on six text
classification datasets show that PATRON outperforms the strongest cold-start
data selection baselines by up to 6.9%. Besides, with 128 labels only, PATRON
achieves 91.0% and 92.1% of the fully supervised performance based on vanilla
fine-tuning and prompt-based learning respectively. Our implementation of
PATRON is available at \url{https://github.com/yueyu1030/Patron}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Span Representations for Named Entity Recognition. (arXiv:2210.04182v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04182">
<div class="article-summary-box-inner">
<span><p>Span-based models are one of the most straightforward methods for named
entity recognition (NER). Existing span-based NER systems shallowly aggregate
the token representations to span representations. However, this typically
results in significant ineffectiveness for long-span entities, a coupling
between the representations of overlapping spans, and ultimately a performance
degradation. In this study, we propose DSpERT (Deep Span Encoder
Representations from Transformers), which comprises a standard Transformer and
a span Transformer. The latter uses low-layered span representations as
queries, and aggregates the token representations as keys and values, layer by
layer from bottom to top. Thus, DSpERT produces span representations of deep
semantics.
</p>
<p>With weight initialization from pretrained language models, DSpERT achieves
performance higher than or competitive with recent state-of-the-art systems on
eight NER benchmarks. Experimental results verify the importance of the depth
for span representations, and show that DSpERT performs particularly well on
long-span entities and nested structures. Further, the deep span
representations are well structured and easily separable in the feature space.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Agnostic Multilingual Information Retrieval with Contrastive Learning. (arXiv:2210.06633v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06633">
<div class="article-summary-box-inner">
<span><p>Multilingual information retrieval (IR) is challenging since annotated
training data is costly to obtain in many languages. We present an effective
method to train multilingual IR systems when only English IR training data and
some parallel corpora between English and other languages are available. We
leverage parallel and non-parallel corpora to improve the pretrained
multilingual language models' cross-lingual transfer ability. We design a
semantic contrastive loss to align representations of parallel sentences that
share the same semantics in different languages, and a new language contrastive
loss to leverage parallel sentence pairs to remove language-specific
information in sentence representations from non-parallel corpora. When trained
on English IR data with these losses and evaluated zero-shot on non-English
data, our model demonstrates significant improvement to prior work on retrieval
performance, while it requires much less computational effort. We also
demonstrate the value of our model for a practical setting when a parallel
corpus is only available for a few languages, but a lack of parallel corpora
resources persists for many other low-resource languages. Our model can work
well even with a small number of parallel sentences, and be used as an add-on
module to any backbones and other tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Demographic Factors Improve Text Classification? Revisiting Demographic Adaptation in the Age of Transformers. (arXiv:2210.07362v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07362">
<div class="article-summary-box-inner">
<span><p>Demographic factors (e.g., gender or age) shape our language. Previous work
showed that incorporating demographic factors can consistently improve
performance for various NLP tasks with traditional NLP models. In this work, we
investigate whether these previous findings still hold with state-of-the-art
pretrained Transformer-based language models (PLMs). We use three common
specialization methods proven effective for incorporating external knowledge
into pretrained Transformers (e.g., domain-specific or geographic knowledge).
We adapt the language representations for the demographic dimensions of gender
and age, using continuous language modeling and dynamic multi-task learning for
adaptation, where we couple language modeling objectives with the prediction of
demographic classes. Our results, when employing a multilingual PLM, show
substantial gains in task performance across four languages (English, German,
French, and Danish), which is consistent with the results of previous work.
However, controlling for confounding factors - primarily domain and language
proficiency of Transformer-based PLMs - shows that downstream performance gains
from our demographic adaptation do not actually stem from demographic
knowledge. Our results indicate that demographic specialization of PLMs, while
holding promise for positive societal impact, still represents an unsolved
problem for (modern) NLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Learning for Analyzing Political Campaigns on Facebook. (arXiv:2210.10669v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10669">
<div class="article-summary-box-inner">
<span><p>Social media platforms are currently the main channel for political
messaging, allowing politicians to target specific demographics and adapt based
on their reactions. However, making this communication transparent is
challenging, as the messaging is tightly coupled with its intended audience and
often echoed by multiple stakeholders interested in advancing specific
policies. Our goal in this paper is to take a first step towards understanding
these highly decentralized settings. We propose a weakly supervised approach to
identify the stance and issue of political ads on Facebook and analyze how
political campaigns use some kind of demographic targeting by location, gender,
or age. Furthermore, we analyze the temporal dynamics of the political ads on
election polls.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Once-for-All Sequence Compression for Self-Supervised Speech Models. (arXiv:2211.02332v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.02332">
<div class="article-summary-box-inner">
<span><p>The sequence length along the time axis is often the dominant factor of the
computation in speech processing. Works have been proposed to reduce the
sequence length for lowering the computational cost in self-supervised speech
models. However, different downstream tasks have different tolerance of
sequence compressing, so a model that produces a fixed compressing rate may not
fit all tasks. In this work, we introduce a once-for-all (OFA) sequence
compression framework for self-supervised speech models that supports a
continuous range of operating compressing rates. The framework is evaluated on
various tasks, showing marginal degradation compared to the fixed compressing
rate variants with a smooth performance-efficiency trade-off. We further
explore adaptive compressing rate learning, demonstrating the ability to select
task-specific preferred frame periods without needing a grid search.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Global and Local Hierarchy-aware Contrastive Framework for Implicit Discourse Relation Recognition. (arXiv:2211.13873v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.13873">
<div class="article-summary-box-inner">
<span><p>Due to the absence of explicit connectives, implicit discourse relation
recognition (IDRR) remains a challenging task in discourse analysis. The
critical step for IDRR is to learn high-quality discourse relation
representations between two arguments. Recent methods tend to integrate the
whole hierarchical information of senses into discourse relation
representations for multi-level sense recognition. Nevertheless, they
insufficiently incorporate the static hierarchical structure containing all
senses (defined as global hierarchy), and ignore the hierarchical sense label
sequence corresponding to each instance (defined as local hierarchy). For the
purpose of sufficiently exploiting global and local hierarchies of senses to
learn better discourse relation representations, we propose a novel GlObal and
Local Hierarchy-aware Contrastive Framework (GOLF), to model two kinds of
hierarchies with the aid of multi-task learning and contrastive learning.
Experimental results on PDTB 2.0 and PDTB 3.0 datasets demonstrate that our
method remarkably outperforms current state-of-the-art models at all
hierarchical levels. Our code is publicly available at
https://github.com/YJiangcm/GOLF_for_IDRR
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Validating Large Language Models with ReLM. (arXiv:2211.15458v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.15458">
<div class="article-summary-box-inner">
<span><p>Although large language models (LLMs) have been touted for their ability to
generate natural-sounding text, there are growing concerns around possible
negative effects of LLMs such as data memorization, bias, and inappropriate
language. Unfortunately, the complexity and generation capacities of LLMs make
validating (and correcting) such concerns difficult. In this work, we introduce
ReLM, a system for validating and querying LLMs using standard regular
expressions. ReLM formalizes and enables a broad range of language model
evaluations, reducing complex evaluation rules to simple regular expression
queries. Our results exploring queries surrounding memorization, gender bias,
toxicity, and language understanding show that ReLM achieves up to 15x higher
system efficiency, 2.5x data efficiency, and increased statistical and
prompt-tuning coverage compared to state-of-the-art ad-hoc queries. ReLM offers
a competitive and general baseline for the increasingly important problem of
LLM validation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GanLM: Encoder-Decoder Pre-training with an Auxiliary Discriminator. (arXiv:2212.10218v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10218">
<div class="article-summary-box-inner">
<span><p>Pre-trained models have achieved remarkable success in natural language
processing (NLP). However, existing pre-training methods underutilize the
benefits of language understanding for generation. Inspired by the idea of
Generative Adversarial Networks (GANs), we propose a GAN-style model for
encoder-decoder pre-training by introducing an auxiliary discriminator,
unifying the ability of language understanding and generation in a single
model. Our model, named as GanLM, is trained with two pre-training objectives:
replaced token detection and replaced token denoising. Specifically, given
masked source sentences, the generator outputs the target distribution and the
discriminator predicts whether the target sampled tokens from distribution are
incorrect. The target sentence is replaced with misclassified tokens to
construct noisy previous context, which is used to generate the gold sentence.
In general, both tasks improve the ability of language understanding and
generation by selectively using the denoising data. Extensive experiments in
language generation benchmarks show that GanLM with the powerful language
understanding capability outperforms various strong pre-trained language models
(PLMs) and achieves state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SeqDiffuSeq: Text Diffusion with Encoder-Decoder Transformers. (arXiv:2212.10325v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10325">
<div class="article-summary-box-inner">
<span><p>Diffusion model, a new generative modelling paradigm, has achieved great
success in image, audio, and video generation. However, considering the
discrete categorical nature of text, it is not trivial to extend continuous
diffusion models to natural language, and text diffusion models are less
studied. Sequence-to-sequence text generation is one of the essential natural
language processing topics. In this work, we apply diffusion models to approach
sequence-to-sequence text generation, and explore whether the superiority
generation performance of diffusion model can transfer to natural language
domain. We propose SeqDiffuSeq, a text diffusion model for sequence-to-sequence
generation. SeqDiffuSeq uses an encoder-decoder Transformers architecture to
model denoising function. In order to improve generation quality, SeqDiffuSeq
combines the self-conditioning technique and a newly proposed adaptive noise
schedule technique. The adaptive noise schedule has the difficulty of denoising
evenly distributed across time steps, and considers exclusive noise schedules
for tokens at different positional order. Experiment results illustrate the
good performance on sequence-to-sequence generation in terms of text quality
and inference time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pretraining Without Attention. (arXiv:2212.10544v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10544">
<div class="article-summary-box-inner">
<span><p>Transformers have been essential to pretraining success in NLP. While other
architectures have been used, downstream accuracy is either significantly
worse, or requires attention layers to match standard benchmarks such as GLUE.
This work explores pretraining without attention by using recent advances in
sequence routing based on state-space models (SSMs). Our proposed model,
Bidirectional Gated SSM (BiGS), combines SSM layers with a multiplicative
gating architecture that has been effective in simplified sequence modeling
architectures. The model learns static layers that do not consider pair-wise
interactions. Even so, BiGS is able to match BERT pretraining accuracy on GLUE
and can be extended to long-form pretraining of 4096 tokens without
approximation. Analysis shows that while the models have similar average
accuracy, the approach has different inductive biases than BERT in terms of
interactions and syntactic representations. All models from this work are
available at https://github.com/jxiw/BiGS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Machine Translation with Large Language Models. (arXiv:2301.13294v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.13294">
<div class="article-summary-box-inner">
<span><p>Consistency is a key requirement of high-quality translation. It is
especially important to adhere to pre-approved terminology and adapt to
corrected translations in domain-specific projects. Machine translation (MT)
has achieved significant progress in the area of domain adaptation. However,
real-time adaptation remains challenging. Large-scale language models (LLMs)
have recently shown interesting capabilities of in-context learning, where they
learn to replicate certain input-output text generation patterns, without
further fine-tuning. By feeding an LLM at inference time with a prompt that
consists of a list of translation pairs, it can then simulate the domain and
style characteristics. This work aims to investigate how we can utilize
in-context learning to improve real-time adaptive MT. Our extensive experiments
show promising results at translation time. For example, LLMs can adapt to a
set of in-domain sentence pairs and/or terminology while translating a new
sentence. We observe that the translation quality with few-shot in-context
learning can surpass that of strong encoder-decoder MT systems, especially for
high-resource languages. Moreover, we investigate whether we can combine MT
from strong encoder-decoder models with fuzzy matches, which can further
improve translation quality, especially for less supported languages. We
conduct our experiments across five diverse language pairs, namely
English-to-Arabic (EN-AR), English-to-Chinese (EN-ZH), English-to-French
(EN-FR), English-to-Kinyarwanda (EN-RW), and English-to-Spanish (EN-ES).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Creating a Large Language Model of a Philosopher. (arXiv:2302.01339v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01339">
<div class="article-summary-box-inner">
<span><p>Can large language models be trained to produce philosophical texts that are
difficult to distinguish from texts produced by human philosophers? To address
this question, we fine-tuned OpenAI's GPT-3 with the works of philosopher
Daniel C. Dennett as additional training data. To explore the Dennett model, we
asked the real Dennett ten philosophical questions and then posed the same
questions to the language model, collecting four responses for each question
without cherry-picking. We recruited 425 participants to distinguish Dennett's
answer from the four machine-generated answers. Experts on Dennett's work (N =
25) succeeded 51% of the time, above the chance rate of 20% but short of our
hypothesized rate of 80% correct. For two of the ten questions, the language
model produced at least one answer that experts selected more frequently than
Dennett's own answer. Philosophy blog readers (N = 302) performed similarly to
the experts, while ordinary research participants (N = 98) were near chance
distinguishing GPT-3's responses from those of an "actual human philosopher".
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distinguishability Calibration to In-Context Learning. (arXiv:2302.06198v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.06198">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed increasing interests in prompt-based learning in
which models can be trained on only a few annotated instances, making them
suitable in low-resource settings. When using prompt-based learning for text
classification, the goal is to use a pre-trained language model (PLM) to
predict a missing token in a pre-defined template given an input text, which
can be mapped to a class label. However, PLMs built on the transformer
architecture tend to generate similar output embeddings, making it difficult to
discriminate between different class labels. The problem is further exacerbated
when dealing with classification tasks involving many fine-grained class
labels. In this work, we alleviate this information diffusion issue, i.e.,
different tokens share a large proportion of similar information after going
through stacked multiple self-attention layers in a transformer, by proposing a
calibration method built on feature transformations through rotation and
scaling to map a PLM-encoded embedding into a new metric space to guarantee the
distinguishability of the resulting embeddings. Furthermore, we take the
advantage of hyperbolic embeddings to capture the hierarchical relations among
fine-grained class-associated token embedding by a coarse-to-fine metric
learning strategy to enhance the distinguishability of the learned output
embeddings. Extensive experiments on the three datasets under various settings
demonstrate the effectiveness of our approach. Our code can be found at
https://github.com/donttal/TARA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Symbolic Discovery of Optimization Algorithms. (arXiv:2302.06675v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.06675">
<div class="article-summary-box-inner">
<span><p>We present a method to formulate algorithm discovery as program search, and
apply it to discover optimization algorithms for deep neural network training.
We leverage efficient search techniques to explore an infinite and sparse
program space. To bridge the large generalization gap between proxy and target
tasks, we also introduce program selection and simplification strategies. Our
method discovers a simple and effective optimization algorithm, $\textbf{Lion}$
($\textit{Evo$\textbf{L}$ved S$\textbf{i}$gn M$\textbf{o}$me$\textbf{n}$tum}$).
It is more memory-efficient than Adam as it only keeps track of the momentum.
Different from adaptive optimizers, its update has the same magnitude for each
parameter calculated through the sign operation. We compare Lion with widely
used optimizers, such as Adam and Adafactor, for training a variety of models
on different tasks. On image classification, Lion boosts the accuracy of ViT by
up to 2% on ImageNet and saves up to 5x the pre-training compute on JFT. On
vision-language contrastive learning, we achieve 88.3% $\textit{zero-shot}$ and
91.1% $\textit{fine-tuning}$ accuracy on ImageNet, surpassing the previous best
results by 2% and 0.1%, respectively. On diffusion models, Lion outperforms
Adam by achieving a better FID score and reducing the training compute by up to
2.3x. For autoregressive, masked language modeling, and fine-tuning, Lion
exhibits a similar or better performance compared to Adam. Our analysis of Lion
reveals that its performance gain grows with the training batch size. It also
requires a smaller learning rate than Adam due to the larger norm of the update
produced by the sign function. Additionally, we examine the limitations of Lion
and identify scenarios where its improvements are small or not statistically
significant. Lion is also successfully deployed in production systems such as
Google search ads CTR model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating the Translation Performance of a Large Multilingual Language Model: the Case of BLOOM. (arXiv:2303.01911v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01911">
<div class="article-summary-box-inner">
<span><p>The NLP community recently saw the release of a new large open-access
multilingual language model, BLOOM (BigScience et al., 2022) covering 46
languages. We focus on BLOOM's multilingual ability by evaluating its machine
translation performance across several datasets (WMT, Flores-101 and DiaBLa)
and language pairs (high- and low-resourced). Our results show that 0-shot
performance suffers from overgeneration and generating in the wrong language,
but this is greatly improved in the few-shot setting, with very good results
for a number of language pairs. We study several aspects including prompt
design, model sizes, cross-lingual transfer and the use of discursive context.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cascading and Direct Approaches to Unsupervised Constituency Parsing on Spoken Sentences. (arXiv:2303.08809v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08809">
<div class="article-summary-box-inner">
<span><p>Past work on unsupervised parsing is constrained to written form. In this
paper, we present the first study on unsupervised spoken constituency parsing
given unlabeled spoken sentences and unpaired textual data. The goal is to
determine the spoken sentences' hierarchical syntactic structure in the form of
constituency parse trees, such that each node is a span of audio that
corresponds to a constituent. We compare two approaches: (1) cascading an
unsupervised automatic speech recognition (ASR) model and an unsupervised
parser to obtain parse trees on ASR transcripts, and (2) direct training an
unsupervised parser on continuous word-level speech representations. This is
done by first splitting utterances into sequences of word-level segments, and
aggregating self-supervised speech representations within segments to obtain
segment embeddings. We find that separately training a parser on the unpaired
text and directly applying it on ASR transcripts for inference produces better
results for unsupervised parsing. Additionally, our results suggest that
accurate segmentation alone may be sufficient to parse spoken sentences
accurately. Finally, we show the direct approach may learn head-directionality
correctly for both head-initial and head-final languages without any explicit
inductive bias.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SheffieldVeraAI at SemEval-2023 Task 3: Mono and multilingual approaches for news genre, topic and persuasion technique classification. (arXiv:2303.09421v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09421">
<div class="article-summary-box-inner">
<span><p>This paper describes our approach for SemEval-2023 Task 3: Detecting the
category, the framing, and the persuasion techniques in online news in a
multi-lingual setup. For Subtask 1 (News Genre), we propose an ensemble of
fully trained and adapter mBERT models which was ranked joint-first for German,
and had the highest mean rank of multi-language teams. For Subtask 2 (Framing),
we achieved first place in 3 languages, and the best average rank across all
the languages, by using two separate ensembles: a monolingual
RoBERTa-MUPPETLARGE and an ensemble of XLM-RoBERTaLARGE with adapters and task
adaptive pretraining. For Subtask 3 (Persuasion Techniques), we train a
monolingual RoBERTa-Base model for English and a multilingual mBERT model for
the remaining languages, which achieved top 10 for all languages, including 2nd
for English. For each subtask, we compared monolingual and multilingual
approaches, and considered class imbalance techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BloombergGPT: A Large Language Model for Finance. (arXiv:2303.17564v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17564">
<div class="article-summary-box-inner">
<span><p>The use of NLP in the realm of financial technology is broad and complex,
with applications ranging from sentiment analysis and named entity recognition
to question answering. Large Language Models (LLMs) have been shown to be
effective on a variety of tasks; however, no LLM specialized for the financial
domain has been reported in literature. In this work, we present BloombergGPT,
a 50 billion parameter language model that is trained on a wide range of
financial data. We construct a 363 billion token dataset based on Bloomberg's
extensive data sources, perhaps the largest domain-specific dataset yet,
augmented with 345 billion tokens from general purpose datasets. We validate
BloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suite
of internal benchmarks that most accurately reflect our intended usage. Our
mixed dataset training leads to a model that outperforms existing models on
financial tasks by significant margins without sacrificing performance on
general LLM benchmarks. Additionally, we explain our modeling choices, training
process, and evaluation methodology. We release Training Chronicles (Appendix
C) detailing our experience in training BloombergGPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ParroT: Translating During Chat Using Large Language Models. (arXiv:2304.02426v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.02426">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) like ChatGPT and GPT-4 have exhibited remarkable
abilities on a wide range of natural language processing (NLP) tasks, including
various machine translation abilities accomplished during chat. However, these
models are only accessible through restricted APIs, which creates barriers to
new research and advancements in the field. Therefore, we propose the
$\mathbf{ParroT}$ framework to enhance and regulate the translation abilities
during chat based on open-sourced LLMs (i.e., LLaMA-7b, BLOOMZ-7b-mt) and human
written translation and evaluation data. Specifically, ParroT reformulates
translation data into the instruction-following style, and introduces a
"$\mathbf{Hint}$" field for incorporating extra requirements to regulate the
translation process. Accordingly, we propose three instruction types for
finetuning ParroT models, including translation instruction, contrastive
instruction, and error-guided instruction. We can finetune either the full
models or partial parameters via low rank adaptation (LoRA). Experiments on
Flores subsets and WMT22 test sets suggest that translation instruction
improves the translation performance of vanilla LLMs significantly while
error-guided instruction can lead to a further improvement, which demonstrates
the importance of learning from low-quality translations annotated by human.
Meanwhile, the ParroT models can also preserve the ability on general tasks
with the Alpaca multi-task dataset involved in finetuning. Please refer to our
Github project for more implementation details:
https://github.com/wxjiao/ParroT
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tailoring Domain Adaptation for Machine Translation Quality Estimation. (arXiv:2304.08891v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.08891">
<div class="article-summary-box-inner">
<span><p>While quality estimation (QE) can play an important role in the translation
process, its effectiveness relies on the availability and quality of training
data. For QE in particular, high-quality labeled data is often lacking due to
the high cost and effort associated with labeling such data. Aside from the
data scarcity challenge, QE models should also be generalizable, i.e., they
should be able to handle data from different domains, both generic and
specific. To alleviate these two main issues -- data scarcity and domain
mismatch -- this paper combines domain adaptation and data augmentation within
a robust QE system. Our method first trains a generic QE model and then
fine-tunes it on a specific domain while retaining generic knowledge. Our
results show a significant improvement for all the language pairs investigated,
better cross-lingual inference, and a superior performance in zero-shot
learning scenarios as compared to state-of-the-art baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training (TXIT) Exam and Red Journal Gray Zone Cases: Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology. (arXiv:2304.11957v2 [physics.med-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11957">
<div class="article-summary-box-inner">
<span><p>The potential of large language models in medicine for education and decision
making purposes has been demonstrated as they achieve decent scores on medical
exams such as the United States Medical Licensing Exam (USMLE) and the MedQA
exam. In this work, we evaluate the performance of ChatGPT-4 in the specialized
field of radiation oncology using the 38th American College of Radiology (ACR)
radiation oncology in-training (TXIT) exam and the 2022 red journal gray zone
cases. For the TXIT exam, ChatGPT-3.5 and ChatGPT-4 have achieved the scores of
63.65% and 74.57%, respectively, highlighting the advantage of the latest
ChatGPT-4 model. Based on the TXIT exam, ChatGPT-4's strong and weak areas in
radiation oncology are identified to some extent. Specifically, ChatGPT-4
demonstrates good knowledge of statistics, CNS &amp; eye, pediatrics, biology, and
physics but has limitations in bone &amp; soft tissue and gynecology, as per the
ACR knowledge domain. Regarding clinical care paths, ChatGPT-4 performs well in
diagnosis, prognosis, and toxicity but lacks proficiency in topics related to
brachytherapy and dosimetry, as well as in-depth questions from clinical
trials. For the gray zone cases, ChatGPT-4 is able to suggest a personalized
treatment approach to each case and achieves comparable votes (28.76% on
average) to human experts in general. Most importantly, it provides
complementary suggestion to the recommendation from a single expert. Both
evaluations have demonstrated the potential of ChatGPT in medical education for
the general public and cancer patients, as well as the potential to aid
clinical decision-making, while acknowledging its limitations in certain
domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Still no evidence for an effect of the proportion of non-native speakers on language complexity -- A response to Kauhanen, Einhaus & Walkden (2023). (arXiv:2305.00217v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.00217">
<div class="article-summary-box-inner">
<span><p>In a recent paper published in the Journal of Language Evolution, Kauhanen,
Einhaus &amp; Walkden (https://doi.org/10.1093/jole/lzad005, KEW) challenge the
results presented in one of my papers (Koplenig, Royal Society Open Science, 6,
181274 (2019), https://doi.org/10.1098/rsos.181274), in which I tried to show
through a series of statistical analyses that large numbers of L2 (second
language) speakers do not seem to affect the (grammatical or statistical)
complexity of a language. To this end, I focus on the way in which the
Ethnologue assesses language status: a language is characterised as vehicular
if, in addition to being used by L1 (first language) speakers, it should also
have a significant number of L2 users. KEW criticise both the use of
vehicularity as a (binary) indicator of whether a language has a significant
number of L2 users and the idea of imputing a zero proportion of L2 speakers to
non-vehicular languages whenever a direct estimate of that proportion is
unavailable. While I recognise the importance of post-publication commentary on
published research, I show in this rejoinder that both points of criticism are
explicitly mentioned and analysed in my paper. In addition, I also comment on
other points raised by KEW and demonstrate that both alternative analyses
offered by KEW do not stand up to closer scrutiny.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models. (arXiv:2305.01219v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01219">
<div class="article-summary-box-inner">
<span><p>The prompt-based learning paradigm, which bridges the gap between
pre-training and fine-tuning, achieves state-of-the-art performance on several
NLP tasks, particularly in few-shot settings. Despite being widely applied,
prompt-based learning is vulnerable to backdoor attacks. Textual backdoor
attacks are designed to introduce targeted vulnerabilities into models by
poisoning a subset of training samples through trigger injection and label
modification. However, they suffer from flaws such as abnormal natural language
expressions resulting from the trigger and incorrect labeling of poisoned
samples. In this study, we propose ProAttack, a novel and efficient method for
performing clean-label backdoor attacks based on the prompt, which uses the
prompt itself as a trigger. Our method does not require external triggers and
ensures correct labeling of poisoned samples, improving the stealthy nature of
the backdoor attack. With extensive experiments on rich-resource and few-shot
text classification tasks, we empirically validate ProAttack's competitive
performance in textual backdoor attacks. Notably, in the rich-resource setting,
ProAttack achieves state-of-the-art attack success rates in the clean-label
backdoor attack benchmark without external triggers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information. (arXiv:2305.01528v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01528">
<div class="article-summary-box-inner">
<span><p>Dungeons &amp; Dragons (D&amp;D) is a tabletop roleplaying game with complex natural
language interactions between players and hidden state information. Recent work
has shown that large language models (LLMs) that have access to state
information can generate higher quality game turns than LLMs that use dialog
history alone. However, previous work used game state information that was
heuristically created and was not a true gold standard game state. We present
FIREBALL, a large dataset containing nearly 25,000 unique sessions from real
D&amp;D gameplay on Discord with true game state info. We recorded game play
sessions of players who used the Avrae bot, which was developed to aid people
in playing D&amp;D online, capturing language, game commands and underlying game
state information. We demonstrate that FIREBALL can improve natural language
generation (NLG) by using Avrae state information, improving both automated
metrics and human judgments of quality. Additionally, we show that LLMs can
generate executable Avrae commands, particularly after finetuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Proactive Dialogue Systems: Problems, Methods, and Prospects. (arXiv:2305.02750v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02750">
<div class="article-summary-box-inner">
<span><p>Proactive dialogue systems, related to a wide range of real-world
conversational applications, equip the conversational agent with the capability
of leading the conversation direction towards achieving pre-defined targets or
fulfilling certain goals from the system side. It is empowered by advanced
techniques to progress to more complicated tasks that require strategical and
motivational interactions. In this survey, we provide a comprehensive overview
of the prominent problems and advanced designs for conversational agent's
proactivity in different types of dialogues. Furthermore, we discuss challenges
that meet the real-world application needs but require a greater research focus
in the future. We hope that this first survey of proactive dialogue systems can
provide the community with a quick access and an overall picture to this
practical problem, and stimulate more progresses on conversational AI to the
next level.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Elephant in the Room: Analyzing the Presence of Big Tech in Natural Language Processing Research. (arXiv:2305.02797v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02797">
<div class="article-summary-box-inner">
<span><p>Recent advances in deep learning methods for natural language processing
(NLP) have created new business opportunities and made NLP research critical
for industry development. As one of the big players in the field of NLP,
together with governments and universities, it is important to track the
influence of industry on research. In this study, we seek to quantify and
characterize industry presence in the NLP community over time. Using a corpus
with comprehensive metadata of 78,187 NLP publications and 701 resumes of NLP
publication authors, we explore the industry presence in the field since the
early 90s. We find that industry presence among NLP authors has been steady
before a steep increase over the past five years (180% growth from 2017 to
2022). A few companies account for most of the publications and provide funding
to academic researchers through grants and internships. Our study shows that
the presence and impact of the industry on natural language processing research
are significant and fast-growing. This work calls for increased transparency of
industry influence in the field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering. (arXiv:2305.03453v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03453">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have recently demonstrated exceptional
performance in various Natural Language Processing (NLP) tasks. They have also
shown the ability to perform chain-of-thought (CoT) reasoning to solve complex
problems. Recent studies have explored CoT reasoning in complex multimodal
scenarios, such as the science question answering task, by fine-tuning
multimodal models with high-quality human-annotated CoT rationales. However,
collecting high-quality COT rationales is usually time-consuming and costly.
Besides, the annotated rationales are hardly accurate due to the redundant
information involved or the essential information missed. To address these
issues, we propose a novel method termed \emph{T-SciQ} that aims at teaching
science question answering with LLM signals. The T-SciQ approach generates
high-quality CoT rationales as teaching signals and is advanced to train much
smaller models to perform CoT reasoning in complex modalities. Additionally, we
introduce a novel data mixing strategy to produce more effective teaching data
samples for simple and complex science question answer problems. Extensive
experimental results show that our T-SciQ method achieves a new
state-of-the-art performance on the ScienceQA benchmark, with an accuracy of
96.18%. Moreover, our approach outperforms the most powerful fine-tuned
baseline by 4.5%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion. (arXiv:2305.03509v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03509">
<div class="article-summary-box-inner">
<span><p>Diffusion-based generative models' impressive ability to create convincing
images has captured global attention. However, their complex internal
structures and operations often make them difficult for non-experts to
understand. We present Diffusion Explainer, the first interactive visualization
tool that explains how Stable Diffusion transforms text prompts into images.
Diffusion Explainer tightly integrates a visual overview of Stable Diffusion's
complex components with detailed explanations of their underlying operations,
enabling users to fluidly transition between multiple levels of abstraction
through animations and interactive elements. By comparing the evolutions of
image representations guided by two related text prompts over refinement
timesteps, users can discover the impact of prompts on image generation.
Diffusion Explainer runs locally in users' web browsers without the need for
installation or specialized hardware, broadening the public's education access
to modern AI techniques. Our open-sourced tool is available at:
https://poloclub.github.io/diffusion-explainer/. A video demo is available at
https://youtu.be/Zg4gxdIWDds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DAMO-NLP at SemEval-2023 Task 2: A Unified Retrieval-augmented System for Multilingual Named Entity Recognition. (arXiv:2305.03688v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03688">
<div class="article-summary-box-inner">
<span><p>The MultiCoNER \RNum{2} shared task aims to tackle multilingual named entity
recognition (NER) in fine-grained and noisy scenarios, and it inherits the
semantic ambiguity and low-context setting of the MultiCoNER \RNum{1} task. To
cope with these problems, the previous top systems in the MultiCoNER \RNum{1}
either incorporate the knowledge bases or gazetteers. However, they still
suffer from insufficient knowledge, limited context length, single retrieval
strategy. In this paper, our team \textbf{DAMO-NLP} proposes a unified
retrieval-augmented system (U-RaNER) for fine-grained multilingual NER. We
perform error analysis on the previous top systems and reveal that their
performance bottleneck lies in insufficient knowledge. Also, we discover that
the limited context length causes the retrieval knowledge to be invisible to
the model. To enhance the retrieval context, we incorporate the entity-centric
Wikidata knowledge base, while utilizing the infusion approach to broaden the
contextual scope of the model. Also, we explore various search strategies and
refine the quality of retrieval knowledge. Our system\footnote{We will release
the dataset, code, and scripts of our system at {\small
\url{https://github.com/modelscope/AdaSeq/tree/master/examples/U-RaNER}}.} wins
9 out of 13 tracks in the MultiCoNER \RNum{2} shared task. Additionally, we
compared our system with ChatGPT, one of the large language models which have
unlocked strong capabilities on many tasks. The results show that there is
still much room for improvement for ChatGPT on the extraction task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UIT-OpenViIC: A Novel Benchmark for Evaluating Image Captioning in Vietnamese. (arXiv:2305.04166v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04166">
<div class="article-summary-box-inner">
<span><p>Image Captioning is one of the vision-language tasks that still interest the
research community worldwide in the 2020s. MS-COCO Caption benchmark is
commonly used to evaluate the performance of advanced captioning models,
although it was published in 2015. Recent captioning models trained on the
MS-COCO Caption dataset only have good performance in language patterns of
English; they do not have such good performance in contexts captured in Vietnam
or fluently caption images using Vietnamese. To contribute to the low-resources
research community as in Vietnam, we introduce a novel image captioning dataset
in Vietnamese, the Open-domain Vietnamese Image Captioning dataset
(UIT-OpenViIC). The introduced dataset includes complex scenes captured in
Vietnam and manually annotated by Vietnamese under strict rules and
supervision. In this paper, we present in more detail the dataset creation
process. From preliminary analysis, we show that our dataset is challenging to
recent state-of-the-art (SOTA) Transformer-based baselines, which performed
well on the MS COCO dataset. Then, the modest results prove that UIT-OpenViIC
has room to grow, which can be one of the standard benchmarks in Vietnamese for
the research community to evaluate their captioning models. Furthermore, we
present a CAMO approach that effectively enhances the image representation
ability by a multi-level encoder output fusion mechanism, which helps improve
the quality of generated captions compared to previous captioning models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AlignSTS: Speech-to-Singing Conversion via Cross-Modal Alignment. (arXiv:2305.04476v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04476">
<div class="article-summary-box-inner">
<span><p>The speech-to-singing (STS) voice conversion task aims to generate singing
samples corresponding to speech recordings while facing a major challenge: the
alignment between the target (singing) pitch contour and the source (speech)
content is difficult to learn in a text-free situation. This paper proposes
AlignSTS, an STS model based on explicit cross-modal alignment, which views
speech variance such as pitch and content as different modalities. Inspired by
the mechanism of how humans will sing the lyrics to the melody, AlignSTS: 1)
adopts a novel rhythm adaptor to predict the target rhythm representation to
bridge the modality gap between content and pitch, where the rhythm
representation is computed in a simple yet effective way and is quantized into
a discrete space; and 2) uses the predicted rhythm representation to re-align
the content based on cross-attention and conducts a cross-modal fusion for
re-synthesize. Extensive experiments show that AlignSTS achieves superior
performance in terms of both objective and subjective metrics. Audio samples
are available at https://alignsts.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PreCog: Exploring the Relation between Memorization and Performance in Pre-trained Language Models. (arXiv:2305.04673v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04673">
<div class="article-summary-box-inner">
<span><p>Pre-trained Language Models such as BERT are impressive machines with the
ability to memorize, possibly generalized learning examples. We present here a
small, focused contribution to the analysis of the interplay between
memorization and performance of BERT in downstream tasks. We propose PreCog, a
measure for evaluating memorization from pre-training, and we analyze its
correlation with the BERT's performance. Our experiments show that highly
memorized examples are better classified, suggesting memorization is an
essential key to success for BERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MultiModal-GPT: A Vision and Language Model for Dialogue with Humans. (arXiv:2305.04790v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04790">
<div class="article-summary-box-inner">
<span><p>We present a vision and language model named MultiModal-GPT to conduct
multi-round dialogue with humans. MultiModal-GPT can follow various
instructions from humans, such as generating a detailed caption, counting the
number of interested objects, and answering general questions from users.
MultiModal-GPT is parameter-efficiently fine-tuned from OpenFlamingo, with
Low-rank Adapter (LoRA) added both in the cross-attention part and the
self-attention part of the language model. We first construct instruction
templates with vision and language data for multi-modality instruction tuning
to make the model understand and follow human instructions. We find the quality
of training data is vital for the dialogue performance, where few data
containing short answers can lead the model to respond shortly to any
instructions. To further enhance the ability to chat with humans of the
MultiModal-GPT, we utilize language-only instruction-following data to train
the MultiModal-GPT jointly. The joint training of language-only and
visual-language instructions with the \emph{same} instruction template
effectively improves dialogue performance. Various demos show the ability of
continuous dialogue of MultiModal-GPT with humans. Code, dataset, and demo are
at https://github.com/open-mmlab/Multimodal-GPT
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-05-10 23:12:05.808199275 UTC">2023-05-10 23:12:05 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>