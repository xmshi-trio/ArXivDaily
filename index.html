<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-06-21T01:30:00Z">06-21</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">A Pairing Enhancement Approach for Aspect Sentiment Triplet Extraction. (arXiv:2306.10042v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.10042">
<div class="article-summary-box-inner">
<span><p>Aspect Sentiment Triplet Extraction (ASTE) aims to extract the triplet of an
aspect term, an opinion term, and their corresponding sentiment polarity from
the review texts. Due to the complexity of language and the existence of
multiple aspect terms and opinion terms in a single sentence, current models
often confuse the connections between an aspect term and the opinion term
describing it. To address this issue, we propose a pairing enhancement approach
for ASTE, which incorporates contrastive learning during the training stage to
inject aspect-opinion pairing knowledge into the triplet extraction model.
Experimental results demonstrate that our approach performs well on four ASTE
datasets (i.e., 14lap, 14res, 15res and 16res) compared to several related
classical and state-of-the-art triplet extraction methods. Moreover, ablation
studies conduct an analysis and verify the advantage of contrastive learning
over other pairing enhancement approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Practical Entity Linking System for Tables in Scientific Literature. (arXiv:2306.10044v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.10044">
<div class="article-summary-box-inner">
<span><p>Entity linking is an important step towards constructing knowledge graphs
that facilitate advanced question answering over scientific documents,
including the retrieval of relevant information included in tables within these
documents. This paper introduces a general-purpose system for linking entities
to items in the Wikidata knowledge base. It describes how we adapt this system
for linking domain-specific entities, especially for those entities embedded
within tables drawn from COVID-19-related scientific literature. We describe
the setup of an efficient offline instance of the system that enables our
entity-linking approach to be more feasible in practice. As part of a broader
approach to infer the semantic meaning of scientific tables, we leverage the
structural and semantic characteristics of the tables to improve overall entity
linking performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generate to Understand for Representation. (arXiv:2306.10056v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.10056">
<div class="article-summary-box-inner">
<span><p>In recent years, a significant number of high-quality pretrained models have
emerged, greatly impacting Natural Language Understanding (NLU), Natural
Language Generation (NLG), and Text Representation tasks. Traditionally, these
models are pretrained on custom domain corpora and finetuned for specific
tasks, resulting in high costs related to GPU usage and labor. Unfortunately,
recent trends in language modeling have shifted towards enhancing performance
through scaling, further exacerbating the associated costs.
</p>
<p>Introducing GUR: a pretraining framework that combines language modeling and
contrastive learning objectives in a single training step. We select similar
text pairs based on their Longest Common Substring (LCS) from raw unlabeled
documents and train the model using masked language modeling and unsupervised
contrastive learning. The resulting model, GUR, achieves impressive results
without any labeled training data, outperforming all other pretrained baselines
as a retriever at the recall benchmark in a zero-shot setting. Additionally,
GUR maintains its language modeling ability, as demonstrated in our ablation
experiment. Our code is available at \url{https://github.com/laohur/GUR}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EM-Network: Oracle Guided Self-distillation for Sequence Learning. (arXiv:2306.10058v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.10058">
<div class="article-summary-box-inner">
<span><p>We introduce EM-Network, a novel self-distillation approach that effectively
leverages target information for supervised sequence-to-sequence (seq2seq)
learning. In contrast to conventional methods, it is trained with oracle
guidance, which is derived from the target sequence. Since the oracle guidance
compactly represents the target-side context that can assist the sequence model
in solving the task, the EM-Network achieves a better prediction compared to
using only the source input. To allow the sequence model to inherit the
promising capability of the EM-Network, we propose a new self-distillation
strategy, where the original sequence model can benefit from the knowledge of
the EM-Network in a one-stage manner. We conduct comprehensive experiments on
two types of seq2seq models: connectionist temporal classification (CTC) for
speech recognition and attention-based encoder-decoder (AED) for machine
translation. Experimental results demonstrate that the EM-Network significantly
advances the current state-of-the-art approaches, improving over the best prior
work on speech recognition and establishing state-of-the-art performance on
WMT'14 and IWSLT'14.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revealing the structure of language model capabilities. (arXiv:2306.10062v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.10062">
<div class="article-summary-box-inner">
<span><p>Building a theoretical understanding of the capabilities of large language
models (LLMs) is vital for our ability to predict and explain the behavior of
these systems. Here, we investigate the structure of LLM capabilities by
extracting latent capabilities from patterns of individual differences across a
varied population of LLMs. Using a combination of Bayesian and frequentist
factor analysis, we analyzed data from 29 different LLMs across 27 cognitive
tasks. We found evidence that LLM capabilities are not monolithic. Instead,
they are better explained by three well-delineated factors that represent
reasoning, comprehension and core language modeling. Moreover, we found that
these three factors can explain a high proportion of the variance in model
performance. These results reveal a consistent structure in the capabilities of
different LLMs and demonstrate the multifaceted nature of these capabilities.
We also found that the three abilities show different relationships to model
properties such as model size and instruction tuning. These patterns help
refine our understanding of scaling laws and indicate that changes to a model
that improve one ability might simultaneously impair others. Based on these
findings, we suggest that benchmarks could be streamlined by focusing on tasks
that tap into each broad model ability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain-specific ChatBots for Science using Embeddings. (arXiv:2306.10067v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.10067">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have emerged as powerful machine-learning
systems capable of handling a myriad of tasks. Tuned versions of these systems
have been turned into chatbots that can respond to user queries on a vast
diversity of topics, providing informative and creative replies. However, their
application to physical science research remains limited owing to their
incomplete knowledge in these areas, contrasted with the needs of rigor and
sourcing in science domains. Here, we demonstrate how existing methods and
software tools can be easily combined to yield a domain-specific chatbot. The
system ingests scientific documents in existing formats, and uses text
embedding lookup to provide the LLM with domain-specific contextual information
when composing its reply. We similarly demonstrate that existing image
embedding methods can be used for search and retrieval across publication
figures. These results confirm that LLMs are already suitable for use by
physical scientists in accelerating their research efforts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Opportunities and Challenges for ChatGPT and Large Language Models in Biomedicine and Health. (arXiv:2306.10070v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.10070">
<div class="article-summary-box-inner">
<span><p>ChatGPT has drawn considerable attention from both the general public and
domain experts with its remarkable text generation capabilities. This has
subsequently led to the emergence of diverse applications in the field of
biomedicine and health. In this work, we examine the diverse applications of
large language models (LLMs), such as ChatGPT, in biomedicine and health.
Specifically we explore the areas of biomedical information retrieval, question
answering, medical text summarization, information extraction, and medical
education, and investigate whether LLMs possess the transformative power to
revolutionize these tasks or whether the distinct complexities of biomedical
domain presents unique challenges. Following an extensive literature survey, we
find that significant advances have been made in the field of text generation
tasks, surpassing the previous state-of-the-art methods. For other
applications, the advances have been modest. Overall, LLMs have not yet
revolutionized the biomedicine, but recent rapid progress indicates that such
methods hold great potential to provide valuable means for accelerating
discovery and improving health. We also find that the use of LLMs, like
ChatGPT, in the fields of biomedicine and health entails various risks and
challenges, including fabricated information in its generated responses, as
well as legal and privacy concerns associated with sensitive patient data. We
believe this first-of-its-kind survey can provide a comprehensive overview to
biomedical researchers and healthcare practitioners on the opportunities and
challenges associated with using ChatGPT and other LLMs for transforming
biomedicine and health.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Error correction and extraction in request dialogs. (arXiv:2004.04243v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.04243">
<div class="article-summary-box-inner">
<span><p>We propose a dialog system utility component that gets the last two
utterances of a user and can detect whether the last utterance is an error
correction of the second last utterance. If yes, it corrects the second last
utterance according to the error correction in the last utterance and outputs
the extracted pairs of reparandum and repair entity. This component offers two
advantages, learning the concept of corrections to avoid collecting corrections
for every new domain and extracting reparandum and repair pairs, which offers
the possibility to learn out of it.
</p>
<p>For the error correction one sequence labeling and two sequence to sequence
approaches are presented. For the error correction detection these three error
correction approaches can also be used and in addition, we present a sequence
classification approach. One error correction detection and one error
correction approach can be combined to a pipeline or the error correction
approaches can be trained and used end-to-end to avoid two components. We
modified the EPIC-KITCHENS-100 dataset to evaluate the approaches for
correcting entity phrases in request dialogs. For error correction detection
and correction, we got an accuracy of 96.40 % on synthetic validation data and
an accuracy of 77.81 % on human-created real-world test data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Word Discovery in Visually Grounded, Self-Supervised Speech Models. (arXiv:2203.15081v5 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.15081">
<div class="article-summary-box-inner">
<span><p>We present a method for visually-grounded spoken term discovery. After
training either a HuBERT or wav2vec2.0 model to associate spoken captions with
natural images, we show that powerful word segmentation and clustering
capability emerges within the model's self-attention heads. Our experiments
reveal that this ability is not present to nearly the same extent in the base
HuBERT and wav2vec2.0 models, suggesting that the visual grounding task is a
crucial component of the word discovery capability we observe. We also evaluate
our method on the Buckeye word segmentation and ZeroSpeech spoken term
discovery tasks, where we perform on par with or better than currently
published methods on several metrics. Code and model weights are available at
https://github.com/jasonppy/word-discovery.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-lingual AMR Aligner: Paying Attention to Cross-Attention. (arXiv:2206.07587v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.07587">
<div class="article-summary-box-inner">
<span><p>This paper introduces a novel aligner for Abstract Meaning Representation
(AMR) graphs that can scale cross-lingually, and is thus capable of aligning
units and spans in sentences of different languages. Our approach leverages
modern Transformer-based parsers, which inherently encode alignment information
in their cross-attention weights, allowing us to extract this information
during parsing. This eliminates the need for English-specific rules or the
Expectation Maximization (EM) algorithm that have been used in previous
approaches. In addition, we propose a guided supervised method using alignment
to further enhance the performance of our aligner. We achieve state-of-the-art
results in the benchmarks for AMR alignment and demonstrate our aligner's
ability to obtain them across multiple languages. Our code will be available at
\href{https://www.github.com/Babelscape/AMR-alignment}{github.com/Babelscape/AMR-alignment}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-aspect Multilingual and Cross-lingual Parliamentary Speech Analysis. (arXiv:2207.01054v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.01054">
<div class="article-summary-box-inner">
<span><p>Parliamentary and legislative debate transcripts provide informative insight
into elected politicians' opinions, positions, and policy preferences. They are
interesting for political and social sciences as well as linguistics and
natural language processing (NLP) research. While existing research studied
individual parliaments, we apply advanced NLP methods to a joint and
comparative analysis of six national parliaments (Bulgarian, Czech, French,
Slovene, Spanish, and United Kingdom) between 2017 and 2020. We analyze
emotions and sentiment in the transcripts from the ParlaMint dataset collection
and assess if the age, gender, and political orientation of speakers can be
detected from their speeches. The results show some commonalities and many
surprising differences among the analyzed countries.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Probing Classifiers are Unreliable for Concept Removal and Detection. (arXiv:2207.04153v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.04153">
<div class="article-summary-box-inner">
<span><p>Neural network models trained on text data have been found to encode
undesirable linguistic or sensitive concepts in their representation. Removing
such concepts is non-trivial because of a complex relationship between the
concept, text input, and the learnt representation. Recent work has proposed
post-hoc and adversarial methods to remove such unwanted concepts from a
model's representation. Through an extensive theoretical and empirical
analysis, we show that these methods can be counter-productive: they are unable
to remove the concepts entirely, and in the worst case may end up destroying
all task-relevant features. The reason is the methods' reliance on a probing
classifier as a proxy for the concept. Even under the most favorable conditions
for learning a probing classifier when a concept's relevant features in
representation space alone can provide 100% accuracy, we prove that a probing
classifier is likely to use non-concept features and thus post-hoc or
adversarial methods will fail to remove the concept correctly. These
theoretical implications are confirmed by experiments on models trained on
synthetic, Multi-NLI, and Twitter datasets. For sensitive applications of
concept removal such as fairness, we recommend caution against using these
methods and propose a spuriousness metric to gauge the quality of the final
classifier.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Cognitive Study on Semantic Similarity Analysis of Large Corpora: A Transformer-based Approach. (arXiv:2207.11716v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.11716">
<div class="article-summary-box-inner">
<span><p>Semantic similarity analysis and modeling is a fundamentally acclaimed task
in many pioneering applications of natural language processing today. Owing to
the sensation of sequential pattern recognition, many neural networks like RNNs
and LSTMs have achieved satisfactory results in semantic similarity modeling.
However, these solutions are considered inefficient due to their inability to
process information in a non-sequential manner, thus leading to the improper
extraction of context. Transformers function as the state-of-the-art
architecture due to their advantages like non-sequential data processing and
self-attention. In this paper, we perform semantic similarity analysis and
modeling on the U.S Patent Phrase to Phrase Matching Dataset using both
traditional and transformer-based techniques. We experiment upon four different
variants of the Decoding Enhanced BERT - DeBERTa and enhance its performance by
performing K-Fold Cross-Validation. The experimental results demonstrate our
methodology's enhanced performance compared to traditional techniques, with an
average Pearson correlation score of 0.79.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompting as Probing: Using Language Models for Knowledge Base Construction. (arXiv:2208.11057v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.11057">
<div class="article-summary-box-inner">
<span><p>Language Models (LMs) have proven to be useful in various downstream
applications, such as summarisation, translation, question answering and text
classification. LMs are becoming increasingly important tools in Artificial
Intelligence, because of the vast quantity of information they can store. In
this work, we present ProP (Prompting as Probing), which utilizes GPT-3, a
large Language Model originally proposed by OpenAI in 2020, to perform the task
of Knowledge Base Construction (KBC). ProP implements a multi-step approach
that combines a variety of prompting techniques to achieve this. Our results
show that manual prompt curation is essential, that the LM must be encouraged
to give answer sets of variable lengths, in particular including empty answer
sets, that true/false questions are a useful device to increase precision on
suggestions generated by the LM, that the size of the LM is a crucial factor,
and that a dictionary of entity aliases improves the LM score. Our evaluation
study indicates that these proposed techniques can substantially enhance the
quality of the final predictions: ProP won track 2 of the LM-KBC competition,
outperforming the baseline by 36.4 percentage points. Our implementation is
available on https://github.com/HEmile/iswc-challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Moral Mimicry: Large Language Models Produce Moral Rationalizations Tailored to Political Identity. (arXiv:2209.12106v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.12106">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have demonstrated impressive capabilities in
generating fluent text, as well as tendencies to reproduce undesirable social
biases. This study investigates whether LLMs reproduce the moral biases
associated with political groups in the United States, an instance of a broader
capability herein termed moral mimicry. This hypothesis is explored in the
GPT-3/3.5 and OPT families of Transformer-based LLMs. Using tools from Moral
Foundations Theory, it is shown that these LLMs are indeed moral mimics. When
prompted with a liberal or conservative political identity, the models generate
text reflecting corresponding moral biases. This study also explores the
relationship between moral mimicry and model size, and similarity between human
and LLM moral word use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting. (arXiv:2210.08964v4 [stat.ME] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08964">
<div class="article-summary-box-inner">
<span><p>This paper presents a new perspective on time series forecasting. In existing
time series forecasting methods, the models take a sequence of numerical values
as input and yield numerical values as output. The existing SOTA models are
largely based on the Transformer architecture, modified with multiple encoding
mechanisms to incorporate the context and semantics around the historical data.
Inspired by the successes of pre-trained language foundation models, we pose a
question about whether these models can also be adapted to solve time-series
forecasting. Thus, we propose a new forecasting paradigm: prompt-based time
series forecasting (PromptCast). In this novel task, the numerical input and
output are transformed into prompts and the forecasting task is framed in a
sentence-to-sentence manner, making it possible to directly apply language
models for forecasting purposes. To support and facilitate the research of this
task, we also present a large-scale dataset (PISA) that includes three
real-world forecasting scenarios. We evaluate different SOTA numerical-based
forecasting methods and language generation models. The benchmark results with
various forecasting settings demonstrate the proposed PromptCast with language
generation models is a promising research direction. Additionally, in
comparison to conventional numerical-based forecasting, PromptCast shows a much
better generalization ability under the zero-shot setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Textual Entailment Recognition with Semantic Features from Empirical Text Representation. (arXiv:2210.09723v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.09723">
<div class="article-summary-box-inner">
<span><p>Textual entailment recognition is one of the basic natural language
understanding(NLU) tasks. Understanding the meaning of sentences is a
prerequisite before applying any natural language processing(NLP) techniques to
automatically recognize the textual entailment. A text entails a hypothesis if
and only if the true value of the hypothesis follows the text. Classical
approaches generally utilize the feature value of each word from word embedding
to represent the sentences. In this paper, we propose a novel approach to
identifying the textual entailment relationship between text and hypothesis,
thereby introducing a new semantic feature focusing on empirical
threshold-based semantic text representation. We employ an element-wise
Manhattan distance vector-based feature that can identify the semantic
entailment relationship between the text-hypothesis pair. We carried out
several experiments on a benchmark entailment classification(SICK-RTE) dataset.
We train several machine learning(ML) algorithms applying both semantic and
lexical features to classify the text-hypothesis pair as entailment, neutral,
or contradiction. Our empirical sentence representation technique enriches the
semantic information of the texts and hypotheses found to be more efficient
than the classical ones. In the end, our approach significantly outperforms
known methods in understanding the meaning of the sentences for the textual
entailment classification task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Tail Wagging the Dog: Dataset Construction Biases of Social Bias Benchmarks. (arXiv:2210.10040v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10040">
<div class="article-summary-box-inner">
<span><p>How reliably can we trust the scores obtained from social bias benchmarks as
faithful indicators of problematic social biases in a given language model? In
this work, we study this question by contrasting social biases with non-social
biases stemming from choices made during dataset construction that might not
even be discernible to the human eye. To do so, we empirically simulate various
alternative constructions for a given benchmark based on innocuous
modifications (such as paraphrasing or random-sampling) that maintain the
essence of their social bias. On two well-known social bias benchmarks
(Winogender and BiasNLI) we observe that these shallow modifications have a
surprising effect on the resulting degree of bias across various models. We
hope these troubling observations motivate more robust measures of social
biases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MoNET: Tackle State Momentum via Noise-Enhanced Training for Dialogue State Tracking. (arXiv:2211.05503v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.05503">
<div class="article-summary-box-inner">
<span><p>Dialogue state tracking (DST) aims to convert the dialogue history into
dialogue states which consist of slot-value pairs. As condensed structural
information memorizing all history information, the dialogue state in the last
turn is typically adopted as the input for predicting the current state by DST
models. However, these models tend to keep the predicted slot values unchanged,
which is defined as state momentum in this paper. Specifically, the models
struggle to update slot values that need to be changed and correct wrongly
predicted slot values in the last turn. To this end, we propose MoNET to tackle
state momentum via noise-enhanced training. First, the previous state of each
turn in the training data is noised via replacing some of its slot values.
Then, the noised previous state is used as the input to learn to predict the
current state, improving the model's ability to update and correct slot values.
Furthermore, a contrastive context matching framework is designed to narrow the
representation distance between a state and its corresponding noised variant,
which reduces the impact of noised state and makes the model better understand
the dialogue history. Experimental results on MultiWOZ datasets show that MoNET
outperforms previous DST methods. Ablations and analysis verify the
effectiveness of MoNET in alleviating state momentum and improving anti-noise
ability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MASTER: Multi-task Pre-trained Bottlenecked Masked Autoencoders are Better Dense Retrievers. (arXiv:2212.07841v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.07841">
<div class="article-summary-box-inner">
<span><p>Pre-trained Transformers (\eg BERT) have been commonly used in existing dense
retrieval methods for parameter initialization, and recent studies are
exploring more effective pre-training tasks for further improving the quality
of dense vectors. Although various novel and effective tasks have been
proposed, their different input formats and learning objectives make them hard
to be integrated for jointly improving the model performance. In this work, we
aim to unify a variety of pre-training tasks into the bottlenecked masked
autoencoder manner, and integrate them into a multi-task pre-trained model,
namely MASTER. Concretely, MASTER utilizes a shared-encoder multi-decoder
architecture that can construct a representation bottleneck to compress the
abundant semantic information across tasks into dense vectors. Based on it, we
integrate three types of representative pre-training tasks: corrupted passages
recovering, related passages recovering and PLMs outputs recovering, to
characterize the inner-passage information, inter-passage relations and PLMs
knowledge. Extensive experiments have shown that our approach outperforms
competitive dense retrieval methods. Our code and data are publicly released in
\url{https://github.com/microsoft/SimXNS}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extrinsic Evaluation of Machine Translation Metrics. (arXiv:2212.10297v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10297">
<div class="article-summary-box-inner">
<span><p>Automatic machine translation (MT) metrics are widely used to distinguish the
translation qualities of machine translation systems across relatively large
test sets (system-level evaluation). However, it is unclear if automatic
metrics are reliable at distinguishing good translations from bad translations
at the sentence level (segment-level evaluation). In this paper, we investigate
how useful MT metrics are at detecting the success of a machine translation
component when placed in a larger platform with a downstream task. We evaluate
the segment-level performance of the most widely used MT metrics (chrF, COMET,
BERTScore, etc.) on three downstream cross-lingual tasks (dialogue state
tracking, question answering, and semantic parsing). For each task, we only
have access to a monolingual task-specific model. We calculate the correlation
between the metric's ability to predict a good/bad translation with the
success/failure on the final task for the Translate-Test setup. Our experiments
demonstrate that all metrics exhibit negligible correlation with the extrinsic
evaluation of the downstream outcomes. We also find that the scores provided by
neural metrics are not interpretable mostly because of undefined ranges. We
synthesise our analysis into recommendations for future MT metrics to produce
labels rather than scores for more informative interaction between machine
translation and multilingual language understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MULTI3NLU++: A Multilingual, Multi-Intent, Multi-Domain Dataset for Natural Language Understanding in Task-Oriented Dialogue. (arXiv:2212.10455v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10455">
<div class="article-summary-box-inner">
<span><p>Task-oriented dialogue (TOD) systems have been widely deployed in many
industries as they deliver more efficient customer support. These systems are
typically constructed for a single domain or language and do not generalise
well beyond this. To support work on Natural Language Understanding (NLU) in
TOD across multiple languages and domains simultaneously, we constructed
MULTI3NLU++, a multilingual, multi-intent, multi-domain dataset. MULTI3NLU++
extends the English only NLU++ dataset to include manual translations into a
range of high, medium, and low resource languages (Spanish, Marathi, Turkish
and Amharic), in two domains (BANKING and HOTELS). Because of its multi-intent
property, MULTI3NLU++ represents complex and natural user goals, and therefore
allows us to measure the realistic performance of TOD systems in a varied set
of the world's languages. We use MULTI3NLU++ to benchmark state-of-the-art
multilingual models for the NLU tasks of intent detection and slot labelling
for TOD systems in the multilingual setting. The results demonstrate the
challenging nature of the dataset, particularly in the low-resource language
setting, offering ample room for future experimentation in multi-domain
multilingual TOD setups.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EXIF as Language: Learning Cross-Modal Associations Between Images and Camera Metadata. (arXiv:2301.04647v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.04647">
<div class="article-summary-box-inner">
<span><p>We learn a visual representation that captures information about the camera
that recorded a given photo. To do this, we train a multimodal embedding
between image patches and the EXIF metadata that cameras automatically insert
into image files. Our model represents this metadata by simply converting it to
text and then processing it with a transformer. The features that we learn
significantly outperform other self-supervised and supervised features on
downstream image forensics and calibration tasks. In particular, we
successfully localize spliced image regions "zero shot" by clustering the
visual embeddings for all of the patches within an image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Compositional Exemplars for In-context Learning. (arXiv:2302.05698v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05698">
<div class="article-summary-box-inner">
<span><p>Large pretrained language models (LMs) have shown impressive In-Context
Learning (ICL) ability, where the model learns to do an unseen task via a
prompt consisting of input-output examples as the demonstration, without any
parameter updates. The performance of ICL is highly dominated by the quality of
the selected in-context examples. However, previous selection methods are
mostly based on simple heuristics, leading to sub-optimal performance. In this
work, we formulate in-context example selection as a subset selection problem.
We propose CEIL (Compositional Exemplars for In-context Learning), which is
instantiated by Determinantal Point Processes (DPPs) to model the interaction
between the given input and in-context examples, and optimized through a
carefully-designed contrastive learning objective to obtain preference from
LMs. We validate CEIL on 12 classification and generation datasets from 7
distinct NLP tasks, including sentiment analysis, paraphrase detection, natural
language inference, commonsense reasoning, open-domain question answering, code
generation, and semantic parsing. Extensive experiments demonstrate not only
the state-of-the-art performance but also the transferability and
compositionality of CEIL, shedding new light on effective and efficient
in-context learning. Our code is released at
https://github.com/HKUNLP/icl-ceil.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MarioGPT: Open-Ended Text2Level Generation through Large Language Models. (arXiv:2302.05981v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05981">
<div class="article-summary-box-inner">
<span><p>Procedural Content Generation (PCG) algorithms provide a technique to
generate complex and diverse environments in an automated way. However, while
generating content with PCG methods is often straightforward, generating
meaningful content that reflects specific intentions and constraints remains
challenging. Furthermore, many PCG algorithms lack the ability to generate
content in an open-ended manner. Recently, Large Language Models (LLMs) have
shown to be incredibly effective in many diverse domains. These trained LLMs
can be fine-tuned, re-using information and accelerating training for new
tasks. In this work, we introduce MarioGPT, a fine-tuned GPT2 model trained to
generate tile-based game levels, in our case Super Mario Bros levels. We show
that MarioGPT can not only generate diverse levels, but can be text-prompted
for controllable level generation, addressing one of the key challenges of
current PCG techniques. As far as we know, MarioGPT is the first text-to-level
model. We also combine MarioGPT with novelty search, enabling it to generate
diverse levels with varying play-style dynamics (i.e. player paths). This
combination allows for the open-ended generation of an increasingly diverse
range of content.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parameter-efficient Modularised Bias Mitigation via AdapterFusion. (arXiv:2302.06321v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.06321">
<div class="article-summary-box-inner">
<span><p>Large pre-trained language models contain societal biases and carry along
these biases to downstream tasks. Current in-processing bias mitigation
approaches (like adversarial training) impose debiasing by updating a model's
parameters, effectively transferring the model to a new, irreversible debiased
state. In this work, we propose a novel approach to develop stand-alone
debiasing functionalities separate from the model, which can be integrated into
the model on-demand, while keeping the core model untouched. Drawing from the
concept of AdapterFusion in multi-task learning, we introduce DAM (Debiasing
with Adapter Modules) - a debiasing approach to first encapsulate arbitrary
bias mitigation functionalities into separate adapters, and then add them to
the model on-demand in order to deliver fairness qualities. We conduct a large
set of experiments on three classification tasks with gender, race, and age as
protected attributes. Our results show that DAM improves or maintains the
effectiveness of bias mitigation, avoids catastrophic forgetting in a
multi-attribute scenario, and maintains on-par task performance, while granting
parameter-efficiency and easy switching between the original and debiased
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NL2CMD: An Updated Workflow for Natural Language to Bash Commands Translation. (arXiv:2302.07845v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07845">
<div class="article-summary-box-inner">
<span><p>Translating natural language into Bash Commands is an emerging research field
that has gained attention in recent years. Most efforts have focused on
producing more accurate translation models. To the best of our knowledge, only
two datasets are available, with one based on the other. Both datasets involve
scraping through known data sources (through platforms like stack overflow,
crowdsourcing, etc.) and hiring experts to validate and correct either the
English text or Bash Commands. This paper provides two contributions to
research on synthesizing Bash Commands from scratch. First, we describe a
state-of-the-art translation model used to generate Bash Commands from the
corresponding English text. Second, we introduce a new NL2CMD dataset that is
automatically generated, involves minimal human intervention, and is over six
times larger than prior datasets. Since the generation pipeline does not rely
on existing Bash Commands, the distribution and types of commands can be custom
adjusted. We evaluate the performance of ChatGPT on this task and discuss the
potential of using it as a data generator. Our empirical results show how the
scale and diversity of our dataset can offer unique opportunities for semantic
parsing researchers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards MoE Deployment: Mitigating Inefficiencies in Mixture-of-Expert (MoE) Inference. (arXiv:2303.06182v2 [cs.DC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.06182">
<div class="article-summary-box-inner">
<span><p>Mixture-of-Experts (MoE) models have gained popularity in achieving
state-of-the-art performance in a wide range of tasks in computer vision and
natural language processing. They effectively expand the model capacity while
incurring a minimal increase in computation cost during training. However,
deploying such models for inference is difficult due to their large size and
complex communication pattern. In this work, we provide a characterization of
two MoE workloads, namely Language Modeling (LM) and Machine Translation (MT)
and identify their sources of inefficiencies at deployment. We propose three
optimization techniques to mitigate sources of inefficiencies, namely (1)
Dynamic gating, (2) Expert Buffering, and (3) Expert load balancing. We show
that dynamic gating improves maximum throughput by 6.21-11.23$\times$ for LM,
5.75-10.98$\times$ for MT Encoder and 2.58-5.71$\times$ for MT Decoder. It also
reduces memory usage by up to 1.36$\times$ for LM and up to 1.1$\times$ for MT.
We further propose Expert Buffering, a new caching mechanism that only keeps
hot, active experts in GPU memory while buffering the rest in CPU memory. This
reduces static memory allocation by up to 1.47$\times$. We finally propose a
load balancing methodology that provides additional scalability to the
workload.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OpenAGI: When LLM Meets Domain Experts. (arXiv:2304.04370v4 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.04370">
<div class="article-summary-box-inner">
<span><p>Human intelligence excels at combining basic skills to solve complex tasks.
This capability is vital for Artificial Intelligence (AI) and should be
embedded in comprehensive intelligent models, enabling them to harness expert
models for complex task-solving towards Artificial General Intelligence (AGI).
Large Language Models (LLMs) show promising learning and reasoning abilities,
and can effectively use external models to tackle complex problems. In this
work, we introduce OpenAGI, an open-source AGI research platform designed for
multi-step, real-world tasks. Specifically, OpenAGI uses a dual strategy,
integrating standard benchmark tasks for benchmarking and evaluation, and
open-ended tasks including more expandable models for creative problem-solving.
Tasks are presented as natural language queries to the LLM, which then selects
and executes appropriate models. We also propose a Reinforcement Learning from
Task Feedback (RLTF) mechanism that uses task results to improve the LLM's
ability, which creates a self-improving AI feedback loop. While we acknowledge
that AGI is a broad and multifaceted research challenge with no singularly
defined solution path, the integration of LLMs with domain-specific expert
models, inspired by mirroring the blend of general and specialized intelligence
in humans, offers a promising approach towards AGI. We are open-sourcing the
OpenAGI project's code, dataset, benchmarks, evaluation methods, and demo to
foster community involvement in AGI advancement:
https://github.com/agiresearch/OpenAGI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ASL Citizen: A Community-Sourced Dataset for Advancing Isolated Sign Language Recognition. (arXiv:2304.05934v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.05934">
<div class="article-summary-box-inner">
<span><p>Sign languages are used as a primary language by approximately 70 million
D/deaf people world-wide. However, most communication technologies operate in
spoken and written languages, creating inequities in access. To help tackle
this problem, we release ASL Citizen, the first crowdsourced Isolated Sign
Language Recognition (ISLR) dataset, collected with consent and containing
83,399 videos for 2,731 distinct signs filmed by 52 signers in a variety of
environments. We propose that this dataset be used for sign language dictionary
retrieval for American Sign Language (ASL), where a user demonstrates a sign to
their webcam to retrieve matching signs from a dictionary. We show that
training supervised machine learning classifiers with our dataset advances the
state-of-the-art on metrics relevant for dictionary retrieval, achieving 63%
accuracy and a recall-at-10 of 91%, evaluated entirely on videos of users who
are not present in the training or validation sets. An accessible PDF of this
article is available at the following link:
https://aashakadesai.github.io/research/ASLCitizen_arxiv_updated.pdf
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting k-NN for Fine-tuning Pre-trained Language Models. (arXiv:2304.09058v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09058">
<div class="article-summary-box-inner">
<span><p>Pre-trained Language Models (PLMs), as parametric-based eager learners, have
become the de-facto choice for current paradigms of Natural Language Processing
(NLP). In contrast, k-Nearest-Neighbor (kNN) classifiers, as the lazy learning
paradigm, tend to mitigate over-fitting and isolated noise. In this paper, we
revisit kNN classifiers for augmenting the PLMs-based classifiers. From the
methodological level, we propose to adopt kNN with textual representations of
PLMs in two steps: (1) Utilize kNN as prior knowledge to calibrate the training
process. (2) Linearly interpolate the probability distribution predicted by kNN
with that of the PLMs' classifier. At the heart of our approach is the
implementation of kNN-calibrated training, which treats predicted results as
indicators for easy versus hard examples during the training process. From the
perspective of the diversity of application scenarios, we conduct extensive
experiments on fine-tuning, prompt-tuning paradigms and zero-shot, few-shot and
fully-supervised settings, respectively, across eight diverse end-tasks. We
hope our exploration will encourage the community to revisit the power of
classical methods for efficient NLP. Code and datasets are available in
https://github.com/zjunlp/Revisit-KNN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Development of a Trust-Aware User Simulator for Statistical Proactive Dialog Modeling in Human-AI Teams. (arXiv:2304.11913v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11913">
<div class="article-summary-box-inner">
<span><p>The concept of a Human-AI team has gained increasing attention in recent
years. For effective collaboration between humans and AI teammates, proactivity
is crucial for close coordination and effective communication. However, the
design of adequate proactivity for AI-based systems to support humans is still
an open question and a challenging topic. In this paper, we present the
development of a corpus-based user simulator for training and testing proactive
dialog policies. The simulator incorporates informed knowledge about proactive
dialog and its effect on user trust and simulates user behavior and personal
information, including socio-demographic features and personality traits. Two
different simulation approaches were compared, and a task-step-based approach
yielded better overall results due to enhanced modeling of sequential
dependencies. This research presents a promising avenue for exploring and
evaluating appropriate proactive strategies in a dialog game setting for
improving Human-AI teams.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models. (arXiv:2305.01146v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01146">
<div class="article-summary-box-inner">
<span><p>We systematically investigate lightweight strategies to adapt large language
models (LLMs) for the task of radiology report summarization (RRS).
Specifically, we focus on domain adaptation via pretraining (on natural
language, biomedical text, or clinical text) and via discrete prompting or
parameter-efficient fine-tuning. Our results consistently achieve best
performance by maximally adapting to the task via pretraining on clinical text
and fine-tuning on RRS examples. Importantly, this method fine-tunes a mere
0.32% of parameters throughout the model, in contrast to end-to-end fine-tuning
(100% of parameters). Additionally, we study the effect of in-context examples
and out-of-distribution (OOD) training before concluding with a radiologist
reader study and qualitative analysis. Our findings highlight the importance of
domain adaptation in RRS and provide valuable insights toward developing
effective natural language processing solutions for clinical tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Working Memory Capacity of ChatGPT: An Empirical Study. (arXiv:2305.03731v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03731">
<div class="article-summary-box-inner">
<span><p>Working memory is a critical aspect of both human intelligence and artificial
intelligence, serving as a workspace for the temporary storage and manipulation
of information. In this paper, we systematically assess the working memory
capacity of ChatGPT (gpt-3.5-turbo), a large language model developed by
OpenAI, by examining its performance in verbal and spatial n-back tasks under
various conditions. Our experiments reveal that ChatGPT experiences significant
declines in performance as n increases (which necessitates more information to
be stored in working memory), suggesting a limit to the working memory capacity
strikingly similar to that of humans. Furthermore, we investigate the impact of
different instruction strategies on ChatGPT's performance and observe that the
fundamental patterns of a capacity limit persist. From our empirical findings,
we propose that n-back tasks may serve as tools for benchmarking the working
memory capacity of large language models and hold potential for informing
future efforts aimed at enhancing AI working memory and deepening our
understanding of human working memory through AI models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Advancing Neural Encoding of Portuguese with Transformer Albertina PT-*. (arXiv:2305.06721v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.06721">
<div class="article-summary-box-inner">
<span><p>To advance the neural encoding of Portuguese (PT), and a fortiori the
technological preparation of this language for the digital age, we developed a
Transformer-based foundation model that sets a new state of the art in this
respect for two of its variants, namely European Portuguese from Portugal
(PT-PT) and American Portuguese from Brazil (PT-BR).
</p>
<p>To develop this encoder, which we named Albertina PT-*, a strong model was
used as a starting point, DeBERTa, and its pre-training was done over data sets
of Portuguese, namely over data sets we gathered for PT-PT and PT-BR, and over
the brWaC corpus for PT-BR. The performance of Albertina and competing models
was assessed by evaluating them on prominent downstream language processing
tasks adapted for Portuguese.
</p>
<p>Both Albertina PT-PT and PT-BR versions are distributed free of charge and
under the most permissive license possible and can be run on consumer-grade
hardware, thus seeking to contribute to the advancement of research and
innovation in language technology for Portuguese.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Hidden Mystery of OCR in Large Multimodal Models. (arXiv:2305.07895v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07895">
<div class="article-summary-box-inner">
<span><p>Large models have recently played a dominant role in natural language
processing and multimodal vision-language learning. It remains less explored
about their efficacy in text-related visual tasks. We conducted a comprehensive
study of existing publicly available multimodal models, evaluating their
performance in text recognition (document text, artistic text, handwritten
text, scene text), text-based visual question answering (document text, scene
text, and bilingual text), key information extraction (receipts, documents, and
nutrition facts) and handwritten mathematical expression recognition. Our
findings reveal strengths and weaknesses in these models, which primarily rely
on semantic understanding for word recognition and exhibit inferior perception
of individual character shapes. They also display indifference towards text
length and have limited capabilities in detecting finegrained features in
images. Consequently, these results demonstrate that even the current most
powerful large multimodal models cannot match domain-specific methods in
traditional text tasks and face greater challenges in more complex tasks. Most
importantly, the baseline results showcased in this study could provide a
foundational framework for the conception and assessment of innovative
strategies targeted at enhancing zero-shot multimodal techniques. Evaluation
pipeline is available at https://github.com/Yuliang-Liu/MultimodalOCR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bring More Attention to Syntactic Symmetry for Automatic Postediting of High-Quality Machine Translations. (arXiv:2305.10557v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10557">
<div class="article-summary-box-inner">
<span><p>Automatic postediting (APE) is an automated process to refine a given machine
translation (MT). Recent findings present that existing APE systems are not
good at handling high-quality MTs even for a language pair with abundant data
resources, English-to-German: the better the given MT is, the harder it is to
decide what parts to edit and how to fix these errors. One possible solution to
this problem is to instill deeper knowledge about the target language into the
model. Thus, we propose a linguistically motivated method of regularization
that is expected to enhance APE models' understanding of the target language: a
loss function that encourages symmetric self-attention on the given MT. Our
analysis of experimental results demonstrates that the proposed method helps
improving the state-of-the-art architecture's APE quality for high-quality MTs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models can be Guided to Evade AI-Generated Text Detection. (arXiv:2305.10847v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10847">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have demonstrated exceptional performance in a
variety of tasks, including essay writing and question answering. However, it
is crucial to address the potential misuse of these models, which can lead to
detrimental outcomes such as plagiarism and spamming. Recently, several
detectors have been proposed, including fine-tuned classifiers and various
statistical methods. In this study, we reveal that with the aid of carefully
crafted prompts, LLMs can effectively evade these detection systems. We propose
a novel Substitution-based In-Context example Optimization method (SICO) to
automatically generate such prompts. On three real-world tasks where LLMs can
be misused, SICO successfully enables ChatGPT to evade six existing detectors,
causing a significant 0.54 AUC drop on average. Surprisingly, in most cases
these detectors perform even worse than random classifiers. These results
firmly reveal the vulnerability of existing detectors. Finally, the strong
performance of SICO suggests itself as a reliable evaluation protocol for any
new detector in this field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the Viability of Synthetic Query Generation for Relevance Prediction. (arXiv:2305.11944v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11944">
<div class="article-summary-box-inner">
<span><p>Query-document relevance prediction is a critical problem in Information
Retrieval systems. This problem has increasingly been tackled using
(pretrained) transformer-based models which are finetuned using large
collections of labeled data. However, in specialized domains such as e-commerce
and healthcare, the viability of this approach is limited by the dearth of
large in-domain data. To address this paucity, recent methods leverage these
powerful models to generate high-quality task and domain-specific synthetic
data. Prior work has largely explored synthetic data generation or query
generation (QGen) for Question-Answering (QA) and binary (yes/no) relevance
prediction, where for instance, the QGen models are given a document, and
trained to generate a query relevant to that document. However in many
problems, we have a more fine-grained notion of relevance than a simple yes/no
label. Thus, in this work, we conduct a detailed study into how QGen approaches
can be leveraged for nuanced relevance prediction. We demonstrate that --
contrary to claims from prior works -- current QGen approaches fall short of
the more conventional cross-domain transfer-learning approaches. Via empirical
studies spanning 3 public e-commerce benchmarks, we identify new shortcomings
of existing QGen approaches -- including their inability to distinguish between
different grades of relevance. To address this, we introduce label-conditioned
QGen models which incorporates knowledge about the different relevance. While
our experiments demonstrate that these modifications help improve performance
of QGen techniques, we also find that QGen approaches struggle to capture the
full nuance of the relevance label space and as a result the generated queries
are not faithful to the desired relevance label.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PromptNER: Prompting For Named Entity Recognition. (arXiv:2305.15444v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15444">
<div class="article-summary-box-inner">
<span><p>In a surprising turn, Large Language Models (LLMs) together with a growing
arsenal of prompt-based heuristics now offer powerful off-the-shelf approaches
providing few-shot solutions to myriad classic NLP problems. However, despite
promising early results, these LLM-based few-shot methods remain far from the
state of the art in Named Entity Recognition (NER), where prevailing methods
include learning representations via end-to-end structural understanding and
fine-tuning on standard labeled corpora. In this paper, we introduce PromptNER,
a new state-of-the-art algorithm for few-Shot and cross-domain NER. To adapt to
any new NER task PromptNER requires a set of entity definitions in addition to
the standard few-shot examples. Given a sentence, PromptNER prompts an LLM to
produce a list of potential entities along with corresponding explanations
justifying their compatibility with the provided entity type definitions.
Remarkably, PromptNER achieves state-of-the-art performance on few-shot NER,
achieving a 4% (absolute) improvement in F1 score on the ConLL dataset, a 9%
(absolute) improvement on the GENIA dataset, and a 4% (absolute) improvement on
the FewNERD dataset. PromptNER also moves the state of the art on Cross Domain
NER, outperforming prior methods (including those not limited to the few-shot
setting), setting a new mark on 3/5 CrossNER target domains, with an average F1
gain of 3%, despite using less than 2% of the available data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Simultaneous Speech Translation with Differentiable Segmentation. (arXiv:2305.16093v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16093">
<div class="article-summary-box-inner">
<span><p>End-to-end simultaneous speech translation (SimulST) outputs translation
while receiving the streaming speech inputs (a.k.a. streaming speech
translation), and hence needs to segment the speech inputs and then translate
based on the current received speech. However, segmenting the speech inputs at
unfavorable moments can disrupt the acoustic integrity and adversely affect the
performance of the translation model. Therefore, learning to segment the speech
inputs at those moments that are beneficial for the translation model to
produce high-quality translation is the key to SimulST. Existing SimulST
methods, either using the fixed-length segmentation or external segmentation
model, always separate segmentation from the underlying translation model,
where the gap results in segmentation outcomes that are not necessarily
beneficial for the translation process. In this paper, we propose
Differentiable Segmentation (DiSeg) for SimulST to directly learn segmentation
from the underlying translation model. DiSeg turns hard segmentation into
differentiable through the proposed expectation training, enabling it to be
jointly trained with the translation model and thereby learn
translation-beneficial segmentation. Experimental results demonstrate that
DiSeg achieves state-of-the-art performance and exhibits superior segmentation
capability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IndicTrans2: Towards High-Quality and Accessible Machine Translation Models for all 22 Scheduled Indian Languages. (arXiv:2305.16307v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16307">
<div class="article-summary-box-inner">
<span><p>India has a rich linguistic landscape with languages from 4 major language
families spoken by over a billion people. 22 of these languages are listed in
the Constitution of India (referred to as scheduled languages) are the focus of
this work. Given the linguistic diversity, high-quality and accessible Machine
Translation (MT) systems are essential in a country like India. Prior to this
work, there was (i) no parallel training data spanning all the 22 languages,
(ii) no robust benchmarks covering all these languages and containing content
relevant to India, and (iii) no existing translation models which support all
the 22 scheduled languages of India. In this work, we aim to address this gap
by focusing on the missing pieces required for enabling wide, easy, and open
access to good machine translation systems for all 22 scheduled Indian
languages. We identify four key areas of improvement: curating and creating
larger training datasets, creating diverse and high-quality benchmarks,
training multilingual models, and releasing models with open access. Our first
contribution is the release of the Bharat Parallel Corpus Collection (BPCC),
the largest publicly available parallel corpora for Indic languages. BPCC
contains a total of 230M bitext pairs, of which a total of 126M were newly
added, including 644K manually translated sentence pairs created as part of
this work. Our second contribution is the release of the first n-way parallel
benchmark covering all 22 Indian languages, featuring diverse domains,
Indian-origin content, and source-original test sets. Next, we present
IndicTrans2, the first model to support all 22 languages, surpassing existing
models on multiple existing and new benchmarks created as a part of this work.
Lastly, to promote accessibility and collaboration, we release our models and
associated data with permissive licenses at
https://github.com/ai4bharat/IndicTrans2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decoding the Underlying Meaning of Multimodal Hateful Memes. (arXiv:2305.17678v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17678">
<div class="article-summary-box-inner">
<span><p>Recent studies have proposed models that yielded promising performance for
the hateful meme classification task. Nevertheless, these proposed models do
not generate interpretable explanations that uncover the underlying meaning and
support the classification output. A major reason for the lack of explainable
hateful meme methods is the absence of a hateful meme dataset that contains
ground truth explanations for benchmarking or training. Intuitively, having
such explanations can educate and assist content moderators in interpreting and
removing flagged hateful memes. This paper address this research gap by
introducing Hateful meme with Reasons Dataset (HatReD), which is a new
multimodal hateful meme dataset annotated with the underlying hateful
contextual reasons. We also define a new conditional generation task that aims
to automatically generate underlying reasons to explain hateful memes and
establish the baseline performance of state-of-the-art pre-trained language
models on this task. We further demonstrate the usefulness of HatReD by
analyzing the challenges of the new conditional generation task in explaining
memes in seen and unseen domains. The dataset and benchmark models are made
available here: https://github.com/Social-AI-Studio/HatRed
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating GPT-3 Generated Explanations for Hateful Content Moderation. (arXiv:2305.17680v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17680">
<div class="article-summary-box-inner">
<span><p>Recent research has focused on using large language models (LLMs) to generate
explanations for hate speech through fine-tuning or prompting. Despite the
growing interest in this area, these generated explanations' effectiveness and
potential limitations remain poorly understood. A key concern is that these
explanations, generated by LLMs, may lead to erroneous judgments about the
nature of flagged content by both users and content moderators. For instance,
an LLM-generated explanation might inaccurately convince a content moderator
that a benign piece of content is hateful. In light of this, we propose an
analytical framework for examining hate speech explanations and conducted an
extensive survey on evaluating such explanations. Specifically, we prompted
GPT-3 to generate explanations for both hateful and non-hateful content, and a
survey was conducted with 2,400 unique respondents to evaluate the generated
explanations. Our findings reveal that (1) human evaluators rated the
GPT-generated explanations as high quality in terms of linguistic fluency,
informativeness, persuasiveness, and logical soundness, (2) the persuasive
nature of these explanations, however, varied depending on the prompting
strategy employed, and (3) this persuasiveness may result in incorrect
judgments about the hatefulness of the content. Our study underscores the need
for caution in applying LLM-generated explanations for content moderation. Code
and results are available at https://github.com/Social-AI-Studio/GPT3-HateEval.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MedNgage: A Dataset for Understanding Engagement in Patient-Nurse Conversations. (arXiv:2305.19981v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19981">
<div class="article-summary-box-inner">
<span><p>Patients who effectively manage their symptoms often demonstrate higher
levels of engagement in conversations and interventions with healthcare
practitioners. This engagement is multifaceted, encompassing cognitive and
socio-affective dimensions. Consequently, it is crucial for AI systems to
understand the engagement in natural conversations between patients and
practitioners to better contribute toward patient care. In this paper, we
present a novel dataset (MedNgage), which consists of patient-nurse
conversations about cancer symptom management. We manually annotate the dataset
with a novel framework of categories of patient engagement from two different
angles, namely: i) socio-affective (3.1K spans), and ii) cognitive use of
language (1.8K spans). Through statistical analysis of the data that is
annotated using our framework, we show a positive correlation between patient
symptom management outcomes and their engagement in conversations.
Additionally, we demonstrate that pre-trained transformer models fine-tuned on
our dataset can reliably predict engagement classes in patient-nurse
conversations. Lastly, we use LIME (Ribeiro et al., 2016) to analyze the
underlying challenges of the tasks that state-of-the-art transformer models
encounter. The de-identified data is available for research purposes upon
request.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beam Tree Recursive Cells. (arXiv:2305.19999v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19999">
<div class="article-summary-box-inner">
<span><p>We propose Beam Tree Recursive Cell (BT-Cell) - a backpropagation-friendly
framework to extend Recursive Neural Networks (RvNNs) with beam search for
latent structure induction. We further extend this framework by proposing a
relaxation of the hard top-k operators in beam search for better propagation of
gradient signals. We evaluate our proposed models in different
out-of-distribution splits in both synthetic and realistic data. Our
experiments show that BTCell achieves near-perfect performance on several
challenging structure-sensitive synthetic tasks like ListOps and logical
inference while maintaining comparable performance in realistic data against
other RvNN-based models. Additionally, we identify a previously unknown failure
case for neural models in generalization to unseen number of arguments in
ListOps. The code is available at:
https://github.com/JRC1995/BeamTreeRecursiveCells.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SpeechGen: Unlocking the Generative Power of Speech Language Models with Prompts. (arXiv:2306.02207v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.02207">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have gained considerable attention for
Artificial Intelligence Generated Content (AIGC), particularly with the
emergence of ChatGPT. However, the direct adaptation of continuous speech to
LLMs that process discrete tokens remains an unsolved challenge, hindering the
application of LLMs for speech generation. The advanced speech LMs are in the
corner, as that speech signals encapsulate a wealth of information, including
speaker and emotion, beyond textual data alone. Prompt tuning has demonstrated
notable gains in parameter efficiency and competitive performance on some
speech classification tasks. However, the extent to which prompts can
effectively elicit generation tasks from speech LMs remains an open question.
In this paper, we present pioneering research that explores the application of
prompt tuning to stimulate speech LMs for various generation tasks, within a
unified framework called SpeechGen, with around 10M trainable parameters. The
proposed unified framework holds great promise for efficiency and
effectiveness, particularly with the imminent arrival of advanced speech LMs,
which will significantly enhance the capabilities of the framework. The code
and demos of SpeechGen will be available on the project website:
\url{https://ga642381.github.io/SpeechPrompt/speechgen}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Cloud-based Machine Learning Pipeline for the Efficient Extraction of Insights from Customer Reviews. (arXiv:2306.07786v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.07786">
<div class="article-summary-box-inner">
<span><p>The efficiency of natural language processing has improved dramatically with
the advent of machine learning models, particularly neural network-based
solutions. However, some tasks are still challenging, especially when
considering specific domains. In this paper, we present a cloud-based system
that can extract insights from customer reviews using machine learning methods
integrated into a pipeline. For topic modeling, our composite model uses
transformer-based neural networks designed for natural language processing,
vector embedding-based keyword extraction, and clustering. The elements of our
model have been integrated and further developed to meet better the
requirements of efficient information extraction, topic modeling of the
extracted information, and user needs. Furthermore, our system can achieve
better results than this task's existing topic modeling and keyword extraction
solutions. Our approach is validated and compared with other state-of-the-art
methods using publicly available datasets for benchmarking.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unifying Large Language Models and Knowledge Graphs: A Roadmap. (arXiv:2306.08302v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08302">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs), such as ChatGPT and GPT4, are making new waves
in the field of natural language processing and artificial intelligence, due to
their emergent ability and generalizability. However, LLMs are black-box
models, which often fall short of capturing and accessing factual knowledge. In
contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are
structured knowledge models that explicitly store rich factual knowledge. KGs
can enhance LLMs by providing external knowledge for inference and
interpretability. Meanwhile, KGs are difficult to construct and evolving by
nature, which challenges the existing methods in KGs to generate new facts and
represent unseen knowledge. Therefore, it is complementary to unify LLMs and
KGs together and simultaneously leverage their advantages. In this article, we
present a forward-looking roadmap for the unification of LLMs and KGs. Our
roadmap consists of three general frameworks, namely, 1) KG-enhanced LLMs,
which incorporate KGs during the pre-training and inference phases of LLMs, or
for the purpose of enhancing understanding of the knowledge learned by LLMs; 2)
LLM-augmented KGs, that leverage LLMs for different KG tasks such as embedding,
completion, construction, graph-to-text generation, and question answering; and
3) Synergized LLMs + KGs, in which LLMs and KGs play equal roles and work in a
mutually beneficial way to enhance both LLMs and KGs for bidirectional
reasoning driven by both data and knowledge. We review and summarize existing
efforts within these three frameworks in our roadmap and pinpoint their future
research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning. (arXiv:2306.09030v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.09030">
<div class="article-summary-box-inner">
<span><p>Pragmatic reasoning plays a pivotal role in deciphering implicit meanings
that frequently arise in real-life conversations and is essential for the
development of communicative social agents. In this paper, we introduce a novel
challenge, DiPlomat, aiming at benchmarking machines' capabilities on pragmatic
reasoning and situated conversational understanding. Compared with previous
works that treat different figurative expressions (e.g. metaphor, sarcasm) as
individual tasks, DiPlomat provides a cohesive framework towards general
pragmatic understanding. Our dataset is created through the utilization of
Amazon Mechanical Turk ( AMT ), resulting in a total of 4, 177 multi-turn
dialogues. In conjunction with the dataset, we propose two tasks, Pragmatic
Identification and Reasoning (PIR) and Conversational Question Answering (CQA).
Experimental results with state-of-the-art (SOTA) neural architectures reveal
several significant findings: 1) large language models ( LLMs) exhibit poor
performance in tackling this subjective domain; 2) comprehensive comprehension
of context emerges as a critical factor for establishing benign human-machine
interactions; 3) current models defect in the application of pragmatic
reasoning. As a result, we call on more attention to improve the ability of
context understanding, reasoning, and implied meaning modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RED$^{\rm FM}$: a Filtered and Multilingual Relation Extraction Dataset. (arXiv:2306.09802v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.09802">
<div class="article-summary-box-inner">
<span><p>Relation Extraction (RE) is a task that identifies relationships between
entities in a text, enabling the acquisition of relational facts and bridging
the gap between natural language and structured knowledge. However, current RE
models often rely on small datasets with low coverage of relation types,
particularly when working with languages other than English. In this paper, we
address the above issue and provide two new resources that enable the training
and evaluation of multilingual RE systems. First, we present SRED$^{\rm FM}$,
an automatically annotated dataset covering 18 languages, 400 relation types,
13 entity types, totaling more than 40 million triplet instances. Second, we
propose RED$^{\rm FM}$, a smaller, human-revised dataset for seven languages
that allows for the evaluation of multilingual RE systems. To demonstrate the
utility of these novel datasets, we experiment with the first end-to-end
multilingual RE model, mREBEL, that extracts triplets, including entity types,
in multiple languages. We release our resources and model checkpoints at
https://www.github.com/babelscape/rebel
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Demystifying GPT Self-Repair for Code Generation. (arXiv:2306.09896v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.09896">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have shown remarkable aptitude in code
generation but still struggle on challenging programming tasks. Self-repair --
in which the model debugs and fixes mistakes in its own code -- has recently
become a popular way to boost performance in these settings. However, only very
limited studies on how and when self-repair works effectively exist in the
literature, and one might wonder to what extent a model is really capable of
providing accurate feedback on why the code is wrong when that code was
generated by the same model. In this paper, we analyze GPT-3.5 and GPT-4's
ability to perform self-repair on APPS, a challenging dataset consisting of
diverse coding challenges. To do so, we first establish a new evaluation
strategy dubbed pass@t that measures the pass rate of the tasks against the
total number of tokens sampled from the model, enabling a fair comparison to
purely sampling-based approaches. With this evaluation strategy, we find that
the effectiveness of self-repair is only seen in GPT-4. We also observe that
self-repair is bottlenecked by the feedback stage; using GPT-4 to give feedback
on the programs generated by GPT-3.5 and using expert human programmers to give
feedback on the programs generated by GPT-4, we unlock significant performance
gains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts. (arXiv:2306.04723v1 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.04723">
<div class="article-summary-box-inner">
<span><p>Rapidly increasing quality of AI-generated content makes it difficult to
distinguish between human and AI-generated texts, which may lead to undesirable
consequences for society. Therefore, it becomes increasingly important to study
the properties of human texts that are invariant over text domains and various
proficiency of human writers, can be easily calculated for any language, and
can robustly separate natural and AI-generated texts regardless of the
generation model and sampling method. In this work, we propose such an
invariant of human texts, namely the intrinsic dimensionality of the manifold
underlying the set of embeddings of a given text sample. We show that the
average intrinsic dimensionality of fluent texts in natural language is
hovering around the value $9$ for several alphabet-based languages and around
$7$ for Chinese, while the average intrinsic dimensionality of AI-generated
texts for each language is $\approx 1.5$ lower, with a clear statistical
separation between human-generated and AI-generated distributions. This
property allows us to build a score-based artificial text detector. The
proposed detector's accuracy is stable over text domains, generator models, and
human writer proficiency levels, outperforming SOTA detectors in model-agnostic
and cross-domain scenarios by a significant margin.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-06-21 23:11:52.321899365 UTC">2023-06-21 23:11:52 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>