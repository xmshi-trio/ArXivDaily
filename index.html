<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-02-28T01:30:00Z">02-28</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Fluid Transformers and Creative Analogies: Exploring Large Language Models' Capacity for Augmenting Cross-Domain Analogical Creativity. (arXiv:2302.12832v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12832">
<div class="article-summary-box-inner">
<span><p>Cross-domain analogical reasoning is a core creative ability that can be
challenging for humans. Recent work has shown some proofs-of concept of Large
language Models' (LLMs) ability to generate cross-domain analogies. However,
the reliability and potential usefulness of this capacity for augmenting human
creative work has received little systematic exploration. In this paper, we
systematically explore LLMs capacity to augment cross-domain analogical
reasoning. Across three studies, we found: 1) LLM-generated cross-domain
analogies were frequently judged as helpful in the context of a problem
reformulation task (median 4 out of 5 helpfulness rating), and frequently (~80%
of cases) led to observable changes in problem formulations, and 2) there was
an upper bound of 25% of outputs bring rated as potentially harmful, with a
majority due to potentially upsetting content, rather than biased or toxic
content. These results demonstrate the potential utility -- and risks -- of
LLMs for augmenting cross-domain analogical creativity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HULAT at SemEval-2023 Task 10: Data augmentation for pre-trained transformers applied to the detection of sexism in social media. (arXiv:2302.12840v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12840">
<div class="article-summary-box-inner">
<span><p>This paper describes our participation in SemEval-2023 Task 10, whose goal is
the detection of sexism in social media. We explore some of the most popular
transformer models such as BERT, DistilBERT, RoBERTa, and XLNet. We also study
different data augmentation techniques to increase the training dataset. During
the development phase, our best results were obtained by using RoBERTa and data
augmentation for tasks B and C. However, the use of synthetic data does not
improve the results for task C. We participated in the three subtasks. Our
approach still has much room for improvement, especially in the two
fine-grained classifications. All our code is available in the repository
https://github.com/isegura/hulat_edos.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NoPPA: Non-Parametric Pairwise Attention Random Walk Model for Sentence Representation. (arXiv:2302.12903v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12903">
<div class="article-summary-box-inner">
<span><p>We propose a novel non-parametric/un-trainable language model, named
Non-Parametric Pairwise Attention Random Walk Model (NoPPA), to generate
sentence embedding only with pre-trained word embedding and pre-counted word
frequency. To the best we know, this study is the first successful attempt to
break the constraint on bag-of-words assumption with a non-parametric attention
mechanism. We evaluate our method on eight different downstream classification
tasks. The experiment results show that NoPPA outperforms all kinds of
bag-of-words-based methods in each dataset and provides a comparable or better
performance than the state-of-the-art non-parametric methods on average.
Furthermore, visualization supports that NoPPA can understand contextual
topics, common phrases, and word causalities. Our model is available at
https://github.com/JacksonWuxs/NoPPA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-Finetuning for Few-Shot Emotional Speech Recognition. (arXiv:2302.12921v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12921">
<div class="article-summary-box-inner">
<span><p>Speech models have long been known to overfit individual speakers for many
classification tasks. This leads to poor generalization in settings where the
speakers are out-of-domain or out-of-distribution, as is common in production
environments. We view speaker adaptation as a few-shot learning problem and
propose investigating transfer learning approaches inspired by recent success
with pre-trained models in natural language tasks. We propose pre-finetuning
speech models on difficult tasks to distill knowledge into few-shot downstream
classification objectives. We pre-finetune Wav2Vec2.0 on every permutation of
four multiclass emotional speech recognition corpora and evaluate our
pre-finetuned models through 33,600 few-shot fine-tuning trials on the
Emotional Speech Dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robot Behavior-Tree-Based Task Generation with Large Language Models. (arXiv:2302.12927v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12927">
<div class="article-summary-box-inner">
<span><p>Nowadays, the behavior tree is gaining popularity as a representation for
robot tasks due to its modularity and reusability. Designing behavior-tree
tasks manually is time-consuming for robot end-users, thus there is a need for
investigating automatic behavior-tree-based task generation. Prior
behavior-tree-based task generation approaches focus on fixed primitive tasks
and lack generalizability to new task domains. To cope with this issue, we
propose a novel behavior-tree-based task generation approach that utilizes
state-of-the-art large language models. We propose a Phase-Step prompt design
that enables a hierarchical-structured robot task generation and further
integrate it with behavior-tree-embedding-based search to set up the
appropriate prompt. In this way, we enable an automatic and cross-domain
behavior-tree task generation. Our behavior-tree-based task generation approach
does not require a set of pre-defined primitive tasks. End-users only need to
describe an abstract desired task and our proposed approach can swiftly
generate the corresponding behavior tree. A full-process case study is provided
to demonstrate our proposed approach. An ablation study is conducted to
evaluate the effectiveness of our Phase-Step prompts. Assessment on Phase-Step
prompts and the limitation of large language models are presented and
discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dependency Dialogue Acts -- Annotation Scheme and Case Study. (arXiv:2302.12944v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12944">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce Dependency Dialogue Acts (DDA), a novel framework
for capturing the structure of speaker-intentions in multi-party dialogues. DDA
combines and adapts features from existing dialogue annotation frameworks, and
emphasizes the multi-relational response structure of dialogues in addition to
the dialogue acts and rhetorical relations. It represents the functional,
discourse, and response structure in multi-party multi-threaded conversations.
A few key features distinguish DDA from existing dialogue annotation frameworks
such as SWBD-DAMSL and the ISO 24617-2 standard. First, DDA prioritizes the
relational structure of the dialogue units and the dialog context, annotating
both dialog acts and rhetorical relations as response relations to particular
utterances. Second, DDA embraces overloading in dialogues, encouraging
annotators to specify multiple response relations and dialog acts for each
dialog unit. Lastly, DDA places an emphasis on adequately capturing how a
speaker is using the full dialog context to plan and organize their speech.
With these features, DDA is highly expressive and recall-oriented with regard
to conversation dynamics between multiple speakers. In what follows, we present
the DDA annotation framework and case studies annotating DDA structures in
multi-party, multi-threaded conversations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust language-based mental health assessments in time and space through social media. (arXiv:2302.12952v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12952">
<div class="article-summary-box-inner">
<span><p>Compared to physical health, population mental health measurement in the U.S.
is very coarse-grained. Currently, in the largest population surveys, such as
those carried out by the Centers for Disease Control or Gallup, mental health
is only broadly captured through "mentally unhealthy days" or "sadness", and
limited to relatively infrequent state or metropolitan estimates. Through the
large scale analysis of social media data, robust estimation of population
mental health is feasible at much higher resolutions, up to weekly estimates
for counties. In the present work, we validate a pipeline that uses a sample of
1.2 billion Tweets from 2 million geo-located users to estimate mental health
changes for the two leading mental health conditions, depression and anxiety.
We find moderate to large associations between the language-based mental health
assessments and survey scores from Gallup for multiple levels of granularity,
down to the county-week (fixed effects $\beta = .25$ to $1.58$; $p&lt;.001$).
Language-based assessment allows for the cost-effective and scalable monitoring
of population mental health at weekly time scales. Such spatially fine-grained
time series are well suited to monitor effects of societal events and policies
as well as enable quasi-experimental study designs in population health and
other disciplines. Beyond mental health in the U.S., this method generalizes to
a broad set of psychological outcomes and allows for community measurement in
under-resourced settings where no traditional survey measures - but social
media data - are available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Locale Encoding For Scalable Multilingual Keyword Spotting Models. (arXiv:2302.12961v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12961">
<div class="article-summary-box-inner">
<span><p>A Multilingual Keyword Spotting (KWS) system detects spokenkeywords over
multiple locales. Conventional monolingual KWSapproaches do not scale well to
multilingual scenarios because ofhigh development/maintenance costs and lack of
resource sharing.To overcome this limit, we propose two locale-conditioned
universalmodels with locale feature concatenation and feature-wise
linearmodulation (FiLM). We compare these models with two baselinemethods:
locale-specific monolingual KWS, and a single universalmodel trained over all
data. Experiments over 10 localized languagedatasets show that
locale-conditioned models substantially improveaccuracy over baseline methods
across all locales in different noiseconditions.FiLMperformed the best,
improving on average FRRby 61% (relative) compared to monolingual KWS models of
similarsizes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Jointly Optimizing Translations and Speech Timing to Improve Isochrony in Automatic Dubbing. (arXiv:2302.12979v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12979">
<div class="article-summary-box-inner">
<span><p>Automatic dubbing (AD) is the task of translating the original speech in a
video into target language speech. The new target language speech should
satisfy isochrony; that is, the new speech should be time aligned with the
original video, including mouth movements, pauses, hand gestures, etc. In this
paper, we propose training a model that directly optimizes both the translation
as well as the speech duration of the generated translations. We show that this
system generates speech that better matches the timing of the original speech,
compared to prior work, while simplifying the system architecture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatAug: Leveraging ChatGPT for Text Data Augmentation. (arXiv:2302.13007v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.13007">
<div class="article-summary-box-inner">
<span><p>Text data augmentation is an effective strategy for overcoming the challenge
of limited sample sizes in many natural language processing (NLP) tasks. This
challenge is especially prominent in the few-shot learning scenario, where the
data in the target domain is generally much scarcer and of lowered quality. A
natural and widely-used strategy to mitigate such challenges is to perform data
augmentation on the training data to better capture the data invariance and
increase the sample size. However, current text data augmentation methods
either can not ensure the correct labeling of the generated data (lacking
faithfulness) or can not ensure sufficient diversity in the generated data
(lacking completeness), or both. Inspired by the recent success of large
language models, especially the development of ChatGPT, which demonstrated
improved language comprehension abilities, in this work, we propose a text data
augmentation approach based on ChatGPT (named ChatAug). ChatGPT is trained on
data with unparalleled linguistic richness and employs a reinforcement training
process with large-scale human feedback, which endows the model with affinity
to the naturalness of human language. Our text data augmentation approach
ChatAug rephrases each sentence in the training samples into multiple
conceptually similar but semantically different samples. The augmented samples
can then be used in downstream model training. Experiment results on few-shot
learning text classification tasks show the superior performance of the
proposed ChatAug approach over state-of-the-art text data augmentation methods
in terms of testing accuracy and distribution of the augmented samples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Choice Fusion as Knowledge for Zero-Shot Dialogue State Tracking. (arXiv:2302.13013v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.13013">
<div class="article-summary-box-inner">
<span><p>With the demanding need for deploying dialogue systems in new domains with
less cost, zero-shot dialogue state tracking (DST), which tracks user's
requirements in task-oriented dialogues without training on desired domains,
draws attention increasingly. Although prior works have leveraged
question-answering (QA) data to reduce the need for in-domain training in DST,
they fail to explicitly model knowledge transfer and fusion for tracking
dialogue states. To address this issue, we propose CoFunDST, which is trained
on domain-agnostic QA datasets and directly uses candidate choices of
slot-values as knowledge for zero-shot dialogue-state generation, based on a T5
pre-trained language model. Specifically, CoFunDST selects highly-relevant
choices to the reference context and fuses them to initialize the decoder to
constrain the model outputs. Our experimental results show that our proposed
model achieves outperformed joint goal accuracy compared to existing zero-shot
DST approaches in most domains on the MultiWOZ 2.1. Extensive analyses
demonstrate the effectiveness of our proposed approach for improving zero-shot
DST learning from QA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SynGen: A Syntactic Plug-and-play Module for Generative Aspect-based Sentiment Analysis. (arXiv:2302.13032v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.13032">
<div class="article-summary-box-inner">
<span><p>Aspect-based Sentiment Analysis (ABSA) is a sentiment analysis task at
fine-grained level. Recently, generative frameworks have attracted increasing
attention in ABSA due to their ability to unify subtasks and their continuity
to upstream pre-training tasks. However, these generative models suffer from
the neighboring dependency problem that induces neighboring words to get higher
attention. In this paper, we propose SynGen, a plug-and-play syntactic
information aware module. As a plug-in module, our SynGen can be easily applied
to any generative framework backbones. The key insight of our module is to add
syntactic inductive bias to attention assignment and thus direct attention to
the correct target words. To the best of our knowledge, we are the first one to
introduce syntactic information to generative ABSA frameworks. Our module
design is based on two main principles: (1) maintaining the structural
integrity of backbone PLMs and (2) disentangling the added syntactic
information and original semantic information. Empirical results on four
popular ABSA datasets demonstrate that SynGen enhanced model achieves a
comparable performance to the state-of-the-art model with relaxed labeling
specification and less training consumption.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human-in-the-Loop Schema Induction. (arXiv:2302.13048v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.13048">
<div class="article-summary-box-inner">
<span><p>Schema induction builds a graph representation explaining how events unfold
in a scenario. Existing approaches have been based on information retrieval
(IR) and information extraction(IE), often with limited human curation. We
demonstrate a human-in-the-loop schema induction system powered by GPT-3. We
first describe the different modules of our system, including prompting to
generate schematic elements, manual edit of those elements, and conversion of
those into a schema graph. By qualitatively comparing our system to previous
ones, we show that our system not only transfers to new domains more easily
than previous approaches, but also reduces efforts of human curation thanks to
our interactive interface.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HADES: Homologous Automated Document Exploration and Summarization. (arXiv:2302.13099v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.13099">
<div class="article-summary-box-inner">
<span><p>This paper introduces HADES, a novel tool for automatic comparative documents
with similar structures. HADES is designed to streamline the work of
professionals dealing with large volumes of documents, such as policy
documents, legal acts, and scientific papers. The tool employs a multi-step
pipeline that begins with processing PDF documents using topic modeling,
summarization, and analysis of the most important words for each topic. The
process concludes with an interactive web app with visualizations that
facilitate the comparison of the documents. HADES has the potential to
significantly improve the productivity of professionals dealing with high
volumes of documents, reducing the time and effort required to complete tasks
related to comparative document analysis. Our package is publically available
on GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topic-Selective Graph Network for Topic-Focused Summarization. (arXiv:2302.13106v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.13106">
<div class="article-summary-box-inner">
<span><p>Due to the success of the pre-trained language model (PLM), existing
PLM-based summarization models show their powerful generative capability.
However, these models are trained on general-purpose summarization datasets,
leading to generated summaries failing to satisfy the needs of different
readers. To generate summaries with topics, many efforts have been made on
topic-focused summarization. However, these works generate a summary only
guided by a prompt comprising topic words. Despite their success, these methods
still ignore the disturbance of sentences with non-relevant topics and only
conduct cross-interaction between tokens by attention module. To address this
issue, we propose a topic-arc recognition objective and topic-selective graph
network. First, the topic-arc recognition objective is used to model training,
which endows the capability to discriminate topics for the model. Moreover, the
topic-selective graph network can conduct topic-guided cross-interaction on
sentences based on the results of topic-arc recognition. In the experiments, we
conduct extensive evaluations on NEWTS and COVIDET datasets. Results show that
our methods achieve state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sequential Query Encoding For Complex Query Answering on Knowledge Graphs. (arXiv:2302.13114v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.13114">
<div class="article-summary-box-inner">
<span><p>Query encoding (QE) is proposed as a fast and robust solution to CQA. In the
encoding process, most existing QE methods first parse the logical query into
an executable computational direct-acyclic graph (DAG), then use neural
networks to parameterize the operators, and finally, recursively execute these
neuralized operators. However, the parameterization-and-execution paradigm may
be potentially over-complicated, as it can be structurally simplified by a
single neural network encoder. Meanwhile, sequence encoders, like LSTM and
Transformer, proved to be effective for encoding semantic graphs in related
tasks. Motivated by this, we propose sequential query encoding (SQE) as an
alternative to encode queries for CQA. Instead of parameterizing and executing
the computational graph, SQE first uses a search-based algorithm to linearize
the computational graph to a sequence of tokens and then uses a sequence
encoder to compute its vector representation. Then this vector representation
is used as a query embedding to retrieve answers from the embedding space
according to similarity scores. Despite its simplicity, SQE demonstrates
state-of-the-art neural query encoding performance on FB15k, FB15k-237, and
NELL on an extended benchmark including twenty-nine types of in-distribution
queries. Further experiment shows that SQE also demonstrates comparable
knowledge inference capability on out-of-distribution queries, whose query
types are not observed during the training process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Abstractive Text Summarization using Attentive GRU based Encoder-Decoder. (arXiv:2302.13117v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.13117">
<div class="article-summary-box-inner">
<span><p>In todays era huge volume of information exists everywhere. Therefore, it is
very crucial to evaluate that information and extract useful, and often
summarized, information out of it so that it may be used for relevant purposes.
This extraction can be achieved through a crucial technique of artificial
intelligence, namely, machine learning. Indeed automatic text summarization has
emerged as an important application of machine learning in text processing. In
this paper, an english text summarizer has been built with GRU-based encoder
and decoder. Bahdanau attention mechanism has been added to overcome the
problem of handling long sequences in the input text. A news-summary dataset
has been used to train the model. The output is observed to outperform
competitive models in the literature. The generated summary can be used as a
newspaper headline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward Fairness in Text Generation via Mutual Information Minimization based on Importance Sampling. (arXiv:2302.13136v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.13136">
<div class="article-summary-box-inner">
<span><p>Pretrained language models (PLMs), such as GPT2, have achieved remarkable
empirical performance in text generation tasks. However, pretrained on
large-scale natural language corpora, the generated text from PLMs may exhibit
social bias against disadvantaged demographic groups. To improve the fairness
of PLMs in text generation, we propose to minimize the mutual information
between the semantics in the generated text sentences and their demographic
polarity, i.e., the demographic group to which the sentence is referring. In
this way, the mentioning of a demographic group (e.g., male or female) is
encouraged to be independent from how it is described in the generated text,
thus effectively alleviating the social bias. Moreover, we propose to
efficiently estimate the upper bound of the above mutual information via
importance sampling, leveraging a natural language corpus. We also propose a
distillation mechanism that preserves the language modeling ability of the PLMs
after debiasing. Empirical results on real-world benchmarks demonstrate that
the proposed method yields superior performance in term of both fairness and
language modeling ability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompt-based Learning for Text Readability Assessment. (arXiv:2302.13139v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.13139">
<div class="article-summary-box-inner">
<span><p>We propose the novel adaptation of a pre-trained seq2seq model for
readability assessment. We prove that a seq2seq model - T5 or BART - can be
adapted to discern which text is more difficult from two given texts
(pairwise). As an exploratory study to prompt-learn a neural network for text
readability in a text-to-text manner, we report useful tips for future work in
seq2seq training and ranking-based approach to readability assessment.
Specifically, we test nine input-output formats/prefixes and show that they can
significantly influence the final model performance.
</p>
<p>Also, we argue that the combination of text-to-text training and pairwise
ranking setup 1) enables leveraging multiple parallel text simplification data
for teaching readability and 2) trains a neural model for the general concept
of readability (therefore, better cross-domain generalization). At last, we
report a 99.6% pairwise classification accuracy on Newsela and a 98.7% for
OneStopEnglish, through a joint training approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">STACC: Code Comment Classification using SentenceTransformers. (arXiv:2302.13149v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.13149">
<div class="article-summary-box-inner">
<span><p>Code comments are a key resource for information about software artefacts.
Depending on the use case, only some types of comments are useful. Thus,
automatic approaches to classify these comments are proposed. In this work, we
address this need by proposing, STACC, a set of SentenceTransformers-based
binary classifiers. These lightweight classifiers are trained and tested on the
NLBSE Code Comment Classification tool competition dataset, and surpass the
baseline by a significant margin, achieving an average F1 score of 0.74 against
the baseline of 0.31, which is an improvement of 139%. A replication package,
as well as the models themselves, are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identifying Machine-Paraphrased Plagiarism. (arXiv:2103.11909v7 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11909">
<div class="article-summary-box-inner">
<span><p>Employing paraphrasing tools to conceal plagiarized text is a severe threat
to academic integrity. To enable the detection of machine-paraphrased text, we
evaluate the effectiveness of five pre-trained word embedding models combined
with machine-learning classifiers and eight state-of-the-art neural language
models. We analyzed preprints of research papers, graduation theses, and
Wikipedia articles, which we paraphrased using different configurations of the
tools SpinBot and SpinnerChief. The best-performing technique, Longformer,
achieved an average F1 score of 81.0% (F1=99.7% for SpinBot and F1=71.6% for
SpinnerChief cases), while human evaluators achieved F1=78.4% for SpinBot and
F1=65.6% for SpinnerChief cases. We show that the automated classification
alleviates shortcomings of widely-used text-matching systems, such as Turnitin
and PlagScan. To facilitate future research, all data, code, and two web
applications showcasing our contributions are openly available at
https://github.com/jpwahle/iconf22-paraphrase.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robustness Challenges in Model Distillation and Pruning for Natural Language Understanding. (arXiv:2110.08419v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08419">
<div class="article-summary-box-inner">
<span><p>Recent work has focused on compressing pre-trained language models (PLMs)
like BERT where the major focus has been to improve the in-distribution
performance for downstream tasks. However, very few of these studies have
analyzed the impact of compression on the generalizability and robustness of
compressed models for out-of-distribution (OOD) data. Towards this end, we
study two popular model compression techniques including knowledge distillation
and pruning and show that the compressed models are significantly less robust
than their PLM counterparts on OOD test sets although they obtain similar
performance on in-distribution development sets for a task. Further analysis
indicates that the compressed models overfit on the shortcut samples and
generalize poorly on the hard ones. We further leverage this observation to
develop a regularization strategy for robust model compression based on sample
uncertainty. Experimental results on several natural language understanding
tasks demonstrate that our bias mitigation framework improves the OOD
generalization of the compressed models, while not sacrificing the
in-distribution task performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incorporating Question Answering-Based Signals into Abstractive Summarization via Salient Span Selection. (arXiv:2111.07935v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.07935">
<div class="article-summary-box-inner">
<span><p>In this work, we propose a method for incorporating question-answering (QA)
signals into a summarization model. Our method identifies salient noun phrases
(NPs) in the input document by automatically generating wh-questions that are
answered by the NPs and automatically determining whether those questions are
answered in the gold summaries. This QA-based signal is incorporated into a
two-stage summarization model which first marks salient NPs in the input
document using a classification model, then conditionally generates a summary.
Our experiments demonstrate that the models trained using QA-based supervision
generate higher-quality summaries than baseline methods of identifying salient
spans on benchmark summarization datasets. Further, we show that the content of
the generated summaries can be controlled based on which NPs are marked in the
input document. Finally, we propose a method of augmenting the training data so
the gold summaries are more consistent with the marked input spans used during
training and show how this results in models which learn to better exclude
unmarked document content.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploration into Translation-Equivariant Image Quantization. (arXiv:2112.00384v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.00384">
<div class="article-summary-box-inner">
<span><p>This is an exploratory study that discovers the current image quantization
(vector quantization) do not satisfy translation equivariance in the quantized
space due to aliasing. Instead of focusing on anti-aliasing, we propose a
simple yet effective way to achieve translation-equivariant image quantization
by enforcing orthogonality among the codebook embeddings. To explore the
advantages of translation-equivariant image quantization, we conduct three
proof-of-concept experiments with a carefully controlled dataset: (1)
text-to-image generation, where the quantized image indices are the target to
predict, (2) image-to-text generation, where the quantized image indices are
given as a condition, (3) using a smaller training set to analyze sample
efficiency. From the strictly controlled experiments, we empirically verify
that the translation-equivariant image quantizer improves not only sample
efficiency but also the accuracy over VQGAN up to +11.9% in text-to-image
generation and +3.9% in image-to-text generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UNIREX: A Unified Learning Framework for Language Model Rationale Extraction. (arXiv:2112.08802v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.08802">
<div class="article-summary-box-inner">
<span><p>An extractive rationale explains a language model's (LM's) prediction on a
given task instance by highlighting the text inputs that most influenced the
prediction. Ideally, rationale extraction should be faithful (reflective of
LM's actual behavior) and plausible (convincing to humans), without
compromising the LM's (i.e., task model's) task performance. Although
attribution algorithms and select-predict pipelines are commonly used in
rationale extraction, they both rely on certain heuristics that hinder them
from satisfying all three desiderata. In light of this, we propose UNIREX, a
flexible learning framework that generalizes rationale extractor optimization
as follows: (1) specify architecture for a learned rationale extractor; (2)
select explainability objectives (i.e., faithfulness and plausibility
criteria); and (3) jointly the train task model and rationale extractor on the
task using the selected objectives. UNIREX enables replacing prior works'
heuristic design choices with a generic learned rationale extractor in (1) and
optimizing it for all three desiderata in (2)-(3). To facilitate comparison
between methods with respect to multiple desiderata, we introduce the
Normalized Relative Gain (NRG) metric. Across five text classification
datasets, our best UNIREX configuration outperforms baselines by an average of
32.9% NRG. Plus, we find that UNIREX-trained rationale extractors can even
generalize to unseen datasets and tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Resources for Turkish Natural Language Processing: A critical survey. (arXiv:2204.05042v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.05042">
<div class="article-summary-box-inner">
<span><p>This paper presents a comprehensive survey of corpora and lexical resources
available for Turkish. We review a broad range of resources, focusing on the
ones that are publicly available. In addition to providing information about
the available linguistic resources, we present a set of recommendations, and
identify gaps in the data available for conducting research and building
applications in Turkish Linguistics and Natural Language Processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">XQA-DST: Multi-Domain and Multi-Lingual Dialogue State Tracking. (arXiv:2204.05895v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.05895">
<div class="article-summary-box-inner">
<span><p>Dialogue State Tracking (DST), a crucial component of task-oriented dialogue
(ToD) systems, keeps track of all important information pertaining to dialogue
history: filling slots with the most probable values throughout the
conversation. Existing methods generally rely on a predefined set of values and
struggle to generalise to previously unseen slots in new domains. To overcome
these challenges, we propose a domain-agnostic extractive question answering
(QA) approach with shared weights across domains. To disentangle the complex
domain information in ToDs, we train our DST with a novel domain filtering
strategy by excluding out-of-domain question samples. With an independent
classifier that predicts the presence of multiple domains given the context,
our model tackles DST by extracting spans in active domains. Empirical results
demonstrate that our model can efficiently leverage domain-agnostic QA datasets
by two-stage fine-tuning while being both domain-scalable and open-vocabulary
in DST. It shows strong transferability by achieving zero-shot
domain-adaptation results on MultiWOZ 2.1 with an average JGA of 36.7%. It
further achieves cross-lingual transfer with state-of-the-art zero-shot
results, 66.2% JGA from English to German and 75.7% JGA from English to Italian
on WOZ 2.0.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feature Structure Distillation with Centered Kernel Alignment in BERT Transferring. (arXiv:2204.08922v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.08922">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation is an approach to transfer information on
representations from a teacher to a student by reducing their difference. A
challenge of this approach is to reduce the flexibility of the student's
representations inducing inaccurate learning of the teacher's knowledge. To
resolve it in transferring, we investigate distillation of structures of
representations specified to three types: intra-feature, local inter-feature,
global inter-feature structures. To transfer them, we introduce feature
structure distillation methods based on the Centered Kernel Alignment, which
assigns a consistent value to similar features structures and reveals more
informative relations. In particular, a memory-augmented transfer method with
clustering is implemented for the global structures. The methods are
empirically analyzed on the nine tasks for language understanding of the GLUE
dataset with Bidirectional Encoder Representations from Transformers (BERT),
which is a representative neural language model. In the results, the proposed
methods effectively transfer the three types of structures and improve
performance compared to state-of-the-art distillation methods. Indeed, the code
for the methods is available in https://github.com/maroo-sky/FSD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multi-level Alignment Training Scheme for Video-and-Language Grounding. (arXiv:2204.10938v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.10938">
<div class="article-summary-box-inner">
<span><p>To solve video-and-language grounding tasks, the key is for the network to
understand the connection between the two modalities. For a pair of video and
language description, their semantic relation is reflected by their encodings'
similarity. A good multi-modality encoder should be able to well capture both
inputs' semantics and encode them in the shared feature space where embedding
distance gets properly translated into their semantic similarity. In this work,
we focused on this semantic connection between video and language, and
developed a multi-level alignment training scheme to directly shape the
encoding process. Global and segment levels of video-language alignment pairs
were designed, based on the information similarity ranging from high-level
context to fine-grained semantics. The contrastive loss was used to contrast
the encodings' similarities between the positive and negative alignment pairs,
and to ensure the network is trained in such a way that similar information is
encoded closely in the shared feature space while information of different
semantics is kept apart. Our multi-level alignment training can be applied to
various video-and-language grounding tasks. Together with the task-specific
training loss, our framework achieved comparable performance to previous
state-of-the-arts on multiple video QA and retrieval datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Handling and Presenting Harmful Text in NLP Research. (arXiv:2204.14256v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.14256">
<div class="article-summary-box-inner">
<span><p>Text data can pose a risk of harm. However, the risks are not fully
understood, and how to handle, present, and discuss harmful text in a safe way
remains an unresolved issue in the NLP community. We provide an analytical
framework categorising harms on three axes: (1) the harm type (e.g.,
misinformation, hate speech or racial stereotypes); (2) whether a harm is
\textit{sought} as a feature of the research design if explicitly studying
harmful content (e.g., training a hate speech classifier), versus
\textit{unsought} if harmful content is encountered when working on unrelated
problems (e.g., language generation or part-of-speech tagging); and (3) who it
affects, from people (mis)represented in the data to those handling the data
and those publishing on the data. We provide advice for practitioners, with
concrete steps for mitigating harm in research and in publication. To assist
implementation we introduce \textsc{HarmCheck} -- a documentation standard for
handling and presenting harmful text in research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visually-Augmented Language Modeling. (arXiv:2205.10178v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10178">
<div class="article-summary-box-inner">
<span><p>Human language is grounded on multimodal knowledge including visual knowledge
like colors, sizes, and shapes. However, current large-scale pre-trained
language models rely on text-only self-supervised training with massive text
data, which precludes them from utilizing relevant visual information when
necessary. To address this, we propose a novel pre-training framework, named
VaLM, to Visually-augment text tokens with retrieved relevant images for
Language Modeling. Specifically, VaLM builds on a novel latent text-image
alignment method via an image retrieval module to fetch corresponding images
given a textual context. With the visually-augmented context, VaLM uses a
visual knowledge fusion layer to enable multimodal grounded language modeling
by attending to both text context and visual knowledge in images. We evaluate
VaLM on various visual knowledge-intensive commonsense reasoning tasks, which
require visual information to excel. The experimental results illustrate that
VaLM outperforms all strong language-only and vision-language baselines with
substantial gains in reasoning object commonsense including color, size, and
shape. Our code is available at https://github.com/Victorwz/VaLM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ER-Test: Evaluating Explanation Regularization Methods for Language Models. (arXiv:2205.12542v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12542">
<div class="article-summary-box-inner">
<span><p>By explaining how humans would solve a given task, human rationales can
provide strong learning signal for neural language models (LMs). Explanation
regularization (ER) aims to improve LM generalization by pushing the LM's
machine rationales (Which input tokens did the LM focus on?) to align with
human rationales (Which input tokens would humans focus on?). Though prior
works primarily study ER via in-distribution (ID) evaluation,
out-of-distribution (OOD) generalization is often more critical in real-world
scenarios, yet ER's effect on OOD generalization has been underexplored. In
this paper, we introduce ER-Test, a framework for evaluating ER models' OOD
generalization along three dimensions: unseen dataset tests, contrast set
tests, and functional tests. Using ER-Test, we extensively analyze how ER
models' OOD generalization varies with different ER design choices. Across two
tasks and six datasets, ER-Test shows that ER has little impact on ID
performance but can yield large OOD performance gains. Also, we find that ER
can improve OOD performance even with limited rationale supervision. ER-Test's
results help demonstrate ER's utility and establish best practices for using ER
effectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning. (arXiv:2205.12679v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12679">
<div class="article-summary-box-inner">
<span><p>There is a rising interest in further exploring the zero-shot learning
potential of large pre-trained language models (PLMs). A new paradigm called
data-generation-based zero-shot learning has achieved impressive success. In
this paradigm, the synthesized data from the PLM acts as the carrier of
knowledge, which is used to train a task-specific model with orders of
magnitude fewer parameters than the PLM, achieving both higher performance and
efficiency than prompt-based zero-shot learning methods on PLMs. The main
hurdle of this approach is that the synthesized data from PLM usually contains
a significant portion of low-quality samples. Fitting on such data will greatly
hamper the performance of the task-specific model, making it unreliable for
deployment. Previous methods remedy this issue mainly by filtering synthetic
data using heuristic metrics(e.g., output confidence), or refining the data
with the help of a human expert, which comes with excessive manual tuning or
expensive costs. In this paper, we propose a novel noise-robust re-weighting
framework SunGen to automatically construct high-quality data for zero-shot
classification problems. Our framework features the ability to learn the sample
weights indicating data quality without requiring any human annotation. We
theoretically and empirically verify the ability of our method to help
construct good-quality synthetic datasets. Notably, SunGen-LSTM yields a 9.8%
relative improvement than the baseline on average accuracy across eight
different established text classification tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse Probability of Agreement. (arXiv:2208.06161v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.06161">
<div class="article-summary-box-inner">
<span><p>Measuring inter-annotator agreement is important for annotation tasks, but
many metrics require a fully-annotated set of data, where all annotators
annotate all samples. We define Sparse Probability of Agreement, SPA, which
estimates the probability of agreement when not all annotator-item-pairs are
available. We show that under certain conditions, SPA is an unbiased estimator,
and we provide multiple weighing schemes for handling data with various degrees
of annotation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NECE: Narrative Event Chain Extraction Toolkit. (arXiv:2208.08063v4 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.08063">
<div class="article-summary-box-inner">
<span><p>To understand a narrative, it is essential to comprehend its main characters
and the associated major events; however, this can be challenging with lengthy
and unstructured narrative texts. To address this, we introduce NECE, an
open-access, document-level toolkit that automatically extracts and aligns
narrative events in the temporal order of their occurrence using sliding window
method. Through extensive human evaluations, we have confirmed the high quality
of the NECE toolkit, and external validation has demonstrated its potential for
application in downstream tasks such as question answering and bias analysis.
The NECE toolkit includes both a Python library and a user-friendly web
interface; the latter offers custom visualizations of event chains and easy
navigation between graphics and text to improve reading efficiency and
experience.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Construction and Applications of Billion-Scale Pre-trained Multimodal Business Knowledge Graph. (arXiv:2209.15214v5 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.15214">
<div class="article-summary-box-inner">
<span><p>Business Knowledge Graphs (KGs) are important to many enterprises today,
providing factual knowledge and structured data that steer many products and
make them more intelligent. Despite their promising benefits, building business
KG necessitates solving prohibitive issues of deficient structure and multiple
modalities. In this paper, we advance the understanding of the practical
challenges related to building KG in non-trivial real-world systems. We
introduce the process of building an open business knowledge graph (OpenBG)
derived from a well-known enterprise, Alibaba Group. Specifically, we define a
core ontology to cover various abstract products and consumption demands, with
fine-grained taxonomy and multimodal facts in deployed applications. OpenBG is
an open business KG of unprecedented scale: 2.6 billion triples with more than
88 million entities covering over 1 million core classes/concepts and 2,681
types of relations. We release all the open resources (OpenBG benchmarks)
derived from it for the community and report experimental results of KG-centric
tasks. We also run up an online competition based on OpenBG benchmarks, and has
attracted thousands of teams. We further pre-train OpenBG and apply it to many
KG- enhanced downstream tasks in business scenarios, demonstrating the
effectiveness of billion-scale multimodal knowledge for e-commerce. All the
resources with codes have been released at
\url{https://github.com/OpenBGBenchmark/OpenBG}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PQLM -- Multilingual Decentralized Portable Quantum Language Model for Privacy Protection. (arXiv:2210.03221v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.03221">
<div class="article-summary-box-inner">
<span><p>With careful manipulation, malicious agents can reverse engineer private
information encoded in pre-trained language models. Security concerns motivate
the development of quantum pre-training. In this work, we propose a highly
Portable Quantum Language Model (PQLM) that can easily transmit information to
downstream tasks on classical machines. The framework consists of a cloud PQLM
built with random Variational Quantum Classifiers (VQC) and local models for
downstream applications. We demonstrate the ad hoc portability of the quantum
model by extracting only the word embeddings and effectively applying them to
downstream tasks on classical machines. Our PQLM exhibits comparable
performance to its classical counterpart on both intrinsic evaluation (loss,
perplexity) and extrinsic evaluation (multilingual sentiment analysis accuracy)
metrics. We also perform ablation studies on the factors affecting PQLM
performance to analyze model stability. Our work establishes a theoretical
foundation for a portable quantum pre-trained language model that could be
trained on private data and made available for public use with privacy
protection guarantees.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Segmentation Approaches for Neural Machine Translation of Code-Switched Egyptian Arabic-English Text. (arXiv:2210.06990v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06990">
<div class="article-summary-box-inner">
<span><p>Data sparsity is one of the main challenges posed by code-switching (CS),
which is further exacerbated in the case of morphologically rich languages. For
the task of machine translation (MT), morphological segmentation has proven
successful in alleviating data sparsity in monolingual contexts; however, it
has not been investigated for CS settings. In this paper, we study the
effectiveness of different segmentation approaches on MT performance, covering
morphology-based and frequency-based segmentation techniques. We experiment on
MT from code-switched Arabic-English to English. We provide detailed analysis,
examining a variety of conditions, such as data size and sentences with
different degrees of CS. Empirical results show that morphology-aware
segmenters perform the best in segmentation tasks but under-perform in MT.
Nevertheless, we find that the choice of the segmentation setup to use for MT
is highly dependent on the data size. For extreme low-resource scenarios, a
combination of frequency and morphology-based segmentations is shown to perform
the best. For more resourced settings, such a combination does not bring
significant improvements over the use of frequency-based segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task. (arXiv:2210.13382v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.13382">
<div class="article-summary-box-inner">
<span><p>Language models show a surprising range of capabilities, but the source of
their apparent competence is unclear. Do these networks just memorize a
collection of surface statistics, or do they rely on internal representations
of the process that generates the sequences they see? We investigate this
question by applying a variant of the GPT model to the task of predicting legal
moves in a simple board game, Othello. Although the network has no a priori
knowledge of the game or its rules, we uncover evidence of an emergent
nonlinear internal representation of the board state. Interventional
experiments indicate this representation can be used to control the output of
the network and create "latent saliency maps" that can help explain predictions
in human terms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Kernels and Channel Attention for Low Resource Speaker Verification. (arXiv:2211.02000v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.02000">
<div class="article-summary-box-inner">
<span><p>State-of-the-art speaker verification frameworks have typically focused on
developing models with increasingly deeper (more layers) and wider (number of
channels) models to improve their verification performance. Instead, this paper
proposes an approach to increase the model resolution capability using
attention-based dynamic kernels in a convolutional neural network to adapt the
model parameters to be feature-conditioned. The attention weights on the
kernels are further distilled by channel attention and multi-layer feature
aggregation to learn global features from speech. This approach provides an
efficient solution to improving representation capacity with lower data
resources. This is due to the self-adaptation to inputs of the structures of
the model parameters. The proposed dynamic convolutional model achieved 1.62\%
EER and 0.18 miniDCF on the VoxCeleb1 test set and has a 17\% relative
improvement compared to the ECAPA-TDNN using the same training resources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VieCap4H-VLSP 2021: ObjectAoA -- Enhancing performance of Object Relation Transformer with Attention on Attention for Vietnamese image captioning. (arXiv:2211.05405v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.05405">
<div class="article-summary-box-inner">
<span><p>Image captioning is currently a challenging task that requires the ability to
both understand visual information and use human language to describe this
visual information in the image. In this paper, we propose an efficient way to
improve the image understanding ability of transformer-based method by
extending Object Relation Transformer architecture with Attention on Attention
mechanism. Experiments on the VieCap4H dataset show that our proposed method
significantly outperforms its original structure on both the public test and
private test of the Image Captioning shared task held by VLSP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discharge Summary Hospital Course Summarisation of In Patient Electronic Health Record Text with Clinical Concept Guided Deep Pre-Trained Transformer Models. (arXiv:2211.07126v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.07126">
<div class="article-summary-box-inner">
<span><p>Brief Hospital Course (BHC) summaries are succinct summaries of an entire
hospital encounter, embedded within discharge summaries, written by senior
clinicians responsible for the overall care of a patient. Methods to
automatically produce summaries from inpatient documentation would be
invaluable in reducing clinician manual burden of summarising documents under
high time-pressure to admit and discharge patients. Automatically producing
these summaries from the inpatient course, is a complex, multi-document
summarisation task, as source notes are written from various perspectives (e.g.
nursing, doctor, radiology), during the course of the hospitalisation. We
demonstrate a range of methods for BHC summarisation demonstrating the
performance of deep learning summarisation models across extractive and
abstractive summarisation scenarios. We also test a novel ensemble extractive
and abstractive summarisation model that incorporates a medical concept
ontology (SNOMED) as a clinical guidance signal and shows superior performance
in 2 real-world clinical data sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Modal Mutual Learning for Cued Speech Recognition. (arXiv:2212.01083v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01083">
<div class="article-summary-box-inner">
<span><p>Automatic Cued Speech Recognition (ACSR) provides an intelligent
human-machine interface for visual communications, where the Cued Speech (CS)
system utilizes lip movements and hand gestures to code spoken language for
hearing-impaired people. Previous ACSR approaches often utilize direct feature
concatenation as the main fusion paradigm. However, the asynchronous modalities
i.e., lip, hand shape and hand position) in CS may cause interference for
feature concatenation. To address this challenge, we propose a transformer
based cross-modal mutual learning framework to prompt multi-modal interaction.
Compared with the vanilla self-attention, our model forces modality-specific
information of different modalities to pass through a modality-invariant
codebook, collating linguistic representations for tokens of each modality.
Then the shared linguistic knowledge is used to re-synchronize multi-modal
sequences. Moreover, we establish a novel large-scale multi-speaker CS dataset
for Mandarin Chinese. To our knowledge, this is the first work on ACSR for
Mandarin Chinese. Extensive experiments are conducted for different languages
i.e., Chinese, French, and British English). Results demonstrate that our model
exhibits superior recognition performance to the state-of-the-art by a large
margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Knowledge Graph Reasoning on Graph Types: Static, Dynamic, and Multimodal. (arXiv:2212.05767v6 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.05767">
<div class="article-summary-box-inner">
<span><p>Knowledge graph reasoning (KGR), aiming to deduce new facts from existing
facts based on mined logic rules underlying knowledge graphs (KGs), has become
a fast-growing research direction. It has been proven to significantly benefit
the usage of KGs in many AI applications, such as question answering and
recommendation systems, etc. According to the graph types, the existing KGR
models can be roughly divided into three categories, i.e., static models,
temporal models, and multi-modal models. The early works in this domain mainly
focus on static KGR and tend to directly apply general knowledge graph
embedding models to the reasoning task. However, these models are not suitable
for more complex but practical tasks, such as inductive static KGR, temporal
KGR, and multi-modal KGR. To this end, multiple works have been developed
recently, but no survey papers and open-source repositories comprehensively
summarize and discuss models in this important direction. To fill the gap, we
conduct a survey for knowledge graph reasoning tracing from static to temporal
and then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR
models, and typical datasets are introduced and discussed consequently.
Moreover, we discuss the challenges and potential opportunities. The
corresponding open-source repository is shared on GitHub:
https://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analysing Discrete Self Supervised Speech Representation for Spoken Language Modeling. (arXiv:2301.00591v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.00591">
<div class="article-summary-box-inner">
<span><p>This work profoundly analyzes discrete self-supervised speech representations
through the eyes of Generative Spoken Language Modeling (GSLM). Following the
findings of such an analysis, we propose practical improvements to the discrete
unit for the GSLM. First, we start comprehending these units by analyzing them
in three axes: interpretation, visualization, and resynthesis. Our analysis
finds a high correlation between the speech units to phonemes and phoneme
families, while their correlation with speaker or gender is weaker.
Additionally, we found redundancies in the extracted units and claim that one
reason may be the units' context. Following this analysis, we propose a new,
unsupervised metric to measure unit redundancies. Finally, we use this metric
to develop new methods that improve the robustness of units clustering and show
significant improvement considering zero-resource speech metrics such as ABX.
Code and analysis tools are available under the following link.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Conversational Search Behavior For Domain Exploration. (arXiv:2301.04098v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.04098">
<div class="article-summary-box-inner">
<span><p>Conversational search has evolved as a new information retrieval paradigm,
marking a shift from traditional search systems towards interactive dialogues
with intelligent search agents. This change especially affects exploratory
information-seeking contexts, where conversational search systems can guide the
discovery of unfamiliar domains. In these scenarios, users find it often
difficult to express their information goals due to insufficient background
knowledge. Conversational interfaces can provide assistance by eliciting
information needs and narrowing down the search space. However, due to the
complexity of information-seeking behavior, the design of conversational
interfaces for retrieving information remains a great challenge. Although prior
work has employed user studies to empirically ground the system design, most
existing studies are limited to well-defined search tasks or known domains,
thus being less exploratory in nature. Therefore, we conducted a laboratory
study to investigate open-ended search behavior for navigation through unknown
information landscapes. The study comprised of 26 participants who were
restricted in their search to a text chat interface. Based on the collected
dialogue transcripts, we applied statistical analyses and process mining
techniques to uncover general information-seeking patterns across five
different domains. We not only identify core dialogue acts and their
interrelations that enable users to discover domain knowledge, but also derive
design suggestions for conversational search systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Memorize Entailment and Discourse Relations for Persona-Consistent Dialogues. (arXiv:2301.04871v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.04871">
<div class="article-summary-box-inner">
<span><p>Maintaining engagement and consistency is particularly important in dialogue
systems. Existing works have improved the performance of dialogue systems by
intentionally learning interlocutor personas with sophisticated network
structures. One issue with this approach is that it requires more personal
corpora with annotations. Additionally, these models typically perform the next
utterance prediction to generate a response but neglect the discourse coherence
in the entire conversation. To address these issues, this study proposes a
method of learning to memorize entailment and discourse relations for
persona-consistent dialogue tasks. Entailment text pairs in natural language
inference dataset were applied to learn latent entailment relations as external
memories by premise-to-hypothesis generation task. Furthermore, an internal
memory with a similar architecture was applied to the discourse information in
the dialogue. Placing orthogonality restrictions on these two memory spaces
ensures that the latent entailment relations remain dialogue-independent. Both
memories collaborate to obtain entailment and discourse representation for the
generation, allowing a deeper understanding of both consistency and coherence.
Experiments on two large public datasets, PersonaChat and DSTC7-AVSD,
demonstrated the effectiveness of the proposed method. Both automatic and human
evaluations indicate that the proposed model outperforms several strong
baselines in terms of both persona consistency and response coherence. Our
source code is available at https://github.com/Chenrj233/LMEDR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding and Detecting Hallucinations in Neural Machine Translation via Model Introspection. (arXiv:2301.07779v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07779">
<div class="article-summary-box-inner">
<span><p>Neural sequence generation models are known to "hallucinate", by producing
outputs that are unrelated to the source text. These hallucinations are
potentially harmful, yet it remains unclear in what conditions they arise and
how to mitigate their impact. In this work, we first identify internal model
symptoms of hallucinations by analyzing the relative token contributions to the
generation in contrastive hallucinated vs. non-hallucinated outputs generated
via source perturbations. We then show that these symptoms are reliable
indicators of natural hallucinations, by using them to design a lightweight
hallucination detector which outperforms both model-free baselines and strong
classifiers based on quality estimation or large pre-trained models on manually
annotated English-Chinese and German-English translation test beds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Heterogeneous Federated Knowledge Graph Embedding Learning and Unlearning. (arXiv:2302.02069v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.02069">
<div class="article-summary-box-inner">
<span><p>Federated Learning (FL) recently emerges as a paradigm to train a global
machine learning model across distributed clients without sharing raw data.
Knowledge Graph (KG) embedding represents KGs in a continuous vector space,
serving as the backbone of many knowledge-driven applications. As a promising
combination, federated KG embedding can fully take advantage of knowledge
learned from different clients while preserving the privacy of local data.
However, realistic problems such as data heterogeneity and knowledge forgetting
still remain to be concerned. In this paper, we propose FedLU, a novel FL
framework for heterogeneous KG embedding learning and unlearning. To cope with
the drift between local optimization and global convergence caused by data
heterogeneity, we propose mutual knowledge distillation to transfer local
knowledge to global, and absorb global knowledge back. Moreover, we present an
unlearning method based on cognitive neuroscience, which combines retroactive
interference and passive decay to erase specific knowledge from local clients
and propagate to the global model by reusing knowledge distillation. We
construct new datasets for assessing realistic performance of the
state-of-the-arts. Extensive experiments show that FedLU achieves superior
results in both link prediction and knowledge forgetting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chain of Hindsight Aligns Language Models with Feedback. (arXiv:2302.02676v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.02676">
<div class="article-summary-box-inner">
<span><p>Learning from human preferences is important for language models to be
helpful and useful for humans, and to align with human and social values. Prior
work have achieved remarkable successes by learning from human feedback to
understand and follow instructions. Nonetheless, these methods are either
founded on hand-picked model generations that are favored by human annotators,
rendering them ineffective in terms of data utilization and challenging to
apply in general, or they depend on reward functions and reinforcement
learning, which are prone to imperfect reward function and extremely
challenging to optimize. In this work, we propose a novel technique, Chain of
Hindsight, that is easy to optimize and can learn from any form of feedback,
regardless of its polarity. Our idea is inspired by how humans learn from
extensive feedback presented in the form of languages. We convert all types of
feedback into sentences, which are then used to fine-tune the model, allowing
us to take advantage of the language comprehension capabilities of language
models. We condition the model on a sequence of model generations paired with
feedback. By doing so, models are trained to generate outputs based on
feedback, and models can learn to identify and correct negative attributes or
errors. Applying our method to large language models, we observed that Chain of
Hindsight significantly surpasses previous methods in aligning language models
with human preferences. We observed significant improvements on summarization
and dialogue tasks and our approach is markedly preferred in human evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks. (arXiv:2302.08043v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08043">
<div class="article-summary-box-inner">
<span><p>Graphs can model complex relationships between objects, enabling a myriad of
Web applications such as online page/article classification and social
recommendation. While graph neural networks(GNNs) have emerged as a powerful
tool for graph representation learning, in an end-to-end supervised setting,
their performance heavily rely on a large amount of task-specific supervision.
To reduce labeling requirement, the "pre-train, fine-tune" and "pre-train,
prompt" paradigms have become increasingly common. In particular, prompting is
a popular alternative to fine-tuning in natural language processing, which is
designed to narrow the gap between pre-training and downstream objectives in a
task-specific manner. However, existing study of prompting on graphs is still
limited, lacking a universal treatment to appeal to different downstream tasks.
In this paper, we propose GraphPrompt, a novel pre-training and prompting
framework on graphs. GraphPrompt not only unifies pre-training and downstream
tasks into a common task template, but also employs a learnable prompt to
assist a downstream task in locating the most relevant knowledge from the
pre-train model in a task-specific manner. Finally, we conduct extensive
experiments on five public datasets to evaluate and analyze GraphPrompt.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks. (arXiv:2302.08399v4 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08399">
<div class="article-summary-box-inner">
<span><p>Intuitive psychology is a pillar of common-sense reasoning. The replication
of this reasoning in machine intelligence is an important stepping-stone on the
way to human-like artificial intelligence. Several recent tasks and benchmarks
for examining this reasoning in Large-Large Models have focused in particular
on belief attribution in Theory-of-Mind tasks. These tasks have shown both
successes and failures. We consider in particular a recent purported success
case, and show that small variations that maintain the principles of ToM turn
the results on their head. We argue that in general, the zero-hypothesis for
model evaluation in intuitive psychology should be skeptical, and that outlying
failure cases should outweigh average success rates. We also consider what
possible future successes on Theory-of-Mind tasks by more powerful LLMs would
mean for ToM tasks with people.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BBT-Fin: Comprehensive Construction of Chinese Financial Domain Pre-trained Language Model, Corpus and Benchmark. (arXiv:2302.09432v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.09432">
<div class="article-summary-box-inner">
<span><p>To advance Chinese financial natural language processing (NLP), we introduce
BBT-FinT5, a new Chinese financial pre-training language model based on the T5
model. To support this effort, we have built BBT-FinCorpus, a large-scale
financial corpus with approximately 300GB of raw text from four different
sources. In general domain NLP, comprehensive benchmarks like GLUE and
SuperGLUE have driven significant advancements in language model pre-training
by enabling head-to-head comparisons among models. Drawing inspiration from
these benchmarks, we propose BBT-CFLEB, a Chinese Financial Language
understanding and generation Evaluation Benchmark, which includes six datasets
covering both understanding and generation tasks. Our aim is to facilitate
research in the development of NLP within the Chinese financial domain. Our
model, corpus and benchmark are released at
https://github.com/ssymmetry/BBT-FinCUGE-Applications. Our work belongs to the
Big Bang Transformer (BBT), a large-scale pre-trained language model project.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">E2E Spoken Entity Extraction for Virtual Agents. (arXiv:2302.10186v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10186">
<div class="article-summary-box-inner">
<span><p>This paper reimagines some aspects of speech processing using speech
encoders, specifically about extracting entities directly from speech, with no
intermediate textual representation. In human-computer conversations,
extracting entities such as names, postal addresses and email addresses from
speech is a challenging task. In this paper, we study the impact of fine-tuning
pre-trained speech encoders on extracting spoken entities in human-readable
form directly from speech without the need for text transcription. We
illustrate that such a direct approach optimizes the encoder to transcribe only
the entity relevant portions of speech, ignoring the superfluous portions such
as carrier phrases and spellings of entities. In the context of dialogs from an
enterprise virtual agent, we demonstrate that the 1-step approach outperforms
the typical 2-step cascade of first generating lexical transcriptions followed
by text-based entity extraction for identifying spoken entities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Pre-trained Vision and Language Models Answer Visual Information-Seeking Questions?. (arXiv:2302.11713v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11713">
<div class="article-summary-box-inner">
<span><p>Large language models have demonstrated an emergent capability in answering
knowledge intensive questions. With recent progress on web-scale visual and
language pre-training, do these models also understand how to answer visual
information seeking questions? To answer this question, we present InfoSeek, a
Visual Question Answering dataset that focuses on asking information-seeking
questions, where the information can not be answered by common sense knowledge.
We perform a multi-stage human annotation to collect a natural distribution of
high-quality visual information seeking question-answer pairs. We also
construct a large-scale, automatically collected dataset by combining existing
visual entity recognition datasets and Wikidata, which provides over one
million examples for model fine-tuning and validation. Based on InfoSeek, we
analyzed various pre-trained Visual QA systems to gain insights into the
characteristics of different pre-trained models. Our analysis shows that it is
challenging for the state-of-the-art multi-modal pre-trained models to answer
visual information seeking questions, but this capability is improved through
fine-tuning on the automated InfoSeek dataset. We hope our analysis paves the
way to understand and develop the next generation of multi-modal pre-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective. (arXiv:2302.12095v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12095">
<div class="article-summary-box-inner">
<span><p>ChatGPT is a recent chatbot service released by OpenAI and is receiving
increasing attention over the past few months. While evaluations of various
aspects of ChatGPT have been done, its robustness, i.e., the performance to
unexpected inputs, is still unclear to the public. Robustness is of particular
concern in responsible AI, especially for safety-critical applications. In this
paper, we conduct a thorough evaluation of the robustness of ChatGPT from the
adversarial and out-of-distribution (OOD) perspective. To do so, we employ the
AdvGLUE and ANLI benchmarks to assess adversarial robustness and the Flipkart
review and DDXPlus medical diagnosis datasets for OOD evaluation. We select
several popular foundation models as baselines. Results show that ChatGPT shows
consistent advantages on most adversarial and OOD classification and
translation tasks. However, the absolute performance is far from perfection,
which suggests that adversarial and OOD robustness remains a significant threat
to foundation models. Moreover, ChatGPT shows astounding performance in
understanding dialogue-related texts and we find that it tends to provide
informal suggestions for medical tasks instead of definitive answers. Finally,
we present in-depth discussions of possible research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Prompting with Chain-of-Thought for Large Language Models. (arXiv:2302.12246v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12246">
<div class="article-summary-box-inner">
<span><p>The increasing scale of large language models (LLMs) brings emergent
abilities to various complex tasks requiring reasoning, such as arithmetic and
commonsense reasoning. It is known that the effective design of task-specific
prompts is critical for LLMs' ability to produce high-quality answers. In
particular, an effective approach for complex question-and-answer tasks is
example-based prompting with chain-of-thought (CoT) reasoning, which
significantly improves the performance of LLMs. However, current CoT methods
rely on a fixed set of human-annotated exemplars, which are not necessarily the
most effective examples for different tasks. This paper proposes a new method,
Active-Prompt, to adapt LLMs to different tasks with task-specific example
prompts (annotated with human-designed CoT reasoning). For this purpose, we
propose a solution to the key problem of determining which questions are the
most important and helpful ones to annotate from a pool of task-specific
queries. By borrowing ideas from the related problem of uncertainty-based
active learning, we introduce several metrics to characterize the uncertainty
so as to select the most uncertain questions for annotation. Experimental
results demonstrate the superiority of our proposed method, achieving
state-of-the-art on eight complex reasoning tasks. Further analyses of
different uncertainty metrics, pool sizes, zero-shot learning, and
accuracy-uncertainty relationship demonstrate the effectiveness of our method.
Our code will be available at https://github.com/shizhediao/active-prompt.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Testing AI performance on less frequent aspects of language reveals insensitivity to underlying meaning. (arXiv:2302.12313v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12313">
<div class="article-summary-box-inner">
<span><p>Advances in computational methods and big data availability have recently
translated into breakthroughs in AI applications. With successes in bottom-up
challenges partially overshadowing shortcomings, the 'human-like' performance
of Large Language Models has raised the question of how linguistic performance
is achieved by algorithms. Given systematic shortcomings in generalization
across many AI systems, in this work we ask whether linguistic performance is
indeed guided by language knowledge in Large Language Models. To this end, we
prompt GPT-3 with a grammaticality judgement task and comprehension questions
on less frequent constructions that are thus unlikely to form part of Large
Language Models' training data. These included grammatical 'illusions',
semantic anomalies, complex nested hierarchies and self-embeddings. GPT-3
failed for every prompt but one, often offering answers that show a critical
lack of understanding even of high-frequency words used in these less frequent
grammatical constructions. The present work sheds light on the boundaries of
the alleged AI human-like linguistic competence and argues that, far from
human-like, the next-word prediction abilities of LLMs may face issues of
robustness, when pushed beyond training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models are Few-shot Learners for Prognostic Prediction. (arXiv:2302.12692v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12692">
<div class="article-summary-box-inner">
<span><p>Clinical prediction is an essential task in the healthcare industry. However,
the recent success of transformers, on which large language models are built,
has not been extended to this domain. In this research, we explore the use of
transformers and language models in prognostic prediction for immunotherapy
using real-world patients' clinical data and molecular profiles. This paper
investigates the potential of transformers to improve clinical prediction
compared to conventional machine learning approaches and addresses the
challenge of few-shot learning in predicting rare disease areas. The study
benchmarks the efficacy of baselines and language models on prognostic
prediction across multiple cancer types and investigates the impact of
different pretrained language models under few-shot regimes. The results
demonstrate significant improvements in accuracy and highlight the potential of
NLP in clinical research to improve early detection and intervention for
different diseases. Anonymous codes are available at
\url{https://anonymous.4open.science/r/table2text-88ED}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Lingual Transfer of Cognitive Processing Complexity. (arXiv:2302.12695v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12695">
<div class="article-summary-box-inner">
<span><p>When humans read a text, their eye movements are influenced by the structural
complexity of the input sentences. This cognitive phenomenon holds across
languages and recent studies indicate that multilingual language models utilize
structural similarities between languages to facilitate cross-lingual transfer.
We use sentence-level eye-tracking patterns as a cognitive indicator for
structural complexity and show that the multilingual model XLM-RoBERTa can
successfully predict varied patterns for 13 typologically diverse languages,
despite being fine-tuned only on English data. We quantify the sensitivity of
the model to structural complexity and distinguish a range of complexity
characteristics. Our results indicate that the model develops a meaningful bias
towards sentence length but also integrates cross-lingual differences. We
conduct a control experiment with randomized word order and find that the model
seems to additionally capture more complex structural information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Massively Multilingual ASR With Auxiliary CTC Objectives. (arXiv:2302.12829v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12829">
<div class="article-summary-box-inner">
<span><p>Multilingual Automatic Speech Recognition (ASR) models have extended the
usability of speech technologies to a wide variety of languages. With how many
languages these models have to handle, however, a key to understanding their
imbalanced performance across different languages is to examine if the model
actually knows which language it should transcribe. In this paper, we introduce
our work on improving performance on FLEURS, a 102-language open ASR benchmark,
by conditioning the entire model on language identity (LID). We investigate
techniques inspired from recent Connectionist Temporal Classification (CTC)
studies to help the model handle the large number of languages, conditioning on
the LID predictions of auxiliary tasks. Our experimental results demonstrate
the effectiveness of our technique over standard CTC/Attention-based hybrid
models. Furthermore, our state-of-the-art systems using self-supervised models
with the Conformer architecture improve over the results of prior work on
FLEURS by a relative 28.4% CER. Trained models and reproducible recipes are
available at https://github.com/espnet/espnet/tree/master/egs2/fleurs/asr1 .
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-02-28 23:13:27.534579994 UTC">2023-02-28 23:13:27 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>