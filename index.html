<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-05-09T01:30:00Z">05-09</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing Working Memory Capacity of ChatGPT. (arXiv:2305.03731v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03731">
<div class="article-summary-box-inner">
<span><p>Working memory is a critical aspect of both human intelligence and artificial
intelligence (AI), serving as a workspace for the temporary storage and
manipulation of information. This paper investigates working memory capacity of
ChatGPT, a state-of-the-art language model, by examining its performance on
N-back tasks. We begin by discussing the importance of working memory to humans
and AI, followed by the methods employed to assess working memory capacity of
ChatGPT. Our study compares behavioral performance of ChatGPT on verbal and
spatial N-back tasks to that of human participants reported in the literature,
revealing notable similarities. Our findings offer crucial insights into the
current progress in designing AI systems with human-level cognitive abilities
and hold promise for informing future endeavors aimed at enhancing AI working
memory and understanding human working memory through AI models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tuning Traditional Language Processing Approaches for Pashto Text Classification. (arXiv:2305.03737v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03737">
<div class="article-summary-box-inner">
<span><p>Today text classification becomes critical task for concerned individuals for
numerous purposes. Hence, several researches have been conducted to develop
automatic text classification for national and international languages.
However, the need for an automatic text categorization system for local
languages is felt. The main aim of this study is to establish a Pashto
automatic text classification system. In order to pursue this work, we built a
Pashto corpus which is a collection of Pashto documents due to the
unavailability of public datasets of Pashto text documents. Besides, this study
compares several models containing both statistical and neural network machine
learning techniques including Multilayer Perceptron (MLP), Support Vector
Machine (SVM), K Nearest Neighbor (KNN), decision tree, gaussian na\"ive Bayes,
multinomial na\"ive Bayes, random forest, and logistic regression to discover
the most effective approach. Moreover, this investigation evaluates two
different feature extraction methods including unigram, and Time Frequency
Inverse Document Frequency (IFIDF). Subsequently, this research obtained
average testing accuracy rate 94% using MLP classification algorithm and TFIDF
feature extraction method in this context.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming. (arXiv:2305.03742v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03742">
<div class="article-summary-box-inner">
<span><p>Pre-trained large language models (LMs) struggle to perform logical reasoning
reliably despite advances in scale and compositionality. In this work, we
tackle this challenge through the lens of symbolic programming. We propose
DSR-LM, a Differentiable Symbolic Reasoning framework where pre-trained LMs
govern the perception of factual knowledge, and a symbolic module performs
deductive reasoning. In contrast to works that rely on hand-crafted logic
rules, our differentiable symbolic reasoning framework efficiently learns
weighted rules and applies semantic loss to further improve LMs. DSR-LM is
scalable, interpretable, and allows easy integration of prior knowledge,
thereby supporting extensive symbolic programming to robustly derive a logical
conclusion. The results of our experiments suggest that DSR-LM improves the
logical reasoning abilities of pre-trained language models, resulting in a
significant increase in accuracy of over 20% on deductive reasoning benchmarks.
Furthermore, DSR-LM outperforms a variety of competitive baselines when faced
with systematic changes in sequence length.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Harnessing the Power of BERT in the Turkish Clinical Domain: Pretraining Approaches for Limited Data Scenarios. (arXiv:2305.03788v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03788">
<div class="article-summary-box-inner">
<span><p>In recent years, major advancements in natural language processing (NLP) have
been driven by the emergence of large language models (LLMs), which have
significantly revolutionized research and development within the field.
Building upon this progress, our study delves into the effects of various
pre-training methodologies on Turkish clinical language models' performance in
a multi-label classification task involving radiology reports, with a focus on
addressing the challenges posed by limited language resources. Additionally, we
evaluated the simultaneous pretraining approach by utilizing limited clinical
task data for the first time. We developed four models, including
TurkRadBERT-task v1, TurkRadBERT-task v2, TurkRadBERT-sim v1, and
TurkRadBERT-sim v2. Our findings indicate that the general Turkish BERT model
(BERTurk) and TurkRadBERT-task v1, both of which utilize knowledge from a
substantial general-domain corpus, demonstrate the best overall performance.
Although the task-adaptive pre-training approach has the potential to capture
domain-specific patterns, it is constrained by the limited task-specific corpus
and may be susceptible to overfitting. Furthermore, our results underscore the
significance of domain-specific vocabulary during pre-training for enhancing
model performance. Ultimately, we observe that the combination of
general-domain knowledge and task-specific fine-tuning is essential for
achieving optimal performance across a range of categories. This study offers
valuable insights for developing effective Turkish clinical language models and
can guide future research on pre-training techniques for other low-resource
languages within the clinical domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Zero-Shot Frame Semantic Parsing with Task Agnostic Ontologies and Simple Labels. (arXiv:2305.03793v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03793">
<div class="article-summary-box-inner">
<span><p>Frame semantic parsing is an important component of task-oriented dialogue
systems. Current models rely on a significant amount training data to
successfully identify the intent and slots in the user's input utterance. This
creates a significant barrier for adding new domains to virtual assistant
capabilities, as creation of this data requires highly specialized NLP
expertise. In this work we propose OpenFSP, a framework that allows for easy
creation of new domains from a handful of simple labels that can be generated
without specific NLP knowledge. Our approach relies on creating a small, but
expressive, set of domain agnostic slot types that enables easy annotation of
new domains. Given such annotation, a matching algorithm relying on sentence
encoders predicts the intent and slots for domains defined by end-users.
Extensive experiments on the TopV2 dataset shows that our model outperforms
strong baselines in this simple labels setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation. (arXiv:2305.03796v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03796">
<div class="article-summary-box-inner">
<span><p>Unlike recurrent models, conventional wisdom has it that Transformers cannot
perfectly model regular languages. Inspired by the notion of working memory, we
propose a new Transformer variant named RegularGPT. With its novel combination
of Weight-Sharing, Adaptive-Depth, and Sliding-Dilated-Attention, RegularGPT
constructs working memory along the depth dimension, thereby enabling efficient
and successful modeling of regular languages such as PARITY. We further test
RegularGPT on the task of natural language length extrapolation and
surprisingly find that it rediscovers the local windowed attention effect
deemed necessary in prior work for length extrapolation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adapting Transformer Language Models for Predictive Typing in Brain-Computer Interfaces. (arXiv:2305.03819v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03819">
<div class="article-summary-box-inner">
<span><p>Brain-computer interfaces (BCI) are an important mode of alternative and
augmentative communication for many people. Unlike keyboards, many BCI systems
do not display even the 26 letters of English at one time, let alone all the
symbols in more complex systems. Using language models to make character-level
predictions, therefore, can greatly speed up BCI typing (Ghosh and Kristensson,
2017). While most existing BCI systems employ character n-gram models or no LM
at all, this paper adapts several wordpiece-level Transformer LMs to make
character predictions and evaluates them on typing tasks. GPT-2 fares best on
clean text, but different LMs react differently to noisy histories. We further
analyze the effect of character positions in a word and context lengths.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty-Aware Bootstrap Learning for Joint Extraction on Distantly-Supervised Data. (arXiv:2305.03827v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03827">
<div class="article-summary-box-inner">
<span><p>Jointly extracting entity pairs and their relations is challenging when
working on distantly-supervised data with ambiguous or noisy labels. To
mitigate such impact, we propose uncertainty-aware bootstrap learning, which is
motivated by the intuition that the higher uncertainty of an instance, the more
likely the model confidence is inconsistent with the ground truths.
Specifically, we first explore instance-level data uncertainty to create an
initial high-confident examples. Such subset serves as filtering noisy
instances and facilitating the model to converge fast at the early stage.
During bootstrap learning, we propose self-ensembling as a regularizer to
alleviate inter-model uncertainty produced by noisy labels. We further define
probability variance of joint tagging probabilities to estimate inner-model
parametric uncertainty, which is used to select and build up new reliable
training instances for the next iteration. Experimental results on two large
datasets reveal that our approach outperforms existing strong baselines and
related methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLaC at SemEval-2023 Task 2: Comparing Span-Prediction and Sequence-Labeling approaches for NER. (arXiv:2305.03845v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03845">
<div class="article-summary-box-inner">
<span><p>This paper summarizes the CLaC submission for the MultiCoNER 2 task which
concerns the recognition of complex, fine-grained named entities. We compare
two popular approaches for NER, namely Sequence Labeling and Span Prediction.
We find that our best Span Prediction system performs slightly better than our
best Sequence Labeling system on test data. Moreover, we find that using the
larger version of XLM RoBERTa significantly improves performance.
Post-competition experiments show that Span Prediction and Sequence Labeling
approaches improve when they use special input tokens (&lt;s&gt; and &lt;/s&gt;) of
XLM-RoBERTa. The code for training all models, preprocessing, and
post-processing is available at
https://github.com/harshshredding/semeval2023-multiconer-paper.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models in Sport Science & Medicine: Opportunities, Risks and Considerations. (arXiv:2305.03851v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03851">
<div class="article-summary-box-inner">
<span><p>This paper explores the potential opportunities, risks, and challenges
associated with the use of large language models (LLMs) in sports science and
medicine. LLMs are large neural networks with transformer style architectures
trained on vast amounts of textual data, and typically refined with human
feedback. LLMs can perform a large range of natural language processing tasks.
In sports science and medicine, LLMs have the potential to support and augment
the knowledge of sports medicine practitioners, make recommendations for
personalised training programs, and potentially distribute high-quality
information to practitioners in developing countries. However, there are also
potential risks associated with the use and development of LLMs, including
biases in the dataset used to create the model, the risk of exposing
confidential data, the risk of generating harmful output, and the need to align
these models with human preferences through feedback. Further research is
needed to fully understand the potential applications of LLMs in sports science
and medicine and to ensure that their use is ethical and beneficial to
athletes, clients, patients, practitioners, and the general public.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages. (arXiv:2305.03873v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03873">
<div class="article-summary-box-inner">
<span><p>In many humanitarian scenarios, translation into severely low resource
languages often does not require a universal translation engine, but a
dedicated text-specific translation engine. For example, healthcare records,
hygienic procedures, government communication, emergency procedures and
religious texts are all limited texts. While generic translation engines for
all languages do not exist, translation of multilingually known limited texts
into new, endangered languages may be possible and reduce human translation
effort. We attempt to leverage translation resources from many rich resource
languages to efficiently produce best possible translation quality for a well
known text, which is available in multiple languages, in a new, severely low
resource language. We examine two approaches: 1. best selection of seed
sentences to jump start translations in a new language in view of best
generalization to the remainder of a larger targeted text(s), and 2. we adapt
large general multilingual translation engines from many other languages to
focus on a specific text in a new, unknown language. We find that adapting
large pretrained multilingual models to the domain/text first and then to the
severely low resource language works best. If we also select a best set of seed
sentences, we can improve average chrF performance on new test languages from a
baseline of 21.9 to 50.7, while reducing the number of seed sentences to only
around 1,000 in the new, unknown language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NorBench -- A Benchmark for Norwegian Language Models. (arXiv:2305.03880v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03880">
<div class="article-summary-box-inner">
<span><p>We present NorBench: a streamlined suite of NLP tasks and probes for
evaluating Norwegian language models (LMs) on standardized data splits and
evaluation metrics. We also introduce a range of new Norwegian language models
(both encoder and encoder-decoder based). Finally, we compare and analyze their
performance, along with other existing LMs, across the different benchmark
tests of NorBench.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fairness in Image Search: A Study of Occupational Stereotyping in Image Retrieval and its Debiasing. (arXiv:2305.03881v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03881">
<div class="article-summary-box-inner">
<span><p>Multi-modal search engines have experienced significant growth and widespread
use in recent years, making them the second most common internet use. While
search engine systems offer a range of services, the image search field has
recently become a focal point in the information retrieval community, as the
adage goes, "a picture is worth a thousand words". Although popular search
engines like Google excel at image search accuracy and agility, there is an
ongoing debate over whether their search results can be biased in terms of
gender, language, demographics, socio-cultural aspects, and stereotypes. This
potential for bias can have a significant impact on individuals' perceptions
and influence their perspectives.
</p>
<p>In this paper, we present our study on bias and fairness in web search, with
a focus on keyword-based image search. We first discuss several kinds of biases
that exist in search systems and why it is important to mitigate them. We
narrow down our study to assessing and mitigating occupational stereotypes in
image search, which is a prevalent fairness issue in image retrieval. For the
assessment of stereotypes, we take gender as an indicator. We explore various
open-source and proprietary APIs for gender identification from images. With
these, we examine the extent of gender bias in top-tanked image search results
obtained for several occupational keywords. To mitigate the bias, we then
propose a fairness-aware re-ranking algorithm that optimizes (a) relevance of
the search result with the keyword and (b) fairness w.r.t genders identified.
We experiment on 100 top-ranked images obtained for 10 occupational keywords
and consider random re-ranking and re-ranking based on relevance as baselines.
Our experimental results show that the fairness-aware re-ranking algorithm
produces rankings with better fairness scores and competitive relevance scores
than the baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HateMM: A Multi-Modal Dataset for Hate Video Classification. (arXiv:2305.03915v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03915">
<div class="article-summary-box-inner">
<span><p>Hate speech has become one of the most significant issues in modern society,
having implications in both the online and the offline world. Due to this, hate
speech research has recently gained a lot of traction. However, most of the
work has primarily focused on text media with relatively little work on images
and even lesser on videos. Thus, early stage automated video moderation
techniques are needed to handle the videos that are being uploaded to keep the
platform safe and healthy. With a view to detect and remove hateful content
from the video sharing platforms, our work focuses on hate video detection
using multi-modalities. To this end, we curate ~43 hours of videos from
BitChute and manually annotate them as hate or non-hate, along with the frame
spans which could explain the labelling decision. To collect the relevant
videos we harnessed search keywords from hate lexicons. We observe various cues
in images and audio of hateful videos. Further, we build deep learning
multi-modal models to classify the hate videos and observe that using all the
modalities of the videos improves the overall hate speech detection performance
(accuracy=0.798, macro F1-score=0.790) by ~5.7% compared to the best uni-modal
model in terms of macro F1 score. In summary, our work takes the first step
toward understanding and modeling hateful videos on video hosting platforms
such as BitChute.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Continual Learning: Labelling Queries in a Sequence of Tasks. (arXiv:2305.03923v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03923">
<div class="article-summary-box-inner">
<span><p>Acquiring new knowledge without forgetting what has been learned in a
sequence of tasks is the central focus of continual learning (CL). While tasks
arrive sequentially, the training data are often prepared and annotated
independently, leading to CL of incoming supervised learning tasks. This paper
considers the under-explored problem of active continual learning (ACL) for a
sequence of active learning (AL) tasks, where each incoming task includes a
pool of unlabelled data and an annotation budget. We investigate the
effectiveness and interplay between several AL and CL algorithms in the domain,
class and task-incremental scenarios. Our experiments reveal the trade-off
between two contrasting goals of not forgetting the old knowledge and the
ability to quickly learn in CL and AL. While conditioning the query strategy on
the annotations collected for the previous tasks leads to improved task
performance on the domain and task incremental learning, our proposed
forgetting-learning profile suggests a gap in balancing the effect of AL and CL
for the class-incremental scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Residual Prompt Tuning: Improving Prompt Tuning with Residual Reparameterization. (arXiv:2305.03937v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03937">
<div class="article-summary-box-inner">
<span><p>Prompt tuning is one of the successful approaches for parameter-efficient
tuning of pre-trained language models. Despite being arguably the most
parameter-efficient (tuned soft prompts constitute &lt;0.1% of total parameters),
it typically performs worse than other efficient tuning methods and is quite
sensitive to hyper-parameters. In this work, we introduce Residual Prompt
Tuning - a simple and efficient method that significantly improves the
performance and stability of prompt tuning. We propose to reparameterize soft
prompt embeddings using a shallow network with a residual connection. Our
experiments show that Residual Prompt Tuning significantly outperforms prompt
tuning on SuperGLUE benchmark. Notably, our method reaches +7 points
improvement over prompt tuning with T5-Base and allows to reduce the prompt
length by 10x without hurting performance. In addition, we show that our
approach is robust to the choice of learning rate and prompt initialization,
and is effective in few-shot settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Label-Free Multi-Domain Machine Translation with Stage-wise Training. (arXiv:2305.03949v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03949">
<div class="article-summary-box-inner">
<span><p>Most multi-domain machine translation models rely on domain-annotated data.
Unfortunately, domain labels are usually unavailable in both training processes
and real translation scenarios. In this work, we propose a label-free
multi-domain machine translation model which requires only a few or no
domain-annotated data in training and no domain labels in inference. Our model
is composed of three parts: a backbone model, a domain discriminator taking
responsibility to discriminate data from different domains, and a set of
experts that transfer the decoded features from generic to specific. We design
a stage-wise training strategy and train the three parts sequentially. To
leverage the extra domain knowledge and improve the training stability, in the
discriminator training stage, domain differences are modeled explicitly with
clustering and distilled into the discriminator through a multi-classification
task. Meanwhile, the Gumbel-Max sampling is adopted as the routing scheme in
the expert training stage to achieve the balance of each expert in
specialization and generalization. Experimental results on the
German-to-English translation task show that our model significantly improves
BLEU scores on six different domains and even outperforms most of the models
trained with domain-annotated data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Rule-based Named Entity Recognition and Relation Extraction for Process Model Generation from Natural Language Text. (arXiv:2305.03960v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03960">
<div class="article-summary-box-inner">
<span><p>Automated generation of business process models from natural language text is
an emerging methodology for avoiding the manual creation of formal business
process models. For this purpose, process entities like actors, activities,
objects etc., and relations among them are extracted from textual process
descriptions. A high-quality annotated corpus of textual process descriptions
(PET) has been published accompanied with a basic process extraction approach.
In its current state, however, PET lacks information about whether two mentions
refer to the same or different process entities, which corresponds to the
crucial decision of whether to create one or two modeling elements in the
target model. Consequently, it is ambiguous whether, for instance, two mentions
of data processing mean processing of different, or the same data. In this
paper, we extend the PET dataset by clustering mentions of process entities and
by proposing a new baseline technique for process extraction equipped with an
additional entity resolution component. In a second step, we replace the
rule-based relation extraction component with a machine learning-based
alternative, enabling rapid adaption to different datasets and domains. In
addition, we evaluate a deep learning-approach built for solving entity and
relation extraction as well as entity resolution in a holistic manner. Finally,
our extensive evaluation of the original PET baseline against our own
implementation shows that a pure machine learning-based process extraction
technique is competitive, while avoiding the massive overhead arising from
feature engineering and rule definition needed to adapt to other datasets,
different entity and relation types, or new domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NER-to-MRC: Named-Entity Recognition Completely Solving as Machine Reading Comprehension. (arXiv:2305.03970v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03970">
<div class="article-summary-box-inner">
<span><p>Named-entity recognition (NER) detects texts with predefined semantic labels
and is an essential building block for natural language processing (NLP).
Notably, recent NER research focuses on utilizing massive extra data, including
pre-training corpora and incorporating search engines. However, these methods
suffer from high costs associated with data collection and pre-training, and
additional training process of the retrieved data from search engines. To
address the above challenges, we completely frame NER as a machine reading
comprehension (MRC) problem, called NER-to-MRC, by leveraging MRC with its
ability to exploit existing data efficiently. Several prior works have been
dedicated to employing MRC-based solutions for tackling the NER problem,
several challenges persist: i) the reliance on manually designed prompts; ii)
the limited MRC approaches to data reconstruction, which fails to achieve
performance on par with methods utilizing extensive additional data. Thus, our
NER-to-MRC conversion consists of two components: i) transform the NER task
into a form suitable for the model to solve with MRC in a efficient manner; ii)
apply the MRC reasoning strategy to the model. We experiment on 6 benchmark
datasets from three domains and achieve state-of-the-art performance without
external data, up to 11.24% improvement on the WNUT-16 dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive loose optimization for robust question answering. (arXiv:2305.03971v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03971">
<div class="article-summary-box-inner">
<span><p>Question answering methods are well-known for leveraging data bias, such as
the language prior in visual question answering and the position bias in
machine reading comprehension (extractive question answering). Current
debiasing methods often come at the cost of significant in-distribution
performance to achieve favorable out-of-distribution generalizability, while
non-debiasing methods sacrifice a considerable amount of out-of-distribution
performance in order to obtain high in-distribution performance. Therefore, it
is challenging for them to deal with the complicated changing real-world
situations. In this paper, we propose a simple yet effective novel loss
function with adaptive loose optimization, which seeks to make the best of both
worlds for question answering. Our main technical contribution is to reduce the
loss adaptively according to the ratio between the previous and current
optimization state on mini-batch training data. This loose optimization can be
used to prevent non-debiasing methods from overlearning data bias while
enabling debiasing methods to maintain slight bias learning. Experiments on the
visual question answering datasets, including VQA v2, VQA-CP v1, VQA-CP v2,
GQA-OOD, and the extractive question answering dataset SQuAD demonstrate that
our approach enables QA methods to obtain state-of-the-art in- and
out-of-distribution performance in most cases. The source code has been
released publicly in \url{https://github.com/reml-group/ALO}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiscoPrompt: Path Prediction Prompt Tuning for Implicit Discourse Relation Recognition. (arXiv:2305.03973v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03973">
<div class="article-summary-box-inner">
<span><p>Implicit Discourse Relation Recognition (IDRR) is a sophisticated and
challenging task to recognize the discourse relations between the arguments
with the absence of discourse connectives. The sense labels for each discourse
relation follow a hierarchical classification scheme in the annotation process
(Prasad et al., 2008), forming a hierarchy structure. Most existing works do
not well incorporate the hierarchy structure but focus on the syntax features
and the prior knowledge of connectives in the manner of pure text
classification. We argue that it is more effective to predict the paths inside
the hierarchical tree (e.g., "Comparison -&gt; Contrast -&gt; however") rather than
flat labels (e.g., Contrast) or connectives (e.g., however). We propose a
prompt-based path prediction method to utilize the interactive information and
intrinsic senses among the hierarchy in IDRR. This is the first work that
injects such structure information into pre-trained language models via prompt
tuning, and the performance of our solution shows significant and consistent
improvement against competitive baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Adversarial Non-Autoregressive Model for Text Generation with Incomplete Information. (arXiv:2305.03977v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03977">
<div class="article-summary-box-inner">
<span><p>Non-autoregressive models have been widely studied in the Complete
Information Scenario (CIS), in which the models have complete input information
to obtain corresponding output. However, their explorations in the Incomplete
Information Scenario (IIS) are extremely limited. Our analyses reveal that the
IIS's incomplete input information will augment the inherent limitations of
existing non-autoregressive models trained under Maximum Likelihood Estimation.
In this paper, we propose for the IIS an Adversarial Non-autoregressive
Transformer (ANT) which has two novel features: 1) Position Aware
Self-Modulation to provide more reasonable hidden representations, and 2)
Dependency Feed Forward Network to strengthen its capacity in dependency
modeling. We compare ANT with other mainstream models in the IIS and
demonstrate that ANT can achieve comparable performance with much fewer
decoding iterations. Furthermore, we show its great potential in various
applications like latent interpolation and semi-supervised learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-training Language Model as a Multi-perspective Course Learner. (arXiv:2305.03981v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03981">
<div class="article-summary-box-inner">
<span><p>ELECTRA, the generator-discriminator pre-training framework, has achieved
impressive semantic construction capability among various downstream tasks.
Despite the convincing performance, ELECTRA still faces the challenges of
monotonous training and deficient interaction. Generator with only masked
language modeling (MLM) leads to biased learning and label imbalance for
discriminator, decreasing learning efficiency; no explicit feedback loop from
discriminator to generator results in the chasm between these two components,
underutilizing the course learning. In this study, a multi-perspective course
learning (MCL) method is proposed to fetch a many degrees and visual angles for
sample-efficient pre-training, and to fully leverage the relationship between
generator and discriminator. Concretely, three self-supervision courses are
designed to alleviate inherent flaws of MLM and balance the label in a
multi-perspective way. Besides, two self-correction courses are proposed to
bridge the chasm between the two encoders by creating a "correction notebook"
for secondary-supervision. Moreover, a course soups trial is conducted to solve
the "tug-of-war" dynamics problem of MCL, evolving a stronger pre-trained
model. Experimental results show that our method significantly improves
ELECTRA's average performance by 2.8% and 3.2% absolute points respectively on
GLUE and SQuAD 2.0 benchmarks, and overshadows recent advanced ELECTRA-style
models under the same settings. The pre-trained MCL model is available at
https://huggingface.co/McmanusChen/MCL-base.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Replicating Complex Dialogue Policy of Humans via Offline Imitation Learning with Supervised Regularization. (arXiv:2305.03987v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03987">
<div class="article-summary-box-inner">
<span><p>Policy learning (PL) is a module of a task-oriented dialogue system that
trains an agent to make actions in each dialogue turn. Imitating human action
is a fundamental problem of PL. However, both supervised learning (SL) and
reinforcement learning (RL) frameworks cannot imitate humans well. Training RL
models require online interactions with user simulators, while simulating
complex human policy is hard. Performances of SL-based models are restricted
because of the covariate shift problem. Specifically, a dialogue is a
sequential decision-making process where slight differences in current
utterances and actions will cause significant differences in subsequent
utterances. Therefore, the generalize ability of SL models is restricted
because statistical characteristics of training and testing dialogue data
gradually become different. This study proposed an offline imitation learning
model that learns policy from real dialogue datasets and does not require user
simulators. It also utilizes state transition information, which alleviates the
influence of the covariate shift problem. We introduced a regularization trick
to make our model can be effectively optimized. We investigated the performance
of our model on four independent public dialogue datasets. The experimental
result showed that our model performed better in the action prediction task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for Verification. (arXiv:2305.04003v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04003">
<div class="article-summary-box-inner">
<span><p>Verification of machine learning models used in Natural Language Processing
(NLP) is known to be a hard problem. In particular, many known neural network
verification methods that work for computer vision and other numeric datasets
do not work for NLP. Here, we study technical reasons that underlie this
problem. Based on this analysis, we propose practical methods and heuristics
for preparing NLP datasets and models in a way that renders them amenable to
known verification methods based on abstract interpretation. We implement these
methods as a Python library called ANTONIO that links to the neural network
verifiers ERAN and Marabou. We perform evaluation of the tool using an NLP
dataset R-U-A-Robot suggested as a benchmark for verifying legally critical NLP
applications. We hope that, thanks to its general applicability, this work will
open novel possibilities for including NLP verification problems into neural
network verification competitions, and will popularise NLP problems within this
community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Refining the Responses of LLMs by Themselves. (arXiv:2305.04039v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04039">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a simple yet efficient approach based on prompt
engineering that leverages the large language model itself to optimize its
answers without relying on auxiliary models. We introduce an iterative
self-evaluating optimization mechanism, with the potential for improved output
quality as iterations progress, removing the need for manual intervention. The
experiment's findings indicate that utilizing our response refinement framework
on the GPT-3.5 model yields results that are on par with, or even surpass,
those generated by the cutting-edge GPT-4 model. Detailed implementation
strategies and illustrative examples are provided to demonstrate the
superiority of our proposed solution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation. (arXiv:2305.04044v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04044">
<div class="article-summary-box-inner">
<span><p>Recently, continuous diffusion models (CDM) have been introduced into
non-autoregressive (NAR) text-to-text generation. However, the discrete nature
of text increases the difficulty of CDM to generate coherent and fluent texts,
and also causes the incompatibility problem between CDM and advanced NLP
techniques, especially the popular pre-trained language models~(PLMs). To solve
it, we propose Diffusion-NAT, which introduces discrete diffusion models~(DDM)
into NAR text-to-text generation and integrates BART to improve the
performance. By revising the decoding process of BART and the typical settings
of DDM, we unify the inference process of BART and the denoising process of DDM
into the same NAR masked tokens recovering task. In this way, DDM can rely on
BART to perform denoising, which can benefit from both the rich pre-learned
knowledge of BART and the iterative refining paradigm of DDM. Besides, we also
propose the iterative self-prompting strategy to further improve the generation
quality. Experimental results on 7 datasets show that our approach can
outperform competitive NAR methods, and even surpass autoregressive methods.
Our code and data will be publicly released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Actively Discovering New Slots for Task-oriented Conversation. (arXiv:2305.04049v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04049">
<div class="article-summary-box-inner">
<span><p>Existing task-oriented conversational search systems heavily rely on domain
ontologies with pre-defined slots and candidate value sets. In practical
applications, these prerequisites are hard to meet, due to the emerging new
user requirements and ever-changing scenarios. To mitigate these issues for
better interaction performance, there are efforts working towards detecting
out-of-vocabulary values or discovering new slots under unsupervised or
semi-supervised learning paradigm. However, overemphasizing on the conversation
data patterns alone induces these methods to yield noisy and arbitrary slot
results. To facilitate the pragmatic utility, real-world systems tend to
provide a stringent amount of human labelling quota, which offers an
authoritative way to obtain accurate and meaningful slot assignments.
Nonetheless, it also brings forward the high requirement of utilizing such
quota efficiently. Hence, we formulate a general new slot discovery task in an
information extraction fashion and incorporate it into an active learning
framework to realize human-in-the-loop learning. Specifically, we leverage
existing language tools to extract value candidates where the corresponding
labels are further leveraged as weak supervision signals. Based on these, we
propose a bi-criteria selection scheme which incorporates two major strategies,
namely, uncertainty-based sampling and diversity-based sampling to efficiently
identify terms of interest. We conduct extensive experiments on several public
datasets and compare with a bunch of competitive baselines to demonstrate the
effectiveness of our method. We have made the code and data used in this paper
publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reactive Perturbation Defocusing for Textual Adversarial Defense. (arXiv:2305.04067v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04067">
<div class="article-summary-box-inner">
<span><p>Recent studies have shown that large pre-trained language models are
vulnerable to adversarial attacks. Existing methods attempt to reconstruct the
adversarial examples. However, these methods usually have limited performance
in defense against adversarial examples, while also negatively impacting the
performance on natural examples. To overcome this problem, we propose a method
called Reactive Perturbation Defocusing (RPD). RPD uses an adversarial detector
to identify adversarial examples and reduce false defenses on natural examples.
Instead of reconstructing the adversaries, RPD injects safe perturbations into
adversarial examples to distract the objective models from the malicious
perturbations. Our experiments on three datasets, two objective models, and
various adversarial attacks show that our proposed framework successfully
repairs up to approximately 97% of correctly identified adversarial examples
with only about a 2% performance decrease on natural examples. We also provide
a demo of adversarial detection and repair based on our work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SANTA: Separate Strategies for Inaccurate and Incomplete Annotation Noise in Distantly-Supervised Named Entity Recognition. (arXiv:2305.04076v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04076">
<div class="article-summary-box-inner">
<span><p>Distantly-Supervised Named Entity Recognition effectively alleviates the
burden of time-consuming and expensive annotation in the supervised setting.
But the context-free matching process and the limited coverage of knowledge
bases introduce inaccurate and incomplete annotation noise respectively.
Previous studies either considered only incomplete annotation noise or
indiscriminately handle two types of noise with the same strategy. In this
paper, we argue that the different causes of two types of noise bring up the
requirement of different strategies in model architecture. Therefore, we
propose the SANTA to handle these two types of noise separately with (1)
Memory-smoothed Focal Loss and Entity-aware KNN to relieve the entity ambiguity
problem caused by inaccurate annotation, and (2) Boundary Mixup to alleviate
decision boundary shifting problem caused by incomplete annotation and a
noise-tolerant loss to improve the robustness. Benefiting from our separate
tailored strategies, we confirm in the experiment that the two types of noise
are well mitigated. SANTA also achieves a new state-of-the-art on five public
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Minimal Approach for Natural Language Action Space in Text-based Games. (arXiv:2305.04082v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04082">
<div class="article-summary-box-inner">
<span><p>Text-based games (TGs) are language-based interactive environments for
reinforcement learning. While language models (LMs) and knowledge graphs (KGs)
are commonly used for handling large action space in TGs, it is unclear whether
these techniques are necessary or overused. In this paper, we revisit the
challenge of exploring the action space in TGs and propose $
\epsilon$-admissible exploration, a minimal approach of utilizing admissible
actions, for training phase. Additionally, we present a text-based actor-critic
(TAC) agent that produces textual commands for game, solely from game
observations, without requiring any KG or LM. Our method, on average across 10
games from Jericho, outperforms strong baselines and state-of-the-art agents
that use LM and KG. Our approach highlights that a much lighter model design,
with a fresh perspective on utilizing the information within the environments,
suffices for an effective exploration of exponentially large action spaces.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Edit: Fault-Aware Code Editor for Code Generation. (arXiv:2305.04087v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04087">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have demonstrated an impressive ability to
generate codes on competitive programming tasks. However, with limited sample
numbers, LLMs still suffer from poor accuracy. Inspired by the process of human
programming, we propose a generate-and-edit approach that utilizes execution
results of the generated code from LLMs to improve the code quality on the
competitive programming task. We execute the generated code on the example test
case provided in the question and wrap execution results into a supplementary
comment. Utilizing this comment as guidance, our fault-aware code editor is
employed to correct errors in the generated code. We perform extensive
evaluations across two competitive programming datasets with nine different
LLMs. Compared to directly generating from LLMs, our approach can improve the
average of pass@1 by 89\% on APPS-dev, 31\% on APPS-test, and 48\% on HumanEval
over nine popular code generation LLMs with parameter sizes ranging from 110M
to 175B. Compared to other post-processing methods, our method demonstrates
superior accuracy and efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models. (arXiv:2305.04091v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04091">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have recently been shown to deliver impressive
performance in various NLP tasks. To tackle multi-step reasoning tasks,
few-shot chain-of-thought (CoT) prompting includes a few manually crafted
step-by-step reasoning demonstrations which enable LLMs to explicitly generate
reasoning steps and improve their reasoning task accuracy. To eliminate the
manual effort, Zero-shot-CoT concatenates the target problem statement with
"Let's think step by step" as an input prompt to LLMs. Despite the success of
Zero-shot-CoT, it still suffers from three pitfalls: calculation errors,
missing-step errors, and semantic misunderstanding errors. To address the
missing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of
two components: first, devising a plan to divide the entire task into smaller
subtasks, and then carrying out the subtasks according to the plan. To address
the calculation errors and improve the quality of generated reasoning steps, we
extend PS prompting with more detailed instructions and derive PS+ prompting.
We evaluate our proposed prompting strategy on ten datasets across three
reasoning problems. The experimental results over GPT-3 show that our proposed
zero-shot prompting consistently outperforms Zero-shot-CoT across all datasets
by a large margin, is comparable to or exceeds Zero-shot-Program-of-Thought
Prompting, and has comparable performance with 8-shot CoT prompting on the math
reasoning problem. The code can be found at
https://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rhetorical Role Labeling of Legal Documents using Transformers and Graph Neural Networks. (arXiv:2305.04100v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04100">
<div class="article-summary-box-inner">
<span><p>A legal document is usually long and dense requiring human effort to parse
it. It also contains significant amounts of jargon which make deriving insights
from it using existing models a poor approach. This paper presents the
approaches undertaken to perform the task of rhetorical role labelling on
Indian Court Judgements as part of SemEval Task 6: understanding legal texts,
shared subtask A. We experiment with graph based approaches like Graph
Convolutional Networks and Label Propagation Algorithm, and transformer-based
approaches including variants of BERT to improve accuracy scores on text
classification of complex legal documents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"When Words Fail, Emojis Prevail": Generating Sarcastic Utterances with Emoji Using Valence Reversal and Semantic Incongruity. (arXiv:2305.04105v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04105">
<div class="article-summary-box-inner">
<span><p>Sarcasm pertains to the subtle form of language that individuals use to
express the opposite of what is implied. We present a novel architecture for
sarcasm generation with emoji from a non-sarcastic input sentence. We divide
the generation task into two sub tasks: one for generating textual sarcasm and
another for collecting emojis associated with those sarcastic sentences. Two
key elements of sarcasm are incorporated into the textual sarcasm generation
task: valence reversal and semantic incongruity with context, where the context
may involve shared commonsense or general knowledge between the speaker and
their audience. The majority of existing sarcasm generation works have focused
on this textual form. However, in the real world, when written texts fall short
of effectively capturing the emotional cues of spoken and face-to-face
communication, people often opt for emojis to accurately express their
emotions. Due to the wide range of applications of emojis, incorporating
appropriate emojis to generate textual sarcastic sentences helps advance
sarcasm generation. We conclude our study by evaluating the generated sarcastic
sentences using human judgement. All the codes and data used in this study will
be made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Human-Like Translation Strategy with Large Language Models. (arXiv:2305.04118v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04118">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have demonstrated impressive capabilities in
general scenarios, exhibiting a level of aptitude that approaches, in some
aspects even surpasses, human-level intelligence. Among their numerous skills,
the translation abilities of LLMs have received considerable attention. In
contrast to traditional machine translation that focuses solely on
source-target mapping, LLM-based translation can potentially mimic the human
translation process that takes many preparatory steps to ensure high-quality
translation. This work aims to explore this possibility by proposing the MAPS
framework, which stands for Multi-Aspect Prompting and Selection. Specifically,
we enable LLMs to first analyze the given source text and extract three aspects
of translation-related knowledge: keywords, topics and relevant demonstrations
to guide the translation process. To filter out the noisy and unhelpful
knowledge, we employ a selection mechanism based on quality estimation.
Experiments suggest that MAPS brings significant and consistent improvements
over text-davinci-003 and Alpaca on eight translation directions from the
latest WMT22 test sets. Our further analysis shows that the extracted knowledge
is critical in resolving up to 59% of hallucination mistakes in translation.
Code is available at https://github.com/zwhe99/MAPS-mt.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controllable Mixed-Initiative Dialogue Generation through Prompting. (arXiv:2305.04147v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04147">
<div class="article-summary-box-inner">
<span><p>Mixed-initiative dialogue tasks involve repeated exchanges of information and
conversational control. Conversational agents gain control by generating
responses that follow particular dialogue intents or strategies, prescribed by
a policy planner. The standard approach has been fine-tuning pre-trained
language models to perform generation conditioned on these intents. However,
these supervised generation models are limited by the cost and quality of data
annotation. We instead prompt large language models as a drop-in replacement to
fine-tuning on conditional generation. We formalize prompt construction for
controllable mixed-initiative dialogue. Our findings show improvements over
fine-tuning and ground truth responses according to human evaluation and
automatic metrics for two tasks: PersuasionForGood and Emotional Support
Conversations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages. (arXiv:2305.04160v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04160">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have demonstrated remarkable language abilities.
GPT-4, based on advanced LLMs, exhibits extraordinary multimodal capabilities
beyond previous visual language models. We attribute this to the use of more
advanced LLMs compared with previous multimodal models. Unfortunately, the
model architecture and training strategies of GPT-4 are unknown. To endow LLMs
with multimodal capabilities, we propose X-LLM, which converts Multi-modalities
(images, speech, videos) into foreign languages using X2L interfaces and inputs
them into a large Language model (ChatGLM). Specifically, X-LLM aligns multiple
frozen single-modal encoders and a frozen LLM using X2L interfaces, where ``X''
denotes multi-modalities such as image, speech, and videos, and ``L'' denotes
languages. X-LLM's training consists of three stages: (1) Converting Multimodal
Information: The first stage trains each X2L interface to align with its
respective single-modal encoder separately to convert multimodal information
into languages. (2) Aligning X2L representations with the LLM: single-modal
encoders are aligned with the LLM through X2L interfaces independently. (3)
Integrating multiple modalities: all single-modal encoders are aligned with the
LLM through X2L interfaces to integrate multimodal capabilities into the LLM.
Our experiments show that X-LLM demonstrates impressive multimodel chat
abilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen
images/instructions, and yields a 84.5\% relative score compared with GPT-4 on
a synthetic multimodal instruction-following dataset. And we also conduct
quantitative tests on using LLM for ASR and multimodal ASR, hoping to promote
the era of LLM-based speech recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UIT-OpenViIC: A Novel Benchmark for Evaluating Image Captioning in Vietnamese. (arXiv:2305.04166v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04166">
<div class="article-summary-box-inner">
<span><p>Image Captioning is one of the vision-language tasks that still interest the
research community worldwide in the 2020s. MS-COCO Caption benchmark is
commonly used to evaluate the performance of advanced captioning models,
although it was published in 2015. Recent captioning models trained on the
MS-COCO Caption dataset only have good performance in language patterns of
English; they do not have such good performance in contexts captured in Vietnam
or fluently caption images using Vietnamese. To contribute to the low-resources
research community as in Vietnam, we introduce a novel image captioning dataset
in Vietnamese, the Open-domain Vietnamese Image Captioning dataset
(UIT-OpenViIC). The introduced dataset includes complex scenes captured in
Vietnam and manually annotated by Vietnamese under strict rules and
supervision. In this paper, we present in more detail the dataset creation
process. From preliminary analysis, we show that our dataset is challenging to
recent state-of-the-art (SOTA) Transformer-based baselines, which performed
well on the MS COCO dataset. Then, the modest results prove that UIT-OpenViIC
has room to grow, which can be one of the standard benchmarks in Vietnamese for
the research community to evaluate their captioning models. Furthermore, we
present a CAMO approach that effectively enhances the image representation
ability by a multi-level encoder output fusion mechanism, which helps improve
the quality of generated captions compared to previous captioning models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MIReAD: Simple Method for Learning High-quality Representations from Scientific Documents. (arXiv:2305.04177v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04177">
<div class="article-summary-box-inner">
<span><p>Learning semantically meaningful representations from scientific documents
can facilitate academic literature search and improve performance of
recommendation systems. Pre-trained language models have been shown to learn
rich textual representations, yet they cannot provide powerful document-level
representations for scientific articles. We propose MIReAD, a simple method
that learns high-quality representations of scientific papers by fine-tuning
transformer model to predict the target journal class based on the abstract. We
train MIReAD on more than 500,000 PubMed and arXiv abstracts across over 2,000
journal classes. We show that MIReAD produces representations that can be used
for similar papers retrieval, topic categorization and literature search. Our
proposed approach outperforms six existing models for representation learning
on scientific documents across four evaluation standards.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shall We Trust All Relational Tuples by Open Information Extraction? A Study on Speculation Detection. (arXiv:2305.04181v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04181">
<div class="article-summary-box-inner">
<span><p>Open Information Extraction (OIE) aims to extract factual relational tuples
from open-domain sentences. Downstream tasks use the extracted OIE tuples as
facts, without examining the certainty of these facts. However,
uncertainty/speculation is a common linguistic phenomenon. Existing studies on
speculation detection are defined at sentence level, but even if a sentence is
determined to be speculative, not all tuples extracted from it may be
speculative. In this paper, we propose to study speculations in OIE and aim to
determine whether an extracted tuple is speculative. We formally define the
research problem of tuple-level speculation detection and conduct a detailed
data analysis on the LSOIE dataset which contains labels for speculative
tuples. Lastly, we propose a baseline model OIE-Spec for this new research
task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OpenViVQA: Task, Dataset, and Multimodal Fusion Models for Visual Question Answering in Vietnamese. (arXiv:2305.04183v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04183">
<div class="article-summary-box-inner">
<span><p>In recent years, visual question answering (VQA) has attracted attention from
the research community because of its highly potential applications (such as
virtual assistance on intelligent cars, assistant devices for blind people, or
information retrieval from document images using natural language as queries)
and challenge. The VQA task requires methods that have the ability to fuse the
information from questions and images to produce appropriate answers. Neural
visual question answering models have achieved tremendous growth on large-scale
datasets which are mostly for resource-rich languages such as English. However,
available datasets narrow the VQA task as the answers selection task or answer
classification task. We argue that this form of VQA is far from human ability
and eliminates the challenge of the answering aspect in the VQA task by just
selecting answers rather than generating them. In this paper, we introduce the
OpenViVQA (Open-domain Vietnamese Visual Question Answering) dataset, the first
large-scale dataset for VQA with open-ended answers in Vietnamese, consists of
11,000+ images associated with 37,000+ question-answer pairs (QAs). Moreover,
we proposed FST, QuMLAG, and MLPAG which fuse information from images and
answers, then use these fused features to construct answers as humans
iteratively. Our proposed methods achieve results that are competitive with
SOTA models such as SAAA, MCAN, LORA, and M4C. The dataset is available to
encourage the research community to develop more generalized algorithms
including transformers for low-resource languages such as Vietnamese.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Modal Retrieval for Motion and Text via MildTriple Loss. (arXiv:2305.04195v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04195">
<div class="article-summary-box-inner">
<span><p>Cross-modal retrieval has become a prominent research topic in computer
vision and natural language processing with advances made in image-text and
video-text retrieval technologies. However, cross-modal retrieval between human
motion sequences and text has not garnered sufficient attention despite the
extensive application value it holds, such as aiding virtual reality
applications in better understanding users' actions and language. This task
presents several challenges, including joint modeling of the two modalities,
demanding the understanding of person-centered information from text, and
learning behavior features from 3D human motion sequences. Previous work on
motion data modeling mainly relied on autoregressive feature extractors that
may forget previous information, while we propose an innovative model that
includes simple yet powerful transformer-based motion and text encoders, which
can learn representations from the two different modalities and capture
long-term dependencies. Furthermore, the overlap of the same atomic actions of
different human motions can cause semantic conflicts, leading us to explore a
new triplet loss function, MildTriple Loss. it leverages the similarity between
samples in intra-modal space to guide soft-hard negative sample mining in the
joint embedding space to train the triplet loss and reduce the violation caused
by false negative samples. We evaluated our model and method on the latest
HumanML3D and KIT Motion-Language datasets, achieving a 62.9\% recall for
motion retrieval and a 71.5\% recall for text retrieval (based on R@10) on the
HumanML3D dataset. Our code is available at
https://github.com/eanson023/rehamot.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Large and Diverse Arabic Corpus for Language Modeling. (arXiv:2201.09227v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.09227">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) have introduced a major paradigm shift in Natural
Language Processing (NLP) modeling where large pre-trained LMs became integral
to most of the NLP tasks. The LMs are intelligent enough to find useful and
relevant representations of the language without any supervision. Perhaps,
these models are used to fine-tune typical NLP tasks with significantly high
accuracy as compared to the traditional approaches. Conversely, the training of
these models requires a massively large corpus that is a good representation of
the language. English LMs generally perform better than their other language
counterparts, due to the availability of massive English corpora. This work
elaborates on the design and development of a large Arabic corpus. It consists
of over 500 GB of Arabic cleaned text targeted at improving cross-domain
knowledge and downstream generalization capability of large-scale language
models. Moreover, the corpus is utilized in the training of a large Arabic LM.
In order to evaluate the effectiveness of the LM, a number of typical NLP tasks
are fine-tuned. The tasks demonstrate a significant boost from 4.5 to 8.5% when
compared to tasks fine-tuned on multi-lingual BERT (mBERT). To the best of my
knowledge, this is currently the largest clean and diverse Arabic corpus ever
collected.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Helpfulness and Fairness of Task-Oriented Dialogue Systems. (arXiv:2205.12554v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12554">
<div class="article-summary-box-inner">
<span><p>Goal-oriented dialogue systems aim to help users achieve certain goals.
Therefore, how humans perceive their helpfulness is important. However, neither
the human-perceived helpfulness of goal-oriented dialogue systems nor its
fairness implication has been well studied. In this paper, we study
computational measurements of helpfulness. We first formally define a dialogue
response as helpful if it is relevant &amp; coherent, useful, and informative to a
query. Then, we collect human annotations for the helpfulness of dialogue
responses based on our definition and build a classifier to automatically
determine the helpfulness of a response. We further propose to use the
helpfulness level of a dialogue system towards different user queries to
measure the fairness of a dialogue system. Experiments with state-of-the-art
dialogue systems under three information-seeking scenarios reveal that existing
systems tend to be more helpful for questions regarding concepts from
highly-developed countries than less-developed countries, uncovering potential
fairness concerns underlying the current goal-oriented dialogue systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Delving into the Openness of CLIP. (arXiv:2206.01986v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.01986">
<div class="article-summary-box-inner">
<span><p>Contrastive Language-Image Pre-training (CLIP) formulates image
classification as an image-to-text matching task, i.e., matching images to the
corresponding natural language descriptions instead of discrete category IDs.
This allows for open-vocabulary visual recognition, where the model can
recognize images from an open class set (also known as an open vocabulary) in a
zero-shot manner. However, evaluating the openness of CLIP-like models is
challenging, as the models are open to arbitrary vocabulary in theory, but
their accuracy varies in practice. To address this, we resort to an incremental
perspective to assess the openness through vocabulary expansions, and define
extensibility to measure a model's ability to handle novel classes. Our
evaluation shows that CLIP-like models are not truly open, and their
performance deteriorates as the vocabulary expands. We further dissect the
feature space of CLIP from the perspectives of representation alignment and
uniformity. Our investigation reveals that the overestimation of openness is
due to confusion among competing text features, rather than a failure to
capture the similarity between image features and text features of novel
classes. We hope that our investigation and analysis will facilitate future
research on the CLIP openness issue.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Characterizing narrative time in books through fluctuations in power and danger arcs. (arXiv:2208.09496v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.09496">
<div class="article-summary-box-inner">
<span><p>While quantitative methods have been used to examine changes in word usage in
books, studies have focused on overall trends, such as the shapes of
narratives, which are independent of book length. We instead look at how words
change over the course of a book as a function of the number of words, rather
than the fraction of the book, completed at any given point; we define this
measure as "cumulative word-time". Using ousiometrics, a reinterpretation of
the valence-arousal-dominance framework of meaning obtained from semantic
differentials, we convert text into time series of power and danger scores in
cumulative word-time. Each time series is then decomposed using empirical mode
decomposition into a sum of constituent oscillatory modes and a non-oscillatory
trend. By comparing the decomposition of the original power and danger time
series with those derived from shuffled text, we find that shorter books
exhibit only a general trend, while longer books have fluctuations in addition
to the general trend. These fluctuations typically have a period of a few
thousand words regardless of the book length or library classification code,
but vary depending on the content and structure of the book. Our findings
suggest that, in the ousiometric sense, longer books are not expanded versions
of shorter books, but are more similar in structure to a concatenation of
shorter texts. Further, they are consistent with editorial practices that
require longer texts to be broken down into sections, such as chapters. Our
method also provides a data-driven denoising approach that works for texts of
various lengths, in contrast to the more traditional approach of using large
window sizes that may inadvertently smooth out relevant information, especially
for shorter texts. These results open up avenues for future work in
computational literary analysis, particularly the measurement of a basic unit
of narrative.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">General-to-Specific Transfer Labeling for Domain Adaptable Keyphrase Generation. (arXiv:2208.09606v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.09606">
<div class="article-summary-box-inner">
<span><p>Training keyphrase generation (KPG) models require a large amount of
annotated data, which can be prohibitively expensive and often limited to
specific domains. In this study, we first demonstrate that large distribution
shifts among different domains severely hinder the transferability of KPG
models. We then propose a three-stage pipeline, which gradually guides KPG
models' learning focus from general syntactical features to domain-related
semantics, in a data-efficient manner. With Domain-general Phrase pre-training,
we pre-train Sequence-to-Sequence models with generic phrase annotations that
are widely available on the web, which enables the models to generate phrases
in a wide range of domains. The resulting model is then applied in the Transfer
Labeling stage to produce domain-specific pseudo keyphrases, which help adapt
models to a new domain. Finally, we fine-tune the model with limited data with
true labels to fully adapt it to the target domain. Our experiment results show
that the proposed process can produce good-quality keyphrases in new domains
and achieve consistent improvements after adaptation with limited in-domain
annotated data. All code and datasets are available at
https://github.com/memray/OpenNMT-kpg-release.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Persuasion Strategies in Advertisements. (arXiv:2208.09626v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.09626">
<div class="article-summary-box-inner">
<span><p>Modeling what makes an advertisement persuasive, i.e., eliciting the desired
response from consumer, is critical to the study of propaganda, social
psychology, and marketing. Despite its importance, computational modeling of
persuasion in computer vision is still in its infancy, primarily due to the
lack of benchmark datasets that can provide persuasion-strategy labels
associated with ads. Motivated by persuasion literature in social psychology
and marketing, we introduce an extensive vocabulary of persuasion strategies
and build the first ad image corpus annotated with persuasion strategies. We
then formulate the task of persuasion strategy prediction with multi-modal
learning, where we design a multi-task attention fusion model that can leverage
other ad-understanding tasks to predict persuasion strategies. Further, we
conduct a real-world case study on 1600 advertising campaigns of 30 Fortune-500
companies where we use our model's predictions to analyze which strategies work
with different demographics (age and gender). The dataset also provides image
segmentation masks, which labels persuasion strategies in the corresponding ad
images on the test split. We publicly release our code and dataset
https://midas-research.github.io/persuasion-advertisements/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shortcut Learning of Large Language Models in Natural Language Understanding. (arXiv:2208.11857v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.11857">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have achieved state-of-the-art performance on a
series of natural language understanding tasks. However, these LLMs might rely
on dataset bias and artifacts as shortcuts for prediction. This has
significantly affected their generalizability and adversarial robustness. In
this paper, we provide a review of recent developments that address the
shortcut learning and robustness challenge of LLMs. We first introduce the
concepts of shortcut learning of language models. We then introduce methods to
identify shortcut learning behavior in language models, characterize the
reasons for shortcut learning, as well as introduce mitigation solutions.
Finally, we discuss key research challenges and potential research directions
in order to advance the field of LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vega-MT: The JD Explore Academy Translation System for WMT22. (arXiv:2209.09444v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.09444">
<div class="article-summary-box-inner">
<span><p>We describe the JD Explore Academy's submission of the WMT 2022 shared
general translation task. We participated in all high-resource tracks and one
medium-resource track, including Chinese-English, German-English,
Czech-English, Russian-English, and Japanese-English. We push the limit of our
previous work -- bidirectional training for translation by scaling up two main
factors, i.e. language pairs and model sizes, namely the \textbf{Vega-MT}
system. As for language pairs, we scale the "bidirectional" up to the
"multidirectional" settings, covering all participating languages, to exploit
the common knowledge across languages, and transfer them to the downstream
bilingual tasks. As for model sizes, we scale the Transformer-Big up to the
extremely large model that owns nearly 4.7 Billion parameters, to fully enhance
the model capacity for our Vega-MT. Also, we adopt the data augmentation
strategies, e.g. cycle translation for monolingual data, and bidirectional
self-training for bilingual and monolingual data, to comprehensively exploit
the bilingual and monolingual data. To adapt our Vega-MT to the general domain
test set, generalization tuning is designed. Based on the official automatic
scores of constrained systems, in terms of the sacreBLEU shown in Figure-1, we
got the 1st place on {Zh-En (33.5), En-Zh (49.7), De-En (33.7), En-De (37.8),
Cs-En (54.9), En-Cs (41.4) and En-Ru (32.7)}, 2nd place on {Ru-En (45.1) and
Ja-En (25.6)}, and 3rd place on {En-Ja(41.5)}, respectively; W.R.T the COMET,
we got the 1st place on {Zh-En (45.1), En-Zh (61.7), De-En (58.0), En-De
(63.2), Cs-En (74.7), Ru-En (64.9), En-Ru (69.6) and En-Ja (65.1)}, 2nd place
on {En-Cs (95.3) and Ja-En (40.6)}, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Music-to-Text Synaesthesia: Generating Descriptive Text from Music Recordings. (arXiv:2210.00434v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.00434">
<div class="article-summary-box-inner">
<span><p>In this paper, we consider a novel research problem: music-to-text
synaesthesia. Different from the classical music tagging problem that
classifies a music recording into pre-defined categories, music-to-text
synaesthesia aims to generate descriptive texts from music recordings with the
same sentiment for further understanding. As existing music-related datasets do
not contain the semantic descriptions on music recordings, we collect a new
dataset that contains 1,955 aligned pairs of classical music recordings and
text descriptions. Based on this, we build a computational model to generate
sentences that can describe the content of the music recording. To tackle the
highly non-discriminative classical music, we design a group
topology-preservation loss, which considers more samples as a group reference
and preserves the relative topology among different samples. Extensive
experimental results qualitatively and quantitatively demonstrate the
effectiveness of our proposed model over five heuristics or pre-trained
competitive methods and their variants on our collected dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are Synonym Substitution Attacks Really Synonym Substitution Attacks?. (arXiv:2210.02844v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.02844">
<div class="article-summary-box-inner">
<span><p>In this paper, we explore the following question: Are synonym substitution
attacks really synonym substitution attacks (SSAs)? We approach this question
by examining how SSAs replace words in the original sentence and show that
there are still unresolved obstacles that make current SSAs generate invalid
adversarial samples. We reveal that four widely used word substitution methods
generate a large fraction of invalid substitution words that are ungrammatical
or do not preserve the original sentence's semantics. Next, we show that the
semantic and grammatical constraints used in SSAs for detecting invalid word
replacements are highly insufficient in detecting invalid adversarial samples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods. (arXiv:2210.07321v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07321">
<div class="article-summary-box-inner">
<span><p>Machine generated text is increasingly difficult to distinguish from human
authored text. Powerful open-source models are freely available, and
user-friendly tools that democratize access to generative models are
proliferating. ChatGPT, which was released shortly after the first edition of
this survey, epitomizes these trends. The great potential of state-of-the-art
natural language generation (NLG) systems is tempered by the multitude of
avenues for abuse. Detection of machine generated text is a key countermeasure
for reducing abuse of NLG models, with significant technical challenges and
numerous open problems. We provide a survey that includes both 1) an extensive
analysis of threat models posed by contemporary NLG systems, and 2) the most
complete review of machine generated text detection methods to date. This
survey places machine generated text within its cybersecurity and social
context, and provides strong guidance for future work addressing the most
critical threat models, and ensuring detection systems themselves demonstrate
trustworthiness through fairness, robustness, and accountability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multitask Pre-training of Modular Prompt for Chinese Few-Shot Learning. (arXiv:2210.07565v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07565">
<div class="article-summary-box-inner">
<span><p>Prompt tuning is a parameter-efficient approach to adapting pre-trained
language models to downstream tasks. Although prompt tuning has been shown to
match the performance of full model tuning when training data is sufficient, it
tends to struggle in few-shot learning settings. In this paper, we present
Multi-task Pre-trained Modular Prompt (MP2) to boost prompt tuning for few-shot
learning. MP2 is a set of combinable prompts pre-trained on 38 Chinese tasks.
On downstream tasks, the pre-trained prompts are selectively activated and
combined, leading to strong compositional generalization to unseen tasks. To
bridge the gap between pre-training and fine-tuning, we formulate upstream and
downstream tasks into a unified machine reading comprehension task. Extensive
experiments under two learning paradigms, i.e., gradient descent and black-box
tuning, show that MP2 significantly outperforms prompt tuning, full model
tuning, and prior prompt pre-training methods in few-shot settings. In
addition, we demonstrate that MP2 can achieve surprisingly fast and strong
adaptation to downstream tasks by merely learning 8 parameters to combine the
pre-trained modular prompts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Close Look into the Calibration of Pre-trained Language Models. (arXiv:2211.00151v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00151">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PLMs) may fail in giving reliable estimates of
their predictive uncertainty. We take a close look into this problem, aiming to
answer two questions: (1) Do PLMs learn to become calibrated in the training
process? (2) How effective are existing calibration methods? For the first
question, we conduct fine-grained control experiments to study the dynamic
change in PLMs' calibration performance in training. We consider six factors as
control variables, including dataset difficulty, available training samples,
training steps, the number of tunable parameters, model scale, and pretraining.
We observe a consistent change in calibration performance across six factors.
We find that PLMs don't learn to become calibrated in training, evidenced by
the continual increase in confidence, no matter whether the predictions are
correct or not. We highlight that our finding somewhat contradicts two
established conclusions: (a) Larger PLMs are more calibrated; (b) Pretraining
improves model calibration. Next, we study the effectiveness of existing
calibration methods in mitigating the overconfidence issue. Besides unlearnable
calibration methods (e.g., label smoothing), we adapt and extend two recently
proposed learnable methods that directly collect data to train models to have
reasonable confidence estimations. Experimental results show that learnable
methods significantly reduce PLMs' confidence in wrong predictions. The code is
available at \url{https://github.com/lifan-yuan/PLMCalibration}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Content-Aware Neural Text-To-Speech MOS Prediction Using Prosodic and Linguistic Features. (arXiv:2211.00342v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00342">
<div class="article-summary-box-inner">
<span><p>Current state-of-the-art methods for automatic synthetic speech evaluation
are based on MOS prediction neural models. Such MOS prediction models include
MOSNet and LDNet that use spectral features as input, and SSL-MOS that relies
on a pretrained self-supervised learning model that directly uses the speech
signal as input. In modern high-quality neural TTS systems, prosodic
appropriateness with regard to the spoken content is a decisive factor for
speech naturalness. For this reason, we propose to include prosodic and
linguistic features as additional inputs in MOS prediction systems, and
evaluate their impact on the prediction outcome. We consider phoneme level F0
and duration features as prosodic inputs, as well as Tacotron encoder outputs,
POS tags and BERT embeddings as higher-level linguistic inputs. All MOS
prediction systems are trained on SOMOS, a neural TTS-only dataset with
crowdsourced naturalness MOS evaluations. Results show that the proposed
additional features are beneficial in the MOS prediction task, by improving the
predicted MOS scores' correlation with the ground truths, both at
utterance-level and system-level predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations. (arXiv:2211.08794v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.08794">
<div class="article-summary-box-inner">
<span><p>Due to the huge amount of parameters, fine-tuning of pretrained language
models (PLMs) is prone to overfitting in the low resource scenarios. In this
work, we present a novel method that operates on the hidden representations of
a PLM to reduce overfitting. During fine-tuning, our method inserts random
autoencoders between the hidden layers of a PLM, which transform activations
from the previous layers into a multi-view compressed representation before
feeding it into the upper layers. The autoencoders are plugged out after
fine-tuning, so our method does not add extra parameters or increase
computation cost during inference. Our method demonstrates promising
performance improvement across a wide range of sequence- and token-level
low-resource NLP tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pivotal Role of Language Modeling in Recommender Systems: Enriching Task-specific and Task-agnostic Representation Learning. (arXiv:2212.03760v4 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03760">
<div class="article-summary-box-inner">
<span><p>Recent studies have proposed unified user modeling frameworks that leverage
user behavior data from various applications. Many of them benefit from
utilizing users' behavior sequences as plain texts, representing rich
information in any domain or system without losing generality. Hence, a
question arises: Can language modeling for user history corpus help improve
recommender systems? While its versatile usability has been widely investigated
in many domains, its applications to recommender systems still remain
underexplored. We show that language modeling applied directly to task-specific
user histories achieves excellent results on diverse recommendation tasks.
Also, leveraging additional task-agnostic user histories delivers significant
performance benefits. We further demonstrate that our approach can provide
promising transfer learning capabilities for a broad spectrum of real-world
recommender systems, even on unseen domains and services.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robustness of Learning from Task Instructions. (arXiv:2212.03813v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03813">
<div class="article-summary-box-inner">
<span><p>Traditional supervised learning mostly works on individual tasks and requires
training on a large set of task-specific examples. This paradigm seriously
hinders the development of task generalization since preparing a task-specific
example set is costly. To build a system that can quickly and easily generalize
to new tasks, task instructions have been adopted as an emerging trend of
supervision recently. These instructions give the model the definition of the
task and allow the model to output the appropriate answer based on the
instructions and inputs. However, task instructions are often expressed in
different forms, which can be interpreted from two threads: first, some
instructions are short sentences and are pretrained language model (PLM)
oriented, such as prompts, while other instructions are paragraphs and are
human-oriented, such as those in Amazon MTurk; second, different end-users very
likely explain the same task with instructions of different textual
expressions. A robust system for task generalization should be able to handle
any new tasks regardless of the variability of instructions.
</p>
<p>However, the system robustness in dealing with instruction-driven task
generalization is still unexplored. This work investigates the system
robustness when the instructions of new tasks are (i) manipulated, (ii)
paraphrased, or (iii) from different levels of conciseness. To our knowledge,
this is the first work that systematically studies how robust a PLM is when it
is supervised by instructions with different factors of variability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model. (arXiv:2212.09146v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09146">
<div class="article-summary-box-inner">
<span><p>Augmenting pretrained language models with retrievers to select the
supporting documents has shown promise in effectively solving common NLP
problems, including language modeling and question answering, in an
interpretable way. In this paper, we first study the strengths and weaknesses
of different retriever-augmented language models (REALM, $k$NN-LM, FiD coupled
with DPR, and ATLAS and Flan-T5 coupled with Contriever) in reasoning over the
retrieved statements in different tasks. We show how the retrieve-then-read
models' limitations in reasoning are rooted both in the retriever module as
well as the language model. Our experimental results demonstrate that the
similarity metric used by the retrievers is generally insufficient for
reasoning tasks. Additionally, we show that the language models in
retriever-augmented models do not take the complicated relations between the
statements into account, which leads to poor reasoning performance even when
using the larger models. Moreover, we analyze the reasoning performance of
large language models using multihop retrieval but we only observe minor
improvements. Overall, this shows great room for further research in this area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Meet NL2Code: A Survey. (arXiv:2212.09420v2 [cs.SE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09420">
<div class="article-summary-box-inner">
<span><p>The task of generating code from a natural language description, or NL2Code,
is considered a pressing and significant challenge in code intelligence. Thanks
to the rapid development of pre-training techniques, surging large language
models are being proposed for code, sparking the advances in NL2Code. To
facilitate further research and applications in this field, in this paper, we
present a comprehensive survey of 27 existing large language models for
NL2Code, and also review benchmarks and metrics. We provide an intuitive
comparison of all existing models on the HumanEval benchmark. Through in-depth
observation and analysis, we provide some insights and conclude that the key
factors contributing to the success of large language models for NL2Code are
"Large Size, Premium Data, Expert Tuning". In addition, we discuss challenges
and opportunities regarding the gap between models and humans. We also create a
website https://nl2code.github.io to track the latest progress through
crowd-sourcing. To the best of our knowledge, this is the first survey of large
language models for NL2Code, and we believe it will contribute to the ongoing
development of the field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09597">
<div class="article-summary-box-inner">
<span><p>Reasoning, as an essential ability for complex problem-solving, can provide
back-end support for various real-world applications, such as medical
diagnosis, negotiation, etc. This paper provides a comprehensive survey of
cutting-edge research on reasoning with language model prompting. We introduce
research works with comparisons and summaries and provide systematic resources
to help beginners. We also discuss the potential reasons for emerging such
reasoning abilities and highlight future research directions. Resources are
available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated
periodically).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Event Individuation for Document-Level Information Extraction. (arXiv:2212.09702v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09702">
<div class="article-summary-box-inner">
<span><p>As information extraction (IE) systems have grown more adept at processing
whole documents, the classic task of template filling has seen renewed interest
as benchmark for document-level IE. In this position paper, we call into
question the suitability of template filling for this purpose. We argue that
the task demands definitive answers to thorny questions of event individuation
-- the problem of distinguishing distinct events -- about which even human
experts disagree. Through an annotation study and error analysis, we show that
this raises concerns about the usefulness of template filling metrics, the
quality of datasets for the task, and the ability of models to learn it.
Finally, we consider possible solutions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does GPT-3 Demonstrate Psychopathy? Evaluating Large Language Models from a Psychological Perspective. (arXiv:2212.10529v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10529">
<div class="article-summary-box-inner">
<span><p>In this work, we determined whether large language models (LLMs) are
psychologically safe. We designed unbiased prompts to systematically evaluate
LLMs from a psychological perspective. First, we tested three different LLMs by
using two personality tests: Short Dark Triad (SD-3) and Big Five Inventory
(BFI). All models scored higher than the human average on SD-3, suggesting a
relatively darker personality pattern. Despite being instruction fine-tuned
with safety metrics to reduce toxicity, InstructGPT and FLAN-T5 still showed
implicit dark personality patterns; both models scored higher than
self-supervised GPT-3 on the Machiavellianism and narcissism traits on SD-3.
Then, we evaluated the LLMs in the GPT-3 series by using well-being tests to
study the impact of fine-tuning with more training data. We observed a
continuous increase in the well-being scores of GPT-3 and InstructGPT.
Following these observations, we showed that instruction fine-tuning FLAN-T5
with positive answers from BFI could effectively improve the model from a
psychological perspective. On the basis of the findings, we recommended the
application of more systematic and comprehensive psychological metrics to
further evaluate and improve the safety of LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ALCAP: Alignment-Augmented Music Captioner. (arXiv:2212.10901v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10901">
<div class="article-summary-box-inner">
<span><p>Growing popularity of streaming media platforms for music search and
recommendations has led to a need for novel methods for interpreting music that
take into account both lyrics and audio. However, many previous works focus on
refining individual components of encoder-decoder architecture that maps music
to caption tokens, ignoring the potential benefits of correspondence between
audio and lyrics. In this paper, we propose to explicitly learn the multimodal
alignment through contrastive learning. By learning audio-lyrics
correspondence, the model is guided to learn better cross-modal consistency,
thus generating high-quality captions. We provide both theoretical and
empirical results demonstrating the advantage of the proposed method, and
achieve new state-of-the-art on two music captioning datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Double Permutation Equivariance for Knowledge Graph Completion. (arXiv:2302.01313v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01313">
<div class="article-summary-box-inner">
<span><p>This work provides a formalization of Knowledge Graphs (KGs) as a new class
of graphs that we denote doubly exchangeable attributed graphs, where node and
pairwise (joint 2-node) representations must be equivariant to permutations of
both node ids and edge (&amp; node) attributes (relations &amp; node features).
Double-permutation equivariant KG representations open a new research direction
in KGs. We show that this equivariance imposes a structural representation of
relations that allows neural networks to perform complex logical reasoning
tasks in KGs. Finally, we introduce a general blueprint for such equivariant
representations and test a simple GNN-based double-permutation equivariant
neural architecture that achieve state-of-the-art Hits@10 test accuracy in the
WN18RR, FB237 and NELL995 inductive KG completion tasks, and can accurately
perform logical reasoning tasks that no existing methods can perform, to the
best of our knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Re-Label Method For Data-Centric Machine Learning. (arXiv:2302.04391v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04391">
<div class="article-summary-box-inner">
<span><p>In industry deep learning application, our manually labeled data has a
certain number of noisy data. To solve this problem and achieve more than 90
score in dev dataset, we present a simple method to find the noisy data and
re-label the noisy data by human, given the model predictions as references in
human labeling. In this paper, we illustrate our idea for a broad set of deep
learning tasks, includes classification, sequence tagging, object detection,
sequence generation, click-through rate prediction. The experimental results
and human evaluation results verify our idea.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Model Analysis for Ontology Subsumption Inference. (arXiv:2302.06761v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.06761">
<div class="article-summary-box-inner">
<span><p>Investigating whether pre-trained language models (LMs) can function as
knowledge bases (KBs) has raised wide research interests recently. However,
existing works focus on simple, triple-based, relational KBs, but omit more
sophisticated, logic-based, conceptualised KBs such as OWL ontologies. To
investigate an LM's knowledge of ontologies, we propose OntoLAMA, a set of
inference-based probing tasks and datasets from ontology subsumption axioms
involving both atomic and complex concepts. We conduct extensive experiments on
ontologies of different domains and scales, and our results demonstrate that
LMs encode relatively less background knowledge of Subsumption Inference (SI)
than traditional Natural Language Inference (NLI) but can improve on SI
significantly when a small number of samples are given. We will open-source our
code and datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SemEval-2023 Task 10: Explainable Detection of Online Sexism. (arXiv:2303.04222v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04222">
<div class="article-summary-box-inner">
<span><p>Online sexism is a widespread and harmful phenomenon. Automated tools can
assist the detection of sexism at scale. Binary detection, however, disregards
the diversity of sexist content, and fails to provide clear explanations for
why something is sexist. To address this issue, we introduce SemEval Task 10 on
the Explainable Detection of Online Sexism (EDOS). We make three main
contributions: i) a novel hierarchical taxonomy of sexist content, which
includes granular vectors of sexism to aid explainability; ii) a new dataset of
20,000 social media comments with fine-grained labels, along with larger
unlabelled datasets for model adaptation; and iii) baseline models as well as
an analysis of the methods, results and errors for participant submissions to
our task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Refined Vision-Language Modeling for Fine-grained Multi-modal Pre-training. (arXiv:2303.05313v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.05313">
<div class="article-summary-box-inner">
<span><p>Fine-grained supervision based on object annotations has been widely used for
vision and language pre-training (VLP). However, in real-world application
scenarios, aligned multi-modal data is usually in the image-caption format,
which only provides coarse-grained supervision. It is not only cost-expensive
but also compute-expensive to collect object annotations and build object
annotation pre-extractor for different scenarios. In this paper, we propose a
fine-grained VLP scheme without object annotations from the linguistic
perspective. First, we propose a homonym sentence rewriting (HSR) algorithm to
provide token-level supervision. The algorithm replaces a
verb/noun/adjective/quantifier word of the caption with its homonyms from
WordNet. Correspondingly, we propose refined vision-language modeling (RVLM)
framework to exploit the token-level supervision. Three refined tasks, i.e.,
refined image-text contrastive (RITC), refined image-text matching (RITM), and
replace language modeling (RLM) are proposed to learn the fine-grained
alignment. Extensive experiments on several downstream tasks demonstrate the
superior performance of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Single Items: Exploring User Preferences in Item Sets with the Conversational Playlist Curation Dataset. (arXiv:2303.06791v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.06791">
<div class="article-summary-box-inner">
<span><p>Users in consumption domains, like music, are often able to more efficiently
provide preferences over a set of items (e.g. a playlist or radio) than over
single items (e.g. songs). Unfortunately, this is an underexplored area of
research, with most existing recommendation systems limited to understanding
preferences over single items. Curating an item set exponentiates the search
space that recommender systems must consider (all subsets of items!): this
motivates conversational approaches-where users explicitly state or refine
their preferences and systems elicit preferences in natural language-as an
efficient way to understand user needs. We call this task conversational item
set curation and present a novel data collection methodology that efficiently
collects realistic preferences about item sets in a conversational setting by
observing both item-level and set-level feedback. We apply this methodology to
music recommendation to build the Conversational Playlist Curation Dataset
(CPCD), where we show that it leads raters to express preferences that would
not be otherwise expressed. Finally, we propose a wide range of conversational
retrieval models as baselines for this task and evaluate them on the dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Geolocation Predicting of Tweets Using BERT-Based Models. (arXiv:2303.07865v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.07865">
<div class="article-summary-box-inner">
<span><p>This research is aimed to solve the tweet/user geolocation prediction task
and provide a flexible methodology for the geotagging of textual big data. The
suggested approach implements neural networks for natural language processing
(NLP) to estimate the location as coordinate pairs (longitude, latitude) and
two-dimensional Gaussian Mixture Models (GMMs). The scope of proposed models
has been finetuned on a Twitter dataset using pretrained Bidirectional Encoder
Representations from Transformers (BERT) as base models. Performance metrics
show a median error of fewer than 30 km on a worldwide-level, and fewer than 15
km on the US-level datasets for the models trained and evaluated on text
features of tweets' content and metadata context. Our source code and data are
available at https://github.com/K4TEL/geo-twitter.git
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models. (arXiv:2303.08896v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08896">
<div class="article-summary-box-inner">
<span><p>Generative Large Language Models (LLMs) such as GPT-3 are capable of
generating highly fluent responses to a wide variety of user prompts. However,
LLMs are known to hallucinate facts and make non-factual statements which can
undermine trust in their output. Existing fact-checking approaches either
require access to the output probability distribution (which may not be
available for systems such as ChatGPT) or external databases that are
interfaced via separate, often complex, modules. In this work, we propose
"SelfCheckGPT", a simple sampling-based approach that can be used to fact-check
black-box models in a zero-resource fashion, i.e. without an external database.
SelfCheckGPT leverages the simple idea that if a LLM has knowledge of a given
concept, sampled responses are likely to be similar and contain consistent
facts. However, for hallucinated facts, stochastically sampled responses are
likely to diverge and contradict one another. We investigate this approach by
using GPT-3 to generate passages about individuals from the WikiBio dataset,
and manually annotate the factuality of the generated passages. We demonstrate
that SelfCheckGPT can: i) detect non-factual and factual sentences; and ii)
rank passages in terms of factuality. We compare our approach to several
baselines and show that in sentence hallucination detection, our approach has
AUC-PR scores comparable to or better than grey-box methods, while SelfCheckGPT
is best at passage factuality assessment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SmartBERT: A Promotion of Dynamic Early Exiting Mechanism for Accelerating BERT Inference. (arXiv:2303.09266v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09266">
<div class="article-summary-box-inner">
<span><p>Dynamic early exiting has been proven to improve the inference speed of the
pre-trained language model like BERT. However, all samples must go through all
consecutive layers before early exiting and more complex samples usually go
through more layers, which still exists redundant computation. In this paper,
we propose a novel dynamic early exiting combined with layer skipping for BERT
inference named SmartBERT, which adds a skipping gate and an exiting operator
into each layer of BERT. SmartBERT can adaptively skip some layers and
adaptively choose whether to exit. Besides, we propose cross-layer contrastive
learning and combine it into our training phases to boost the intermediate
layers and classifiers which would be beneficial for early exiting. To keep the
consistent usage of skipping gates between training and inference phases, we
propose a hard weight mechanism during training phase. We conduct experiments
on eight classification datasets of the GLUE benchmark. Experimental results
show that SmartBERT achieves 2-3x computation reduction with minimal accuracy
drops compared with BERT and our method outperforms previous methods in both
efficiency and accuracy. Moreover, in some complex datasets like RTE and WNLI,
we prove that the early exiting based on entropy hardly works, and the skipping
mechanism is essential for reducing computation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trained on 100 million words and still in shape: BERT meets British National Corpus. (arXiv:2303.09859v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09859">
<div class="article-summary-box-inner">
<span><p>While modern masked language models (LMs) are trained on ever larger corpora,
we here explore the effects of down-scaling training to a modestly-sized but
representative, well-balanced, and publicly available English text source --
the British National Corpus. We show that pre-training on this carefully
curated corpus can reach better performance than the original BERT model. We
argue that this type of corpora has great potential as a language modeling
benchmark. To showcase this potential, we present fair, reproducible and
data-efficient comparative studies of LMs, in which we evaluate several
training objectives and model architectures and replicate previous empirical
results in a systematic way. We propose an optimized LM architecture called
LTG-BERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep RL with Hierarchical Action Exploration for Dialogue Generation. (arXiv:2303.13465v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.13465">
<div class="article-summary-box-inner">
<span><p>Traditionally, approximate dynamic programming is employed in dialogue
generation with greedy policy improvement through action sampling, as the
natural language action space is vast. However, this practice is inefficient
for reinforcement learning (RL) due to the sparsity of eligible responses with
high action values, which leads to weak improvement sustained by random
sampling. This paper presents theoretical analysis and experiments showing that
the dialogue policy's performance is positively correlated with the sampling
size. To alleviate this limitation, we introduce a novel dual-granularity
Q-function that explores the most promising response category to intervene in
the sampling process. Our approach extracts actions based on a grained
hierarchy, achieving the optimum with fewer policy iterations. Additionally, we
use offline RL and learn from multiple reward functions designed to capture
emotional nuances in human interactions. Empirical studies demonstrate that our
algorithm outperforms baselines across automatic metrics and human evaluations.
Further testing reveals that ours generates responses with higher expected
rewards and controllability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bias or Diversity? Unraveling Fine-Grained Thematic Discrepancy in U.S. News Headlines. (arXiv:2303.15708v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.15708">
<div class="article-summary-box-inner">
<span><p>There is a broad consensus that news media outlets incorporate ideological
biases in their news articles. However, prior studies on measuring the
discrepancies among media outlets and further dissecting the origins of
thematic differences suffer from small sample sizes and limited scope and
granularity. In this study, we use a large dataset of 1.8 million news
headlines from major U.S. media outlets spanning from 2014 to 2022 to
thoroughly track and dissect the fine-grained thematic discrepancy in U.S. news
media. We employ multiple correspondence analysis (MCA) to quantify the
fine-grained thematic discrepancy related to four prominent topics - domestic
politics, economic issues, social issues, and foreign affairs in order to
derive a more holistic analysis. Additionally, we compare the most frequent
$n$-grams in media headlines to provide further qualitative insights into our
analysis. Our findings indicate that on domestic politics and social issues,
the discrepancy can be attributed to a certain degree of media bias. Meanwhile,
the discrepancy in reporting foreign affairs is largely attributed to the
diversity in individual journalistic styles. Finally, U.S. media outlets show
consistency and high similarity in their coverage of economic issues.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Large Language Models. (arXiv:2303.18223v10 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18223">
<div class="article-summary-box-inner">
<span><p>Language is essentially a complex, intricate system of human expressions
governed by grammatical rules. It poses a significant challenge to develop
capable AI algorithms for comprehending and grasping a language. As a major
approach, language modeling has been widely studied for language understanding
and generation in the past two decades, evolving from statistical language
models to neural language models. Recently, pre-trained language models (PLMs)
have been proposed by pre-training Transformer models over large-scale corpora,
showing strong capabilities in solving various NLP tasks. Since researchers
have found that model scaling can lead to performance improvement, they further
study the scaling effect by increasing the model size to an even larger size.
Interestingly, when the parameter scale exceeds a certain level, these enlarged
language models not only achieve a significant performance improvement but also
show some special abilities that are not present in small-scale language
models. To discriminate the difference in parameter scale, the research
community has coined the term large language models (LLM) for the PLMs of
significant size. Recently, the research on LLMs has been largely advanced by
both academia and industry, and a remarkable progress is the launch of ChatGPT,
which has attracted widespread attention from society. The technical evolution
of LLMs has been making an important impact on the entire AI community, which
would revolutionize the way how we develop and use AI algorithms. In this
survey, we review the recent advances of LLMs by introducing the background,
key findings, and mainstream techniques. In particular, we focus on four major
aspects of LLMs, namely pre-training, adaptation tuning, utilization, and
capacity evaluation. Besides, we also summarize the available resources for
developing LLMs and discuss the remaining issues for future directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spam-T5: Benchmarking Large Language Models for Few-Shot Email Spam Detection. (arXiv:2304.01238v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.01238">
<div class="article-summary-box-inner">
<span><p>This paper investigates the effectiveness of large language models (LLMs) in
email spam detection by comparing prominent models from three distinct
families: BERT-like, Sentence Transformers, and Seq2Seq. Additionally, we
examine well-established machine learning techniques for spam detection, such
as Na\"ive Bayes and LightGBM, as baseline methods. We assess the performance
of these models across four public datasets, utilizing different numbers of
training samples (full training set and few-shot settings). Our findings reveal
that, in the majority of cases, LLMs surpass the performance of the popular
baseline techniques, particularly in few-shot scenarios. This adaptability
renders LLMs uniquely suited to spam detection tasks, where labeled samples are
limited in number and models require frequent updates. Additionally, we
introduce Spam-T5, a Flan-T5 model that has been specifically adapted and
fine-tuned for the purpose of detecting email spam. Our results demonstrate
that Spam-T5 surpasses baseline models and other LLMs in the majority of
scenarios, particularly when there are a limited number of training samples
available. Our code is publicly available at
https://github.com/jpmorganchase/emailspamdetection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models. (arXiv:2304.01933v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.01933">
<div class="article-summary-box-inner">
<span><p>The success of large language models (LLMs), like GPT-3 and ChatGPT, has led
to the development of numerous cost-effective and accessible alternatives that
are created by fine-tuning open-access LLMs with task-specific data (e.g.,
ChatDoctor) or instruction data (e.g., Alpaca). Among the various fine-tuning
methods, adapter-based parameter-efficient fine-tuning (PEFT) is undoubtedly
one of the most attractive topics, as it only requires fine-tuning a few
external parameters instead of the entire LLMs while achieving comparable or
even better performance. To enable further research on PEFT methods of LLMs,
this paper presents LLM-Adapters, an easy-to-use framework that integrates
various adapters into LLMs and can execute these adapter-based PEFT methods of
LLMs for different tasks. The framework includes state-of-the-art open-access
LLMs such as LLaMA, BLOOM, OPT, and GPT-J, as well as widely used adapters such
as Series adapter, Parallel adapter, and LoRA. The framework is designed to be
research-friendly, efficient, modular, and extendable, allowing the integration
of new adapters and the evaluation of them with new and larger-scale LLMs.
Furthermore, to evaluate the effectiveness of adapters in LLMs-Adapters, we
conduct experiments on six math reasoning datasets. The results demonstrate
that using adapter-based PEFT in smaller-scale LLMs (7B) with few extra
trainable parameters yields comparable, and in some cases superior, performance
to that of powerful LLMs (175B) in zero-shot inference on simple math reasoning
datasets. Overall, we provide a promising framework for fine-tuning large LLMs
on downstream tasks. We believe the proposed LLMs-Adapters will advance
adapter-based PEFT research, facilitate the deployment of research pipelines,
and enable practical applications to real-world systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Examining Temporalities on Stance Detection towards COVID-19 Vaccination. (arXiv:2304.04806v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.04806">
<div class="article-summary-box-inner">
<span><p>Previous studies have highlighted the importance of vaccination as an
effective strategy to control the transmission of the COVID-19 virus. It is
crucial for policymakers to have a comprehensive understanding of the public's
stance towards vaccination on a large scale. However, attitudes towards
COVID-19 vaccination, such as pro-vaccine or vaccine hesitancy, have evolved
over time on social media. Thus, it is necessary to account for possible
temporal shifts when analysing these stances. This study aims to examine the
impact of temporal concept drift on stance detection towards COVID-19
vaccination on Twitter. To this end, we evaluate a range of transformer-based
models using chronological (split the training, validation and testing sets in
the order of time) and random splits (randomly split these three sets) of
social media data. Our findings demonstrate significant discrepancies in model
performance when comparing random and chronological splits across all
monolingual and multilingual datasets. Chronological splits significantly
reduce the accuracy of stance classification. Therefore, real-world stance
detection approaches need to be further refined to incorporate temporal factors
as a key consideration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Large-Scale Comparative Study of Accurate COVID-19 Information versus Misinformation. (arXiv:2304.04811v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.04811">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic led to an infodemic where an overwhelming amount of
COVID-19 related content was being disseminated at high velocity through social
media. This made it challenging for citizens to differentiate between accurate
and inaccurate information about COVID-19. This motivated us to carry out a
comparative study of the characteristics of COVID-19 misinformation versus
those of accurate COVID-19 information through a large-scale computational
analysis of over 242 million tweets. The study makes comparisons alongside four
key aspects: 1) the distribution of topics, 2) the live status of tweets, 3)
language analysis and 4) the spreading power over time. An added contribution
of this study is the creation of a COVID-19 misinformation classification
dataset. Finally, we demonstrate that this new dataset helps improve
misinformation classification by more than 9\% based on average F1 measure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Romanian Multiword Expression Detection Using Multilingual Adversarial Training and Lateral Inhibition. (arXiv:2304.11350v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11350">
<div class="article-summary-box-inner">
<span><p>Multiword expressions are a key ingredient for developing large-scale and
linguistically sound natural language processing technology. This paper
describes our improvements in automatically identifying Romanian multiword
expressions on the corpus released for the PARSEME v1.2 shared task. Our
approach assumes a multilingual perspective based on the recently introduced
lateral inhibition layer and adversarial training to boost the performance of
the employed multilingual language models. With the help of these two methods,
we improve the F1-score of XLM-RoBERTa by approximately 2.7% on unseen
multiword expressions, the main task of the PARSEME 1.2 edition. In addition,
our results can be considered SOTA performance, as they outperform the previous
results on Romanian obtained by the participants in this competition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GlyphDiffusion: Text Generation as Image Generation. (arXiv:2304.12519v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12519">
<div class="article-summary-box-inner">
<span><p>Diffusion models have become a new generative paradigm for text generation.
Considering the discrete categorical nature of text, in this paper, we propose
GlyphDiffusion, a novel diffusion approach for text generation via text-guided
image generation. Our key idea is to render the target text as a glyph image
containing visual language content. In this way, conditional text generation
can be cast as a glyph image generation task, and it is then natural to apply
continuous diffusion models to discrete texts. Specially, we utilize a cascaded
architecture (ie a base and a super-resolution diffusion model) to generate
high-fidelity glyph images, conditioned on the input text. Furthermore, we
design a text grounding module to transform and refine the visual language
content from generated glyph images into the final texts. In experiments over
four conditional text generation tasks and two classes of metrics (ie quality
and diversity), GlyphDiffusion can achieve comparable or even better results
than several baselines, including pretrained language models. Our model also
makes significant improvements compared to the recent diffusion model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Association to Generation: Text-only Captioning by Unsupervised Cross-modal Mapping. (arXiv:2304.13273v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.13273">
<div class="article-summary-box-inner">
<span><p>With the development of Vision-Language Pre-training Models (VLPMs)
represented by CLIP and ALIGN, significant breakthroughs have been achieved for
association-based visual tasks such as image classification and image-text
retrieval by the zero-shot capability of CLIP without fine-tuning. However,
CLIP is hard to apply to generation-based tasks. This is due to the lack of
decoder architecture and pre-training tasks for generation. Although previous
works have created generation capacity for CLIP through additional language
models, a modality gap between the CLIP representations of different modalities
and the inability of CLIP to model the offset of this gap, which fails the
concept to transfer across modalities. To solve the problem, we try to map
images/videos to the language modality and generate captions from the language
modality. In this paper, we propose the K-nearest-neighbor Cross-modality
Mapping (Knight), a zero-shot method from association to generation. With
text-only unsupervised training, Knight achieves State-of-the-Art performance
in zero-shot methods for image captioning and video captioning. Our code is
available at https://github.com/junyangwang0410/Knight.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Energy-based Models are Zero-Shot Planners for Compositional Scene Rearrangement. (arXiv:2304.14391v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.14391">
<div class="article-summary-box-inner">
<span><p>Language is compositional; an instruction can express multiple relation
constraints to hold among objects in a scene that a robot is tasked to
rearrange. Our focus in this work is an instructable scene-rearranging
framework that generalizes to longer instructions and to spatial concept
compositions never seen at training time. We propose to represent
language-instructed spatial concepts with energy functions over relative object
arrangements. A language parser maps instructions to corresponding energy
functions and an open-vocabulary visual-language model grounds their arguments
to relevant objects in the scene. We generate goal scene configurations by
gradient descent on the sum of energy functions, one per language predicate in
the instruction. Local vision-based policies then re-locate objects to the
inferred goal locations. We test our model on established instruction-guided
manipulation benchmarks, as well as benchmarks of compositional instructions we
introduce. We show our model can execute highly compositional instructions
zero-shot in simulation and in the real world. It outperforms
language-to-action reactive policies and Large Language Model planners by a
large margin, especially for long instructions that involve compositions of
multiple spatial concepts. Simulation and real-world robot execution videos, as
well as our code and datasets are publicly available on our website:
https://ebmplanner.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. (arXiv:2305.00050v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.00050">
<div class="article-summary-box-inner">
<span><p>The causal capabilities of large language models (LLMs) is a matter of
significant debate, with critical implications for the use of LLMs in
societally impactful domains such as medicine, science, law, and policy. We
further our understanding of LLMs and their causal implications, considering
the distinctions between different types of causal reasoning tasks, as well as
the entangled threats of construct and measurement validity. LLM-based methods
establish new state-of-the-art accuracies on multiple causal benchmarks.
Algorithms based on GPT-3.5 and 4 outperform existing algorithms on a pairwise
causal discovery task (97%, 13 points gain), counterfactual reasoning task
(92%, 20 points gain), and actual causality (86% accuracy in determining
necessary and sufficient causes in vignettes). At the same time, LLMs exhibit
unpredictable failure modes and we provide some techniques to interpret their
robustness.
</p>
<p>Crucially, LLMs perform these causal tasks while relying on sources of
knowledge and methods distinct from and complementary to non-LLM based
approaches. Specifically, LLMs bring capabilities so far understood to be
restricted to humans, such as using collected knowledge to generate causal
graphs or identifying background causal context from natural language. We
envision LLMs to be used alongside existing causal methods, as a proxy for
human domain knowledge and to reduce human effort in setting up a causal
analysis, one of the biggest impediments to the widespread adoption of causal
methods. We also see existing causal methods as promising tools for LLMs to
formalize, validate, and communicate their reasoning especially in high-stakes
scenarios.
</p>
<p>In capturing common sense and domain knowledge about causal mechanisms and
supporting translation between natural language and formal methods, LLMs open
new frontiers for advancing the research, practice, and adoption of causality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Still no evidence for an effect of the proportion of non-native speakers on language complexity -- A response to Kauhanen, Einhaus & Walkden (2023). (arXiv:2305.00217v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.00217">
<div class="article-summary-box-inner">
<span><p>In a recent paper published in the Journal of Language Evolution, Kauhanen,
Einhaus &amp; Walkden (https://doi.org/10.1093/jole/lzad005, KEW) challenge the
results presented in one of my papers (Koplenig, Royal Society Open Science, 6,
181274 (2019), https://doi.org/10.1098/rsos.181274), in which I tried to show
through a series of statistical analyses that large numbers of L2 (second
language) speakers do not seem to affect the (grammatical or statistical)
complexity of a language. To this end, I focus on the way in which the
Ethnologue assesses language status: a language is characterised as vehicular
if, in addition to being used by L1 (first language) speakers, it should also
have a significant number of L2 users. KEW criticise both the use of
vehicularity as a (binary) indicator of whether a language has a significant
number of L2 users and the idea of imputing a zero proportion of L2 speakers to
non-vehicular languages whenever a direct estimate of that proportion is
unavailable. While I recognise the importance of post-publication commentary on
published research, I show in this rejoinder that both points of criticism are
explicitly mentioned and analysed in my paper. In addition, I also comment on
other points raised by KEW and demonstrate that both alternative analyses
offered by KEW do not stand up to closer scrutiny.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models. (arXiv:2305.01219v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01219">
<div class="article-summary-box-inner">
<span><p>The prompt-based learning paradigm, which bridges the gap between
pre-training and fine-tuning, achieves state-of-the-art performance on several
NLP tasks, particularly in few-shot settings. Despite being widely applied,
prompt-based learning is vulnerable to backdoor attacks. Textual backdoor
attacks are designed to introduce targeted vulnerabilities into models by
poisoning a subset of training samples through trigger injection and label
modification. However, they suffer from flaws such as abnormal natural language
expressions resulting from the trigger and incorrect labeling of poisoned
samples. In this study, we propose ProAttack, a novel and efficient method for
performing clean-label backdoor attacks based on the prompt, which uses the
prompt itself as a trigger. Our method does not require external triggers and
ensures correct labeling of poisoned samples, improving the stealthy nature of
the backdoor attack. With extensive experiments on rich-resource and few-shot
text classification tasks, we empirically validate ProAttack's competitive
performance in textual backdoor attacks. Notably, in the rich-resource setting,
ProAttack achieves state-of-the-art attack success rates in the clean-label
backdoor attack benchmark without external triggers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Study on the Integration of Pipeline and E2E SLU systems for Spoken Semantic Parsing toward STOP Quality Challenge. (arXiv:2305.01620v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01620">
<div class="article-summary-box-inner">
<span><p>Recently there have been efforts to introduce new benchmark tasks for spoken
language understanding (SLU), like semantic parsing. In this paper, we describe
our proposed spoken semantic parsing system for the quality track (Track 1) in
Spoken Language Understanding Grand Challenge which is part of ICASSP Signal
Processing Grand Challenge 2023. We experiment with both end-to-end and
pipeline systems for this task. Strong automatic speech recognition (ASR)
models like Whisper and pretrained Language models (LM) like BART are utilized
inside our SLU framework to boost performance. We also investigate the output
level combination of various models to get an exact match accuracy of 80.8,
which won the 1st place at the challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causality-aware Concept Extraction based on Knowledge-guided Prompting. (arXiv:2305.01876v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01876">
<div class="article-summary-box-inner">
<span><p>Concepts benefit natural language understanding but are far from complete in
existing knowledge graphs (KGs). Recently, pre-trained language models (PLMs)
have been widely used in text-based concept extraction (CE). However, PLMs tend
to mine the co-occurrence associations from massive corpus as pre-trained
knowledge rather than the real causal effect between tokens. As a result, the
pre-trained knowledge confounds PLMs to extract biased concepts based on
spurious co-occurrence correlations, inevitably resulting in low precision. In
this paper, through the lens of a Structural Causal Model (SCM), we propose
equipping the PLM-based extractor with a knowledge-guided prompt as an
intervention to alleviate concept bias. The prompt adopts the topic of the
given entity from the existing knowledge in KGs to mitigate the spurious
co-occurrence correlations between entities and biased concepts. Our extensive
experiments on representative multilingual KG datasets justify that our
proposed prompt can effectively alleviate concept bias and improve the
performance of PLM-based CE models.The code has been released on
https://github.com/siyuyuan/KPCE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Language Models on Low-end Hardware. (arXiv:2305.02350v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02350">
<div class="article-summary-box-inner">
<span><p>This paper evaluates the viability of using fixed language models for
training text classification networks on low-end hardware. We combine language
models with a CNN architecture and put together a comprehensive benchmark with
8 datasets covering single-label and multi-label classification of topic,
sentiment, and genre. Our observations are distilled into a list of trade-offs,
concluding that there are scenarios, where not fine-tuning a language model
yields competitive effectiveness at faster training, requiring only a quarter
of the memory compared to fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents. (arXiv:2305.02412v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02412">
<div class="article-summary-box-inner">
<span><p>Pre-trained large language models (LLMs) capture procedural knowledge about
the world. Recent work has leveraged LLM's ability to generate abstract plans
to simplify challenging control tasks, either by action scoring, or action
modeling (fine-tuning). However, the transformer architecture inherits several
constraints that make it difficult for the LLM to directly serve as the agent:
e.g. limited input lengths, fine-tuning inefficiency, bias from pre-training,
and incompatibility with non-text environments. To maintain compatibility with
a low-level trainable actor, we propose to instead use the knowledge in LLMs to
simplify the control problem, rather than solving it. We propose the Plan,
Eliminate, and Track (PET) framework. The Plan module translates a task
description into a list of high-level sub-tasks. The Eliminate module masks out
irrelevant objects and receptacles from the observation for the current
sub-task. Finally, the Track module determines whether the agent has
accomplished each sub-task. On the AlfWorld instruction following benchmark,
the PET framework leads to a significant 15% improvement over SOTA for
generalization to human goal specifications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neighboring Words Affect Human Interpretation of Saliency Explanations. (arXiv:2305.02679v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02679">
<div class="article-summary-box-inner">
<span><p>Word-level saliency explanations ("heat maps over words") are often used to
communicate feature-attribution in text-based models. Recent studies found that
superficial factors such as word length can distort human interpretation of the
communicated saliency scores. We conduct a user study to investigate how the
marking of a word's neighboring words affect the explainee's perception of the
word's importance in the context of a saliency explanation. We find that
neighboring words have significant effects on the word's importance rating.
Concretely, we identify that the influence changes based on neighboring
direction (left vs. right) and a-priori linguistic and computational measures
of phrases and collocations (vs. unrelated neighboring words). Our results
question whether text-based saliency explanations should be continued to be
communicated at word level, and inform future research on alternative saliency
explanation methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Big Data and Large Numbers. Interpreting Zipf's Law. (arXiv:2305.02687v2 [physics.soc-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02687">
<div class="article-summary-box-inner">
<span><p>It turns out that some empirical facts in Big Data are the effects of
properties of large numbers. Zipf's law 'noise' is an example of such an
artefact. We expose several properties of the power law distributions and of
similar distribution that occur when the population is finite and the rank and
counts of elements in the population are natural numbers. We are particularly
concerned with the low-rank end of the graph of the law, the potential of noise
in the law, and with the approximation of the number of types of objects at
various ranks. Approximations instead of exact solutions are the center of
attention. Consequences in the interpretation of Zipf's law are discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">White-Box Multi-Objective Adversarial Attack on Dialogue Generation. (arXiv:2305.03655v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03655">
<div class="article-summary-box-inner">
<span><p>Pre-trained transformers are popular in state-of-the-art dialogue generation
(DG) systems. Such language models are, however, vulnerable to various
adversarial samples as studied in traditional tasks such as text
classification, which inspires our curiosity about their robustness in DG
systems. One main challenge of attacking DG models is that perturbations on the
current sentence can hardly degrade the response accuracy because the unchanged
chat histories are also considered for decision-making. Instead of merely
pursuing pitfalls of performance metrics such as BLEU, ROUGE, we observe that
crafting adversarial samples to force longer generation outputs benefits attack
effectiveness -- the generated responses are typically irrelevant, lengthy, and
repetitive. To this end, we propose a white-box multi-objective attack method
called DGSlow. Specifically, DGSlow balances two objectives -- generation
accuracy and length, via a gradient-based multi-objective optimizer and applies
an adaptive searching mechanism to iteratively craft adversarial samples with
only a few modifications. Comprehensive experiments on four benchmark datasets
demonstrate that DGSlow could significantly degrade state-of-the-art DG models
with a higher success rate than traditional accuracy-based methods. Besides,
our crafted sentences also exhibit strong transferability in attacking other
models.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-05-09 23:11:27.711108523 UTC">2023-05-09 23:11:27 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>