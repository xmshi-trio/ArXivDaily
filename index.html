<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-04-03T01:30:00Z">04-03</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">oBERTa: Improving Sparse Transfer Learning via improved initialization, distillation, and pruning regimes. (arXiv:2303.17612v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17612">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce the range of oBERTa language models, an
easy-to-use set of language models, which allows Natural Language Processing
(NLP) practitioners to obtain between 3.8 and 24.3 times faster models without
expertise in model compression. Specifically, oBERTa extends existing work on
pruning, knowledge distillation, and quantization and leverages frozen
embeddings to improve knowledge distillation, and improved model initialization
to deliver higher accuracy on a a broad range of transfer tasks. In generating
oBERTa, we explore how the highly optimized RoBERTa differs from the BERT with
respect to pruning during pre-training and fine-tuning and find it less
amenable to compression during fine-tuning. We explore the use of oBERTa on a
broad seven representative NLP tasks and find that the improved compression
techniques allow a pruned oBERTa model to match the performance of BERTBASE and
exceed the performance of Prune OFA Large on the SQUAD V1.1 Question Answering
dataset, despite being 8x and 2x, respectively, faster in inference. We release
our code, training regimes, and associated model for broad usage to encourage
usage and experimentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting and Grounding Important Characters in Visual Stories. (arXiv:2303.17647v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17647">
<div class="article-summary-box-inner">
<span><p>Characters are essential to the plot of any story. Establishing the
characters before writing a story can improve the clarity of the plot and the
overall flow of the narrative. However, previous work on visual storytelling
tends to focus on detecting objects in images and discovering relationships
between them. In this approach, characters are not distinguished from other
objects when they are fed into the generation pipeline. The result is a
coherent sequence of events rather than a character-centric story. In order to
address this limitation, we introduce the VIST-Character dataset, which
provides rich character-centric annotations, including visual and textual
co-reference chains and importance ratings for characters. Based on this
dataset, we propose two new tasks: important character detection and character
grounding in visual stories. For both tasks, we develop simple, unsupervised
models based on distributional similarity and pre-trained vision-and-language
models. Our new dataset, together with these models, can serve as the
foundation for subsequent work on analysing and generating stories from a
character-centric perspective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Aligning a medium-size GPT model in English to a small closed domain in Spanish using reinforcement learning. (arXiv:2303.17649v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17649">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a methodology to align a medium-sized GPT model,
originally trained in English for an open domain, to a small closed domain in
Spanish. The application for which the model is finely tuned is the question
answering task. To achieve this we also needed to train and implement another
neural network (which we called the reward model) that could score and
determine whether an answer is appropriate for a given question. This component
served to improve the decoding and generation of the answers of the system.
Numerical metrics such as BLEU and perplexity were used to evaluate the model,
and human judgment was also used to compare the decoding technique with others.
Finally, the results favored the proposed method, and it was determined that it
is feasible to use a reward model to align the generation of responses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparing Abstractive Summaries Generated by ChatGPT to Real Summaries Through Blinded Reviewers and Text Classification Algorithms. (arXiv:2303.17650v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17650">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have gathered significant attention due to their
impressive performance on a variety of tasks. ChatGPT, developed by OpenAI, is
a recent addition to the family of language models and is being called a
disruptive technology by a few, owing to its human-like text-generation
capabilities. Although, many anecdotal examples across the internet have
evaluated ChatGPT's strength and weakness, only a few systematic research
studies exist. To contribute to the body of literature of systematic research
on ChatGPT, we evaluate the performance of ChatGPT on Abstractive Summarization
by the means of automated metrics and blinded human reviewers. We also build
automatic text classifiers to detect ChatGPT generated summaries. We found that
while text classification algorithms can distinguish between real and generated
summaries, humans are unable to distinguish between real summaries and those
produced by ChatGPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Refine: Iterative Refinement with Self-Feedback. (arXiv:2303.17651v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17651">
<div class="article-summary-box-inner">
<span><p>Like people, LLMs do not always generate the best text for a given generation
problem on their first try (e.g., summaries, answers, explanations). Just as
people then refine their text, we introduce SELF-REFINE, a framework for
similarly improving initial outputs from LLMs through iterative feedback and
refinement. The main idea is to generate an output using an LLM, then allow the
same model to provide multi-aspect feedback for its own output; finally, the
same model refines its previously generated output given its own feedback.
Unlike earlier work, our iterative refinement framework does not require
supervised training data or reinforcement learning, and works with a single
LLM. We experiment with 7 diverse tasks, ranging from review rewriting to math
reasoning, demonstrating that our approach outperforms direct generation. In
all tasks, outputs generated with SELF-REFINE are preferred by humans and by
automated metrics over those generated directly with GPT-3.5 and GPT-4,
improving on average by absolute 20% across tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-Tuning BERT with Character-Level Noise for Zero-Shot Transfer to Dialects and Closely-Related Languages. (arXiv:2303.17683v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17683">
<div class="article-summary-box-inner">
<span><p>In this work, we induce character-level noise in various forms when
fine-tuning BERT to enable zero-shot cross-lingual transfer to unseen dialects
and languages. We fine-tune BERT on three sentence-level classification tasks
and evaluate our approach on an assortment of unseen dialects and languages. We
find that character-level noise can be an extremely effective agent of
cross-lingual transfer under certain conditions, while it is not as helpful in
others. Specifically, we explore these differences in terms of the nature of
the task and the relationships between source and target languages, finding
that introduction of character-level noise during fine-tuning is particularly
helpful when a task draws on surface level cues and the source-target
cross-lingual pair has a relatively high lexical overlap with shorter (i.e.,
less meaningful) unseen tokens on average.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task Oriented Conversational Modelling With Subjective Knowledge. (arXiv:2303.17695v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17695">
<div class="article-summary-box-inner">
<span><p>Existing conversational models are handled by a database(DB) and API based
systems. However, very often users' questions require information that cannot
be handled by such systems. Nonetheless, answers to these questions are
available in the form of customer reviews and FAQs. DSTC-11 proposes a three
stage pipeline consisting of knowledge seeking turn detection, knowledge
selection and response generation to create a conversational model grounded on
this subjective knowledge. In this paper, we focus on improving the knowledge
selection module to enhance the overall system performance. In particular, we
propose entity retrieval methods which result in an accurate and faster
knowledge search. Our proposed Named Entity Recognition (NER) based entity
retrieval method results in 7X faster search compared to the baseline model.
Additionally, we also explore a potential keyword extraction method which can
improve the accuracy of knowledge selection. Preliminary results show a 4 \%
improvement in exact match score on knowledge selection task. The code is
available https://github.com/raja-kumar/knowledge-grounded-TODS
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What Types of Questions Require Conversation to Answer? A Case Study of AskReddit Questions. (arXiv:2303.17710v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17710">
<div class="article-summary-box-inner">
<span><p>The proliferation of automated conversational systems such as chatbots,
spoken-dialogue systems, and smart speakers, has significantly impacted modern
digital life. However, these systems are primarily designed to provide answers
to well-defined questions rather than to support users in exploring complex,
ill-defined questions. In this paper, we aim to push the boundaries of
conversational systems by examining the types of nebulous, open-ended questions
that can best be answered through conversation. We first sampled 500 questions
from one million open-ended requests posted on AskReddit, and then recruited
online crowd workers to answer eight inquiries about these questions. We also
performed open coding to categorize the questions into 27 different domains. We
found that the issues people believe require conversation to resolve
satisfactorily are highly social and personal. Our work provides insights into
how future research could be geared to align with users' needs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluation of GPT and BERT-based models on identifying protein-protein interactions in biomedical text. (arXiv:2303.17728v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17728">
<div class="article-summary-box-inner">
<span><p>Detecting protein-protein interactions (PPIs) is crucial for understanding
genetic mechanisms, disease pathogenesis, and drug design. However, with the
fast-paced growth of biomedical literature, there is a growing need for
automated and accurate extraction of PPIs to facilitate scientific knowledge
discovery. Pre-trained language models, such as generative pre-trained
transformer (GPT) and bidirectional encoder representations from transformers
(BERT), have shown promising results in natural language processing (NLP)
tasks. We evaluated the PPI identification performance of various GPT and BERT
models using a manually curated benchmark corpus of 164 PPIs in 77 sentences
from learning language in logic (LLL). BERT-based models achieved the best
overall performance, with PubMedBERT achieving the highest precision (85.17%)
and F1-score (86.47%) and BioM-ALBERT achieving the highest recall (93.83%).
Despite not being explicitly trained for biomedical texts, GPT-4 achieved
comparable performance to the best BERT models with 83.34% precision, 76.57%
recall, and 79.18% F1-score. These findings suggest that GPT models can
effectively detect PPIs from text data and have the potential for use in
biomedical literature mining tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Design by Contract Framework for Quantum Software. (arXiv:2303.17750v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17750">
<div class="article-summary-box-inner">
<span><p>To realize reliable quantum software, techniques to automatically ensure the
quantum software's correctness have recently been investigated. However, they
primarily focus on fixed quantum circuits rather than the procedure of building
quantum circuits. Despite being a common approach, the correctness of building
circuits using different parameters following the same procedure is not
guaranteed. To this end, we propose a design-by-contract framework for quantum
software. Our framework provides a python-embedded language to write assertions
on the input and output states of all quantum circuits built by certain
procedures. Additionally, it provides a method to write assertions about the
statistical processing of measurement results to ensure the procedure's
correctness for obtaining the final result. These assertions are automatically
checked using a quantum computer simulator. For evaluation, we implemented our
framework and wrote assertions for some widely used quantum algorithms.
Consequently, we found that our framework has sufficient expressive power to
verify the whole procedure of quantum software.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society. (arXiv:2303.17760v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17760">
<div class="article-summary-box-inner">
<span><p>The rapid advancement of conversational and chat-based language models has
led to remarkable progress in complex task-solving. However, their success
heavily relies on human input to guide the conversation, which can be
challenging and time-consuming. This paper explores the potential of building
scalable techniques to facilitate autonomous cooperation among communicative
agents and provide insight into their "cognitive" processes. To address the
challenges of achieving autonomous cooperation, we propose a novel
communicative agent framework named role-playing. Our approach involves using
inception prompting to guide chat agents toward task completion while
maintaining consistency with human intentions. We showcase how role-playing can
be used to generate conversational data for studying the behaviors and
capabilities of chat agents, providing a valuable resource for investigating
conversational language models. Our contributions include introducing a novel
communicative agent framework, offering a scalable approach for studying the
cooperative behaviors and capabilities of multi-agent systems, and
open-sourcing our library to support research on communicative agents and
beyond. The GitHub repository of this project is made publicly available on:
https://github.com/lightaime/camel.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention is Not Always What You Need: Towards Efficient Classification of Domain-Specific Text. (arXiv:2303.17786v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17786">
<div class="article-summary-box-inner">
<span><p>For large-scale IT corpora with hundreds of classes organized in a hierarchy,
the task of accurate classification of classes at the higher level in the
hierarchies is crucial to avoid errors propagating to the lower levels. In the
business world, an efficient and explainable ML model is preferred over an
expensive black-box model, especially if the performance increase is marginal.
A current trend in the Natural Language Processing (NLP) community is towards
employing huge pre-trained language models (PLMs) or what is known as
self-attention models (e.g., BERT) for almost any kind of NLP task (e.g.,
question-answering, sentiment analysis, text classification). Despite the
widespread use of PLMs and the impressive performance in a broad range of NLP
tasks, there is a lack of a clear and well-justified need to as why these
models are being employed for domain-specific text classification (TC) tasks,
given the monosemic nature of specialized words (i.e., jargon) found in
domain-specific text which renders the purpose of contextualized embeddings
(e.g., PLMs) futile. In this paper, we compare the accuracies of some
state-of-the-art (SOTA) models reported in the literature against a Linear SVM
classifier and TFIDF vectorization model on three TC datasets. Results show a
comparable performance for the LinearSVM. The findings of this study show that
for domain-specific TC tasks, a linear model can provide a comparable, cheap,
reproducible, and interpretable alternative to attention-based models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dialog act guided contextual adapter for personalized speech recognition. (arXiv:2303.17799v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17799">
<div class="article-summary-box-inner">
<span><p>Personalization in multi-turn dialogs has been a long standing challenge for
end-to-end automatic speech recognition (E2E ASR) models. Recent work on
contextual adapters has tackled rare word recognition using user catalogs. This
adaptation, however, does not incorporate an important cue, the dialog act,
which is available in a multi-turn dialog scenario. In this work, we propose a
dialog act guided contextual adapter network. Specifically, it leverages dialog
acts to select the most relevant user catalogs and creates queries based on
both -- the audio as well as the semantic relationship between the carrier
phrase and user catalogs to better guide the contextual biasing. On industrial
voice assistant datasets, our model outperforms both the baselines - dialog act
encoder-only model, and the contextual adaptation, leading to the most
improvement over the no-context model: 58% average relative word error rate
reduction (WERR) in the multi-turn dialog scenario, in comparison to the
prior-art contextual adapter, which has achieved 39% WERR over the no-context
model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the Potential of Large Language models in Traditional Korean Medicine: A Foundation Model Approach to Culturally-Adapted Healthcare. (arXiv:2303.17807v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17807">
<div class="article-summary-box-inner">
<span><p>Introduction: Traditional Korean medicine (TKM) emphasizes individualized
diagnosis and treatment, making AI modeling difficult due to limited data and
implicit processes. GPT-3.5 and GPT-4, large language models, have shown
impressive medical knowledge despite lacking medicine-specific training. This
study aimed to assess the capabilities of GPT-3.5 and GPT-4 for TKM using the
Korean National Licensing Examination for Korean Medicine Doctors. Methods:
GPT-3.5 (February 2023) and GPT-4 (March 2023) models answered 340 questions
from the 2022 examination across 12 subjects. Each question was independently
evaluated five times in an initialized session. Results: GPT-3.5 and GPT-4
achieved 42.06% and 57.29% accuracy, respectively, with GPT-4 nearing passing
performance. There were significant differences in accuracy by subjects, with
83.75% accuracy for neuropsychiatry compared to 28.75% for internal medicine
(2). Both models showed high accuracy in recall-based and diagnosis-based
questions but struggled with intervention-based ones. The accuracy for
questions that require TKM-specialized knowledge was relatively lower than the
accuracy for questions that do not GPT-4 showed high accuracy for table-based
questions, and both models demonstrated consistent responses. A positive
correlation between consistency and accuracy was observed. Conclusion: Models
in this study showed near-passing performance in decision-making for TKM
without domain-specific training. However, limits were also observed that were
believed to be caused by culturally-biased learning. Our study suggests that
foundation models have potential in culturally-adapted medicine, specifically
TKM, for clinical assistance, medical education, and medical research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-shot Referring Image Segmentation with Global-Local Context Features. (arXiv:2303.17811v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17811">
<div class="article-summary-box-inner">
<span><p>Referring image segmentation (RIS) aims to find a segmentation mask given a
referring expression grounded to a region of the input image. Collecting
labelled datasets for this task, however, is notoriously costly and
labor-intensive. To overcome this issue, we propose a simple yet effective
zero-shot referring image segmentation method by leveraging the pre-trained
cross-modal knowledge from CLIP. In order to obtain segmentation masks grounded
to the input text, we propose a mask-guided visual encoder that captures global
and local contextual information of an input image. By utilizing instance masks
obtained from off-the-shelf mask proposal techniques, our method is able to
segment fine-detailed Istance-level groundings. We also introduce a
global-local text encoder where the global feature captures complex
sentence-level semantics of the entire input expression while the local feature
focuses on the target noun phrase extracted by a dependency parser. In our
experiments, the proposed method outperforms several zero-shot baselines of the
task and even the weakly supervised referring expression segmentation method
with substantial margins. Our code is available at
https://github.com/Seonghoon-Yu/Zero-shot-RIS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Procedure-aware Video Representation from Instructional Videos and Their Narrations. (arXiv:2303.17839v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17839">
<div class="article-summary-box-inner">
<span><p>The abundance of instructional videos and their narrations over the Internet
offers an exciting avenue for understanding procedural activities. In this
work, we propose to learn video representation that encodes both action steps
and their temporal ordering, based on a large-scale dataset of web
instructional videos and their narrations, without using human annotations. Our
method jointly learns a video representation to encode individual step
concepts, and a deep probabilistic model to capture both temporal dependencies
and immense individual variations in the step ordering. We empirically
demonstrate that learning temporal ordering not only enables new capabilities
for procedure reasoning, but also reinforces the recognition of individual
steps. Our model significantly advances the state-of-the-art results on step
classification (+2.8% / +3.3% on COIN / EPIC-Kitchens) and step forecasting
(+7.4% on COIN). Moreover, our model attains promising results in zero-shot
inference for step classification and forecasting, as well as in predicting
diverse and plausible steps for incomplete procedures. Our code is available at
https://github.com/facebookresearch/ProcedureVRL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can AI Put Gamma-Ray Astrophysicists Out of a Job?. (arXiv:2303.17853v1 [physics.pop-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17853">
<div class="article-summary-box-inner">
<span><p>In what will likely be a litany of generative-model-themed arXiv submissions
celebrating April the 1st, we evaluate the capacity of state-of-the-art
transformer models to create a paper detailing the detection of a Pulsar Wind
Nebula with a non-existent Imaging Atmospheric Cherenkov Telescope (IACT)
Array. We do this to evaluate the ability of such models to interpret
astronomical observations and sources based on language information alone, and
to assess potential means by which fraudulently generated scientific papers
could be identified during peer review (given that reliable generative model
watermarking has yet to be deployed for these tools). We conclude that our jobs
as astronomers are safe for the time being. From this point on, prompts given
to ChatGPT and Stable Diffusion are shown in orange, text generated by ChatGPT
is shown in black, whereas analysis by the (human) authors is in blue.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WebQAmGaze: A Multilingual Webcam Eye-Tracking-While-Reading Dataset. (arXiv:2303.17876v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17876">
<div class="article-summary-box-inner">
<span><p>We create WebQAmGaze, a multilingual low-cost eye-tracking-while-reading
dataset, designed to support the development of fair and transparent NLP
models. WebQAmGaze includes webcam eye-tracking data from 332 participants
naturally reading English, Spanish, and German texts. Each participant performs
two reading tasks composed of five texts, a normal reading and an
information-seeking task. After preprocessing the data, we find that fixations
on relevant spans seem to indicate correctness when answering the comprehension
questions. Additionally, we perform a comparative analysis of the data
collected to high-quality eye-tracking data. The results show a moderate
correlation between the features obtained with the webcam-ET compared to those
of a commercial ET device. We believe this data can advance webcam-based
reading studies and open a way to cheaper and more accessible data collection.
WebQAmGaze is useful to learn about the cognitive processes behind question
answering (QA) and to apply these insights to computational models of language
understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Selective Knowledge Distillation for Non-Autoregressive Neural Machine Translation. (arXiv:2303.17910v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17910">
<div class="article-summary-box-inner">
<span><p>Benefiting from the sequence-level knowledge distillation, the
Non-Autoregressive Transformer (NAT) achieves great success in neural machine
translation tasks. However, existing knowledge distillation has side effects,
such as propagating errors from the teacher to NAT students, which may limit
further improvements of NAT models and are rarely discussed in existing
research. In this paper, we introduce selective knowledge distillation by
introducing an NAT evaluator to select NAT-friendly targets that are of high
quality and easy to learn. In addition, we introduce a simple yet effective
progressive distillation method to boost NAT performance. Experiment results on
multiple WMT language directions and several representative NAT models show
that our approach can realize a flexible trade-off between the quality and
complexity of training data for NAT models, achieving strong performances.
Further analysis shows that distilling only 5% of the raw translations can help
an NAT outperform its counterpart trained on raw data by about 2.4 BLEU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Cultural Transfer Learning for Chinese Offensive Language Detection. (arXiv:2303.17927v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17927">
<div class="article-summary-box-inner">
<span><p>Detecting offensive language is a challenging task. Generalizing across
different cultures and languages becomes even more challenging: besides
lexical, syntactic and semantic differences, pragmatic aspects such as cultural
norms and sensitivities, which are particularly relevant in this context, vary
greatly. In this paper, we target Chinese offensive language detection and aim
to investigate the impact of transfer learning using offensive language
detection data from different cultural backgrounds, specifically Korean and
English. We find that culture-specific biases in what is considered offensive
negatively impact the transferability of language models (LMs) and that LMs
trained on diverse cultural data are sensitive to different features in Chinese
offensive language detection. In a few-shot learning scenario, however, our
study shows promising prospects for non-English offensive language detection
with limited resources. Our findings highlight the importance of cross-cultural
transfer learning in improving offensive language detection and promoting
inclusive digital spaces.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">JobHam-place with smart recommend job options and candidate filtering options. (arXiv:2303.17930v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17930">
<div class="article-summary-box-inner">
<span><p>Due to the increasing number of graduates, many applicants experience the
situation about finding a job, and employers experience difficulty filtering
job applicants, which might negatively impact their effectiveness. However,
most job-hunting websites lack job recommendation and CV filtering or ranking
functionality, which are not integrated into the system. Thus, a smart job
hunter combined with the above functionality will be conducted in this project,
which contains job recommendations, CV ranking and even a job dashboard for
skills and job applicant functionality. Job recommendation and CV ranking
starts from the automatic keyword extraction and end with the Job/CV ranking
algorithm. Automatic keyword extraction is implemented by Job2Skill and the
CV2Skill model based on Bert. Job2Skill consists of two components, text
encoder and Gru-based layers, while CV2Skill is mainly based on Bert and
fine-tunes the pre-trained model by the Resume- Entity dataset. Besides, to
match skills from CV and job description and rank lists of jobs and candidates,
job/CV ranking algorithms have been provided to compute the occurrence ratio of
skill words based on TFIDF score and match ratio of the total skill numbers.
Besides, some advanced features have been integrated into the website to
improve user experiences, such as the calendar and sweetalert2 plugin. And some
basic features to go through job application processes, such as job application
tracking and interview arrangement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trimming Phonetic Alignments Improves the Inference of Sound Correspondence Patterns from Multilingual Wordlists. (arXiv:2303.17932v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17932">
<div class="article-summary-box-inner">
<span><p>Sound correspondence patterns form the basis of cognate detection and
phonological reconstruction in historical language comparison. Methods for the
automatic inference of correspondence patterns from phonetically aligned
cognate sets have been proposed, but their application to multilingual
wordlists requires extremely well annotated datasets. Since annotation is
tedious and time consuming, it would be desirable to find ways to improve
aligned cognate data automatically. Taking inspiration from trimming techniques
in evolutionary biology, which improve alignments by excluding problematic
sites, we propose a workflow that trims phonetic alignments in comparative
linguistics prior to the inference of correspondence patterns. Testing these
techniques on a large standardized collection of ten datasets with expert
annotations from different language families, we find that the best trimming
technique substantially improves the overall consistency of the alignments. The
results show a clear increase in the proportion of frequent correspondence
patterns and words exhibiting regular cognate relations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">$\mathcal{E}$ K\'U [MASK]: Integrating Yor\`ub\'a cultural greetings into machine translation. (arXiv:2303.17972v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17972">
<div class="article-summary-box-inner">
<span><p>This paper investigates the performance of massively multilingual neural
machine translation (NMT) systems in translating Yor\`ub\'a greetings
($\mathcal{E}$ k\'u [MASK]), which are a big part of Yor\`ub\'a language and
culture, into English. To evaluate these models, we present IkiniYor\`ub\'a, a
Yor\`ub\'a-English translation dataset containing some Yor\`ub\'a greetings,
and sample use cases. We analysed the performance of different multilingual NMT
systems including Google and NLLB and show that these models struggle to
accurately translate Yor\`ub\'a greetings into English. In addition, we trained
a Yor\`ub\'a-English model by finetuning an existing NMT model on the training
split of IkiniYor\`ub\'a and this achieved better performance when compared to
the pre-trained multilingual NMT models, although they were trained on a large
volume of data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploiting Multilingualism in Low-resource Neural Machine Translation via Adversarial Learning. (arXiv:2303.18011v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18011">
<div class="article-summary-box-inner">
<span><p>Generative Adversarial Networks (GAN) offer a promising approach for Neural
Machine Translation (NMT). However, feeding multiple morphologically languages
into a single model during training reduces the NMT's performance. In GAN,
similar to bilingual models, multilingual NMT only considers one reference
translation for each sentence during model training. This single reference
translation limits the GAN model from learning sufficient information about the
source sentence representation. Thus, in this article, we propose Denoising
Adversarial Auto-encoder-based Sentence Interpolation (DAASI) approach to
perform sentence interpolation by learning the intermediate latent
representation of the source and target sentences of multilingual language
pairs. Apart from latent representation, we also use the Wasserstein-GAN
approach for the multilingual NMT model by incorporating the model generated
sentences of multiple languages for reward computation. This computed reward
optimizes the performance of the GAN-based multilingual model in an effective
manner. We demonstrate the experiments on low-resource language pairs and find
that our approach outperforms the existing state-of-the-art approaches for
multilingual NMT with a performance gain of up to 4 BLEU points. Moreover, we
use our trained model on zero-shot language pairs under an unsupervised
scenario and show the robustness of the proposed approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating GPT-4 and ChatGPT on Japanese Medical Licensing Examinations. (arXiv:2303.18027v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18027">
<div class="article-summary-box-inner">
<span><p>As large language models (LLMs) gain popularity among speakers of diverse
languages, we believe that it is crucial to benchmark them to better understand
model behaviors, failures, and limitations in languages beyond English. In this
work, we evaluate LLM APIs (ChatGPT, GPT-3, and GPT-4) on the Japanese national
medical licensing examinations from the past five years. Our team comprises
native Japanese-speaking NLP researchers and a practicing cardiologist based in
Japan. Our experiments show that GPT-4 outperforms ChatGPT and GPT-3 and passes
all five years of the exams, highlighting LLMs' potential in a language that is
typologically distant from English. However, our evaluation also exposes
critical limitations of the current LLM APIs. First, LLMs sometimes select
prohibited choices that should be strictly avoided in medical practice in
Japan, such as suggesting euthanasia. Further, our analysis shows that the API
costs are generally higher and the maximum context size is smaller for Japanese
because of the way non-Latin scripts are currently tokenized in the pipeline.
We release our benchmark as Igaku QA as well as all model outputs and exam
metadata. We hope that our results and benchmark will spur progress on more
diverse applications of LLMs. Our benchmark is available at
https://github.com/jungokasai/IgakuQA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">No Place to Hide: Dual Deep Interaction Channel Network for Fake News Detection based on Data Augmentation. (arXiv:2303.18049v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18049">
<div class="article-summary-box-inner">
<span><p>Online Social Network (OSN) has become a hotbed of fake news due to the low
cost of information dissemination. Although the existing methods have made many
attempts in news content and propagation structure, the detection of fake news
is still facing two challenges: one is how to mine the unique key features and
evolution patterns, and the other is how to tackle the problem of small samples
to build the high-performance model. Different from popular methods which take
full advantage of the propagation topology structure, in this paper, we propose
a novel framework for fake news detection from perspectives of semantic,
emotion and data enhancement, which excavates the emotional evolution patterns
of news participants during the propagation process, and a dual deep
interaction channel network of semantic and emotion is designed to obtain a
more comprehensive and fine-grained news representation with the consideration
of comments. Meanwhile, the framework introduces a data enhancement module to
obtain more labeled data with high quality based on confidence which further
improves the performance of the classification model. Experiments show that the
proposed approach outperforms the state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Solving morphological analogies: from retrieval to generation. (arXiv:2303.18062v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18062">
<div class="article-summary-box-inner">
<span><p>Analogical inference is a remarkable capability of human reasoning, and has
been used to solve hard reasoning tasks. Analogy based reasoning (AR) has
gained increasing interest from the artificial intelligence community and has
shown its potential in multiple machine learning tasks such as classification,
decision making and recommendation with competitive results. We propose a deep
learning (DL) framework to address and tackle two key tasks in AR: analogy
detection and solving. The framework is thoroughly tested on the Siganalogies
dataset of morphological analogical proportions (APs) between words, and shown
to outperform symbolic approaches in many languages. Previous work have
explored the behavior of the Analogy Neural Network for classification (ANNc)
on analogy detection and of the Analogy Neural Network for retrieval (ANNr) on
analogy solving by retrieval, as well as the potential of an autoencoder (AE)
for analogy solving by generating the solution word. In this article we
summarize these findings and we extend them by combining ANNr and the AE
embedding model, and checking the performance of ANNc as an retrieval method.
The combination of ANNr and AE outperforms the other approaches in almost all
cases, and ANNc as a retrieval method achieves competitive or better
performance than 3CosMul. We conclude with general guidelines on using our
framework to tackle APs with DL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dataset and Baseline System for Multi-lingual Extraction and Normalization of Temporal and Numerical Expressions. (arXiv:2303.18103v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18103">
<div class="article-summary-box-inner">
<span><p>Temporal and numerical expression understanding is of great importance in
many downstream Natural Language Processing (NLP) and Information Retrieval
(IR) tasks. However, much previous work covers only a few sub-types and focuses
only on entity extraction, which severely limits the usability of identified
mentions. In order for such entities to be useful in downstream scenarios,
coverage and granularity of sub-types are important; and, even more so,
providing resolution into concrete values that can be manipulated. Furthermore,
most previous work addresses only a handful of languages. Here we describe a
multi-lingual evaluation dataset - NTX - covering diverse temporal and
numerical expressions across 14 languages and covering extraction,
normalization, and resolution. Along with the dataset we provide a robust
rule-based system as a strong baseline for comparisons against other models to
be evaluated in this dataset. Data and code are available at
\url{https://aka.ms/NTX}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Edinburgh International Accents of English Corpus: Towards the Democratization of English ASR. (arXiv:2303.18110v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18110">
<div class="article-summary-box-inner">
<span><p>English is the most widely spoken language in the world, used daily by
millions of people as a first or second language in many different contexts. As
a result, there are many varieties of English. Although the great many advances
in English automatic speech recognition (ASR) over the past decades, results
are usually reported based on test datasets which fail to represent the
diversity of English as spoken today around the globe. We present the first
release of The Edinburgh International Accents of English Corpus (EdAcc). This
dataset attempts to better represent the wide diversity of English,
encompassing almost 40 hours of dyadic video call conversations between
friends. Unlike other datasets, EdAcc includes a wide range of first and
second-language varieties of English and a linguistic background profile of
each speaker. Results on latest public, and commercial models show that EdAcc
highlights shortcomings of current English ASR models. The best performing
model, trained on 680 thousand hours of transcribed data, obtains an average of
19.7% word error rate (WER) -- in contrast to the 2.7% WER obtained when
evaluated on US English clean read speech. Across all models, we observe a drop
in performance on Indian, Jamaican, and Nigerian English speakers. Recordings,
linguistic backgrounds, data statement, and evaluation scripts are released on
our website (https://groups.inf.ed.ac.uk/edacc/) under CC-BY-SA license.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pair Programming with Large Language Models for Sampling and Estimation of Copulas. (arXiv:2303.18116v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18116">
<div class="article-summary-box-inner">
<span><p>Without writing a single line of code by a human, an example Monte Carlo
simulation based application for stochastic dependence modeling with copulas is
developed using a state-of-the-art large language model (LLM) fine-tuned for
conversations. This includes interaction with ChatGPT in natural language and
using mathematical formalism, which, under careful supervision by a
human-expert, led to producing a working code in MATLAB, Python and R for
sampling from a given copula model, evaluation of the model's density,
performing maximum likelihood estimation, optimizing the code for parallel
computing for CPUs as well as for GPUs, and visualization of the computed
results. In contrast to other emerging studies that assess the accuracy of LLMs
like ChatGPT on tasks from a selected area, this work rather investigates ways
how to achieve a successful solution of a standard statistical task in a
collaboration of a human-expert and artificial intelligence (AI). Particularly,
through careful prompt engineering, we separate successful solutions generated
by ChatGPT from unsuccessful ones, resulting in a comprehensive list of related
pros and cons. It is demonstrated that if the typical pitfalls are avoided, we
can substantially benefit from collaborating with an AI partner. For example,
we show that if ChatGPT is not able to provide a correct solution due to a lack
of or incorrect knowledge, the human-expert can feed it with the correct
knowledge, e.g., in the form of mathematical theorems and formulas, and make it
to apply the gained knowledge in order to provide a solution that is correct.
Such ability presents an attractive opportunity to achieve a programmed
solution even for users with rather limited knowledge of programming
techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UKP-SQuARE v3: A Platform for Multi-Agent QA Research. (arXiv:2303.18120v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18120">
<div class="article-summary-box-inner">
<span><p>The continuous development of Question Answering (QA) datasets has drawn the
research community's attention toward multi-domain models. A popular approach
is to use multi-dataset models, which are models trained on multiple datasets
to learn their regularities and prevent overfitting to a single dataset.
However, with the proliferation of QA models in online repositories such as
GitHub or Hugging Face, an alternative is becoming viable. Recent works have
demonstrated that combining expert agents can yield large performance gains
over multi-dataset models. To ease research in multi-agent models, we extend
UKP-SQuARE, an online platform for QA research, to support three families of
multi-agent systems: i) agent selection, ii) early-fusion of agents, and iii)
late-fusion of agents. We conduct experiments to evaluate their inference speed
and discuss the performance vs. speed trade-off compared to multi-dataset
models. UKP-SQuARE is open-source and publicly available at
<a href="http://square.ukp-lab.de.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERTino: an Italian DistilBERT model. (arXiv:2303.18121v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18121">
<div class="article-summary-box-inner">
<span><p>The recent introduction of Transformers language representation models
allowed great improvements in many natural language processing (NLP) tasks.
However, if on one hand the performances achieved by this kind of architectures
are surprising, on the other their usability is limited by the high number of
parameters which constitute their network, resulting in high computational and
memory demands. In this work we present BERTino, a DistilBERT model which
proposes to be the first lightweight alternative to the BERT architecture
specific for the Italian language. We evaluated BERTino on the Italian ISDT,
Italian ParTUT, Italian WikiNER and multiclass classification tasks, obtaining
F1 scores comparable to those obtained by a BERTBASE with a remarkable
improvement in training and inference speed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can AI Chatbots Pass the Fundamentals of Engineering (FE) and Principles and Practice of Engineering (PE) Structural Exams?. (arXiv:2303.18149v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18149">
<div class="article-summary-box-inner">
<span><p>The engineering community has recently witnessed the emergence of chatbot
technology with the release of OpenAI ChatGPT-4 and Google Bard. While these
chatbots have been reported to perform well and even pass various standardized
tests, including medical and law exams, this forum paper explores whether these
chatbots can also pass the Fundamentals of Engineering (FE) and Principles and
Practice of Engineering (PE) exams. A diverse range of civil and environmental
engineering questions and scenarios are used to evaluate the chatbots'
performance, as commonly present in the FE and PE exams. The chatbots'
responses were analyzed based on their relevance, accuracy, and clarity and
then compared against the recommendations of the National Council of Examiners
for Engineering and Surveying (NCEES). Our report shows that ChatGPT-4 and
Bard, respectively scored 70.9% and 39.2% in the FE exam and 46.2% and 41% in
the PE exam. It is evident that the current version of ChatGPT-4 could
potentially pass the FE exam. While future editions are much more likely to
pass both exams, this study also highlights the potential of using chatbots as
teaching assistants and guiding engineers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multiple Choices Reading Comprehension Corpus for Vietnamese Language Education. (arXiv:2303.18162v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18162">
<div class="article-summary-box-inner">
<span><p>Machine reading comprehension has been an interesting and challenging task in
recent years, with the purpose of extracting useful information from texts. To
attain the computer ability to understand the reading text and answer relevant
information, we introduce ViMMRC 2.0 - an extension of the previous ViMMRC for
the task of multiple-choice reading comprehension in Vietnamese Textbooks which
contain the reading articles for students from Grade 1 to Grade 12. This
dataset has 699 reading passages which are prose and poems, and 5,273
questions. The questions in the new dataset are not fixed with four options as
in the previous version. Moreover, the difficulty of questions is increased,
which challenges the models to find the correct choice. The computer must
understand the whole context of the reading passage, the question, and the
content of each choice to extract the right answers. Hence, we propose the
multi-stage approach that combines the multi-step attention network (MAN) with
the natural language inference (NLI) task to enhance the performance of the
reading comprehension model. Then, we compare the proposed methodology with the
baseline BERTology models on the new dataset and the ViMMRC 1.0. Our
multi-stage models achieved 58.81% by Accuracy on the test set, which is 5.34%
better than the highest BERTology models. From the results of the error
analysis, we found the challenge of the reading comprehension models is
understanding the implicit context in texts and linking them together in order
to find the correct answers. Finally, we hope our new dataset will motivate
further research in enhancing the language understanding ability of computers
in the Vietnamese language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing Language Model Deployment with Risk Cards. (arXiv:2303.18190v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18190">
<div class="article-summary-box-inner">
<span><p>This paper introduces RiskCards, a framework for structured assessment and
documentation of risks associated with an application of language models. As
with all language, text generated by language models can be harmful, or used to
bring about harm. Automating language generation adds both an element of scale
and also more subtle or emergent undesirable tendencies to the generated text.
Prior work establishes a wide variety of language model harms to many different
actors: existing taxonomies identify categories of harms posed by language
models; benchmarks establish automated tests of these harms; and documentation
standards for models, tasks and datasets encourage transparent reporting.
However, there is no risk-centric framework for documenting the complexity of a
landscape in which some risks are shared across models and contexts, while
others are specific, and where certain conditions may be required for risks to
manifest as harms. RiskCards address this methodological gap by providing a
generic framework for assessing the use of a given language model in a given
scenario. Each RiskCard makes clear the routes for the risk to manifest harm,
their placement in harm taxonomies, and example prompt-output pairs. While
RiskCards are designed to be open-source, dynamic and participatory, we present
a "starter set" of RiskCards taken from a broad literature survey, each of
which details a concrete risk presentation. Language model RiskCards initiate a
community knowledge base which permits the mapping of risks and harms to a
specific model or its application scenario, ultimately contributing to a
better, safer and shared understanding of the risk landscape.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18223">
<div class="article-summary-box-inner">
<span><p>Language is essentially a complex, intricate system of human expressions
governed by grammatical rules. It poses a significant challenge to develop
capable AI algorithms for comprehending and grasping a language. As a major
approach, language modeling has been widely studied for language understanding
and generation in the past two decades, evolving from statistical language
models to neural language models. Recently, pre-trained language models (PLMs)
have been proposed by pre-training Transformer models over large-scale corpora,
showing strong capabilities in solving various NLP tasks. Since researchers
have found that model scaling can lead to performance improvement, they further
study the scaling effect by increasing the model size to an even larger size.
Interestingly, when the parameter scale exceeds a certain level, these enlarged
language models not only achieve a significant performance improvement but also
show some special abilities that are not present in small-scale language
models. To discriminate the difference in parameter scale, the research
community has coined the term large language models (LLM) for the PLMs of
significant size. Recently, the research on LLMs has been largely advanced by
both academia and industry, and a remarkable progress is the launch of ChatGPT,
which has attracted widespread attention from society. The technical evolution
of LLMs has been making an important impact on the entire AI community, which
would revolutionize the way how we develop and use AI algorithms. In this
survey, we review the recent advances of LLMs by introducing the background,
key findings, and mainstream techniques. In particular, we focus on four major
aspects of LLMs, namely pre-training, adaptation tuning, utilization, and
capacity evaluation. Besides, we also summarize the available resources for
developing LLMs and discuss the remaining issues for future directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated scholarly paper review: Concepts, technologies, and challenges. (arXiv:2111.07533v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.07533">
<div class="article-summary-box-inner">
<span><p>Peer review is a widely accepted mechanism for research evaluation, playing a
pivotal role in academic publishing. However, criticisms have long been leveled
on this mechanism, mostly because of its poor efficiency and low
reproducibility. Recent years have seen the application of artificial
intelligence (AI) in assisting the peer review process. Nonetheless, with the
involvement of humans, such limitations remain inevitable. In this paper, we
propose the concept and pipeline of automated scholarly paper review (ASPR) and
review the relevant literature and technologies of achieving a full-scale
computerized review process. On the basis of the review and discussion, we
conclude that there is already corresponding research and preliminary
implementation at each stage of ASPR. We further look into the challenges in
ASPR with the existing technologies. The major difficulties lie in imperfect
document parsing and representation, inadequate data, defective human-computer
interaction, and flawed deep logical reasoning. Moreover, we discuss the
possible moral and ethical issues and point out the future directions of ASPR.
In the foreseeable future, ASPR and peer review will coexist in a reinforcing
manner before ASPR is able to fully undertake the reviewing workload from
humans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Natural Language to Simulations: Applying GPT-3 Codex to Automate Simulation Modeling of Logistics Systems. (arXiv:2202.12107v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.12107">
<div class="article-summary-box-inner">
<span><p>Our work is the first attempt to apply Natural Language Processing to
automate the development of simulation models of systems vitally important for
logistics. We demonstrated that the framework built on top of the fine-tuned
GPT-3 Codex, a Transformer-based language model, could produce functionally
valid simulations of queuing and inventory control systems given the verbal
description. In conducted experiments, GPT-3 Codex demonstrated convincing
expertise in Python as well as an understanding of the domain-specific
vocabulary. As a result, the language model could produce simulations of a
single-product inventory-control system and single-server queuing system given
the domain-specific context, a detailed description of the process, and a list
of variables with the corresponding values. The demonstrated results, along
with the rapid improvement of language models, open the door for significant
simplification of the workflow behind the simulation model development, which
will allow experts to focus on the high-level consideration of the problem and
holistic thinking.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">M-MELD: A Multilingual Multi-Party Dataset for Emotion Recognition in Conversations. (arXiv:2203.16799v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.16799">
<div class="article-summary-box-inner">
<span><p>Expression of emotions is a crucial part of daily human communication.
Emotion recognition in conversations (ERC) is an emerging field of study, where
the primary task is to identify the emotion behind each utterance in a
conversation. Though a lot of work has been done on ERC in the past, these
works only focus on ERC in the English language, thereby ignoring any other
languages. In this paper, we present Multilingual MELD (M-MELD), where we
extend the Multimodal EmotionLines Dataset (MELD) \cite{poria2018meld} to 4
other languages beyond English, namely Greek, Polish, French, and Spanish.
Beyond just establishing strong baselines for all of these 4 languages, we also
propose a novel architecture, DiscLSTM, that uses both sequential and
conversational discourse context in a conversational dialogue for ERC. Our
proposed approach is computationally efficient, can transfer across languages
using just a cross-lingual encoder, and achieves better performance than most
uni-modal text approaches in the literature on both MELD and M-MELD. We make
our data and code publicly on GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploiting prompt learning with pre-trained language models for Alzheimer's Disease detection. (arXiv:2210.16539v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.16539">
<div class="article-summary-box-inner">
<span><p>Early diagnosis of Alzheimer's disease (AD) is crucial in facilitating
preventive care and to delay further progression. Speech based automatic AD
screening systems provide a non-intrusive and more scalable alternative to
other clinical screening techniques. Textual embedding features produced by
pre-trained language models (PLMs) such as BERT are widely used in such
systems. However, PLM domain fine-tuning is commonly based on the masked word
or sentence prediction costs that are inconsistent with the back-end AD
detection task. To this end, this paper investigates the use of prompt-based
fine-tuning of PLMs that consistently uses AD classification errors as the
training objective function. Disfluency features based on hesitation or pause
filler token frequencies are further incorporated into prompt phrases during
PLM fine-tuning. The decision voting based combination among systems using
different PLMs (BERT and RoBERTa) or systems with different fine-tuning
paradigms (conventional masked-language modelling fine-tuning and prompt-based
fine-tuning) is further applied. Mean, standard deviation and the maximum among
accuracy scores over 15 experiment runs are adopted as performance measurements
for the AD detection system. Mean detection accuracy of 84.20% (with std 2.09%,
best 87.5%) and 82.64% (with std 4.0%, best 89.58%) were obtained using manual
and ASR speech transcripts respectively on the ADReSS20 test set consisting of
48 elderly speakers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Calibrated Interpretation: Confidence Estimation in Semantic Parsing. (arXiv:2211.07443v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.07443">
<div class="article-summary-box-inner">
<span><p>Sequence generation models are increasingly being used to translate language
into executable programs, i.e. to perform executable semantic parsing. The fact
that semantic parsing aims to execute actions in the real world motivates
developing safe systems, which in turn makes measuring calibration -- a central
component to safety -- particularly important. We investigate the calibration
of common generation models across four popular semantic parsing datasets,
finding that it varies across models and datasets. We then analyze factors
associated with calibration error and release new confidence-based challenge
splits of two parsing datasets. To facilitate the inclusion of calibration in
semantic parsing evaluations, we release a library for computing calibration
metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SexWEs: Domain-Aware Word Embeddings via Cross-lingual Semantic Specialisation for Chinese Sexism Detection in Social Media. (arXiv:2211.08447v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.08447">
<div class="article-summary-box-inner">
<span><p>The goal of sexism detection is to mitigate negative online content targeting
certain gender groups of people. However, the limited availability of labeled
sexism-related datasets makes it problematic to identify online sexism for
low-resource languages. In this paper, we address the task of automatic sexism
detection in social media for one low-resource language -- Chinese. Rather than
collecting new sexism data or building cross-lingual transfer learning models,
we develop a cross-lingual domain-aware semantic specialisation system in order
to make the most of existing data. Semantic specialisation is a technique for
retrofitting pre-trained distributional word vectors by integrating external
linguistic knowledge (such as lexico-semantic relations) into the specialised
feature space. To do this, we leverage semantic resources for sexism from a
high-resource language (English) to specialise pre-trained word vectors in the
target language (Chinese) to inject domain knowledge. We demonstrate the
benefit of our sexist word embeddings (SexWEs) specialised by our framework via
intrinsic evaluation of word similarity and extrinsic evaluation of sexism
detection. Compared with other specialisation approaches and Chinese baseline
word vectors, our SexWEs shows an average score improvement of 0.033 and 0.064
in both intrinsic and extrinsic evaluations, respectively. The ablative results
and visualisation of SexWEs also prove the effectiveness of our framework on
retrofitting word vectors in low-resource languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoP: Factual Inconsistency Detection by Controlling the Preference. (arXiv:2212.01611v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01611">
<div class="article-summary-box-inner">
<span><p>Abstractive summarization is the process of generating a summary given a
document as input. Although significant progress has been made, the factual
inconsistency between the document and the generated summary still limits its
practical applications. Previous work found that the probabilities assigned by
the generation model reflect its preferences for the generated summary,
including the preference for factual consistency, and the preference for the
language or knowledge prior as well. To separate the preference for factual
consistency, we propose an unsupervised framework named CoP by controlling the
preference of the generation model with the help of prompt. More specifically,
the framework performs an extra inference step in which a text prompt is
introduced as an additional input. In this way, another preference is described
by the generation probability of this extra inference process. The difference
between the above two preferences, i.e. the difference between the
probabilities, could be used as measurements for detecting factual
inconsistencies. Interestingly, we found that with the properly designed
prompt, our framework could evaluate specific preferences and serve as
measurements for fine-grained categories of inconsistency, such as
entity-related inconsistency, coreference-related inconsistency, etc. Moreover,
our framework could also be extended to the supervised setting to learn better
prompt from the labeled data as well. Experiments show that our framework
achieves new SOTA results on three factual inconsistency detection tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Editing Models with Task Arithmetic. (arXiv:2212.04089v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04089">
<div class="article-summary-box-inner">
<span><p>Changing how pre-trained models behave -- e.g., improving their performance
on a downstream task or mitigating biases learned during pre-training -- is a
common practice when developing machine learning systems. In this work, we
propose a new paradigm for steering the behavior of neural networks, centered
around \textit{task vectors}. A task vector specifies a direction in the weight
space of a pre-trained model, such that movement in that direction improves
performance on the task. We build task vectors by subtracting the weights of a
pre-trained model from the weights of the same model after fine-tuning on a
task. We show that these task vectors can be modified and combined together
through arithmetic operations such as negation and addition, and the behavior
of the resulting model is steered accordingly. Negating a task vector decreases
performance on the target task, with little change in model behavior on control
tasks. Moreover, adding task vectors together can improve performance on
multiple tasks at once. Finally, when tasks are linked by an analogy
relationship of the form ``A is to B as C is to D", combining task vectors from
three of the tasks can improve performance on the fourth, even when no data
from the fourth task is used for training. Overall, our experiments with
several models, modalities and tasks show that task arithmetic is a simple,
efficient and effective way of editing models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-shot Learning for Cross-Target Stance Detection by Aggregating Multimodal Embeddings. (arXiv:2301.04535v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.04535">
<div class="article-summary-box-inner">
<span><p>Despite the increasing popularity of the stance detection task, existing
approaches are predominantly limited to using the textual content of social
media posts for the classification, overlooking the social nature of the task.
The stance detection task becomes particularly challenging in cross-target
classification scenarios, where even in few-shot training settings the model
needs to predict the stance towards new targets for which the model has only
seen few relevant samples during training. To address the cross-target stance
detection in social media by leveraging the social nature of the task, we
introduce CT-TN, a novel model that aggregates multimodal embeddings derived
from both textual and network features of the data. We conduct experiments in a
few-shot cross-target scenario on six different combinations of
source-destination target pairs. By comparing CT-TN with state-of-the-art
cross-target stance detection models, we demonstrate the effectiveness of our
model by achieving average performance improvements ranging from 11% to 21%
across different baseline models. Experiments with different numbers of shots
show that CT-TN can outperform other models after seeing 300 instances of the
destination target. Further, ablation experiments demonstrate the positive
contribution of each of the components of CT-TN towards the final performance.
We further analyse the network interactions between social media users, which
reveal the potential of using social features for cross-target stance
detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rewarding Chatbots for Real-World Engagement with Millions of Users. (arXiv:2303.06135v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.06135">
<div class="article-summary-box-inner">
<span><p>The emergence of pretrained large language models has led to the deployment
of a range of social chatbots for chitchat. Although these chatbots demonstrate
language ability and fluency, they are not guaranteed to be engaging and can
struggle to retain users. This work investigates the development of social
chatbots that prioritize user engagement to enhance retention, specifically
examining the use of human feedback to efficiently develop highly engaging
chatbots. The proposed approach uses automatic pseudo-labels collected from
user interactions to train a reward model that can be used to reject
low-scoring sample responses generated by the chatbot model at inference time.
Intuitive evaluation metrics, such as mean conversation length (MCL), are
introduced as proxies to measure the level of engagement of deployed chatbots.
A/B testing on groups of 10,000 new daily chatbot users on the Chai Research
platform shows that this approach increases the MCL by up to 70%, which
translates to a more than 30% increase in user retention for a GPT-J 6B model.
Future work aims to use the reward model to realise a data fly-wheel, where the
latest user conversations can be used to alternately fine-tune the language
model and the reward model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fairness-guided Few-shot Prompting for Large Language Models. (arXiv:2303.13217v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.13217">
<div class="article-summary-box-inner">
<span><p>Large language models have demonstrated surprising ability to perform
in-context learning, i.e., these models can be directly applied to solve
numerous downstream tasks by conditioning on a prompt constructed by a few
input-output examples. However, prior research has shown that in-context
learning can suffer from high instability due to variations in training
examples, example order, and prompt formats. Therefore, the construction of an
appropriate prompt is essential for improving the performance of in-context
learning. In this paper, we revisit this problem from the view of predictive
bias. Specifically, we introduce a metric to evaluate the predictive bias of a
fixed prompt against labels or a given attributes. Then we empirically show
that prompts with higher bias always lead to unsatisfactory predictive quality.
Based on this observation, we propose a novel search strategy based on the
greedy search to identify the near-optimal prompt for improving the performance
of in-context learning. We perform comprehensive experiments with
state-of-the-art mainstream models such as GPT-3 on various downstream tasks.
Our results indicate that our method can enhance the model's in-context
learning performance in an effective and interpretable manner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT and a New Academic Reality: Artificial Intelligence-Written Research Papers and the Ethics of the Large Language Models in Scholarly Publishing. (arXiv:2303.13367v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.13367">
<div class="article-summary-box-inner">
<span><p>This paper discusses OpenAIs ChatGPT, a generative pre-trained transformer,
which uses natural language processing to fulfill text-based user requests
(i.e., a chatbot). The history and principles behind ChatGPT and similar models
are discussed. This technology is then discussed in relation to its potential
impact on academia and scholarly research and publishing. ChatGPT is seen as a
potential model for the automated preparation of essays and other types of
scholarly manuscripts. Potential ethical issues that could arise with the
emergence of large language models like GPT-3, the underlying technology behind
ChatGPT, and its usage by academics and researchers, are discussed and situated
within the context of broader advancements in artificial intelligence, machine
learning, and natural language processing for research and scholarly
publishing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompting Multilingual Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages. (arXiv:2303.13592v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.13592">
<div class="article-summary-box-inner">
<span><p>While code-mixing is a common linguistic practice in many parts of the world,
collecting high-quality and low-cost code-mixed data remains a challenge for
natural language processing (NLP) research. The proliferation of Large Language
Models (LLMs) in recent times compels one to ask: can these systems be used for
data generation? In this article, we explore prompting multilingual LLMs in a
zero-shot manner to create code-mixed data for five languages in South East
Asia (SEA) -- Indonesian, Malay, Chinese, Tagalog, Vietnamese, as well as the
creole language Singlish. We find that ChatGPT shows the most potential,
capable of producing code-mixed text 68% of the time when the term
"code-mixing" is explicitly defined. Moreover, both ChatGPT's and InstructGPT's
(davinci-003) performances in generating Singlish texts are noteworthy,
averaging a 96% success rate across a variety of prompts. Their code-mixing
proficiency, however, is dampened by word choice errors that lead to semantic
inaccuracies. Other multilingual models such as BLOOMZ and Flan-T5-XXL are
unable to produce code-mixed texts altogether. By highlighting the limited
promises of LLMs in a specific form of low-resource data generation, we call
for a measured approach when applying similar techniques to other data-scarce
NLP contexts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reproducibility is Nothing without Correctness: The Importance of Testing Code in NLP. (arXiv:2303.16166v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.16166">
<div class="article-summary-box-inner">
<span><p>Despite its pivotal role in research experiments, code correctness is often
presumed only on the basis of the perceived quality of the results. This comes
with the risk of erroneous outcomes and potentially misleading findings. To
address this issue, we posit that the current focus on result reproducibility
should go hand in hand with the emphasis on coding best practices. We bolster
our call to the NLP community by presenting a case study, in which we identify
(and correct) three bugs in widely used open-source implementations of the
state-of-the-art Conformer architecture. Through comparative experiments on
automatic speech recognition and translation in various language settings, we
demonstrate that the existence of bugs does not prevent the achievement of good
and reproducible results and can lead to incorrect conclusions that potentially
misguide future research. In response to this, this study is a call to action
toward the adoption of coding best practices aimed at fostering correctness and
improving the quality of the developed software.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Did You Mean...? Confidence-based Trade-offs in Semantic Parsing. (arXiv:2303.16857v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.16857">
<div class="article-summary-box-inner">
<span><p>We illustrate how a calibrated model can help balance common trade-offs in
task-oriented parsing. In a simulated annotator-in-the-loop experiment, we show
that well-calibrated confidence scores allow us to balance cost with annotator
load, improving accuracy with a small number of interactions. We then examine
how confidence scores can help optimize the trade-off between usability and
safety. We show that confidence-based thresholding can substantially reduce the
number of incorrect low-confidence programs executed; however, this comes at a
cost to usability. We propose the DidYouMean system which better balances
usability and safety.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study. (arXiv:2303.17466v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17466">
<div class="article-summary-box-inner">
<span><p>The recent release of ChatGPT has garnered widespread recognition for its
exceptional ability to generate human-like responses in dialogue. Given its
usage by users from various nations and its training on a vast multilingual
corpus that incorporates diverse cultural and societal norms, it is crucial to
evaluate its effectiveness in cultural adaptation. In this paper, we
investigate the underlying cultural background of ChatGPT by analyzing its
responses to questions designed to quantify human cultural differences. Our
findings suggest that, when prompted with American context, ChatGPT exhibits a
strong alignment with American culture, but it adapts less effectively to other
cultural contexts. Furthermore, by using different prompts to probe the model,
we show that English prompts reduce the variance in model responses, flattening
out cultural differences and biasing them towards American culture. This study
provides valuable insights into the cultural implications of ChatGPT and
highlights the necessity of greater diversity and cultural awareness in
language technologies.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-04-03 23:11:12.803063987 UTC">2023-04-03 23:11:12 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>