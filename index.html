<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-06-05T01:30:00Z">06-05</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly-supervised forced alignment of disfluent speech using phoneme-level modeling. (arXiv:2306.00996v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00996">
<div class="article-summary-box-inner">
<span><p>The study of speech disorders can benefit greatly from time-aligned data.
However, audio-text mismatches in disfluent speech cause rapid performance
degradation for modern speech aligners, hindering the use of automatic
approaches. In this work, we propose a simple and effective modification of
alignment graph construction of CTC-based models using Weighted Finite State
Transducers. The proposed weakly-supervised approach alleviates the need for
verbatim transcription of speech disfluencies for forced alignment. During the
graph construction, we allow the modeling of common speech disfluencies, i.e.
repetitions and omissions. Further, we show that by assessing the degree of
audio-text mismatch through the use of Oracle Error Rate, our method can be
effectively used in the wild. Our evaluation on a corrupted version of the
TIMIT test set and the UCLASS dataset shows significant improvements,
particularly for recall, achieving a 23-25% relative improvement over our
baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Selection of Text-to-speech Data to Augment ASR Training. (arXiv:2306.00998v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00998">
<div class="article-summary-box-inner">
<span><p>This paper presents a method for selecting appropriate synthetic speech
samples from a given large text-to-speech (TTS) dataset as supplementary
training data for an automatic speech recognition (ASR) model. We trained a
neural network, which can be optimised using cross-entropy loss or Arcface
loss, to measure the similarity of a synthetic data to real speech. We found
that incorporating synthetic samples with considerable dissimilarity to real
speech, owing in part to lexical differences, into ASR training is crucial for
boosting recognition performance. Experimental results on Librispeech test sets
indicate that, in order to maintain the same speech recognition accuracy as
when using all TTS data, our proposed solution can reduce the size of the TTS
data down below its $30\,\%$, which is superior to several baseline methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AoM: Detecting Aspect-oriented Information for Multimodal Aspect-Based Sentiment Analysis. (arXiv:2306.01004v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01004">
<div class="article-summary-box-inner">
<span><p>Multimodal aspect-based sentiment analysis (MABSA) aims to extract aspects
from text-image pairs and recognize their sentiments. Existing methods make
great efforts to align the whole image to corresponding aspects. However,
different regions of the image may relate to different aspects in the same
sentence, and coarsely establishing image-aspect alignment will introduce noise
to aspect-based sentiment analysis (i.e., visual noise). Besides, the sentiment
of a specific aspect can also be interfered by descriptions of other aspects
(i.e., textual noise). Considering the aforementioned noises, this paper
proposes an Aspect-oriented Method (AoM) to detect aspect-relevant semantic and
sentiment information. Specifically, an aspect-aware attention module is
designed to simultaneously select textual tokens and image blocks that are
semantically related to the aspects. To accurately aggregate sentiment
information, we explicitly introduce sentiment embedding into AoM, and use a
graph convolutional network to model the vision-text and text-text interaction.
Extensive experiments demonstrate the superiority of AoM to existing methods.
The source code is publicly released at https://github.com/SilyRab/AoM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scaling Evidence-based Instructional Design Expertise through Large Language Models. (arXiv:2306.01006v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01006">
<div class="article-summary-box-inner">
<span><p>This paper presents a comprehensive exploration of leveraging Large Language
Models (LLMs), specifically GPT-4, in the field of instructional design. With a
focus on scaling evidence-based instructional design expertise, our research
aims to bridge the gap between theoretical educational studies and practical
implementation. We discuss the benefits and limitations of AI-driven content
generation, emphasizing the necessity of human oversight in ensuring the
quality of educational materials. This work is elucidated through two detailed
case studies where we applied GPT-4 in creating complex higher-order
assessments and active learning components for different courses. From our
experiences, we provide best practices for effectively using LLMs in
instructional design tasks, such as utilizing templates, fine-tuning, handling
unexpected output, implementing LLM chains, citing references, evaluating
output, creating rubrics, grading, and generating distractors. We also share
our vision of a future recommendation system, where a customized GPT-4 extracts
instructional design principles from educational studies and creates
personalized, evidence-supported strategies for users' unique educational
contexts. Our research contributes to understanding and optimally harnessing
the potential of AI-driven language models in enhancing educational outcomes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Examining the Emergence of Deductive Reasoning in Generative Language Models. (arXiv:2306.01009v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01009">
<div class="article-summary-box-inner">
<span><p>We conduct a preliminary inquiry into the ability of generative transformer
models to deductively reason from premises provided. We observe notable
differences in the performance of models coming from different training setups
and find that the deductive reasoning ability increases with scale. Further, we
discover that the performance generally does not decrease with the length of
the deductive chain needed to reach the conclusion, with the exception of
OpenAI GPT-3 and GPT-3.5 models. Our study considers a wide variety of
transformer-decoder models, ranging from 117 million to 175 billion parameters
in size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Estimate Model Transferability of Pre-Trained Speech Models?. (arXiv:2306.01015v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01015">
<div class="article-summary-box-inner">
<span><p>In this work, we introduce a ``score-based assessment'' framework for
estimating the transferability of pre-trained speech models (PSMs) for
fine-tuning target tasks. We leverage upon two representation theories,
Bayesian likelihood estimation and optimal transport, to generate rank scores
for the PSM candidates using the extracted representations. Our framework
efficiently computes transferability scores without actual fine-tuning of
candidate models or layers by making a temporal independent hypothesis. We
evaluate some popular supervised speech models (e.g., Conformer RNN-Transducer)
and self-supervised speech models (e.g., HuBERT) in cross-layer and cross-model
settings using public data. Experimental results show a high Spearman's rank
correlation and low $p$-value between our estimation framework and fine-tuning
ground truth. Our proposed transferability framework requires less
computational time and resources, making it a resource-saving and
time-efficient approach for tuning speech foundation models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PV2TEA: Patching Visual Modality to Textual-Established Information Extraction. (arXiv:2306.01016v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01016">
<div class="article-summary-box-inner">
<span><p>Information extraction, e.g., attribute value extraction, has been
extensively studied and formulated based only on text. However, many attributes
can benefit from image-based extraction, like color, shape, pattern, among
others. The visual modality has long been underutilized, mainly due to
multimodal annotation difficulty. In this paper, we aim to patch the visual
modality to the textual-established attribute information extractor. The
cross-modality integration faces several unique challenges: (C1) images and
textual descriptions are loosely paired intra-sample and inter-samples; (C2)
images usually contain rich backgrounds that can mislead the prediction; (C3)
weakly supervised labels from textual-established extractors are biased for
multimodal training. We present PV2TEA, an encoder-decoder architecture
equipped with three bias reduction schemes: (S1) Augmented label-smoothed
contrast to improve the cross-modality alignment for loosely-paired image and
text; (S2) Attention-pruning that adaptively distinguishes the visual
foreground; (S3) Two-level neighborhood regularization that mitigates the label
textual bias via reliability estimation. Empirical results on real-world
e-Commerce datasets demonstrate up to 11.74% absolute (20.97% relatively) F1
increase over unimodal baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bypass Temporal Classification: Weakly Supervised Automatic Speech Recognition with Imperfect Transcripts. (arXiv:2306.01031v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01031">
<div class="article-summary-box-inner">
<span><p>This paper presents a novel algorithm for building an automatic speech
recognition (ASR) model with imperfect training data. Imperfectly transcribed
speech is a prevalent issue in human-annotated speech corpora, which degrades
the performance of ASR models. To address this problem, we propose Bypass
Temporal Classification (BTC) as an expansion of the Connectionist Temporal
Classification (CTC) criterion. BTC explicitly encodes the uncertainties
associated with transcripts during training. This is accomplished by enhancing
the flexibility of the training graph, which is implemented as a weighted
finite-state transducer (WFST) composition. The proposed algorithm improves the
robustness and accuracy of ASR systems, particularly when working with
imprecisely transcribed speech corpora. Our implementation will be
open-sourced.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are Layout-Infused Language Models Robust to Layout Distribution Shifts? A Case Study with Scientific Documents. (arXiv:2306.01058v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01058">
<div class="article-summary-box-inner">
<span><p>Recent work has shown that infusing layout features into language models
(LMs) improves processing of visually-rich documents such as scientific papers.
Layout-infused LMs are often evaluated on documents with familiar layout
features (e.g., papers from the same publisher), but in practice models
encounter documents with unfamiliar distributions of layout features, such as
new combinations of text sizes and styles, or new spatial configurations of
textual elements. In this work we test whether layout-infused LMs are robust to
layout distribution shifts. As a case study we use the task of scientific
document structure recovery, segmenting a scientific paper into its structural
categories (e.g., "title", "caption", "reference"). To emulate distribution
shifts that occur in practice we re-partition the GROTOAP2 dataset. We find
that under layout distribution shifts model performance degrades by up to 20
F1. Simple training strategies, such as increasing training diversity, can
reduce this degradation by over 35% relative F1; however, models fail to reach
in-distribution performance in any tested out-of-distribution conditions. This
work highlights the need to consider layout distribution shifts during model
evaluation, and presents a methodology for conducting such evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reimagining Retrieval Augmented Language Models for Answering Queries. (arXiv:2306.01061v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01061">
<div class="article-summary-box-inner">
<span><p>We present a reality check on large language models and inspect the promise
of retrieval augmented language models in comparison. Such language models are
semi-parametric, where models integrate model parameters and knowledge from
external data sources to make their predictions, as opposed to the parametric
nature of vanilla large language models. We give initial experimental findings
that semi-parametric architectures can be enhanced with views, a query
analyzer/planner, and provenance to make a significantly more powerful system
for question answering in terms of accuracy and efficiency, and potentially for
other NLP tasks
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TimelineQA: A Benchmark for Question Answering over Timelines. (arXiv:2306.01069v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01069">
<div class="article-summary-box-inner">
<span><p>Lifelogs are descriptions of experiences that a person had during their life.
Lifelogs are created by fusing data from the multitude of digital services,
such as online photos, maps, shopping and content streaming services. Question
answering over lifelogs can offer personal assistants a critical resource when
they try to provide advice in context. However, obtaining answers to questions
over lifelogs is beyond the current state of the art of question answering
techniques for a variety of reasons, the most pronounced of which is that
lifelogs combine free text with some degree of structure such as temporal and
geographical information.
</p>
<p>We create and publicly release TimelineQA1, a benchmark for accelerating
progress on querying lifelogs. TimelineQA generates lifelogs of imaginary
people. The episodes in the lifelog range from major life episodes such as high
school graduation to those that occur on a daily basis such as going for a run.
We describe a set of experiments on TimelineQA with several state-of-the-art QA
models. Our experiments reveal that for atomic queries, an extractive QA system
significantly out-performs a state-of-the-art retrieval-augmented QA system.
For multi-hop queries involving aggregates, we show that the best result is
obtained with a state-of-the-art table QA technique, assuming the ground truth
set of episodes for deriving the answer is available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantization-Aware and Tensor-Compressed Training of Transformers for Natural Language Understanding. (arXiv:2306.01076v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01076">
<div class="article-summary-box-inner">
<span><p>Fine-tuned transformer models have shown superior performances in many
natural language tasks. However, the large model size prohibits deploying
high-performance transformer models on resource-constrained devices. This paper
proposes a quantization-aware tensor-compressed training approach to reduce the
model size, arithmetic operations, and ultimately runtime latency of
transformer-based models. We compress the embedding and linear layers of
transformers into small low-rank tensor cores, which significantly reduces
model parameters. A quantization-aware training with learnable scale factors is
used to further obtain low-precision representations of the tensor-compressed
models. The developed approach can be used for both end-to-end training and
distillation-based training. To improve the convergence, a layer-by-layer
distillation is applied to distill a quantized and tensor-compressed student
model from a pre-trained transformer. The performance is demonstrated in two
natural language understanding tasks, showing up to $63\times$ compression
ratio, little accuracy loss and remarkable inference and training speedup.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving the Robustness of Summarization Systems with Dual Augmentation. (arXiv:2306.01090v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01090">
<div class="article-summary-box-inner">
<span><p>A robust summarization system should be able to capture the gist of the
document, regardless of the specific word choices or noise in the input. In
this work, we first explore the summarization models' robustness against
perturbations including word-level synonym substitution and noise. To create
semantic-consistent substitutes, we propose a SummAttacker, which is an
efficient approach to generating adversarial samples based on language models.
Experimental results show that state-of-the-art summarization models have a
significant decrease in performance on adversarial and noisy test sets. Next,
we analyze the vulnerability of the summarization systems and explore improving
the robustness by data augmentation. Specifically, the first brittleness factor
we found is the poor understanding of infrequent words in the input.
Correspondingly, we feed the encoder with more diverse cases created by
SummAttacker in the input space. The other factor is in the latent space, where
the attacked inputs bring more variations to the hidden states. Hence, we
construct adversarial decoder input and devise manifold softmixing operation in
hidden space to introduce more diversity. Experimental results on Gigaword and
CNN/DM datasets demonstrate that our approach achieves significant improvements
over strong baselines and exhibits higher robustness on noisy, attacked, and
clean datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of Multilingual BERT for Low-resource Sentiment Analysis. (arXiv:2306.01093v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01093">
<div class="article-summary-box-inner">
<span><p>This paper describes our system designed for SemEval-2023 Task 12: Sentiment
analysis for African languages. The challenge faced by this task is the
scarcity of labeled data and linguistic resources in low-resource settings. To
alleviate these, we propose a generalized multilingual system SACL-XLMR for
sentiment analysis on low-resource languages. Specifically, we design a
lexicon-based multilingual BERT to facilitate language adaptation and
sentiment-aware representation learning. Besides, we apply a supervised
adversarial contrastive learning technique to learn sentiment-spread structured
representations and enhance model generalization. Our system achieved
competitive results, largely outperforming baselines on both multilingual and
zero-shot sentiment classification subtasks. Notably, the system obtained the
1st rank on the zero-shot classification subtask in the official ranking.
Extensive experiments demonstrate the effectiveness of our system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLMatic: Neural Architecture Search via Large Language Models and Quality-Diversity Optimization. (arXiv:2306.01102v1 [cs.NE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01102">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have emerged as powerful tools capable of
accomplishing a broad spectrum of tasks. Their abilities span numerous areas,
and one area where they have made a significant impact is in the domain of code
generation. In this context, we view LLMs as mutation and crossover tools.
Meanwhile, Quality-Diversity (QD) algorithms are known to discover diverse and
robust solutions. By merging the code-generating abilities of LLMs with the
diversity and robustness of QD solutions, we introduce LLMatic, a Neural
Architecture Search (NAS) algorithm. While LLMs struggle to conduct NAS
directly through prompts, LLMatic uses a procedural approach, leveraging QD for
prompts and network architecture to create diverse and highly performant
networks. We test LLMatic on the CIFAR-10 image classification benchmark,
demonstrating that it can produce competitive networks with just $2,000$
searches, even without prior knowledge of the benchmark domain or exposure to
any previous top-performing models for the benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Hate Speech Benchmarks: From Data Curation to System Deployment. (arXiv:2306.01105v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01105">
<div class="article-summary-box-inner">
<span><p>Social media is awash with hateful content, much of which is often veiled
with linguistic and topical diversity. The benchmark datasets used for hate
speech detection do not account for such divagation as they are predominantly
compiled using hate lexicons. However, capturing hate signals becomes
challenging in neutrally-seeded malicious content. Thus, designing models and
datasets that mimic the real-world variability of hate warrants further
investigation.
</p>
<p>To this end, we present GOTHate, a large-scale code-mixed crowdsourced
dataset of around 51k posts for hate speech detection from Twitter. GOTHate is
neutrally seeded, encompassing different languages and topics. We conduct
detailed comparisons of GOTHate with the existing hate speech datasets,
highlighting its novelty. We benchmark it with 10 recent baselines. Our
extensive empirical and benchmarking experiments suggest that GOTHate is hard
to classify in a text-only setup. Thus, we investigate how adding endogenous
signals enhances the hate speech detection task. We augment GOTHate with the
user's timeline information and ego network, bringing the overall data source
closer to the real-world setup for understanding hateful content. Our proposed
solution HEN-mBERT is a modular, multilingual, mixture-of-experts model that
enriches the linguistic subspace with latent endogenous signals from history,
topology, and exemplars. HEN-mBERT transcends the best baseline by 2.5% and 5%
in overall macro-F1 and hate class F1, respectively. Inspired by our
experiments, in partnership with Wipro AI, we are developing a semi-automated
pipeline to detect hateful content as a part of their mission to tackle online
harm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only. (arXiv:2306.01116v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01116">
<div class="article-summary-box-inner">
<span><p>Large language models are commonly trained on a mixture of filtered web data
and curated high-quality corpora, such as social media conversations, books, or
technical papers. This curation process is believed to be necessary to produce
performant models with broad zero-shot generalization abilities. However, as
larger models requiring pretraining on trillions of tokens are considered, it
is unclear how scalable is curation and whether we will run out of unique
high-quality data soon. At variance with previous beliefs, we show that
properly filtered and deduplicated web data alone can lead to powerful models;
even significantly outperforming models from the state-of-the-art trained on
The Pile. Despite extensive filtering, the high-quality data we extract from
the web is still plentiful, and we are able to obtain five trillion tokens from
CommonCrawl. We publicly release an extract of 600 billion tokens from our
RefinedWeb dataset, and 1.3/7.5B parameters language models trained on it.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Examining the Causal Effect of First Names on Language Models: The Case of Social Commonsense Reasoning. (arXiv:2306.01117v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01117">
<div class="article-summary-box-inner">
<span><p>As language models continue to be integrated into applications of personal
and societal relevance, ensuring these models' trustworthiness is crucial,
particularly with respect to producing consistent outputs regardless of
sensitive attributes. Given that first names may serve as proxies for
(intersectional) socio-demographic representations, it is imperative to examine
the impact of first names on commonsense reasoning capabilities. In this paper,
we study whether a model's reasoning given a specific input differs based on
the first names provided. Our underlying assumption is that the reasoning about
Alice should not differ from the reasoning about James. We propose and
implement a controlled experimental framework to measure the causal effect of
first names on commonsense reasoning, enabling us to distinguish between model
predictions due to chance and caused by actual factors of interest. Our results
indicate that the frequency of first names has a direct effect on model
prediction, with less frequent names yielding divergent predictions compared to
more frequent names. To gain insights into the internal mechanisms of models
that are contributing to these behaviors, we also conduct an in-depth
explainable analysis. Overall, our findings suggest that to ensure model
robustness, it is essential to augment datasets with more diverse first names
during the configuration stage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Transformer Programs. (arXiv:2306.01128v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01128">
<div class="article-summary-box-inner">
<span><p>Recent research in mechanistic interpretability has attempted to
reverse-engineer Transformer models by carefully inspecting network weights and
activations. However, these approaches require considerable manual effort and
still fall short of providing complete, faithful descriptions of the underlying
algorithms. In this work, we introduce a procedure for training Transformers
that are mechanistically interpretable by design. We build on RASP [Weiss et
al., 2021], a programming language that can be compiled into Transformer
weights. Instead of compiling human-written programs into Transformers, we
design a modified Transformer that can be trained using gradient-based
optimization and then be automatically converted into a discrete,
human-readable program. We refer to these models as Transformer Programs. To
validate our approach, we learn Transformer Programs for a variety of problems,
including an in-context learning task, a suite of algorithmic problems (e.g.
sorting, recognizing Dyck-languages), and NLP tasks including named entity
recognition and text classification. The Transformer Programs can automatically
find reasonable solutions, performing on par with standard Transformers of
comparable size; and, more importantly, they are easy to interpret. To
demonstrate these advantages, we convert Transformers into Python programs and
use off-the-shelf code analysis tools to debug model errors and identify the
``circuits'' used to solve different sub-problems. We hope that Transformer
Programs open a new path toward the goal of intrinsically interpretable machine
learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating the Capabilities of Multi-modal Reasoning Models with Synthetic Task Data. (arXiv:2306.01144v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01144">
<div class="article-summary-box-inner">
<span><p>The impressive advances and applications of large language and joint
language-and-visual understanding models has led to an increased need for
methods of probing their potential reasoning capabilities. However, the
difficulty of gather naturally-occurring data for complex multi-modal reasoning
tasks bottlenecks the evaluation of AI methods on tasks which are not already
covered by an academic dataset. In this work, we leverage recent advances in
high resolution text-to-image generation to develop a framework for generating
evaluation data for multi-modal reasoning tasks. We apply this framework to
generate context-dependent anomaly data, creating a synthetic dataset on a
challenging task which is not well covered by existing datasets. We benchmark
the performance of a state-of-the-art visual question answering (VQA) model
against data generated with this method, and demonstrate that while the task is
tractable, the model performs significantly worse on the context-dependent
anomaly detection task than on standard VQA tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Did You Read the Instructions? Rethinking the Effectiveness of Task Definitions in Instruction Learning. (arXiv:2306.01150v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01150">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have shown impressive performance in following
natural language instructions to solve unseen tasks. However, it remains
unclear whether models truly understand task definitions and whether the
human-written definitions are optimal. In this paper, we systematically study
the role of task definitions in instruction learning. We first conduct an
ablation analysis informed by human annotations to understand which parts of a
task definition are most important, and find that model performance only drops
substantially when removing contents describing the task output, in particular
label information. Next, we propose an automatic algorithm to compress task
definitions to a minimal supporting set of tokens, and find that 60\% of tokens
can be removed while maintaining or even improving model performance. Based on
these results, we propose two strategies to help models better leverage task
instructions: (1) providing only key information for tasks in a common
structured format, and (2) adding a meta-tuning stage to help the model better
understand the definitions. With these two strategies, we achieve a 4.2 Rouge-L
improvement over 119 unseen test tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diverse and Faithful Knowledge-Grounded Dialogue Generation via Sequential Posterior Inference. (arXiv:2306.01153v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01153">
<div class="article-summary-box-inner">
<span><p>The capability to generate responses with diversity and faithfulness using
factual knowledge is paramount for creating a human-like, trustworthy dialogue
system. Common strategies either adopt a two-step paradigm, which optimizes
knowledge selection and response generation separately, and may overlook the
inherent correlation between these two tasks, or leverage conditional
variational method to jointly optimize knowledge selection and response
generation by employing an inference network. In this paper, we present an
end-to-end learning framework, termed Sequential Posterior Inference (SPI),
capable of selecting knowledge and generating dialogues by approximately
sampling from the posterior distribution. Unlike other methods, SPI does not
require the inference network or assume a simple geometry of the posterior
distribution. This straightforward and intuitive inference procedure of SPI
directly queries the response generation model, allowing for accurate knowledge
selection and generation of faithful responses. In addition to modeling
contributions, our experimental results on two common dialogue datasets (Wizard
of Wikipedia and Holl-E) demonstrate that SPI outperforms previous strong
baselines according to both automatic and human evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Faster Causal Attention Over Large Sequences Through Sparse Flash Attention. (arXiv:2306.01160v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01160">
<div class="article-summary-box-inner">
<span><p>Transformer-based language models have found many diverse applications
requiring them to process sequences of increasing length. For these
applications, the causal self-attention -- which is the only component scaling
quadratically w.r.t. the sequence length -- becomes a central concern. While
many works have proposed schemes to sparsify the attention patterns and reduce
the computational overhead of self-attention, those are often limited by
implementations concerns and end up imposing a simple and static structure over
the attention matrix. Conversely, implementing more dynamic sparse attentions
often results in runtimes significantly slower than computing the full
attention using the Flash implementation from Dao et al. (2022). We extend
FlashAttention to accommodate a large class of attention sparsity patterns
that, in particular, encompass key/query dropping and hashing-based attention.
This leads to implementations with no computational complexity overhead and a
multi-fold runtime speedup on top of FlashAttention. Even with relatively low
degrees of sparsity, our method improves visibly upon FlashAttention as the
sequence length increases. Without sacrificing perplexity, we increase the
training speed of a transformer language model by $2.0\times$ and $3.3\times$
for sequences of respectively $8k$ and $16k$ tokens.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Natural Language Processing For Public Health Screening On YouTube: A COVID-19 Case Study. (arXiv:2306.01164v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01164">
<div class="article-summary-box-inner">
<span><p>Background: Social media platforms have become a viable source of medical
information, with patients and healthcare professionals using them to share
health-related information and track diseases. Similarly, YouTube, the largest
video-sharing platform in the world contains vlogs where individuals talk about
their illnesses. The aim of our study was to investigate the use of Natural
Language Processing (NLP) to identify the spoken content of YouTube vlogs
related to the diagnosis of Coronavirus disease of 2019 (COVID-19) for public
health screening. Methods: COVID-19 videos on YouTube were searched using
relevant keywords. A total of 1000 videos being spoken in English were
downloaded out of which 791 were classified as vlogs, 192 were non-vlogs, and
17 were deleted by the channel. The videos were converted into a textual format
using Microsoft Streams. The textual data was preprocessed using basic and
advanced preprocessing methods. A lexicon of 200 words was created which
contained words related to COVID-19. The data was analyzed using topic
modeling, word clouds, and lexicon matching. Results: The word cloud results
revealed discussions about COVID-19 symptoms like "fever", along with generic
terms such as "mask" and "isolation". Lexical analysis demonstrated that in
96.46% of videos, patients discussed generic terms, and in 95.45% of videos,
people talked about COVID-19 symptoms. LDA Topic Modeling results also
generated topics that successfully captured key themes and content related to
our investigation of COVID-19 diagnoses in YouTube vlogs. Conclusion: By
leveraging NLP techniques on YouTube vlogs public health practitioners can
enhance their ability to mitigate the effects of pandemics and effectively
respond to public health challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hybrid Long Document Summarization using C2F-FAR and ChatGPT: A Practical Study. (arXiv:2306.01169v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01169">
<div class="article-summary-box-inner">
<span><p>Text summarization is a downstream natural language processing (NLP) task
that challenges the understanding and generation capabilities of language
models. Considerable progress has been made in automatically summarizing short
texts, such as news articles, often leading to satisfactory results. However,
summarizing long documents remains a major challenge. This is due to the
complex contextual information in the text and the lack of open-source
benchmarking datasets and evaluation frameworks that can be used to develop and
test model performance. In this work, we use ChatGPT, the latest breakthrough
in the field of large language models (LLMs), together with the extractive
summarization model C2F-FAR (Coarse-to-Fine Facet-Aware Ranking) to propose a
hybrid extraction and summarization pipeline for long documents such as
business articles and books. We work with the world-renowned company
getAbstract AG and leverage their expertise and experience in professional book
summarization. A practical study has shown that machine-generated summaries can
perform at least as well as human-written summaries when evaluated using
current automated evaluation metrics. However, a closer examination of the
texts generated by ChatGPT through human evaluations has shown that there are
still critical issues in terms of text coherence, faithfulness, and style.
Overall, our results show that the use of ChatGPT is a very promising but not
yet mature approach for summarizing long documents and can at best serve as an
inspiration for human editors. We anticipate that our work will inform NLP
researchers about the extent to which ChatGPT's capabilities for summarizing
long documents overlap with practitioners' needs. Further work is needed to
test the proposed hybrid summarization pipeline, in particular involving GPT-4,
and to propose a new evaluation framework tailored to the task of summarizing
long documents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Systematic Evaluation of GPT-3 for Zero-Shot Personality Estimation. (arXiv:2306.01183v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01183">
<div class="article-summary-box-inner">
<span><p>Very large language models (LLMs) perform extremely well on a spectrum of NLP
tasks in a zero-shot setting. However, little is known about their performance
on human-level NLP problems which rely on understanding psychological concepts,
such as assessing personality traits. In this work, we investigate the
zero-shot ability of GPT-3 to estimate the Big 5 personality traits from users'
social media posts. Through a set of systematic experiments, we find that
zero-shot GPT-3 performance is somewhat close to an existing pre-trained SotA
for broad classification upon injecting knowledge about the trait in the
prompts. However, when prompted to provide fine-grained classification, its
performance drops to close to a simple most frequent class (MFC) baseline. We
further analyze where GPT-3 performs better, as well as worse, than a
pretrained lexical model, illustrating systematic errors that suggest ways to
improve LLMs on human-level NLP tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Dimensional Evaluation of Text Summarization with In-Context Learning. (arXiv:2306.01200v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01200">
<div class="article-summary-box-inner">
<span><p>Evaluation of natural language generation (NLG) is complex and
multi-dimensional. Generated text can be evaluated for fluency, coherence,
factuality, or any other dimensions of interest. Most frameworks that perform
such multi-dimensional evaluation require training on large manually or
synthetically generated datasets. In this paper, we study the efficacy of large
language models as multi-dimensional evaluators using in-context learning,
obviating the need for large training datasets. Our experiments show that
in-context learning-based evaluators are competitive with learned evaluation
frameworks for the task of text summarization, establishing state-of-the-art on
dimensions such as relevance and factual consistency. We then analyze the
effects of factors such as the selection and number of in-context examples on
performance. Finally, we study the efficacy of in-context learning based
evaluators in evaluating zero-shot summaries written by large language models
such as GPT-3.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning When to Speak: Latency and Quality Trade-offs for Simultaneous Speech-to-Speech Translation with Offline Models. (arXiv:2306.01201v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01201">
<div class="article-summary-box-inner">
<span><p>Recent work in speech-to-speech translation (S2ST) has focused primarily on
offline settings, where the full input utterance is available before any output
is given. This, however, is not reasonable in many real-world scenarios. In
latency-sensitive applications, rather than waiting for the full utterance,
translations should be spoken as soon as the information in the input is
present. In this work, we introduce a system for simultaneous S2ST targeting
real-world use cases. Our system supports translation from 57 languages to
English with tunable parameters for dynamically adjusting the latency of the
output -- including four policies for determining when to speak an output
sequence. We show that these policies achieve offline-level accuracy with
minimal increases in latency over a Greedy (wait-$k$) baseline. We open-source
our evaluation code and interactive test script to aid future SimulS2ST
research and application development.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Estimating Semantic Similarity between In-Domain and Out-of-Domain Samples. (arXiv:2306.01206v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01206">
<div class="article-summary-box-inner">
<span><p>Prior work typically describes out-of-domain (OOD) or out-of-distribution
(OODist) samples as those that originate from dataset(s) or source(s) different
from the training set but for the same task. When compared to in-domain (ID)
samples, the models have been known to usually perform poorer on OOD samples,
although this observation is not consistent. Another thread of research has
focused on OOD detection, albeit mostly using supervised approaches. In this
work, we first consolidate and present a systematic analysis of multiple
definitions of OOD and OODist as discussed in prior literature. Then, we
analyze the performance of a model under ID and OOD/OODist settings in a
principled way. Finally, we seek to identify an unsupervised method for
reliably identifying OOD/OODist samples without using a trained model. The
results of our extensive evaluation using 12 datasets from 4 different tasks
suggest the promising potential of unsupervised metrics in this task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adapting an Unadaptable ASR System. (arXiv:2306.01208v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01208">
<div class="article-summary-box-inner">
<span><p>As speech recognition model sizes and training data requirements grow, it is
increasingly common for systems to only be available via APIs from online
service providers rather than having direct access to models themselves. In
this scenario it is challenging to adapt systems to a specific target domain.
To address this problem we consider the recently released OpenAI Whisper ASR as
an example of a large-scale ASR system to assess adaptation methods. An error
correction based approach is adopted, as this does not require access to the
model, but can be trained from either 1-best or N-best outputs that are
normally available via the ASR API. LibriSpeech is used as the primary target
domain for adaptation. The generalization ability of the system in two distinct
dimensions are then evaluated. First, whether the form of correction model is
portable to other speech recognition domains, and secondly whether it can be
used for ASR models having a different architecture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Responsible Task Automation: Empowering Large Language Models as Responsible Task Automators. (arXiv:2306.01242v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01242">
<div class="article-summary-box-inner">
<span><p>The recent success of Large Language Models (LLMs) signifies an impressive
stride towards artificial general intelligence. They have shown a promising
prospect in automatically completing tasks upon user instructions, functioning
as brain-like coordinators. The associated risks will be revealed as we
delegate an increasing number of tasks to machines for automated completion. A
big question emerges: how can we make machines behave responsibly when helping
humans automate tasks as personal copilots? In this paper, we explore this
question in depth from the perspectives of feasibility, completeness and
security. In specific, we present Responsible Task Automation (ResponsibleTA)
as a fundamental framework to facilitate responsible collaboration between
LLM-based coordinators and executors for task automation with three empowered
capabilities: 1) predicting the feasibility of the commands for executors; 2)
verifying the completeness of executors; 3) enhancing the security (e.g., the
protection of users' privacy). We further propose and compare two paradigms for
implementing the first two capabilities. One is to leverage the generic
knowledge of LLMs themselves via prompt engineering while the other is to adopt
domain-specific learnable models. Moreover, we introduce a local memory
mechanism for achieving the third capability. We evaluate our proposed
ResponsibleTA on UI task automation and hope it could bring more attentions to
ensuring LLMs more responsible in diverse scenarios. The research project
homepage is at
https://task-automation-research.github.io/responsible_task_automation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">THiFLY Research at SemEval-2023 Task 7: A Multi-granularity System for CTR-based Textual Entailment and Evidence Retrieval. (arXiv:2306.01245v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01245">
<div class="article-summary-box-inner">
<span><p>The NLI4CT task aims to entail hypotheses based on Clinical Trial Reports
(CTRs) and retrieve the corresponding evidence supporting the justification.
This task poses a significant challenge, as verifying hypotheses in the NLI4CT
task requires the integration of multiple pieces of evidence from one or two
CTR(s) and the application of diverse levels of reasoning, including textual
and numerical. To address these problems, we present a multi-granularity system
for CTR-based textual entailment and evidence retrieval in this paper.
Specifically, we construct a Multi-granularity Inference Network (MGNet) that
exploits sentence-level and token-level encoding to handle both textual
entailment and evidence retrieval tasks. Moreover, we enhance the numerical
inference capability of the system by leveraging a T5-based model, SciFive,
which is pre-trained on the medical corpus. Model ensembling and a joint
inference method are further utilized in the system to increase the stability
and consistency of inference. The system achieves f1-scores of 0.856 and 0.853
on textual entailment and evidence retrieval tasks, resulting in the best
performance on both subtasks. The experimental results corroborate the
effectiveness of our proposed method. Our code is publicly available at
https://github.com/THUMLP/NLI4CT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Ready are Pre-trained Abstractive Models and LLMs for Legal Case Judgement Summarization?. (arXiv:2306.01248v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01248">
<div class="article-summary-box-inner">
<span><p>Automatic summarization of legal case judgements has traditionally been
attempted by using extractive summarization methods. However, in recent years,
abstractive summarization models are gaining popularity since they can generate
more natural and coherent summaries. Legal domain-specific pre-trained
abstractive summarization models are now available. Moreover, general-domain
pre-trained Large Language Models (LLMs), such as ChatGPT, are known to
generate high-quality text and have the capacity for text summarization. Hence
it is natural to ask if these models are ready for off-the-shelf application to
automatically generate abstractive summaries for case judgements. To explore
this question, we apply several state-of-the-art domain-specific abstractive
summarization models and general-domain LLMs on Indian court case judgements,
and check the quality of the generated summaries. In addition to standard
metrics for summary quality, we check for inconsistencies and hallucinations in
the summaries. We see that abstractive summarization models generally achieve
slightly higher scores than extractive models in terms of standard summary
evaluation metrics such as ROUGE and BLEU. However, we often find inconsistent
or hallucinated information in the generated abstractive summaries. Overall,
our investigation indicates that the pre-trained abstractive summarization
models and LLMs are not yet ready for fully automatic deployment for case
judgement summarization; rather a human-in-the-loop approach including manual
checks for inconsistencies is more suitable at present.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Translation of Hate Speech to Non-hate Speech in Social Media Texts. (arXiv:2306.01261v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01261">
<div class="article-summary-box-inner">
<span><p>In this paper, we investigate the issue of hate speech by presenting a novel
task of translating hate speech into non-hate speech text while preserving its
meaning. As a case study, we use Spanish texts. We provide a dataset and
several baselines as a starting point for further research in the task. We
evaluated our baseline results using multiple metrics, including BLEU scores.
The aim of this study is to contribute to the development of more effective
methods for reducing the spread of hate speech in online communities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VoteTRANS: Detecting Adversarial Text without Training by Voting on Hard Labels of Transformations. (arXiv:2306.01273v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01273">
<div class="article-summary-box-inner">
<span><p>Adversarial attacks reveal serious flaws in deep learning models. More
dangerously, these attacks preserve the original meaning and escape human
recognition. Existing methods for detecting these attacks need to be trained
using original/adversarial data. In this paper, we propose detection without
training by voting on hard labels from predictions of transformations, namely,
VoteTRANS. Specifically, VoteTRANS detects adversarial text by comparing the
hard labels of input text and its transformation. The evaluation demonstrates
that VoteTRANS effectively detects adversarial text across various
state-of-the-art attacks, models, and datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KL-Divergence Guided Temperature Sampling. (arXiv:2306.01286v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01286">
<div class="article-summary-box-inner">
<span><p>Temperature sampling is a conventional approach to diversify large language
model predictions. As temperature increases, the prediction becomes diverse but
also vulnerable to hallucinations -- generating tokens that are sensible but
not factual. One common approach to mitigate hallucinations is to provide
source/grounding documents and the model is trained to produce predictions that
bind to and are attributable to the provided source. It appears that there is a
trade-off between diversity and attribution. To mitigate any such trade-off, we
propose to relax the constraint of having a fixed temperature over decoding
steps, and a mechanism to guide the dynamic temperature according to its
relevance to the source through KL-divergence. Our experiments justifies the
trade-off, and shows that our sampling algorithm outperforms the conventional
top-k and top-p algorithms in conversational question-answering and
summarization tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved Training for End-to-End Streaming Automatic Speech Recognition Model with Punctuation. (arXiv:2306.01296v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01296">
<div class="article-summary-box-inner">
<span><p>Punctuated text prediction is crucial for automatic speech recognition as it
enhances readability and impacts downstream natural language processing tasks.
In streaming scenarios, the ability to predict punctuation in real-time is
particularly desirable but presents a difficult technical challenge. In this
work, we propose a method for predicting punctuated text from input speech
using a chunk-based Transformer encoder trained with Connectionist Temporal
Classification (CTC) loss. The acoustic model trained with long sequences by
concatenating the input and target sequences can learn punctuation marks
attached to the end of sentences more effectively. Additionally, by combining
CTC losses on the chunks and utterances, we achieved both the improved F1 score
of punctuation prediction and Word Error Rate (WER).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DistilXLSR: A Light Weight Cross-Lingual Speech Representation Model. (arXiv:2306.01303v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01303">
<div class="article-summary-box-inner">
<span><p>Multilingual self-supervised speech representation models have greatly
enhanced the speech recognition performance for low-resource languages, and the
compression of these huge models has also become a crucial prerequisite for
their industrial application. In this paper, we propose DistilXLSR, a distilled
cross-lingual speech representation model. By randomly shuffling the phonemes
of existing speech, we reduce the linguistic information and distill
cross-lingual models using only English data. We also design a layer-jumping
initialization method to fully leverage the teacher's pre-trained weights.
Experiments on 2 kinds of teacher models and 15 low-resource languages show
that our method can reduce the parameters by 50% while maintaining
cross-lingual representation ability. Our method is proven to be generalizable
to various languages/teacher models and has the potential to improve the
cross-lingual performance of the English pre-trained models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MetaVL: Transferring In-Context Learning Ability From Language Models to Vision-Language Models. (arXiv:2306.01311v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01311">
<div class="article-summary-box-inner">
<span><p>Large-scale language models have shown the ability to adapt to a new task via
conditioning on a few demonstrations (i.e., in-context learning). However, in
the vision-language domain, most large-scale pre-trained vision-language (VL)
models do not possess the ability to conduct in-context learning. How can we
enable in-context learning for VL models? In this paper, we study an
interesting hypothesis: can we transfer the in-context learning ability from
the language domain to VL domain? Specifically, we first meta-trains a language
model to perform in-context learning on NLP tasks (as in MetaICL); then we
transfer this model to perform VL tasks by attaching a visual encoder. Our
experiments suggest that indeed in-context learning ability can be transferred
cross modalities: our model considerably improves the in-context learning
capability on VL tasks and can even compensate for the size of the model
significantly. On VQA, OK-VQA, and GQA, our method could outperform the
baseline model while having 20 times fewer parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Syntax-aware Hybrid prompt model for Few-shot multi-modal sentiment analysis. (arXiv:2306.01312v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01312">
<div class="article-summary-box-inner">
<span><p>Multimodal Sentiment Analysis (MSA) has been a popular topic in natural
language processing nowadays, at both sentence and aspect level. However, the
existing approaches almost require large-size labeled datasets, which bring
about large consumption of time and resources. Therefore, it is practical to
explore the method for few-shot sentiment analysis in cross-modalities.
Previous works generally execute on textual modality, using the prompt-based
methods, mainly two types: hand-crafted prompts and learnable prompts. The
existing approach in few-shot multi-modality sentiment analysis task has
utilized both methods, separately. We further design a hybrid pattern that can
combine one or more fixed hand-crafted prompts and learnable prompts and
utilize the attention mechanisms to optimize the prompt encoder. The
experiments on both sentence-level and aspect-level datasets prove that we get
a significant outperformance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text Style Transfer Back-Translation. (arXiv:2306.01318v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01318">
<div class="article-summary-box-inner">
<span><p>Back Translation (BT) is widely used in the field of machine translation, as
it has been proved effective for enhancing translation quality. However, BT
mainly improves the translation of inputs that share a similar style (to be
more specific, translation-like inputs), since the source side of BT data is
machine-translated. For natural inputs, BT brings only slight improvements and
sometimes even adverse effects. To address this issue, we propose Text Style
Transfer Back Translation (TST BT), which uses a style transfer model to modify
the source side of BT data. By making the style of source-side text more
natural, we aim to improve the translation of natural inputs. Our experiments
on various language pairs, including both high-resource and low-resource ones,
demonstrate that TST BT significantly improves translation performance against
popular BT benchmarks. In addition, TST BT is proved to be effective in domain
adaptation so this strategy can be regarded as a general data augmentation
method. Our training code and text style transfer model are open-sourced.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LyricSIM: A novel Dataset and Benchmark for Similarity Detection in Spanish Song LyricS. (arXiv:2306.01325v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01325">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a new dataset and benchmark tailored to the task of
semantic similarity in song lyrics. Our dataset, originally consisting of 2775
pairs of Spanish songs, was annotated in a collective annotation experiment by
63 native annotators. After collecting and refining the data to ensure a high
degree of consensus and data integrity, we obtained 676 high-quality annotated
pairs that were used to evaluate the performance of various state-of-the-art
monolingual and multilingual language models. Consequently, we established
baseline results that we hope will be useful to the community in all future
academic and industrial applications conducted in this context.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speech Translation with Foundation Models and Optimal Transport: UPC at IWSLT23. (arXiv:2306.01327v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01327">
<div class="article-summary-box-inner">
<span><p>This paper describes the submission of the UPC Machine Translation group to
the IWSLT 2023 Offline Speech Translation task. Our Speech Translation systems
utilize foundation models for speech (wav2vec 2.0) and text (mBART50). We
incorporate a Siamese pretraining step of the speech and text encoders with CTC
and Optimal Transport, to adapt the speech representations to the space of the
text model, thus maximizing transfer learning from MT. After this pretraining,
we fine-tune our system end-to-end on ST, with Cross Entropy and Knowledge
Distillation. Apart from the available ST corpora, we create synthetic data
with SegAugment to better adapt our models to the custom segmentations of the
IWSLT test sets. Our best single model obtains 31.2 BLEU points on MuST-C
tst-COMMON, 29.8 points on IWLST.tst2020 and 33.4 points on the newly released
IWSLT.ACLdev2023.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Study on Challenging Math Problem Solving with GPT-4. (arXiv:2306.01337v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01337">
<div class="article-summary-box-inner">
<span><p>Employing Large Language Models (LLMs) to address mathematical problems is an
intriguing research endeavor, considering the abundance of math problems
expressed in natural language across numerous science and engineering fields.
While several prior works have investigated solving elementary mathematics
using LLMs, this work explores the frontier of using GPT-4 for solving more
complex and challenging math problems. We evaluate various ways of using GPT-4.
Some of them are adapted from existing work, and one is \MathChat, a
conversational problem-solving framework newly proposed in this work. We
perform the evaluation on difficult high school competition problems from the
MATH dataset, which shows the advantage of the proposed conversational
approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Auxiliary Domain Parallel Data in Intermediate Task Fine-tuning for Low-resource Translation. (arXiv:2306.01382v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01382">
<div class="article-summary-box-inner">
<span><p>NMT systems trained on Pre-trained Multilingual Sequence-Sequence (PMSS)
models flounder when sufficient amounts of parallel data is not available for
fine-tuning. This specifically holds for languages missing/under-represented in
these models. The problem gets aggravated when the data comes from different
domains. In this paper, we show that intermediate-task fine-tuning (ITFT) of
PMSS models is extremely beneficial for domain-specific NMT, especially when
target domain data is limited/unavailable and the considered languages are
missing or under-represented in the PMSS model. We quantify the domain-specific
results variations using a domain-divergence test, and show that ITFT can
mitigate the impact of domain divergence to some extent.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task-Agnostic Structured Pruning of Speech Representation Models. (arXiv:2306.01385v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01385">
<div class="article-summary-box-inner">
<span><p>Self-supervised pre-trained models such as Wav2vec2, Hubert, and WavLM have
been shown to significantly improve many speech tasks. However, their large
memory and strong computational requirements hinder their industrial
applicability. Structured pruning is a hardware-friendly model compression
technique but usually results in a larger loss of accuracy. In this paper, we
propose a fine-grained attention head pruning method to compensate for the
performance degradation. In addition, we also introduce the straight through
estimator into the L0 regularization to further accelerate the pruned model.
Experiments on the SUPERB benchmark show that our model can achieve comparable
performance to the dense model in multiple tasks and outperforms the Wav2vec
2.0 base model on average, with 72% fewer parameters and 2 times faster
inference speed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT for Zero-shot Dialogue State Tracking: A Solution or an Opportunity?. (arXiv:2306.01386v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01386">
<div class="article-summary-box-inner">
<span><p>Recent research on dialogue state tracking (DST) focuses on methods that
allow few- and zero-shot transfer to new domains or schemas. However,
performance gains heavily depend on aggressive data augmentation and
fine-tuning of ever larger language model based architectures. In contrast,
general purpose language models, trained on large amounts of diverse data, hold
the promise of solving any kind of task without task-specific training. We
present preliminary experimental results on the ChatGPT research preview,
showing that ChatGPT achieves state-of-the-art performance in zero-shot DST.
Despite our findings, we argue that properties inherent to general purpose
models limit their ability to replace specialized systems. We further theorize
that the in-context learning capabilities of such models will likely become
powerful tools to support the development of dedicated and dynamic dialogue
state trackers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing the Importance of Frequency versus Compositionality for Subword-based Tokenization in NMT. (arXiv:2306.01393v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01393">
<div class="article-summary-box-inner">
<span><p>Subword tokenization is the de facto standard for tokenization in neural
language models and machine translation systems. Three advantages are
frequently cited in favor of subwords: shorter encoding of frequent tokens,
compositionality of subwords, and ability to deal with unknown words. As their
relative importance is not entirely clear yet, we propose a tokenization
approach that enables us to separate frequency (the first advantage) from
compositionality. The approach uses Huffman coding to tokenize words, by order
of frequency, using a fixed amount of symbols. Experiments with CS-DE, EN-FR
and EN-DE NMT show that frequency alone accounts for 90%-95% of the scores
reached by BPE, hence compositionality has less importance than previously
thought.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Graph Reasoning over Entities and Numerical Values. (arXiv:2306.01399v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01399">
<div class="article-summary-box-inner">
<span><p>A complex logic query in a knowledge graph refers to a query expressed in
logic form that conveys a complex meaning, such as where did the Canadian
Turing award winner graduate from? Knowledge graph reasoning-based
applications, such as dialogue systems and interactive search engines, rely on
the ability to answer complex logic queries as a fundamental task. In most
knowledge graphs, edges are typically used to either describe the relationships
between entities or their associated attribute values. An attribute value can
be in categorical or numerical format, such as dates, years, sizes, etc.
However, existing complex query answering (CQA) methods simply treat numerical
values in the same way as they treat entities. This can lead to difficulties in
answering certain queries, such as which Australian Pulitzer award winner is
born before 1927, and which drug is a pain reliever and has fewer side effects
than Paracetamol. In this work, inspired by the recent advances in numerical
encoding and knowledge graph reasoning, we propose numerical complex query
answering. In this task, we introduce new numerical variables and operations to
describe queries involving numerical attribute values. To address the
difference between entities and numerical values, we also propose the framework
of Number Reasoning Network (NRN) for alternatively encoding entities and
numerical values into separate encoding structures. During the numerical
encoding process, NRN employs a parameterized density function to encode the
distribution of numerical values. During the entity encoding process, NRN uses
established query encoding methods for the original CQA problem. Experimental
results show that NRN consistently improves various query encoding methods on
three different knowledge graphs and achieves state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpretable and Explainable Logical Policies via Neurally Guided Symbolic Abstraction. (arXiv:2306.01439v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01439">
<div class="article-summary-box-inner">
<span><p>The limited priors required by neural networks make them the dominating
choice to encode and learn policies using reinforcement learning (RL). However,
they are also black-boxes, making it hard to understand the agent's behaviour,
especially when working on the image level. Therefore, neuro-symbolic RL aims
at creating policies that are interpretable in the first place. Unfortunately,
interpretability is not explainability. To achieve both, we introduce Neurally
gUided Differentiable loGic policiEs (NUDGE). NUDGE exploits trained neural
network-based agents to guide the search of candidate-weighted logic rules,
then uses differentiable logic to train the logic agents. Our experimental
evaluation demonstrates that NUDGE agents can induce interpretable and
explainable policies while outperforming purely neural ones and showing good
flexibility to environments of different initial states and problem sizes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Robust FastSpeech 2 by Modelling Residual Multimodality. (arXiv:2306.01442v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01442">
<div class="article-summary-box-inner">
<span><p>State-of-the-art non-autoregressive text-to-speech (TTS) models based on
FastSpeech 2 can efficiently synthesise high-fidelity and natural speech. For
expressive speech datasets however, we observe characteristic audio
distortions. We demonstrate that such artefacts are introduced to the vocoder
reconstruction by over-smooth mel-spectrogram predictions, which are induced by
the choice of mean-squared-error (MSE) loss for training the mel-spectrogram
decoder. With MSE loss FastSpeech 2 is limited to learn conditional averages of
the training distribution, which might not lie close to a natural sample if the
distribution still appears multimodal after all conditioning signals. To
alleviate this problem, we introduce TVC-GMM, a mixture model of
Trivariate-Chain Gaussian distributions, to model the residual multimodality.
TVC-GMM reduces spectrogram smoothness and improves perceptual audio quality in
particular for expressive datasets as shown by both objective and subjective
evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Paraphrasing of Multiword Expressions. (arXiv:2306.01443v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01443">
<div class="article-summary-box-inner">
<span><p>We propose an unsupervised approach to paraphrasing multiword expressions
(MWEs) in context. Our model employs only monolingual corpus data and
pre-trained language models (without fine-tuning), and does not make use of any
external resources such as dictionaries. We evaluate our method on the SemEval
2022 idiomatic semantic text similarity task, and show that it outperforms all
unsupervised systems and rivals supervised systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Extractive Summarization of Emotion Triggers. (arXiv:2306.01444v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01444">
<div class="article-summary-box-inner">
<span><p>Understanding what leads to emotions during large-scale crises is important
as it can provide groundings for expressed emotions and subsequently improve
the understanding of ongoing disasters. Recent approaches trained supervised
models to both detect emotions and explain emotion triggers (events and
appraisals) via abstractive summarization. However, obtaining timely and
qualitative abstractive summaries is expensive and extremely time-consuming,
requiring highly-trained expert annotators. In time-sensitive, high-stake
contexts, this can block necessary responses. We instead pursue unsupervised
systems that extract triggers from text. First, we introduce CovidET-EXT,
augmenting (Zhan et al. 2022)'s abstractive dataset (in the context of the
COVID-19 crisis) with extractive triggers. Second, we develop new unsupervised
learning models that can jointly detect emotions and summarize their triggers.
Our best approach, entitled Emotion-Aware Pagerank, incorporates emotion
information from external sources combined with a language understanding
module, and outperforms strong baselines. We release our data and code at
https://github.com/tsosea2/CovidET-EXT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Driving Context into Text-to-Text Privatization. (arXiv:2306.01457v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01457">
<div class="article-summary-box-inner">
<span><p>\textit{Metric Differential Privacy} enables text-to-text privatization by
adding calibrated noise to the vector of a word derived from an embedding space
and projecting this noisy vector back to a discrete vocabulary using a nearest
neighbor search. Since words are substituted without context, this mechanism is
expected to fall short at finding substitutes for words with ambiguous
meanings, such as \textit{'bank'}. To account for these ambiguous words, we
leverage a sense embedding and incorporate a sense disambiguation step prior to
noise injection. We encompass our modification to the privatization mechanism
with an estimation of privacy and utility. For word sense disambiguation on the
\textit{Words in Context} dataset, we demonstrate a substantial increase in
classification accuracy by $6.05\%$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Light Coreference Resolution for Russian with Hierarchical Discourse Features. (arXiv:2306.01465v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01465">
<div class="article-summary-box-inner">
<span><p>Coreference resolution is the task of identifying and grouping mentions
referring to the same real-world entity. Previous neural models have mainly
focused on learning span representations and pairwise scores for coreference
decisions. However, current methods do not explicitly capture the referential
choice in the hierarchical discourse, an important factor in coreference
resolution. In this study, we propose a new approach that incorporates
rhetorical information into neural coreference resolution models. We collect
rhetorical features from automated discourse parses and examine their impact.
As a base model, we implement an end-to-end span-based coreference resolver
using a partially fine-tuned multilingual entity-aware language model LUKE. We
evaluate our method on the RuCoCo-23 Shared Task for coreference resolution in
Russian. Our best model employing rhetorical distance between mentions has
ranked 1st on the development set (74.6% F1) and 2nd on the test set (73.3% F1)
of the Shared Task. We hope that our work will inspire further research on
incorporating discourse information in neural coreference resolution models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Guiding Text-to-Text Privatization by Syntax. (arXiv:2306.01471v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01471">
<div class="article-summary-box-inner">
<span><p>Metric Differential Privacy is a generalization of differential privacy
tailored to address the unique challenges of text-to-text privatization. By
adding noise to the representation of words in the geometric space of
embeddings, words are replaced with words located in the proximity of the noisy
representation. Since embeddings are trained based on word co-occurrences, this
mechanism ensures that substitutions stem from a common semantic context.
Without considering the grammatical category of words, however, this mechanism
cannot guarantee that substitutions play similar syntactic roles. We analyze
the capability of text-to-text privatization to preserve the grammatical
category of words after substitution and find that surrogate texts consist
almost exclusively of nouns. Lacking the capability to produce surrogate texts
that correlate with the structure of the sensitive texts, we encompass our
analysis by transforming the privatization step into a candidate selection
problem in which substitutions are directed to words with matching grammatical
properties. We demonstrate a substantial improvement in the performance of
downstream tasks by up to $4.66\%$ while retaining comparative privacy
guarantees.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GAIA Search: Hugging Face and Pyserini Interoperability for NLP Training Data Exploration. (arXiv:2306.01481v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01481">
<div class="article-summary-box-inner">
<span><p>Noticing the urgent need to provide tools for fast and user-friendly
qualitative analysis of large-scale textual corpora of the modern NLP, we
propose to turn to the mature and well-tested methods from the domain of
Information Retrieval (IR) - a research field with a long history of tackling
TB-scale document collections. We discuss how Pyserini - a widely used toolkit
for reproducible IR research can be integrated with the Hugging Face ecosystem
of open-source AI libraries and artifacts. We leverage the existing
functionalities of both platforms while proposing novel features further
facilitating their integration. Our goal is to give NLP researchers tools that
will allow them to develop retrieval-based instrumentation for their data
analytics needs with ease and agility. We include a Jupyter Notebook-based walk
through the core interoperability features, available on GitHub at
https://github.com/huggingface/gaia. We then demonstrate how the ideas we
present can be operationalized to create a powerful tool for qualitative data
analysis in NLP. We present GAIA Search - a search engine built following
previously laid out principles, giving access to four popular large-scale text
collections. GAIA serves a dual purpose of illustrating the potential of
methodologies we discuss but also as a standalone qualitative analysis tool
that can be leveraged by NLP researchers aiming to understand datasets prior to
using them in training. GAIA is hosted live on Hugging Face Spaces -
https://huggingface.co/spaces/spacerini/gaia.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-Efficient French Language Modeling with CamemBERTa. (arXiv:2306.01497v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01497">
<div class="article-summary-box-inner">
<span><p>Recent advances in NLP have significantly improved the performance of
language models on a variety of tasks. While these advances are largely driven
by the availability of large amounts of data and computational power, they also
benefit from the development of better training methods and architectures. In
this paper, we introduce CamemBERTa, a French DeBERTa model that builds upon
the DeBERTaV3 architecture and training objective. We evaluate our model's
performance on a variety of French downstream tasks and datasets, including
question answering, part-of-speech tagging, dependency parsing, named entity
recognition, and the FLUE benchmark, and compare against CamemBERT, the
state-of-the-art monolingual model for French. Our results show that, given the
same amount of training tokens, our model outperforms BERT-based models trained
with MLM on most tasks. Furthermore, our new model reaches similar or superior
performance on downstream tasks compared to CamemBERT, despite being trained on
only 30% of its total number of input tokens. In addition to our experimental
results, we also publicly release the weights and code implementation of
CamemBERTa, making it the first publicly available DeBERTaV3 model outside of
the original paper and the first openly available implementation of a DeBERTaV3
training objective. https://gitlab.inria.fr/almanach/CamemBERTa
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can LLMs like GPT-4 outperform traditional AI tools in dementia diagnosis? Maybe, but not today. (arXiv:2306.01499v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01499">
<div class="article-summary-box-inner">
<span><p>Recent investigations show that large language models (LLMs), specifically
GPT-4, not only have remarkable capabilities in common Natural Language
Processing (NLP) tasks but also exhibit human-level performance on various
professional and academic benchmarks. However, whether GPT-4 can be directly
used in practical applications and replace traditional artificial intelligence
(AI) tools in specialized domains requires further experimental validation. In
this paper, we explore the potential of LLMs such as GPT-4 to outperform
traditional AI tools in dementia diagnosis. Comprehensive comparisons between
GPT-4 and traditional AI tools are conducted to examine their diagnostic
accuracy in a clinical setting. Experimental results on two real clinical
datasets show that, although LLMs like GPT-4 demonstrate potential for future
advancements in dementia diagnosis, they currently do not surpass the
performance of traditional AI tools. The interpretability and faithfulness of
GPT-4 are also evaluated by comparison with real doctors. We discuss the
limitations of GPT-4 in its current state and propose future research
directions to enhance GPT-4 in dementia diagnosis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Supervised Adversarial Contrastive Learning for Emotion Recognition in Conversations. (arXiv:2306.01505v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01505">
<div class="article-summary-box-inner">
<span><p>Extracting generalized and robust representations is a major challenge in
emotion recognition in conversations (ERC). To address this, we propose a
supervised adversarial contrastive learning (SACL) framework for learning
class-spread structured representations. The framework applies contrast-aware
adversarial training to generate worst-case samples and uses a joint
class-spread contrastive learning objective on both original and adversarial
samples. It can effectively utilize label-level feature consistency and retain
fine-grained intra-class features. To avoid the negative impact of adversarial
perturbations on context-dependent data, we design a contextual adversarial
training strategy to learn more diverse features from context and enhance the
model's context robustness. We develop a sequence-based method SACL-LSTM under
this framework, to learn label-consistent and context-robust emotional features
for ERC. Experiments on three datasets demonstrate that SACL-LSTM achieves
state-of-the-art performance on ERC. Extended experiments prove the
effectiveness of the SACL framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BabySLM: language-acquisition-friendly benchmark of self-supervised spoken language models. (arXiv:2306.01506v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01506">
<div class="article-summary-box-inner">
<span><p>Self-supervised techniques for learning speech representations have been
shown to develop linguistic competence from exposure to speech without the need
for human labels. In order to fully realize the potential of these approaches
and further our understanding of how infants learn language, simulations must
closely emulate real-life situations by training on developmentally plausible
corpora and benchmarking against appropriate test sets. To this end, we propose
a language-acquisition-friendly benchmark to probe spoken language models at
the lexical and syntactic levels, both of which are compatible with the
vocabulary typical of children's language experiences. This paper introduces
the benchmark and summarizes a range of experiments showing its usefulness. In
addition, we highlight two exciting challenges that need to be addressed for
further progress: bridging the gap between text and speech and between clean
speech and in-the-wild speech.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PassGPT: Password Modeling and (Guided) Generation with Large Language Models. (arXiv:2306.01545v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01545">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) successfully model natural language from vast
amounts of text without the need for explicit supervision. In this paper, we
investigate the efficacy of LLMs in modeling passwords. We present PassGPT, a
LLM trained on password leaks for password generation. PassGPT outperforms
existing methods based on generative adversarial networks (GAN) by guessing
twice as many previously unseen passwords. Furthermore, we introduce the
concept of guided password generation, where we leverage PassGPT sampling
procedure to generate passwords matching arbitrary constraints, a feat lacking
in current GAN-based strategies. Lastly, we conduct an in-depth analysis of the
entropy and probability distribution that PassGPT defines over passwords and
discuss their use in enhancing existing password strength estimators.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Machine Translation Quality with Conformal Predictive Distributions. (arXiv:2306.01549v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01549">
<div class="article-summary-box-inner">
<span><p>This paper presents a new approach for assessing uncertainty in machine
translation by simultaneously evaluating translation quality and providing a
reliable confidence score. Our approach utilizes conformal predictive
distributions to produce prediction intervals with guaranteed coverage, meaning
that for any given significance level $\epsilon$, we can expect the true
quality score of a translation to fall out of the interval at a rate of
$1-\epsilon$. In this paper, we demonstrate how our method outperforms a
simple, but effective baseline on six different language pairs in terms of
coverage and sharpness. Furthermore, we validate that our approach requires the
data exchangeability assumption to hold for optimal performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparing a composite model versus chained models to locate a nearest visual object. (arXiv:2306.01551v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01551">
<div class="article-summary-box-inner">
<span><p>Extracting information from geographic images and text is crucial for
autonomous vehicles to determine in advance the best cell stations to connect
to along their future path. Multiple artificial neural network models can
address this challenge; however, there is no definitive guidance on the
selection of an appropriate model for such use cases. Therefore, we
experimented two architectures to solve such a task: a first architecture with
chained models where each model in the chain addresses a sub-task of the task;
and a second architecture with a single model that addresses the whole task.
Our results showed that these two architectures achieved the same level
performance with a root mean square error (RMSE) of 0.055 and 0.056; The
findings further revealed that when the task can be decomposed into sub-tasks,
the chain architecture exhibits a twelve-fold increase in training speed
compared to the composite model. Nevertheless, the composite model
significantly alleviates the burden of data labeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EmoUS: Simulating User Emotions in Task-Oriented Dialogues. (arXiv:2306.01579v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01579">
<div class="article-summary-box-inner">
<span><p>Existing user simulators (USs) for task-oriented dialogue systems only model
user behaviour on semantic and natural language levels without considering the
user persona and emotions. Optimising dialogue systems with generic user
policies, which cannot model diverse user behaviour driven by different
emotional states, may result in a high drop-off rate when deployed in the real
world. Thus, we present EmoUS, a user simulator that learns to simulate user
emotions alongside user behaviour. EmoUS generates user emotions, semantic
actions, and natural language responses based on the user goal, the dialogue
history, and the user persona. By analysing what kind of system behaviour
elicits what kind of user emotions, we show that EmoUS can be used as a probe
to evaluate a variety of dialogue systems and in particular their effect on the
user's emotional state. Developing such methods is important in the age of
large language model chat-bots and rising ethical concerns.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning from Partially Annotated Data: Example-aware Creation of Gap-filling Exercises for Language Learning. (arXiv:2306.01584v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01584">
<div class="article-summary-box-inner">
<span><p>Since performing exercises (including, e.g., practice tests) forms a crucial
component of learning, and creating such exercises requires non-trivial effort
from the teacher. There is a great value in automatic exercise generation in
digital tools in education. In this paper, we particularly focus on automatic
creation of gapfilling exercises for language learning, specifically grammar
exercises. Since providing any annotation in this domain requires human expert
effort, we aim to avoid it entirely and explore the task of converting existing
texts into new gap-filling exercises, purely based on an example exercise,
without explicit instruction or detailed annotation of the intended grammar
topics. We contribute (i) a novel neural network architecture specifically
designed for aforementioned gap-filling exercise generation task, and (ii) a
real-world benchmark dataset for French grammar. We show that our model for
this French grammar gap-filling exercise generation outperforms a competitive
baseline classifier by 8% in F1 percentage points, achieving an average F1
score of 82%. Our model implementation and the dataset are made publicly
available to foster future research, thus offering a standardized evaluation
and baseline solution of the proposed partially annotated data prediction task
in grammar exercise creation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiffusEmp: A Diffusion Model-Based Framework with Multi-Grained Control for Empathetic Response Generation. (arXiv:2306.01657v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01657">
<div class="article-summary-box-inner">
<span><p>Empathy is a crucial factor in open-domain conversations, which naturally
shows one's caring and understanding to others. Though several methods have
been proposed to generate empathetic responses, existing works often lead to
monotonous empathy that refers to generic and safe expressions. In this paper,
we propose to use explicit control to guide the empathy expression and design a
framework DiffusEmp based on conditional diffusion language model to unify the
utilization of dialogue context and attribute-oriented control signals.
Specifically, communication mechanism, intent, and semantic frame are imported
as multi-grained signals that control the empathy realization from coarse to
fine levels. We then design a specific masking strategy to reflect the
relationship between multi-grained signals and response tokens, and integrate
it into the diffusion model to influence the generative process. Experimental
results on a benchmark dataset EmpatheticDialogue show that our framework
outperforms competitive baselines in terms of controllability, informativeness,
and diversity without the loss of context-relatedness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-Grained Human Feedback Gives Better Rewards for Language Model Training. (arXiv:2306.01693v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01693">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) often exhibit undesirable text generation behaviors,
including generating false, toxic, or irrelevant outputs. Reinforcement
learning from human feedback (RLHF) - where human preference judgments on LM
outputs are transformed into a learning signal - has recently shown promise in
addressing these issues. However, such holistic feedback conveys limited
information on long text outputs; it does not indicate which aspects of the
outputs influenced user preference; e.g., which parts contain what type(s) of
errors. In this paper, we use fine-grained human feedback (e.g., which sentence
is false, which sub-sentence is irrelevant) as an explicit training signal. We
introduce Fine-Grained RLHF, a framework that enables training and learning
from reward functions that are fine-grained in two respects: (1) density,
providing a reward after every segment (e.g., a sentence) is generated; and (2)
incorporating multiple reward models associated with different feedback types
(e.g., factual incorrectness, irrelevance, and information incompleteness). We
conduct experiments on detoxification and long-form question answering to
illustrate how learning with such reward functions leads to improved
performance, supported by both automatic and human evaluation. Additionally, we
show that LM behaviors can be customized using different combinations of
fine-grained reward models. We release all data, collected human feedback, and
codes at https://FineGrainedRLHF.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Multi-step Reasoning from Arithmetic Task. (arXiv:2306.01707v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01707">
<div class="article-summary-box-inner">
<span><p>Mathematical reasoning is regarded as a necessary ability for Language Models
(LMs). Recent works demonstrate large LMs' impressive performance in solving
math problems. The success is attributed to their Chain-of-Thought (CoT)
reasoning abilities, i.e., the ability to decompose complex questions into
step-by-step reasoning chains, but such ability seems only to emerge from
models with abundant parameters. This work investigates how to incorporate
relatively small LMs with the capabilities of multi-step reasoning. We propose
to inject such abilities by continually pre-training LMs on a synthetic dataset
MsAT, which stands for Multi-step Arithmetic Task. Our experiments on four math
word problem datasets show the effectiveness of the proposed method in
enhancing LMs' math reasoning abilities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Resolving Interference When Merging Models. (arXiv:2306.01708v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01708">
<div class="article-summary-box-inner">
<span><p>Transfer learning - i.e., further fine-tuning a pre-trained model on a
downstream task - can confer significant advantages, including improved
downstream performance, faster convergence, and better sample efficiency. These
advantages have led to a proliferation of task-specific fine-tuned models,
which typically can only perform a single task and do not benefit from one
another. Recently, model merging techniques have emerged as a solution to
combine multiple task-specific models into a single multitask model without
performing additional training. However, existing merging methods often ignore
the interference between parameters of different models, resulting in large
performance drops when merging multiple models. In this paper, we demonstrate
that prior merging techniques inadvertently lose valuable information due to
two major sources of interference: (a) interference due to redundant parameter
values and (b) disagreement on the sign of a given parameter's values across
models. To address this, we propose our method, TrIm, Elect Sign &amp; Merge
(TIES-Merging), which introduces three novel steps when merging models: (1)
resetting parameters that only changed a small amount during fine-tuning, (2)
resolving sign conflicts, and (3) merging only the parameters that are in
alignment with the final agreed-upon sign. We find that TIES-Merging
outperforms several existing methods in diverse settings covering a range of
modalities, domains, number of tasks, model sizes, architectures, and
fine-tuning settings. We further analyze the impact of different types of
interference on model parameters, highlight the importance of resolving sign
interference. Our code is available at
https://github.com/prateeky2806/ties-merging
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distilling Efficient Language-Specific Models for Cross-Lingual Transfer. (arXiv:2306.01709v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01709">
<div class="article-summary-box-inner">
<span><p>Massively multilingual Transformers (MMTs), such as mBERT and XLM-R, are
widely used for cross-lingual transfer learning. While these are pretrained to
represent hundreds of languages, end users of NLP systems are often interested
only in individual languages. For such purposes, the MMTs' language coverage
makes them unnecessarily expensive to deploy in terms of model size, inference
time, energy, and hardware cost. We thus propose to extract compressed,
language-specific models from MMTs which retain the capacity of the original
MMTs for cross-lingual transfer. This is achieved by distilling the MMT
bilingually, i.e., using data from only the source and target language of
interest. Specifically, we use a two-phase distillation approach, termed
BiStil: (i) the first phase distils a general bilingual model from the MMT,
while (ii) the second, task-specific phase sparsely fine-tunes the bilingual
"student" model using a task-tuned variant of the original MMT as its
"teacher". We evaluate this distillation technique in zero-shot cross-lingual
transfer across a number of standard cross-lingual benchmarks. The key results
indicate that the distilled models exhibit minimal degradation in target
language performance relative to the base MMT despite being significantly
smaller and faster. Furthermore, we find that they outperform multilingually
distilled models such as DistilmBERT and MiniLMv2 while having a very modest
training budget in comparison, even on a per-language basis. We also show that
bilingual models distilled from MMTs greatly outperform bilingual models
trained from scratch. Our code and models are available at
https://github.com/AlanAnsell/bistil.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Generalization in Task-oriented Dialogues with Workflows and Action Plans. (arXiv:2306.01729v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01729">
<div class="article-summary-box-inner">
<span><p>Task-oriented dialogue is difficult in part because it involves understanding
user intent, collecting information from the user, executing API calls, and
generating helpful and fluent responses. However, for complex tasks one must
also correctly do all of these things over multiple steps, and in a specific
order. While large pre-trained language models can be fine-tuned end-to-end to
create multi-step task-oriented dialogue agents that generate fluent text, our
experiments confirm that this approach alone cannot reliably perform new
multi-step tasks that are unseen during training. To address these limitations,
we augment the dialogue contexts given to \textmd{text2text} transformers with
known \textit{valid workflow names} and \textit{action plans}. Action plans
consist of sequences of actions required to accomplish a task, and are encoded
as simple sequences of keywords (e.g. verify-identity, pull-up-account,
reset-password, etc.). We perform extensive experiments on the Action-Based
Conversations Dataset (ABCD) with T5-small, base and large models, and show
that such models: a) are able to more readily generalize to unseen workflows by
following the provided plan, and b) are able to generalize to executing unseen
actions if they are provided in the plan. In contrast, models are unable to
fully accomplish new multi-step tasks when they are not provided action plan
information, even when given new valid workflow names.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lessons on Parameter Sharing across Layers in Transformers. (arXiv:2104.06022v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06022">
<div class="article-summary-box-inner">
<span><p>We propose a parameter sharing method for Transformers (Vaswani et al.,
2017). The proposed approach relaxes a widely used technique, which shares
parameters for one layer with all layers such as Universal Transformers
(Dehghani et al., 2019), to increase the efficiency in the computational time.
We propose three strategies: Sequence, Cycle, and Cycle (rev) to assign
parameters to each layer. Experimental results show that the proposed
strategies are efficient in the parameter size and computational time.
Moreover, we indicate that the proposed strategies are also effective in the
configuration where we use many training data such as the recent WMT
competition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Syntax-Aware Graph-to-Graph Transformer for Semantic Role Labelling. (arXiv:2104.07704v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07704">
<div class="article-summary-box-inner">
<span><p>Recent models have shown that incorporating syntactic knowledge into the
semantic role labelling (SRL) task leads to a significant improvement. In this
paper, we propose Syntax-aware Graph-to-Graph Transformer (SynG2G-Tr) model,
which encodes the syntactic structure using a novel way to input graph
relations as embeddings, directly into the self-attention mechanism of
Transformer. This approach adds a soft bias towards attention patterns that
follow the syntactic structure but also allows the model to use this
information to learn alternative patterns. We evaluate our model on both
span-based and dependency-based SRL datasets, and outperform previous
alternative methods in both in-domain and out-of-domain settings, on CoNLL 2005
and CoNLL 2009 datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PhysNLU: A Language Resource for Evaluating Natural Language Understanding and Explanation Coherence in Physics. (arXiv:2201.04275v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04275">
<div class="article-summary-box-inner">
<span><p>In order for language models to aid physics research, they must first encode
representations of mathematical and natural language discourse which lead to
coherent explanations, with correct ordering and relevance of statements. We
present a collection of datasets developed to evaluate the performance of
language models in this regard, which measure capabilities with respect to
sentence ordering, position, section prediction, and discourse coherence.
Analysis of the data reveals equations and sub-disciplines which are most
common in physics discourse, as well as the sentence-level frequency of
equations and expressions. We present baselines that demonstrate how
contemporary language models are challenged by coherence related tasks in
physics, even when trained on mathematical natural language objectives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models. (arXiv:2206.14268v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14268">
<div class="article-summary-box-inner">
<span><p>It is crucial to automatically construct knowledge graphs (KGs) of diverse
new relations to support knowledge discovery and broad applications. Previous
KG construction methods, based on either crowdsourcing or text mining, are
often limited to a small predefined set of relations due to manual cost or
restrictions in text corpus. Recent research proposed to use pretrained
language models (LMs) as implicit knowledge bases that accept knowledge queries
with prompts. Yet, the implicit knowledge lacks many desirable properties of a
full-scale symbolic KG, such as easy access, navigation, editing, and quality
assurance. In this paper, we propose a new approach of harvesting massive KGs
of arbitrary relations from pretrained LMs. With minimal input of a relation
definition (a prompt and a few shot of example entity pairs), the approach
efficiently searches in the vast entity pair space to extract diverse accurate
knowledge of the desired relation. We develop an effective search-and-rescore
mechanism for improved efficiency and accuracy. We deploy the approach to
harvest KGs of over 400 new relations from different LMs. Extensive human and
automatic evaluations show our approach manages to extract diverse accurate
knowledge, including tuples of complex relations (e.g., "A is capable of but
not good at B"). The resulting KGs as a symbolic interpretation of the source
LMs also reveal new insights into the LMs' knowledge capacities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ThinkSum: Probabilistic reasoning over sets using large language models. (arXiv:2210.01293v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.01293">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have a substantial capacity for high-level
analogical reasoning: reproducing patterns in linear text that occur in their
training data (zero-shot evaluation) or in the provided context (few-shot
in-context learning). However, recent studies show that even the more advanced
LLMs fail in scenarios that require reasoning over multiple objects or facts
and making sequences of logical deductions. We propose a two-stage
probabilistic inference paradigm, ThinkSum, which reasons over sets of objects
or facts in a structured manner. In the first stage (Think - retrieval of
associations), a LLM is queried in parallel over a set of phrases extracted
from the prompt or an auxiliary model call. In the second stage (Sum -
probabilistic inference or reasoning), the results of these queries are
aggregated to make the final prediction. We demonstrate the possibilities and
advantages of ThinkSum on the BIG-bench suite of LLM evaluation tasks,
achieving improvements over the state of the art using GPT-family models on
thirteen difficult tasks, often with far smaller model variants. We also
compare and contrast ThinkSum with other proposed modifications to direct
prompting of LLMs, such as variants of chain-of-thought prompting. Our results
suggest that because the probabilistic inference in ThinkSum is performed
outside of calls to the LLM, ThinkSum is less sensitive to prompt design,
yields more interpretable predictions, and can be flexibly combined with latent
variable models to extract structured knowledge from LLMs. Overall, our
proposed paradigm represents a promising approach for enhancing the reasoning
capabilities of LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified Detoxifying and Debiasing in Language Generation via Inference-time Adaptive Optimization. (arXiv:2210.04492v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04492">
<div class="article-summary-box-inner">
<span><p>Warning: this paper contains model outputs exhibiting offensiveness and
biases. Recently pre-trained language models (PLMs) have prospered in various
natural language generation (NLG) tasks due to their ability to generate fairly
fluent text. Nevertheless, these models are observed to capture and reproduce
harmful contents in training corpora, typically toxic language and social
biases, raising severe moral issues. Prior works on ethical NLG tackle
detoxifying and debiasing separately, which is problematic since we find
debiased models still exhibit toxicity while detoxified ones even exacerbate
social biases. To address such a challenge, we propose the first unified
framework of detoxifying and debiasing called UDDIA, which jointly formalizes
these two problems as rectifying the output space. We theoretically interpret
our framework as learning a text distribution mixing weighted attributes.
Besides, UDDIA conducts adaptive optimization of only a few parameters during
decoding based on a parameter-efficient tuning schema without any training
data. This leads to minimal generation quality loss and improved rectification
performance with acceptable computational cost. Experimental results
demonstrate that compared to several strong baselines, UDDIA achieves debiasing
and detoxifying simultaneously and better balances efficiency and
effectiveness, taking a further step towards practical ethical NLG.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">REV: Information-Theoretic Evaluation of Free-Text Rationales. (arXiv:2210.04982v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04982">
<div class="article-summary-box-inner">
<span><p>Generating free-text rationales is a promising step towards explainable NLP,
yet evaluating such rationales remains a challenge. Existing metrics have
mostly focused on measuring the association between the rationale and a given
label. We argue that an ideal metric should focus on the new information
uniquely provided in the rationale that is otherwise not provided in the input
or the label. We investigate this research problem from an
information-theoretic perspective using conditional V-information (Hewitt et
al., 2021). More concretely, we propose a metric called REV (Rationale
Evaluation with conditional V-information), to quantify the amount of new,
label-relevant information in a rationale beyond the information already
available in the input or the label. Experiments across four benchmarks with
reasoning tasks, including chain-of-thought, demonstrate the effectiveness of
REV in evaluating rationale-label pairs, compared to existing metrics. We
further demonstrate REV is consistent with human judgments on rationale
evaluations and provides more sensitive measurements of new information in
free-text rationales. When used alongside traditional performance metrics, REV
provides deeper insights into models' reasoning and prediction processes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Easy Guided Decoding in Providing Suggestions for Interactive Machine Translation. (arXiv:2211.07093v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.07093">
<div class="article-summary-box-inner">
<span><p>Machine translation technology has made great progress in recent years, but
it cannot guarantee error free results. Human translators perform post editing
on machine translations to correct errors in the scene of computer aided
translation. In favor of expediting the post editing process, many works have
investigated machine translation in interactive modes, in which machines can
automatically refine the rest of translations constrained by human's edits.
Translation Suggestion (TS), as an interactive mode to assist human
translators, requires machines to generate alternatives for specific incorrect
words or phrases selected by human translators. In this paper, we utilize the
parameterized objective function of neural machine translation (NMT) and
propose a novel constrained decoding algorithm, namely Prefix Suffix Guided
Decoding (PSGD), to deal with the TS problem without additional training.
Compared to the state of the art lexically constrained decoding method, PSGD
improves translation quality by an average of $10.87$ BLEU and $8.62$ BLEU on
the WeTS and the WMT 2022 Translation Suggestion datasets, respectively, and
reduces decoding time overhead by an average of 63.4% tested on the WMT
translation datasets. Furthermore, on both of the TS benchmark datasets, it is
superior to other supervised learning systems trained with TS annotated data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Why Did the Chicken Cross the Road? Rephrasing and Analyzing Ambiguous Questions in VQA. (arXiv:2211.07516v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.07516">
<div class="article-summary-box-inner">
<span><p>Natural language is ambiguous. Resolving ambiguous questions is key to
successfully answering them. Focusing on questions about images, we create a
dataset of ambiguous examples. We annotate these, grouping answers by the
underlying question they address and rephrasing the question for each group to
reduce ambiguity. Our analysis reveals a linguistically-aligned ontology of
reasons for ambiguity in visual questions. We then develop an English
question-generation model which we demonstrate via automatic and human
evaluation produces less ambiguous questions. We further show that the question
generation objective we use allows the model to integrate answer group
information without any direct supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Level Knowledge Distillation for Out-of-Distribution Detection in Text. (arXiv:2211.11300v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.11300">
<div class="article-summary-box-inner">
<span><p>Self-supervised representation learning has proved to be a valuable component
for out-of-distribution (OoD) detection with only the texts of in-distribution
(ID) examples. These approaches either train a language model from scratch or
fine-tune a pre-trained language model using ID examples, and then take the
perplexity output by the language model as OoD scores. In this paper, we
analyze the complementary characteristics of both OoD detection methods and
propose a multi-level knowledge distillation approach that integrates their
strengths while mitigating their limitations. Specifically, we use a fine-tuned
model as the teacher to teach a randomly initialized student model on the ID
examples. Besides the prediction layer distillation, we present a
similarity-based intermediate layer distillation method to thoroughly explore
the representation space of the teacher model. In this way, the learned student
can better represent the ID data manifold while gaining a stronger ability to
map OoD examples outside the ID data manifold with the regularization inherited
from pre-training. Besides, the student model sees only ID examples during
parameter learning, further promoting more distinguishable features for OoD
detection. We conduct extensive experiments over multiple benchmark datasets,
i.e., CLINC150, SST, ROSTD, 20 NewsGroups, and AG News; showing that the
proposed method yields new state-of-the-art performance. We also explore its
application as an AIGC detector to distinguish between answers generated by
ChatGPT and human experts. It is observed that our model exceeds human
evaluators in the pair-expert task on the Human ChatGPT Comparison Corpus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Federated Learning Meets Pre-trained Language Models' Parameter-Efficient Tuning Methods. (arXiv:2212.10025v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10025">
<div class="article-summary-box-inner">
<span><p>With increasing privacy concerns on data, recent studies have made
significant progress using federated learning (FL) on privacy-sensitive natural
language processing (NLP) tasks. Much literature suggests fully fine-tuning
pre-trained language models (PLMs) in the FL paradigm can mitigate the data
heterogeneity problem and close the performance gap with centralized training.
However, large PLMs bring the curse of prohibitive communication overhead and
local model adaptation costs for the FL system. To this end, we introduce
various parameter-efficient tuning (PETuning) methods into federated learning.
Specifically, we provide a holistic empirical study of representative PLMs
tuning methods in FL. The experimental results cover the analysis of data
heterogeneity levels, data scales, and different FL scenarios. Overall
communication overhead can be significantly reduced by locally tuning and
globally aggregating lightweight model parameters while maintaining acceptable
performance in various FL settings. To facilitate the research of PETuning in
FL, we also develop a federated tuning framework FedPETuning, which allows
practitioners to exploit different PETuning methods under the FL training
paradigm conveniently. The source code is available at
\url{https://github.com/iezhuozhuo/FedETuning/tree/deltaTuning}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">True Detective: A Deep Abductive Reasoning Benchmark Undoable for GPT-3 and Challenging for GPT-4. (arXiv:2212.10114v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10114">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have demonstrated solid zero-shot reasoning
capabilities, which is reflected in their performance on the current test
tasks. This calls for a more challenging benchmark requiring highly advanced
reasoning ability to be solved. In this paper, we introduce such a benchmark,
consisting of 191 long-form (1200 words on average) mystery narratives
constructed as detective puzzles. Puzzles are sourced from the "5 Minute
Mystery" platform and include a multiple-choice question for evaluation. Only
47% of humans solve a puzzle successfully on average, while the best human
solvers achieve over 80% success rate. We show that GPT-3 models barely
outperform random on this benchmark (with 28% accuracy) while state-of-the-art
GPT-4 solves only 38% of puzzles. This indicates that there is still a
significant gap in the deep reasoning abilities of LLMs and humans and
highlights the need for further research in this area. Our work introduces a
challenging benchmark for future studies on reasoning in language models and
contributes to a better understanding of the limits of LLMs' abilities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shades of Iteration: from Elgot to Kleene. (arXiv:2301.06202v2 [cs.LO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.06202">
<div class="article-summary-box-inner">
<span><p>Notions of iteration range from the arguably most general Elgot iteration to
a very specific Kleene iteration. The fundamental nature of Elgot iteration has
been extensively explored by Bloom and Esik in the form of iteration theories,
while Kleene iteration became extremely popular as an integral part of
(untyped) formalisms, such as automata theory, regular expressions and Kleene
algebra. Here, we establish a formal connection between Elgot iteration and
Kleene iteration in the form of Elgot monads and Kleene monads, respectively.
We also introduce a novel class of while-monads, which like Kleene monads admit
a relatively simple description in algebraic terms. Like Elgot monads,
while-monads cover a large variety of models that meaningfully support
while-loops, but may fail the Kleene algebra laws, or even fail to support a
Kleen iteration operator altogether.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT: Jack of all trades, master of none. (arXiv:2302.10724v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10724">
<div class="article-summary-box-inner">
<span><p>OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and
revolutionized the approach in artificial intelligence to human-model
interaction. Several publications on ChatGPT evaluation test its effectiveness
on well-known natural language processing (NLP) tasks. However, the existing
studies are mostly non-automated and tested on a very limited scale. In this
work, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks,
most of them subjective even to humans, such as sentiment analysis, emotion
recognition, offensiveness, and stance detection. In contrast, the other tasks
require more objective reasoning like word sense disambiguation, linguistic
acceptability, and question answering. We also evaluated GPT-4 model on five
selected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process
and analyzed more than 49k responses. Our comparison of its results with
available State-of-the-Art (SOTA) solutions showed that the average loss in
quality of the ChatGPT model was about 25% for zero-shot and few-shot
evaluation. For GPT-4 model, a loss for semantic tasks is significantly lower
than for ChatGPT. We showed that the more difficult the task (lower SOTA
performance), the higher the ChatGPT loss. It especially refers to pragmatic
NLP problems like emotion recognition. We also tested the ability to
personalize ChatGPT responses for selected subjective tasks via Random
Contextual Few-Shot Personalization, and we obtained significantly better
user-based predictions. Additional qualitative analysis revealed a ChatGPT
bias, most likely due to the rules imposed on human trainers by OpenAI. Our
results provide the basis for a fundamental discussion of whether the high
quality of recent predictive NLP models can indicate a tool's usefulness to
society and how the learning and validation procedures for such systems should
be established.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fluid Transformers and Creative Analogies: Exploring Large Language Models' Capacity for Augmenting Cross-Domain Analogical Creativity. (arXiv:2302.12832v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12832">
<div class="article-summary-box-inner">
<span><p>Cross-domain analogical reasoning is a core creative ability that can be
challenging for humans. Recent work has shown some proofs-of concept of Large
language Models' (LLMs) ability to generate cross-domain analogies. However,
the reliability and potential usefulness of this capacity for augmenting human
creative work has received little systematic exploration. In this paper, we
systematically explore LLMs capacity to augment cross-domain analogical
reasoning. Across three studies, we found: 1) LLM-generated cross-domain
analogies were frequently judged as helpful in the context of a problem
reformulation task (median 4 out of 5 helpfulness rating), and frequently (~80%
of cases) led to observable changes in problem formulations, and 2) there was
an upper bound of 25% of outputs bring rated as potentially harmful, with a
majority due to potentially upsetting content, rather than biased or toxic
content. These results demonstrate the potential utility -- and risks -- of
LLMs for augmenting cross-domain analogical creativity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">N-best T5: Robust ASR Error Correction using Multiple Input Hypotheses and Constrained Decoding Space. (arXiv:2303.00456v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.00456">
<div class="article-summary-box-inner">
<span><p>Error correction models form an important part of Automatic Speech
Recognition (ASR) post-processing to improve the readability and quality of
transcriptions. Most prior works use the 1-best ASR hypothesis as input and
therefore can only perform correction by leveraging the context within one
sentence. In this work, we propose a novel N-best T5 model for this task, which
is fine-tuned from a T5 model and utilizes ASR N-best lists as model input. By
transferring knowledge from the pre-trained language model and obtaining richer
information from the ASR decoding space, the proposed approach outperforms a
strong Conformer-Transducer baseline. Another issue with standard error
correction is that the generation process is not well-guided. To address this a
constrained decoding process, either based on the N-best list or an ASR
lattice, is used which allows additional information to be propagated.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quick Dense Retrievers Consume KALE: Post Training Kullback Leibler Alignment of Embeddings for Asymmetrical dual encoders. (arXiv:2304.01016v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.01016">
<div class="article-summary-box-inner">
<span><p>In this paper, we consider the problem of improving the inference latency of
language model-based dense retrieval systems by introducing structural
compression and model size asymmetry between the context and query encoders.
First, we investigate the impact of pre and post-training compression on the
MSMARCO, Natural Questions, TriviaQA, SQUAD, and SCIFACT, finding that
asymmetry in the dual encoders in dense retrieval can lead to improved
inference efficiency. Knowing this, we introduce Kullback Leibler Alignment of
Embeddings (KALE), an efficient and accurate method for increasing the
inference efficiency of dense retrieval methods by pruning and aligning the
query encoder after training. Specifically, KALE extends traditional Knowledge
Distillation after bi-encoder training, allowing for effective query encoder
compression without full retraining or index generation. Using KALE and
asymmetric training, we can generate models which exceed the performance of
DistilBERT despite having 3x faster inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Possibilities of AI-Generated Text Detection. (arXiv:2304.04736v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.04736">
<div class="article-summary-box-inner">
<span><p>Our work focuses on the challenge of detecting outputs generated by Large
Language Models (LLMs) to distinguish them from those generated by humans. This
ability is of the utmost importance in numerous applications. However, the
possibility of such discernment has been the subject of debate within the
community. Therefore, a central question is whether we can detect AI-generated
text and, if so, when. In this work, we provide evidence that it should almost
always be possible to detect AI-generated text unless the distributions of
human and machine-generated texts are exactly the same over the entire support.
This observation follows from the standard results in information theory and
relies on the fact that if the machine text becomes more human-like, we need
more samples to detect it. We derive a precise sample complexity bound of
AI-generated text detection, which tells how many samples are needed to detect
AI-generated text. This gives rise to additional challenges of designing more
complicated detectors that take in $n$ samples for detection (rather than just
one), which is the scope of future research on this topic. Our empirical
evaluations on various real and synthetic datasets support our claim about the
existence of better detectors, demonstrating that AI-generated text detection
should be achievable in the majority of scenarios. Our theory and results align
with OpenAI's empirical findings, (in relation to sequence length), and we are
the first to provide a solid theoretical justification for these outcomes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-end spoken language understanding using joint CTC loss and self-supervised, pretrained acoustic encoders. (arXiv:2305.02937v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02937">
<div class="article-summary-box-inner">
<span><p>It is challenging to extract semantic meanings directly from audio signals in
spoken language understanding (SLU), due to the lack of textual information.
Popular end-to-end (E2E) SLU models utilize sequence-to-sequence automatic
speech recognition (ASR) models to extract textual embeddings as input to infer
semantics, which, however, require computationally expensive auto-regressive
decoding. In this work, we leverage self-supervised acoustic encoders
fine-tuned with Connectionist Temporal Classification (CTC) to extract textual
embeddings and use joint CTC and SLU losses for utterance-level SLU tasks.
Experiments show that our model achieves 4% absolute improvement over the the
state-of-the-art (SOTA) dialogue act classification model on the DSTC2 dataset
and 1.3% absolute improvement over the SOTA SLU model on the SLURP dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ProKnow: Process Knowledge for Safety Constrained and Explainable Question Generation for Mental Health Diagnostic Assistance. (arXiv:2305.08010v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.08010">
<div class="article-summary-box-inner">
<span><p>Current Virtual Mental Health Assistants (VMHAs) provide counseling and
suggestive care. They refrain from patient diagnostic assistance because they
lack training in safety-constrained and specialized clinical process knowledge.
In this work, we define Proknow as an ordered set of information that maps to
evidence-based guidelines or categories of conceptual understanding to experts
in a domain. We also introduce a new dataset of diagnostic conversations guided
by safety constraints and Proknow that healthcare professionals use. We develop
a method for natural language question generation (NLG) that collects
diagnostic information from the patient interactively. We demonstrate the
limitations of using state-of-the-art large-scale language models (LMs) on this
dataset. Our algorithm models the process knowledge through explicitly modeling
safety, knowledge capture, and explainability. LMs augmented with ProKnow
guided method generated 89% safer questions in the depression and anxiety
domain. The Explainability of the generated question is assessed by computing
similarity with concepts in depression and anxiety knowledge bases. Overall,
irrespective of the type of LMs augmented with our ProKnow, we achieved an
average 82% improvement over simple pre-trained LMs on safety, explainability,
and process-guided question generation. We qualitatively and quantitatively
evaluate the efficacy of the proposed ProKnow-guided methods by introducing
three new evaluation metrics for safety, explainability, and process knowledge
adherence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Measuring Consistency in Text-based Financial Forecasting Models. (arXiv:2305.08524v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.08524">
<div class="article-summary-box-inner">
<span><p>Financial forecasting has been an important and active area of machine
learning research, as even the most modest advantage in predictive accuracy can
be parlayed into significant financial gains. Recent advances in natural
language processing (NLP) bring the opportunity to leverage textual data, such
as earnings reports of publicly traded companies, to predict the return rate
for an asset. However, when dealing with such a sensitive task, the consistency
of models -- their invariance under meaning-preserving alternations in input --
is a crucial property for building user trust. Despite this, current financial
forecasting methods do not consider consistency. To address this problem, we
propose FinTrust, an evaluation tool that assesses logical consistency in
financial text. Using FinTrust, we show that the consistency of
state-of-the-art NLP models for financial forecasting is poor. Our analysis of
the performance degradation caused by meaning-preserving alternations suggests
that current text-based methods are not suitable for robustly predicting market
information. All resources are available at
https://github.com/yingpengma/fintrust.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"I'm fully who I am": Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation. (arXiv:2305.09941v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09941">
<div class="article-summary-box-inner">
<span><p>Transgender and non-binary (TGNB) individuals disproportionately experience
discrimination and exclusion from daily life. Given the recent popularity and
adoption of language generation technologies, the potential to further
marginalize this population only grows. Although a multitude of NLP fairness
literature focuses on illuminating and addressing gender biases, assessing
gender harms for TGNB identities requires understanding how such identities
uniquely interact with societal gender norms and how they differ from gender
binary-centric perspectives. Such measurement frameworks inherently require
centering TGNB voices to help guide the alignment between gender-inclusive NLP
and whom they are intended to serve. Towards this goal, we ground our work in
the TGNB community and existing interdisciplinary literature to assess how the
social reality surrounding experienced marginalization of TGNB persons
contributes to and persists within Open Language Generation (OLG). This social
knowledge serves as a guide for evaluating popular large language models (LLMs)
on two key aspects: (1) misgendering and (2) harmful responses to gender
disclosure. To do this, we introduce TANGO, a dataset of template-based
real-world text curated from a TGNB-oriented community. We discover a dominance
of binary gender norms reflected by the models; LLMs least misgendered subjects
in generated text when triggered by prompts whose subjects used binary
pronouns. Meanwhile, misgendering was most prevalent when triggering generation
with singular they and neopronouns. When prompted with gender disclosures, TGNB
disclosure generated the most stigmatizing language and scored most toxic, on
average. Our findings warrant further research on how TGNB harms manifest in
LLMs and serve as a broader case study toward concretely grounding the design
of gender-inclusive AI in community voices and interdisciplinary literature.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark. (arXiv:2305.10036v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10036">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have demonstrated powerful capabilities in both
text understanding and generation. Companies have begun to offer Embedding as a
Service (EaaS) based on these LLMs, which can benefit various natural language
processing (NLP) tasks for customers. However, previous studies have shown that
EaaS is vulnerable to model extraction attacks, which can cause significant
losses for the owners of LLMs, as training these models is extremely expensive.
To protect the copyright of LLMs for EaaS, we propose an Embedding Watermark
method called EmbMarker that implants backdoors on embeddings. Our method
selects a group of moderate-frequency words from a general text corpus to form
a trigger set, then selects a target embedding as the watermark, and inserts it
into the embeddings of texts containing trigger words as the backdoor. The
weight of insertion is proportional to the number of trigger words included in
the text. This allows the watermark backdoor to be effectively transferred to
EaaS-stealer's model for copyright verification while minimizing the adverse
impact on the original embeddings' utility. Our extensive experiments on
various datasets show that our method can effectively protect the copyright of
EaaS models without compromising service quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Off-Target Problem of Zero-Shot Multilingual Neural Machine Translation. (arXiv:2305.10930v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10930">
<div class="article-summary-box-inner">
<span><p>While multilingual neural machine translation has achieved great success, it
suffers from the off-target issue, where the translation is in the wrong
language. This problem is more pronounced on zero-shot translation tasks. In
this work, we find that failing in encoding discriminative target language
signal will lead to off-target and a closer lexical distance (i.e.,
KL-divergence) between two languages' vocabularies is related with a higher
off-target rate. We also find that solely isolating the vocab of different
languages in the decoder can alleviate the problem. Motivated by the findings,
we propose Language Aware Vocabulary Sharing (LAVS), a simple and effective
algorithm to construct the multilingual vocabulary, that greatly alleviates the
off-target problem of the translation model by increasing the KL-divergence
between languages. We conduct experiments on a multilingual machine translation
benchmark in 11 languages. Experiments show that the off-target rate for 90
translation tasks is reduced from 29\% to 8\%, while the overall BLEU score is
improved by an average of 1.9 points without extra training cost or sacrificing
the supervised directions' performance. We release the code at
https://github.com/PKUnlp-icler/Off-Target-MNMT for reproduction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimizing Non-Autoregressive Transformers with Contrastive Learning. (arXiv:2305.13667v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.13667">
<div class="article-summary-box-inner">
<span><p>Non-autoregressive Transformers (NATs) reduce the inference latency of
Autoregressive Transformers (ATs) by predicting words all at once rather than
in sequential order. They have achieved remarkable progress in machine
translation as well as many other applications. However, a long-standing
challenge for NATs is the learning of multi-modality data distribution, which
is the main cause of the performance gap between NATs and ATs. In this paper,
we propose to ease the difficulty of modality learning via sampling from the
model distribution instead of the data distribution. We derive contrastive
constraints to stabilize the training process and integrate this resulting
objective with the state-of-the-art NAT architecture DA-Transformer. Our model
\method is examined on 3 different tasks, including machine translation, text
summarization, and paraphrasing with 5 benchmarks. Results show that our
approach outperforms previous non-autoregressive baselines by a significant
margin and establishes new state-of-the-art results for non-autoregressive
transformers on all the benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SenteCon: Leveraging Lexicons to Learn Human-Interpretable Language Representations. (arXiv:2305.14728v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14728">
<div class="article-summary-box-inner">
<span><p>Although deep language representations have become the dominant form of
language featurization in recent years, in many settings it is important to
understand a model's decision-making process. This necessitates not only an
interpretable model but also interpretable features. In particular, language
must be featurized in a way that is interpretable while still characterizing
the original text well. We present SenteCon, a method for introducing human
interpretability in deep language representations. Given a passage of text,
SenteCon encodes the text as a layer of interpretable categories in which each
dimension corresponds to the relevance of a specific category. Our empirical
evaluations indicate that encoding language with SenteCon provides high-level
interpretability at little to no cost to predictive performance on downstream
tasks. Moreover, we find that SenteCon outperforms existing interpretable
language representations with respect to both its downstream performance and
its agreement with human characterizations of the text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Linguistic Properties of Truthful Response. (arXiv:2305.15875v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15875">
<div class="article-summary-box-inner">
<span><p>We investigate the phenomenon of an LLM's untruthful response using a large
set of 220 handcrafted linguistic features. We focus on GPT-3 models and find
that the linguistic profiles of responses are similar across model sizes. That
is, how varying-sized LLMs respond to given prompts stays similar on the
linguistic properties level. We expand upon this finding by training support
vector machines that rely only upon the stylistic components of model responses
to classify the truthfulness of statements. Though the dataset size limits our
current findings, we show the possibility that truthfulness detection is
possible without evaluating the content itself. But at the same time, the
limited scope of our experiments must be taken into account in interpreting the
results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Non-Autoregressive Translation at Scale. (arXiv:2305.16155v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16155">
<div class="article-summary-box-inner">
<span><p>In real-world systems, scaling has been critical for improving the
translation quality in autoregressive translation (AT), which however has not
been well studied for non-autoregressive translation (NAT). In this work, we
bridge the gap by systematically studying the impact of scaling on NAT
behaviors. Extensive experiments on six WMT benchmarks over two advanced NAT
models show that scaling can alleviate the commonly-cited weaknesses of NAT
models, resulting in better translation performance. To reduce the side-effect
of scaling on decoding speed, we empirically investigate the impact of NAT
encoder and decoder on the translation performance. Experimental results on the
large-scale WMT20 En-De show that the asymmetric architecture (e.g. bigger
encoder and smaller decoder) can achieve comparable performance with the
scaling model, while maintaining the superiority of decoding speed with
standard NAT models. To this end, we establish a new benchmark by validating
scaled NAT models on the scaled dataset, which can be regarded as a strong
baseline for future works. We release code and system outputs at
https://github.com/DeepLearnXMU/Scaling4NAT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Natural Language Processing for Long Texts: A Survey of the State-of-the-Art. (arXiv:2305.16259v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16259">
<div class="article-summary-box-inner">
<span><p>The adoption of Deep Neural Networks (DNNs) has greatly benefited Natural
Language Processing (NLP) during the past decade. However, the demands of long
document analysis are quite different from those of shorter texts, while the
ever increasing size of documents uploaded on-line renders automated
understanding of long texts a critical area of research. This article has two
goals: a) it overviews the relevant neural building blocks, thus serving as a
short tutorial, and b) it surveys the state-of-the-art in long document NLP,
mainly focusing on two central tasks: document classification and document
summarization. Sentiment analysis for long texts is also covered, since it is
typically treated as a particular case of document classification.
Additionally, this article discusses the main challenges, issues and current
solutions related to long document NLP. Finally, the relevant, publicly
available, annotated datasets are presented, in order to facilitate further
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Motion-Based Sign Language Video Summarization using Curvature and Torsion. (arXiv:2305.16801v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16801">
<div class="article-summary-box-inner">
<span><p>An interesting problem in many video-based applications is the generation of
short synopses by selecting the most informative frames, a procedure which is
known as video summarization. For sign language videos the benefits of using
the $t$-parameterized counterpart of the curvature of the 2-D signer's wrist
trajectory to identify keyframes, have been recently reported in the
literature. In this paper we extend these ideas by modeling the 3-D hand motion
that is extracted from each frame of the video. To this end we propose a new
informative function based on the $t$-parameterized curvature and torsion of
the 3-D trajectory. The method to characterize video frames as keyframes
depends on whether the motion occurs in 2-D or 3-D space. Specifically, in the
case of 3-D motion we look for the maxima of the harmonic mean of the curvature
and torsion of the target's trajectory; in the planar motion case we seek for
the maxima of the trajectory's curvature. The proposed 3-D feature is
experimentally evaluated in applications of sign language videos on (1)
objective measures using ground-truth keyframe annotations, (2) human-based
evaluation of understanding, and (3) gloss classification and the results
obtained are promising.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Better Text Image Translation with Multimodal Codebook. (arXiv:2305.17415v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17415">
<div class="article-summary-box-inner">
<span><p>Text image translation (TIT) aims to translate the source texts embedded in
the image to target translations, which has a wide range of applications and
thus has important research value. However, current studies on TIT are
confronted with two main bottlenecks: 1) this task lacks a publicly available
TIT dataset, 2) dominant models are constructed in a cascaded manner, which
tends to suffer from the error propagation of optical character recognition
(OCR). In this work, we first annotate a Chinese-English TIT dataset named
OCRMT30K, providing convenience for subsequent studies. Then, we propose a TIT
model with a multimodal codebook, which is able to associate the image with
relevant texts, providing useful supplementary information for translation.
Moreover, we present a multi-stage training framework involving text machine
translation, image-text alignment, and TIT tasks, which fully exploits
additional bilingual texts, OCR dataset and our OCRMT30K dataset to train our
model. Extensive experiments and in-depth analyses strongly demonstrate the
effectiveness of our proposed model and training framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multiscale Positive-Unlabeled Detection of AI-Generated Texts. (arXiv:2305.18149v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18149">
<div class="article-summary-box-inner">
<span><p>Recent releases of Large Language Models (LLMs), e.g. ChatGPT, are
astonishing at generating human-like texts, but they may get misused for fake
scholarly texts, fake news, fake tweets, et cetera. Previous works have
proposed methods to detect these multiscale AI-generated texts, including
simple ML classifiers, pretrained-model-based training-agnostic methods, and
finetuned language classification models. However, mainstream detectors are
formulated without considering the factor of corpus length: shorter corpuses
are harder to detect compared with longer ones for shortage of informative
features. In this paper, a Multiscale Positive-Unlabeled (MPU) training
framework is proposed to address the challenge of multiscale text detection.
Firstly, we acknowledge the human-resemblance property of short machine texts,
and rephrase text classification as a Positive-Unlabeled (PU) problem by
marking these short machine texts as "unlabeled" during training. In this PU
context, we propose the length-sensitive Multiscale PU Loss, where we use a
recurrent model in abstraction to estimate positive priors of scale-variant
corpuses. Additionally, we introduce a Text Multiscaling module to enrich
training corpuses. Experiments show that our MPU method augments detection
performance on long AI-generated text, and significantly improves short-corpus
detection of language model detectors. Language Models trained with MPU could
outcompete existing detectors by large margins on multiscale AI-generated
texts. The codes are available at
https://github.com/mindspore-lab/mindone/tree/master/examples/detect_chatgpt
and https://github.com/YuchuanTian/AIGC_text_detector.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Faith and Fate: Limits of Transformers on Compositionality. (arXiv:2305.18654v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18654">
<div class="article-summary-box-inner">
<span><p>Transformer large language models (LLMs) have sparked admiration for their
exceptional performance on tasks that demand intricate multi-step reasoning.
Yet, these models simultaneously show failures on surprisingly trivial
problems. This begs the question: Are these errors incidental, or do they
signal more substantial limitations? In an attempt to demystify Transformers,
we investigate the limits of these models across three representative
compositional tasks -- multi-digit multiplication, logic grid puzzles, and a
classic dynamic programming problem. These tasks require breaking problems down
into sub-steps and synthesizing these steps into a precise answer. We formulate
compositional tasks as computation graphs to systematically quantify the level
of complexity, and break down reasoning steps into intermediate sub-procedures.
Our empirical findings suggest that Transformers solve compositional tasks by
reducing multi-step compositional reasoning into linearized subgraph matching,
without necessarily developing systematic problem-solving skills. To round off
our empirical study, we provide theoretical arguments on abstract multi-step
reasoning problems that highlight how Transformers' performance will rapidly
decay with increased task complexity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KEYword based Sampling (KEYS) for Large Language Models. (arXiv:2305.18679v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18679">
<div class="article-summary-box-inner">
<span><p>Question answering (Q/A) can be formulated as a generative task (Mitra, 2017)
where the task is to generate an answer given the question and the passage
(knowledge, if available). Recent advances in QA task is focused a lot on
language model advancements and less on other areas such as sampling(Krishna et
al., 2021), (Nakano et al., 2021). Keywords play very important role for humans
in language generation. (Humans formulate keywords and use grammar to connect
those keywords and work). In the research community, very little focus is on
how humans generate answers to a question and how this behavior can be
incorporated in a language model. In this paper, we want to explore these two
areas combined, i.e., how sampling can be to used generate answers which are
close to human-like behavior and factually correct. Hence, the type of decoding
algorithm we think should be used for Q/A tasks should also depend on the
keywords. These keywords can be obtained from the question, passage or internet
results. We use knowledge distillation techniques to extract keywords and
sample using these extracted keywords on top of vanilla decoding algorithms
when formulating the answer to generate a human-like answer. In this paper, we
show that our decoding method outperforms most commonly used decoding methods
for Q/A task
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UKP-SQuARE: An Interactive Tool for Teaching Question Answering. (arXiv:2305.19748v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19748">
<div class="article-summary-box-inner">
<span><p>The exponential growth of question answering (QA) has made it an
indispensable topic in any Natural Language Processing (NLP) course.
Additionally, the breadth of QA derived from this exponential growth makes it
an ideal scenario for teaching related NLP topics such as information
retrieval, explainability, and adversarial attacks among others. In this paper,
we introduce UKP-SQuARE as a platform for QA education. This platform provides
an interactive environment where students can run, compare, and analyze various
QA models from different perspectives, such as general behavior,
explainability, and robustness. Therefore, students can get a first-hand
experience in different QA techniques during the class. Thanks to this, we
propose a learner-centered approach for QA education in which students
proactively learn theoretical concepts and acquire problem-solving skills
through interactive exploration, experimentation, and practical assignments,
rather than solely relying on traditional lectures. To evaluate the
effectiveness of UKP-SQuARE in teaching scenarios, we adopted it in a
postgraduate NLP course and surveyed the students after the course. Their
positive feedback shows the platform's effectiveness in their course and
invites a wider adoption.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AfriNames: Most ASR models "butcher" African Names. (arXiv:2306.00253v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00253">
<div class="article-summary-box-inner">
<span><p>Useful conversational agents must accurately capture named entities to
minimize error for downstream tasks, for example, asking a voice assistant to
play a track from a certain artist, initiating navigation to a specific
location, or documenting a laboratory result for a patient. However, where
named entities such as ``Ukachukwu`` (Igbo), ``Lakicia`` (Swahili), or
``Ingabire`` (Rwandan) are spoken, automatic speech recognition (ASR) models'
performance degrades significantly, propagating errors to downstream systems.
We model this problem as a distribution shift and demonstrate that such model
bias can be mitigated through multilingual pre-training, intelligent data
augmentation strategies to increase the representation of African-named
entities, and fine-tuning multilingual ASR models on multiple African accents.
The resulting fine-tuned models show an 81.5\% relative WER improvement
compared with the baseline on samples with African-named entities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TopEx: Topic-based Explanations for Model Comparison. (arXiv:2306.00976v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00976">
<div class="article-summary-box-inner">
<span><p>Meaningfully comparing language models is challenging with current
explanation methods. Current explanations are overwhelming for humans due to
large vocabularies or incomparable across models. We present TopEx, an
explanation method that enables a level playing field for comparing language
models via model-agnostic topics. We demonstrate how TopEx can identify
similarities and differences between DistilRoBERTa and GPT-2 on a variety of
NLP tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classifying YouTube Comments Based on Sentiment and Type of Sentence. (arXiv:2111.01908v1 [cs.IR] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01908">
<div class="article-summary-box-inner">
<span><p>As a YouTube channel grows, each video can potentially collect enormous
amounts of comments that provide direct feedback from the viewers. These
comments are a major means of understanding viewer expectations and improving
channel engagement. However, the comments only represent a general collection
of user opinions about the channel and the content. Many comments are poorly
constructed, trivial, and have improper spellings and grammatical errors. As a
result, it is a tedious job to identify the comments that best interest the
content creators. In this paper, we extract and classify the raw comments into
different categories based on both sentiment and sentence types that will help
YouTubers find relevant comments for growing their viewership. Existing studies
have focused either on sentiment analysis (positive and negative) or
classification of sub-types within the same sentence types (e.g., types of
questions) on a text corpus. These have limited application on non-traditional
text corpus like YouTube comments. We address this challenge of text extraction
and classification from YouTube comments using well-known statistical measures
and machine learning models. We evaluate each combination of statistical
measure and the machine learning model using cross validation and $F_1$ scores.
The results show that our approach that incorporates conventional methods
performs well on the classification task, validating its potential in assisting
content creators increase viewer engagement on their channel.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-06-05 23:11:20.705893505 UTC">2023-06-05 23:11:20 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>