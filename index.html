<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-01-04T01:30:00Z">01-04</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">ClusTop: An unsupervised and integrated text clustering and topic extraction framework. (arXiv:2301.00818v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.00818">
<div class="article-summary-box-inner">
<span><p>Text clustering and topic extraction are two important tasks in text mining.
Usually, these two tasks are performed separately. For topic extraction to
facilitate clustering, we can first project texts into a topic space and then
perform a clustering algorithm to obtain clusters. To promote topic extraction
by clustering, we can first obtain clusters with a clustering algorithm and
then extract cluster-specific topics. However, this naive strategy ignores the
fact that text clustering and topic extraction are strongly correlated and
follow a chicken-and-egg relationship. Performing them separately fails to make
them mutually benefit each other to achieve the best overall performance. In
this paper, we propose an unsupervised text clustering and topic extraction
framework (ClusTop) which integrates text clustering and topic extraction into
a unified framework and can achieve high-quality clustering result and extract
topics from each cluster simultaneously. Our framework includes four
components: enhanced language model training, dimensionality reduction,
clustering and topic extraction, where the enhanced language model can be
viewed as a bridge between clustering and topic extraction. On one hand, it
provides text embeddings with a strong cluster structure which facilitates
effective text clustering; on the other hand, it pays high attention on the
topic related words for topic extraction because of its self-attention
architecture. Moreover, the training of enhanced language model is
unsupervised. Experiments on two datasets demonstrate the effectiveness of our
framework and provide benchmarks for different model combinations in this
framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Kannudi -- A Reference Editor for Kannada. (arXiv:2301.00836v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.00836">
<div class="article-summary-box-inner">
<span><p>Kannudi is a reference editor for Kannada based on OPOK! and OHOK!
principles, and domain knowledge. It introduces a method of input for Kannada,
called OHOK!, that is, Ottu Haku Ottu Kodu! (apply pressure and give ottu).
This is especially suited for pressure sensitive input devices, though the
current online implementation uses the regular mechanical keyboard. OHOK! has
three possible modes, namely, sva-ottu (self-conjunct), kandante (as you see),
and andante (as you say). It may be noted that kandante mode does not follow
the phonetic order. However, this mode may work well for those who are inclined
to visualize as they type rather than vocalizing the sounds.
</p>
<p>Kannudi also demonstrates how domain knowledge can be effectively used to
potentially increase speed, accuracy, and user friendliness. For example,
selection of a default vowel, automatic shunyification, and arkification. Also
implemented are four types Deletes that are necessary for phono-syllabic
languages like Kannada.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Follow the Timeline! Generating Abstractive and Extractive Timeline Summary in Chronological Order. (arXiv:2301.00867v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.00867">
<div class="article-summary-box-inner">
<span><p>Nowadays, time-stamped web documents related to a general news query floods
spread throughout the Internet, and timeline summarization targets concisely
summarizing the evolution trajectory of events along the timeline. Unlike
traditional document summarization, timeline summarization needs to model the
time series information of the input events and summarize important events in
chronological order. To tackle this challenge, in this paper, we propose a
Unified Timeline Summarizer (UTS) that can generate abstractive and extractive
timeline summaries in time order. Concretely, in the encoder part, we propose a
graph-based event encoder that relates multiple events according to their
content dependency and learns a global representation of each event. In the
decoder part, to ensure the chronological order of the abstractive summary, we
propose to extract the feature of event-level attention in its generation
process with sequential information remained and use it to simulate the
evolutionary attention of the ground truth summary. The event-level attention
can also be used to assist in extracting summary, where the extracted summary
also comes in time sequence. We augment the previous Chinese large-scale
timeline summarization dataset and collect a new English timeline dataset.
Extensive experiments conducted on these datasets and on the out-of-domain
Timeline 17 dataset show that UTS achieves state-of-the-art performance in
terms of both automatic and human evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MAUD: An Expert-Annotated Legal NLP Dataset for Merger Agreement Understanding. (arXiv:2301.00876v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.00876">
<div class="article-summary-box-inner">
<span><p>Reading comprehension of legal text can be a particularly challenging task
due to the length and complexity of legal clauses and a shortage of
expert-annotated datasets. To address this challenge, we introduce the Merger
Agreement Understanding Dataset (MAUD), an expert-annotated reading
comprehension dataset based on the American Bar Association's 2021 Public
Target Deal Points Study, with over 39,000 examples and over 47,000 total
annotations. Our fine-tuned Transformer baselines show promising results, with
models performing well above random on most questions. However, on a large
subset of questions, there is still room for significant improvement. As the
only expert-annotated merger agreement dataset, MAUD is valuable as a benchmark
for both the legal profession and the NLP community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Political Polarisation using Language Models: A dataset and method. (arXiv:2301.00891v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.00891">
<div class="article-summary-box-inner">
<span><p>Our paper aims to analyze political polarization in US political system using
Language Models, and thereby help candidates make an informed decision. The
availability of this information will help voters understand their candidates
views on the economy, healthcare, education and other social issues. Our main
contributions are a dataset extracted from Wikipedia that spans the past 120
years and a Language model based method that helps analyze how polarized a
candidate is. Our data is divided into 2 parts, background information and
political information about a candidate, since our hypothesis is that the
political views of a candidate should be based on reason and be independent of
factors such as birthplace, alma mater, etc. We further split this data into 4
phases chronologically, to help understand if and how the polarization amongst
candidates changes. This data has been cleaned to remove biases. To understand
the polarization we begin by showing results from some classical language
models in Word2Vec and Doc2Vec. And then use more powerful techniques like the
Longformer, a transformer based encoder, to assimilate more information and
find the nearest neighbors of each candidate based on their political view and
their background.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EZInterviewer: To Improve Job Interview Performance with Mock Interview Generator. (arXiv:2301.00972v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.00972">
<div class="article-summary-box-inner">
<span><p>Interview has been regarded as one of the most crucial step for recruitment.
To fully prepare for the interview with the recruiters, job seekers usually
practice with mock interviews between each other. However, such a mock
interview with peers is generally far away from the real interview experience:
the mock interviewers are not guaranteed to be professional and are not likely
to behave like a real interviewer. Due to the rapid growth of online
recruitment in recent years, recruiters tend to have online interviews, which
makes it possible to collect real interview data from real interviewers. In
this paper, we propose a novel application named EZInterviewer, which aims to
learn from the online interview data and provides mock interview services to
the job seekers. The task is challenging in two ways: (1) the interview data
are now available but still of low-resource; (2) to generate meaningful and
relevant interview dialogs requires thorough understanding of both resumes and
job descriptions. To address the low-resource challenge, EZInterviewer is
trained on a very small set of interview dialogs. The key idea is to reduce the
number of parameters that rely on interview dialogs by disentangling the
knowledge selector and dialog generator so that most parameters can be trained
with ungrounded dialogs as well as the resume data that are not low-resource.
Evaluation results on a real-world job interview dialog dataset indicate that
we achieve promising results to generate mock interviews. With the help of
EZInterviewer, we hope to make mock interview practice become easier for job
seekers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analogical Inference Enhanced Knowledge Graph Embedding. (arXiv:2301.00982v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.00982">
<div class="article-summary-box-inner">
<span><p>Knowledge graph embedding (KGE), which maps entities and relations in a
knowledge graph into continuous vector spaces, has achieved great success in
predicting missing links in knowledge graphs. However, knowledge graphs often
contain incomplete triples that are difficult to inductively infer by KGEs. To
address this challenge, we resort to analogical inference and propose a novel
and general self-supervised framework AnKGE to enhance KGE models with
analogical inference capability. We propose an analogical object retriever that
retrieves appropriate analogical objects from entity-level, relation-level, and
triple-level. And in AnKGE, we train an analogy function for each level of
analogical inference with the original element embedding from a well-trained
KGE model as input, which outputs the analogical object embedding. In order to
combine inductive inference capability from the original KGE model and
analogical inference capability enhanced by AnKGE, we interpolate the analogy
score with the base model score and introduce the adaptive weights in the score
function for prediction. Through extensive experiments on FB15k-237 and WN18RR
datasets, we show that AnKGE achieves competitive results on link prediction
task and well performs analogical inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-Structured Object Sequence Encoders. (arXiv:2301.01015v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01015">
<div class="article-summary-box-inner">
<span><p>In this paper we explore the task of modeling (semi) structured object
sequences; in particular we focus our attention on the problem of developing a
structure-aware input representation for such sequences. In such sequences, we
assume that each structured object is represented by a set of key-value pairs
which encode the attributes of the structured object. Given a universe of keys,
a sequence of structured objects can then be viewed as an evolution of the
values for each key, over time. We encode and construct a sequential
representation using the values for a particular key (Temporal Value Modeling -
TVM) and then self-attend over the set of key-conditioned value sequences to a
create a representation of the structured object sequence (Key Aggregation -
KA). We pre-train and fine-tune the two components independently and present an
innovative training schedule that interleaves the training of both modules with
shared attention heads. We find that this iterative two part-training results
in better performance than a unified network with hierarchical encoding as well
as over, other methods that use a {\em record-view} representation of the
sequence \cite{de2021transformers4rec} or a simple {\em flattened}
representation of the sequence. We conduct experiments using real-world data to
demonstrate the advantage of interleaving TVM-KA on multiple tasks and detailed
ablation studies motivating our modeling choices. We find that our approach
performs better than flattening sequence objects and also allows us to operate
on significantly larger sequences than existing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Supervised Acoustic Embeddings And Their Transferability Across Languages. (arXiv:2301.01020v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01020">
<div class="article-summary-box-inner">
<span><p>In speech recognition, it is essential to model the phonetic content of the
input signal while discarding irrelevant factors such as speaker variations and
noise, which is challenging in low-resource settings. Self-supervised
pre-training has been proposed as a way to improve both supervised and
unsupervised speech recognition, including frame-level feature representations
and Acoustic Word Embeddings (AWE) for variable-length segments. However,
self-supervised models alone cannot learn perfect separation of the linguistic
content as they are trained to optimize indirect objectives. In this work, we
experiment with different pre-trained self-supervised features as input to AWE
models and show that they work best within a supervised framework. Models
trained on English can be transferred to other languages with no adaptation and
outperform self-supervised models trained solely on the target languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PIE-QG: Paraphrased Information Extraction for Unsupervised Question Generation from Small Corpora. (arXiv:2301.01064v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01064">
<div class="article-summary-box-inner">
<span><p>Supervised Question Answering systems (QA systems) rely on domain-specific
human-labeled data for training. Unsupervised QA systems generate their own
question-answer training pairs, typically using secondary knowledge sources to
achieve this outcome. Our approach (called PIE-QG) uses Open Information
Extraction (OpenIE) to generate synthetic training questions from paraphrased
passages and uses the question-answer pairs as training data for a language
model for a state-of-the-art QA system based on BERT. Triples in the form of
&lt;subject, predicate, object&gt; are extracted from each passage, and questions are
formed with subjects (or objects) and predicates while objects (or subjects)
are considered as answers. Experimenting on five extractive QA datasets
demonstrates that our technique achieves on-par performance with existing
state-of-the-art QA systems with the benefit of being trained on an order of
magnitude fewer documents and without any recourse to external reference data
sources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Knowledge-Intensive Text-to-SQL Semantic Parsing with Formulaic Knowledge. (arXiv:2301.01067v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01067">
<div class="article-summary-box-inner">
<span><p>In this paper, we study the problem of knowledge-intensive text-to-SQL, in
which domain knowledge is necessary to parse expert questions into SQL queries
over domain-specific tables. We formalize this scenario by building a new
Chinese benchmark KnowSQL consisting of domain-specific questions covering
various domains. We then address this problem by presenting formulaic
knowledge, rather than by annotating additional data examples. More concretely,
we construct a formulaic knowledge bank as a domain knowledge base and propose
a framework (ReGrouP) to leverage this formulaic knowledge during parsing.
Experiments using ReGrouP demonstrate a significant 28.2% improvement overall
on KnowSQL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ring That Bell: A Corpus and Method for Multimodal Metaphor Detection in Videos. (arXiv:2301.01134v1 [cs.MM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01134">
<div class="article-summary-box-inner">
<span><p>We present the first openly available multimodal metaphor annotated corpus.
The corpus consists of videos including audio and subtitles that have been
annotated by experts. Furthermore, we present a method for detecting metaphors
in the new dataset based on the textual content of the videos. The method
achieves a high F1-score (62\%) for metaphorical labels. We also experiment
with other modalities and multimodal methods; however, these methods did not
out-perform the text-based model. In our error analysis, we do identify that
there are cases where video could help in disambiguating metaphors, however,
the visual cues are too subtle for our model to capture. The data is available
on Zenodo.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models are Drummers: Drum Composition with Natural Language Pre-Training. (arXiv:2301.01162v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01162">
<div class="article-summary-box-inner">
<span><p>Automatic music generation with artificial intelligence typically requires a
large amount of data which is hard to obtain for many less common genres and
musical instruments. To tackle this issue, we present ongoing work and
preliminary findings on the possibility for deep models to transfer knowledge
from language to music, by finetuning large language models pre-trained on a
massive text corpus on only hundreds of MIDI files of drum performances. We
show that by doing so, one of the largest, state-of-the-art models (GPT3) is
capable of generating reasonable drum grooves, while models that are not
pre-trained (Transformer) shows no such ability beyond naive repetition.
Evaluating generated music is a challenging task, more so is evaluating drum
grooves with little precedence in literature. Hence, we propose a tailored
structural evaluation method and analyze drum grooves produced by GPT3 compared
to those played by human professionals, exposing the strengths and weaknesses
of such generation by language-to-music transfer. Our findings suggest that
language-to-music transfer learning with large language models is viable and
promising.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer Based Geocoding. (arXiv:2301.01170v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01170">
<div class="article-summary-box-inner">
<span><p>In this paper, we formulate the problem of predicting a geolocation from free
text as a sequence-to-sequence problem. Using this formulation, we obtain a
geocoding model by training a T5 encoder-decoder transformer model using free
text as an input and geolocation as an output. The geocoding model was trained
on geo-tagged wikidump data with adaptive cell partitioning for the geolocation
representation. All of the code including Rest-based application, dataset and
model checkpoints used in this work are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey On Few-shot Knowledge Graph Completion with Structural and Commonsense Knowledge. (arXiv:2301.01172v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01172">
<div class="article-summary-box-inner">
<span><p>Knowledge graphs (KG) have served as the key component of various natural
language processing applications. Commonsense knowledge graphs (CKG) are a
special type of KG, where entities and relations are composed of free-form
text. However, previous works in KG completion and CKG completion suffer from
long-tail relations and newly-added relations which do not have many know
triples for training. In light of this, few-shot KG completion (FKGC), which
requires the strengths of graph representation learning and few-shot learning,
has been proposed to challenge the problem of limited annotated data. In this
paper, we comprehensively survey previous attempts on such tasks in the form of
a series of methods and applications. Specifically, we first introduce FKGC
challenges, commonly used KGs, and CKGs. Then we systematically categorize and
summarize existing works in terms of the type of KGs and the methods. Finally,
we present applications of FKGC models on prediction tasks in different areas
and share our thoughts on future research directions of FKGC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models as Corporate Lobbyists. (arXiv:2301.01181v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01181">
<div class="article-summary-box-inner">
<span><p>We demonstrate a proof-of-concept of a large language model conducting
corporate lobbying related activities. We use an autoregressive large language
model (OpenAI's text-davinci-003) to determine if proposed U.S. Congressional
bills are relevant to specific public companies and provide explanations and
confidence levels. For the bills the model deems as relevant, the model drafts
a letter to the sponsor of the bill in an attempt to persuade the
congressperson to make changes to the proposed legislation. We use hundreds of
ground-truth labels of the relevance of a bill to a company to benchmark the
performance of the model, which outperforms the baseline of predicting the most
common outcome of irrelevance. However, we test the ability to determine the
relevance of a bill with the previous OpenAI GPT-3 model (text-davinci-002),
which was state-of-the-art on many language tasks until text-davinci-003 was
released on November 28, 2022. The performance of text-davinci-002 is worse
than simply always predicting that a bill is irrelevant to a company. These
results suggest that, as large language models continue to improve core natural
language understanding capabilities, performance on corporate lobbying related
tasks will continue to improve. We then discuss why this could be problematic
for societal-AI alignment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Average Is Not Enough: Caveats of Multilingual Evaluation. (arXiv:2301.01269v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01269">
<div class="article-summary-box-inner">
<span><p>This position paper discusses the problem of multilingual evaluation. Using
simple statistics, such as average language performance, might inject
linguistic biases in favor of dominant language families into evaluation
methodology. We argue that a qualitative analysis informed by comparative
linguistics is needed for multilingual results to detect this kind of bias. We
show in our case study that results in published works can indeed be
linguistically biased and we demonstrate that visualization based on URIEL
typological database can detect it.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey on Publicly Available Sinhala Natural Language Processing Tools and Research. (arXiv:1906.02358v15 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.02358">
<div class="article-summary-box-inner">
<span><p>Sinhala is the native language of the Sinhalese people who make up the
largest ethnic group of Sri Lanka. The language belongs to the globe-spanning
language tree, Indo-European. However, due to poverty in both linguistic and
economic capital, Sinhala, in the perspective of Natural Language Processing
tools and research, remains a resource-poor language which has neither the
economic drive its cousin English has nor the sheer push of the law of numbers
a language such as Chinese has. A number of research groups from Sri Lanka have
noticed this dearth and the resultant dire need for proper tools and research
for Sinhala natural language processing. However, due to various reasons, these
attempts seem to lack coordination and awareness of each other. The objective
of this paper is to fill that gap of a comprehensive literature survey of the
publicly available Sinhala natural language tools and research so that the
researchers working in this field can better utilize contributions of their
peers. As such, we shall be uploading this paper to arXiv and perpetually
update it periodically to reflect the advances made in the field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Objective Metric for Explainable AI: How and Why to Estimate the Degree of Explainability. (arXiv:2109.05327v4 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05327">
<div class="article-summary-box-inner">
<span><p>Explainable AI was born as a pathway to allow humans to explore and
understand the inner working of complex systems. But establishing what is an
explanation and objectively evaluating explainability, are not trivial tasks.
With this paper, we present a new model-agnostic metric to measure the Degree
of Explainability of information in an objective way, exploiting a specific
theoretical model from Ordinary Language Philosophy called the Achinstein's
Theory of Explanations, implemented with an algorithm relying on deep language
models for knowledge graph extraction and information retrieval. To understand
whether this metric is actually able to measure explainability, we devised a
few experiments and user studies involving more than 190 participants,
evaluating two realistic systems for healthcare and finance using famous AI
technology including Artificial Neural Networks and TreeSHAP. The results we
obtained are statistically significant (with p-values lower than .01),
suggesting that our proposed metric for measuring the Degree of Explainability
is robust on several scenarios and it aligns with concrete expectations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5). (arXiv:2203.13366v7 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.13366">
<div class="article-summary-box-inner">
<span><p>For a long time, different recommendation tasks typically require designing
task-specific architectures and training objectives. As a result, it is hard to
transfer the learned knowledge and representations from one task to another,
thus restricting the generalization ability of existing recommendation
approaches, e.g., a sequential recommendation model can hardly be applied or
transferred to a review generation method. To deal with such issues,
considering that language can describe almost anything and language grounding
is a powerful medium to represent various problems or tasks, we present a
flexible and unified text-to-text paradigm called "Pretrain, Personalized
Prompt, and Predict Paradigm" (P5) for recommendation, which unifies various
recommendation tasks in a shared framework. In P5, all data such as user-item
interactions, user descriptions, item metadata, and user reviews are converted
to a common format -- natural language sequences. The rich information from
natural language assists P5 to capture deeper semantics for personalization and
recommendation. Specifically, P5 learns different tasks with the same language
modeling objective during pretraining. Thus, it serves as the foundation model
for various downstream recommendation tasks, allows easy integration with other
modalities, and enables instruction-based recommendation based on prompts. P5
advances recommender systems from shallow model to deep model to big model, and
will revolutionize the technical form of recommender systems towards universal
recommendation engine. With adaptive personalized prompt for different users,
P5 is able to make predictions in a zero-shot or few-shot manner and largely
reduces the necessity for extensive fine-tuning. On several recommendation
benchmarks, we conduct experiments to show the effectiveness of P5. We release
the source code at https://github.com/jeykigung/P5.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StarGraph: Knowledge Representation Learning based on Incomplete Two-hop Subgraph. (arXiv:2205.14209v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.14209">
<div class="article-summary-box-inner">
<span><p>Conventional representation learning algorithms for knowledge graphs (KG) map
each entity to a unique embedding vector, ignoring the rich information
contained in the neighborhood. We propose a method named StarGraph, which gives
a novel way to utilize the neighborhood information for large-scale knowledge
graphs to obtain entity representations. An incomplete two-hop neighborhood
subgraph for each target node is at first generated, then processed by a
modified self-attention network to obtain the entity representation, which is
used to replace the entity embedding in conventional methods. We achieved SOTA
performance on ogbl-wikikg2 and got competitive results on fb15k-237. The
experimental results proves that StarGraph is efficient in parameters, and the
improvement made on ogbl-wikikg2 demonstrates its great effectiveness of
representation learning on large-scale knowledge graphs. The code is now
available at \url{https://github.com/hzli-ucas/StarGraph}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Self-Attention for Language Understanding. (arXiv:2206.12608v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12608">
<div class="article-summary-box-inner">
<span><p>Deep neural models (e.g. Transformer) naturally learn spurious features,
which create a ``shortcut'' between the labels and inputs, thus impairing the
generalization and robustness. This paper advances self-attention mechanism to
its robust variant for Transformer-based pre-trained language models (e.g.
BERT). We propose \textit{Adversarial Self-Attention} mechanism (ASA), which
adversarially biases the attentions to effectively suppress the model reliance
on features (e.g. specific keywords) and encourage its exploration of broader
semantics. We conduct comprehensive evaluation across a wide range of tasks for
both pre-training and fine-tuning stages. For pre-training, ASA unfolds
remarkable performance gain compared to naive training for longer steps. For
fine-tuning, ASA-empowered models outweigh naive models by a large margin
considering both generalization and robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Once-for-All Sequence Compression for Self-Supervised Speech Models. (arXiv:2211.02332v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.02332">
<div class="article-summary-box-inner">
<span><p>The sequence length along the time axis is often the dominant factor of the
computational cost of self-supervised speech models. Works have been proposed
to reduce the sequence length for lowering the computational cost. However,
different downstream tasks have different tolerance of sequence compressing, so
a model that produces a fixed compressing rate may not fit all tasks. In this
work, we introduce a once-for-all (OFA) sequence compression framework for
self-supervised speech models that supports a continuous range of compressing
rates. The framework is evaluated on various tasks, showing marginal
degradation compared to the fixed compressing rate variants with a smooth
performance-efficiency trade-off. We further explore adaptive compressing rate
learning, demonstrating the ability to select task-specific preferred frame
periods without needing a grid search.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-01-04 23:12:33.852972889 UTC">2023-01-04 23:12:33 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>