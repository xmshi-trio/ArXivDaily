<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-01-19T01:30:00Z">01-19</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning a Formality-Aware Japanese Sentence Representation. (arXiv:2301.07209v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07209">
<div class="article-summary-box-inner">
<span><p>While the way intermediate representations are generated in encoder-decoder
sequence-to-sequence models typically allow them to preserve the semantics of
the input sentence, input features such as formality might be left out. On the
other hand, downstream tasks such as translation would benefit from working
with a sentence representation that preserves formality in addition to
semantics, so as to generate sentences with the appropriate level of social
formality -- the difference between speaking to a friend versus speaking with a
supervisor. We propose a sequence-to-sequence method for learning a
formality-aware representation for Japanese sentences, where sentence
generation is conditioned on both the original representation of the input
sentence, and a side constraint which guides the sentence representation
towards preserving formality information. Additionally, we propose augmenting
the sentence representation with a learned representation of formality which
facilitates the extraction of formality in downstream tasks. We address the
lack of formality-annotated parallel data by adapting previous works on
procedural formality classification of Japanese sentences. Experimental results
suggest that our techniques not only helps the decoder recover the formality of
the input sentence, but also slightly improves the preservation of input
sentence semantics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Curriculum Script Distillation for Multilingual Visual Question Answering. (arXiv:2301.07227v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07227">
<div class="article-summary-box-inner">
<span><p>Pre-trained models with dual and cross encoders have shown remarkable success
in propelling the landscape of several tasks in vision and language in Visual
Question Answering (VQA). However, since they are limited by the requirements
of gold annotated data, most of these advancements do not see the light of day
in other languages beyond English. We aim to address this problem by
introducing a curriculum based on the source and target language translations
to finetune the pre-trained models for the downstream task. Experimental
results demonstrate that script plays a vital role in the performance of these
models. Specifically, we show that target languages that share the same script
perform better (~6%) than other languages and mixed-script code-switched
languages perform better than their counterparts (~5-12%).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adapting Multilingual Speech Representation Model for a New, Underresourced Language through Multilingual Fine-tuning and Continued Pretraining. (arXiv:2301.07295v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07295">
<div class="article-summary-box-inner">
<span><p>In recent years, neural models learned through self-supervised pretraining on
large scale multilingual text or speech data have exhibited promising results
for underresourced languages, especially when a relatively large amount of data
from related language(s) is available. While the technology has a potential for
facilitating tasks carried out in language documentation projects, such as
speech transcription, pretraining a multilingual model from scratch for every
new language would be highly impractical. We investigate the possibility for
adapting an existing multilingual wav2vec 2.0 model for a new language,
focusing on actual fieldwork data from a critically endangered tongue: Ainu.
Specifically, we (i) examine the feasibility of leveraging data from similar
languages also in fine-tuning; (ii) verify whether the model's performance can
be improved by further pretraining on target language data. Our results show
that continued pretraining is the most effective method to adapt a wav2vec 2.0
model for a new language and leads to considerable reduction in error rates.
Furthermore, we find that if a model pretrained on a related speech variety or
an unrelated language with similar phonological characteristics is available,
multilingual fine-tuning using additional data from that language can have
positive impact on speech recognition performance when there is very little
labeled data in the target language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KILDST: Effective Knowledge-Integrated Learning for Dialogue State Tracking using Gazetteer and Speaker Information. (arXiv:2301.07341v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07341">
<div class="article-summary-box-inner">
<span><p>Dialogue State Tracking (DST) is core research in dialogue systems and has
received much attention. In addition, it is necessary to define a new problem
that can deal with dialogue between users as a step toward the conversational
AI that extracts and recommends information from the dialogue between users.
So, we introduce a new task - DST from dialogue between users about scheduling
an event (DST-USERS). The DST-USERS task is much more challenging since it
requires the model to understand and track dialogue states in the dialogue
between users and to understand who suggested the schedule and who agreed to
the proposed schedule. To facilitate DST-USERS research, we develop dialogue
datasets between users that plan a schedule. The annotated slot values which
need to be extracted in the dialogue are date, time, and location. Previous
approaches, such as Machine Reading Comprehension (MRC) and traditional DST
techniques, have not achieved good results in our extensive evaluations. By
adopting the knowledge-integrated learning method, we achieve exceptional
results. The proposed model architecture combines gazetteer features and
speaker information efficiently. Our evaluations of the dialogue datasets
between users that plan a schedule show that our model outperforms the baseline
model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Newsbridge -Telecom SudParis VoxCeleb Speaker Recognition Challenge 2022 System Description. (arXiv:2301.07491v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07491">
<div class="article-summary-box-inner">
<span><p>We describe the system used by our team for the VoxCeleb Speaker Recognition
Challenge 2022 (VoxSRC 2022) in the speaker diarization track. Our solution was
designed around a new combination of voice activity detection algorithms that
uses the strengths of several systems. We introduce a novel multi stream
approach with a decision protocol based on classifiers entropy. We called this
method a multi-stream voice activity detection and used it with standard
baseline diarization embeddings, clustering and resegmentation. With this work,
we successfully demonstrated that using a strong baseline and working only on
voice activity detection, one can achieved close to state-of-theart results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graphix-T5: Mixing Pre-Trained Transformers with Graph-Aware Layers for Text-to-SQL Parsing. (arXiv:2301.07507v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07507">
<div class="article-summary-box-inner">
<span><p>The task of text-to-SQL parsing, which aims at converting natural language
questions into executable SQL queries, has garnered increasing attention in
recent years, as it can assist end users in efficiently extracting vital
information from databases without the need for technical background. One of
the major challenges in text-to-SQL parsing is domain generalization, i.e., how
to generalize well to unseen databases. Recently, the pre-trained text-to-text
transformer model, namely T5, though not specialized for text-to-SQL parsing,
has achieved state-of-the-art performance on standard benchmarks targeting
domain generalization. In this work, we explore ways to further augment the
pre-trained T5 model with specialized components for text-to-SQL parsing. Such
components are expected to introduce structural inductive bias into text-to-SQL
parsers thus improving model's capacity on (potentially multi-hop) reasoning,
which is critical for generating structure-rich SQLs. To this end, we propose a
new architecture GRAPHIX-T5, a mixed model with the standard pre-trained
transformer model augmented by some specially-designed graph-aware layers.
Extensive experiments and analysis demonstrate the effectiveness of GRAPHIX-T5
across four text-to-SQL benchmarks: SPIDER, SYN, REALISTIC and DK. GRAPHIX-T5
surpass all other T5-based parsers with a significant margin, achieving new
state-of-the-art performance. Notably, GRAPHIX-T5-large reach performance
superior to the original T5-large by 5.7% on exact match (EM) accuracy and 6.6%
on execution accuracy (EX). This even outperforms the T5-3B by 1.2% on EM and
1.5% on EX.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Quantitative Exploration of Natural Language Processing Applications for Electricity Demand Analysis. (arXiv:2301.07535v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07535">
<div class="article-summary-box-inner">
<span><p>The relationship between electricity demand and weather has been established
for a long time and is one of the cornerstones in load prediction for operation
and planning, along with behavioral and social aspects such as calendars or
significant events. This paper explores how and why the social information
contained in the news can be used better to understand aggregate population
behaviour in terms of energy demand. The work is done through experiments
analysing the impact of predicting features extracted from national news on
day-ahead electric demand prediction. The results are compared to a benchmark
model trained exclusively on the calendar and meteorological information.
Experimental results showed that the best-performing model reduced the official
standard errors around 4%, 11%, and 10% in terms of RMSE, MAE, and SMAPE. The
best-performing methods are: word frequency identified COVID-19-related
keywords; topic distribution that identified news on the pandemic and internal
politics; global word embeddings that identified news about international
conflicts. This study brings a new perspective to traditional electricity
demand analysis and confirms the feasibility of improving its predictions with
unstructured information contained in texts, with potential consequences in
sociology and economics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards a Holistic Understanding of Mathematical Questions with Contrastive Pre-training. (arXiv:2301.07558v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07558">
<div class="article-summary-box-inner">
<span><p>Understanding mathematical questions effectively is a crucial task, which can
benefit many applications, such as difficulty estimation. Researchers have
drawn much attention to designing pre-training models for question
representations due to the scarcity of human annotations (e.g., labeling
difficulty). However, unlike general free-format texts (e.g., user comments),
mathematical questions are generally designed with explicit purposes and
mathematical logic, and usually consist of more complex content, such as
formulas, and related mathematical knowledge (e.g., Function). Therefore, the
problem of holistically representing mathematical questions remains
underexplored. To this end, in this paper, we propose a novel contrastive
pre-training approach for mathematical question representations, namely QuesCo,
which attempts to bring questions with more similar purposes closer.
Specifically, we first design two-level question augmentations, including
content-level and structure-level, which generate literally diverse question
pairs with similar purposes. Then, to fully exploit hierarchical information of
knowledge concepts, we propose a knowledge hierarchy-aware rank strategy
(KHAR), which ranks the similarities between questions in a fine-grained
manner. Next, we adopt a ranking contrastive learning task to optimize our
model based on the augmented and ranked questions. We conduct extensive
experiments on two real-world mathematical datasets. The experimental results
demonstrate the effectiveness of our model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection. (arXiv:2301.07597v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07597">
<div class="article-summary-box-inner">
<span><p>The introduction of ChatGPT has garnered widespread attention in both
academic and industrial communities. ChatGPT is able to respond effectively to
a wide range of human questions, providing fluent and comprehensive answers
that significantly surpass previous public chatbots in terms of security and
usefulness. On one hand, people are curious about how ChatGPT is able to
achieve such strength and how far it is from human experts. On the other hand,
people are starting to worry about the potential negative impacts that large
language models (LLMs) like ChatGPT could have on society, such as fake news,
plagiarism, and social security issues. In this work, we collected tens of
thousands of comparison responses from both human experts and ChatGPT, with
questions ranging from open-domain, financial, medical, legal, and
psychological areas. We call the collected dataset the Human ChatGPT Comparison
Corpus (HC3). Based on the HC3 dataset, we study the characteristics of
ChatGPT's responses, the differences and gaps from human experts, and future
directions for LLMs. We conducted comprehensive human evaluations and
linguistic analyses of ChatGPT-generated content compared with that of humans,
where many interesting results are revealed. After that, we conduct extensive
experiments on how to effectively detect whether a certain text is generated by
ChatGPT or humans. We build three different detection systems, explore several
key factors that influence their effectiveness, and evaluate them in different
scenarios. The dataset, code, and models are all publicly available at
https://github.com/Hello-SimpleAI/chatgpt-comparison-detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EHRSQL: A Practical Text-to-SQL Benchmark for Electronic Health Records. (arXiv:2301.07695v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07695">
<div class="article-summary-box-inner">
<span><p>We present a new text-to-SQL dataset for electronic health records (EHRs).
The utterances were collected from 222 hospital staff, including physicians,
nurses, insurance review and health records teams, and more. To construct the
QA dataset on structured EHR data, we conducted a poll at a university hospital
and templatized the responses to create seed questions. Then, we manually
linked them to two open-source EHR databases, MIMIC-III and eICU, and included
them with various time expressions and held-out unanswerable questions in the
dataset, which were all collected from the poll. Our dataset poses a unique set
of challenges: the model needs to 1) generate SQL queries that reflect a wide
range of needs in the hospital, including simple retrieval and complex
operations such as calculating survival rate, 2) understand various time
expressions to answer time-sensitive questions in healthcare, and 3)
distinguish whether a given question is answerable or unanswerable based on the
prediction confidence. We believe our dataset, EHRSQL, could serve as a
practical benchmark to develop and assess QA models on structured EHR data and
take one step further towards bridging the gap between text-to-SQL research and
its real-life deployment in healthcare. EHRSQL is available at
https://github.com/glee4810/EHRSQL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controllable Neural Story Plot Generation via Reward Shaping. (arXiv:1809.10736v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1809.10736">
<div class="article-summary-box-inner">
<span><p>Language-modeling--based approaches to story plot generation attempt to
construct a plot by sampling from a language model (LM) to predict the next
character, word, or sentence to add to the story. LM techniques lack the
ability to receive guidance from the user to achieve a specific goal, resulting
in stories that don't have a clear sense of progression and lack coherence. We
present a reward-shaping technique that analyzes a story corpus and produces
intermediate rewards that are backpropagated into a pre-trained LM in order to
guide the model towards a given goal. Automated evaluations show our technique
can create a model that generates story plots which consistently achieve a
specified goal. Human-subject studies show that the generated stories have more
plausible event ordering than baseline plot generation techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Named Tensor Notation. (arXiv:2102.13196v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13196">
<div class="article-summary-box-inner">
<span><p>We propose a notation for tensors with named axes, which relieves the author,
reader, and future implementers of machine learning models from the burden of
keeping track of the order of axes and the purpose of each. The notation makes
it easy to lift operations on low-order tensors to higher order ones, for
example, from images to minibatches of images, or from an attention mechanism
to multiple attention heads.
</p>
<p>After a brief overview and formal definition of the notation, we illustrate
it through several examples from modern machine learning, from building blocks
like attention and convolution to full models like Transformers and LeNet. We
then discuss differential calculus in our notation and compare with some
alternative notations. Our proposals build on ideas from many previous papers
and software libraries. We hope that our notation will encourage more authors
to use named tensors, resulting in clearer papers and more precise
implementations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social Impact. (arXiv:2106.02359v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02359">
<div class="article-summary-box-inner">
<span><p>Recent years have seen many breakthroughs in natural language processing
(NLP), transitioning it from a mostly theoretical field to one with many
real-world applications. Noting the rising number of applications of other
machine learning and AI techniques with pervasive societal impact, we
anticipate the rising importance of developing NLP technologies for social
good. Inspired by theories in moral philosophy and global priorities research,
we aim to promote a guideline for social good in the context of NLP. We lay the
foundations via the moral philosophy definition of social good, propose a
framework to evaluate the direct and indirect real-world impact of NLP tasks,
and adopt the methodology of global priorities research to identify priority
causes for NLP research. Finally, we use our theoretical framework to provide
some practical guidelines for future NLP research for social good. Our data and
code are available at <a href="http://github.com/zhijing-jin/nlp4sg_acl2021.">this http URL</a> In
addition, we curate a list of papers and resources on NLP for social good at
https://github.com/zhijing-jin/NLP4SocialGood_Papers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Out-of-Distribution Performance on Document Image Classifiers. (arXiv:2210.07448v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07448">
<div class="article-summary-box-inner">
<span><p>The ability of a document classifier to handle inputs that are drawn from a
distribution different from the training distribution is crucial for robust
deployment and generalizability. The RVL-CDIP corpus is the de facto standard
benchmark for document classification, yet to our knowledge all studies that
use this corpus do not include evaluation on out-of-distribution documents. In
this paper, we curate and release a new out-of-distribution benchmark for
evaluating out-of-distribution performance for document classifiers. Our new
out-of-distribution benchmark consists of two types of documents: those that
are not part of any of the 16 in-domain RVL-CDIP categories (RVL-CDIP-O), and
those that are one of the 16 in-domain categories yet are drawn from a
distribution different from that of the original RVL-CDIP dataset (RVL-CDIP-N).
While prior work on document classification for in-domain RVL-CDIP documents
reports high accuracy scores, we find that these models exhibit accuracy drops
of between roughly 15-30% on our new out-of-domain RVL-CDIP-N benchmark, and
further struggle to distinguish between in-domain RVL-CDIP-N and out-of-domain
RVL-CDIP-O inputs. Our new benchmark provides researchers with a valuable new
resource for analyzing out-of-distribution performance on document classifiers.
Our new out-of-distribution data can be found at
https://github.com/gxlarson/rvl-cdip-ood.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teacher Forcing Recovers Reward Functions for Text Generation. (arXiv:2210.08708v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08708">
<div class="article-summary-box-inner">
<span><p>Reinforcement learning (RL) has been widely used in text generation to
alleviate the exposure bias issue or to utilize non-parallel datasets. The
reward function plays an important role in making RL training successful.
However, previous reward functions are typically task-specific and sparse,
restricting the use of RL. In our work, we propose a task-agnostic approach
that derives a step-wise reward function directly from a model trained with
teacher forcing. We additionally propose a simple modification to stabilize the
RL training on non-parallel datasets with our induced reward function.
Empirical results show that our method outperforms self-training and reward
regression methods on several text generation tasks, confirming the
effectiveness of our reward function.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Global Contrastive Batch Sampling via Optimization on Sample Permutations. (arXiv:2210.12874v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12874">
<div class="article-summary-box-inner">
<span><p>Contrastive Learning has recently achieved state-of-the-art performance in a
wide range of tasks. Many contrastive learning approaches use mined hard
negatives to make batches more informative during training but these approaches
are inefficient as they increase epoch length proportional to the number of
mined negatives and require frequent updates of nearest neighbor indices or
mining from recent batches. In this work, we provide an alternative to hard
negative mining, Global Contrastive Batch Sampling (GCBS), an efficient
approximation to the batch assignment problem that upper bounds the gap between
the global and training losses, $\mathcal{L}^{Global} - \mathcal{L}^{Train}$,
in contrastive learning settings. Through experimentation we find GCBS improves
state-of-the-art performance in sentence embedding and code-search tasks.
Additionally, GCBS is easy to implement as it requires only a few additional
lines of code, does not maintain external data structures such as nearest
neighbor indices, is more computationally efficient than the most minimal hard
negative mining approaches, and makes no changes to the model being trained.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InstructPix2Pix: Learning to Follow Image Editing Instructions. (arXiv:2211.09800v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09800">
<div class="article-summary-box-inner">
<span><p>We propose a method for editing images from human instructions: given an
input image and a written instruction that tells the model what to do, our
model follows these instructions to edit the image. To obtain training data for
this problem, we combine the knowledge of two large pretrained models -- a
language model (GPT-3) and a text-to-image model (Stable Diffusion) -- to
generate a large dataset of image editing examples. Our conditional diffusion
model, InstructPix2Pix, is trained on our generated data, and generalizes to
real images and user-written instructions at inference time. Since it performs
edits in the forward pass and does not require per example fine-tuning or
inversion, our model edits images quickly, in a matter of seconds. We show
compelling editing results for a diverse collection of input images and written
instructions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Programming by Example and Text-to-Code Translation for Conversational Code Generation. (arXiv:2211.11554v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.11554">
<div class="article-summary-box-inner">
<span><p>Dialogue systems is an increasingly popular task of natural language
processing. However, the dialogue paths tend to be deterministic, restricted to
the system rails, regardless of the given request or input text. Recent
advances in program synthesis have led to systems which can synthesize programs
from very general search spaces, e.g. Programming by Example, and to systems
with very accessible interfaces for writing programs, e.g. text-to-code
translation, but have not achieved both of these qualities in the same system.
We propose Modular Programs for Text-guided Hierarchical Synthesis (MPaTHS), a
method for integrating Programming by Example and text-to-code systems which
offers an accessible natural language interface for synthesizing general
programs. We present a program representation that allows our method to be
applied to the problem of task-oriented dialogue. Finally, we demo MPaTHS using
our program representation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topic Modelling of Swedish Newspaper Articles about Coronavirus: a Case Study using Latent Dirichlet Allocation Method. (arXiv:2301.03029v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.03029">
<div class="article-summary-box-inner">
<span><p>Topic Modelling (TM) is from the research branches of natural language
understanding (NLU) and natural language processing (NLP) that is to facilitate
insightful analysis from large documents and datasets, such as a summarisation
of main topics and the topic changes. This kind of discovery is getting more
popular in real-life applications due to its impact on big data analytics. In
this study, from the social-media and healthcare domain, we apply popular
Latent Dirichlet Allocation (LDA) methods to model the topic changes in Swedish
newspaper articles about Coronavirus. We describe the corpus we created
including 6515 articles, methods applied, and statistics on topic changes over
approximately 1 year and two months period of time from 17th January 2020 to
13th March 2021. We hope this work can be an asset for grounding applications
of topic modelling and can be inspiring for similar case studies in an era with
pandemics, to support socio-economic impact research as well as clinical and
healthcare analytics. Our data and source code are openly available at
https://github. com/poethan/Swed_Covid_TM Keywords: Latent Dirichlet Allocation
(LDA); Topic Modelling; Coronavirus; Pandemics; Natural Language Understanding
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompting Large Language Model for Machine Translation: A Case Study. (arXiv:2301.07069v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07069">
<div class="article-summary-box-inner">
<span><p>Research on prompting has shown excellent performance with little or even no
supervised training across many tasks. However, prompting for machine
translation is still under-explored in the literature. We fill this gap by
offering a systematic study on prompting strategies for translation, examining
various factors for prompt template and demonstration example selection. We
further explore the use of monolingual data and the feasibility of
cross-lingual, cross-domain, and sentence-to-document transfer learning in
prompting. Extensive experiments with GLM-130B (Zeng et al., 2022) as the
testbed show that 1) the number and the quality of prompt examples matter,
where using suboptimal examples degenerates translation; 2) several features of
prompt examples, such as semantic similarity, show significant Spearman
correlation with their prompting performance; yet, none of the correlations are
strong enough; 3) using pseudo parallel prompt examples constructed from
monolingual data via zero-shot prompting could improve translation; and 4)
improved performance is achievable by transferring knowledge from prompt
examples selected in other settings. We finally provide an analysis on the
model outputs and discuss several problems that prompting still suffers from.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-01-19 23:13:29.508321440 UTC">2023-01-19 23:13:29 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>