<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-10-17T01:30:00Z">10-17</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">SODAPOP: Open-Ended Discovery of Social Biases in Social Commonsense Reasoning Models. (arXiv:2210.07269v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07269">
<div class="article-summary-box-inner">
<span><p>A common limitation of diagnostic tests for detecting social biases in NLP
models is that they may only detect stereotypic associations that are
pre-specified by the designer of the test. Since enumerating all possible
problematic associations is infeasible, it is likely these tests fail to detect
biases that are present in a model but not pre-specified by the designer. To
address this limitation, we propose SODAPOP (SOcial bias Discovery from Answers
about PeOPle) in social commonsense question-answering. Our pipeline generates
modified instances from the Social IQa dataset (Sap et al., 2019) by (1)
substituting names associated with different demographic groups, and (2)
generating many distractor answers from a masked language model. By using a
social commonsense model to score the generated distractors, we are able to
uncover the model's stereotypic associations between demographic groups and an
open set of words. We also test SODAPOP on debiased models and show the
limitations of multiple state-of-the-art debiasing algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Task Learning for Joint Semantic Role and Proto-Role Labeling. (arXiv:2210.07270v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07270">
<div class="article-summary-box-inner">
<span><p>We put forward an end-to-end multi-step machine learning model which jointly
labels semantic roles and the proto-roles of Dowty (1991), given a sentence and
the predicates therein. Our best architecture first learns argument spans
followed by learning the argument's syntactic heads. This information is shared
with the next steps for predicting the semantic roles and proto-roles. We also
experiment with transfer learning from argument and head prediction to role and
proto-role labeling. We compare using static and contextual embeddings for
words, arguments, and sentences. Unlike previous work, our model does not
require pre-training or fine-tuning on additional tasks, beyond using
off-the-shelf (static or contextual) embeddings and supervision. It also does
not require argument spans, their semantic roles, and/or their gold syntactic
heads as additional input, because it learns to predict all these during
training. Our multi-task learning model raises the state-of-the-art predictions
for most proto-roles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Reasoning on Hybrid-knowledge sources for Task-Oriented Dialog. (arXiv:2210.07295v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07295">
<div class="article-summary-box-inner">
<span><p>Traditional systems designed for task oriented dialog utilize knowledge
present only in structured knowledge sources to generate responses. However,
relevant information required to generate responses may also reside in
unstructured sources, such as documents. Recent state of the art models such as
HyKnow and SeKnow aimed at overcoming these challenges make limiting
assumptions about the knowledge sources. For instance, these systems assume
that certain types of information, such as a phone number, is always present in
a structured KB while information about aspects such as entrance ticket prices
would always be available in documents.
</p>
<p>In this paper, we create a modified version of the MutliWOZ based dataset
prepared by SeKnow to demonstrate how current methods have significant
degradation in performance when strict assumptions about the source of
information are removed. Then, in line with recent work exploiting pre-trained
language models, we fine-tune a BART based model using prompts for the tasks of
querying knowledge sources, as well as, for response generation, without making
assumptions about the information present in each knowledge source. Through a
series of experiments, we demonstrate that our model is robust to perturbations
to knowledge modality (source of information), and that it can fuse information
from structured as well as unstructured knowledge to generate responses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bootstrapping Multilingual Semantic Parsers using Large Language Models. (arXiv:2210.07313v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07313">
<div class="article-summary-box-inner">
<span><p>Despite cross-lingual generalization demonstrated by pre-trained multilingual
models, the translate-train paradigm of transferring English datasets across
multiple languages remains to be the key ingredient for training task-specific
multilingual models. However, for many low-resource languages, the availability
of a reliable translation service entails significant amounts of costly
human-annotated translation pairs. Further, the translation services for
low-resource languages may continue to be brittle due to domain mismatch
between the task-specific input text and the general-purpose text used while
training the translation models. We consider the task of multilingual semantic
parsing and demonstrate the effectiveness and flexibility offered by large
language models (LLMs) for translating English datasets into several languages
via few-shot prompting. We provide (i) Extensive comparisons with prior
translate-train methods across 50 languages demonstrating that LLMs can serve
as highly effective data translators, outperforming prior translation based
methods on 40 out of 50 languages; (ii) A comprehensive study of the key design
choices that enable effective data translation via prompted LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MTEB: Massive Text Embedding Benchmark. (arXiv:2210.07316v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07316">
<div class="article-summary-box-inner">
<span><p>Text embeddings are commonly evaluated on a small set of datasets from a
single task not covering their possible applications to other tasks. It is
unclear whether state-of-the-art embeddings on semantic textual similarity
(STS) can be equally well applied to other tasks like clustering or reranking.
This makes progress in the field difficult to track, as various models are
constantly being proposed without proper evaluation. To solve this problem, we
introduce the Massive Text Embedding Benchmark (MTEB). MTEB spans 8 embedding
tasks covering a total of 56 datasets and 112 languages. Through the
benchmarking of 33 models on MTEB, we establish the most comprehensive
benchmark of text embeddings to date. We find that no particular text embedding
method dominates across all tasks. This suggests that the field has yet to
converge on a universal text embedding method and scale it up sufficiently to
provide state-of-the-art results on all embedding tasks. MTEB comes with
open-source code and a public leaderboard at
https://huggingface.co/spaces/mteb/leaderboard.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods. (arXiv:2210.07321v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07321">
<div class="article-summary-box-inner">
<span><p>Advances in natural language generation (NLG) have resulted in machine
generated text that is increasingly difficult to distinguish from human
authored text. Powerful open-source models are freely available, and
user-friendly tools democratizing access to generative models are
proliferating. The great potential of state-of-the-art NLG systems is tempered
by the multitude of avenues for abuse. Detection of machine generated text is a
key countermeasure for reducing abuse of NLG models, with significant technical
challenges and numerous open problems. We provide a survey that includes both
1) an extensive analysis of threat models posed by contemporary NLG systems,
and 2) the most complete review of machine generated text detection methods to
date. This survey places machine generated text within its cybersecurity and
social context, and provides strong guidance for future work addressing the
most critical threat models, and ensuring detection systems themselves
demonstrate trustworthiness through fairness, robustness, and accountability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HuBERT-TR: Reviving Turkish Automatic Speech Recognition with Self-supervised Speech Representation Learning. (arXiv:2210.07323v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07323">
<div class="article-summary-box-inner">
<span><p>While the Turkish language is listed among low-resource languages, literature
on Turkish automatic speech recognition (ASR) is relatively old. In this paper,
we present HuBERT-TR, a speech representation model for Turkish based on
HuBERT. HuBERT-TR achieves state-of-the-art results on several Turkish ASR
datasets. We investigate pre-training HuBERT for Turkish with large-scale data
curated from online resources. We pre-train HuBERT-TR using over 6,500 hours of
speech data curated from YouTube that includes extensive variability in terms
of quality and genre. We show that pre-trained models within a multi-lingual
setup are inferior to language-specific models, where our Turkish model
HuBERT-TR base performs better than its x10 times larger multi-lingual
counterpart XLS-R-1B. Moreover, we study the effect of scaling on ASR
performance by scaling our models up to 1B parameters. Our best model yields a
state-of-the-art word error rate of 4.97% on the Turkish Broadcast News
dataset. Models are available at huggingface.co/asafaya .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting Fine-Tuning Performance with Probing. (arXiv:2210.07352v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07352">
<div class="article-summary-box-inner">
<span><p>Large NLP models have recently shown impressive performance in language
understanding tasks, typically evaluated by their fine-tuned performance.
Alternatively, probing has received increasing attention as being a lightweight
method for interpreting the intrinsic mechanisms of large NLP models. In
probing, post-hoc classifiers are trained on "out-of-domain" datasets that
diagnose specific abilities. While probing the language models has led to
insightful findings, they appear disjointed from the development of models.
This paper explores the utility of probing deep NLP models to extract a proxy
signal widely used in model development -- the fine-tuning performance. We find
that it is possible to use the accuracies of only three probing tests to
predict the fine-tuning performance with errors $40\%$ - $80\%$ smaller than
baselines. We further discuss possible avenues where probing can empower the
development of deep NLP models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">JOIST: A Joint Speech and Text Streaming Model For ASR. (arXiv:2210.07353v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07353">
<div class="article-summary-box-inner">
<span><p>We present JOIST, an algorithm to train a streaming, cascaded, encoder
end-to-end (E2E) model with both speech-text paired inputs, and text-only
unpaired inputs. Unlike previous works, we explore joint training with both
modalities, rather than pre-training and fine-tuning. In addition, we explore
JOIST using a streaming E2E model with an order of magnitude more data, which
are also novelties compared to previous works. Through a series of ablation
studies, we explore different types of text modeling, including how to model
the length of the text sequence and the appropriate text sub-word unit
representation. We find that best text representation for JOIST improves WER
across a variety of search and rare-word test sets by 4-14% relative, compared
to a model not trained with text. In addition, we quantitatively show that
JOIST maintains streaming capabilities, which is important for good user-level
experience.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Demographic Factors Improve Text Classification? Revisiting Demographic Adaptation in the Age of Transformers. (arXiv:2210.07362v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07362">
<div class="article-summary-box-inner">
<span><p>Demographic factors (e.g., gender or age) shape our language. Previous work
showed that incorporating demographic factors can consistently improve
performance for various NLP tasks with traditional NLP models. In this work, we
investigate whether these previous findings still hold with state-of-the-art
pretrained Transformer-based language models (PLMs). We use three common
specialization methods proven effective for incorporating external knowledge
into pretrained Transformers (e.g., domain-specific or geographic knowledge).
We adapt the language representations for the demographic dimensions of gender
and age, using continuous language modeling and dynamic multi-task learning for
adaptation, where we couple language modeling objectives with the prediction of
demographic classes. Our results when employing a multilingual PLM show
substantial performance gains across four languages (English, German, French,
and Danish), which is consistent with the results of previous work. However,
controlling for confounding factors -- primarily domain and language
proficiency of Transformer-based PLMs -- shows that downstream performance
gains from our demographic adaptation do not actually stem from demographic
knowledge. Our results indicate that demographic specialization of PLMs, while
holding promise for positive societal impact, still represents an unsolved
problem for (modern) NLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is It Worth the (Environmental) Cost? Limited Evidence for the Benefits of Diachronic Continuous Training. (arXiv:2210.07365v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07365">
<div class="article-summary-box-inner">
<span><p>Language is constantly changing and evolving, leaving language models to
quickly become outdated, both factually and linguistically. Recent research
proposes we continuously update our models using new data. Continuous training
allows us to teach language models about new events and facts and changing
norms. However, continuous training also means continuous costs. We show there
is currently limited evidence for the benefits of continuous training, be it
for the actual downstream performance or the environmental cost. Our results
show continuous training does not significantly improve performance. While it
is clear that, sooner or later, our language models need to be updated, it is
unclear when this effort is worth the cost. We call for a critical reflection
about when and how to use continuous training and for more benchmarks to
support this research direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">M2D2: A Massively Multi-domain Language Modeling Dataset. (arXiv:2210.07370v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07370">
<div class="article-summary-box-inner">
<span><p>We present M2D2, a fine-grained, massively multi-domain corpus for studying
domain adaptation in language models (LMs). M2D2 consists of 8.5B tokens and
spans 145 domains extracted from Wikipedia and Semantic Scholar. Using
ontologies derived from Wikipedia and ArXiv categories, we organize the domains
in each data source into 22 groups. This two-level hierarchy enables the study
of relationships between domains and their effects on in- and out-of-domain
performance after adaptation. We also present a number of insights into the
nature of effective domain adaptation in LMs, as examples of the new types of
studies M2D2 enables. To improve in-domain performance, we show the benefits of
adapting the LM along a domain hierarchy; adapting to smaller amounts of
fine-grained domain-specific data can lead to larger in-domain performance
gains than larger amounts of weakly relevant data. We further demonstrate a
trade-off between in-domain specialization and out-of-domain generalization
within and across ontologies, as well as a strong correlation between
out-of-domain performance and lexical overlap between domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mind the Labels: Describing Relations in Knowledge Graphs With Pretrained Models. (arXiv:2210.07373v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07373">
<div class="article-summary-box-inner">
<span><p>Pretrained language models (PLMs) for data-to-text (D2T) generation can use
human-readable data labels such as column headings, keys, or relation names to
generalize to out-of-domain examples. However, the models are well-known in
producing semantically inaccurate outputs if these labels are ambiguous or
incomplete, which is often the case in D2T datasets. In this paper, we expose
this issue on the task of descibing a relation between two entities. For our
experiments, we collect a novel dataset for verbalizing a diverse set of 1,522
unique relations from three large-scale knowledge graphs (Wikidata, DBPedia,
YAGO). We find that although PLMs for D2T generation expectedly fail on unclear
cases, models trained with a large variety of relation labels are surprisingly
robust in verbalizing novel, unseen relations. We argue that using data with a
diverse set of clear and meaningful labels is key to training D2T generation
systems capable of generalizing to novel domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Frustratingly Easy Sentiment Analysis of Text Streams: Generating High-Quality Emotion Arcs Using Emotion Lexicons. (arXiv:2210.07381v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07381">
<div class="article-summary-box-inner">
<span><p>Automatically generated emotion arcs -- that capture how an individual or a
population feels over time -- are widely used in industry and research.
However, there is little work on evaluating the generated arcs. This is in part
due to the difficulty of establishing the true (gold) emotion arc. Our work,
for the first time, systematically and quantitatively evaluates automatically
generated emotion arcs. We also compare two common ways of generating emotion
arcs: Machine-Learning (ML) models and Lexicon-Only (LexO) methods. Using a
number of diverse datasets, we systematically study the relationship between
the quality of an emotion lexicon and the quality of the emotion arc that can
be generated with it. We also study the relationship between the quality of an
instance-level emotion detection system (say from an ML model) and the quality
of emotion arcs that can be generated with it. We show that despite being
markedly poor at instance level, LexO methods are highly accurate at generating
emotion arcs by aggregating information from hundreds of instances. This has
wide-spread implications for commercial development, as well as research in
psychology, public health, digital humanities, etc. that values simple
interpretable methods and disprefers the need for domain-specific training
data, programming expertise, and high-carbon-footprint models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Behavior Cloned Transformers are Neurosymbolic Reasoners. (arXiv:2210.07382v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07382">
<div class="article-summary-box-inner">
<span><p>In this work, we explore techniques for augmenting interactive agents with
information from symbolic modules, much like humans use tools like calculators
and GPS systems to assist with arithmetic and navigation. We test our agent's
abilities in text games -- challenging benchmarks for evaluating the multi-step
reasoning abilities of game agents in grounded, language-based environments.
Our experimental study indicates that injecting the actions from these symbolic
modules into the action space of a behavior cloned transformer agent increases
performance on four text game benchmarks that test arithmetic, navigation,
sorting, and common sense reasoning by an average of 22%, allowing an agent to
reach the highest possible performance on unseen games. This action injection
technique is easily extended to new agents, environments, and symbolic modules.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Early Discovery of Disappearing Entities in Microblogs. (arXiv:2210.07404v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07404">
<div class="article-summary-box-inner">
<span><p>We make decisions by reacting to changes in the real world, in particular,
the emergence and disappearance of impermanent entities such as events,
restaurants, and services. Because we want to avoid missing out on
opportunities or making fruitless actions after they have disappeared, it is
important to know when entities disappear as early as possible. We thus tackle
the task of detecting disappearing entities from microblogs, whose posts
mention various entities, in a timely manner. The major challenge is detecting
uncertain contexts of disappearing entities from noisy microblog posts. To
collect these disappearing contexts, we design time-sensitive distant
supervision, which utilizes entities from the knowledge base and time-series
posts, for this task to build large-scale Twitter datasets\footnote{We will
release the datasets (tweet IDs) used in the experiments to promote
reproducibility.} for English and Japanese. To ensure robust detection in noisy
environments, we refine pretrained word embeddings of the detection model on
microblog streams of the target day. Experimental results on the Twitter
datasets confirmed the effectiveness of the collected labeled data and refined
word embeddings; more than 70\% of the detected disappearing entities in
Wikipedia are discovered earlier than the update on Wikipedia, and the average
lead-time is over one month.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Noise Audits Improve Moral Foundation Classification. (arXiv:2210.07415v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07415">
<div class="article-summary-box-inner">
<span><p>Morality plays an important role in culture, identity, and emotion. Recent
advances in natural language processing have shown that it is possible to
classify moral values expressed in text at scale. Morality classification
relies on human annotators to label the moral expressions in text, which
provides training data to achieve state-of-the-art performance. However, these
annotations are inherently subjective and some of the instances are hard to
classify, resulting in noisy annotations due to error or lack of agreement. The
presence of noise in training data harms the classifier's ability to accurately
recognize moral foundations from text. We propose two metrics to audit the
noise of annotations. The first metric is entropy of instance labels, which is
a proxy measure of annotator disagreement about how the instance should be
labeled. The second metric is the silhouette coefficient of a label assigned by
an annotator to an instance. This metric leverages the idea that instances with
the same label should have similar latent representations, and deviations from
collective judgments are indicative of errors. Our experiments on three widely
used moral foundations datasets show that removing noisy annotations based on
the proposed metrics improves classification performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PCFG-based Natural Language Interface Improves Generalization for Controlled Text Generation. (arXiv:2210.07431v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07431">
<div class="article-summary-box-inner">
<span><p>Existing work on controlled text generation (CTG) assumes a control interface
of categorical attributes. In this work, we propose a natural language (NL)
interface, where we craft a PCFG to embed the control attributes into natural
language commands, and propose variants of existing CTG models that take
commands as input. In our experiments, we design tailored setups to test
model's generalization abilities. We find our PCFG-based command generation
approach is effective for handling unseen commands compared to fix-set
templates; our proposed NL models can effectively generalize to unseen
attributes, a new ability enabled by the NL interface, as well as unseen
attribute combinations. Interestingly, we discover that the simple conditional
generation approach, enhanced with our proposed NL interface, is a strong
baseline in those challenging settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InterFair: Debiasing with Natural Language Feedback for Fair Interpretable Predictions. (arXiv:2210.07440v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07440">
<div class="article-summary-box-inner">
<span><p>Debiasing methods in NLP models traditionally focus on isolating information
related to a sensitive attribute (like gender or race). We instead argue that a
favorable debiasing method should use sensitive information 'fairly,' with
explanations, rather than blindly eliminating it. This fair balance is often
subjective and can be challenging to achieve algorithmically. We show that an
interactive setup with users enabled to provide feedback can achieve a better
and fair balance between task performance and bias mitigation, supported by
faithful explanations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Word Sense Disambiguation with Unified Sense Representation. (arXiv:2210.07447v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07447">
<div class="article-summary-box-inner">
<span><p>As a key natural language processing (NLP) task, word sense disambiguation
(WSD) evaluates how well NLP models can understand the lexical semantics of
words under specific contexts. Benefited from the large-scale annotation,
current WSD systems have achieved impressive performances in English by
combining supervised learning with lexical knowledge. However, such success is
hard to be replicated in other languages, where we only have limited
annotations.In this paper, based on the multilingual lexicon BabelNet
describing the same set of concepts across languages, we propose building
knowledge and supervised-based Multilingual Word Sense Disambiguation (MWSD)
systems. We build unified sense representations for multiple languages and
address the annotation scarcity problem for MWSD by transferring annotations
from rich-sourced languages to poorer ones. With the unified sense
representations, annotations from multiple languages can be jointly trained to
benefit the MWSD tasks. Evaluations of SemEval-13 and SemEval-15 datasets
demonstrate the effectiveness of our methodology.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Out-of-Distribution Performance on Document Image Classifiers. (arXiv:2210.07448v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07448">
<div class="article-summary-box-inner">
<span><p>The ability of a document classifier to handle inputs that are drawn from a
distribution different from the training distribution is crucial for robust
deployment and generalizability. The RVL-CDIP corpus is the de facto standard
benchmark for document classification, yet to our knowledge all studies that
use this corpus do not include evaluation on out-of-distribution documents. In
this paper, we curate and release a new out-of-distribution benchmark for
evaluating out-of-distribution performance for document classifiers. Our new
out-of-distribution benchmark consists of two types of documents: those that
are not part of any of the 16 in-domain RVL-CDIP categories (RVL-CDIP-O), and
those that are one of the 16 in-domain categories yet are drawn from a
distribution different from that of the original RVL-CDIP dataset (RVL-CDIP-N).
While prior work on document classification for in-domain RVL-CDIP documents
reports high accuracy scores, we find that these models exhibit accuracy drops
of between roughly 15-30% on our new out-of-domain RVL-CDIP-N benchmark, and
further struggle to distinguish between in-domain RVL-CDIP-N and out-of-domain
RVL-CDIP-O inputs. Our new benchmark provides researchers with a valuable new
resource for analyzing out-of-distribution performance on document classifiers.
Our new out-of-distribution data can be found at https://tinyurl.com/4he6my23.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controlling Bias Exposure for Fair Interpretable Predictions. (arXiv:2210.07455v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07455">
<div class="article-summary-box-inner">
<span><p>Recent work on reducing bias in NLP models usually focuses on protecting or
isolating information related to a sensitive attribute (like gender or race).
However, when sensitive information is semantically entangled with the task
information of the input, e.g., the gender information is predictive for a
profession, a fair trade-off between task performance and bias mitigation is
difficult to achieve. Existing approaches perform this trade-off by eliminating
bias information from the latent space, lacking control over how much bias is
necessarily required to be removed. We argue that a favorable debiasing method
should use sensitive information 'fairly' rather than blindly eliminating it
(Caliskan et al., 2017; Sun et al., 2019). In this work, we provide a novel
debiasing algorithm by adjusting the predictive model's belief to (1) ignore
the sensitive information if it is not useful for the task; (2) use sensitive
information minimally as necessary for the prediction (while also incurring a
penalty). Experimental results on two text classification tasks (influenced by
gender) and an open-ended generation task (influenced by race) indicate that
our model achieves a desirable trade-off between debiasing and task performance
along with producing debiased rationales as evidence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptable Claim Rewriting with Offline Reinforcement Learning for Effective Misinformation Discovery. (arXiv:2210.07467v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07467">
<div class="article-summary-box-inner">
<span><p>We propose a novel system to help fact-checkers formulate search queries for
known misinformation claims and effectively search across multiple social media
platforms. We introduce an adaptable rewriting strategy, where editing actions
(e.g., swap a word with its synonym; change verb tense into present simple) for
queries containing claims are automatically learned through offline
reinforcement learning. Specifically, we use a decision transformer to learn a
sequence of editing actions that maximize query retrieval metrics such as mean
average precision. Through several experiments, we show that our approach can
increase the effectiveness of the queries by up to 42\% relatively, while
producing editing action sequences that are human readable, thus making the
system easy to use and explain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transparency Helps Reveal When Language Models Learn Meaning. (arXiv:2210.07468v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07468">
<div class="article-summary-box-inner">
<span><p>Many current NLP systems are built from language models trained to optimize
unsupervised objectives on large amounts of raw text. Under what conditions
might such a procedure acquire meaning? Our systematic experiments with
synthetic data reveal that, with languages where all expressions have
context-independent denotations (i.e., languages with strong transparency),
both autoregressive and masked language models successfully learn to emulate
semantic relations between expressions. However, when denotations are changed
to be context-dependent with the language otherwise unmodified, this ability
degrades. Turning to natural language, our experiments with a specific
phenomenon -- referential opacity -- add to the growing body of evidence that
current language models do not well-represent natural language semantics. We
show this failure relates to the context-dependent nature of natural language
form-meaning mappings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StyLEx: Explaining Styles with Lexicon-Based Human Perception. (arXiv:2210.07469v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07469">
<div class="article-summary-box-inner">
<span><p>Style plays a significant role in how humans express themselves and
communicate with others. Large pre-trained language models produce impressive
results on various style classification tasks. However, they often learn
spurious domain-specific words to make predictions. This incorrect word
importance learned by the model often leads to ambiguous token-level
explanations which do not align with human perception of linguistic styles. To
tackle this challenge, we introduce StyLEx, a model that learns annotated human
perceptions of stylistic lexica and uses these stylistic words as additional
information for predicting the style of a sentence. Our experiments show that
StyLEx can provide human-like stylistic lexical explanations without
sacrificing the performance of sentence-level style prediction on both original
and out-of-domain datasets. Explanations from StyLEx show higher sufficiency,
and plausibility when compared to human annotations, and are also more
understandable by human judges compared to the existing widely-used saliency
baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"John is 50 years old, can his son be 65?" Evaluating NLP Models' Understanding of Feasibility. (arXiv:2210.07471v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07471">
<div class="article-summary-box-inner">
<span><p>In current NLP research, large-scale language models and their abilities are
widely being discussed. Some recent works have also found notable failures of
these models. Often these failure examples involve complex reasoning abilities.
This work focuses on a simple commonsense ability, reasoning about when an
action (or its effect) is feasible. We introduce FeasibilityQA, a
question-answering dataset involving binary classification (BCQ) and
multi-choice multi-correct questions (MCQ) that test understanding of
feasibility. We show that even state-of-the-art models such as GPT-3 struggle
to answer the feasibility questions correctly. Specifically, on (MCQ, BCQ)
questions, GPT-3 achieves accuracy of just (19%, 62%) and (25%, 64%) in
zero-shot and few-shot settings, respectively. We also evaluate models by
providing relevant knowledge statements required to answer the question and
find that the additional knowledge leads to a 7% gain in performance, but the
overall performance still remains low. These results make one wonder how much
commonsense knowledge about action feasibility is encoded in GPT-3 and how well
the model can reason about it.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Candidate Generation for Entity Linking on Short Social Media Texts. (arXiv:2210.07472v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07472">
<div class="article-summary-box-inner">
<span><p>Entity Linking (EL) is the gateway into Knowledge Bases. Recent advances in
EL utilize dense retrieval approaches for Candidate Generation, which addresses
some of the shortcomings of the Lookup based approach of matching NER mentions
against pre-computed dictionaries. In this work, we show that in the domain of
Tweets, such methods suffer as users often include informal spelling, limited
context, and lack of specificity, among other issues. We investigate these
challenges on a large and recent Tweets benchmark for EL, empirically evaluate
lookup and dense retrieval approaches, and demonstrate a hybrid solution using
long contextual representation from Wikipedia is necessary to achieve
considerable gains over previous work, achieving 0.93 recall.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SQA3D: Situated Question Answering in 3D Scenes. (arXiv:2210.07474v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07474">
<div class="article-summary-box-inner">
<span><p>We propose a new task to benchmark scene understanding of embodied agents:
Situated Question Answering in 3D Scenes (SQA3D). Given a scene context (e.g.,
3D scan), SQA3D requires the tested agent to first understand its situation
(position, orientation, etc.) in the 3D scene as described by text, then reason
about its surrounding environment and answer a question under that situation.
Based upon 650 scenes from ScanNet, we provide a dataset centered around 6.8k
unique situations, along with 20.4k descriptions and 33.4k diverse reasoning
questions for these situations. These questions examine a wide spectrum of
reasoning capabilities for an intelligent agent, ranging from spatial relation
comprehension to commonsense understanding, navigation, and multi-hop
reasoning. SQA3D imposes a significant challenge to current multi-modal
especially 3D reasoning models. We evaluate various state-of-the-art approaches
and find that the best one only achieves an overall score of 47.20%, while
amateur human participants can reach 90.06%. We believe SQA3D could facilitate
future embodied AI research with stronger situation understanding and reasoning
capability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Holistic Sentence Embeddings for Better Out-of-Distribution Detection. (arXiv:2210.07485v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07485">
<div class="article-summary-box-inner">
<span><p>Detecting out-of-distribution (OOD) instances is significant for the safe
deployment of NLP models. Among recent textual OOD detection works based on
pretrained language models (PLMs), distance-based methods have shown superior
performance. However, they estimate sample distance scores in the last-layer
CLS embedding space and thus do not make full use of linguistic information
underlying in PLMs. To address the issue, we propose to boost OOD detection by
deriving more holistic sentence embeddings. On the basis of the observations
that token averaging and layer combination contribute to improving OOD
detection, we propose a simple embedding approach named Avg-Avg, which averages
all token representations from each intermediate layer as the sentence
embedding and significantly surpasses the state-of-the-art on a comprehensive
suite of benchmarks by a 9.33% FAR95 margin. Furthermore, our analysis
demonstrates that it indeed helps preserve general linguistic knowledge in
fine-tuned PLMs and substantially benefits detecting background shifts. The
simple yet effective embedding method can be applied to fine-tuned PLMs with
negligible extra costs, providing a free gain in OOD detection. Our code is
available at https://github.com/lancopku/Avg-Avg.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MetaFill: Text Infilling for Meta-Path Generation on Heterogeneous Information Networks. (arXiv:2210.07488v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07488">
<div class="article-summary-box-inner">
<span><p>Heterogeneous Information Network (HIN) is essential to study complicated
networks containing multiple edge types and node types. Meta-path, a sequence
of node types and edge types, is the core technique to embed HINs. Since
manually curating meta-paths is time-consuming, there is a pressing need to
develop automated meta-path generation approaches. Existing meta-path
generation approaches cannot fully exploit the rich textual information in
HINs, such as node names and edge type names. To address this problem, we
propose MetaFill, a text-infilling-based approach for meta-path generation. The
key idea of MetaFill is to formulate meta-path identification problem as a word
sequence infilling problem, which can be advanced by Pretrained Language Models
(PLMs). We observed the superior performance of MetaFill against existing
meta-path generation methods and graph embedding methods that do not leverage
meta-paths in both link prediction and node classification on two real-world
HIN datasets. We further demonstrated how MetaFill can accurately classify
edges in the zero-shot setting, where existing approaches cannot generate any
meta-paths. MetaFill exploits PLMs to generate meta-paths for graph embedding,
opening up new avenues for language model applications in graph analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Psychology-guided Controllable Story Generation. (arXiv:2210.07493v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07493">
<div class="article-summary-box-inner">
<span><p>Controllable story generation is a challenging task in the field of NLP,
which has attracted increasing research interest in recent years. However, most
existing works generate a whole story conditioned on the appointed keywords or
emotions, ignoring the psychological changes of the protagonist. Inspired by
psychology theories, we introduce global psychological state chains, which
include the needs and emotions of the protagonists, to help a story generation
system create more controllable and well-planned stories. In this paper, we
propose a Psychology-guIded Controllable Story Generation System (PICS) to
generate stories that adhere to the given leading context and desired
psychological state chains for the protagonist. Specifically, psychological
state trackers are employed to memorize the protagonist's local psychological
states to capture their inner temporal relationships. In addition,
psychological state planners are adopted to gain the protagonist's global
psychological states for story planning. Eventually, a psychology controller is
designed to integrate the local and global psychological states into the story
context representation for composing psychology-guided stories. Automatic and
manual evaluations demonstrate that PICS outperforms baselines, and each part
of PICS shows effectiveness for writing stories with more consistent
psychological changes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bayes risk CTC: Controllable CTC alignment in Sequence-to-Sequence tasks. (arXiv:2210.07499v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07499">
<div class="article-summary-box-inner">
<span><p>Sequence-to-Sequence (seq2seq) tasks transcribe the input sequence to a
target sequence. The Connectionist Temporal Classification (CTC) criterion is
widely used in multiple seq2seq tasks. Besides predicting the target sequence,
a side product of CTC is to predict the alignment, which is the most probable
input-long sequence that specifies a hard aligning relationship between the
input and target units. As there are multiple potential aligning sequences
(called paths) that are equally considered in CTC formulation, the choice of
which path will be most probable and become the predicted alignment is always
uncertain. In addition, it is usually observed that the alignment predicted by
vanilla CTC will drift compared with its reference and rarely provides
practical functionalities. Thus, the motivation of this work is to make the CTC
alignment prediction controllable and thus equip CTC with extra
functionalities. The Bayes risk CTC (BRCTC) criterion is then proposed in this
work, in which a customizable Bayes risk function is adopted to enforce the
desired characteristics of the predicted alignment. With the risk function, the
BRCTC is a general framework to adopt some customizable preference over the
paths in order to concentrate the posterior into a particular subset of the
paths. In applications, we explore one particular preference which yields
models with the down-sampling ability and reduced inference costs. By using
BRCTC with another preference for early emissions, we obtain an improved
performance-latency trade-off for online models. Experimentally, the proposed
BRCTC reduces the inference cost of offline models by up to 47% without
performance degradation and cuts down the overall latency of online systems to
an unseen level.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Language Representation Models Think in Bets?. (arXiv:2210.07519v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07519">
<div class="article-summary-box-inner">
<span><p>In recent years, transformer-based language representation models (LRMs) have
achieved state-of-the-art results on difficult natural language understanding
problems, such as question answering and text summarization. As these models
are integrated into real-world applications, evaluating their ability to make
rational decisions is an important research agenda, with practical
ramifications. This article investigates LRMs' rational decision-making ability
through a carefully designed set of decision-making benchmarks and experiments.
Inspired by classic work in cognitive science, we model the decision-making
problem as a bet. We then investigate an LRM's ability to choose outcomes that
have optimal, or at minimum, positive expected gain. Through a robust body of
experiments on four established LRMs, we show that a model is only able to
`think in bets' if it is first fine-tuned on bet questions with an identical
structure. Modifying the bet question's structure, while still retaining its
fundamental characteristics, decreases an LRM's performance by more than 25\%,
on average, although absolute performance remains well above random. LRMs are
also found to be more rational when selecting outcomes with non-negative
expected gain, rather than optimal or strictly positive expected gain. Our
results suggest that LRMs could potentially be applied to tasks that rely on
cognitive decision-making skills, but that more research is necessary before
they can robustly make rational decisions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Adaptive Named Entity Recognition by Retrieving Unstructured Knowledge. (arXiv:2210.07523v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07523">
<div class="article-summary-box-inner">
<span><p>Although named entity recognition (NER) helps us to extract various
domain-specific entities from text (e.g., artists in the music domain), it is
costly to create a large amount of training data or a structured knowledge base
to perform accurate NER in the target domain. Here, we propose self-adaptive
NER, where the model retrieves the external knowledge from unstructured text to
learn the usage of entities that has not been learned well. To retrieve useful
knowledge for NER, we design an effective two-stage model that retrieves
unstructured knowledge using uncertain entities as queries. Our model first
predicts the entities in the input and then finds the entities of which the
prediction is not confident. Then, our model retrieves knowledge by using these
uncertain entities as queries and concatenates the retrieved text to the
original input to revise the prediction. Experiments on CrossNER datasets
demonstrated that our model outperforms the strong NERBERT baseline by 2.45
points on average.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AutoMoE: Neural Architecture Search for Efficient Sparsely Activated Transformers. (arXiv:2210.07535v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07535">
<div class="article-summary-box-inner">
<span><p>Neural architecture search (NAS) has demonstrated promising results on
identifying efficient Transformer architectures which outperform manually
designed ones for natural language tasks like neural machine translation (NMT).
Existing NAS methods operate on a space of dense architectures, where all of
the sub-architecture weights are activated for every input. Motivated by the
recent advances in sparsely activated models like the Mixture-of-Experts (MoE)
model, we introduce sparse architectures with conditional computation into the
NAS search space. Given this expressive search space which subsumes prior
densely activated architectures, we develop a new framework AutoMoE to search
for efficient sparsely activated sub-Transformers. AutoMoE-generated sparse
models obtain (i) 3x FLOPs reduction over manually designed dense Transformers
and (ii) 23% FLOPs reduction over state-of-the-art NAS-generated dense
sub-Transformers with parity in BLEU score on benchmark datasets for NMT.
AutoMoE consists of three training phases: (a) Heterogeneous search space
design with dense and sparsely activated Transformer modules (e.g., how many
experts? where to place them? what should be their sizes?); (b) SuperNet
training that jointly trains several subnetworks sampled from the large search
space by weight-sharing; (c) Evolutionary search for the architecture with the
optimal trade-off between task performance and computational constraint like
FLOPs and latency. AutoMoE code, data and trained models are available at
https://github.com/microsoft/AutoMoE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The User-Aware Arabic Gender Rewriter. (arXiv:2210.07538v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07538">
<div class="article-summary-box-inner">
<span><p>We introduce the User-Aware Arabic Gender Rewriter, a user-centric web-based
system for Arabic gender rewriting in contexts involving two users. The system
takes either Arabic or English sentences as input, and provides users with the
ability to specify their desired first and/or second person target genders. The
system outputs gender rewritten alternatives of the Arabic input sentences (or
their Arabic translations in case of English input) to match the target users'
gender preferences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Watermarking Pre-trained Language Models with Backdooring. (arXiv:2210.07543v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07543">
<div class="article-summary-box-inner">
<span><p>Large pre-trained language models (PLMs) have proven to be a crucial
component of modern natural language processing systems. PLMs typically need to
be fine-tuned on task-specific downstream datasets, which makes it hard to
claim the ownership of PLMs and protect the developer's intellectual property
due to the catastrophic forgetting phenomenon. We show that PLMs can be
watermarked with a multi-task learning framework by embedding backdoors
triggered by specific inputs defined by the owners, and those watermarks are
hard to remove even though the watermarked PLMs are fine-tuned on multiple
downstream tasks. In addition to using some rare words as triggers, we also
show that the combination of common words can be used as backdoor triggers to
avoid them being easily detected. Extensive experiments on multiple datasets
demonstrate that the embedded watermarks can be robustly extracted with a high
success rate and less influenced by the follow-up fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Legal Case Document Summarization: Extractive and Abstractive Methods and their Evaluation. (arXiv:2210.07544v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07544">
<div class="article-summary-box-inner">
<span><p>Summarization of legal case judgement documents is a challenging problem in
Legal NLP. However, not much analyses exist on how different families of
summarization models (e.g., extractive vs. abstractive) perform when applied to
legal case documents. This question is particularly important since many recent
transformer-based abstractive summarization models have restrictions on the
number of input tokens, and legal documents are known to be very long. Also, it
is an open question on how best to evaluate legal case document summarization
systems. In this paper, we carry out extensive experiments with several
extractive and abstractive summarization methods (both supervised and
unsupervised) over three legal summarization datasets that we have developed.
Our analyses, that includes evaluation by law practitioners, lead to several
interesting insights on legal summarization in specific and long document
summarization in general.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Kernel-Whitening: Overcome Dataset Bias with Isotropic Sentence Embedding. (arXiv:2210.07547v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07547">
<div class="article-summary-box-inner">
<span><p>Dataset bias has attracted increasing attention recently for its detrimental
effect on the generalization ability of fine-tuned models. The current
mainstream solution is designing an additional shallow model to pre-identify
biased instances. However, such two-stage methods scale up the computational
complexity of training process and obstruct valid feature information while
mitigating bias. To address this issue, we utilize the representation
normalization method which aims at disentangling the correlations between
features of encoded sentences. We find it also promising in eliminating the
bias problem by providing isotropic data distribution. We further propose
Kernel-Whitening, a Nystrom kernel approximation method to achieve more
thorough debiasing on nonlinear spurious correlations. Our framework is
end-to-end with similar time consumption to fine-tuning. Experiments show that
Kernel-Whitening significantly improves the performance of BERT on
out-of-distribution datasets while maintaining in-distribution accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DyLoRA: Parameter Efficient Tuning of Pre-trained Models using Dynamic Search-Free Low-Rank Adaptation. (arXiv:2210.07558v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07558">
<div class="article-summary-box-inner">
<span><p>With the ever-growing size of pre-trained models (PMs), fine-tuning them has
become more expensive and resource-hungry. As a remedy, low-rank adapters
(LoRA) keep the main pre-trained weights of the model frozen and just introduce
some learnable truncated SVD modules (so-called LoRA blocks) to the model.
While LoRA blocks are parameter efficient, they suffer from two major problems:
first, the size of these blocks is fixed and cannot be modified after training
(for example, if we need to change the rank of LoRA blocks, then we need to
re-train them from scratch); second, optimizing their rank requires an
exhaustive search and effort. In this work, we introduce a dynamic low-rank
adaptation (DyLoRA) technique to address these two problems together. Our
DyLoRA method trains LoRA blocks for a range of ranks instead of a single rank
by sorting out the representation learned by the adapter module at different
ranks during training. We evaluate our solution on different tasks of the GLUE
benchmark using the RoBERTa model. Our results show that we can train dynamic
search-free models with DyLoRA at least $7\times$ faster than LoRA without
significantly compromising performance. Moreover, our models can perform
consistently well on a much larger range of ranks compared to LoRA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Empirical Study Incorporating Linguistic Knowledge on Filled Pauses for Personalized Spontaneous Speech Synthesis. (arXiv:2210.07559v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07559">
<div class="article-summary-box-inner">
<span><p>We present a comprehensive empirical study for personalized spontaneous
speech synthesis on the basis of linguistic knowledge. With the advent of voice
cloning for reading-style speech synthesis, a new voice cloning paradigm for
human-like and spontaneous speech synthesis is required. We, therefore, focus
on personalized spontaneous speech synthesis that can clone both the
individual's voice timbre and speech disfluency. Specifically, we deal with
filled pauses, a major source of speech disfluency, which is known to play an
important role in speech generation and communication in psychology and
linguistics. To comparatively evaluate personalized filled pause insertion and
non-personalized filled pause prediction methods, we developed a speech
synthesis method with a non-personalized external filled pause predictor
trained with a multi-speaker corpus. The results clarify the position-word
entanglement of filled pauses, i.e., the necessity of precisely predicting
positions for naturalness and the necessity of precisely predicting words for
individuality on the evaluation of synthesized speech.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Q-TOD: A Query-driven Task-oriented Dialogue System. (arXiv:2210.07564v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07564">
<div class="article-summary-box-inner">
<span><p>Existing pipelined task-oriented dialogue systems usually have difficulties
adapting to unseen domains, whereas end-to-end systems are plagued by
large-scale knowledge bases in practice. In this paper, we introduce a novel
query-driven task-oriented dialogue system, namely Q-TOD. The essential
information from the dialogue context is extracted into a query, which is
further employed to retrieve relevant knowledge records for response
generation. Firstly, as the query is in the form of natural language and not
confined to the schema of the knowledge base, the issue of domain adaption is
alleviated remarkably in Q-TOD. Secondly, as the query enables the decoupling
of knowledge retrieval from the generation, Q-TOD gets rid of the issue of
knowledge base scalability. To evaluate the effectiveness of the proposed
Q-TOD, we collect query annotations for three publicly available task-oriented
dialogue datasets. Comprehensive experiments verify that Q-TOD outperforms
strong baselines and establishes a new state-of-the-art performance on these
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Task Pre-Training of Modular Prompt for Few-Shot Learning. (arXiv:2210.07565v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07565">
<div class="article-summary-box-inner">
<span><p>Prompt tuning is a parameter-efficient approach to adapting pre-trained
language models to downstream tasks. Although prompt tuning has been shown to
match the performance of full model tuning when training data is sufficient, it
tends to struggle in few-shot learning settings. In this paper, we present
Multi-task Pre-trained Modular Prompt (MP2) to boost prompt tuning for few-shot
learning. MP2 is a set of combinable prompts pre-trained on 38 Chinese tasks.
On downstream tasks, the pre-trained prompts are selectively activated and
combined, leading to strong compositional generalization to unseen tasks. To
bridge the gap between pre-training and fine-tuning, we formulate upstream and
downstream tasks into a unified machine reading comprehension task. Extensive
experiments under two learning paradigms, i.e., gradient descent and black-box
tuning, show that MP2 significantly outperforms prompt tuning, full model
tuning, and prior prompt pre-training methods in few-shot settings. In
addition, we demonstrate that MP2 can achieve surprisingly fast and strong
adaptation to downstream tasks by merely learning 8 parameters to combine the
pre-trained modular prompts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Parameters Associated with the Quality of Benchmarks in NLP. (arXiv:2210.07566v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07566">
<div class="article-summary-box-inner">
<span><p>Several benchmarks have been built with heavy investment in resources to
track our progress in NLP. Thousands of papers published in response to those
benchmarks have competed to top leaderboards, with models often surpassing
human performance. However, recent studies have shown that models triumph over
several popular benchmarks just by overfitting on spurious biases, without
truly learning the desired task. Despite this finding, benchmarking, while
trying to tackle bias, still relies on workarounds, which do not fully utilize
the resources invested in benchmark creation, due to the discarding of low
quality data, and cover limited sets of bias. A potential solution to these
issues -- a metric quantifying quality -- remains underexplored. Inspired by
successful quality indices in several domains such as power, food, and water,
we take the first step towards a metric by identifying certain language
properties that can represent various possible interactions leading to biases
in a benchmark. We look for bias related parameters which can potentially help
pave our way towards the metric. We survey existing works and identify
parameters capturing various properties of bias, their origins, types and
impact on performance, generalization, and robustness. Our analysis spans over
datasets and a hierarchy of tasks ranging from NLI to Summarization, ensuring
that our parameters are generic and are not overfitted towards a specific task
or dataset. We also develop certain parameters in this process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MICO: A Multi-alternative Contrastive Learning Framework for Commonsense Knowledge Representation. (arXiv:2210.07570v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07570">
<div class="article-summary-box-inner">
<span><p>Commonsense reasoning tasks such as commonsense knowledge graph completion
and commonsense question answering require powerful representation learning. In
this paper, we propose to learn commonsense knowledge representation by MICO, a
Multi-alternative contrastve learning framework on COmmonsense knowledge graphs
(MICO). MICO generates the commonsense knowledge representation by contextual
interaction between entity nodes and relations with multi-alternative
contrastive learning. In MICO, the head and tail entities in an $(h,r,t)$
knowledge triple are converted to two relation-aware sequence pairs (a premise
and an alternative) in the form of natural language. Semantic representations
generated by MICO can benefit the following two tasks by simply comparing the
distance score between the representations: 1) zero-shot commonsense question
answering task; 2) inductive commonsense knowledge graph completion task.
Extensive experiments show the effectiveness of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Creation of Named Entity Recognition Datasets by Querying Phrase Representations. (arXiv:2210.07586v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07586">
<div class="article-summary-box-inner">
<span><p>Most weakly supervised named entity recognition (NER) models rely on
domain-specific dictionaries provided by experts. This approach is infeasible
in many domains where dictionaries do not exist. While a phrase retrieval model
was used to construct pseudo-dictionaries with entities retrieved from
Wikipedia automatically in a recent study, these dictionaries often have
limited coverage because the retriever is likely to retrieve popular entities
rather than rare ones. In this study, a phrase embedding search to efficiently
create high-coverage dictionaries is presented. Specifically, the reformulation
of natural language queries into phrase representations allows the retriever to
search a space densely populated with various entities. In addition, we present
a novel framework, HighGEN, that generates NER datasets with high-coverage
dictionaries obtained using the phrase embedding search. HighGEN generates weak
labels based on the distance between the embeddings of a candidate phrase and
target entity type to reduce the noise in high-coverage dictionaries. We
compare HighGEN with current weakly supervised NER models on six NER benchmarks
and demonstrate the superiority of our models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConEntail: An Entailment-based Framework for Universal Zero and Few Shot Classification with Supervised Contrastive Pretraining. (arXiv:2210.07587v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07587">
<div class="article-summary-box-inner">
<span><p>A universal classification model aims to generalize to diverse classification
tasks in both zero and few shot settings. A promising way toward universal
classification is to cast heterogeneous data formats into a dataset-agnostic
"meta-task" (e.g., textual entailment, question answering) then pretrain a
model on the combined meta dataset. The existing work is either pretrained on
specific subsets of classification tasks, or pretrained on both classification
and generation data but the model could not fulfill its potential in
universality and reliability. These also leave a massive amount of annotated
data under-exploited. To fill these gaps, we propose ConEntail, a new framework
for universal zero and few shot classification with supervised contrastive
pretraining. Our unified meta-task for classification is based on nested
entailment. It can be interpreted as "Does sentence a entails [sentence b
entails label c]". This formulation enables us to make better use of 57
annotated classification datasets for supervised contrastive pretraining and
universal evaluation. In this way, ConEntail helps the model (1) absorb
knowledge from different datasets, and (2) gain consistent performance gain
with more pretraining data. In experiments, we compare our model with
discriminative and generative models pretrained on the same dataset. The
results confirm that our framework effectively exploits existing annotated data
and consistently outperforms baselines in both zero (9.4% average improvement)
and few shot settings (3.5% average improvement).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The State of Profanity Obfuscation in Natural Language Processing. (arXiv:2210.07595v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07595">
<div class="article-summary-box-inner">
<span><p>Work on hate speech has made the consideration of rude and harmful examples
in scientific publications inevitable. This raises various problems, such as
whether or not to obscure profanities. While science must accurately disclose
what it does, the unwarranted spread of hate speech is harmful to readers, and
increases its internet frequency. While maintaining publications' professional
appearance, obfuscating profanities makes it challenging to evaluate the
content, especially for non-native speakers. Surveying 150 ACL papers, we
discovered that obfuscation is usually employed for English but not other
languages, and even so quite uneven. We discuss the problems with obfuscation
and suggest a multilingual community resource called PrOf that has a Python
module to standardize profanity obfuscation processes. We believe PrOf can help
scientific publication policies to make hate speech work accessible and
comparable, irrespective of language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mention Annotations Alone Enable Efficient Domain Adaptation for Coreference Resolution. (arXiv:2210.07602v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07602">
<div class="article-summary-box-inner">
<span><p>Although, recent advances in neural network models for coreference resolution
have led to substantial improvements on benchmark datasets, it remains a
challenge to successfully transfer those models to new target domains
containing many out-of-vocabulary spans and requiring differing annotation
schemes. Typical approaches for domain adaptation involve continued training on
coreference annotations in the target domain, but obtaining those annotations
is costly and time-consuming. In this work, we show that adapting mention
detection is the key component to successful domain adaptation of coreference
models, rather than antecedent linking. Through timed annotation experiments,
we also show annotating mentions alone is nearly twice as fast as annotating
full coreference chains. Based on these insights, we propose a method for
effectively adapting coreference models that requires only mention annotations
in the target domain. We use an auxiliary mention detection objective trained
with mention examples in the target domain resulting in higher mention
precision. We demonstrate that our approach facilitates sample- and
time-efficient transfer to new annotation schemes and lexicons in extensive
evaluation across three English coreference datasets: CoNLL-2012
(news/conversation), i2b2/VA (medical case notes), and a dataset of child
welfare case notes. We show that annotating mentions results in 7-14%
improvement in average F1 over annotating coreference over an equivalent amount
of time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dense-ATOMIC: Construction of Densely-connected and Multi-hop Commonsense Knowledge Graph upon ATOMIC. (arXiv:2210.07621v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07621">
<div class="article-summary-box-inner">
<span><p>ATOMIC is a large-scale commonsense knowledge graph (CSKG) containing
everyday if-then knowledge triplets, i.e., {head event, relation, tail event}.
The one-hop annotation manner made ATOMIC a set of independent bipartite
graphs, which ignored the numerous missing links between events in different
bipartite graphs and consequently caused shortcomings in knowledge coverage and
multi-hop reasoning. To address these issues, we propose a CSKG completion
approach by training a relation prediction model based on a set of existing
triplets, and infer the missing links on ATOMIC. On this basis, we construct
Dense-ATOMIC, a densely-connected and multi-hop commonsense knowledge graph.
The experimental results on an annotated dense subgraph demonstrate the
effectiveness of our CSKG completion approach upon ATOMIC. The evaluation on a
downstream commonsense reasoning task also proves the advantage of Dense-ATOMIC
against conventional ATOMIC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for Text Generation. (arXiv:2210.07626v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07626">
<div class="article-summary-box-inner">
<span><p>Automatic evaluation metrics are crucial to the development of generative
systems. In recent years, pre-trained language model (PLM) based metrics, such
as BERTScore, have been commonly adopted in various generation tasks. However,
it has been demonstrated that PLMs encode a range of stereotypical societal
biases, leading to a concern on the fairness of PLMs as metrics. To that end,
this work presents the first systematic study on the social bias in PLM-based
metrics. We demonstrate that popular PLM-based metrics exhibit significantly
higher social bias than traditional metrics on 6 sensitive attributes, namely
race, gender, religion, physical appearance, age, and socioeconomic status.
In-depth analysis suggests that choosing paradigms (matching, regression, or
generation) of the metric has a greater impact on fairness than choosing PLMs.
In addition, we develop debiasing adapters that are injected into PLM layers,
mitigating bias in PLM-based metrics while retaining high performance for
evaluating text generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hardness of Samples Need to be Quantified for a Reliable Evaluation System: Exploring Potential Opportunities with a New Task. (arXiv:2210.07631v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07631">
<div class="article-summary-box-inner">
<span><p>Evaluation of models on benchmarks is unreliable without knowing the degree
of sample hardness; this subsequently overestimates the capability of AI
systems and limits their adoption in real world applications. We propose a Data
Scoring task that requires assignment of each unannotated sample in a benchmark
a score between 0 to 1, where 0 signifies easy and 1 signifies hard. Use of
unannotated samples in our task design is inspired from humans who can
determine a question difficulty without knowing its correct answer. This also
rules out the use of methods involving model based supervision (since they
require sample annotations to get trained), eliminating potential biases
associated with models in deciding sample difficulty. We propose a method based
on Semantic Textual Similarity (STS) for this task; we validate our method by
showing that existing models are more accurate with respect to the easier
sample-chunks than with respect to the harder sample-chunks. Finally we
demonstrate five novel applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training speech emotion classifier without categorical annotations. (arXiv:2210.07642v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07642">
<div class="article-summary-box-inner">
<span><p>There are two paradigms of emotion representation, categorical labeling and
dimensional description in continuous space. Therefore, the emotion recognition
task can be treated as a classification or regression. The main aim of this
study is to investigate the relation between these two representations and
propose a classification pipeline that uses only dimensional annotation. The
proposed approach contains a regressor model which is trained to predict a
vector of continuous values in dimensional representation for given speech
audio. The output of this model can be interpreted as an emotional category
using a mapping algorithm. We investigated the performances of a combination of
three feature extractors, three neural network architectures, and three mapping
algorithms on two different corpora. Our study shows the advantages and
limitations of the classification via regression approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enabling Classifiers to Make Judgements Explicitly Aligned with Human Values. (arXiv:2210.07652v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07652">
<div class="article-summary-box-inner">
<span><p>Many NLP classification tasks, such as sexism/racism detection or toxicity
detection, are based on human values. Yet, human values can vary under diverse
cultural conditions. Therefore, we introduce a framework for value-aligned
classification that performs prediction based on explicitly written human
values in the command. Along with the task, we propose a practical approach
that distills value-aligned knowledge from large-scale language models (LLMs)
to construct value-aligned classifiers in two steps. First, we generate
value-aligned training data from LLMs by prompt-based few-shot learning. Next,
we fine-tune smaller classification models with the generated data for the
task. Empirical results show that our VA-Models surpass multiple baselines by
at least 15.56% on the F1-score, including few-shot learning with OPT-175B and
existing text augmentation methods. We suggest that using classifiers with
explicit human value input improves both inclusivity &amp; explainability in AI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pretrained Transformers Do not Always Improve Robustness. (arXiv:2210.07663v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07663">
<div class="article-summary-box-inner">
<span><p>Pretrained Transformers (PT) have been shown to improve Out of Distribution
(OOD) robustness than traditional models such as Bag of Words (BOW), LSTMs,
Convolutional Neural Networks (CNN) powered by Word2Vec and Glove embeddings.
How does the robustness comparison hold in a real world setting where some part
of the dataset can be noisy? Do PT also provide more robust representation than
traditional models on exposure to noisy data? We perform a comparative study on
10 models and find an empirical evidence that PT provide less robust
representation than traditional models on exposure to noisy data. We
investigate further and augment PT with an adversarial filtering (AF) mechanism
that has been shown to improve OOD generalization. However, increase in
generalization does not necessarily increase robustness, as we find that noisy
data fools the AF method powered by PT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Plausible May Not Be Faithful: Probing Object Hallucination in Vision-Language Pre-training. (arXiv:2210.07688v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07688">
<div class="article-summary-box-inner">
<span><p>Large-scale vision-language pre-trained (VLP) models are prone to hallucinate
non-existent visual objects when generating text based on visual information.
In this paper, we exhaustively probe the object hallucination problem from
three aspects. First, we examine various state-of-the-art VLP models, showing
that models achieving better scores on standard metrics(e.g., BLEU-4, CIDEr)
could hallucinate objects more frequently. Second, we investigate how different
types of visual features in VLP influence hallucination, including
region-based, grid-based, and patch-based. Surprisingly, we find that
patch-based features perform the best and smaller patch resolution yields a
non-trivial reduction in object hallucination. Third, we decouple various VLP
objectives and demonstrate their effectiveness in alleviating object
hallucination. Based on that, we propose a new pre-training loss, object masked
language modeling, to further reduce object hallucination. We evaluate models
on both COCO (in-domain) and NoCaps (out-of-domain) datasets with our improved
CHAIR metric. Furthermore, we investigate the effects of various text decoding
strategies and image augmentation methods on object hallucination.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Generation Models Can Cause Harm: So What Can We Do About It? An Actionable Survey. (arXiv:2210.07700v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07700">
<div class="article-summary-box-inner">
<span><p>Recent advances in the capacity of large language models to generate
human-like text have resulted in their increased adoption in user-facing
settings. In parallel, these improvements have prompted a heated discourse
around the risks of societal harms they introduce, whether inadvertent or
malicious. Several studies have identified potential causes of these harms and
called for their mitigation via development of safer and fairer models. Going
beyond enumerating the risks of harms, this work provides a survey of practical
methods for addressing potential threats and societal harms from language
generation models. We draw on several prior works' taxonomies of language model
risks to present a structured overview of strategies for detecting and
ameliorating different kinds of risks/harms of language generators. Bridging
diverse strands of research, this survey aims to serve as a practical guide for
both LM researchers and practitioners with explanations of motivations behind
different mitigation strategies, their limitations, and open problems for
future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-grained Category Discovery under Coarse-grained supervision with Hierarchical Weighted Self-contrastive Learning. (arXiv:2210.07733v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07733">
<div class="article-summary-box-inner">
<span><p>Novel category discovery aims at adapting models trained on known categories
to novel categories. Previous works only focus on the scenario where known and
novel categories are of the same granularity. In this paper, we investigate a
new practical scenario called Fine-grained Category Discovery under
Coarse-grained supervision (FCDC). FCDC aims at discovering fine-grained
categories with only coarse-grained labeled data, which can adapt models to
categories of different granularity from known ones and reduce significant
labeling cost. It is also a challenging task since supervised training on
coarse-grained categories tends to focus on inter-class distance (distance
between coarse-grained classes) but ignore intra-class distance (distance
between fine-grained sub-classes) which is essential for separating
fine-grained categories. Considering most current methods cannot transfer
knowledge from coarse-grained level to fine-grained level, we propose a
hierarchical weighted self-contrastive network by building a novel weighted
self-contrastive module and combining it with supervised learning in a
hierarchical manner. Extensive experiments on public datasets show both
effectiveness and efficiency of our model over compared methods. Code and data
are available at https://github.com/Lackel/Hierarchical_Weighted_SCL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Confidence estimation of classification based on the distribution of the neural network output layer. (arXiv:2210.07745v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07745">
<div class="article-summary-box-inner">
<span><p>One of the most common problems preventing the application of prediction
models in the real world is lack of generalization: The accuracy of models,
measured in the benchmark does repeat itself on future data, e.g. in the
settings of real business. There is relatively little methods exist that
estimate the confidence of prediction models. In this paper, we propose novel
methods that, given a neural network classification model, estimate uncertainty
of particular predictions generated by this model. Furthermore, we propose a
method that, given a model and a confidence level, calculates a threshold that
separates prediction generated by this model into two subsets, one of them
meets the given confidence level. In contrast to other methods, the proposed
methods do not require any changes on existing neural networks, because they
simply build on the output logit layer of a common neural network. In
particular, the methods infer the confidence of a particular prediction based
on the distribution of the logit values corresponding to this prediction. The
proposed methods constitute a tool that is recommended for filtering
predictions in the process of knowledge extraction, e.g. based on web
scrapping, where predictions subsets are identified that maximize the precision
on cost of the recall, which is less important due to the availability of data.
The method has been tested on different tasks including relation extraction,
named entity recognition and image classification to show the significant
increase of accuracy achieved.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extracting Cultural Commonsense Knowledge at Scale. (arXiv:2210.07763v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07763">
<div class="article-summary-box-inner">
<span><p>Structured knowledge is important for many AI applications. Commonsense
knowledge, which is crucial for robust human-centric AI, is covered by a small
number of structured knowledge projects. However, they lack knowledge about
human traits and behaviors conditioned on socio-cultural contexts, which is
crucial for situative AI. This paper presents CANDLE, an end-to-end methodology
for extracting high-quality cultural commonsense knowledge (CCSK) at scale.
CANDLE extracts CCSK assertions from a huge web corpus and organizes them into
coherent clusters, for 3 domains of subjects (geography, religion, occupation)
and several cultural facets (food, drinks, clothing, traditions, rituals,
behaviors). CANDLE includes judicious techniques for classification-based
filtering and scoring of interestingness. Experimental evaluations show the
superiority of the CANDLE CCSK collection over prior works, and an extrinsic
use case demonstrates the benefits of CCSK for the GPT-3 language model. Code
and data can be accessed at https://cultural-csk.herokuapp.com/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Jointly Transcribe and Subtitle for End-to-End Spontaneous Speech Recognition. (arXiv:2210.07771v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07771">
<div class="article-summary-box-inner">
<span><p>TV subtitles are a rich source of transcriptions of many types of speech,
ranging from read speech in news reports to conversational and spontaneous
speech in talk shows and soaps. However, subtitles are not verbatim (i.e.
exact) transcriptions of speech, so they cannot be used directly to improve an
Automatic Speech Recognition (ASR) model. We propose a multitask dual-decoder
Transformer model that jointly performs ASR and automatic subtitling. The ASR
decoder (possibly pre-trained) predicts the verbatim output and the subtitle
decoder generates a subtitle, while sharing the encoder. The two decoders can
be independent or connected. The model is trained to perform both tasks
jointly, and is able to effectively use subtitle data. We show improvements on
regular ASR and on spontaneous and conversational ASR by incorporating the
additional subtitle decoder. The method does not require preprocessing
(aligning, filtering, pseudo-labeling, ...) of the subtitles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEATHER: A Framework for Learning to Generate Human-like Text in Dialogue. (arXiv:2210.07777v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07777">
<div class="article-summary-box-inner">
<span><p>Algorithms for text-generation in dialogue can be misguided. For example, in
task-oriented settings, reinforcement learning that optimizes only task-success
can lead to abysmal lexical diversity. We hypothesize this is due to poor
theoretical understanding of the objectives in text-generation and their
relation to the learning process (i.e., model training). To this end, we
propose a new theoretical framework for learning to generate text in dialogue.
Compared to existing theories of learning, our framework allows for analysis of
the multi-faceted goals inherent to text-generation. We use our framework to
develop theoretical guarantees for learners that adapt to unseen data. As an
example, we apply our theory to study data-shift within a cooperative learning
algorithm proposed for the GuessWhat?! visual dialogue game. From this insight,
we propose a new algorithm, and empirically, we demonstrate our proposal
improves both task-success and human-likeness of the generated text. Finally,
we show statistics from our theory are empirically predictive of multiple
qualities of the generated dialogue, suggesting our theory is useful for
model-selection when human evaluations are not available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompt Conditioned VAE: Enhancing Generative Replay for Lifelong Learning in Task-Oriented Dialogue. (arXiv:2210.07783v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07783">
<div class="article-summary-box-inner">
<span><p>Lifelong learning (LL) is vital for advanced task-oriented dialogue (ToD)
systems. To address the catastrophic forgetting issue of LL, generative replay
methods are widely employed to consolidate past knowledge with generated pseudo
samples. However, most existing generative replay methods use only a single
task-specific token to control their models. This scheme is usually not strong
enough to constrain the generative model due to insufficient information
involved. In this paper, we propose a novel method, prompt conditioned VAE for
lifelong learning (PCLL), to enhance generative replay by incorporating tasks'
statistics. PCLL captures task-specific distributions with a conditional
variational autoencoder, conditioned on natural language prompts to guide the
pseudo-sample generation. Moreover, it leverages a distillation process to
further consolidate past knowledge by alleviating the noise in pseudo samples.
Experiments on natural language understanding tasks of ToD systems demonstrate
that PCLL significantly outperforms competitive baselines in building LL
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Preference Learning for Storytelling via Contrastive Reinforcement Learning. (arXiv:2210.07792v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07792">
<div class="article-summary-box-inner">
<span><p>Controlled automated story generation seeks to generate natural language
stories satisfying constraints from natural language critiques or preferences.
Existing methods to control for story preference utilize prompt engineering
which is labor intensive and often inconsistent. They may also use
logit-manipulation methods which require annotated datasets to exist for the
desired attributes. To address these issues, we first train a contrastive
bi-encoder model to align stories with corresponding human critiques, named
CARP, building a general purpose preference model. This is subsequently used as
a reward function to fine-tune a generative language model via reinforcement
learning. However, simply fine-tuning a generative language model with a
contrastive reward model does not always reliably result in a story generation
system capable of generating stories that meet user preferences. To increase
story generation robustness we further fine-tune the contrastive reward model
using a prompt-learning technique. A human participant study is then conducted
comparing generations from our full system, ablations, and two baselines. We
show that the full fine-tuning pipeline results in a story generator preferred
over a LLM 20x as large as well as logit-based methods. This motivates the use
of contrastive learning for general purpose human preference modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EfficientVLM: Fast and Accurate Vision-Language Models via Knowledge Distillation and Modal-adaptive Pruning. (arXiv:2210.07795v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07795">
<div class="article-summary-box-inner">
<span><p>Pre-trained vision-language models (VLMs) have achieved impressive results in
a range of vision-language tasks. However, popular VLMs usually consist of
hundreds of millions of parameters which brings challenges for fine-tuning and
deployment in real-world applications due to space, memory, and latency
constraints. In this work, we introduce a distilling then pruning framework to
compress large vision-language models into smaller, faster, and more accurate
ones. We first shrink the size of a pre-trained large VLM and apply knowledge
distillation in the vision-language pre-training stage to obtain a
task-agnostic compact VLM. Then we propose a modal-adaptive pruning algorithm
to automatically infer the importance of vision and language modalities for
different downstream tasks and adaptively remove redundant structures and
neurons in different encoders with controllable target sparsity. We apply our
framework to train EfficientVLM, a fast and accurate vision-language model
consisting of 6 vision layers, 3 text layers, and 3 cross-modal fusion layers,
accounting for only 93 million parameters in total, which is 44.3% of the
teacher model. EfficientVLM retains 98.4% performance of the teacher model and
accelerates its inference speed by 2.2x. EfficientVLM achieves a large absolute
improvement over previous SoTA efficient VLMs of similar sizes by a large
margin on various vision-language tasks, including VQAv2 (+4.9%), NLVR2
(+5.6%), ITR (R@1 on TR +17.2%, on IR + 15.6% ) and COCO caption generation
(CIDEr +6.5), demonstrating a large potential on training lightweight VLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bringing NURC/SP to Digital Life: the Role of Open-source Automatic Speech Recognition Models. (arXiv:2210.07852v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07852">
<div class="article-summary-box-inner">
<span><p>The NURC Project that started in 1969 to study the cultured linguistic urban
norm spoken in five Brazilian capitals, was responsible for compiling a large
corpus for each capital. The digitized NURC/SP comprises 375 inquiries in 334
hours of recordings taken in S\~ao Paulo capital. Although 47 inquiries have
transcripts, there was no alignment between the audio-transcription, and 328
inquiries were not transcribed. This article presents an evaluation and error
analysis of three automatic speech recognition models trained with spontaneous
speech in Portuguese and one model trained with prepared speech. The evaluation
allowed us to choose the best model, using WER and CER metrics, in a manually
aligned sample of NURC/SP, to automatically transcribe 284 hours.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One Graph to Rule them All: Using NLP and Graph Neural Networks to analyse Tolkien's Legendarium. (arXiv:2210.07871v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07871">
<div class="article-summary-box-inner">
<span><p>Natural Language Processing and Machine Learning have considerably advanced
Computational Literary Studies. Similarly, the construction of co-occurrence
networks of literary characters, and their analysis using methods from social
network analysis and network science, have provided insights into the micro-
and macro-level structure of literary texts. Combining these perspectives, in
this work we study character networks extracted from a text corpus of J.R.R.
Tolkien's Legendarium. We show that this perspective helps us to analyse and
visualise the narrative style that characterises Tolkien's works. Addressing
character classification, embedding and co-occurrence prediction, we further
investigate the advantages of state-of-the-art Graph Neural Networks over a
popular word embedding method. Our results highlight the large potential of
graph learning in Computational Literary Studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Second Wave of UD Hebrew Treebanking and Cross-Domain Parsing. (arXiv:2210.07873v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07873">
<div class="article-summary-box-inner">
<span><p>Foundational Hebrew NLP tasks such as segmentation, tagging and parsing, have
relied to date on various versions of the Hebrew Treebank (HTB, Sima'an et al.
2001). However, the data in HTB, a single-source newswire corpus, is now over
30 years old, and does not cover many aspects of contemporary Hebrew on the
web. This paper presents a new, freely available UD treebank of Hebrew
stratified from a range of topics selected from Hebrew Wikipedia. In addition
to introducing the corpus and evaluating the quality of its annotations, we
deploy automatic validation tools based on grew (Guillaume, 2021), and conduct
the first cross domain parsing experiments in Hebrew. We obtain new
state-of-the-art (SOTA) results on UD NLP tasks, using a combination of the
latest language modelling and some incremental improvements to existing
transformer based approaches. We also release a new version of the UD HTB
matching annotation scheme updates from our new corpus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HashFormers: Towards Vocabulary-independent Pre-trained Transformers. (arXiv:2210.07904v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07904">
<div class="article-summary-box-inner">
<span><p>Transformer-based pre-trained language models are vocabulary-dependent,
mapping by default each token to its corresponding embedding. This one-to-one
mapping results into embedding matrices that occupy a lot of memory (i.e.
millions of parameters) and grow linearly with the size of the vocabulary.
Previous work on on-device transformers dynamically generate token embeddings
on-the-fly without embedding matrices using locality-sensitive hashing over
morphological information. These embeddings are subsequently fed into
transformer layers for text classification. However, these methods are not
pre-trained. Inspired by this line of work, we propose HashFormers, a new
family of vocabulary-independent pre-trained transformers that support an
unlimited vocabulary (i.e. all possible tokens in a corpus) given a
substantially smaller fixed-sized embedding matrix. We achieve this by first
introducing computationally cheap hashing functions that bucket together
individual tokens to embeddings. We also propose three variants that do not
require an embedding matrix at all, further reducing the memory requirements.
We empirically demonstrate that HashFormers are more memory efficient compared
to standard pre-trained transformers while achieving comparable predictive
performance when fine-tuned on multiple text classification tasks. For example,
our most efficient HashFormer variant has a negligible performance degradation
(0.4\% on GLUE) using only 99.1K parameters for representing the embeddings
compared to 12.3-38M parameters of state-of-the-art models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Expose Backdoors on the Way: A Feature-Based Efficient Defense against Textual Backdoor Attacks. (arXiv:2210.07907v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07907">
<div class="article-summary-box-inner">
<span><p>Natural language processing (NLP) models are known to be vulnerable to
backdoor attacks, which poses a newly arisen threat to NLP models. Prior online
backdoor defense methods for NLP models only focus on the anomalies at either
the input or output level, still suffering from fragility to adaptive attacks
and high computational cost. In this work, we take the first step to
investigate the unconcealment of textual poisoned samples at the
intermediate-feature level and propose a feature-based efficient online defense
method. Through extensive experiments on existing attacking methods, we find
that the poisoned samples are far away from clean samples in the intermediate
feature space of a poisoned NLP model. Motivated by this observation, we devise
a distance-based anomaly score (DAN) to distinguish poisoned samples from clean
samples at the feature level. Experiments on sentiment analysis and offense
detection tasks demonstrate the superiority of DAN, as it substantially
surpasses existing online defense methods in terms of defending performance and
enjoys lower inference costs. Moreover, we show that DAN is also resistant to
adaptive attacks based on feature-level regularization. Our code is available
at https://github.com/lancopku/DAN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Measures of Biases and Harms in NLP. (arXiv:2108.03362v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03362">
<div class="article-summary-box-inner">
<span><p>Recent studies show that Natural Language Processing (NLP) technologies
propagate societal biases about demographic groups associated with attributes
such as gender, race, and nationality. To create interventions and mitigate
these biases and associated harms, it is vital to be able to detect and measure
such biases. While existing works propose bias evaluation and mitigation
methods for various tasks, there remains a need to cohesively understand the
biases and the specific harms they measure, and how different measures compare
with each other. To address this gap, this work presents a practical framework
of harms and a series of questions that practitioners can answer to guide the
development of bias measures. As a validation of our framework and
documentation questions, we also present several case studies of how existing
bias measures in NLP -- both intrinsic measures of bias in representations and
extrinsic measures of bias of downstream applications -- can be aligned with
different harms and how our proposed documentation questions facilitates more
holistic understanding of what bias measures are measuring.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Do Things without Words: Modeling Semantic Drift of Emoji. (arXiv:2110.04093v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04093">
<div class="article-summary-box-inner">
<span><p>Emoji have become a significant part of our informal textual communication.
Previous work addressing the societal and linguistic functions of emoji
overlook the evolving meaning of the symbol. This evolution could be addressed
through the framework of semantic drifts. In this paper we model and analyze
the semantic drift of emoji and discuss the features that may be contributing
to the drift, some are unique to emoji and some are more general.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Template Filling for Controllable Commonsense Reasoning. (arXiv:2111.00539v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00539">
<div class="article-summary-box-inner">
<span><p>Large-scale sequence-to-sequence models have shown to be adept at both
multiple-choice and open-domain commonsense reasoning tasks. However, the
current systems do not provide the ability to control the various attributes of
the reasoning chain. To enable better controllability, we propose to study the
commonsense reasoning as a template filling task (TemplateCSR) -- where the
language models fills reasoning templates with the given constraints as control
factors. As an approach to TemplateCSR, we (i) propose a dataset of commonsense
reasoning template-expansion pairs and (ii) introduce POTTER, a pretrained
sequence-to-sequence model using prompts to perform commonsense reasoning
across concepts. Our experiments show that our approach outperforms baselines
both in generation metrics and factuality metrics. We also present a detailed
error analysis on our approach's ability to reliably perform commonsense
reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">P4E: Few-Shot Event Detection as Prompt-Guided Identification and Localization. (arXiv:2202.07615v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.07615">
<div class="article-summary-box-inner">
<span><p>We propose P4E, an identify-and-localize event detection framework that
integrates the best of few-shot prompting and structured prediction. Our
framework decomposes event detection into an unstructured identification task
and a structured localization task. For the unstructured identification task,
we leverage prompting to elicit knowledge from pretrained language models,
allowing our model to adapt to new event types quickly. We then employ a
type-agnostic sequence labeling model to localize the event trigger conditioned
on the identification output. This heterogeneous model design allows P4E to
make fast adaptation without sacrificing the ability to make structured
predictions. Our experiments demonstrate the effectiveness of our proposed
design, and P4E achieves the new state-of-the-art on few-shot entity detection
across multiple datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COLD Decoding: Energy-based Constrained Text Generation with Langevin Dynamics. (arXiv:2202.11705v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11705">
<div class="article-summary-box-inner">
<span><p>Many applications of text generation require incorporating different
constraints to control the semantics or style of generated text. These
constraints can be hard (e.g., ensuring certain keywords are included in the
output) and soft (e.g., contextualizing the output with the left- or right-hand
context). In this paper, we present Energy-based Constrained Decoding with
Langevin Dynamics (COLD), a decoding framework which unifies constrained
generation as specifying constraints through an energy function, then
performing efficient differentiable reasoning over the constraints through
gradient-based sampling. COLD decoding is a flexible framework that can be
applied directly to off-the-shelf left-to-right language models without the
need for any task-specific fine-tuning, as demonstrated through three
challenging text generation applications: lexically-constrained generation,
abductive reasoning, and counterfactual reasoning. Our experiments on these
constrained generation tasks point to the effectiveness of our approach, both
in terms of automatic and human evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Learning of Sociopragmatic Meaning in Social Media. (arXiv:2203.07648v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07648">
<div class="article-summary-box-inner">
<span><p>Recent progress in representation and contrastive learning in NLP has not
widely considered the class of \textit{sociopragmatic meaning} (i.e., meaning
in interaction within different language communities). To bridge this gap, we
propose a novel framework for learning task-agnostic representations
transferable to a wide range of sociopragmatic tasks (e.g., emotion, hate
speech, humor, sarcasm). Our framework outperforms other contrastive learning
frameworks for both in-domain and out-of-domain data, across both the general
and few-shot settings. For example, compared to two popular pre-trained
language models, our method obtains an improvement of $11.66$ average $F_1$ on
$16$ datasets when fine-tuned on only $20$ training samples per dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FastKASSIM: A Fast Tree Kernel-Based Syntactic Similarity Metric. (arXiv:2203.08299v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08299">
<div class="article-summary-box-inner">
<span><p>Syntax is a fundamental component of language, yet few metrics have been
employed to capture syntactic similarity or coherence at the utterance- and
document-level. The existing standard document-level syntactic similarity
metric is computationally expensive and performs inconsistently when faced with
syntactically dissimilar documents. To address these challenges, we present
FastKASSIM, a metric for utterance- and document-level syntactic similarity
which pairs and averages the most similar constituency parse trees between a
pair of documents based on tree kernels. FastKASSIM is more robust to syntactic
dissimilarities and runs up to to 5.32 times faster than its predecessor over
documents in the r/ChangeMyView corpus. FastKASSIM's improvements allow us to
examine hypotheses in two settings with large documents. We find that
syntactically similar arguments on r/ChangeMyView tend to be more persuasive,
and that syntax is predictive of authorship attribution in the Australian High
Court Judgment corpus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CorrectSpeech: A Fully Automated System for Speech Correction and Accent Reduction. (arXiv:2204.05460v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.05460">
<div class="article-summary-box-inner">
<span><p>This study propose a fully automated system for speech correction and accent
reduction. Consider the application scenario that a recorded speech audio
contains certain errors, e.g., inappropriate words, mispronunciations, that
need to be corrected. The proposed system, named CorrectSpeech, performs the
correction in three steps: recognizing the recorded speech and converting it
into time-stamped symbol sequence, aligning recognized symbol sequence with
target text to determine locations and types of required edit operations, and
generating the corrected speech. Experiments show that the quality and
naturalness of corrected speech depend on the performance of speech recognition
and alignment modules, as well as the granularity level of editing operations.
The proposed system is evaluated on two corpora: a manually perturbed version
of VCTK and L2-ARCTIC. The results demonstrate that our system is able to
correct mispronunciation and reduce accent in speech recordings. Audio samples
are available online for demonstration
https://daxintan-cuhk.github.io/CorrectSpeech/ .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Building Markovian Generative Architectures over Pretrained LM Backbones for Efficient Task-Oriented Dialog Systems. (arXiv:2204.06452v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.06452">
<div class="article-summary-box-inner">
<span><p>Recently, Transformer based pretrained language models (PLMs), such as GPT2
and T5, have been leveraged to build generative task-oriented dialog (TOD)
systems. A drawback of existing PLM-based models is their non-Markov
architectures across turns, i.e., the whole history is used as the conditioning
input at each turn. First, this brings inefficiencies in memory and
computation. Furthermore, using the whole history increases model complexity
and may hurt the training efficiency, especially when facing small amounts of
labeled training data (the low-resource setting). In this paper, motivated by
the observation that dialog states could be viewed as Markov states, we propose
to build Markovian Generative Architectures (MGA) over PLM backbones for
efficient TOD systems. Experiments on MultiWOZ2.1 show that in the
rich-resource setting, the proposed Markov models reduce memory and time costs
without performance degradation; in the low-resource setting, the training
efficiency of the Markov models is more significant.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FETA: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue. (arXiv:2205.06262v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06262">
<div class="article-summary-box-inner">
<span><p>Task transfer, transferring knowledge contained in related tasks, holds the
promise of reducing the quantity of labeled data required to fine-tune language
models. Dialogue understanding encompasses many diverse tasks, yet task
transfer has not been thoroughly studied in conversational AI. This work
explores conversational task transfer by introducing FETA: a benchmark for
few-sample task transfer in open-domain dialogue. FETA contains two underlying
sets of conversations upon which there are 10 and 7 tasks annotated, enabling
the study of intra-dataset task transfer; task transfer without domain
adaptation. We utilize three popular language models and three learning
algorithms to analyze the transferability between 132 source-target task pairs
and create a baseline for future work. We run experiments in the single- and
multi-source settings and report valuable findings, e.g., most performance
trends are model-specific, and span extraction and multiple-choice tasks
benefit the most from task transfer. In addition to task transfer, FETA can be
a valuable resource for future research into the efficiency and
generalizability of pre-training datasets and model architectures, as well as
for learning settings such as continual and multitask learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Rule Induction for Interpretable Semi-Supervised Learning. (arXiv:2205.09067v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09067">
<div class="article-summary-box-inner">
<span><p>Semi-supervised learning has shown promise in allowing NLP models to
generalize from small amounts of labeled data. Meanwhile, pretrained
transformer models act as black-box correlation engines that are difficult to
explain and sometimes behave unreliably. In this paper, we propose tackling
both of these challenges via Automatic Rule Induction (ARI), a simple and
general-purpose framework for the automatic discovery and integration of
symbolic rules into pretrained transformer models. First, we extract weak
symbolic rules from low-capacity machine learning models trained on small
amounts of labeled data. Next, we use an attention mechanism to integrate these
rules into high-capacity pretrained transformer models. Last, the
rule-augmented system becomes part of a self-training framework to boost
supervision signal on unlabeled data. These steps can be layered beneath a
variety of existing weak supervision and semi-supervised NLP algorithms in
order to improve performance and interpretability. Experiments across nine
sequence classification and relation extraction tasks suggest that ARI can
improve state-of-the-art methods with no manual effort and minimal
computational overhead.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BBTv2: Towards a Gradient-Free Future with Large Language Models. (arXiv:2205.11200v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11200">
<div class="article-summary-box-inner">
<span><p>Most downstream adaptation methods tune all or part of the parameters of
pre-trained models (PTMs) through gradient descent, where the tuning cost
increases linearly with the growth of the model size. By contrast,
gradient-free methods only require the forward computation of the PTM to tune
the prompt, retaining the benefits of efficient tuning and deployment. Though,
past work on gradient-free tuning often introduces gradient descent to seek a
good initialization of prompt and lacks versatility across tasks and PTMs. In
this paper, we present BBTv2, an improved version of Black-Box Tuning, to drive
PTMs for few-shot learning. We prepend continuous prompts to every layer of the
PTM and propose a divide-and-conquer gradient-free algorithm to optimize the
prompts at different layers alternately. Extensive experiments across various
tasks and PTMs show that BBTv2 can achieve comparable performance to full model
tuning and state-of-the-art parameter-efficient methods (e.g., Adapter, LoRA,
BitFit, etc.) under few-shot settings while maintaining much fewer tunable
parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Tokenization Learning. (arXiv:2205.11443v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11443">
<div class="article-summary-box-inner">
<span><p>In the presented study, we discover that the so-called "transition freedom"
metric appears superior for unsupervised tokenization purposes in comparison to
statistical metrics such as mutual information and conditional probability,
providing F-measure scores in range from $0.71$ to $1.0$ across explored
multilingual corpora. We find that different languages require different
offshoots of that metric (such as derivative, variance, and "peak values") for
successful tokenization. Larger training corpora do not necessarily result in
better tokenization quality, while compressing the models by eliminating
statistically weak evidence tends to improve performance. The proposed
unsupervised tokenization technique provides quality better than or comparable
to lexicon-based ones, depending on the language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LingMess: Linguistically Informed Multi Expert Scorers for Coreference Resolution. (arXiv:2205.12644v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12644">
<div class="article-summary-box-inner">
<span><p>While coreference resolution typically involves various linguistic
challenges, recent models are based on a single pairwise scorer for all types
of pairs. We present LingMess, a new coreference model that defines different
categories of coreference cases and optimize multiple pairwise scorers, where
each scorer learns a specific set of linguistic challenges. Our model
substantially improves pairwise scores for most categories and outperforms
cluster-level performance on Ontonotes and 5 additional datasets. Our model is
available in https://github.com/shon-otmazgin/lingmess-coref
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoNT: Contrastive Neural Text Generation. (arXiv:2205.14690v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.14690">
<div class="article-summary-box-inner">
<span><p>Recently, contrastive learning attracts increasing interests in neural text
generation as a new solution to alleviate the exposure bias problem. It
introduces a sequence-level training signal which is crucial to generation
tasks that always rely on auto-regressive decoding. However, previous methods
using contrastive learning in neural text generation usually lead to inferior
performance. In this paper, we analyse the underlying reasons and propose a new
Contrastive Neural Text generation framework, CoNT. CoNT addresses bottlenecks
that prevent contrastive learning from being widely adopted in generation tasks
from three aspects -- the construction of contrastive examples, the choice of
the contrastive loss, and the strategy in decoding. We validate CoNT on five
generation tasks with ten benchmarks, including machine translation,
summarization, code comment generation, data-to-text generation and commonsense
generation. Experimental results show that CoNT clearly outperforms the
conventional training framework on all the ten benchmarks with a convincing
margin. Especially, CoNT surpasses previous the most competitive contrastive
learning method for text generation, by 1.50 BLEU on machine translation and
1.77 ROUGE-1 on summarization, respectively. It achieves new state-of-the-art
on summarization, code comment generation (without external data) and
data-to-text generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EcoFormer: Energy-Saving Attention with Linear Complexity. (arXiv:2209.09004v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.09004">
<div class="article-summary-box-inner">
<span><p>Transformer is a transformative framework that models sequential data and has
achieved remarkable performance on a wide range of tasks, but with high
computational and energy cost. To improve its efficiency, a popular choice is
to compress the models via binarization which constrains the floating-point
values into binary ones to save resource consumption owing to cheap bitwise
operations significantly. However, existing binarization methods only aim at
minimizing the information loss for the input distribution statistically, while
ignoring the pairwise similarity modeling at the core of the attention. To this
end, we propose a new binarization paradigm customized to high-dimensional
softmax attention via kernelized hashing, called EcoFormer, to map the original
queries and keys into low-dimensional binary codes in Hamming space. The
kernelized hash functions are learned to match the ground-truth similarity
relations extracted from the attention map in a self-supervised way. Based on
the equivalence between the inner product of binary codes and the Hamming
distance as well as the associative property of matrix multiplication, we can
approximate the attention in linear complexity by expressing it as a
dot-product of binary codes. Moreover, the compact binary representations of
queries and keys enable us to replace most of the expensive multiply-accumulate
operations in attention with simple accumulations to save considerable on-chip
energy footprint on edge devices. Extensive experiments on both vision and
language tasks show that EcoFormer consistently achieves comparable performance
with standard attentions while consuming much fewer resources. For example,
based on PVTv2-B0 and ImageNet-1K, Ecoformer achieves a 73% on-chip energy
footprint reduction with only a 0.33% performance drop compared to the standard
attention. Code is available at https://github.com/ziplab/EcoFormer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Physical computation and compositionality. (arXiv:2210.00392v2 [quant-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.00392">
<div class="article-summary-box-inner">
<span><p>Developments in quantum computing and, more in general, non-standard
computing systems, represent a clear indication that the very notion of what a
physical computing device is and does should be recast in a rigorous and sound
framework. Physical computing has opened a whole stream of new research aimed
to understand and control how information is processed by several types of
physical devices. Therefore, classical definitions and entire frameworks need
to be adapted in order to fit a broader notion of what physical computing
systems really are. Recent studies have proposed a formalism that can be used
to carve out a more proper notion of physical computing. In this paper we
present a framework which capture such results in a very natural way via some
basic constructions in Category Theory. Furthermore, we show that, within our
framework, the compositional nature of physical computing systems is naturally
formalized, and that it can be organized in coherent structures by the means of
their relational nature.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COMPS: Conceptual Minimal Pair Sentences for testing Property Knowledge and Inheritance in Pre-trained Language Models. (arXiv:2210.01963v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.01963">
<div class="article-summary-box-inner">
<span><p>A characteristic feature of human semantic memory is its ability to not only
store and retrieve the properties of concepts observed through experience, but
to also facilitate the inheritance of properties (can breathe) from
superordinate concepts (animal) to their subordinates (dog) -- i.e. demonstrate
property inheritance. In this paper, we present COMPS, a collection of minimal
pair sentences that jointly tests pre-trained language models (PLMs) on their
ability to attribute properties to concepts and their ability to demonstrate
property inheritance behavior. Analyses of 22 different PLMs on COMPS reveal
that they can easily distinguish between concepts on the basis of a property
when they are trivially different, but find it relatively difficult when
concepts are related on the basis of nuanced knowledge representations.
Furthermore, we find that PLMs can demonstrate behavior consistent with
property inheritance to a great extent, but fail in the presence of distracting
information, which decreases the performance of many models, sometimes even
below chance. This lack of robustness in demonstrating simple reasoning raises
important questions about PLMs' capacity to make correct inferences even when
they appear to possess the prerequisite knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Not another Negation Benchmark: The NaN-NLI Test Suite for Sub-clausal Negation. (arXiv:2210.03256v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.03256">
<div class="article-summary-box-inner">
<span><p>Negation is poorly captured by current language models, although the extent
of this problem is not widely understood. We introduce a natural language
inference (NLI) test suite to enable probing the capabilities of NLP methods,
with the aim of understanding sub-clausal negation. The test suite contains
premise--hypothesis pairs where the premise contains sub-clausal negation and
the hypothesis is constructed by making minimal modifications to the premise in
order to reflect different possible interpretations. Aside from adopting
standard NLI labels, our test suite is systematically constructed under a
rigorous linguistic framework. It includes annotation of negation types and
constructions grounded in linguistic theory, as well as the operations used to
construct hypotheses. This facilitates fine-grained analysis of model
performance. We conduct experiments using pre-trained language models to
demonstrate that our test suite is more challenging than existing benchmarks
focused on negation, and show how our annotation supports a deeper
understanding of the current NLI capabilities in terms of negation and
quantification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models Are Poor Learners of Directional Inference. (arXiv:2210.04695v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04695">
<div class="article-summary-box-inner">
<span><p>We examine LMs' competence of directional predicate entailments by supervised
fine-tuning with prompts. Our analysis shows that contrary to their apparent
success on standard NLI, LMs show limited ability to learn such directional
inference; moreover, existing datasets fail to test directionality, and/or are
infested by artefacts that can be learnt as proxy for entailments, yielding
over-optimistic results. In response, we present BoOQA (Boolean Open QA), a
robust multi-lingual evaluation benchmark for directional predicate
entailments, extrinsic to existing training sets. On BoOQA, we establish
baselines and show evidence of existing LM-prompting models being incompetent
directional entailment learners, in contrast to entailment graphs, however
limited by sparsity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty Quantification with Pre-trained Language Models: A Large-Scale Empirical Analysis. (arXiv:2210.04714v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04714">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PLMs) have gained increasing popularity due to
their compelling prediction performance in diverse natural language processing
(NLP) tasks. When formulating a PLM-based prediction pipeline for NLP tasks, it
is also crucial for the pipeline to minimize the calibration error, especially
in safety-critical applications. That is, the pipeline should reliably indicate
when we can trust its predictions. In particular, there are various
considerations behind the pipeline: (1) the choice and (2) the size of PLM, (3)
the choice of uncertainty quantifier, (4) the choice of fine-tuning loss, and
many more. Although prior work has looked into some of these considerations,
they usually draw conclusions based on a limited scope of empirical studies.
There still lacks a holistic analysis on how to compose a well-calibrated
PLM-based prediction pipeline. To fill this void, we compare a wide range of
popular options for each consideration based on three prevalent NLP
classification tasks and the setting of domain shift. In response, we recommend
the following: (1) use ELECTRA for PLM encoding, (2) use larger PLMs if
possible, (3) use Temp Scaling as the uncertainty quantifier, and (4) use Focal
Loss for fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DIGAT: Modeling News Recommendation with Dual-Graph Interaction. (arXiv:2210.05196v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.05196">
<div class="article-summary-box-inner">
<span><p>News recommendation (NR) is essential for online news services. Existing NR
methods typically adopt a news-user representation learning framework, facing
two potential limitations. First, in news encoder, single candidate news
encoding suffers from an insufficient semantic information problem. Second,
existing graph-based NR methods are promising but lack effective news-user
feature interaction, rendering the graph-based recommendation suboptimal. To
overcome these limitations, we propose dual-interactive graph attention
networks (DIGAT) consisting of news- and user-graph channels. In the news-graph
channel, we enrich the semantics of single candidate news by incorporating the
semantically relevant news information with a semantic-augmented graph (SAG).
In the user-graph channel, multi-level user interests are represented with a
news-topic graph. Most notably, we design a dual-graph interaction process to
perform effective feature interaction between the news and user graphs, which
facilitates accurate news-user representation matching. Experiment results on
the benchmark dataset MIND show that DIGAT outperforms existing news
recommendation methods. Further ablation studies and analyses validate the
effectiveness of (1) semantic-augmented news graph modeling and (2) dual-graph
interaction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ERNIE-Layout: Layout Knowledge Enhanced Pre-training for Visually-rich Document Understanding. (arXiv:2210.06155v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06155">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed the rise and success of pre-training techniques
in visually-rich document understanding. However, most existing methods lack
the systematic mining and utilization of layout-centered knowledge, leading to
sub-optimal performances. In this paper, we propose ERNIE-Layout, a novel
document pre-training solution with layout knowledge enhancement in the whole
workflow, to learn better representations that combine the features from text,
layout, and image. Specifically, we first rearrange input sequences in the
serialization stage, and then present a correlative pre-training task, reading
order prediction, to learn the proper reading order of documents. To improve
the layout awareness of the model, we integrate a spatial-aware disentangled
attention into the multi-modal transformer and a replaced regions prediction
task into the pre-training phase. Experimental results show that ERNIE-Layout
achieves superior performance on various downstream tasks, setting new
state-of-the-art on key information extraction, document image classification,
and document question answering datasets. The code and models are publicly
available at
<a href="http://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/ernie-layout.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InfoCSE: Information-aggregated Contrastive Learning of Sentence Embeddings. (arXiv:2210.06432v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06432">
<div class="article-summary-box-inner">
<span><p>Contrastive learning has been extensively studied in sentence embedding
learning, which assumes that the embeddings of different views of the same
sentence are closer. The constraint brought by this assumption is weak, and a
good sentence representation should also be able to reconstruct the original
sentence fragments. Therefore, this paper proposes an information-aggregated
contrastive learning framework for learning unsupervised sentence embeddings,
termed InfoCSE. InfoCSE forces the representation of [CLS] positions to
aggregate denser sentence information by introducing an additional Masked
language model task and a well-designed network. We evaluate the proposed
InfoCSE on several benchmark datasets w.r.t the semantic text similarity (STS)
task. Experimental results show that InfoCSE outperforms SimCSE by an average
Spearman correlation of 2.60% on BERT-base, and 1.77% on BERT-large, achieving
state-of-the-art results among unsupervised sentence representation learning
methods. Our code are available at
https://github.com/caskcsg/sentemb/tree/main/InfoCSE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Study on Finding Spans. (arXiv:2210.06824v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06824">
<div class="article-summary-box-inner">
<span><p>We present an empirical study on methods for span finding, the selection of
consecutive tokens in text for some downstream tasks. We focus on approaches
that can be employed in training end-to-end information extraction systems, and
find there is no definitive solution without considering task properties, and
provide our observations to help with future design choices: 1) a tagging
approach often yields higher precision while span enumeration and boundary
prediction provide higher recall; 2) span type information can benefit a
boundary prediction approach; 3) additional contextualization does not help
span finding in most cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anonymizing Speech with Generative Adversarial Networks to Preserve Speaker Privacy. (arXiv:2210.07002v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07002">
<div class="article-summary-box-inner">
<span><p>In order to protect the privacy of speech data, speaker anonymization aims
for hiding the identity of a speaker by changing the voice in speech
recordings. This typically comes with a privacy-utility trade-off between
protection of individuals and usability of the data for downstream
applications. One of the challenges in this context is to create non-existent
voices that sound as natural as possible.
</p>
<p>In this work, we propose to tackle this issue by generating speaker
embeddings using a generative adversarial network with Wasserstein distance as
cost function. By incorporating these artificial embeddings into a
speech-to-text-to-speech pipeline, we outperform previous approaches in terms
of privacy and utility. According to standard objective metrics and human
evaluation, our approach generates intelligible and content-preserving yet
privacy-protecting versions of the original recordings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLASP: Few-Shot Cross-Lingual Data Augmentation for Semantic Parsing. (arXiv:2210.07074v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07074">
<div class="article-summary-box-inner">
<span><p>A bottleneck to developing Semantic Parsing (SP) models is the need for a
large volume of human-labeled training data. Given the complexity and cost of
human annotation for SP, labeled data is often scarce, particularly in
multilingual settings. Large Language Models (LLMs) excel at SP given only a
few examples, however LLMs are unsuitable for runtime systems which require low
latency. In this work, we propose CLASP, a simple method to improve
low-resource SP for moderate-sized models: we generate synthetic data from
AlexaTM 20B to augment the training set for a model 40x smaller (500M
parameters). We evaluate on two datasets in low-resource settings: English
PIZZA, containing either 348 or 16 real examples, and mTOP cross-lingual
zero-shot, where training data is available only in English, and the model must
generalize to four new languages. On both datasets, we show significant
improvements over strong baseline methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Compressing Sequences for Self-Supervised Speech Models. (arXiv:2210.07189v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07189">
<div class="article-summary-box-inner">
<span><p>Compressing self-supervised models has become increasingly necessary, as
self-supervised models become larger. While previous approaches have primarily
focused on compressing the model size, shortening sequences is also effective
in reducing the computational cost. In this work, we study fixed-length and
variable-length subsampling along the time axis in self-supervised learning. We
explore how individual downstream tasks are sensitive to input frame rates.
Subsampling while training self-supervised models not only improves the overall
performance on downstream tasks under certain frame rates, but also brings
significant speed-up in inference. Variable-length subsampling performs
particularly well under low frame rates. In addition, if we have access to
phonetic boundaries, we find no degradation in performance for an average frame
rate as low as 10 Hz.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-10-17 23:20:24.302592016 UTC">2022-10-17 23:20:24 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>