<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-05-18T01:30:00Z">05-18</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">OOD-Speech: A Large Bengali Speech Recognition Dataset for Out-of-Distribution Benchmarking. (arXiv:2305.09688v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09688">
<div class="article-summary-box-inner">
<span><p>We present OOD-Speech, the first out-of-distribution (OOD) benchmarking
dataset for Bengali automatic speech recognition (ASR). Being one of the most
spoken languages globally, Bengali portrays large diversity in dialects and
prosodic features, which demands ASR frameworks to be robust towards
distribution shifts. For example, islamic religious sermons in Bengali are
delivered with a tonality that is significantly different from regular speech.
Our training dataset is collected via massively online crowdsourcing campaigns
which resulted in 1177.94 hours collected and curated from $22,645$ native
Bengali speakers from South Asia. Our test dataset comprises 23.03 hours of
speech collected and manually annotated from 17 different sources, e.g.,
Bengali TV drama, Audiobook, Talk show, Online class, and Islamic sermons to
name a few. OOD-Speech is jointly the largest publicly available speech
dataset, as well as the first out-of-distribution ASR benchmarking dataset for
Bengali.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Table Pre-training Empowers Models for Tabular Prediction. (arXiv:2305.09696v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09696">
<div class="article-summary-box-inner">
<span><p>Recently, the topic of table pre-training has attracted considerable research
interest. However, how to employ table pre-training to boost the performance of
tabular prediction remains an open challenge. In this paper, we propose TapTap,
the first attempt that leverages table pre-training to empower models for
tabular prediction. After pre-training on a large corpus of real-world tabular
data, TapTap can generate high-quality synthetic tables to support various
applications on tabular data, including privacy protection, low resource
regime, missing value imputation, and imbalanced classification. Extensive
experiments on 12 datasets demonstrate that TapTap outperforms a total of 16
baselines in different scenarios. Meanwhile, it can be easily combined with
various backbone models, including LightGBM, Multilayer Perceptron (MLP) and
Transformer. Moreover, with the aid of table pre-training, models trained using
synthetic data generated by TapTap can even compete with models using the
original dataset on half of the experimental datasets, marking a milestone in
the development of synthetic tabular data generation. The codes are available
at https://github.com/ZhangTP1996/TapTap.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What In-Context Learning "Learns" In-Context: Disentangling Task Recognition and Task Learning. (arXiv:2305.09731v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09731">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) exploit in-context learning (ICL) to solve tasks
with only a few demonstrations, but its mechanisms are not yet well-understood.
Some works suggest that LLMs only recall already learned concepts from
pre-training, while others hint that ICL performs implicit learning over
demonstrations. We characterize two ways through which ICL leverages
demonstrations. Task recognition (TR) captures the extent to which LLMs can
recognize a task through demonstrations -- even without ground-truth labels --
and apply their pre-trained priors, whereas task learning (TL) is the ability
to capture new input-label mappings unseen in pre-training. Using a wide range
of classification datasets and three LLM families (GPT-3, LLaMA and OPT), we
design controlled experiments to disentangle the roles of TR and TL in ICL. We
show that (1) models can achieve non-trivial performance with only TR, and TR
does not further improve with larger models or more demonstrations; (2) LLMs
acquire TL as the model scales, and TL's performance consistently improves with
more demonstrations in context. Our findings unravel two different forces
behind ICL and we advocate for discriminating them in future ICL research due
to their distinct nature.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Clinical Note Owns its Hierarchy: Multi-Level Hypergraph Neural Networks for Patient-Level Representation Learning. (arXiv:2305.09756v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09756">
<div class="article-summary-box-inner">
<span><p>Leveraging knowledge from electronic health records (EHRs) to predict a
patient's condition is essential to the effective delivery of appropriate care.
Clinical notes of patient EHRs contain valuable information from healthcare
professionals, but have been underused due to their difficult contents and
complex hierarchies. Recently, hypergraph-based methods have been proposed for
document classifications. Directly adopting existing hypergraph methods on
clinical notes cannot sufficiently utilize the hierarchy information of the
patient, which can degrade clinical semantic information by (1) frequent
neutral words and (2) hierarchies with imbalanced distribution. Thus, we
propose a taxonomy-aware multi-level hypergraph neural network (TM-HGNN), where
multi-level hypergraphs assemble useful neutral words with rare keywords via
note and taxonomy level hyperedges to retain the clinical semantic information.
The constructed patient hypergraphs are fed into hierarchical message passing
layers for learning more balanced multi-level knowledge at the note and
taxonomy levels. We validate the effectiveness of TM-HGNN by conducting
extensive experiments with MIMIC-III dataset on benchmark in-hospital-mortality
prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Video Is Worth 4096 Tokens: Verbalize Story Videos To Understand Them In Zero Shot. (arXiv:2305.09758v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09758">
<div class="article-summary-box-inner">
<span><p>Multimedia content, such as advertisements and story videos, exhibit a rich
blend of creativity and multiple modalities. They incorporate elements like
text, visuals, audio, and storytelling techniques, employing devices like
emotions, symbolism, and slogans to convey meaning. While previous research in
multimedia understanding has focused mainly on videos with specific actions
like cooking, there is a dearth of large annotated training datasets, hindering
the development of supervised learning models with satisfactory performance for
real-world applications. However, the rise of large language models (LLMs) has
witnessed remarkable zero-shot performance in various natural language
processing (NLP) tasks, such as emotion classification, question-answering, and
topic classification. To bridge this performance gap in multimedia
understanding, we propose verbalizing story videos to generate their
descriptions in natural language and then performing video-understanding tasks
on the generated story as opposed to the original video. Through extensive
experiments on five video-understanding tasks, we demonstrate that our method,
despite being zero-shot, achieves significantly better results than supervised
baselines for video understanding. Further, alleviating a lack of story
understanding benchmarks, we publicly release the first dataset on a crucial
task in computational social science, persuasion strategy identification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Application-Agnostic Language Modeling for On-Device ASR. (arXiv:2305.09764v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09764">
<div class="article-summary-box-inner">
<span><p>On-device automatic speech recognition systems face several challenges
compared to server-based systems. They have to meet stricter constraints in
terms of speed, disk size and memory while maintaining the same accuracy. Often
they have to serve several applications with different distributions at once,
such as communicating with a virtual assistant and speech-to-text. The simplest
solution to serve multiple applications is to build application-specific
(language) models, but this leads to an increase in memory. Therefore, we
explore different data- and architecture-driven language modeling approaches to
build a single application-agnostic model. We propose two novel feed-forward
architectures that find an optimal trade off between different on-device
constraints. In comparison to the application-specific solution, one of our
novel approaches reduces the disk size by half, while maintaining speed and
accuracy of the original model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing. (arXiv:2305.09770v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09770">
<div class="article-summary-box-inner">
<span><p>While various AI explanation (XAI) methods have been proposed to interpret AI
systems, whether the state-of-the-art XAI methods are practically useful for
humans remains inconsistent findings. To improve the usefulness of XAI methods,
a line of studies identifies the gaps between the diverse and dynamic
real-world user needs with the status quo of XAI methods. Although prior
studies envision mitigating these gaps by integrating multiple XAI methods into
the universal XAI interfaces (e.g., conversational or GUI-based XAI systems),
there is a lack of work investigating how these systems should be designed to
meet practical user needs. In this study, we present ConvXAI, a conversational
XAI system that incorporates multiple XAI types, and empowers users to request
a variety of XAI questions via a universal XAI dialogue interface.
Particularly, we innovatively embed practical user needs (i.e., four principles
grounding on the formative study) into ConvXAI design to improve practical
usefulness. Further, we design the domain-specific language (DSL) to implement
the essential conversational XAI modules and release the core conversational
universal XAI API for generalization. The findings from two within-subjects
studies with 21 users show that ConvXAI is more useful for humans in perceiving
the understanding and writing improvement, and improving the writing process in
terms of productivity and sentence quality. Finally, this work contributes
insight into the design space of useful XAI, reveals humans' XAI usage patterns
with empirical evidence in practice, and identifies opportunities for future
useful XAI work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SpecInfer: Accelerating Generative LLM Serving with Speculative Inference and Token Tree Verification. (arXiv:2305.09781v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09781">
<div class="article-summary-box-inner">
<span><p>The high computational and memory requirements of generative large language
models (LLMs) make it challenging to serve them quickly and cheaply. This paper
introduces SpecInfer, an LLM serving system that accelerates generative LLM
inference with speculative inference and token tree verification. A key insight
behind SpecInfer is to combine various collectively boost-tuned small language
models to jointly predict the LLM's outputs; the predictions are organized as a
token tree, whose nodes each represent a candidate token sequence. The
correctness of all candidate token sequences represented by a token tree is
verified by the LLM in parallel using a novel tree-based parallel decoding
mechanism. SpecInfer uses an LLM as a token tree verifier instead of an
incremental decoder, which significantly reduces the end-to-end latency and
computational requirement for serving generative LLMs while provably preserving
model quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analysis of Visual Question Answering Algorithms with attention model. (arXiv:2305.09782v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09782">
<div class="article-summary-box-inner">
<span><p>Visual question answering (VQA) usesimage processing algorithms to process
the image and natural language processing methods to understand and answer the
question. VQA is helpful to a visually impaired person, can be used for the
security surveillance system and online chatbots that learn from the web. It
uses NLP methods to learn the semantic of the question and to derive the
textual features. Computer vision techniques are used for generating image
representation in such a way that they can identify the objects about which
question is asked. The Attention model tries to mimic the human behavior of
giving attention to a different region of an image according to our
understanding of its context. This paper critically examines and reviews
methods of VQA algorithm such as generation of semantics of text,
identification of objects and answer classification techniques that use the
co-attention approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distilling Semantic Concept Embeddings from Contrastively Fine-Tuned Language Models. (arXiv:2305.09785v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09785">
<div class="article-summary-box-inner">
<span><p>Learning vectors that capture the meaning of concepts remains a fundamental
challenge. Somewhat surprisingly, perhaps, pre-trained language models have
thus far only enabled modest improvements to the quality of such concept
embeddings. Current strategies for using language models typically represent a
concept by averaging the contextualised representations of its mentions in some
corpus. This is potentially sub-optimal for at least two reasons. First,
contextualised word vectors have an unusual geometry, which hampers downstream
tasks. Second, concept embeddings should capture the semantic properties of
concepts, whereas contextualised word vectors are also affected by other
factors. To address these issues, we propose two contrastive learning
strategies, based on the view that whenever two sentences reveal similar
properties, the corresponding contextualised vectors should also be similar.
One strategy is fully unsupervised, estimating the properties which are
expressed in a sentence from the neighbourhood structure of the contextualised
word embeddings. The second strategy instead relies on a distant supervision
signal from ConceptNet. Our experimental results show that the resulting
vectors substantially outperform existing concept embeddings in predicting the
semantic properties of concepts, with the ConceptNet-based strategy achieving
the best results. These findings are furthermore confirmed in a clustering task
and in the downstream task of ontology completion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Ways of Words: The Impact of Word Choice on Information Engagement and Decision Making. (arXiv:2305.09798v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09798">
<div class="article-summary-box-inner">
<span><p>Little research has explored how information engagement (IE), the degree to
which individuals interact with and use information in a manner that manifests
cognitively, behaviorally, and affectively. This study explored the impact of
phrasing, specifically word choice, on IE and decision making. Synthesizing two
theoretical models, User Engagement Theory UET and Information Behavior Theory
IBT, a theoretical framework illustrating the impact of and relationships among
the three IE dimensions of perception, participation, and perseverance was
developed and hypotheses generated. The framework was empirically validated in
a large-scale user study measuring how word choice impacts the dimensions of
IE. The findings provide evidence that IE differs from other forms of
engagement in that it is driven and fostered by the expression of the
information itself, regardless of the information system used to view, interact
with, and use the information. The findings suggest that phrasing can have a
significant effect on the interpretation of and interaction with digital
information, indicating the importance of expression of information, in
particular word choice, on decision making and IE. The research contributes to
the literature by identifying methods for assessment and improvement of IE and
decision making with digital text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mirages: On Anthropomorphism in Dialogue Systems. (arXiv:2305.09800v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09800">
<div class="article-summary-box-inner">
<span><p>Automated dialogue or conversational systems are anthropomorphised by
developers and personified by users. While a degree of anthropomorphism is
inevitable, conscious and unconscious design choices can guide users to
personify them to varying degrees. Encouraging users to relate to automated
systems as if they were human can lead to transparency and trust issues, and
high risk scenarios caused by over-reliance on their outputs. As a result,
natural language processing researchers have begun to investigate factors that
induce personification and develop resources to mitigate such effects. However,
these efforts are fragmented, and many aspects of anthropomorphism have yet to
be considered. In this paper, we discuss the linguistic factors that contribute
to the anthropomorphism of dialogue systems and the harms that can arise,
arguing that it can reinforce stereotypes of gender roles and notions of
acceptable language. We recommend that future efforts towards developing
dialogue systems take particular care in their design, development, release,
and description; and attend to the many linguistic cues that can elicit
personification by users.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Dataset Transferability in Active Learning for Transformers. (arXiv:2305.09807v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09807">
<div class="article-summary-box-inner">
<span><p>Active learning (AL) aims to reduce labeling costs by querying the examples
most beneficial for model learning. While the effectiveness of AL for
fine-tuning transformer-based pre-trained language models (PLMs) has been
demonstrated, it is less clear to what extent the AL gains obtained with one
model transfer to others. We consider the problem of transferability of
actively acquired datasets in text classification and investigate whether AL
gains persist when a dataset built using AL coupled with a specific PLM is used
to train a different PLM. We link the AL dataset transferability to the
similarity of instances queried by the different PLMs and show that AL methods
with similar acquisition sequences produce highly transferable datasets
regardless of the models used. Additionally, we show that the similarity of
acquisition sequences is influenced more by the choice of the AL method than
the choice of the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CPL-NoViD: Context-Aware Prompt-based Learning for Norm Violation Detection in Online Communities. (arXiv:2305.09846v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09846">
<div class="article-summary-box-inner">
<span><p>Detecting norm violations in online communities is critical to maintaining
healthy and safe spaces for online discussions. Existing machine learning
approaches often struggle to adapt to the diverse rules and interpretations
across different communities due to the inherent challenges of fine-tuning
models for such context-specific tasks. In this paper, we introduce
Context-aware Prompt-based Learning for Norm Violation Detection (CPL-NoViD), a
novel method that employs prompt-based learning to detect norm violations
across various types of rules. CPL-NoViD outperforms the baseline by
incorporating context through natural language prompts and demonstrates
improved performance across different rule types. Significantly, it not only
excels in cross-rule-type and cross-community norm violation detection but also
exhibits adaptability in few-shot learning scenarios. Most notably, it
establishes a new state-of-the-art in norm violation detection, surpassing
existing benchmarks. Our work highlights the potential of prompt-based learning
for context-sensitive norm violation detection and paves the way for future
research on more adaptable, context-aware models to better support online
community moderators.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoEdIT: Text Editing by Task-Specific Instruction Tuning. (arXiv:2305.09857v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09857">
<div class="article-summary-box-inner">
<span><p>Text editing or revision is an essential function of the human writing
process. Understanding the capabilities of LLMs for making high-quality
revisions and collaborating with human writers is a critical step toward
building effective writing assistants. With the prior success of LLMs and
instruction tuning, we leverage instruction-tuned LLMs for text revision to
improve the quality of user-generated text and improve the efficiency of the
process. We introduce CoEdIT, a state-of-the-art text editing model for writing
assistance. CoEdIT takes instructions from the user specifying the attributes
of the desired text, such as "Make the sentence simpler" or "Write it in a more
neutral style," and outputs the edited text. We present a large language model
fine-tuned on a diverse collection of task-specific instructions for text
editing (a total of 82K instructions). Our model (1) achieves state-of-the-art
performance on various text editing benchmarks, (2) is competitive with
publicly available largest-sized LLMs trained on instructions while being
$\sim$60x smaller, (3) is capable of generalizing to unseen edit instructions,
and (4) exhibits compositional comprehension abilities to generalize to
instructions containing different combinations of edit actions. Through
extensive qualitative and quantitative analysis, we show that writers prefer
the edits suggested by CoEdIT, relative to other state-of-the-art text editing
models. Our code and dataset are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Graph Completion Models are Few-shot Learners: An Empirical Study of Relation Labeling in E-commerce with LLMs. (arXiv:2305.09858v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09858">
<div class="article-summary-box-inner">
<span><p>Knowledge Graphs (KGs) play a crucial role in enhancing e-commerce system
performance by providing structured information about entities and their
relationships, such as complementary or substitutable relations between
products or product types, which can be utilized in recommender systems.
However, relation labeling in KGs remains a challenging task due to the dynamic
nature of e-commerce domains and the associated cost of human labor. Recently,
breakthroughs in Large Language Models (LLMs) have shown surprising results in
numerous natural language processing tasks. In this paper, we conduct an
empirical study of LLMs for relation labeling in e-commerce KGs, investigating
their powerful learning capabilities in natural language and effectiveness in
predicting relations between product types with limited labeled data. We
evaluate various LLMs, including PaLM and GPT-3.5, on benchmark datasets,
demonstrating their ability to achieve competitive performance compared to
humans on relation labeling tasks using just 1 to 5 labeled examples per
relation. Additionally, we experiment with different prompt engineering
techniques to examine their impact on model performance. Our results show that
LLMs significantly outperform existing KG completion models in relation
labeling for e-commerce KGs and exhibit performance strong enough to replace
human labeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smaller Language Models are Better Black-box Machine-Generated Text Detectors. (arXiv:2305.09859v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09859">
<div class="article-summary-box-inner">
<span><p>With the advent of fluent generative language models that can produce
convincing utterances very similar to those written by humans, distinguishing
whether a piece of text is machine-generated or human-written becomes more
challenging and more important, as such models could be used to spread
misinformation, fake news, fake reviews and to mimic certain authors and
figures. To this end, there have been a slew of methods proposed to detect
machine-generated text. Most of these methods need access to the logits of the
target model or need the ability to sample from the target. One such black-box
detection method relies on the observation that generated text is locally
optimal under the likelihood function of the generator, while human-written
text is not. We find that overall, smaller and partially-trained models are
better universal text detectors: they can more precisely detect text generated
from both small and larger models. Interestingly, we find that whether the
detector and generator were trained on the same data is not critically
important to the detection success. For instance the OPT-125M model has an AUC
of 0.81 in detecting ChatGPT generations, whereas a larger model from the GPT
family, GPTJ-6B, has AUC of 0.45.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Epsilon Sampling Rocks: Investigating Sampling Strategies for \\Minimum Bayes Risk Decoding for Machine Translation. (arXiv:2305.09860v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09860">
<div class="article-summary-box-inner">
<span><p>Recent advances in machine translation (MT) have shown that Minimum Bayes
Risk (MBR) decoding can be a powerful alternative to beam search decoding,
especially when combined with neural-based utility functions. However, the
performance of MBR decoding depends heavily on how and how many candidates are
sampled from the model. In this paper, we explore how different sampling
approaches for generating candidate lists for MBR decoding affect performance.
We evaluate popular sampling approaches, such as ancestral, nucleus, and top-k
sampling. Based on our insights into their limitations, we experiment with the
recently proposed epsilon-sampling approach, which prunes away all tokens with
a probability smaller than epsilon, ensuring that each token in a sample
receives a fair probability mass. Through extensive human evaluations, we
demonstrate that MBR decoding based on epsilon-sampling significantly
outperforms not only beam search decoding, but also MBR decoding with all other
tested sampling methods across four language pairs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explaining black box text modules in natural language with language models. (arXiv:2305.09863v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09863">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have demonstrated remarkable prediction
performance for a growing array of tasks. However, their rapid proliferation
and increasing opaqueness have created a growing need for interpretability.
Here, we ask whether we can automatically obtain natural language explanations
for black box text modules. A "text module" is any function that maps text to a
scalar continuous value, such as a submodule within an LLM or a fitted model of
a brain region. "Black box" indicates that we only have access to the module's
inputs/outputs.
</p>
<p>We introduce Summarize and Score (SASC), a method that takes in a text module
and returns a natural language explanation of the module's selectivity along
with a score for how reliable the explanation is. We study SASC in 3 contexts.
First, we evaluate SASC on synthetic modules and find that it often recovers
ground truth explanations. Second, we use SASC to explain modules found within
a pre-trained BERT model, enabling inspection of the model's internals.
Finally, we show that SASC can generate explanations for the response of
individual fMRI voxels to language stimuli, with potential applications to
fine-grained brain mapping. All code for using SASC and reproducing results is
made available on Github.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Jaseci Programming Paradigm and Runtime Stack: Building Scale-out Production Applications Easy and Fast. (arXiv:2305.09864v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09864">
<div class="article-summary-box-inner">
<span><p>Today's production scale-out applications include many sub-application
components, such as storage backends, logging infrastructure and AI models.
These components have drastically different characteristics, are required to
work in collaboration, and interface with each other as microservices. This
leads to increasingly high complexity in developing, optimizing, configuring,
and deploying scale-out applications, raising the barrier to entry for most
individuals and small teams. We developed a novel co-designed runtime system,
Jaseci, and programming language, Jac, which aims to reduce this complexity.
The key design principle throughout Jaseci's design is to raise the level of
abstraction by moving as much of the scale-out data management, microservice
componentization, and live update complexity into the runtime stack to be
automated and optimized automatically. We use real-world AI applications to
demonstrate Jaseci's benefit for application performance and developer
productivity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Similarity Measure of Natural Language Text through Machine Learning and a Keyword-Aware Cross-Encoder-Ranking Summarizer -- A Case Study Using UCGIS GIS&T Body of Knowledge. (arXiv:2305.09877v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09877">
<div class="article-summary-box-inner">
<span><p>Initiated by the University Consortium of Geographic Information Science
(UCGIS), GIS&amp;T Body of Knowledge (BoK) is a community-driven endeavor to
define, develop, and document geospatial topics related to geographic
information science and technologies (GIS&amp;T). In recent years, GIS&amp;T BoK has
undergone rigorous development in terms of its topic re-organization and
content updating, resulting in a new digital version of the project. While the
BoK topics provide useful materials for researchers and students to learn about
GIS, the semantic relationships among the topics, such as semantic similarity,
should also be identified so that a better and automated topic navigation can
be achieved. Currently, the related topics are either defined manually by
editors or authors, which may result in an incomplete assessment of topic
relationship. To address this challenge, our research evaluates the
effectiveness of multiple natural language processing (NLP) techniques in
extracting semantics from text, including both deep neural networks and
traditional machine learning approaches. Besides, a novel text summarization -
KACERS (Keyword-Aware Cross-Encoder-Ranking Summarizer) - is proposed to
generate a semantic summary of scientific publications. By identifying the
semantic linkages among key topics, this work provides guidance for future
development and content organization of the GIS&amp;T BoK project. It also offers a
new perspective on the use of machine learning techniques for analyzing
scientific publications, and demonstrate the potential of KACERS summarizer in
semantic understanding of long text documents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Clustering-Aware Negative Sampling for Unsupervised Sentence Representation. (arXiv:2305.09892v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09892">
<div class="article-summary-box-inner">
<span><p>Contrastive learning has been widely studied in sentence representation
learning. However, earlier works mainly focus on the construction of positive
examples, while in-batch samples are often simply treated as negative examples.
This approach overlooks the importance of selecting appropriate negative
examples, potentially leading to a scarcity of hard negatives and the inclusion
of false negatives. To address these issues, we propose ClusterNS
(Clustering-aware Negative Sampling), a novel method that incorporates cluster
information into contrastive learning for unsupervised sentence representation
learning. We apply a modified K-means clustering algorithm to supply hard
negatives and recognize in-batch false negatives during training, aiming to
solve the two issues in one unified framework. Experiments on semantic textual
similarity (STS) tasks demonstrate that our proposed ClusterNS compares
favorably with baselines in unsupervised sentence representation learning. Our
code has been made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Balancing Lexical and Semantic Quality in Abstractive Summarization. (arXiv:2305.09898v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09898">
<div class="article-summary-box-inner">
<span><p>An important problem of the sequence-to-sequence neural models widely used in
abstractive summarization is exposure bias. To alleviate this problem,
re-ranking systems have been applied in recent years. Despite some performance
improvements, this approach remains underexplored. Previous works have mostly
specified the rank through the ROUGE score and aligned candidate summaries, but
there can be quite a large gap between the lexical overlap metric and semantic
similarity. In this paper, we propose a novel training method in which a
re-ranker balances the lexical and semantic quality. We further newly define
false positives in ranking and present a strategy to reduce their influence.
Experiments on the CNN/DailyMail and XSum datasets show that our method can
estimate the meaning of summaries without seriously degrading the lexical
aspect. More specifically, it achieves an 89.67 BERTScore on the CNN/DailyMail
dataset, reaching new state-of-the-art performance. Our code is publicly
available at https://github.com/jeewoo1025/BalSum.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Equivariant Few-Shot Learning from Pretrained Models. (arXiv:2305.09900v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09900">
<div class="article-summary-box-inner">
<span><p>Efficient transfer learning algorithms are key to the success of foundation
models on diverse downstream tasks even with limited data. Recent works of
\cite{basu2022equi} and \cite{kaba2022equivariance} propose group averaging
(\textit{equitune}) and optimization-based methods, respectively, over features
from group-transformed inputs to obtain equivariant outputs from
non-equivariant neural networks. While \cite{kaba2022equivariance} are only
concerned with training from scratch, we find that equitune performs poorly on
equivariant zero-shot tasks despite good finetuning results. We hypothesize
that this is because pretrained models provide better quality features for
certain transformations than others and simply averaging them is deleterious.
Hence, we propose $\lambda$-\textit{equitune} that averages the features using
\textit{importance weights}, $\lambda$s. These weights are learned directly
from the data using a small neural network, leading to excellent zero-shot and
finetuned results that outperform equitune. Further, we prove that
$\lambda$-equitune is equivariant and a universal approximator of equivariant
functions. Additionally, we show that the method of \cite{kaba2022equivariance}
used with appropriate loss functions, which we call \textit{equizero}, also
gives excellent zero-shot and finetuned performance. Both equitune and equizero
are special cases of $\lambda$-equitune. To show the simplicity and generality
of our method, we validate on a wide range of diverse applications and models
such as 1) image classification using CLIP, 2) deep Q-learning, 3) fairness in
natural language generation (NLG), 4) compositional generalization in
languages, and 5) image classification using pretrained CNNs such as Resnet and
Alexnet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"I'm fully who I am": Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation. (arXiv:2305.09941v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09941">
<div class="article-summary-box-inner">
<span><p>Transgender and non-binary (TGNB) individuals disproportionately experience
discrimination and exclusion from daily life. Given the recent popularity and
adoption of language generation technologies, the potential to further
marginalize this population only grows. Although a multitude of NLP fairness
literature focuses on illuminating and addressing gender biases, assessing
gender harms for TGNB identities requires understanding how such identities
uniquely interact with societal gender norms and how they differ from gender
binary-centric perspectives. Such measurement frameworks inherently require
centering TGNB voices to help guide the alignment between gender-inclusive NLP
and whom they are intended to serve. Towards this goal, we ground our work in
the TGNB community and existing interdisciplinary literature to assess how the
social reality surrounding experienced marginalization by TGNB persons
contributes to and persists within Open Language Generation (OLG). By first
understanding their marginalization stressors, we evaluate (1) misgendering and
(2) harmful responses to gender disclosure. To do this, we introduce the TANGO
dataset, comprising of template-based text curated from real-world text within
a TGNB-oriented community. We discover a dominance of binary gender norms
within the models; LLMs least misgendered subjects in generated text when
triggered by prompts whose subjects used binary pronouns. Meanwhile,
misgendering was most prevalent when triggering generation with singular they
and neopronouns. When prompted with gender disclosures, LLM text contained
stigmatizing language and scored most toxic when triggered by TGNB gender
disclosure. Our findings warrant further research on how TGNB harms manifest in
LLMs and serve as a broader case study toward concretely grounding the design
of gender-inclusive AI in community voices and interdisciplinary literature.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge. (arXiv:2305.09955v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09955">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) are increasingly adopted for knowledge-intensive
tasks and contexts. Existing approaches improve the knowledge capabilities of
general-purpose LLMs through retrieval or generated knowledge prompting, but
they fall short of reflecting two key properties of knowledge-rich models:
knowledge should be modular, ever-growing, sourced from diverse domains;
knowledge acquisition and production should be a collaborative process, where
diverse stakeholders contribute new information. To this end, we propose CooK,
a novel framework to empower general-purpose large language models with modular
and collaboratively sourced knowledge. We first introduce specialized language
models, autoregressive models trained on corpora from a wide range of domains
and sources. These specialized LMs serve as parametric knowledge repositories
that are later prompted to generate background knowledge for general-purpose
LLMs. We then propose three knowledge filters to dynamically select and retain
information in generated documents by controlling for relevance, brevity, and
factuality. Finally, we propose bottom-up and top-down knowledge integration
approaches to augment general-purpose LLMs with the curated (relevant, factual)
knowledge from community-driven specialized LMs that enable multi-domain
knowledge synthesis and on-demand knowledge requests. Through extensive
experiments, we demonstrate that CooK achieves state-of-the-art performance on
six benchmark datasets. Our results highlight the potential of enriching
general-purpose LLMs with evolving and modular knowledge -- relevant knowledge
that can be continuously updated through the collective efforts of the research
community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smart Word Suggestions for Writing Assistance. (arXiv:2305.09975v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09975">
<div class="article-summary-box-inner">
<span><p>Enhancing word usage is a desired feature for writing assistance. To further
advance research in this area, this paper introduces "Smart Word Suggestions"
(SWS) task and benchmark. Unlike other works, SWS emphasizes end-to-end
evaluation and presents a more realistic writing assistance scenario. This task
involves identifying words or phrases that require improvement and providing
substitution suggestions. The benchmark includes human-labeled data for
testing, a large distantly supervised dataset for training, and the framework
for evaluation. The test data includes 1,000 sentences written by English
learners, accompanied by over 16,000 substitution suggestions annotated by 10
native speakers. The training dataset comprises over 3.7 million sentences and
12.7 million suggestions generated through rules. Our experiments with seven
baselines demonstrate that SWS is a challenging task. Based on experimental
analysis, we suggest potential directions for future research on SWS. The
dataset and related codes is available at
https://github.com/microsoft/SmartWordSuggestions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual Semantic Knowledge Composed Multimodal Dialog Systems. (arXiv:2305.09990v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09990">
<div class="article-summary-box-inner">
<span><p>Textual response generation is an essential task for multimodal task-oriented
dialog systems.Although existing studies have achieved fruitful progress, they
still suffer from two critical limitations: 1) focusing on the attribute
knowledge but ignoring the relation knowledge that can reveal the correlations
between different entities and hence promote the response generation}, and 2)
only conducting the cross-entropy loss based output-level supervision but
lacking the representation-level regularization. To address these limitations,
we devise a novel multimodal task-oriented dialog system (named MDS-S2).
Specifically, MDS-S2 first simultaneously acquires the context related
attribute and relation knowledge from the knowledge base, whereby the
non-intuitive relation knowledge is extracted by the n-hop graph walk.
Thereafter, considering that the attribute knowledge and relation knowledge can
benefit the responding to different levels of questions, we design a
multi-level knowledge composition module in MDS-S2 to obtain the latent
composed response representation. Moreover, we devise a set of latent query
variables to distill the semantic information from the composed response
representation and the ground truth response representation, respectively, and
thus conduct the representation-level semantic regularization. Extensive
experiments on a public dataset have verified the superiority of our proposed
MDS-S2. We have released the codes and parameters to facilitate the research
community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling. (arXiv:2305.09993v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09993">
<div class="article-summary-box-inner">
<span><p>We introduce Reprompting, an iterative sampling algorithm that searches for
the Chain-of-Thought (CoT) recipes for a given task without human intervention.
Through Gibbs sampling, we infer CoT recipes that work consistently well for a
set of training samples. Our method iteratively samples new recipes using
previously sampled solutions as parent prompts to solve other training
problems. On five Big-Bench Hard tasks that require multi-step reasoning,
Reprompting achieves consistently better performance than the zero-shot,
few-shot, and human-written CoT baselines. Reprompting can also facilitate
transfer of knowledge from a stronger model to a weaker model leading to
substantially improved performance of the weaker model. Overall, Reprompting
brings up to +17 point improvements over the previous state-of-the-art method
that uses human-written CoT prompts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DinoSR: Self-Distillation and Online Clustering for Self-supervised Speech Representation Learning. (arXiv:2305.10005v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10005">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce self-distillation and online clustering for
self-supervised speech representation learning (DinoSR) which combines masked
language modeling, self-distillation, and online clustering. We show that these
concepts complement each other and result in a strong representation learning
model for speech. DinoSR first extracts contextualized embeddings from the
input audio with a teacher network, then runs an online clustering system on
the embeddings to yield a machine-discovered phone inventory, and finally uses
the discretized tokens to guide a student network. We show that DinoSR
surpasses previous state-of-the-art performance in several downstream tasks,
and provide a detailed analysis of the model and the learned discrete units.
The source code will be made available after the anonymity period.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EfficientSCI: Densely Connected Network with Space-time Factorization for Large-scale Video Snapshot Compressive Imaging. (arXiv:2305.10006v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10006">
<div class="article-summary-box-inner">
<span><p>Video snapshot compressive imaging (SCI) uses a two-dimensional detector to
capture consecutive video frames during a single exposure time. Following this,
an efficient reconstruction algorithm needs to be designed to reconstruct the
desired video frames. Although recent deep learning-based state-of-the-art
(SOTA) reconstruction algorithms have achieved good results in most tasks, they
still face the following challenges due to excessive model complexity and GPU
memory limitations:
</p>
<p>1) these models need high computational cost, and
</p>
<p>2) they are usually unable to reconstruct large-scale video frames at high
compression ratios.
</p>
<p>To address these issues, we develop an {\bf{\em efficient network}} for video
SCI by using {\bf {\em dense connections and space-time factorization
mechanism}} within a single residual block, dubbed {\bf \emph{EfficientSCI}}.
The EfficientSCI network can well establish spatial-temporal correlation by
using {\bf {\em convolution in the spatial domain and Transformer in the
temporal domain}}, respectively. We are the first time to show that an UHD
color video with high compression ratio can be reconstructed from a snapshot 2D
measurement using a single end-to-end deep learning model with PSNR above 32
dB. Extensive results on both simulation and real data show that our method
significantly outperforms all previous SOTA algorithms with better real-time
performance. The code is at
\url{https://github.com/ucaswangls/EfficientSCI.git}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AD-KD: Attribution-Driven Knowledge Distillation for Language Model Compression. (arXiv:2305.10010v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10010">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation has attracted a great deal of interest recently to
compress pre-trained language models. However, existing knowledge distillation
methods suffer from two limitations. First, the student model simply imitates
the teacher's behavior while ignoring the underlying reasoning. Second, these
methods usually focus on the transfer of sophisticated model-specific knowledge
but overlook data-specific knowledge. In this paper, we present a novel
attribution-driven knowledge distillation approach, which explores the
token-level rationale behind the teacher model based on Integrated Gradients
(IG) and transfers attribution knowledge to the student model. To enhance the
knowledge transfer of model reasoning and generalization, we further explore
multi-view attribution distillation on all potential decisions of the teacher.
Comprehensive experiments are conducted with BERT on the GLUE benchmark. The
experimental results demonstrate the superior performance of our approach to
several state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Gradient Descent Meets Derivative-Free Optimization: A Match Made in Black-Box Scenario. (arXiv:2305.10013v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10013">
<div class="article-summary-box-inner">
<span><p>Large pre-trained language models (PLMs) have garnered significant attention
for their versatility and potential for solving a wide spectrum of natural
language processing (NLP) tasks. However, the cost of running these PLMs may be
prohibitive. Furthermore, PLMs may not be open-sourced due to commercial
considerations and potential risks of misuse, such as GPT-3. The parameters and
gradients of PLMs are unavailable in this scenario. To solve the issue,
black-box tuning has been proposed, which utilizes derivative-free optimization
(DFO), instead of gradient descent, for training task-specific continuous
prompts. However, these gradient-free methods still exhibit a significant gap
compared to gradient-based methods. In this paper, we introduce gradient
descent into black-box tuning scenario through knowledge distillation.
Furthermore, we propose a novel method GDFO, which integrates gradient descent
and derivative-free optimization to optimize task-specific continuous prompts
in a harmonized manner. Experimental results show that GDFO can achieve
significant performance gains over previous state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark. (arXiv:2305.10036v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10036">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have demonstrated powerful capabilities in both
text understanding and generation. Companies have begun to offer Embedding as a
Service (EaaS) based on these LLMs, which can benefit various natural language
processing (NLP) tasks for customers. However, previous studies have shown that
EaaS is vulnerable to model extraction attacks, which can cause significant
losses for the owners of LLMs, as training these models is extremely expensive.
To protect the copyright of LLMs for EaaS, we propose an Embedding Watermark
method called EmbMarker that implants backdoors on embeddings. Our method
selects a group of moderate-frequency words from a general text corpus to form
a trigger set, then selects a target embedding as the watermark, and inserts it
into the embeddings of texts containing trigger words as the backdoor. The
weight of insertion is proportional to the number of trigger words included in
the text. This allows the watermark backdoor to be effectively transferred to
EaaS-stealer's model for copyright verification while minimizing the adverse
impact on the original embeddings' utility. Our extensive experiments on
various datasets show that our method can effectively protect the copyright of
EaaS models without compromising service quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Language Models Solve Graph Problems in Natural Language?. (arXiv:2305.10037v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10037">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) are increasingly adopted for a variety of tasks
with implicit graphical structures, such as planning in robotics, multi-hop
question answering or knowledge probing, structured commonsense reasoning, and
more. While LLMs have advanced the state-of-the-art on these tasks with
structure implications, whether LLMs could explicitly process textual
descriptions of graphs and structures, map them to grounded conceptual spaces,
and perform structured operations remains underexplored. To this end, we
propose NLGraph (Natural Language Graph), a comprehensive benchmark of
graph-based problem solving designed in natural language. NLGraph contains
29,370 problems, covering eight graph reasoning tasks with varying complexity
from simple tasks such as connectivity and shortest path up to complex problems
such as maximum flow and simulating graph neural networks. We evaluate LLMs
(GPT-3/4) with various prompting approaches on the NLGraph benchmark and find
that 1) language models do demonstrate preliminary graph reasoning abilities,
2) the benefit of advanced prompting and in-context learning diminishes on more
complex graph problems, while 3) LLMs are also (un)surprisingly brittle in the
face of spurious correlations in graph and problem settings. We then propose
Build-a-Graph Prompting and Algorithmic Prompting, two instruction-based
approaches to enhance LLMs in solving natural language graph problems.
Build-a-Graph and Algorithmic prompting improve the performance of LLMs on
NLGraph by 3.07% to 16.85% across multiple tasks and settings, while how to
solve the most complicated graph reasoning tasks in our setup with language
models remains an open research question. The NLGraph benchmark and evaluation
code are available at https://github.com/Arthur-Heng/NLGraph.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Probing the Role of Positional Information in Vision-Language Models. (arXiv:2305.10046v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10046">
<div class="article-summary-box-inner">
<span><p>In most Vision-Language models (VL), the understanding of the image structure
is enabled by injecting the position information (PI) about objects in the
image. In our case study of LXMERT, a state-of-the-art VL model, we probe the
use of the PI in the representation and study its effect on Visual Question
Answering. We show that the model is not capable of leveraging the PI for the
image-text matching task on a challenge set where only position differs. Yet,
our experiments with probing confirm that the PI is indeed present in the
representation. We introduce two strategies to tackle this: (i) Positional
Information Pre-training and (ii) Contrastive Learning on PI using
Cross-Modality Matching. Doing so, the model can correctly classify if images
with detailed PI statements match. Additionally to the 2D information from
bounding boxes, we introduce the object's depth as new feature for a better
object localization in the space. Even though we were able to improve the model
properties as defined by our probes, it only has a negligible effect on the
downstream performance. Our results thus highlight an important issue of
multimodal modeling: the mere presence of information detectable by a probing
classifier is not a guarantee that the information is available in a
cross-modal setup.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Use of a Taxonomy of Empathetic Response Intents to Control and Interpret Empathy in Neural Chatbots. (arXiv:2305.10096v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10096">
<div class="article-summary-box-inner">
<span><p>A recent trend in the domain of open-domain conversational agents is enabling
them to converse empathetically to emotional prompts. Current approaches either
follow an end-to-end approach or condition the responses on similar emotion
labels to generate empathetic responses. But empathy is a broad concept that
refers to the cognitive and emotional reactions of an individual to the
observed experiences of another and it is more complex than mere mimicry of
emotion. Hence, it requires identifying complex human conversational strategies
and dynamics in addition to generic emotions to control and interpret
empathetic responding capabilities of chatbots. In this work, we make use of a
taxonomy of eight empathetic response intents in addition to generic emotion
categories in building a dialogue response generation model capable of
generating empathetic responses in a controllable and interpretable manner. It
consists of two modules: 1) a response emotion/intent prediction module; and 2)
a response generation module. We propose several rule-based and neural
approaches to predict the next response's emotion/intent and generate responses
conditioned on these predicted emotions/intents. Automatic and human evaluation
results emphasize the importance of the use of the taxonomy of empathetic
response intents in producing more diverse and empathetically more appropriate
responses than end-to-end models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Empirical Analysis of Oral and Nasal Vowels of Konkani. (arXiv:2305.10122v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10122">
<div class="article-summary-box-inner">
<span><p>Konkani is a highly nasalised language which makes it unique among Indo-Aryan
languages. This work investigates the acoustic-phonetic properties of Konkani
oral and nasal vowels. For this study, speech samples from six speakers (3 male
and 3 female) were collected. A total of 74 unique sentences were used as a
part of the recording script, 37 each for oral and nasal vowels, respectively.
The final data set consisted of 1135 vowel phonemes. A comparative F1-F2 plot
of Konkani oral and nasal vowels is presented with an experimental result and
formant analysis. The average F1, F2 and F3 values are also reported for the
first time through experimentation for all nasal and oral vowels. This study
can be helpful for the linguistic research on vowels and speech synthesis
systems specific to the Konkani language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Additive manifesto decomposition: A policy domain aware method for understanding party positioning. (arXiv:2305.10136v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10136">
<div class="article-summary-box-inner">
<span><p>Automatic extraction of party (dis)similarities from texts such as party
election manifestos or parliamentary speeches plays an increasing role in
computational political science. However, existing approaches are fundamentally
limited to targeting only global party (dis)-similarity: they condense the
relationship between a pair of parties into a single figure, their similarity.
In aggregating over all policy domains (e.g., health or foreign policy), they
do not provide any qualitative insights into which domains parties agree or
disagree on. This paper proposes a workflow for estimating policy domain aware
party similarity that overcomes this limitation. The workflow covers (a)
definition of suitable policy domains; (b) automatic labeling of domains, if no
manual labels are available; (c) computation of domain-level similarities and
aggregation at a global level; (d) extraction of interpretable party positions
on major policy axes via multidimensional scaling. We evaluate our workflow on
manifestos from the German federal elections. We find that our method (a)
yields high correlation when predicting party similarity at a global level and
(b) provides accurate party-specific positions, even with automatically
labelled policy domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback. (arXiv:2305.10142v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10142">
<div class="article-summary-box-inner">
<span><p>We study whether multiple large language models (LLMs) can autonomously
improve each other in a negotiation game by playing, reflecting, and
criticizing. We are interested in this question because if LLMs were able to
improve each other, it would imply the possibility of creating strong AI agents
with minimal human intervention. We ask two LLMs to negotiate with each other,
playing the roles of a buyer and a seller, respectively. They aim to reach a
deal with the buyer targeting a lower price and the seller a higher one. A
third language model, playing the critic, provides feedback to a player to
improve the player's negotiation strategies. We let the two agents play
multiple rounds, using previous negotiation history and AI feedback as
in-context demonstrations to improve the model's negotiation strategy
iteratively. We use different LLMs (GPT and Claude) for different roles and use
the deal price as the evaluation metric. Our experiments reveal multiple
intriguing findings: (1) Only a subset of the language models we consider can
self-play and improve the deal price from AI feedback, weaker models either do
not understand the game's rules or cannot incorporate AI feedback for further
improvement. (2) Models' abilities to learn from the feedback differ when
playing different roles. For example, it is harder for Claude-instant to
improve as the buyer than as the seller. (3) When unrolling the game to
multiple rounds, stronger agents can consistently improve their performance by
meaningfully using previous experiences and iterative AI feedback, yet have a
higher risk of breaking the deal. We hope our work provides insightful initial
explorations of having models autonomously improve each other with game playing
and AI feedback.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Grained Knowledge Retrieval for End-to-End Task-Oriented Dialog. (arXiv:2305.10149v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10149">
<div class="article-summary-box-inner">
<span><p>Retrieving proper domain knowledge from an external database lies at the
heart of end-to-end task-oriented dialog systems to generate informative
responses. Most existing systems blend knowledge retrieval with response
generation and optimize them with direct supervision from reference responses,
leading to suboptimal retrieval performance when the knowledge base becomes
large-scale. To address this, we propose to decouple knowledge retrieval from
response generation and introduce a multi-grained knowledge retriever (MAKER)
that includes an entity selector to search for relevant entities and an
attribute selector to filter out irrelevant attributes. To train the retriever,
we propose a novel distillation objective that derives supervision signals from
the response generator. Experiments conducted on three standard benchmarks with
both small and large-scale knowledge bases demonstrate that our retriever
performs knowledge retrieval more effectively than existing methods. Our code
has been made publicly
available.\footnote{https://github.<a href="/abs/com/1890730">com/1890730</a>5772/MAKER}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Iterated learning and communication jointly explain efficient color naming systems. (arXiv:2305.10154v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10154">
<div class="article-summary-box-inner">
<span><p>It has been argued that semantic systems reflect pressure for efficiency, and
a current debate concerns the cultural evolutionary process that produces this
pattern. We consider efficiency as instantiated in the Information Bottleneck
(IB) principle, and a model of cultural evolution that combines iterated
learning and communication. We show that this model, instantiated in neural
networks, converges to color naming systems that are efficient in the IB sense
and similar to human color naming systems. We also show that iterated learning
alone, and communication alone, do not yield the same outcome as clearly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Personality Understanding of Fictional Characters during Book Reading. (arXiv:2305.10156v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10156">
<div class="article-summary-box-inner">
<span><p>Comprehending characters' personalities is a crucial aspect of story reading.
As readers engage with a story, their understanding of a character evolves
based on new events and information; and multiple fine-grained aspects of
personalities can be perceived. This leads to a natural problem of situated and
fine-grained personality understanding. The problem has not been studied in the
NLP field, primarily due to the lack of appropriate datasets mimicking the
process of book reading. We present the first labeled dataset PersoNet for this
problem. Our novel annotation strategy involves annotating user notes from
online reading apps as a proxy for the original books. Experiments and human
studies indicate that our dataset construction is both efficient and accurate;
and our task heavily relies on long-term context to achieve accurate
predictions for both machines and humans. The dataset is available at
https://github.com/Gorov/personet_acl23.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stop Uploading Test Data in Plain Text: Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks. (arXiv:2305.10160v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10160">
<div class="article-summary-box-inner">
<span><p>Data contamination has become especially prevalent and challenging with the
rise of models pretrained on very large, automatically-crawled corpora. For
closed models, the training data becomes a trade secret, and even for open
models, it is not trivial to ascertain whether a particular test instance has
been compromised. Strategies such as live leaderboards with hidden answers, or
using test data which is guaranteed to be unseen, are expensive and become
fragile with time. Assuming that all relevant actors value clean test data and
will cooperate to mitigate data contamination, what can be done? We propose
three strategies that can make a difference: (1) Test data made public should
be encrypted with a public key and licensed to disallow derivative
distribution; (2) demand training exclusion controls from closed API holders,
and protect your test data by refusing to evaluate until demands are met; (3)
in case of test data based on internet text, avoid data which appears with its
solution on the internet, and release the context of internet-derived data
along with the data. These strategies are practical and can be effective in
preventing data contamination and allowing trustworthy evaluation of models'
capabilities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model. (arXiv:2305.10163v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10163">
<div class="article-summary-box-inner">
<span><p>Generative Pre-Training (GPT) models like ChatGPT have demonstrated
exceptional performance in various Natural Language Processing (NLP) tasks.
Although ChatGPT has been integrated into the overall workflow to boost
efficiency in many domains, the lack of flexibility in the finetuning process
hinders its applications in areas that demand extensive domain expertise and
semantic knowledge, such as healthcare. In this paper, we evaluate ChatGPT on
the China National Medical Licensing Examination (CNMLE) and propose a novel
approach to improve ChatGPT from two perspectives: integrating medical domain
knowledge and enabling few-shot learning. By using a simple but effective
retrieval method, medical background knowledge is extracted as semantic
instructions to guide the inference of ChatGPT. Similarly, relevant medical
questions are identified and fed as demonstrations to ChatGPT. Experimental
results show that directly applying ChatGPT fails to qualify the CNMLE at a
score of 51 (i.e., only 51\% of questions are answered correctly). While our
knowledge-enhanced model achieves a high score of 70 on CNMLE-2022 which not
only passes the qualification but also surpasses the average score of humans
(61). This research demonstrates the potential of knowledge-enhanced ChatGPT to
serve as versatile medical assistants, capable of analyzing real-world medical
problems in a more accessible, user-friendly, and adaptable manner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pragmatic Reasoning in Structured Signaling Games. (arXiv:2305.10167v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10167">
<div class="article-summary-box-inner">
<span><p>In this work we introduce a structured signaling game, an extension of the
classical signaling game with a similarity structure between meanings in the
context, along with a variant of the Rational Speech Act (RSA) framework which
we call structured-RSA (sRSA) for pragmatic reasoning in structured domains. We
explore the behavior of the sRSA in the domain of color and show that pragmatic
agents using sRSA on top of semantic representations, derived from the World
Color Survey, attain efficiency very close to the information theoretic limit
after only 1 or 2 levels of recursion. We also explore the interaction between
pragmatic reasoning and learning in multi-agent reinforcement learning
framework. Our results illustrate that artificial agents using sRSA develop
communication closer to the information theoretic frontier compared to agents
using RSA and just reinforcement learning. We also find that the ambiguity of
the semantic representation increases as the pragmatic agents are allowed to
perform deeper reasoning about each other during learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-enhanced Mixed-initiative Dialogue System for Emotional Support Conversations. (arXiv:2305.10172v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10172">
<div class="article-summary-box-inner">
<span><p>Unlike empathetic dialogues, the system in emotional support conversations
(ESC) is expected to not only convey empathy for comforting the help-seeker,
but also proactively assist in exploring and addressing their problems during
the conversation. In this work, we study the problem of mixed-initiative ESC
where the user and system can both take the initiative in leading the
conversation. Specifically, we conduct a novel analysis on mixed-initiative ESC
systems with a tailor-designed schema that divides utterances into different
types with speaker roles and initiative types. Four emotional support metrics
are proposed to evaluate the mixed-initiative interactions. The analysis
reveals the necessity and challenges of building mixed-initiative ESC systems.
In the light of this, we propose a knowledge-enhanced mixed-initiative
framework (KEMI) for ESC, which retrieves actual case knowledge from a
large-scale mental health knowledge graph for generating mixed-initiative
responses. Experimental results on two ESC datasets show the superiority of
KEMI in both content-preserving evaluation and mixed initiative related
analyses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Variable-length Neural Interlingua Representations for Zero-shot Neural Machine Translation. (arXiv:2305.10190v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10190">
<div class="article-summary-box-inner">
<span><p>The language-independency of encoded representations within multilingual
neural machine translation (MNMT) models is crucial for their generalization
ability on zero-shot translation. Neural interlingua representations have been
shown as an effective method for achieving this. However, fixed-length neural
interlingua representations introduced in previous work can limit its
flexibility and representation ability. In this study, we introduce a novel
method to enhance neural interlingua representations by making their length
variable, thereby overcoming the constraint of fixed-length neural interlingua
representations. Our empirical results on zero-shot translation on OPUS, IWSLT,
and Europarl datasets demonstrate stable model convergence and superior
zero-shot translation results compared to fixed-length neural interlingua
representations. However, our analysis reveals the suboptimal efficacy of our
approach in translating from certain source languages, wherein we pinpoint the
defective model component in our proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Distress Support Dialogue Responses with Motivational Interviewing Strategy. (arXiv:2305.10195v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10195">
<div class="article-summary-box-inner">
<span><p>AI-driven chatbots have become an emerging solution to address psychological
distress. Due to the lack of psychotherapeutic data, researchers use dialogues
scraped from online peer support forums to train them. But since the responses
in such platforms are not given by professionals, they contain both conforming
and non-conforming responses. In this work, we attempt to recognize these
conforming and non-conforming response types present in online distress-support
dialogues using labels adapted from a well-established behavioral coding scheme
named Motivational Interviewing Treatment Integrity (MITI) code and show how
some response types could be rephrased into a more MI adherent form that can,
in turn, enable chatbot responses to be more compliant with the MI strategy. As
a proof of concept, we build several rephrasers by fine-tuning Blender and GPT3
to rephrase MI non-adherent "Advise without permission" responses into "Advise
with permission". We show how this can be achieved with the construction of
pseudo-parallel corpora avoiding costs for human labor. Through automatic and
human evaluation we show that in the presence of less training data, techniques
such as prompting and data augmentation can be used to produce substantially
good rephrasings that reflect the intended style and preserve the content of
the original text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Zero Pronoun Translation. (arXiv:2305.10196v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10196">
<div class="article-summary-box-inner">
<span><p>Zero pronouns (ZPs) are frequently omitted in pro-drop languages (e.g.
Chinese, Hungarian, and Hindi), but should be recalled in non-pro-drop
languages (e.g. English). This phenomenon has been studied extensively in
machine translation (MT), as it poses a significant challenge for MT systems
due to the difficulty in determining the correct antecedent for the pronoun.
This survey paper highlights the major works that have been undertaken in zero
pronoun translation (ZPT) after the neural revolution, so that researchers can
recognise the current state and future directions of this field. We provide an
organisation of the literature based on evolution, dataset, method and
evaluation. In addition, we compare and analyze competing models and evaluation
metrics on different benchmarks. We uncover a number of insightful findings
such as: 1) ZPT is in line with the development trend of large language model;
2) data limitation causes learning bias in languages and domains; 3)
performance improvements are often reported on single benchmarks, but advanced
methods are still far from real-world use; 4) general-purpose metrics are not
reliable on nuances and complexities of ZPT, emphasizing the necessity of
targeted metrics; 5) apart from commonly-cited errors, ZPs will cause risks of
gender bias.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shielded Representations: Protecting Sensitive Attributes Through Iterative Gradient-Based Projection. (arXiv:2305.10204v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10204">
<div class="article-summary-box-inner">
<span><p>Natural language processing models tend to learn and encode social biases
present in the data. One popular approach for addressing such biases is to
eliminate encoded information from the model's representations. However,
current methods are restricted to removing only linearly encoded information.
In this work, we propose Iterative Gradient-Based Projection (IGBP), a novel
method for removing non-linear encoded concepts from neural representations.
Our method consists of iteratively training neural classifiers to predict a
particular attribute we seek to eliminate, followed by a projection of the
representation on a hypersurface, such that the classifiers become oblivious to
the target attribute. We evaluate the effectiveness of our method on the task
of removing gender and race information as sensitive attributes. Our results
demonstrate that IGBP is effective in mitigating bias through intrinsic and
extrinsic evaluations, with minimal impact on downstream task accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OpenSLU: A Unified, Modularized, and Extensible Toolkit for Spoken Language Understanding. (arXiv:2305.10231v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10231">
<div class="article-summary-box-inner">
<span><p>Spoken Language Understanding (SLU) is one of the core components of a
task-oriented dialogue system, which aims to extract the semantic meaning of
user queries (e.g., intents and slots). In this work, we introduce OpenSLU, an
open-source toolkit to provide a unified, modularized, and extensible toolkit
for spoken language understanding. Specifically, OpenSLU unifies 10 SLU models
for both single-intent and multi-intent scenarios, which support both
non-pretrained and pretrained models simultaneously. Additionally, OpenSLU is
highly modularized and extensible by decomposing the model architecture,
inference, and learning process into reusable modules, which allows researchers
to quickly set up SLU experiments with highly flexible configurations. OpenSLU
is implemented based on PyTorch, and released at
\url{https://github.com/LightChen233/OpenSLU}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A quantitative study of NLP approaches to question difficulty estimation. (arXiv:2305.10236v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10236">
<div class="article-summary-box-inner">
<span><p>Recent years witnessed an increase in the amount of research on the task of
Question Difficulty Estimation from Text QDET with Natural Language Processing
(NLP) techniques, with the goal of targeting the limitations of traditional
approaches to question calibration. However, almost the entirety of previous
research focused on single silos, without performing quantitative comparisons
between different models or across datasets from different educational domains.
In this work, we aim at filling this gap, by quantitatively analyzing several
approaches proposed in previous research, and comparing their performance on
three publicly available real world datasets containing questions of different
types from different educational domains. Specifically, we consider reading
comprehension Multiple Choice Questions (MCQs), science MCQs, and math
questions. We find that Transformer based models are the best performing across
different educational domains, with DistilBERT performing almost as well as
BERT, and that they outperform other approaches even on smaller datasets. As
for the other models, the hybrid ones often outperform the ones based on a
single type of features, the ones based on linguistic features perform well on
reading comprehension questions, while frequency based features (TF-IDF) and
word embeddings (word2vec) perform better in domain knowledge assessment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MemoryBank: Enhancing Large Language Models with Long-Term Memory. (arXiv:2305.10250v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10250">
<div class="article-summary-box-inner">
<span><p>Revolutionary advancements in Large Language Models have drastically reshaped
our interactions with artificial intelligence systems. Despite this, a notable
hindrance remains-the deficiency of a long-term memory mechanism within these
models. This shortfall becomes increasingly evident in situations demanding
sustained interaction, such as personal companion systems and psychological
counseling. Therefore, we propose MemoryBank, a novel memory mechanism tailored
for LLMs. MemoryBank enables the models to summon relevant memories,
continually evolve through continuous memory updates, comprehend, and adapt to
a user personality by synthesizing information from past interactions. To mimic
anthropomorphic behaviors and selectively preserve memory, MemoryBank
incorporates a memory updating mechanism, inspired by the Ebbinghaus Forgetting
Curve theory, which permits the AI to forget and reinforce memory based on time
elapsed and the relative significance of the memory, thereby offering a
human-like memory mechanism. MemoryBank is versatile in accommodating both
closed-source models like ChatGPT and open-source models like ChatGLM. We
exemplify application of MemoryBank through the creation of an LLM-based
chatbot named SiliconFriend in a long-term AI Companion scenario. Further tuned
with psychological dialogs, SiliconFriend displays heightened empathy in its
interactions. Experiment involves both qualitative analysis with real-world
user dialogs and quantitative analysis with simulated dialogs. In the latter,
ChatGPT acts as users with diverse characteristics and generates long-term
dialog contexts covering a wide array of topics. The results of our analysis
reveal that SiliconFriend, equipped with MemoryBank, exhibits a strong
capability for long-term companionship as it can provide emphatic response,
recall relevant memories and understand user personality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. (arXiv:2305.10263v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10263">
<div class="article-summary-box-inner">
<span><p>Large language models have recently made tremendous progress in a variety of
aspects, e.g., cross-task generalization, instruction following.
Comprehensively evaluating the capability of large language models in multiple
tasks is of great importance. In this paper, we propose M3KE, a Massive
Multi-Level Multi-Subject Knowledge Evaluation benchmark, which is developed to
measure knowledge acquired by Chinese large language models by testing their
multitask accuracy in zero- and few-shot settings. We have collected 20,477
questions from 71 tasks. Our selection covers all major levels of Chinese
education system, ranging from the primary school to college, as well as a wide
variety of subjects, including humanities, history, politics, law, education,
psychology, science, technology, art and religion. All questions are
multiple-choice questions with four options, hence guaranteeing a standardized
and unified assessment process. We've assessed a number of state-of-the-art
open-source Chinese large language models on the proposed benchmark. The size
of these models varies from 335M to 130B parameters. Experiment results
demonstrate that they perform significantly worse than GPT-3.5 that reaches an
accuracy of ~ 48% on M3KE. The dataset is available at
https://github.com/tjunlp-lab/M3KE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Searching for Needles in a Haystack: On the Role of Incidental Bilingualism in PaLM's Translation Capability. (arXiv:2305.10266v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10266">
<div class="article-summary-box-inner">
<span><p>Large, multilingual language models exhibit surprisingly good zero- or
few-shot machine translation capabilities, despite having never seen the
intentionally-included translation examples provided to typical neural
translation systems. We investigate the role of incidental bilingualism -- the
unintentional consumption of bilingual signals, including translation examples
-- in explaining the translation capabilities of large language models, taking
the Pathways Language Model (PaLM) as a case study. We introduce a mixed-method
approach to measure and understand incidental bilingualism at scale. We show
that PaLM is exposed to over 30 million translation pairs across at least 44
languages. Furthermore, the amount of incidental bilingual content is highly
correlated with the amount of monolingual in-language content for non-English
languages. We relate incidental bilingual content to zero-shot prompts and show
that it can be used to mine new prompts to improve PaLM's out-of-English
zero-shot translation quality. Finally, in a series of small-scale ablations,
we show that its presence has a substantial impact on translation capabilities,
although this impact diminishes with model scale.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Local Spectro-Temporal Features for Speech Analysis. (arXiv:2305.10270v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10270">
<div class="article-summary-box-inner">
<span><p>We introduce the problem of phone classification in the context of speech
recognition, and explore several sets of local spectro-temporal features that
can be used for phone classification. In particular, we present some
preliminary results for phone classification using two sets of features that
are commonly used for object detection: Haar features and SVM-classified
Histograms of Gradients (HoG)
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models. (arXiv:2305.10276v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10276">
<div class="article-summary-box-inner">
<span><p>In this paper, we take the initiative to investigate the performance of LLMs
on complex planning tasks that require LLMs to understand a virtual spatial
environment simulated via natural language and act correspondingly in text. We
propose a benchmark named Natural Language Planning (NLP) composed of a set of
novel tasks: Brick World, NLVR-based Manipulations, and Natural Language
Navigation. We found that current popular LLMs such as ChatGPT still lack
abilities in complex planning. This arises a question -- do the LLMs have a
good understanding of the environments described in natural language, or maybe
other alternatives such as symbolic representations are neater and hence better
to be understood by LLMs? To this end, we propose a novel method called CoS
(Chain-of-Symbol Prompting) that represents the complex environments with
condensed symbolic spatial representations during the chained intermediate
thinking steps. CoS is easy to use and does not need additional training on
LLMs. Extensive experiments indicate that CoS clearly surpasses the performance
of the Chain-of-Thought (CoT) Prompting in all three planning tasks with even
fewer tokens used in the inputs compared with CoT on ChatGPT and InstructGPT.
The performance gain is strong, by up to 60.8% accuracy (from 31.8% to 92.6%)
on Brick World for ChatGPT. CoS also reduces the number of tokens in the prompt
obviously, by up to 65.8% of the tokens (from 407 to 139) for the intermediate
steps from demonstrations on Brick World.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards More Robust NLP System Evaluation: Handling Missing Scores in Benchmarks. (arXiv:2305.10284v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10284">
<div class="article-summary-box-inner">
<span><p>The evaluation of natural language processing (NLP) systems is crucial for
advancing the field, but current benchmarking approaches often assume that all
systems have scores available for all tasks, which is not always practical. In
reality, several factors such as the cost of running baseline, private systems,
computational limitations, or incomplete data may prevent some systems from
being evaluated on entire tasks. This paper formalize an existing problem in
NLP research: benchmarking when some systems scores are missing on the task,
and proposes a novel approach to address it. Our method utilizes a compatible
partial ranking approach to impute missing data, which is then aggregated using
the Borda count method. It includes two refinements designed specifically for
scenarios where either task-level or instance-level scores are available. We
also introduce an extended benchmark, which contains over 131 million scores,
an order of magnitude larger than existing benchmarks. We validate our methods
and demonstrate their effectiveness in addressing the challenge of missing
system evaluation on an entire task. This work highlights the need for more
comprehensive benchmarking approaches that can handle real-world scenarios
where not all systems are evaluated on the entire task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UniEX: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective. (arXiv:2305.10306v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10306">
<div class="article-summary-box-inner">
<span><p>We propose a new paradigm for universal information extraction (IE) that is
compatible with any schema format and applicable to a list of IE tasks, such as
named entity recognition, relation extraction, event extraction and sentiment
analysis. Our approach converts the text-based IE tasks as the token-pair
problem, which uniformly disassembles all extraction targets into joint span
detection, classification and association problems with a unified extractive
framework, namely UniEX. UniEX can synchronously encode schema-based prompt and
textual information, and collaboratively learn the generalized knowledge from
pre-defined information using the auto-encoder language models. We develop a
traffine attention mechanism to integrate heterogeneous factors including
tasks, labels and inside tokens, and obtain the extraction target via a scoring
matrix. Experiment results show that UniEX can outperform generative universal
IE models in terms of performance and inference-speed on $14$ benchmarks IE
datasets with the supervised setting. The state-of-the-art performance in
low-resource scenarios also verifies the transferability and effectiveness of
UniEX.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FACE: Evaluating Natural Language Generation with Fourier Analysis of Cross-Entropy. (arXiv:2305.10307v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10307">
<div class="article-summary-box-inner">
<span><p>Measuring the distance between machine-produced and human language is
acritical open problem. Inspired by empirical findings from psycholinguistics
on theperiodicity of entropy in language, we propose FACE, a set of metrics
based onFourier Analysis of the estimated Cross-Entropy of language, for
measuring thesimilarity between model-generated and human-written languages.
Based on anopen-ended generation task and the experimental data from previous
studies, weind that FACE can effectively identify the human-model gap, scales
with modelsize, reflects the outcomes of different sampling methods for
decoding, correlateswell with other evaluation metrics and with human judgment
scores. FACE iscomputationally efficient and provides intuitive
interpretations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LeTI: Learning to Generate from Textual Interactions. (arXiv:2305.10314v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10314">
<div class="article-summary-box-inner">
<span><p>Finetuning pre-trained language models (LMs) enhances the models'
capabilities. Prior techniques fine-tune a pre-trained LM on input-output pairs
(e.g., instruction fine-tuning), or with numerical rewards that gauge the
quality of its outputs (e.g., reinforcement learning from human feedback). We
explore LMs' potential to learn from textual interactions (LeTI) that not only
check their correctness with binary labels, but also pinpoint and explain
errors in their outputs through textual feedback. Our investigation focuses on
the code generation task, where the model produces code pieces in response to
natural language instructions. This setting invites a natural and scalable way
to acquire the textual feedback: the error messages and stack traces from code
execution using a Python interpreter. LeTI iteratively fine-tunes the model,
using the LM objective, on a concatenation of natural language instructions,
LM-generated programs, and textual feedback, which is only provided when the
generated program fails to solve the task. Prepended to this fine-tuning text,
a binary reward token is used to differentiate correct and buggy solutions. On
MBPP, a code generation dataset, LeTI substantially improves the performance of
two base LMs of different scales. LeTI requires no ground-truth outputs for
training and even outperforms a fine-tuned baseline that does. LeTI's strong
performance generalizes to other datasets. Trained on MBPP, it achieves
comparable or better performance than the base LMs on unseen problems in
HumanEval. Furthermore, compared to binary feedback, we observe that textual
feedback leads to improved generation quality and sample efficiency, achieving
the same performance with fewer than half of the gradient steps. LeTI is
equally applicable in natural language tasks when they can be formulated as
code generation, which we empirically verified on event argument extraction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using a Large Language Model to Control Speaking Style for Expressive TTS. (arXiv:2305.10321v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10321">
<div class="article-summary-box-inner">
<span><p>Appropriate prosody is critical for successful spoken communication.
Contextual word embeddings are proven to be helpful in predicting prosody but
do not allow for choosing between plausible prosodic renditions.
Reference-based TTS models attempt to address this by conditioning speech
generation on a reference speech sample. These models can generate expressive
speech but this requires finding an appropriate reference.
</p>
<p>Sufficiently large generative language models have been used to solve various
language-related tasks. We explore whether such models can be used to suggest
appropriate prosody for expressive TTS. We train a TTS model on a
non-expressive corpus and then prompt the language model to suggest changes to
pitch, energy and duration. The prompt can be designed for any task and we
prompt the model to make suggestions based on target speaking style and
dialogue context. The proposed method is rated most appropriate in 49.9\% of
cases compared to 31.0\% for a baseline model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interactive Learning of Hierarchical Tasks from Dialog with GPT. (arXiv:2305.10349v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10349">
<div class="article-summary-box-inner">
<span><p>We present a system for interpretable, symbolic, interactive task learning
from dialog using a GPT model as a conversational front-end. The learned tasks
are represented as hierarchical decompositions of predicate-argument structures
with scoped variable arguments. By using a GPT model to convert interactive
dialog into a semantic representation, and then recursively asking for
definitions of unknown steps, we show that hierarchical task knowledge can be
acquired and re-used in a natural and unrestrained conversational environment.
We compare our system to a similar architecture using a more conventional
parser and show that our system tolerates a much wider variety of linguistic
variance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Object Hallucination in Large Vision-Language Models. (arXiv:2305.10355v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10355">
<div class="article-summary-box-inner">
<span><p>Inspired by the superior language abilities of large language models (LLM),
large vision-language models (LVLM) have been recently explored by integrating
powerful LLMs for improving the performance on complex multimodal tasks.
Despite the promising progress on LVLMs, we find that LVLMs suffer from the
hallucination problem, i.e. they tend to generate objects that are inconsistent
with the target images in the descriptions. To investigate it, this work
presents the first systematic study on object hallucination of LVLMs. We
conduct the evaluation experiments on several representative LVLMs, and show
that they mostly suffer from severe object hallucination issue. We further
discuss that the visual instructions may influence the hallucination, and find
that: objects that frequently occur in the visual instructions or co-occur with
the image objects, are obviously prone to be hallucinated by LVLMs. Besides, we
find that existing evaluation methods might be affected by the input
instructions and generation styles of LVLMs. Thus, we further design an
improved evaluation method for object hallucination by proposing a
polling-based query method called \emph{POPE}. Experiment results demonstrate
that our POPE can evaluate the object hallucination in a more stable and
flexible way. Our codes and data are publicly available at
https://github.com/RUCAIBox/POPE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large-Scale Text Analysis Using Generative Language Models: A Case Study in Discovering Public Value Expressions in AI Patents. (arXiv:2305.10383v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10383">
<div class="article-summary-box-inner">
<span><p>Labeling data is essential for training text classifiers but is often
difficult to accomplish accurately, especially for complex and abstract
concepts. Seeking an improved method, this paper employs a novel approach using
a generative language model (GPT-4) to produce labels and rationales for
large-scale text analysis. We apply this approach to the task of discovering
public value expressions in US AI patents. We collect a database comprising
154,934 patent documents using an advanced Boolean query submitted to
InnovationQ+. The results are merged with full patent text from the USPTO,
resulting in 5.4 million sentences. We design a framework for identifying and
labeling public value expressions in these AI patent sentences. A prompt for
GPT-4 is developed which includes definitions, guidelines, examples, and
rationales for text classification. We evaluate the quality of the labels and
rationales produced by GPT-4 using BLEU scores and topic modeling and find that
they are accurate, diverse, and faithful. These rationales also serve as a
chain-of-thought for the model, a transparent mechanism for human verification,
and support for human annotators to overcome cognitive limitations. We conclude
that GPT-4 achieved a high-level of recognition of public value theory from our
framework, which it also uses to discover unseen public value expressions. We
use the labels produced by GPT-4 to train BERT-based classifiers and predict
sentences on the entire database, achieving high F1 scores for the 3-class
(0.85) and 2-class classification (0.91) tasks. We discuss the implications of
our approach for conducting large-scale text analyses with complex and abstract
concepts and suggest that, with careful framework design and interactive human
oversight, generative language models can offer significant advantages in
quality and in reduced time and costs for producing labels and rationales.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Logit-Based Ensemble Distribution Distillation for Robust Autoregressive Sequence Uncertainties. (arXiv:2305.10384v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10384">
<div class="article-summary-box-inner">
<span><p>Efficiently and reliably estimating uncertainty is an important objective in
deep learning. It is especially pertinent to autoregressive sequence tasks,
where training and inference costs are typically very high. However, existing
research has predominantly focused on tasks with static data such as image
classification. In this work, we investigate Ensemble Distribution Distillation
(EDD) applied to large-scale natural language sequence-to-sequence data. EDD
aims to compress the superior uncertainty performance of an expensive (teacher)
ensemble into a cheaper (student) single model. Importantly, the ability to
separate knowledge (epistemic) and data (aleatoric) uncertainty is retained.
Existing probability-space approaches to EDD, however, are difficult to scale
to large vocabularies. We show, for modern transformer architectures on
large-scale translation tasks, that modelling the ensemble logits, instead of
softmax probabilities, leads to significantly better students. Moreover, the
students surprisingly even outperform Deep Ensembles by up to ~10% AUROC on
out-of-distribution detection, whilst matching them at in-distribution
translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Elaborative Simplification as Implicit Questions Under Discussion. (arXiv:2305.10387v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10387">
<div class="article-summary-box-inner">
<span><p>Automated text simplification, a technique useful for making text more
accessible to people such as children and emergent bilinguals, is often thought
of as a monolingual translation task from complex sentences to simplified
sentences using encoder-decoder models. This view fails to account for
elaborative simplification, where new information is added into the simplified
text. This paper proposes to view elaborative simplification through the lens
of the Question Under Discussion (QUD) framework, providing a robust way to
investigate what writers elaborate upon, how they elaborate, and how
elaborations fit into the discourse context by viewing elaborations as explicit
answers to implicit questions. We introduce ElabQUD, consisting of 1.3K
elaborations accompanied with implicit QUDs, to study these phenomena. We show
that explicitly modeling QUD (via question generation) not only provides
essential understanding of elaborative simplification and how the elaborations
connect with the rest of the discourse, but also substantially improves the
quality of elaboration generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What You See is What You Read? Improving Text-Image Alignment Evaluation. (arXiv:2305.10400v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10400">
<div class="article-summary-box-inner">
<span><p>Automatically determining whether a text and a corresponding image are
semantically aligned is a significant challenge for vision-language models,
with applications in generative text-to-image and image-to-text tasks. In this
work, we study methods for automatic text-image alignment evaluation. We first
introduce SeeTRUE: a comprehensive evaluation set, spanning multiple datasets
from both text-to-image and image-to-text generation tasks, with human
judgements for whether a given text-image pair is semantically aligned. We then
describe two automatic methods to determine alignment: the first involving a
pipeline based on question generation and visual question answering models, and
the second employing an end-to-end classification approach by finetuning
multimodal pretrained models. Both methods surpass prior approaches in various
text-image alignment tasks, with significant improvements in challenging cases
that involve complex composition or unnatural images. Finally, we demonstrate
how our approaches can localize specific misalignments between an image and a
given text, and how they can be used to automatically re-rank candidates in
text-to-image generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PaLM 2 Technical Report. (arXiv:2305.10403v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10403">
<div class="article-summary-box-inner">
<span><p>We introduce PaLM 2, a new state-of-the-art language model that has better
multilingual and reasoning capabilities and is more compute-efficient than its
predecessor PaLM. PaLM 2 is a Transformer-based model trained using a mixture
of objectives. Through extensive evaluations on English and multilingual
language, and reasoning tasks, we demonstrate that PaLM 2 has significantly
improved quality on downstream tasks across different model sizes, while
simultaneously exhibiting faster and more efficient inference compared to PaLM.
This improved efficiency enables broader deployment while also allowing the
model to respond faster, for a more natural pace of interaction. PaLM 2
demonstrates robust reasoning capabilities exemplified by large improvements
over PaLM on BIG-Bench and other reasoning tasks. PaLM 2 exhibits stable
performance on a suite of responsible AI evaluations, and enables
inference-time control over toxicity without additional overhead or impact on
other capabilities. Overall, PaLM 2 achieves state-of-the-art performance
across a diverse set of tasks and capabilities.
</p>
<p>When discussing the PaLM 2 family, it is important to distinguish between
pre-trained models (of various sizes), fine-tuned variants of these models, and
the user-facing products that use these models. In particular, user-facing
products typically include additional pre- and post-processing steps.
Additionally, the underlying models may evolve over time. Therefore, one should
not expect the performance of user-facing products to exactly match the results
reported in this report.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BAD: BiAs Detection for Large Language Models in the context of candidate screening. (arXiv:2305.10407v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10407">
<div class="article-summary-box-inner">
<span><p>Application Tracking Systems (ATS) have allowed talent managers, recruiters,
and college admissions committees to process large volumes of potential
candidate applications efficiently. Traditionally, this screening process was
conducted manually, creating major bottlenecks due to the quantity of
applications and introducing many instances of human bias. The advent of large
language models (LLMs) such as ChatGPT and the potential of adopting methods to
current automated application screening raises additional bias and fairness
issues that must be addressed. In this project, we wish to identify and
quantify the instances of social bias in ChatGPT and other OpenAI LLMs in the
context of candidate screening in order to demonstrate how the use of these
models could perpetuate existing biases and inequalities in the hiring process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extracting Blockchain Concepts from Text. (arXiv:2305.10408v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10408">
<div class="article-summary-box-inner">
<span><p>Blockchains provide a mechanism through which mutually distrustful remote
parties can reach consensus on the state of a ledger of information. With the
great acceleration with which this space is developed, the demand for those
seeking to learn about blockchain also grows. Being a technical subject, it can
be quite intimidating to start learning. For this reason, the main objective of
this project was to apply machine learning models to extract information from
whitepapers and academic articles focused on the blockchain area to organize
this information and aid users to navigate the space.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SLiC-HF: Sequence Likelihood Calibration with Human Feedback. (arXiv:2305.10425v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10425">
<div class="article-summary-box-inner">
<span><p>Learning from human feedback has been shown to be effective at aligning
language models with human preferences. Past work has often relied on
Reinforcement Learning from Human Feedback (RLHF), which optimizes the language
model using reward scores assigned from a reward model trained on human
preference data. In this work we show how the recently introduced Sequence
Likelihood Calibration (SLiC), can also be used to effectively learn from human
preferences (SLiC-HF). Furthermore, we demonstrate this can be done with human
feedback data collected for a different model, similar to off-policy, offline
RL data. Automatic and human evaluation experiments on the TL;DR summarization
task show that SLiC-HF significantly improves supervised fine-tuning baselines.
Furthermore, SLiC-HF presents a competitive alternative to the PPO RLHF
implementation used in past work while being much simpler to implement, easier
to tune and more computationally efficient in practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accelerating Transformer Inference for Translation via Parallel Decoding. (arXiv:2305.10427v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10427">
<div class="article-summary-box-inner">
<span><p>Autoregressive decoding limits the efficiency of transformers for Machine
Translation (MT). The community proposed specific network architectures and
learning-based methods to solve this issue, which are expensive and require
changes to the MT model, trading inference speed at the cost of the translation
quality. In this paper, we propose to address the problem from the point of
view of decoding algorithms, as a less explored but rather compelling
direction. We propose to reframe the standard greedy autoregressive decoding of
MT with a parallel formulation leveraging Jacobi and Gauss-Seidel fixed-point
iteration methods for fast inference. This formulation allows to speed up
existing models without training or modifications while retaining translation
quality. We present three parallel decoding algorithms and test them on
different languages and models showing how the parallelization introduces a
speedup up to 38% w.r.t. the standard autoregressive decoding and nearly 2x
when scaling the method on parallel resources. Finally, we introduce a decoding
dependency graph visualizer (DDGviz) that let us see how the model has learned
the conditional dependence between tokens and inspect the decoding procedure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining. (arXiv:2305.10429v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10429">
<div class="article-summary-box-inner">
<span><p>The mixture proportions of pretraining data domains (e.g., Wikipedia, books,
web text) greatly affect language model (LM) performance. In this paper, we
propose Domain Reweighting with Minimax Optimization (DoReMi), which first
trains a small proxy model using group distributionally robust optimization
(Group DRO) over domains to produce domain weights (mixture proportions)
without knowledge of downstream tasks. We then resample a dataset with these
domain weights and train a larger, full-sized model. In our experiments, we use
DoReMi on a 280M-parameter proxy model to find domain weights for training an
8B-parameter model (30x larger) more efficiently. On The Pile, DoReMi improves
perplexity across all domains, even when it downweights a domain. DoReMi
improves average few-shot downstream accuracy by 6.5% over a baseline model
trained using The Pile's default domain weights and reaches the baseline
accuracy with 2.6x fewer training steps. On the GLaM dataset, DoReMi, which has
no knowledge of downstream tasks, even matches the performance of using domain
weights tuned on downstream tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mining Legal Arguments in Court Decisions. (arXiv:2208.06178v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.06178">
<div class="article-summary-box-inner">
<span><p>Identifying, classifying, and analyzing arguments in legal discourse has been
a prominent area of research since the inception of the argument mining field.
However, there has been a major discrepancy between the way natural language
processing (NLP) researchers model and annotate arguments in court decisions
and the way legal experts understand and analyze legal argumentation. While
computational approaches typically simplify arguments into generic premises and
claims, arguments in legal research usually exhibit a rich typology that is
important for gaining insights into the particular case and applications of law
in general. We address this problem and make several substantial contributions
to move the field forward. First, we design a new annotation scheme for legal
arguments in proceedings of the European Court of Human Rights (ECHR) that is
deeply rooted in the theory and practice of legal argumentation research.
Second, we compile and annotate a large corpus of 373 court decisions (2.3M
tokens and 15k annotated argument spans). Finally, we train an argument mining
model that outperforms state-of-the-art models in the legal NLP domain and
provide a thorough expert-based evaluation. All datasets and source codes are
available under open lincenses at
https://github.com/trusthlt/mining-legal-arguments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KGLM: Integrating Knowledge Graph Structure in Language Models for Link Prediction. (arXiv:2211.02744v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.02744">
<div class="article-summary-box-inner">
<span><p>The ability of knowledge graphs to represent complex relationships at scale
has led to their adoption for various needs including knowledge representation,
question-answering, and recommendation systems. Knowledge graphs are often
incomplete in the information they represent, necessitating the need for
knowledge graph completion tasks. Pre-trained and fine-tuned language models
have shown promise in these tasks although these models ignore the intrinsic
information encoded in the knowledge graph, namely the entity and relation
types. In this work, we propose the Knowledge Graph Language Model (KGLM)
architecture, where we introduce a new entity/relation embedding layer that
learns to differentiate distinctive entity and relation types, therefore
allowing the model to learn the structure of the knowledge graph. In this work,
we show that further pre-training the language models with this additional
embedding layer using the triples extracted from the knowledge graph, followed
by the standard fine-tuning phase sets a new state-of-the-art performance for
the link prediction task on the benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Inclusive Notion of Text. (arXiv:2211.05604v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.05604">
<div class="article-summary-box-inner">
<span><p>Natural language processing (NLP) researchers develop models of grammar,
meaning and communication based on written text. Due to task and data
differences, what is considered text can vary substantially across studies. A
conceptual framework for systematically capturing these differences is lacking.
We argue that clarity on the notion of text is crucial for reproducible and
generalizable NLP. Towards that goal, we propose common terminology to discuss
the production and transformation of textual data, and introduce a two-tier
taxonomy of linguistic and non-linguistic elements that are available in
textual sources and can be used in NLP modeling. We apply this taxonomy to
survey existing work that extends the notion of text beyond the conservative
language-centered view. We outline key desiderata and challenges of the
emerging inclusive approach to text in NLP, and suggest community-level
reporting as a crucial next step to consolidate the discussion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Exploration of Knowledge-Preserving Prompts for Document Summarisation. (arXiv:2301.11719v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.11719">
<div class="article-summary-box-inner">
<span><p>Despite the great development of document summarisation techniques nowadays,
factual inconsistencies between the generated summaries and the original texts
still occur from time to time. This study explores the possibility of adopting
prompts to incorporate factual knowledge into generated summaries. We
specifically study prefix-tuning that uses a set of trainable continuous prefix
prompts together with discrete natural language prompts to aid summary
generation. Experimental results demonstrate that the trainable prefixes can
help the summarisation model extract information from discrete prompts
precisely, thus generating knowledge-preserving summaries that are factually
consistent with the discrete prompts. The ROUGE improvements of the generated
summaries indicate that explicitly adding factual knowledge into the
summarisation process could boost the overall performance, showing great
potential for applying it to other natural language processing tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Positive-Augmented Contrastive Learning for Image and Video Captioning Evaluation. (arXiv:2303.12112v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.12112">
<div class="article-summary-box-inner">
<span><p>The CLIP model has been recently proven to be very effective for a variety of
cross-modal tasks, including the evaluation of captions generated from
vision-and-language architectures. In this paper, we propose a new recipe for a
contrastive-based evaluation metric for image captioning, namely
Positive-Augmented Contrastive learning Score (PAC-S), that in a novel way
unifies the learning of a contrastive visual-semantic space with the addition
of generated images and text on curated data. Experiments spanning several
datasets demonstrate that our new metric achieves the highest correlation with
human judgments on both images and videos, outperforming existing
reference-based metrics like CIDEr and SPICE and reference-free metrics like
CLIP-Score. Finally, we test the system-level correlation of the proposed
metric when considering popular image captioning approaches, and assess the
impact of employing different cross-modal features. Our source code and trained
models are publicly available at: https://github.com/aimagelab/pacscore.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UKP-SQuARE v3: A Platform for Multi-Agent QA Research. (arXiv:2303.18120v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18120">
<div class="article-summary-box-inner">
<span><p>The continuous development of Question Answering (QA) datasets has drawn the
research community's attention toward multi-domain models. A popular approach
is to use multi-dataset models, which are models trained on multiple datasets
to learn their regularities and prevent overfitting to a single dataset.
However, with the proliferation of QA models in online repositories such as
GitHub or Hugging Face, an alternative is becoming viable. Recent works have
demonstrated that combining expert agents can yield large performance gains
over multi-dataset models. To ease research in multi-agent models, we extend
UKP-SQuARE, an online platform for QA research, to support three families of
multi-agent systems: i) agent selection, ii) early-fusion of agents, and iii)
late-fusion of agents. We conduct experiments to evaluate their inference speed
and discuss the performance vs. speed trade-off compared to multi-dataset
models. UKP-SQuARE is open-source and publicly available at
<a href="http://square.ukp-lab.de.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RPTQ: Reorder-based Post-training Quantization for Large Language Models. (arXiv:2304.01089v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.01089">
<div class="article-summary-box-inner">
<span><p>Large-scale language models (LLMs) have demonstrated impressive performance,
but their deployment presents challenges due to their significant memory usage.
This issue can be alleviated through quantization. In this paper, we identify
that the challenge in quantizing activations in LLMs arises from varying ranges
across channels, rather than solely the presence of outliers. To address this
challenge, we introduce a quantization method called RPTQ, which utilizes a
reorder-based approach. By rearranging the channels and quantizing them in
clusters, RPTQ effectively mitigates the impact of range differences between
channels. To minimize the overhead of the reorder operation, we fuse it into
the layer norm operation and weights in linear layers. In our experiments, RPTQ
achieved a significant breakthrough by utilizing 3-bit activation in LLMs for
the first time, resulting in a substantial reduction in memory usage. For
instance, quantizing OPT-175b can lead to a memory consumption reduction of up
to 80%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classification of US Supreme Court Cases using BERT-Based Techniques. (arXiv:2304.08649v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.08649">
<div class="article-summary-box-inner">
<span><p>Models based on bidirectional encoder representations from transformers
(BERT) produce state of the art (SOTA) results on many natural language
processing (NLP) tasks such as named entity recognition (NER), part-of-speech
(POS) tagging etc. An interesting phenomenon occurs when classifying long
documents such as those from the US supreme court where BERT-based models can
be considered difficult to use on a first-pass or out-of-the-box basis. In this
paper, we experiment with several BERT-based classification techniques for US
supreme court decisions or supreme court database (SCDB) and compare them with
the previous SOTA results. We then compare our results specifically with SOTA
models for long documents. We compare our results for two classification tasks:
(1) a broad classification task with 15 categories and (2) a fine-grained
classification task with 279 categories. Our best result produces an accuracy
of 80\% on the 15 broad categories and 60\% on the fine-grained 279 categories
which marks an improvement of 8\% and 28\% respectively from previously
reported SOTA results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner. (arXiv:2305.01711v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01711">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) trained on vast quantities of unlabelled data have
greatly advanced the field of natural language processing (NLP). In this study,
we re-visit the widely accepted notion in NLP that continued pre-training LMs
on task-related texts improves the performance of fine-tuning (FT) in
downstream tasks. Through experiments on eight single-sentence tasks and eight
sentence-pair tasks in both semi-supervised and fully-supervised settings, we
find that conventional continued pre-training does not consistently provide
benefits and can even be detrimental for sentence-pair tasks or when
prompt-based FT is used. To tackle these issues, we propose Prompt-based
Continued Pre-training (PCP), which combines the idea of instruction tuning
with conventional continued pre-training. Our approach aims to improve the
performance of prompt-based FT by presenting both task-related texts and prompt
templates to LMs through unsupervised pre-training objectives before
fine-tuning for the target task. Our empirical evaluations on 21 benchmarks
demonstrate that the PCP consistently improves the performance of
state-of-the-art prompt-based FT approaches (up to 20.1% absolute) in both
semi-supervised and fully-supervised settings, even with only hundreds of
unlabelled examples. Additionally, prompt-based FT with the PCP outperforms
state-of-the-art semi-supervised approaches with greater simplicity,
eliminating the need for an iterative process and extra data augmentation. Our
further analysis explores the performance lower bound of the PCP and reveals
that the advantages of PCP persist across different sizes of models and
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory. (arXiv:2305.02437v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02437">
<div class="article-summary-box-inner">
<span><p>With direct access to human-written reference as memory, retrieval-augmented
generation has achieved much progress in a wide range of text generation tasks.
Since better memory would typically prompt better generation~(we define this as
primal problem). The traditional approach for memory retrieval involves
selecting memory that exhibits the highest similarity to the input. However,
this method is constrained by the quality of the fixed corpus from which memory
is retrieved. In this paper, by exploring the duality of the primal problem:
better generation also prompts better memory, we propose a novel framework,
selfmem, which addresses this limitation by iteratively employing a
retrieval-augmented generator to create an unbounded memory pool and using a
memory selector to choose one output as memory for the subsequent generation
round. This enables the model to leverage its own output, referred to as
self-memory, for improved generation. We evaluate the effectiveness of selfmem
on three distinct text generation tasks: neural machine translation,
abstractive text summarization, and dialogue generation, under two generation
paradigms: fine-tuned small model and few-shot LLM. Our approach achieves
state-of-the-art results in four directions in JRC-Acquis, XSum (50.3 ROUGE-1),
and BigPatent (62.9 ROUGE-1), demonstrating the potential of self-memory in
enhancing retrieval-augmented generation models. Furthermore, we conduct
thorough analyses of each component in the selfmem framework to identify
bottlenecks and provide insights for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Politics of Language Choice: How the Russian-Ukrainian War Influences Ukrainians' Language Use on Twitter. (arXiv:2305.02770v2 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02770">
<div class="article-summary-box-inner">
<span><p>The use of language is innately political and often a vehicle of cultural
identity as well as the basis for nation building. Here, we examine language
choice and tweeting activity of Ukrainian citizens based on more than 4 million
geo-tagged tweets from over 62,000 users before and during the
Russian-Ukrainian War, from January 2020 to October 2022. Using statistical
models, we disentangle sample effects, arising from the in- and outflux of
users on Twitter, from behavioural effects, arising from behavioural changes of
the users. We observe a steady shift from the Russian language towards the
Ukrainian language already before the war, which drastically speeds up with its
outbreak. We attribute these shifts in large part to users' behavioural
changes. Notably, we find that more than half of the Russian-tweeting users
perform a hard-switch to Ukrainian as a result of the war.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DAMO-NLP at SemEval-2023 Task 2: A Unified Retrieval-augmented System for Multilingual Named Entity Recognition. (arXiv:2305.03688v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03688">
<div class="article-summary-box-inner">
<span><p>The MultiCoNER \RNum{2} shared task aims to tackle multilingual named entity
recognition (NER) in fine-grained and noisy scenarios, and it inherits the
semantic ambiguity and low-context setting of the MultiCoNER \RNum{1} task. To
cope with these problems, the previous top systems in the MultiCoNER \RNum{1}
either incorporate the knowledge bases or gazetteers. However, they still
suffer from insufficient knowledge, limited context length, single retrieval
strategy. In this paper, our team \textbf{DAMO-NLP} proposes a unified
retrieval-augmented system (U-RaNER) for fine-grained multilingual NER. We
perform error analysis on the previous top systems and reveal that their
performance bottleneck lies in insufficient knowledge. Also, we discover that
the limited context length causes the retrieval knowledge to be invisible to
the model. To enhance the retrieval context, we incorporate the entity-centric
Wikidata knowledge base, while utilizing the infusion approach to broaden the
contextual scope of the model. Also, we explore various search strategies and
refine the quality of retrieval knowledge. Our system\footnote{We will release
the dataset, code, and scripts of our system at {\small
\url{https://github.com/modelscope/AdaSeq/tree/master/examples/U-RaNER}}.} wins
9 out of 13 tracks in the MultiCoNER \RNum{2} shared task. Additionally, we
compared our system with ChatGPT, one of the large language models which have
unlocked strong capabilities on many tasks. The results show that there is
still much room for improvement for ChatGPT on the extraction task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">K-UniMorph: Korean Universal Morphology and its Feature Schema. (arXiv:2305.06335v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.06335">
<div class="article-summary-box-inner">
<span><p>We present in this work a new Universal Morphology dataset for Korean.
Previously, the Korean language has been underrepresented in the field of
morphological paradigms amongst hundreds of diverse world languages. Hence, we
propose this Universal Morphological paradigms for the Korean language that
preserve its distinct characteristics. For our K-UniMorph dataset, we outline
each grammatical criterion in detail for the verbal endings, clarify how to
extract inflected forms, and demonstrate how we generate the morphological
schemata. This dataset adopts morphological feature schema from Sylak-Glassman
et al. (2015) and Sylak-Glassman (2016) for the Korean language as we extract
inflected verb forms from the Sejong morphologically analyzed corpus that is
one of the largest annotated corpora for Korean. During the data creation, our
methodology also includes investigating the correctness of the conversion from
the Sejong corpus. Furthermore, we carry out the inflection task using three
different Korean word forms: letters, syllables and morphemes. Finally, we
discuss and describe future perspectives on Korean morphological paradigms and
the dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chain-of-Dictionary Prompting Elicits Translation in Large Language Models. (arXiv:2305.06575v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.06575">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have shown surprisingly good performance in
multilingual neural machine translation (MNMT) even when trained without
parallel data. Yet, despite the fact that the amount of training data is
gigantic, they still struggle with translating rare words, particularly for
low-resource languages. Even worse, it is usually unrealistic to retrieve
relevant demonstrations for in-context learning with low-resource languages on
LLMs, which restricts the practical use of LLMs for translation -- how should
we mitigate this problem? To this end, we present a novel method, CoD, which
augments LLMs with prior knowledge with the chains of multilingual dictionaries
for a subset of input words to elicit translation abilities for LLMs. Extensive
experiments indicate that augmenting ChatGPT with CoD elicits large gains by up
to 13x chrF++ points for MNMT (3.08 to 42.63 for English to Serbian written in
Cyrillic script) on FLORES-200 full devtest set. We further demonstrate the
importance of chaining the multilingual dictionaries, as well as the
superiority of CoD to few-shot demonstration for low-resource languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Large Language Models in Conversational Recommender Systems. (arXiv:2305.07961v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07961">
<div class="article-summary-box-inner">
<span><p>A Conversational Recommender System (CRS) offers increased transparency and
control to users by enabling them to engage with the system through a real-time
multi-turn dialogue. Recently, Large Language Models (LLMs) have exhibited an
unprecedented ability to converse naturally and incorporate world knowledge and
common-sense reasoning into language understanding, unlocking the potential of
this paradigm. However, effectively leveraging LLMs within a CRS introduces new
technical challenges, including properly understanding and controlling a
complex conversation and retrieving from external sources of information. These
issues are exacerbated by a large, evolving item corpus and a lack of
conversational data for training. In this paper, we provide a roadmap for
building an end-to-end large-scale CRS using LLMs. In particular, we propose
new implementations for user preference understanding, flexible dialogue
management and explainable recommendations as part of an integrated
architecture powered by LLMs. For improved personalization, we describe how an
LLM can consume interpretable natural language user profiles and use them to
modulate session-level context. To overcome conversational data limitations in
the absence of an existing production CRS, we propose techniques for building a
controllable LLM-based user simulator to generate synthetic conversations. As a
proof of concept we introduce RecLLM, a large-scale CRS for YouTube videos
built on LaMDA, and demonstrate its fluency and diverse functionality through
some illustrative example conversations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. (arXiv:2305.08322v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.08322">
<div class="article-summary-box-inner">
<span><p>New NLP benchmarks are urgently needed to align with the rapid development of
large language models (LLMs). We present C-Eval, the first comprehensive
Chinese evaluation suite designed to assess advanced knowledge and reasoning
abilities of foundation models in a Chinese context. C-Eval comprises
multiple-choice questions across four difficulty levels: middle school, high
school, college, and professional. The questions span 52 diverse disciplines,
ranging from humanities to science and engineering. C-Eval is accompanied by
C-Eval Hard, a subset of very challenging subjects in C-Eval that requires
advanced reasoning abilities to solve. We conduct a comprehensive evaluation of
the most advanced LLMs on C-Eval, including both English- and Chinese-oriented
models. Results indicate that only GPT-4 could achieve an average accuracy of
over 60%, suggesting that there is still significant room for improvement for
current LLMs. We anticipate C-Eval will help analyze important strengths and
shortcomings of foundation models, and foster their development and growth for
Chinese users.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NLG Evaluation Metrics Beyond Correlation Analysis: An Empirical Metric Preference Checklist. (arXiv:2305.08566v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.08566">
<div class="article-summary-box-inner">
<span><p>In this study, we analyze NLG automatic metrics based on whether human
evaluation aspect is used as context or objective to compute the metrics: (i)
Task-agnostic and (ii) Human-aligned. Task-agnostic metrics, such as
Perplexity, BLEU, BERTScore, are cost-effective and highly adaptable to diverse
NLG tasks, yet they have a weak correlation with human. Human-aligned metrics
(CTC, CtrlEval, UniEval) improves correlation level by incorporating desirable
human-like qualities as training objective. However, their effectiveness at
discerning system-level performance and quality of system outputs remains
unclear.
</p>
<p>We present metric preference checklist as a framework to assess the
discriminative power of automatic metrics in three NLG tasks: Text
Summarization, Dialogue Response Generation, and Controlled Generation. We show
that multi-aspect human-aligned metric (UniEval) is not necessarily dominant
over single-aspect human-aligned metrics (CTC, CtrlEval) and task-agnostic
metrics (BLEU, BERTScore), particularly when a disagreement between human
evaluation aspects is present. We also show particular use cases in which
automatic metrics provide a better guidance than human on discriminating
system-level performance. Our proposed framework provides access: (i) for
verifying whether automatic metrics are faithful to human preference,
regardless their correlation level to human; and (ii) for scrutinizing the
strengths and limitations of NLG systems, which are often obscured by a
standard averaging method of evaluation scores.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERTTM: Leveraging Contextualized Word Embeddings from Pre-trained Language Models for Neural Topic Modeling. (arXiv:2305.09329v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09329">
<div class="article-summary-box-inner">
<span><p>With the development of neural topic models in recent years, topic modelling
is playing an increasingly important role in natural language understanding.
However, most existing topic models still rely on bag-of-words (BoW)
information, either as training input or training target. This limits their
ability to capture word order information in documents and causes them to
suffer from the out-of-vocabulary (OOV) issue, i.e. they cannot handle
unobserved words in new documents. Contextualized word embeddings from
pre-trained language models show superiority in the ability of word sense
disambiguation and prove to be effective in dealing with OOV words. In this
work, we developed a novel neural topic model combining contextualized word
embeddings from the pre-trained language model BERT. The model can infer the
topic distribution of a document without using any BoW information. In
addition, the model can infer the topic distribution of each word in a document
directly from the contextualized word embeddings. Experiments on several
datasets show that our model outperforms existing topic models in terms of both
document classification and topic coherence metrics and can accommodate unseen
words from newly arrived documents. Experiments on the NER dataset also show
that our model can produce high-quality word topic representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GIFT: Graph-Induced Fine-Tuning for Multi-Party Conversation Understanding. (arXiv:2305.09360v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09360">
<div class="article-summary-box-inner">
<span><p>Addressing the issues of who saying what to whom in multi-party conversations
(MPCs) has recently attracted a lot of research attention. However, existing
methods on MPC understanding typically embed interlocutors and utterances into
sequential information flows, or utilize only the superficial of inherent graph
structures in MPCs. To this end, we present a plug-and-play and lightweight
method named graph-induced fine-tuning (GIFT) which can adapt various
Transformer-based pre-trained language models (PLMs) for universal MPC
understanding. In detail, the full and equivalent connections among utterances
in regular Transformer ignore the sparse but distinctive dependency of an
utterance on another in MPCs. To distinguish different relationships between
utterances, four types of edges are designed to integrate graph-induced signals
into attention mechanisms to refine PLMs originally designed for processing
sequential texts. We evaluate GIFT by implementing it into three PLMs, and test
the performance on three downstream tasks including addressee recognition,
speaker identification and response selection. Experimental results show that
GIFT can significantly improve the performance of three PLMs on three
downstream tasks and two benchmarks with only 4 additional parameters per
encoding layer, achieving new state-of-the-art performance on MPC
understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Life of PII -- A PII Obfuscation Transformer. (arXiv:2305.09550v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09550">
<div class="article-summary-box-inner">
<span><p>Protecting sensitive information is crucial in today's world of Large
Language Models (LLMs) and data-driven services. One common method used to
preserve privacy is by using data perturbation techniques to reduce
overreaching utility of (sensitive) Personal Identifiable Information (PII)
data while maintaining its statistical and semantic properties. Data
perturbation methods often result in significant information loss, making them
impractical for use. In this paper, we propose 'Life of PII', a novel
Obfuscation Transformer framework for transforming PII into faux-PII while
preserving the original information, intent, and context as much as possible.
Our approach includes an API to interface with the given document, a
configuration-based obfuscator, and a model based on the Transformer
architecture, which has shown high context preservation and performance in
natural language processing tasks and LLMs.
</p>
<p>Our Transformer-based approach learns mapping between the original PII and
its transformed faux-PII representation, which we call "obfuscated" data. Our
experiments demonstrate that our method, called Life of PII, outperforms
traditional data perturbation techniques in terms of both utility preservation
and privacy protection. We show that our approach can effectively reduce
utility loss while preserving the original information, offering greater
flexibility in the trade-off between privacy protection and data utility. Our
work provides a solution for protecting PII in various real-world applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Satisfiability-Aided Language Models Using Declarative Prompting. (arXiv:2305.09656v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09656">
<div class="article-summary-box-inner">
<span><p>Prior work has combined chain-of-thought prompting in large language models
(LLMs) with programmatic representations to perform effective and transparent
reasoning. While such an approach works very well for tasks that only require
forward reasoning (e.g., straightforward arithmetic), it is less effective for
constraint solving problems that require more sophisticated planning and
search. In this paper, we propose a new satisfiability-aided language modeling
(SATLM) approach for improving the reasoning capabilities of LLMs. We use an
LLM to generate a declarative task specification rather than an imperative
program and leverage an off-the-shelf automated theorem prover to derive the
final answer. This approach has two key advantages. The declarative
specification is closer to the problem description than the reasoning steps
are, so the LLM can parse it out of the description more accurately.
Furthermore, by offloading the actual reasoning task to an automated theorem
prover, our approach can guarantee the correctness of the answer with respect
to the parsed specification and avoid planning errors in the solving process.
We evaluate SATLM on 6 different datasets and show that it consistently
outperforms program-aided LMs in an imperative paradigm. In particular, SATLM
outperforms program-aided LMs by 23% on a challenging subset of the GSM
arithmetic reasoning dataset; SATLM also achieves a new SoTA on LSAT,
surpassing previous models that are trained on the full training set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pruning Pre-trained Language Models Without Fine-Tuning. (arXiv:2210.06210v2 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06210">
<div class="article-summary-box-inner">
<span><p>To overcome the overparameterized problem in Pre-trained Language Models
(PLMs), pruning is widely used as a simple and straightforward compression
method by directly removing unimportant weights. Previous first-order methods
successfully compress PLMs to extremely high sparsity with little performance
drop. These methods, such as movement pruning, use first-order information to
prune PLMs while fine-tuning the remaining weights. In this work, we argue
fine-tuning is redundant for first-order pruning, since first-order pruning is
sufficient to converge PLMs to downstream tasks without fine-tuning. Under this
motivation, we propose Static Model Pruning (SMP), which only uses first-order
pruning to adapt PLMs to downstream tasks while achieving the target sparsity
level. In addition, we also design a new masking function and training
objective to further improve SMP. Extensive experiments at various sparsity
levels show SMP has significant improvements over first-order and zero-order
methods. Unlike previous first-order methods, SMP is also applicable to low
sparsity and outperforms zero-order methods. Meanwhile, SMP is more parameter
efficient than other methods due to it does not require fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-05-18 23:11:29.529974282 UTC">2023-05-18 23:11:29 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>