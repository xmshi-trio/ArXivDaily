<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-02-20T01:30:00Z">02-20</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning with Rejection for Abstractive Text Summarization. (arXiv:2302.08531v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08531">
<div class="article-summary-box-inner">
<span><p>State-of-the-art abstractive summarization systems frequently hallucinate
content that is not supported by the source document, mainly due to noise in
the training dataset. Existing methods opt to drop the noisy samples or tokens
from the training set entirely, reducing the effective training set size and
creating an artificial propensity to copy words from the source. In this work,
we propose a training objective for abstractive summarization based on
rejection learning, in which the model learns whether or not to reject
potentially noisy tokens. We further propose a regularized decoding objective
that penalizes non-factual candidate summaries during inference by using the
rejection probability learned during training. We show that our method
considerably improves the factuality of generated summaries in automatic and
human evaluations when compared to five baseline models and that it does so
while increasing the abstractiveness of the generated summaries.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Foundation Models for Natural Language Processing -- Pre-trained Language Models Integrating Media. (arXiv:2302.08575v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08575">
<div class="article-summary-box-inner">
<span><p>This open access book provides a comprehensive overview of the state of the
art in research and applications of Foundation Models and is intended for
readers familiar with basic Natural Language Processing (NLP) concepts. Over
the recent years, a revolutionary new paradigm has been developed for training
models for NLP. These models are first pre-trained on large collections of text
documents to acquire general syntactic knowledge and semantic information.
Then, they are fine-tuned for specific tasks, which they can often solve with
superhuman accuracy. When the models are large enough, they can be instructed
by prompts to solve new tasks without any fine-tuning. Moreover, they can be
applied to a wide range of different media and problem domains, ranging from
image and video processing to robot control learning. Because they provide a
blueprint for solving many tasks in artificial intelligence, they have been
called Foundation Models. After a brief introduction to basic NLP models the
main pre-trained language models BERT, GPT and sequence-to-sequence transformer
are described, as well as the concepts of self-attention and context-sensitive
embedding. Then, different approaches to improving these models are discussed,
such as expanding the pre-training criteria, increasing the length of input
texts, or including extra knowledge. An overview of the best-performing models
for about twenty application areas is then presented, e.g., question answering,
translation, story generation, dialog systems, generating images from text,
etc. For each application area, the strengths and weaknesses of current models
are discussed, and an outlook on further developments is given. In addition,
links are provided to freely available program code. A concluding chapter
summarizes the economic opportunities, mitigation of risks, and potential
developments of AI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Keep it Neutral: Using Natural Language Inference to Improve Generation. (arXiv:2302.08577v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08577">
<div class="article-summary-box-inner">
<span><p>We explore incorporating natural language inference (NLI) into the text
generative pipeline by using a pre-trained NLI model to assess whether a
generated sentence entails, contradicts, or is neutral to the prompt and
preceding text. First, we show that the NLI task is predictive of generation
errors made by GPT-3. We use these results to develop an NLI-informed
generation procedure for GPT-J. Then, we evaluate these generations by
obtaining human annotations on error types and overall quality. We find that an
NLI strategy of maximizing entailment improves text generation when the nucleus
sampling randomness parameter value is high, while one which maximizes
contradiction is in fact productive when the parameter value is low. Overall,
though, we demonstrate that an NLI strategy of maximizing the neutral class
provides the highest quality of generated text (significantly better than the
vanilla generations), regardless of parameter value.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pretraining Language Models with Human Preferences. (arXiv:2302.08582v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08582">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) are pretrained to imitate internet text, including
content that would violate human preferences if generated by an LM: falsehoods,
offensive comments, personally identifiable information, low-quality or buggy
code, and more. Here, we explore alternative objectives for pretraining LMs in
a way that also guides them to generate text aligned with human preferences. We
benchmark five objectives for pretraining with human feedback across three
tasks and study how they affect the trade-off between alignment and
capabilities of pretrained LMs. We find a Pareto-optimal and simple approach
among those we explored: conditional training, or learning distribution over
tokens conditional on their human preference scores given by a reward model.
Conditional training reduces the rate of undesirable content by up to an order
of magnitude, both when generating without a prompt and with an
adversarially-chosen prompt. Moreover, conditional training maintains the
downstream task performance of standard LM pretraining, both before and after
task-specific finetuning. Pretraining with human feedback results in much
better preference satisfaction than standard LM pretraining followed by
finetuning with feedback, i.e., learning and then unlearning undesirable
behavior. Our results suggest that we should move beyond imitation learning
when pretraining LMs and incorporate human preferences from the start of
training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">JEIT: Joint End-to-End Model and Internal Language Model Training for Speech Recognition. (arXiv:2302.08583v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08583">
<div class="article-summary-box-inner">
<span><p>We propose JEIT, a joint end-to-end (E2E) model and internal language model
(ILM) training method to inject large-scale unpaired text into ILM during E2E
training which improves rare-word speech recognition. With JEIT, the E2E model
computes an E2E loss on audio-transcript pairs while its ILM estimates a
cross-entropy loss on unpaired text. The E2E model is trained to minimize a
weighted sum of E2E and ILM losses. During JEIT, ILM absorbs knowledge from
unpaired text while the E2E training serves as regularization. Unlike ILM
adaptation methods, JEIT does not require a separate adaptation step and avoids
the need for Kullback-Leibler divergence regularization of ILM. We also show
that modular hybrid autoregressive transducer (MHAT) performs better than HAT
in the JEIT framework, and is much more robust than HAT during ILM adaptation.
To push the limit of unpaired text injection, we further propose a combined
JEIT and JOIST training (CJJT) that benefits from modality matching, encoder
text injection and ILM training. Both JEIT and CJJT can foster a more effective
LM fusion. With 100B unpaired sentences, JEIT/CJJT improves rare-word
recognition accuracy by up to 16.4% over a model trained without unpaired text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Syntactic Structure Processing in the Brain while Listening. (arXiv:2302.08589v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08589">
<div class="article-summary-box-inner">
<span><p>Syntactic parsing is the task of assigning a syntactic structure to a
sentence. There are two popular syntactic parsing methods: constituency and
dependency parsing. Recent works have used syntactic embeddings based on
constituency trees, incremental top-down parsing, and other word syntactic
features for brain activity prediction given the text stimuli to study how the
syntax structure is represented in the brain's language network. However, the
effectiveness of dependency parse trees or the relative predictive power of the
various syntax parsers across brain areas, especially for the listening task,
is yet unexplored. In this study, we investigate the predictive power of the
brain encoding models in three settings: (i) individual performance of the
constituency and dependency syntactic parsing based embedding methods, (ii)
efficacy of these syntactic parsing based embedding methods when controlling
for basic syntactic signals, (iii) relative effectiveness of each of the
syntactic embedding methods when controlling for the other. Further, we explore
the relative importance of syntactic information (from these syntactic
embedding methods) versus semantic information using BERT embeddings. We find
that constituency parsers help explain activations in the temporal lobe and
middle-frontal gyrus, while dependency parsers better encode syntactic
structure in the angular gyrus and posterior cingulate cortex. Although
semantic signals from BERT are more effective compared to any of the syntactic
features or embedding methods, syntactic embedding methods explain additional
variance for a few brain regions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What A Situated Language-Using Agent Must be Able to Do: A Top-Down Analysis. (arXiv:2302.08590v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08590">
<div class="article-summary-box-inner">
<span><p>Even in our increasingly text-intensive times, the primary site of language
use is situated, co-present interaction. It is primary ontogenetically and
phylogenetically, and it is arguably also still primary in negotiating everyday
social situations. Situated interaction is also the final frontier of Natural
Language Processing, where, compared to the area of text processing, very
little progress has been made in the past decade, and where a myriad of
practical applications is waiting to be unlocked. While the usual approach in
the field is to reach, bottom-up, for the ever next "adjacent possible", in
this paper I attempt a top-down analysis of what the demands are that
unrestricted situated interaction makes on the participating agent, and suggest
ways in which this analysis can structure computational models and research on
them. Specifically, I discuss representational demands (the building up and
application of world model, language model, situation model, discourse model,
and agent model) and what I call anchoring processes (incremental processing,
incremental learning, conversational grounding, multimodal grounding) that bind
the agent to the here, now, and us.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InstructABSA: Instruction Learning for Aspect Based Sentiment Analysis. (arXiv:2302.08624v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08624">
<div class="article-summary-box-inner">
<span><p>In this paper, we present InstructABSA, Aspect-Based Sentiment Analysis
(ABSA) using instruction learning paradigm for all ABSA subtasks: Aspect Term
Extraction (ATE), Aspect Term Sentiment Classification (ATSC), and Joint Task
modeling. Our method introduces positive, negative, and neutral examples to
each training sample, and instruction tunes the model (Tk-Instruct Base) for
each ABSA subtask, yielding significant performance improvements. Experimental
results on the Sem Eval 2014 dataset demonstrate that InstructABSA outperforms
the previous state-of-the-art (SOTA) approaches on all three ABSA subtasks
(ATE, ATSC, and Joint Task) by a significant margin, outperforming 7x larger
models. In particular, InstructABSA surpasses the SOTA on the restaurant ATE
subtask by 7.31% points and on the Laptop Joint Task by 8.63% points. Our
results also suggest a strong generalization ability to unseen tasks across all
three subtasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty-aware Self-training for Low-resource Neural Sequence Labeling. (arXiv:2302.08659v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08659">
<div class="article-summary-box-inner">
<span><p>Neural sequence labeling (NSL) aims at assigning labels for input language
tokens, which covers a broad range of applications, such as named entity
recognition (NER) and slot filling, etc. However, the satisfying results
achieved by traditional supervised-based approaches heavily depend on the large
amounts of human annotation data, which may not be feasible in real-world
scenarios due to data privacy and computation efficiency issues. This paper
presents SeqUST, a novel uncertain-aware self-training framework for NSL to
address the labeled data scarcity issue and to effectively utilize unlabeled
data. Specifically, we incorporate Monte Carlo (MC) dropout in Bayesian neural
network (BNN) to perform uncertainty estimation at the token level and then
select reliable language tokens from unlabeled data based on the model
confidence and certainty. A well-designed masked sequence labeling task with a
noise-robust loss supports robust training, which aims to suppress the problem
of noisy pseudo labels. In addition, we develop a Gaussian-based consistency
regularization technique to further improve the model robustness on
Gaussian-distributed perturbed representations. This effectively alleviates the
over-fitting dilemma originating from pseudo-labeled augmented data. Extensive
experiments over six benchmarks demonstrate that our SeqUST framework
effectively improves the performance of self-training, and consistently
outperforms strong baselines by a large margin in low-resource scenarios
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Subtask Graph Generation from Instructional Videos. (arXiv:2302.08672v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08672">
<div class="article-summary-box-inner">
<span><p>Real-world tasks consist of multiple inter-dependent subtasks (e.g., a dirty
pan needs to be washed before it can be used for cooking). In this work, we aim
to model the causal dependencies between such subtasks from instructional
videos describing the task. This is a challenging problem since complete
information about the world is often inaccessible from videos, which demands
robust learning mechanisms to understand the causal structure of events. We
present Multimodal Subtask Graph Generation (MSG2), an approach that constructs
a Subtask Graph defining the dependency between a task's subtasks relevant to a
task from noisy web videos. Graphs generated by our multimodal approach are
closer to human-annotated graphs compared to prior approaches. MSG2 further
performs the downstream task of next subtask prediction 85% and 30% more
accurately than recent video transformer models in the ProceL and CrossTask
datasets, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DREEAM: Guiding Attention with Evidence for Improving Document-Level Relation Extraction. (arXiv:2302.08675v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08675">
<div class="article-summary-box-inner">
<span><p>Document-level relation extraction (DocRE) is the task of identifying all
relations between each entity pair in a document. Evidence, defined as
sentences containing clues for the relationship between an entity pair, has
been shown to help DocRE systems focus on relevant texts, thus improving
relation extraction. However, evidence retrieval (ER) in DocRE faces two major
issues: high memory consumption and limited availability of annotations. This
work aims at addressing these issues to improve the usage of ER in DocRE.
First, we propose DREEAM, a memory-efficient approach that adopts evidence
information as the supervisory signal, thereby guiding the attention modules of
the DocRE system to assign high weights to evidence. Second, we propose a
self-training strategy for DREEAM to learn ER from automatically-generated
evidence on massive data without evidence annotations. Experimental results
reveal that our approach exhibits state-of-the-art performance on the DocRED
benchmark for both DocRE and ER. To the best of our knowledge, DREEAM is the
first approach to employ ER self-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Propaganda Processing. (arXiv:2302.08709v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08709">
<div class="article-summary-box-inner">
<span><p>Propaganda campaigns have long been used to influence public opinion via
disseminating biased and/or misleading information. Despite the increasing
prevalence of propaganda content on the Internet, few attempts have been made
by AI researchers to analyze such content. We introduce the task of multimodal
propaganda processing, where the goal is to automatically analyze propaganda
content. We believe that this task presents a long-term challenge to AI
researchers and that successful processing of propaganda could bring machine
understanding one important step closer to human understanding. We discuss the
technical challenges associated with this task and outline the steps that need
to be taken to address it.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hate Speech and Offensive Language Detection using an Emotion-aware Shared Encoder. (arXiv:2302.08777v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08777">
<div class="article-summary-box-inner">
<span><p>The rise of emergence of social media platforms has fundamentally altered how
people communicate, and among the results of these developments is an increase
in online use of abusive content. Therefore, automatically detecting this
content is essential for banning inappropriate information, and reducing
toxicity and violence on social media platforms. The existing works on hate
speech and offensive language detection produce promising results based on
pre-trained transformer models, however, they considered only the analysis of
abusive content features generated through annotated datasets. This paper
addresses a multi-task joint learning approach which combines external
emotional features extracted from another corpora in dealing with the
imbalanced and scarcity of labeled datasets. Our analysis are using two
well-known Transformer-based models, BERT and mBERT, where the later is used to
address abusive content detection in multi-lingual scenarios. Our model jointly
learns abusive content detection with emotional features by sharing
representations through transformers' shared encoder. This approach increases
data efficiency, reduce overfitting via shared representations, and ensure fast
learning by leveraging auxiliary information. Our findings demonstrate that
emotional knowledge helps to more reliably identify hate speech and offensive
language across datasets. Our hate speech detection Multi-task model exhibited
3% performance improvement over baseline models, but the performance of
multi-task models were not significant for offensive language detection task.
More interestingly, in both tasks, multi-task models exhibits less false
positive errors compared to single task scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Natural Response Generation for Chinese Reading Comprehension. (arXiv:2302.08817v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08817">
<div class="article-summary-box-inner">
<span><p>Machine reading comprehension (MRC) is an important area of conversation
agents and draws a lot of attention. However, there is a notable limitation to
current MRC benchmarks: The labeled answers are mostly either spans extracted
from the target corpus or the choices of the given candidates, ignoring the
natural aspect of high-quality responses. As a result, MRC models trained on
these datasets can not generate human-like responses in real QA scenarios. To
this end, we construct a new dataset called Penguin to promote the research of
MRC, providing a training and test bed for natural response generation to real
scenarios. Concretely, Penguin consists of 200k training data with high-quality
fluent, and well-informed responses. Penguin is the first benchmark towards
natural response generation in Chinese MRC on a relatively large scale. To
address the challenges in Penguin, we develop two strong baselines: end-to-end
and two-stage frameworks. Following that, we further design Prompt-BART:
fine-tuning the pre-trained generative language models with a mixture of prefix
prompts in Penguin. Extensive experiments validated the effectiveness of this
design.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">False perspectives on human language: why statistics needs linguistics. (arXiv:2302.08822v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08822">
<div class="article-summary-box-inner">
<span><p>A sharp tension exists about the nature of human language between two
opposite parties: those who believe that statistical surface distributions, in
particular using measures like surprisal, provide a better understanding of
language processing, vs. those who believe that discrete hierarchical
structures implementing linguistic information such as syntactic ones are a
better tool. In this paper, we show that this dichotomy is a false one. Relying
on the fact that statistical measures can be defined on the basis of either
structural or non-structural models, we provide empirical evidence that only
models of surprisal that reflect syntactic structure are able to account for
language regularities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring External Knowledge for Accurate modeling of Visual and Language Problems. (arXiv:2302.08901v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08901">
<div class="article-summary-box-inner">
<span><p>The interest in Artificial Intelligence (AI) and its applications has seen
unprecedented growth in the last few years. The success can be partly
attributed to the advancements of deep neural networks made in the sub-fields
of AI such as Computer Vision (CV) and Natural Language Processing (NLP). The
promising research area that this dissertation focuses on is visual and
language understanding which involves many challenging tasks, i.e.,
classification, detection, segmentation, machine translation and captioning,
etc. The state-of-the-art methods for solving these problems usually involves
only two parts: source data and target labels, which is rather insufficient
especially when the dataset is small. Meanwhile, many external tools or sources
can provide extra useful information (external knowledge) that can help improve
the performance of these methods. For example, a detection model has been
applied to provide better object features than state-of-the-art ResNet for
image captioning models. Inspired by this observation, we developed a
methodology that we can first extract external knowledge and then integrate it
with the original models. The external knowledge has to be extracted from the
dataset, or can directly come from external, e.g., grammar rules or scene
graphs. We apply this methodology to different AI tasks, including machine
translation and image captioning and improve the original state-of-the-art
models by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Massively Multilingual Shallow Fusion with Large Language Models. (arXiv:2302.08917v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08917">
<div class="article-summary-box-inner">
<span><p>While large language models (LLM) have made impressive progress in natural
language processing, it remains unclear how to utilize them in improving
automatic speech recognition (ASR). In this work, we propose to train a single
multilingual language model (LM) for shallow fusion in multiple languages. We
push the limits of the multilingual LM to cover up to 84 languages by scaling
up using a mixture-of-experts LLM, i.e., generalist language model (GLaM). When
the number of experts increases, GLaM dynamically selects only two at each
decoding step to keep the inference computation roughly constant. We then apply
GLaM to a multilingual shallow fusion task based on a state-of-the-art
end-to-end model. Compared to a dense LM of similar computation during
inference, GLaM reduces the WER of an English long-tail test set by 4.4%
relative. In a multilingual shallow fusion task, GLaM improves 41 out of 50
languages with an average relative WER reduction of 3.85%, and a maximum
reduction of 10%. Compared to the baseline model, GLaM achieves an average WER
reduction of 5.53% over 43 languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Implicit Distribution Alignment Networks for Cross-Corpus Speech Emotion Recognition. (arXiv:2302.08921v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08921">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel deep transfer learning method called deep
implicit distribution alignment networks (DIDAN) to deal with cross-corpus
speech emotion recognition (SER) problem, in which the labeled training
(source) and unlabeled testing (target) speech signals come from different
corpora. Specifically, DIDAN first adopts a simple deep regression network
consisting of a set of convolutional and fully connected layers to directly
regress the source speech spectrums into the emotional labels such that the
proposed DIDAN can own the emotion discriminative ability. Then, such ability
is transferred to be also applicable to the target speech samples regardless of
corpus variance by resorting to a well-designed regularization term called
implicit distribution alignment (IDA). Unlike widely-used maximum mean
discrepancy (MMD) and its variants, the proposed IDA absorbs the idea of sample
reconstruction to implicitly align the distribution gap, which enables DIDAN to
learn both emotion discriminative and corpus invariant features from speech
spectrums. To evaluate the proposed DIDAN, extensive cross-corpus SER
experiments on widely-used speech emotion corpora are carried out. Experimental
results show that the proposed DIDAN can outperform lots of recent
state-of-the-art methods in coping with the cross-corpus SER tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">More Data Types More Problems: A Temporal Analysis of Complexity, Stability, and Sensitivity in Privacy Policies. (arXiv:2302.08936v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08936">
<div class="article-summary-box-inner">
<span><p>Collecting personally identifiable information (PII) on data subjects has
become big business. Data brokers and data processors are part of a
multi-billion-dollar industry that profits from collecting, buying, and selling
consumer data. Yet there is little transparency in the data collection industry
which makes it difficult to understand what types of data are being collected,
used, and sold, and thus the risk to individual data subjects. In this study,
we examine a large textual dataset of privacy policies from 1997-2019 in order
to investigate the data collection activities of data brokers and data
processors. We also develop an original lexicon of PII-related terms
representing PII data types curated from legislative texts. This mesoscale
analysis looks at privacy policies overtime on the word, topic, and network
levels to understand the stability, complexity, and sensitivity of privacy
policies over time. We find that (1) privacy legislation correlates with
changes in stability and turbulence of PII data types in privacy policies; (2)
the complexity of privacy policies decreases over time and becomes more
regularized; (3) sensitivity rises over time and shows spikes that are
correlated with events when new privacy legislation is introduced.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Entry Separation using a Mixed Visual and Textual Language Model: Application to 19th century French Trade Directories. (arXiv:2302.08948v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08948">
<div class="article-summary-box-inner">
<span><p>When extracting structured data from repetitively organized documents, such
as dictionaries, directories, or even newspapers, a key challenge is to
correctly segment what constitutes the basic text regions for the target
database. Traditionally, such a problem was tackled as part of the layout
analysis and was mostly based on visual clues for dividing (top-down)
approaches. Some agglomerating (bottom-up) approaches started to consider
textual information to link similar contents, but they required a proper
over-segmentation of fine-grained units. In this work, we propose a new
pragmatic approach whose efficiency is demonstrated on 19th century French
Trade Directories. We propose to consider two sub-problems: coarse layout
detection (text columns and reading order), which is assumed to be effective
and not detailed here, and a fine-grained entry separation stage for which we
propose to adapt a state-of-the-art Named Entity Recognition (NER) approach. By
injecting special visual tokens, coding, for instance, indentation or breaks,
into the token stream of the language model used for NER purpose, we can
leverage both textual and visual knowledge simultaneously. Code, data, results
and models are available at
https://github.com/soduco/paper-entryseg-icdar23-code,
https://huggingface.co/HueyNemud/ (icdar23-entrydetector* variants)
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Handling the Alignment for Wake Word Detection: A Comparison Between Alignment-Based, Alignment-Free and Hybrid Approaches. (arXiv:2302.08950v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08950">
<div class="article-summary-box-inner">
<span><p>Wake word detection exists in most intelligent homes and portable devices. It
offers these devices the ability to "wake up" when summoned at a low cost of
power and computing. This paper focuses on understanding alignment's role in
developing a wake-word system that answers a generic phrase. We discuss three
approaches. The first is alignment-based, where the model is trained with
frame-wise cross-entropy. The second is alignment-free, where the model is
trained with CTC. The third, proposed by us, is a hybrid solution in which the
model is trained with a small set of aligned data and then tuned with a
sizeable unaligned dataset. We compare the three approaches and evaluate the
impact of the different aligned-to-unaligned ratios for hybrid training. Our
results show that the alignment-free system performs better alignment-based for
the target operating point, and with a small fraction of the data (20%), we can
train a model that complies with our initial constraints.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages. (arXiv:2302.08956v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08956">
<div class="article-summary-box-inner">
<span><p>Africa is home to over 2000 languages from over six language families and has
the highest linguistic diversity among all continents. This includes 75
languages with at least one million speakers each. Yet, there is little NLP
research conducted on African languages. Crucial in enabling such research is
the availability of high-quality annotated datasets. In this paper, we
introduce AfriSenti, which consists of 14 sentiment datasets of 110,000+ tweets
in 14 African languages (Amharic, Algerian Arabic, Hausa, Igbo, Kinyarwanda,
Moroccan Arabic, Mozambican Portuguese, Nigerian Pidgin, Oromo, Swahili,
Tigrinya, Twi, Xitsonga, and Yor\`ub\'a) from four language families annotated
by native speakers. The data is used in SemEval 2023 Task 12, the first
Afro-centric SemEval shared task. We describe the data collection methodology,
annotation process, and related challenges when curating each of the datasets.
We conduct experiments with different sentiment classification baselines and
discuss their usefulness. We hope AfriSenti enables new work on
under-represented languages. The dataset is available at
https://github.com/afrisenti-semeval/afrisent-semeval-2023 and can also be
loaded as a huggingface datasets
(https://huggingface.co/datasets/shmuhammad/AfriSenti).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Like a Good Nearest Neighbor: Practical Content Moderation with Sentence Transformers. (arXiv:2302.08957v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08957">
<div class="article-summary-box-inner">
<span><p>Modern text classification systems have impressive capabilities but are
infeasible to deploy and use reliably due to their dependence on prompting and
billion-parameter language models. SetFit (Tunstall et al., 2022) is a recent,
practical approach that fine-tunes a Sentence Transformer under a contrastive
learning paradigm and achieves similar results to more unwieldy systems. Text
classification is important for addressing the problem of domain drift in
detecting harmful content, which plagues all social media platforms. Here, we
propose Like a Good Nearest Neighbor (LaGoNN), an inexpensive modification to
SetFit that requires no additional parameters or hyperparameters but modifies
input with information about its nearest neighbor, for example, the label and
text, in the training data, making novel data appear similar to an instance on
which the model was optimized. LaGoNN is effective at the task of detecting
harmful content and generally improves performance compared to SetFit. To
demonstrate the value of our system, we conduct a thorough study of text
classification systems in the context of content moderation under four label
distributions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales. (arXiv:2302.08961v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08961">
<div class="article-summary-box-inner">
<span><p>The quality of text-to-image generation is continuously improving, yet the
boundaries of its applicability are still unclear. In particular, refinement of
the text input with the objective of achieving better results - commonly called
prompt engineering - so far seems to have not been geared towards work with
pre-existing texts. We investigate whether text-to-image generation and prompt
engineering could be used to generate basic illustrations of popular
fairytales. Using Midjourney v4, we engage in action research with a dual aim:
to attempt to generate 5 believable illustrations for each of 5 popular
fairytales, and to define a prompt engineering process that starts from a
pre-existing text and arrives at an illustration of it. We arrive at a
tentative 4-stage process: i) initial prompt, ii) composition adjustment, iii)
style refinement, and iv) variation selection. We also discuss three reasons
why the generation model struggles with certain illustrations: difficulties
with counts, bias from stereotypical configurations and inability to depict
overly fantastic situations. Our findings are not limited to the specific
generation model and are intended to be generalisable to future ones.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Fine-Grained Information: Identifying the Type and Location of Translation Errors. (arXiv:2302.08975v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08975">
<div class="article-summary-box-inner">
<span><p>Fine-grained information on translation errors is helpful for the translation
evaluation community. Existing approaches can not synchronously consider error
position and type, failing to integrate the error information of both. In this
paper, we propose Fine-Grained Translation Error Detection (FG-TED) task,
aiming at identifying both the position and the type of translation errors on
given source-hypothesis sentence pairs. Besides, we build an FG-TED model to
predict the \textbf{addition} and \textbf{omission} errors -- two typical
translation accuracy errors. First, we use a word-level classification paradigm
to form our model and use the shortcut learning reduction to relieve the
influence of monolingual features. Besides, we construct synthetic datasets for
model training, and relieve the disagreement of data labeling in authoritative
datasets, making the experimental benchmark concordant. Experiments show that
our model can identify both error type and position concurrently, and gives
state-of-the-art results on the restored dataset. Our model also delivers more
reliable predictions on low-resource and transfer scenarios than existing
baselines. The related datasets and the source code will be released in the
future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Designing and Evaluating Interfaces that Highlight News Coverage Diversity Using Discord Questions. (arXiv:2302.08997v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08997">
<div class="article-summary-box-inner">
<span><p>Modern news aggregators do the hard work of organizing a large news stream,
creating collections for a given news story with tens of source options. This
paper shows that navigating large source collections for a news story can be
challenging without further guidance. In this work, we design three interfaces
-- the Annotated Article, the Recomposed Article, and the Question Grid --
aimed at accompanying news readers in discovering coverage diversity while they
read. A first usability study with 10 journalism experts confirms the designed
interfaces all reveal coverage diversity and determine each interface's
potential use cases and audiences. In a second usability study, we developed
and implemented a reading exercise with 95 novice news readers to measure
exposure to coverage diversity. Results show that Annotated Article users are
able to answer questions 34% more completely than with two existing interfaces
while finding the interface equally easy to use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CK-Transformer: Commonsense Knowledge Enhanced Transformers for Referring Expression Comprehension. (arXiv:2302.09027v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.09027">
<div class="article-summary-box-inner">
<span><p>The task of multimodal referring expression comprehension (REC), aiming at
localizing an image region described by a natural language expression, has
recently received increasing attention within the research comminity. In this
paper, we specifically focus on referring expression comprehension with
commonsense knowledge (KB-Ref), a task which typically requires reasoning
beyond spatial, visual or semantic information. We propose a novel framework
for Commonsense Knowledge Enhanced Transformers (CK-Transformer) which
effectively integrates commonsense knowledge into the representations of
objects in an image, facilitating identification of the target objects referred
to by the expressions. We conduct extensive experiments on several benchmarks
for the task of KB-Ref. Our results show that the proposed CK-Transformer
achieves a new state of the art, with an absolute improvement of 3.14% accuracy
over the existing state of the art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Complex QA and language models hybrid architectures, Survey. (arXiv:2302.09051v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.09051">
<div class="article-summary-box-inner">
<span><p>This paper provides a survey of the state of the art of hybrid language
models architectures and strategies for "complex" question-answering (QA, CQA,
CPS). Very large language models are good at leveraging public data on standard
problems but once you want to tackle more specific complex questions or
problems you may need specific architecture, knowledge, skills, tasks, methods,
sensitive data, performance, human approval and versatile feedback... This
survey extends findings from the robust community edited research papers BIG,
BLOOM and HELM which open source, benchmark and analyze limits and challenges
of large language models in terms of tasks complexity and strict evaluation on
accuracy (e.g. fairness, robustness, toxicity, ...). It identifies the key
elements used with Large Language Models (LLM) to solve complex questions or
problems. Recent projects like ChatGPT and GALACTICA have allowed
non-specialists to grasp the great potential as well as the equally strong
limitations of language models in complex QA. Hybridizing these models with
different components could allow to overcome these different limits and go much
further. We discuss some challenges associated with complex QA, including
domain adaptation, decomposition and efficient multi-step QA, long form QA,
non-factoid QA, safety and multi-sensitivity data protection, multimodal
search, hallucinations, QA explainability and truthfulness, time dimension.
Therefore we review current solutions and promising strategies, using elements
such as hybrid LLM architectures, human-in-the-loop reinforcement learning,
prompting adaptation, neuro-symbolic and structured knowledge grounding,
program synthesis, and others. We analyze existing solutions and provide an
overview of the current research and trends in the area of complex QA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Aligning AI With Shared Human Values. (arXiv:2008.02275v6 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.02275">
<div class="article-summary-box-inner">
<span><p>We show how to assess a language model's knowledge of basic concepts of
morality. We introduce the ETHICS dataset, a new benchmark that spans concepts
in justice, well-being, duties, virtues, and commonsense morality. Models
predict widespread moral judgments about diverse text scenarios. This requires
connecting physical and social world knowledge to value judgements, a
capability that may enable us to steer chatbot outputs or eventually regularize
open-ended reinforcement learning agents. With the ETHICS dataset, we find that
current language models have a promising but incomplete ability to predict
basic human ethical judgements. Our work shows that progress can be made on
machine ethics today, and it provides a steppingstone toward AI that is aligned
with human values.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Keyphrase Extraction via Interpretable Neural Networks. (arXiv:2203.07640v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07640">
<div class="article-summary-box-inner">
<span><p>Keyphrase extraction aims at automatically extracting a list of "important"
phrases representing the key concepts in a document. Prior approaches for
unsupervised keyphrase extraction resorted to heuristic notions of phrase
importance via embedding clustering or graph centrality, requiring extensive
domain expertise. Our work presents a simple alternative approach which defines
keyphrases as document phrases that are salient for predicting the topic of the
document. To this end, we propose INSPECT -- an approach that uses
self-explaining models for identifying influential keyphrases in a document by
measuring the predictive impact of input phrases on the downstream task of the
document topic classification. We show that this novel method not only
alleviates the need for ad-hoc heuristics but also achieves state-of-the-art
results in unsupervised keyphrase extraction in four datasets across two
domains: scientific publications and news articles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Descartes: Generating Short Descriptions of Wikipedia Articles. (arXiv:2205.10012v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10012">
<div class="article-summary-box-inner">
<span><p>Wikipedia is one of the richest knowledge sources on the Web today. In order
to facilitate navigating, searching, and maintaining its content, Wikipedia's
guidelines state that all articles should be annotated with a so-called short
description indicating the article's topic (e.g., the short description of beer
is "Alcoholic drink made from fermented cereal grains"). Nonetheless, a large
fraction of articles (ranging from 10.2% in Dutch to 99.7% in Kazakh) have no
short description yet, with detrimental effects for millions of Wikipedia
users. Motivated by this problem, we introduce the novel task of automatically
generating short descriptions for Wikipedia articles and propose Descartes, a
multilingual model for tackling it. Descartes integrates three sources of
information to generate an article description in a target language: the text
of the article in all its language versions, the already-existing descriptions
(if any) of the article in other languages, and semantic type information
obtained from a knowledge graph. We evaluate a Descartes model trained for
handling 25 languages simultaneously, showing that it beats baselines
(including a strong translation-based baseline) and performs on par with
monolingual models tailored for specific languages. A human evaluation on three
languages further shows that the quality of Descartes's descriptions is largely
indistinguishable from that of human-written descriptions; e.g., 91.3% of our
English descriptions (vs. 92.1% of human-written descriptions) pass the bar for
inclusion in Wikipedia, suggesting that Descartes is ready for production, with
the potential to support human editors in filling a major gap in today's
Wikipedia across languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Write and Paint: Generative Vision-Language Models are Unified Modal Learners. (arXiv:2206.07699v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.07699">
<div class="article-summary-box-inner">
<span><p>Recent advances in vision-language pre-training have pushed the
state-of-the-art on various vision-language tasks, making machines more capable
of multi-modal writing (image-to-text generation) and painting (text-to-image
generation). However, few studies investigate if these two essential
capabilities can be learned together and boost each other, making a versatile
and powerful multi-modal foundation model. In this work, we disclose the
potential of symmetric generative vision-language pre-training in learning to
write and paint concurrently, and propose a new unified modal model, named
DaVinci, trained with prefix language modeling and prefix image modeling, a
simple generative self-supervised objective on image-text pairs. Thanks to the
proposed prefix multi-modal modeling framework, DaVinci is simple to train,
scalable to huge data, adaptable to both writing and painting tasks, and also
strong on other vision, text, and multi-modal understanding tasks. DaVinci
achieves competitive performance on a wide range of 27 generation/understanding
tasks and demonstrates the superiority of combining vision/language generative
pre-training. Furthermore, we carefully benchmark the performance of different
vision-language pre-training objectives on different scales of pre-training
datasets on a heterogeneous and broad distribution coverage. Our results
demonstrate the potential of exploiting self-supervision in both language and
vision inputs, and establish new, stronger baselines for future comparisons at
different data scales. The code and pre-trained models are available at
https://github.com/shizhediao/DaVinci.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FRMT: A Benchmark for Few-Shot Region-Aware Machine Translation. (arXiv:2210.00193v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.00193">
<div class="article-summary-box-inner">
<span><p>We present FRMT, a new dataset and evaluation benchmark for Few-shot
Region-aware Machine Translation, a type of style-targeted translation. The
dataset consists of professional translations from English into two regional
variants each of Portuguese and Mandarin Chinese. Source documents are selected
to enable detailed analysis of phenomena of interest, including lexically
distinct terms and distractor terms. We explore automatic evaluation metrics
for FRMT and validate their correlation with expert human evaluation across
both region-matched and mismatched rating scenarios. Finally, we present a
number of baseline models for this task, and offer guidelines for how
researchers can train, evaluate, and compare their own models. Our dataset and
evaluation code are publicly available: https://bit.ly/frmt-task
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Kernel-Based View of Language Model Fine-Tuning. (arXiv:2210.05643v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.05643">
<div class="article-summary-box-inner">
<span><p>It has become standard to solve NLP tasks by fine-tuning pre-trained language
models (LMs), especially in low-data settings. There is minimal theoretical
understanding of empirical success, e.g., why fine-tuning a model with $10^8$
or more parameters on a couple dozen training points does not result in
overfitting. We investigate whether the Neural Tangent Kernel (NTK) - which
originated as a model to study the gradient descent dynamics of infinitely wide
networks with suitable random initialization - describes fine-tuning of
pre-trained LMs. This study was inspired by the decent performance of NTK for
computer vision tasks (Wei et al., 2022). We extend the NTK formalism to Adam
and use Tensor Programs (Yang, 2020) to characterize conditions under which the
NTK lens may describe fine-tuning updates to pre-trained language models.
Extensive experiments on 14 NLP tasks validate our theory and show that
formulating the downstream task as a masked word prediction problem through
prompting often induces kernel-based dynamics during fine-tuning. Finally, we
use this kernel view to propose an explanation for the success of
parameter-efficient subspace-based fine-tuning methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Alibaba-Translate China's Submission for WMT 2022 Metrics Shared Task. (arXiv:2210.09683v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.09683">
<div class="article-summary-box-inner">
<span><p>In this report, we present our submission to the WMT 2022 Metrics Shared
Task. We build our system based on the core idea of UNITE (Unified Translation
Evaluation), which unifies source-only, reference-only, and
source-reference-combined evaluation scenarios into one single model.
Specifically, during the model pre-training phase, we first apply the
pseudo-labeled data examples to continuously pre-train UNITE. Notably, to
reduce the gap between pre-training and fine-tuning, we use data cropping and a
ranking-based score normalization strategy. During the fine-tuning phase, we
use both Direct Assessment (DA) and Multidimensional Quality Metrics (MQM) data
from past years' WMT competitions. Specially, we collect the results from
models with different pre-trained language model backbones, and use different
ensembling strategies for involved translation directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Alibaba-Translate China's Submission for WMT 2022 Quality Estimation Shared Task. (arXiv:2210.10049v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10049">
<div class="article-summary-box-inner">
<span><p>In this paper, we present our submission to the sentence-level MQM benchmark
at Quality Estimation Shared Task, named UniTE (Unified Translation
Evaluation). Specifically, our systems employ the framework of UniTE, which
combined three types of input formats during training with a pre-trained
language model. First, we apply the pseudo-labeled data examples for the
continuously pre-training phase. Notably, to reduce the gap between
pre-training and fine-tuning, we use data pruning and a ranking-based score
normalization strategy. For the fine-tuning phase, we use both Direct
Assessment (DA) and Multidimensional Quality Metrics (MQM) data from past
years' WMT competitions. Finally, we collect the source-only evaluation
results, and ensemble the predictions generated by two UniTE models, whose
backbones are XLM-R and InfoXLM, respectively. Results show that our models
reach 1st overall ranking in the Multilingual and English-Russian settings, and
2nd overall ranking in English-German and Chinese-English settings, showing
relatively strong performances in this year's quality estimation competition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modular Hybrid Autoregressive Transducer. (arXiv:2210.17049v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.17049">
<div class="article-summary-box-inner">
<span><p>Text-only adaptation of a transducer model remains challenging for end-to-end
speech recognition since the transducer has no clearly separated acoustic model
(AM), language model (LM) or blank model. In this work, we propose a modular
hybrid autoregressive transducer (MHAT) that has structurally separated label
and blank decoders to predict label and blank distributions, respectively,
along with a shared acoustic encoder. The encoder and label decoder outputs are
directly projected to AM and internal LM scores and then added to compute label
posteriors. We train MHAT with an internal LM loss and a HAT loss to ensure
that its internal LM becomes a standalone neural LM that can be effectively
adapted to text. Moreover, text adaptation of MHAT fosters a much better LM
fusion than internal LM subtraction-based methods. On Google's large-scale
production data, a multi-domain MHAT adapted with 100B sentences achieves
relative WER reductions of up to 12.4% without LM fusion and 21.5% with LM
fusion from 400K-hour trained HAT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Building Text-To-Speech Systems for the Next Billion Users. (arXiv:2211.09536v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09536">
<div class="article-summary-box-inner">
<span><p>Deep learning based text-to-speech (TTS) systems have been evolving rapidly
with advances in model architectures, training methodologies, and
generalization across speakers and languages. However, these advances have not
been thoroughly investigated for Indian language speech synthesis. Such
investigation is computationally expensive given the number and diversity of
Indian languages, relatively lower resource availability, and the diverse set
of advances in neural TTS that remain untested. In this paper, we evaluate the
choice of acoustic models, vocoders, supplementary loss functions, training
schedules, and speaker and language diversity for Dravidian and Indo-Aryan
languages. Based on this, we identify monolingual models with FastPitch and
HiFi-GAN V1, trained jointly on male and female speakers to perform the best.
With this setup, we train and evaluate TTS models for 13 languages and find our
models to significantly improve upon existing models in all languages as
measured by mean opinion scores. We open-source all models on the Bhashini
platform.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints. (arXiv:2212.05055v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.05055">
<div class="article-summary-box-inner">
<span><p>Training large, deep neural networks to convergence can be prohibitively
expensive. As a result, often only a small selection of popular, dense models
are reused across different contexts and tasks. Increasingly, sparsely
activated models, which seek to decouple model size from computation costs, are
becoming an attractive alternative to dense models. Although more efficient in
terms of quality and computation cost, sparse models remain data-hungry and
costly to train from scratch in the large scale regime. In this work, we
propose sparse upcycling -- a simple way to reuse sunk training costs by
initializing a sparsely activated Mixture-of-Experts model from a dense
checkpoint. We show that sparsely upcycled T5 Base, Large, and XL language
models and Vision Transformer Base and Large models, respectively,
significantly outperform their dense counterparts on SuperGLUE and ImageNet,
using only ~50% of the initial dense pretraining sunk cost. The upcycled models
also outperform sparse models trained from scratch on 100% of the initial dense
pretraining computation budget.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text Generation with Diffusion Language Models: A Pre-training Approach with Continuous Paragraph Denoise. (arXiv:2212.11685v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.11685">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce a novel dIffusion language modEl pre-training
framework for text generation, which we call GENIE. GENIE is a large-scale
pretrained diffusion language model that consists of an encoder and a
diffusion-based decoder, which can generate text by gradually transforming a
random noise sequence into a coherent text sequence. To pre-train GENIE on a
large-scale language corpus, we design a new continuous paragraph denoise
objective, which encourages the diffusion-decoder to reconstruct a clean text
paragraph from a corrupted version, while preserving the semantic and syntactic
coherence. We evaluate GENIE on four downstream text generation benchmarks,
namely XSum, CNN/DailyMail, Gigaword, and CommonGen. Our experimental results
show that GENIE achieves comparable performance with the state-of-the-art
autoregressive models on these benchmarks, and generates more diverse text
samples. The code and models of GENIE are available at
https://github.com/microsoft/ProphetNet/tree/master/GENIE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TextDescriptives: A Python package for calculating a large variety of metrics from text. (arXiv:2301.02057v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.02057">
<div class="article-summary-box-inner">
<span><p>TextDescriptives is a Python package for calculating a large variety of
metrics from text. It is built on top of spaCy and can be easily integrated
into existing workflows. The package has already been used for analysing the
linguistic stability of clinical texts, creating features for predicting
neuropsychiatric conditions, and analysing linguistic goals of primary school
students. This paper describes the package and its features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topic Modelling of Swedish Newspaper Articles about Coronavirus: a Case Study using Latent Dirichlet Allocation Method. (arXiv:2301.03029v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.03029">
<div class="article-summary-box-inner">
<span><p>Topic Modelling (TM) is from the research branches of natural language
understanding (NLU) and natural language processing (NLP) that is to facilitate
insightful analysis from large documents and datasets, such as a summarisation
of main topics and the topic changes. This kind of discovery is getting more
popular in real-life applications due to its impact on big data analytics. In
this study, from the social-media and healthcare domain, we apply popular
Latent Dirichlet Allocation (LDA) methods to model the topic changes in Swedish
newspaper articles about Coronavirus. We describe the corpus we created
including 6515 articles, methods applied, and statistics on topic changes over
approximately 1 year and two months period of time from 17th January 2020 to
13th March 2021. We hope this work can be an asset for grounding applications
of topic modelling and can be inspiring for similar case studies in an era with
pandemics, to support socio-economic impact research as well as clinical and
healthcare analytics. Our data and source code are openly available at
https://github. com/poethan/Swed_Covid_TM Keywords: Latent Dirichlet Allocation
(LDA); Topic Modelling; Coronavirus; Pandemics; Natural Language Understanding;
BERT-topic
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Chain-of-Thought Reasoning in Language Models. (arXiv:2302.00923v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00923">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have shown impressive performance on complex
reasoning by leveraging chain-of-thought (CoT) prompting to generate
intermediate reasoning chains as the rationale to infer the answer. However,
existing CoT studies have focused on the language modality. We propose
Multimodal-CoT that incorporates language (text) and vision (images) modalities
into a two-stage framework that separates rationale generation and answer
inference. In this way, answer inference can leverage better generated
rationales that are based on multimodal information. With Multimodal-CoT, our
model under 1 billion parameters outperforms the previous state-of-the-art LLM
(GPT-3.5) by 16 percentage points (75.17%-&gt;91.68% accuracy) on the ScienceQA
benchmark and even surpasses human performance. Code is publicly available
available at https://github.com/amazon-science/mm-cot.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">$IC^3$: Image Captioning by Committee Consensus. (arXiv:2302.01328v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01328">
<div class="article-summary-box-inner">
<span><p>If you ask a human to describe an image, they might do so in a thousand
different ways. Traditionally, image captioning models are trained to
approximate the reference distribution of image captions, however, doing so
encourages captions that are viewpoint-impoverished. Such captions often focus
on only a subset of the possible details, while ignoring potentially useful
information in the scene. In this work, we introduce a simple, yet novel,
method: "Image Captioning by Committee Consensus" ($IC^3$), designed to
generate a single caption that captures high-level details from several
viewpoints. Notably, humans rate captions produced by $IC^3$ at least as
helpful as baseline SOTA models more than two thirds of the time, and $IC^3$
captions can improve the performance of SOTA automated recall systems by up to
84%, indicating significant material improvements over existing SOTA approaches
for visual description. Our code is publicly available at
https://github.com/DavidMChan/caption-by-committee
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PLACES: Prompting Language Models for Social Conversation Synthesis. (arXiv:2302.03269v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03269">
<div class="article-summary-box-inner">
<span><p>Collecting high quality conversational data can be very expensive for most
applications and infeasible for others due to privacy, ethical, or similar
concerns. A promising direction to tackle this problem is to generate synthetic
dialogues by prompting large language models. In this work, we use a small set
of expert-written conversations as in-context examples to synthesize a social
conversation dataset using prompting. We perform several thorough evaluations
of our synthetic conversations compared to human-collected conversations. This
includes various dimensions of conversation quality with human evaluation
directly on the synthesized conversations, and interactive human evaluation of
chatbots fine-tuned on the synthetically generated dataset. We additionally
demonstrate that this prompting approach is generalizable to multi-party
conversations, providing potential to create new synthetic data for multi-party
tasks. Our synthetic multi-party conversations were rated more favorably across
all measured dimensions compared to conversation excerpts sampled from a
human-collected multi-party dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Categorical Archive of ChatGPT Failures. (arXiv:2302.03494v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03494">
<div class="article-summary-box-inner">
<span><p>Large language models have been demonstrated to be valuable in different
fields. ChatGPT, developed by OpenAI, has been trained using massive amounts of
data and simulates human conversation by comprehending context and generating
appropriate responses. It has garnered significant attention due to its ability
to effectively answer a broad range of human inquiries, with fluent and
comprehensive answers surpassing prior public chatbots in both security and
usefulness. However, a comprehensive analysis of ChatGPT's failures is lacking,
which is the focus of this study. Eleven categories of failures, including
reasoning, factual errors, math, coding, and bias, are presented and discussed.
The risks, limitations, and societal implications of ChatGPT are also
highlighted. The goal of this study is to assist researchers and developers in
enhancing future language models and chatbots.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Symbolic Discovery of Optimization Algorithms. (arXiv:2302.06675v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.06675">
<div class="article-summary-box-inner">
<span><p>We present a method to formulate algorithm discovery as program search, and
apply it to discover optimization algorithms for deep neural network training.
We leverage efficient search techniques to explore an infinite and sparse
program space. To bridge the large generalization gap between proxy and target
tasks, we also introduce program selection and simplification strategies. Our
method discovers a simple and effective optimization algorithm, $\textbf{Lion}$
($\textit{Evo$\textbf{L}$ved S$\textbf{i}$gn M$\textbf{o}$me$\textbf{n}$tum}$).
It is more memory-efficient than Adam as it only keeps track of the momentum.
Different from adaptive optimizers, its update has the same magnitude for each
parameter calculated through the sign operation. We compare Lion with widely
used optimizers, such as Adam and Adafactor, for training a variety of models
on different tasks. On image classification, Lion boosts the accuracy of ViT by
up to 2% on ImageNet and saves up to 5x the pre-training compute on JFT. On
vision-language contrastive learning, we achieve 88.3% $\textit{zero-shot}$ and
91.1% $\textit{fine-tuning}$ accuracy on ImageNet, surpassing the previous best
results by 2% and 0.1%, respectively. On diffusion models, Lion outperforms
Adam by achieving a better FID score and reducing the training compute by up to
2.3x. For autoregressive, masked language modeling, and fine-tuning, Lion
exhibits a similar or better performance compared to Adam. Our analysis of Lion
reveals that its performance gain grows with the training batch size. It also
requires a smaller learning rate than Adam due to the larger norm of the update
produced by the sign function. Additionally, we examine the limitations of Lion
and identify scenarios where its improvements are small or not statistically
significant. The implementation of Lion is publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Learning Model Attribution Challenge. (arXiv:2302.06716v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.06716">
<div class="article-summary-box-inner">
<span><p>We present the findings of the Machine Learning Model Attribution Challenge.
Fine-tuned machine learning models may derive from other trained models without
obvious attribution characteristics. In this challenge, participants identify
the publicly-available base models that underlie a set of anonymous, fine-tuned
large language models (LLMs) using only textual output of the models.
Contestants aim to correctly attribute the most fine-tuned models, with ties
broken in the favor of contestants whose solutions use fewer calls to the
fine-tuned models' API. The most successful approaches were manual, as
participants observed similarities between model outputs and developed
attribution heuristics based on public documentation of the base models, though
several teams also submitted automated, statistical solutions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI Chat Assistants can Improve Conversations about Divisive Topics. (arXiv:2302.07268v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07268">
<div class="article-summary-box-inner">
<span><p>A rapidly increasing amount of human conversation occurs online. But
divisiveness and conflict can fester in text-based interactions on social media
platforms, in messaging apps, and on other digital forums. Such toxicity
increases polarization and, importantly, corrodes the capacity of diverse
societies to develop efficient solutions to complex social problems that impact
everyone. Scholars and civil society groups promote interventions that can make
interpersonal conversations less divisive or more productive in offline
settings, but scaling these efforts to the amount of discourse that occurs
online is extremely challenging. We present results of a large-scale experiment
that demonstrates how online conversations about divisive topics can be
improved with artificial intelligence tools. Specifically, we employ a large
language model to make real-time, evidence-based recommendations intended to
improve participants' perception of feeling understood in conversations. We
find that these interventions improve the reported quality of the conversation,
reduce political divisiveness, and improve the tone, without systematically
changing the content of the conversation or moving people's policy attitudes.
These findings have important implications for future research on social media,
political deliberation, and the growing community of scholars interested in the
place of artificial intelligence within computational social science.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficiency 360: Efficient Vision Transformers. (arXiv:2302.08374v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08374">
<div class="article-summary-box-inner">
<span><p>Transformers are widely used for solving tasks in natural language
processing, computer vision, speech, and music domains. In this paper, we talk
about the efficiency of transformers in terms of memory (the number of
parameters), computation cost (number of floating points operations), and
performance of models, including accuracy, the robustness of the model, and
fair \&amp; bias-free features. We mainly discuss the vision transformer for the
image classification task. Our contribution is to introduce an efficient 360
framework, which includes various aspects of the vision transformer, to make it
more efficient for industrial applications. By considering those applications,
we categorize them into multiple dimensions such as privacy, robustness,
transparency, fairness, inclusiveness, continual learning, probabilistic
models, approximation, computational complexity, and spectral complexity. We
compare various vision transformer models based on their performance, the
number of parameters, and the number of floating point operations (FLOPs) on
multiple datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks. (arXiv:2302.08399v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08399">
<div class="article-summary-box-inner">
<span><p>Intuitive psychology is a pillar of common-sense reasoning. The replication
of this reasoning in machine intelligence is an important stepping-stone on the
way to human-like artificial intelligence. Several recent tasks and benchmarks
for examining this reasoning in Large-Large Models have focused in particular
on belief attribution in Theory-of-Mind tasks. These tasks have shown both
successes and failures. We consider in particular a recent purported success
case, and show that small variations that maintain the principles of ToM turn
the results on their head. We argue that in general, the zero-hypothesis for
model evaluation in intuitive psychology should be skeptical, and that outlying
failure cases should outweigh average success rates. We also consider what
possible future successes on Theory-of-Mind tasks by more powerful LLMs would
mean for ToM tasks with people.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-02-20 23:12:50.036662422 UTC">2023-02-20 23:12:50 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>