<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-02-09T01:30:00Z">02-09</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Concept Algebra for Text-Controlled Vision Models. (arXiv:2302.03693v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03693">
<div class="article-summary-box-inner">
<span><p>This paper concerns the control of text-guided generative models, where a
user provides a natural language prompt and the model generates samples based
on this input. Prompting is intuitive, general, and flexible. However, there
are significant limitations: prompting can fail in surprising ways, and it is
often unclear how to find a prompt that will elicit some desired target
behavior. A core difficulty for developing methods to overcome these issues is
that failures are know-it-when-you-see-it -- it's hard to fix bugs if you can't
state precisely what the model should have done! In this paper, we introduce a
formalization of "what the user intended" in terms of latent concepts implicit
to the data generating process that the model was trained on. This
formalization allows us to identify some fundamental limitations of prompting.
We then use the formalism to develop concept algebra to overcome these
limitations. Concept algebra is a way of directly manipulating the concepts
expressed in the output through algebraic operations on a suitably defined
representation of input prompts. We give examples using concept algebra to
overcome limitations of prompting, including concept transfer through
arithmetic, and concept nullification through projection. Code available at
https://github.com/zihao12/concept-algebra.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Characterizing Financial Market Coverage using Artificial Intelligence. (arXiv:2302.03694v1 [q-fin.ST])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03694">
<div class="article-summary-box-inner">
<span><p>This paper scrutinizes a database of over 4900 YouTube videos to characterize
financial market coverage. Financial market coverage generates a large number
of videos. Therefore, watching these videos to derive actionable insights could
be challenging and complex. In this paper, we leverage Whisper, a
speech-to-text model from OpenAI, to generate a text corpus of market coverage
videos from Bloomberg and Yahoo Finance. We employ natural language processing
to extract insights regarding language use from the market coverage. Moreover,
we examine the prominent presence of trending topics and their evolution over
time, and the impacts that some individuals and organizations have on the
financial market. Our characterization highlights the dynamics of the financial
market coverage and provides valuable insights reflecting broad discussions
regarding recent financial events and the world economy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mining Effective Features Using Quantum Entropy for Humor Recognition. (arXiv:2302.03716v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03716">
<div class="article-summary-box-inner">
<span><p>Humor recognition has been extensively studied with different methods in the
past years. However, existing studies on humor recognition do not understand
the mechanisms that generate humor. In this paper, inspired by the incongruity
theory, any joke can be divided into two components (the setup and the
punchline). Both components have multiple possible semantics, and there is an
incongruous relationship between them. We use density matrices to represent the
semantic uncertainty of the setup and the punchline, respectively, and design
QE-Uncertainty and QE-Incongruity with the help of quantum entropy as features
for humor recognition. The experimental results on the SemEval2021 Task 7
dataset show that the proposed features are more effective than the baselines
for recognizing humorous and non-humorous texts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories. (arXiv:2302.03754v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03754">
<div class="article-summary-box-inner">
<span><p>In this paper we improve the zero-shot generalization ability of language
models via Mixture-Of-Memory Augmentation (MoMA), a mechanism that retrieves
augmentation documents from multiple information corpora ("external memories"),
with the option to "plug in" new memory at inference time. We develop a joint
learning mechanism that trains the augmentation component with latent labels
derived from the end retrieval task, paired with hard negatives from the memory
mixture. We instantiate the model in a zero-shot dense retrieval setting by
augmenting a strong T5-based retriever with MoMA. Our model, MoMA, obtains
strong zero-shot retrieval accuracy on the eighteen tasks included in the
standard BEIR benchmark. It outperforms systems that seek generalization from
increased model parameters and computation steps. Our analysis further
illustrates the necessity of augmenting with mixture-of-memory for robust
generalization, the benefits of augmentation learning, and how MoMA utilizes
the plug-in memory at inference time without changing its parameters. We plan
to open source our code.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer-based Models for Long-Form Document Matching: Challenges and Empirical Analysis. (arXiv:2302.03765v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03765">
<div class="article-summary-box-inner">
<span><p>Recent advances in the area of long document matching have primarily focused
on using transformer-based models for long document encoding and matching.
There are two primary challenges associated with these models. Firstly, the
performance gain provided by transformer-based models comes at a steep cost -
both in terms of the required training time and the resource (memory and
energy) consumption. The second major limitation is their inability to handle
more than a pre-defined input token length at a time. In this work, we
empirically demonstrate the effectiveness of simple neural models (such as
feed-forward networks, and CNNs) and simple embeddings (like GloVe, and
Paragraph Vector) over transformer-based models on the task of document
matching. We show that simple models outperform the more complex BERT-based
models while taking significantly less training time, energy, and memory. The
simple models are also more robust to variations in document length and text
perturbations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What Matters In The Structured Pruning of Generative Language Models?. (arXiv:2302.03773v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03773">
<div class="article-summary-box-inner">
<span><p>Auto-regressive large language models such as GPT-3 require enormous
computational resources to use. Traditionally, structured pruning methods are
employed to reduce resource usage. However, their application to and efficacy
for generative language models is heavily under-explored. In this paper we
conduct an comprehensive evaluation of common structured pruning methods,
including magnitude, random, and movement pruning on the feed-forward layers in
GPT-type models. Unexpectedly, random pruning results in performance that is
comparable to the best established methods, across multiple natural language
generation tasks. To understand these results, we provide a framework for
measuring neuron-level redundancy of models pruned by different methods, and
discover that established structured pruning methods do not take into account
the distinctiveness of neurons, leaving behind excess redundancies. In view of
this, we introduce Globally Unique Movement (GUM) to improve the uniqueness of
neurons in pruned models. We then discuss the effects of our techniques on
different redundancy metrics to explain the improved performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reliable Natural Language Understanding with Large Language Models and Answer Set Programming. (arXiv:2302.03780v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03780">
<div class="article-summary-box-inner">
<span><p>Humans understand language by extracting information (meaning) from
sentences, combining it with existing commonsense knowledge, and then
performing reasoning to draw conclusions. While large language models (LLMs)
such as GPT-3 and ChatGPT are able to leverage patterns in the text to solve a
variety of NLP tasks, they fall short in problems that require reasoning. They
also cannot reliably explain the answers generated for a given question. In
order to emulate humans better, we propose STAR, a framework that combines LLMs
with Answer Set Programming (ASP). We show how LLMs can be used to effectively
extract knowledge -- represented as predicates -- from language. Goal-directed
ASP is then employed to reliably reason over this knowledge. We apply the STAR
framework to three different NLU tasks requiring reasoning: qualitative
reasoning, mathematical reasoning, and goal-directed conversation. Our
experiments reveal that STAR is able to bridge the gap of reasoning in NLU
tasks, leading to significant performance improvements, especially for smaller
LLMs, i.e., LLMs with a smaller number of parameters. NLU applications
developed using the STAR framework are also explainable: along with the
predicates generated, a justification in the form of a proof tree can be
produced for a given output.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Long Text and Multi-Table Summarization: Dataset and Method. (arXiv:2302.03815v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03815">
<div class="article-summary-box-inner">
<span><p>Automatic document summarization aims to produce a concise summary covering
the input document's salient information. Within a report document, the salient
information can be scattered in the textual and non-textual content. However,
existing document summarization datasets and methods usually focus on the text
and filter out the non-textual content. Missing tabular data can limit produced
summaries' informativeness, especially when summaries require covering
quantitative descriptions of critical metrics in tables. Existing datasets and
methods cannot meet the requirements of summarizing long text and multiple
tables in each report. To deal with the scarcity of available data, we propose
FINDSum, the first large-scale dataset for long text and multi-table
summarization. Built on 21,125 annual reports from 3,794 companies, it has two
subsets for summarizing each company's results of operations and liquidity. To
summarize the long text and dozens of tables in each report, we present three
types of summarization methods. Besides, we propose a set of evaluation metrics
to assess the usage of numerical information in produced summaries. Dataset
analyses and experimental results indicate the importance of jointly
considering input textual and tabular data when summarizing report documents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Clinical BioBERT Hyperparameter Optimization using Genetic Algorithm Clinical BioBERT Hyperparameter Optimization using Genetic Algorithm. (arXiv:2302.03822v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03822">
<div class="article-summary-box-inner">
<span><p>Clinical factors account only for a small portion, about 10-30%, of the
controllable factors that affect an individual's health outcomes. The remaining
factors include where a person was born and raised, where he/she pursued their
education, what their work and family environment is like, etc. These factors
are collectively referred to as Social Determinants of Health (SDoH). The
majority of SDoH data is recorded in unstructured clinical notes by physicians
and practitioners. Recording SDoH data in a structured manner (in an EHR) could
greatly benefit from a dedicated ontology of SDoH terms. Our research focuses
on extracting sentences from clinical notes, making use of such an SDoH
ontology (called SOHO) to provide appropriate concepts. We utilize recent
advancements in Deep Learning to optimize the hyperparameters of a Clinical
BioBERT model for SDoH text. A genetic algorithm-based hyperparameter tuning
regimen was implemented to identify optimal parameter settings. To implement a
complete classifier, we pipelined Clinical BioBERT with two subsequent linear
layers and two dropout layers. The output predicts whether a text fragment
describes an SDoH issue of the patient. We compared the AdamW, Adafactor, and
LAMB optimizers. In our experiments, AdamW outperformed the others in terms of
accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controlling Personality Style in Dialogue with Zero-Shot Prompt-Based Learning. (arXiv:2302.03848v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03848">
<div class="article-summary-box-inner">
<span><p>Prompt-based or in-context learning has achieved high zero-shot performance
on many natural language generation (NLG) tasks. Here we explore the
performance of prompt-based learning for simultaneously controlling the
personality and the semantic accuracy of an NLG for task-oriented dialogue. We
experiment with prompt-based learning on the PERSONAGE restaurant
recommendation corpus to generate semantically and stylistically-controlled
text for 5 different Big-5 personality types: agreeable, disagreeable,
conscientious, unconscientious, and extravert. We test two different classes of
discrete prompts to generate utterances for a particular personality style: (1)
prompts that demonstrate generating directly from a meaning representation that
includes a personality specification; and (2) prompts that rely on first
converting the meaning representation to a textual pseudo-reference, and then
using the pseudo-reference in a textual style transfer (TST) prompt. In each
case, we show that we can vastly improve performance by over-generating outputs
and ranking them, testing several ranking functions based on automatic metrics
for semantic accuracy, personality-match, and fluency. We also test whether NLG
personality demonstrations from the restaurant domain can be used with meaning
representations for the video game domain to generate personality stylized
utterances about video games. Our findings show that the TST prompts produces
the highest semantic accuracy (78.46% for restaurants and 87.6% for video
games) and personality accuracy (100% for restaurants and 97% for video games).
Our results on transferring personality style to video game utterances are
surprisingly good. To our knowledge, there is no previous work testing the
application of prompt-based learning to simultaneously controlling both style
and semantic accuracy in NLG.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Auto-Learning: An Adversarial Process of Two Pre-trained Models for Natural Language Generation. (arXiv:2302.03896v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03896">
<div class="article-summary-box-inner">
<span><p>Pre-trained models have been used in many fields in recent years, ranging
from natural language understanding to computer vision and natural language
generation. However, the performance of these natural language generation
models is overly dependent on the scale of the model and the size of the
dataset. While the larger language model is excellent in some respects, it
cannot learn up-to-date knowledge and is relatively difficult to relearn. In
this paper, a new adversarial process learning method called Auto-Learning.
This can improve the performance of any natural language generation model
without the help of additional datasets. Auto-Learning includes two models: $G$
is a text generation model and $D$ can test whether the data generated by G is
legitimate. Firstly, the fine-tuned $D$ model is used as the brain's knowledge
base before the process. Then the text generated by the $G$ model is used as
the input of $D$ to determine whether the text is legitimate or not. Finally,
$G$ is fine-tuned according to the output of $D$. This adversarial process is
like a self-escalation of the brain through some a priori knowledge. When this
adversarial system wants to learn something new, simply fine-tune the $D$
model. Our approach applies to Autoregressive Language Modeling for all
Transformer classes. The results are good in existing experimental tasks,
including more grammatical text generation and better performance on some text
comprehension tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COMBO: A Complete Benchmark for Open KG Canonicalization. (arXiv:2302.03905v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03905">
<div class="article-summary-box-inner">
<span><p>Open knowledge graph (KG) consists of (subject, relation, object) triples
extracted from millions of raw text. The subject and object noun phrases and
the relation in open KG have severe redundancy and ambiguity and need to be
canonicalized. Existing datasets for open KG canonicalization only provide gold
entity-level canonicalization for noun phrases. In this paper, we present
COMBO, a Complete Benchmark for Open KG canonicalization. Compared with
existing datasets, we additionally provide gold canonicalization for relation
phrases, gold ontology-level canonicalization for noun phrases, as well as
source sentences from which triples are extracted. We also propose metrics for
evaluating each type of canonicalization. On the COMBO dataset, we empirically
compare previously proposed canonicalization methods as well as a few simple
baseline methods based on pretrained language models. We find that properly
encoding the phrases in a triple using pretrained language models results in
better relation canonicalization and ontology-level canonicalization of the
noun phrase. We release our dataset, baselines, and evaluation scripts at
https://github.com/jeffchy/COMBO/tree/main.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving (Dis)agreement Detection with Inductive Social Relation Information From Comment-Reply Interactions. (arXiv:2302.03950v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03950">
<div class="article-summary-box-inner">
<span><p>(Dis)agreement detection aims to identify the authors' attitudes or positions
(\textit{{agree, disagree, neutral}}) towards a specific text. It is limited
for existing methods merely using textual information for identifying
(dis)agreements, especially for cross-domain settings. Social relation
information can play an assistant role in the (dis)agreement task besides
textual information. We propose a novel method to extract such relation
information from (dis)agreement data into an inductive social relation graph,
merely using the comment-reply pairs without any additional platform-specific
information. The inductive social relation globally considers the historical
discussion and the relation between authors. Textual information based on a
pre-trained language model and social relation information encoded by
pre-trained RGCN are jointly considered for (dis)agreement detection.
Experimental results show that our model achieves state-of-the-art performance
for both the in-domain and cross-domain tasks on the benchmark -- DEBAGREEMENT.
We find social relations can boost the performance of the (dis)agreement
detection model, especially for the long-token comment-reply pairs,
demonstrating the effectiveness of the social relation graph. We also explore
the effect of the knowledge graph embedding methods, the information fusing
method, and the time interval in constructing the social relation graph, which
shows the effectiveness of our model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Summary Guidance on Medical Report Summarization. (arXiv:2302.04001v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04001">
<div class="article-summary-box-inner">
<span><p>This study presents three deidentified large medical text datasets, named
DISCHARGE, ECHO and RADIOLOGY, which contain 50K, 16K and 378K pairs of report
and summary that are derived from MIMIC-III, respectively. We implement
convincing baselines of automated abstractive summarization on the proposed
datasets with pre-trained encoder-decoder language models, including BERT2BERT,
T5-large and BART. Further, based on the BART model, we leverage the sampled
summaries from the train set as prior knowledge guidance, for encoding
additional contextual representations of the guidance with the encoder and
enhancing the decoding representations in the decoder. The experimental results
confirm the improvement of ROUGE scores and BERTScore made by the proposed
method, outperforming the larger model T5-large.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Systematically Finding Security Vulnerabilities in Black-Box Code Generation Models. (arXiv:2302.04012v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04012">
<div class="article-summary-box-inner">
<span><p>Recently, large language models for code generation have achieved
breakthroughs in several programming language tasks. Their advances in
competition-level programming problems have made them an emerging pillar in
AI-assisted pair programming. Tools such as GitHub Copilot are already part of
the daily programming workflow and are used by more than a million developers.
The training data for these models is usually collected from open-source
repositories (e.g., GitHub) that contain software faults and security
vulnerabilities. This unsanitized training data can lead language models to
learn these vulnerabilities and propagate them in the code generation
procedure. Given the wide use of these models in the daily workflow of
developers, it is crucial to study the security aspects of these models
systematically.
</p>
<p>In this work, we propose the first approach to automatically finding security
vulnerabilities in black-box code generation models. To achieve this, we
propose a novel black-box inversion approach based on few-shot prompting. We
evaluate the effectiveness of our approach by examining code generation models
in the generation of high-risk security weaknesses. We show that our approach
automatically and systematically finds 1000s of security vulnerabilities in
various code generation models, including the commercial black-box model GitHub
Copilot.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity. (arXiv:2302.04023v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04023">
<div class="article-summary-box-inner">
<span><p>This paper proposes a framework for quantitatively evaluating interactive
LLMs such as ChatGPT using publicly available data sets. We carry out an
extensive technical evaluation of ChatGPT using 21 data sets covering 8
different common NLP application tasks. We evaluate the multitask, multilingual
and multi-modal aspects of ChatGPT based on these data sets and a newly
designed multimodal dataset. We find that ChatGPT outperforms LLMs with
zero-shot learning on most tasks and even outperforms fine-tuned models on some
tasks. We find that it is better at understanding non-Latin script languages
than generating them. It is able to generate multimodal content from textual
prompts, via an intermediate code generation step. Moreover, we find that
ChatGPT is 64.33% accurate on average in 10 different reasoning categories
under logical reasoning, non-textual reasoning, and commonsense reasoning,
hence making it an unreliable reasoner. It is, for example, better at deductive
than inductive reasoning. ChatGPT suffers from hallucination problems like
other LLMs and it generates more extrinsic hallucinations from its parametric
memory as it does not have access to an external knowledge base. Finally, the
interactive feature of ChatGPT enables human collaboration with the underlying
LLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++
on machine translation, in a multi-turn "prompt engineering" fashion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Offline Compression: Going Beyond Factorization-based Methods for Transformer Language Models. (arXiv:2302.04045v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04045">
<div class="article-summary-box-inner">
<span><p>Recent transformer language models achieve outstanding results in many
natural language processing (NLP) tasks. However, their enormous size often
makes them impractical on memory-constrained devices, requiring practitioners
to compress them to smaller networks. In this paper, we explore offline
compression methods, meaning computationally-cheap approaches that do not
require further fine-tuning of the compressed model. We challenge the classical
matrix factorization methods by proposing a novel, better-performing
autoencoder-based framework. We perform a comprehensive ablation study of our
approach, examining its different aspects over a diverse set of evaluation
settings. Moreover, we show that enabling collaboration between modules across
layers by compressing certain modules together positively impacts the final
model performance. Experiments on various NLP tasks demonstrate that our
approach significantly outperforms commonly used factorization-based offline
compression methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04054">
<div class="article-summary-box-inner">
<span><p>Reliability of machine learning evaluation -- the consistency of observed
evaluation scores across replicated model training runs -- is affected by
several sources of nondeterminism which can be regarded as measurement noise.
Current tendencies to remove noise in order to enforce reproducibility of
research results neglect inherent nondeterminism at the implementation level
and disregard crucial interaction effects between algorithmic noise factors and
data properties. This limits the scope of conclusions that can be drawn from
such experiments. Instead of removing noise, we propose to incorporate several
sources of variance, including their interaction with data properties, into an
analysis of significance and reliability of machine learning evaluation, with
the aim to draw inferences beyond particular instances of trained models. We
show how to use linear mixed effects models (LMEMs) to analyze performance
evaluation scores, and to conduct statistical inference with a generalized
likelihood ratio test (GLRT). This allows us to incorporate arbitrary sources
of noise like meta-parameter variations into statistical significance testing,
and to assess performance differences conditional on data properties.
Furthermore, a variance component analysis (VCA) enables the analysis of the
contribution of noise sources to overall variance and the computation of a
reliability coefficient by the ratio of substantial to total variance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reception Reader: Exploring Text Reuse in Early Modern British Publications. (arXiv:2302.04084v1 [cs.DL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04084">
<div class="article-summary-box-inner">
<span><p>The Reception Reader is a web tool for studying text reuse in the Early
English Books Online (EEBO-TCP) and Eighteenth Century Collections Online
(ECCO) data. Users can: 1) explore a visual overview of the reception of a
work, or its incoming connections, across time based on shared text segments,
2) interactively survey the details of connected documents, and 3) examine the
context of reused text for "close reading". We show examples of how the tool
streamlines research and exploration tasks, and discuss the utility and
limitations of the user interface along with its current data sources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ZipLM: Hardware-Aware Structured Pruning of Language Models. (arXiv:2302.04089v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04089">
<div class="article-summary-box-inner">
<span><p>The breakthrough performance of large language models (LLMs) comes with large
computational footprints and high deployment costs. In this paper, we progress
towards resolving this problem by proposing a new structured compression
approach for LLMs, called ZipLM, which provides state-of-the-art
compression-vs-accuracy results, while guaranteeing to match a set of
(achievable) target speedups on any given target hardware. Specifically, given
a task, a model, an inference environment, as well as a set of speedup targets,
ZipLM identifies and removes redundancies in the model through iterative
structured shrinking of the model's weight matrices. Importantly, ZipLM works
in both, the post-training/one-shot and the gradual compression setting, where
it produces a set of accurate models in a single run, making it
highly-efficient in practice. Our approach is based on new structured pruning
and knowledge distillation techniques, and consistently outperforms prior
structured compression methods in terms of accuracy-versus-speedup in
experiments on BERT- and GPT-family models. In particular, when compressing
GPT2 model, it outperforms DistilGPT2 while being 60% smaller and 30% faster.
Further, ZipLM matches performance of heavily optimized MobileBERT model,
obtained via extensive architecture search, by simply pruning the baseline
BERT-large architecture, and outperforms all prior BERT-base compression
techniques like CoFi, MiniLM and TinyBERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-Word Error Correction with Trigrams: Correcting Multiple Errors in a Sentence. (arXiv:2302.04096v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04096">
<div class="article-summary-box-inner">
<span><p>Spelling correction is a fundamental task in Text Mining. In this study, we
assess the real-word error correction model proposed by Mays, Damerau and
Mercer and describe several drawbacks of the model. We propose a new variation
which focuses on detecting and correcting multiple real-word errors in a
sentence, by manipulating a Probabilistic Context-Free Grammar (PCFG) to
discriminate between items in the search space. We test our approach on the
Wall Street Journal corpus and show that it outperforms Hirst and Budanitsky's
WordNet-based method and Wilcox-O'Hearn, Hirst, and Budanitsky's fixed windows
size method.-O'Hearn, Hirst, and Budanitsky's fixed windows size method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training-free Lexical Backdoor Attacks on Language Models. (arXiv:2302.04116v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04116">
<div class="article-summary-box-inner">
<span><p>Large-scale language models have achieved tremendous success across various
natural language processing (NLP) applications. Nevertheless, language models
are vulnerable to backdoor attacks, which inject stealthy triggers into models
for steering them to undesirable behaviors. Most existing backdoor attacks,
such as data poisoning, require further (re)training or fine-tuning language
models to learn the intended backdoor patterns. The additional training process
however diminishes the stealthiness of the attacks, as training a language
model usually requires long optimization time, a massive amount of data, and
considerable modifications to the model parameters. In this work, we propose
Training-Free Lexical Backdoor Attack (TFLexAttack) as the first training-free
backdoor attack on language models. Our attack is achieved by injecting lexical
triggers into the tokenizer of a language model via manipulating its embedding
dictionary using carefully designed rules. These rules are explainable to human
developers which inspires attacks from a wider range of hackers. The sparse
manipulation of the dictionary also habilitates the stealthiness of our attack.
We conduct extensive experiments on three dominant NLP tasks based on nine
language models to demonstrate the effectiveness and universality of our
attack. The code of this work is available at
https://github.com/Jinxhy/TFLexAttack.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompting for Multimodal Hateful Meme Classification. (arXiv:2302.04156v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04156">
<div class="article-summary-box-inner">
<span><p>Hateful meme classification is a challenging multimodal task that requires
complex reasoning and contextual background knowledge. Ideally, we could
leverage an explicit external knowledge base to supplement contextual and
cultural information in hateful memes. However, there is no known explicit
external knowledge base that could provide such hate speech contextual
information. To address this gap, we propose PromptHate, a simple yet effective
prompt-based model that prompts pre-trained language models (PLMs) for hateful
meme classification. Specifically, we construct simple prompts and provide a
few in-context examples to exploit the implicit knowledge in the pre-trained
RoBERTa language model for hateful meme classification. We conduct extensive
experiments on two publicly available hateful and offensive meme datasets. Our
experimental results show that PromptHate is able to achieve a high AUC of
90.96, outperforming state-of-the-art baselines on the hateful meme
classification task. We also perform fine-grained analyses and case studies on
various prompt settings and demonstrate the effectiveness of the prompts on
hateful meme classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPTScore: Evaluate as You Desire. (arXiv:2302.04166v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04166">
<div class="article-summary-box-inner">
<span><p>Generative Artificial Intelligence (AI) has enabled the development of
sophisticated models that are capable of producing high-caliber text, images,
and other outputs through the utilization of large pre-trained models.
Nevertheless, assessing the quality of the generation is an even more arduous
task than the generation itself, and this issue has not been given adequate
consideration recently. This paper proposes a novel evaluation framework,
GPTScore, which utilizes the emergent abilities (e.g., zero-shot instruction)
from generative pre-trained models to score generated texts. Experimental
results on four text generation tasks, 22 evaluation aspects, and corresponding
37 datasets demonstrate that this approach can effectively allow us to achieve
what one desires to evaluate for texts simply by natural language instructions.
This nature helps us overcome several long-standing challenges in text
evaluation--how to achieve customized, multi-faceted evaluation without the
need for annotated samples. We make our code publicly available at
https://github.com/jinlanfu/GPTScore.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Joint Learning for Clinical Named Entity Recognition and Relation Extraction Using Fourier Networks: A Use Case in Adverse Drug Events. (arXiv:2302.04185v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04185">
<div class="article-summary-box-inner">
<span><p>Current approaches for clinical information extraction are inefficient in
terms of computational costs and memory consumption, hindering their
application to process large-scale electronic health records (EHRs). We propose
an efficient end-to-end model, the Joint-NER-RE-Fourier (JNRF), to jointly
learn the tasks of named entity recognition and relation extraction for
documents of variable length. The architecture uses positional encoding and
unitary batch sizes to process variable length documents and uses a
weight-shared Fourier network layer for low-complexity token mixing. Finally,
we reach the theoretical computational complexity lower bound for relation
extraction using a selective pooling strategy and distance-aware attention
weights with trainable polynomial distance functions. We evaluated the JNRF
architecture using the 2018 N2C2 ADE benchmark to jointly extract
medication-related entities and relations in variable-length EHR summaries.
JNRF outperforms rolling window BERT with selective pooling by 0.42%, while
being twice as fast to train. Compared to state-of-the-art BiLSTM-CRF
architectures on the N2C2 ADE benchmark, results show that the proposed
approach trains 22 times faster and reduces GPU memory consumption by 1.75
folds, with a reasonable performance tradeoff of 90%, without the use of
external tools, hand-crafted rules or post-processing. Given the significant
carbon footprint of deep learning models and the current energy crises, these
methods could support efficient and cleaner information extraction in EHRs and
other types of large-scale document databases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Event Grounding. (arXiv:2302.04197v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04197">
<div class="article-summary-box-inner">
<span><p>Event grounding aims at linking mention references in text corpora to events
from a knowledge base (KB). Previous work on this task focused primarily on
linking to a single KB event, thereby overlooking the hierarchical aspects of
events. Events in documents are typically described at various levels of
spatio-temporal granularity (Glavas et al. 2014). These hierarchical relations
are utilized in downstream tasks of narrative understanding and schema
construction. In this work, we present an extension to the event grounding task
that requires tackling hierarchical event structures from the KB. Our proposed
task involves linking a mention reference to a set of event labels from a
subevent hierarchy in the KB. We propose a retrieval methodology that leverages
event hierarchy through an auxiliary hierarchical loss (Murty et al. 2018). On
an automatically created multilingual dataset from Wikipedia and Wikidata, our
experiments demonstrate the effectiveness of the hierarchical loss against
retrieve and re-rank baselines (Wu et al. 2020; Pratapa, Gupta, and Mitamura
2022). Furthermore, we demonstrate the systems' ability to aid hierarchical
discovery among unseen events.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diagnosing and Rectifying Vision Models using Language. (arXiv:2302.04269v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04269">
<div class="article-summary-box-inner">
<span><p>Recent multi-modal contrastive learning models have demonstrated the ability
to learn an embedding space suitable for building strong vision classifiers, by
leveraging the rich information in large-scale image-caption datasets. Our work
highlights a distinct advantage of this multi-modal embedding space: the
ability to diagnose vision classifiers through natural language. The
traditional process of diagnosing model behaviors in deployment settings
involves labor-intensive data acquisition and annotation. Our proposed method
can discover high-error data slices, identify influential attributes and
further rectify undesirable model behaviors, without requiring any visual data.
Through a combination of theoretical explanation and empirical verification, we
present conditions under which classifiers trained on embeddings from one
modality can be equivalently applied to embeddings from another modality. On a
range of image datasets with known error slices, we demonstrate that our method
can effectively identify the error slices and influential attributes, and can
further use language to rectify failure modes of the classifier.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Identification of Toxic Code Reviews Using ToxiCR. (arXiv:2202.13056v3 [cs.SE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.13056">
<div class="article-summary-box-inner">
<span><p>Toxic conversations during software development interactions may have serious
repercussions on a Free and Open Source Software (FOSS) development project.
For example, victims of toxic conversations may become afraid to express
themselves, therefore get demotivated, and may eventually leave the project.
Automated filtering of toxic conversations may help a FOSS community to
maintain healthy interactions among its members. However, off-the-shelf
toxicity detectors perform poorly on Software Engineering (SE) datasets, such
as one curated from code review comments. To encounter this challenge, we
present ToxiCR, a supervised learning-based toxicity identification tool for
code review interactions. ToxiCR includes a choice to select one of the ten
supervised learning algorithms, an option to select text vectorization
techniques, eight preprocessing steps, and a large-scale labeled dataset of
19,571 code review comments. Two out of those eight preprocessing steps are SE
domain specific. With our rigorous evaluation of the models with various
combinations of preprocessing steps and vectorization techniques, we have
identified the best combination for our dataset that boosts 95.8% accuracy and
88.9% F1 score. ToxiCR significantly outperforms existing toxicity detectors on
our dataset. We have released our dataset, pre-trained models, evaluation
results, and source code publicly available at:
https://github.com/WSU-SEAL/ToxiCR
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models. (arXiv:2204.14211v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.14211">
<div class="article-summary-box-inner">
<span><p>Language Models (LMs) become outdated as the world changes; they often fail
to perform tasks requiring recent factual information which was absent or
different during training, a phenomenon called temporal misalignment. This is
especially a challenging problem because the research community still lacks a
coherent dataset for assessing the adaptability of LMs to frequently-updated
knowledge corpus such as Wikipedia. To this end, we introduce TemporalWiki, a
lifelong benchmark for ever-evolving LMs that utilizes the difference between
consecutive snapshots of English Wikipedia and English Wikidata for training
and evaluation, respectively. The benchmark hence allows researchers to
periodically track an LM's ability to retain previous knowledge and acquire
updated/new knowledge at each point in time. We also find that training an LM
on the diff data through continual learning methods achieves similar or better
perplexity than on the entire snapshot in our benchmark with 12 times less
computational cost, which verifies that factual knowledge in LMs can be safely
updated with minimal training data via continual learning. The dataset and the
code are available at https://github.com/joeljang/temporalwiki.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Self-Attention for Language Understanding. (arXiv:2206.12608v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12608">
<div class="article-summary-box-inner">
<span><p>Deep neural models (e.g. Transformer) naturally learn spurious features,
which create a ``shortcut'' between the labels and inputs, thus impairing the
generalization and robustness. This paper advances the self-attention mechanism
to its robust variant for Transformer-based pre-trained language models (e.g.
BERT). We propose \textit{Adversarial Self-Attention} mechanism (ASA), which
adversarially biases the attentions to effectively suppress the model reliance
on features (e.g. specific keywords) and encourage its exploration of broader
semantics. We conduct a comprehensive evaluation across a wide range of tasks
for both pre-training and fine-tuning stages. For pre-training, ASA unfolds
remarkable performance gains compared to naive training for longer steps. For
fine-tuning, ASA-empowered models outweigh naive models by a large margin
considering both generalization and robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How trial-to-trial learning shapes mappings in the mental lexicon: Modelling Lexical Decision with Linear Discriminative Learning. (arXiv:2207.00430v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.00430">
<div class="article-summary-box-inner">
<span><p>Trial-to-trial effects have been found in a number of studies, indicating
that processing a stimulus influences responses in subsequent trials. A special
case are priming effects which have been modelled successfully with
error-driven learning (Marsolek, 2008), implying that participants are
continuously learning during experiments. This study investigates whether
trial-to-trial learning can be detected in an unprimed lexical decision
experiment. We used the Discriminative Lexicon Model (DLM; Baayen et al.,
2019), a model of the mental lexicon with meaning representations from
distributional semantics, which models error-driven incremental learning with
the Widrow-Hoff rule. We used data from the British Lexicon Project (BLP;
Keuleers et al., 2012) and simulated the lexical decision experiment with the
DLM on a trial-by-trial basis for each subject individually. Then, reaction
times were predicted with Generalised Additive Models (GAMs), using measures
derived from the DLM simulations as predictors. We extracted measures from two
simulations per subject (one with learning updates between trials and one
without), and used them as input to two GAMs. Learning-based models showed
better model fit than the non-learning ones for the majority of subjects. Our
measures also provide insights into lexical processing and individual
differences. This demonstrates the potential of the DLM to model behavioural
data and leads to the conclusion that trial-to-trial learning can indeed be
detected in unprimed lexical decision. Our results support the possibility that
our lexical knowledge is subject to continuous changes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents. (arXiv:2207.01206v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.01206">
<div class="article-summary-box-inner">
<span><p>Existing benchmarks for grounding language in interactive environments either
lack real-world linguistic elements, or prove difficult to scale up due to
substantial human involvement in the collection of data or feedback signals. To
bridge this gap, we develop WebShop -- a simulated e-commerce website
environment with $1.18$ million real-world products and $12,087$ crowd-sourced
text instructions. Given a text instruction specifying a product requirement,
an agent needs to navigate multiple types of webpages and issue diverse actions
to find, customize, and purchase an item. WebShop provides several challenges
for language grounding including understanding compositional instructions,
query (re-)formulation, comprehending and acting on noisy text in webpages, and
performing strategic exploration. We collect over $1,600$ human demonstrations
for the task, and train and evaluate a diverse range of agents using
reinforcement learning, imitation learning, and pre-trained image and language
models. Our best model achieves a task success rate of $29\%$, which
outperforms rule-based heuristics ($9.6\%$) but is far lower than human expert
performance ($59\%$). We also analyze agent and human trajectories and ablate
various model components to provide insights for developing future agents with
stronger language understanding and decision making abilities. Finally, we show
that agents trained on WebShop exhibit non-trivial sim-to-real transfer when
evaluated on amazon.com and ebay.com, indicating the potential value of WebShop
in developing practical web-based agents that can operate in the wild.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Grounded Planning for Embodied Tasks with Language Models. (arXiv:2209.00465v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.00465">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) have demonstrated their capability in possessing
commonsense knowledge of the physical world, a crucial aspect of performing
tasks in everyday life. However, it remains unclear whether they have the
capacity to generate grounded, executable plans for embodied tasks. This is a
challenging task as LMs lack the ability to perceive the environment through
vision and feedback from the physical environment. In this paper, we address
this important research question and present the first investigation into the
topic. Our novel problem formulation, named G-PlanET, inputs a high-level goal
and a data table about objects in a specific environment, and then outputs a
step-by-step actionable plan for a robotic agent to follow. To facilitate the
study, we establish an evaluation protocol and design a dedicated metric, KAS,
to assess the quality of the plans. Our experiments demonstrate that the use of
tables for encoding the environment and an iterative decoding strategy can
significantly enhance the LMs' ability in grounded planning. Our analysis also
reveals interesting and non-trivial findings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ViLPAct: A Benchmark for Compositional Generalization on Multimodal Human Activities. (arXiv:2210.05556v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.05556">
<div class="article-summary-box-inner">
<span><p>We introduce ViLPAct, a novel vision-language benchmark for human activity
planning. It is designed for a task where embodied AI agents can reason and
forecast future actions of humans based on video clips about their initial
activities and intents in text. The dataset consists of 2.9k videos from
\charades extended with intents via crowdsourcing, a multi-choice question test
set, and four strong baselines. One of the baselines implements a neurosymbolic
approach based on a multi-modal knowledge base (MKB), while the other ones are
deep generative models adapted from recent state-of-the-art (SOTA) methods.
According to our extensive experiments, the key challenges are compositional
generalization and effective use of information from both modalities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RedHOT: A Corpus of Annotated Medical Questions, Experiences, and Claims on Social Media. (arXiv:2210.06331v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06331">
<div class="article-summary-box-inner">
<span><p>We present Reddit Health Online Talk (RedHOT), a corpus of 22,000 richly
annotated social media posts from Reddit spanning 24 health conditions.
Annotations include demarcations of spans corresponding to medical claims,
personal experiences, and questions. We collect additional granular annotations
on identified claims. Specifically, we mark snippets that describe patient
Populations, Interventions, and Outcomes (PIO elements) within these. Using
this corpus, we introduce the task of retrieving trustworthy evidence relevant
to a given claim made on social media. We propose a new method to automatically
derive (noisy) supervision for this task which we use to train a dense
retrieval model; this outperforms baseline models. Manual evaluation of
retrieval results performed by medical doctors indicate that while our system
performance is promising, there is considerable room for improvement. Collected
annotations (and scripts to assemble the dataset), are available at
https://github.com/sominw/redhot.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Reasoning on Hybrid-knowledge sources for Task-Oriented Dialog. (arXiv:2210.07295v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07295">
<div class="article-summary-box-inner">
<span><p>Traditional systems designed for task oriented dialog utilize knowledge
present only in structured knowledge sources to generate responses. However,
relevant information required to generate responses may also reside in
unstructured sources, such as documents. Recent state of the art models such as
HyKnow and SeKnow aimed at overcoming these challenges make limiting
assumptions about the knowledge sources. For instance, these systems assume
that certain types of information, such as a phone number, is always present in
a structured knowledge base (KB) while information about aspects such as
entrance ticket prices, would always be available in documents.
</p>
<p>In this paper, we create a modified version of the MutliWOZ-based dataset
prepared by SeKnow to demonstrate how current methods have significant
degradation in performance when strict assumptions about the source of
information are removed. Then, in line with recent work exploiting pre-trained
language models, we fine-tune a BART based model using prompts for the tasks of
querying knowledge sources, as well as, for response generation, without making
assumptions about the information present in each knowledge source. Through a
series of experiments, we demonstrate that our model is robust to perturbations
to knowledge modality (source of information), and that it can fuse information
from structured as well as unstructured knowledge to generate responses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Synthetic Speech from SpokenVocab for Speech Translation. (arXiv:2210.08174v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08174">
<div class="article-summary-box-inner">
<span><p>Training end-to-end speech translation (ST) systems requires sufficiently
large-scale data, which is unavailable for most language pairs and domains. One
practical solution to the data scarcity issue is to convert machine translation
data (MT) to ST data via text-to-speech (TTS) systems. Yet, using TTS systems
can be tedious and slow, as the conversion needs to be done for each MT
dataset. In this work, we propose a simple, scalable and effective data
augmentation technique, i.e., SpokenVocab, to convert MT data to ST data
on-the-fly. The idea is to retrieve and stitch audio snippets from a
SpokenVocab bank according to words in an MT sequence. Our experiments on
multiple language pairs from Must-C show that this method outperforms strong
baselines by an average of 1.83 BLEU scores, and it performs equally well as
TTS-generated speech. We also showcase how SpokenVocab can be applied in
code-switching ST for which often no TTS systems exit. Our code is available at
https://github.com/mingzi151/SpokenVocab
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Monitor Model and its Misconceptions: A Clarification. (arXiv:2210.14367v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.14367">
<div class="article-summary-box-inner">
<span><p>Horizontal (automatic) and vertical (control) processes have been observed
and reported for a long time in translation production. Schaeffer and Carl's
Monitor Model integrates these two processes into one framework, assuming that
priming mechanisms underlie horizontal/automatic processes, while
vertical/monitoring processes implement consciously accessible control
mechanisms. The Monitor Model has been criticized in various ways and several
misconceptions have accumulated over the past years. In this chapter, I update
the Monitor Model with additional evidence and argue that it is compatible with
an enactivist approach to cognition. I address several misconceptions related
to the Monitor Model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on In-context Learning. (arXiv:2301.00234v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.00234">
<div class="article-summary-box-inner">
<span><p>With the increasing ability of large language models (LLMs), in-context
learning (ICL) has become a new paradigm for natural language processing (NLP),
where LLMs make predictions only based on contexts augmented with a few
examples. It has been a new trend to explore ICL to evaluate and extrapolate
the ability of LLMs. In this paper, we aim to survey and summarize the progress
and challenges of ICL. We first present a formal definition of ICL and clarify
its correlation to related studies. Then, we organize and discuss advanced
techniques, including training strategies, demonstration designing strategies,
as well as related analysis. Finally, we discuss the challenges of ICL and
provide potential directions for further research. We hope that our work can
encourage more research on uncovering how ICL works and improving ICL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Syntax-guided Neural Module Distillation to Probe Compositionality in Sentence Embeddings. (arXiv:2301.08998v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.08998">
<div class="article-summary-box-inner">
<span><p>Past work probing compositionality in sentence embedding models faces issues
determining the causal impact of implicit syntax representations. Given a
sentence, we construct a neural module net based on its syntax parse and train
it end-to-end to approximate the sentence's embedding generated by a
transformer model. The distillability of a transformer to a Syntactic NeurAl
Module Net (SynNaMoN) then captures whether syntax is a strong causal model of
its compositional ability. Furthermore, we address questions about the geometry
of semantic composition by specifying individual SynNaMoN modules' internal
architecture &amp; linearity. We find differences in the distillability of various
sentence embedding models that broadly correlate with their performance, but
observe that distillability doesn't considerably vary by model size. We also
present preliminary evidence that much syntax-guided composition in sentence
embedding models is linear, and that non-linearities may serve primarily to
handle non-compositional phrases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantifying Context Mixing in Transformers. (arXiv:2301.12971v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.12971">
<div class="article-summary-box-inner">
<span><p>Self-attention weights and their transformed variants have been the main
source of information for analyzing token-to-token interactions in
Transformer-based models. But despite their ease of interpretation, these
weights are not faithful to the models' decisions as they are only one part of
an encoder, and other components in the encoder layer can have considerable
impact on information mixing in the output representations. In this work, by
expanding the scope of analysis to the whole encoder block, we propose Value
Zeroing, a novel context mixing score customized for Transformers that provides
us with a deeper understanding of how information is mixed at each encoder
layer. We demonstrate the superiority of our context mixing score over other
analysis methods through a series of complementary evaluations with different
viewpoints based on linguistically informed rationales, probing, and
faithfulness analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Entity Alignment for Temporal Knowledge Graphs. (arXiv:2302.00796v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00796">
<div class="article-summary-box-inner">
<span><p>Entity alignment (EA) is a fundamental data integration task that identifies
equivalent entities between different knowledge graphs (KGs). Temporal
Knowledge graphs (TKGs) extend traditional knowledge graphs by introducing
timestamps, which have received increasing attention. State-of-the-art
time-aware EA studies have suggested that the temporal information of TKGs
facilitates the performance of EA. However, existing studies have not
thoroughly exploited the advantages of temporal information in TKGs. Also, they
perform EA by pre-aligning entity pairs, which can be labor-intensive and thus
inefficient.
</p>
<p>In this paper, we present DualMatch which effectively fuses the relational
and temporal information for EA. DualMatch transfers EA on TKGs into a weighted
graph matching problem. More specifically, DualMatch is equipped with an
unsupervised method, which achieves EA without necessitating seed alignment.
DualMatch has two steps: (i) encoding temporal and relational information into
embeddings separately using a novel label-free encoder, Dual-Encoder; and (ii)
fusing both information and transforming it into alignment using a novel
graph-matching-based decoder, GM-Decoder. DualMatch is able to perform EA on
TKGs with or without supervision, due to its capability of effectively
capturing temporal information. Extensive experiments on three real-world TKG
datasets offer the insight that DualMatch outperforms the state-of-the-art
methods in terms of H@1 by 2.4% - 10.7% and MRR by 1.7% - 7.6%, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Curriculum-Guided Abstractive Summarization. (arXiv:2302.01342v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01342">
<div class="article-summary-box-inner">
<span><p>Recent Transformer-based summarization models have provided a promising
approach to abstractive summarization. They go beyond sentence selection and
extractive strategies to deal with more complicated tasks such as novel word
generation and sentence paraphrasing. Nonetheless, these models have two
shortcomings: (1) they often perform poorly in content selection, and (2) their
training strategy is not quite efficient, which restricts model performance. In
this paper, we explore two orthogonal ways to compensate for these pitfalls.
First, we augment the Transformer network with a sentence cross-attention
module in the decoder, encouraging more abstraction of salient content. Second,
we include a curriculum learning approach to reweight the training samples,
bringing about an efficient learning procedure. Our second approach to enhance
the training strategy of Transformers networks makes stronger gains as compared
to the first approach. We apply our model on extreme summarization dataset of
Reddit TIFU posts. We further look into three cross-domain summarization
datasets (Webis-TLDR-17, CNN/DM, and XSum), measuring the efficacy of
curriculum learning when applied in summarization. Moreover, a human evaluation
is conducted to show the efficacy of the proposed method in terms of
qualitative criteria, namely, fluency, informativeness, and overall quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Semantic Approach to Negation Detection and Word Disambiguation with Natural Language Processing. (arXiv:2302.02291v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.02291">
<div class="article-summary-box-inner">
<span><p>This study aims to demonstrate the methods for detecting negations in a
sentence by uniquely evaluating the lexical structure of the text via word
sense disambiguation. Additionally, the proposed method examined all the unique
features of the related expressions within a text to resolve the contextual
usage of the sentence and the effect of negation on sentiment analysis. The
application of popular expression detectors skips this important step, thereby
neglecting the root words caught in the web of negation, and making text
classification difficult for machine learning and sentiment analysis. This
study adopts the Natural Language Processing (NLP) approach to discover and
antonimize words that were negated for better accuracy in text classification.
This method acts as a lens that reads through a given word sequence using a
knowledge base provided by an NLP library called WordHoard in order to detect
negation signals. Early results show that our initial analysis improved
traditional sentiment analysis that sometimes neglects word negations or
assigns an inverse polarity score. The SentiWordNet analyzer was improved by
35%, the Vader analyzer by 20% and the TextBlob analyzer by 6%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PLACES: Prompting Language Models for Social Conversation Synthesis. (arXiv:2302.03269v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03269">
<div class="article-summary-box-inner">
<span><p>Collecting high quality conversational data can be very expensive for most
applications and infeasible for others due to privacy, ethical, or similar
concerns. A promising direction to tackle this problem is to generate synthetic
dialogues by prompting large language models. In this work, we use a small set
of expert-written conversations as in-context examples to synthesize a social
conversation dataset using prompting. We perform several thorough evaluations
of our synthetic conversations compared to human-collected conversations. This
includes various dimensions of conversation quality with human evaluation
directly on the synthesized conversations, and interactive human evaluation of
chatbots fine-tuned on the synthetically generated dataset. We additionally
demonstrate that this prompting approach is generalizable to multi-party
conversations, providing potential to create new synthetic data for multi-party
tasks. Our synthetic multi-party conversations were rated more favorably across
all measured dimensions compared to conversation excerpts sampled from a
human-collected multi-party dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Arabic Named Entity Recognition: Past, Recent Advances, and Future Trends. (arXiv:2302.03512v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03512">
<div class="article-summary-box-inner">
<span><p>As more and more Arabic texts emerged on the Internet, extracting important
information from these Arabic texts is especially useful. As a fundamental
technology, Named entity recognition (NER) serves as the core component in
information extraction technology, while also playing a critical role in many
other Natural Language Processing (NLP) systems, such as question answering and
knowledge graph building. In this paper, we provide a comprehensive review of
the development of Arabic NER, especially the recent advances in deep learning
and pre-trained language model. Specifically, we first introduce the background
of Arabic NER, including the characteristics of Arabic and existing resources
for Arabic NER. Then, we systematically review the development of Arabic NER
methods. Traditional Arabic NER systems focus on feature engineering and
designing domain-specific rules. In recent years, deep learning methods achieve
significant progress by representing texts via continuous vector
representations. With the growth of pre-trained language model, Arabic NER
yields better performance. Finally, we conclude the method gap between Arabic
NER and NER methods from other languages, which helps outline future directions
for Arabic NER.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploitation and exploration in text evolution. Quantifying planning and translation flows during writing. (arXiv:2302.03645v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03645">
<div class="article-summary-box-inner">
<span><p>Writing is a complex process at the center of much of modern human activity.
Despite it appears to be a linear process, writing conceals many highly
non-linear processes. Previous research has focused on three phases of writing:
planning, translation and transcription, and revision. While research has shown
these are non-linear, they are often treated linearly when measured. Here, we
introduce measures to detect and quantify subcycles of planning (exploration)
and translation (exploitation) during the writing process. We apply these to a
novel dataset that recorded the creation of a text in all its phases, from
early attempts to the finishing touches on a final version. This dataset comes
from a series of writing workshops in which, through innovative versioning
software, we were able to record all the steps in the construction of a text.
More than 60 junior researchers in science wrote a scientific essay intended
for a general readership. We recorded each essay as a writing cloud, defined as
a complex topological structure capturing the history of the essay itself.
Through this unique dataset of writing clouds, we expose a representation of
the writing process that quantifies its complexity and the writer's efforts
throughout the draft and through time. Interestingly, this representation
highlights the phases of "translation flow", where authors improve existing
ideas, and exploration, where creative deviations appear as the writer returns
to the planning phase. These turning points between translation and exploration
become rarer as the writing process progresses and the author approaches the
final version. Our results and the new measures introduced have the potential
to foster the discussion about the non-linear nature of writing and support the
development of tools that can support more creative and impactful writing
processes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Auditing Gender Presentation Differences in Text-to-Image Models. (arXiv:2302.03675v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03675">
<div class="article-summary-box-inner">
<span><p>Text-to-image models, which can generate high-quality images based on textual
input, have recently enabled various content-creation tools. Despite
significantly affecting a wide range of downstream applications, the
distributions of these generated images are still not fully understood,
especially when it comes to the potential stereotypical attributes of different
genders. In this work, we propose a paradigm (Gender Presentation Differences)
that utilizes fine-grained self-presentation attributes to study how gender is
presented differently in text-to-image models. By probing gender indicators in
the input text (e.g., "a woman" or "a man"), we quantify the frequency
differences of presentation-centric attributes (e.g., "a shirt" and "a dress")
through human annotation and introduce a novel metric: GEP. Furthermore, we
propose an automatic method to estimate such differences. The automatic GEP
metric based on our approach yields a higher correlation with human annotations
than that based on existing CLIP scores, consistently across three
state-of-the-art text-to-image models. Finally, we demonstrate the
generalization ability of our metrics in the context of gender stereotypes
related to occupations.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-02-09 23:14:26.119806820 UTC">2023-02-09 23:14:26 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>