<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-03-21T01:30:00Z">03-21</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Conversational Tree Search: A New Hybrid Dialog Task. (arXiv:2303.10227v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10227">
<div class="article-summary-box-inner">
<span><p>Conversational interfaces provide a flexible and easy way for users to seek
information that may otherwise be difficult or inconvenient to obtain. However,
existing interfaces generally fall into one of two categories: FAQs, where
users must have a concrete question in order to retrieve a general answer, or
dialogs, where users must follow a predefined path but may receive a
personalized answer. In this paper, we introduce Conversational Tree Search
(CTS) as a new task that bridges the gap between FAQ-style information
retrieval and task-oriented dialog, allowing domain-experts to define dialog
trees which can then be converted to an efficient dialog policy that learns
only to ask the questions necessary to navigate a user to their goal. We
collect a dataset for the travel reimbursement domain and demonstrate a
baseline as well as a novel deep Reinforcement Learning architecture for this
task. Our results show that the new architecture combines the positive aspects
of both the FAQ and dialog system used in the baseline and achieves higher goal
completion while skipping unnecessary questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feedback Effect in User Interaction with Intelligent Assistants: Delayed Engagement, Adaption and Drop-out. (arXiv:2303.10255v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10255">
<div class="article-summary-box-inner">
<span><p>With the growing popularity of intelligent assistants (IAs), evaluating IA
quality becomes an increasingly active field of research. This paper identifies
and quantifies the feedback effect, a novel component in IA-user interactions:
how the capabilities and limitations of the IA influence user behavior over
time. First, we demonstrate that unhelpful responses from the IA cause users to
delay or reduce subsequent interactions in the short term via an observational
study. Next, we expand the time horizon to examine behavior changes and show
that as users discover the limitations of the IA's understanding and functional
capabilities, they learn to adjust the scope and wording of their requests to
increase the likelihood of receiving a helpful response from the IA. Our
findings highlight the impact of the feedback effect at both the micro and meso
levels. We further discuss its macro-level consequences: unsatisfactory
interactions continuously reduce the likelihood and diversity of future user
engagements in a feedback loop.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the rise of fear speech in online social media. (arXiv:2303.10311v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10311">
<div class="article-summary-box-inner">
<span><p>Recently, social media platforms are heavily moderated to prevent the spread
of online hate speech, which is usually fertile in toxic words and is directed
toward an individual or a community. Owing to such heavy moderation, newer and
more subtle techniques are being deployed. One of the most striking among these
is fear speech. Fear speech, as the name suggests, attempts to incite fear
about a target community. Although subtle, it might be highly effective, often
pushing communities toward a physical conflict. Therefore, understanding their
prevalence in social media is of paramount importance. This article presents a
large-scale study to understand the prevalence of 400K fear speech and over
700K hate speech posts collected from Gab.com. Remarkably, users posting a
large number of fear speech accrue more followers and occupy more central
positions in social networks than users posting a large number of hate speech.
They can also reach out to benign users more effectively than hate speech users
through replies, reposts, and mentions. This connects to the fact that, unlike
hate speech, fear speech has almost zero toxic content, making it look
plausible. Moreover, while fear speech topics mostly portray a community as a
perpetrator using a (fake) chain of argumentation, hate speech topics hurl
direct multitarget insults, thus pointing to why general users could be more
gullible to fear speech. Our findings transcend even to other platforms
(Twitter and Facebook) and thus necessitate using sophisticated moderation
policies and mass awareness to combat fear speech.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Automatic Question Summarization Evaluation in the Biomedical Domain. (arXiv:2303.10328v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10328">
<div class="article-summary-box-inner">
<span><p>Automatic evaluation metrics have been facilitating the rapid development of
automatic summarization methods by providing instant and fair assessments of
the quality of summaries. Most metrics have been developed for the general
domain, especially news and meeting notes, or other language-generation tasks.
However, these metrics are applied to evaluate summarization systems in
different domains, such as biomedical question summarization. To better
understand whether commonly used evaluation metrics are capable of evaluating
automatic summarization in the biomedical domain, we conduct human evaluations
of summarization quality from four different aspects of a biomedical question
summarization task. Based on human judgments, we identify different noteworthy
features for current automatic metrics and summarization systems as well. We
also release a dataset of our human annotations to aid the research of
summarization evaluation metrics in the biomedical domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Partial Knowledge Base Inference in Biomedical Entity Linking. (arXiv:2303.10330v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10330">
<div class="article-summary-box-inner">
<span><p>Biomedical entity linking (EL) consists of named entity recognition (NER) and
named entity disambiguation (NED). EL models are trained on corpora labeled by
a predefined KB. However, it is a common scenario that only entities within a
subset of the KB are precious to stakeholders. We name this scenario partial
knowledge base inference: training an EL model with one KB and inferring on the
part of it without further training. In this work, we give a detailed
definition and evaluation procedures for this practically valuable but
significantly understudied scenario and evaluate methods from three
representative EL paradigms. We construct partial KB inference benchmarks and
witness a catastrophic degradation in EL performance due to dramatically
precision drop. Our findings reveal these EL paradigms can not correctly handle
unlinkable mentions (NIL), so they are not robust to partial KB inference. We
also propose two simple-and-effective redemption methods to combat the NIL
issue with little computational overhead.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Study of Pre-trained Language Models in Simple Knowledge Graph Question Answering. (arXiv:2303.10368v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10368">
<div class="article-summary-box-inner">
<span><p>Large-scale pre-trained language models (PLMs) such as BERT have recently
achieved great success and become a milestone in natural language processing
(NLP). It is now the consensus of the NLP community to adopt PLMs as the
backbone for downstream tasks. In recent works on knowledge graph question
answering (KGQA), BERT or its variants have become necessary in their KGQA
models. However, there is still a lack of comprehensive research and comparison
of the performance of different PLMs in KGQA. To this end, we summarize two
basic KGQA frameworks based on PLMs without additional neural network modules
to compare the performance of nine PLMs in terms of accuracy and efficiency. In
addition, we present three benchmarks for larger-scale KGs based on the popular
SimpleQuestions benchmark to investigate the scalability of PLMs. We carefully
analyze the results of all PLMs-based KGQA basic frameworks on these benchmarks
and two other popular datasets, WebQuestionSP and FreebaseQA, and find that
knowledge distillation techniques and knowledge enhancement methods in PLMs are
promising for KGQA. Furthermore, we test ChatGPT, which has drawn a great deal
of attention in the NLP community, demonstrating its impressive capabilities
and limitations in zero-shot KGQA. We have released the code and benchmarks to
promote the use of PLMs on KGQA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Powerful and Extensible WFST Framework for RNN-Transducer Losses. (arXiv:2303.10384v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10384">
<div class="article-summary-box-inner">
<span><p>This paper presents a framework based on Weighted Finite-State Transducers
(WFST) to simplify the development of modifications for RNN-Transducer (RNN-T)
loss. Existing implementations of RNN-T use CUDA-related code, which is hard to
extend and debug. WFSTs are easy to construct and extend, and allow debugging
through visualization. We introduce two WFST-powered RNN-T implementations: (1)
"Compose-Transducer", based on a composition of the WFST graphs from acoustic
and textual schema -- computationally competitive and easy to modify; (2)
"Grid-Transducer", which constructs the lattice directly for further
computations -- most compact, and computationally efficient. We illustrate the
ease of extensibility through introduction of a new W-Transducer loss -- the
adaptation of the Connectionist Temporal Classification with Wild Cards.
W-Transducer (W-RNNT) consistently outperforms the standard RNN-T in a
weakly-supervised data setup with missing parts of transcriptions at the
beginning and end of utterances. All RNN-T losses are implemented with the k2
framework and are available in the NeMo toolkit.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Graph-Guided Reasoning Approach for Open-ended Commonsense Question Answering. (arXiv:2303.10395v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10395">
<div class="article-summary-box-inner">
<span><p>Recently, end-to-end trained models for multiple-choice commonsense question
answering (QA) have delivered promising results. However, such
question-answering systems cannot be directly applied in real-world scenarios
where answer candidates are not provided. Hence, a new benchmark challenge set
for open-ended commonsense reasoning (OpenCSR) has been recently released,
which contains natural science questions without any predefined choices. On the
OpenCSR challenge set, many questions require implicit multi-hop reasoning and
have a large decision space, reflecting the difficult nature of this task.
Existing work on OpenCSR sorely focuses on improving the retrieval process,
which extracts relevant factual sentences from a textual knowledge base,
leaving the important and non-trivial reasoning task outside the scope. In this
work, we extend the scope to include a reasoner that constructs a
question-dependent open knowledge graph based on retrieved supporting facts and
employs a sequential subgraph reasoning process to predict the answer. The
subgraph can be seen as a concise and compact graphical explanation of the
prediction. Experiments on two OpenCSR datasets show that the proposed model
achieves great performance on benchmark OpenCSR datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models. (arXiv:2303.10420v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10420">
<div class="article-summary-box-inner">
<span><p>GPT series models, such as GPT-3, CodeX, InstructGPT, ChatGPT, and so on,
have gained considerable attention due to their exceptional natural language
processing capabilities. However, despite the abundance of research on the
difference in capabilities between GPT series models and fine-tuned models,
there has been limited attention given to the evolution of GPT series models'
capabilities over time. To conduct a comprehensive analysis of the capabilities
of GPT series models, we select six representative models, comprising two GPT-3
series models (i.e., davinci and text-davinci-001) and four GPT-3.5 series
models (i.e., code-davinci-002, text-davinci-002, text-davinci-003, and
gpt-3.5-turbo). We evaluate their performance on nine natural language
understanding (NLU) tasks using 21 datasets. In particular, we compare the
performance and robustness of different models for each task under zero-shot
and few-shot scenarios. Our extensive experiments reveal that the overall
ability of GPT series models on NLU tasks does not increase gradually as the
models evolve, especially with the introduction of the RLHF training strategy.
While this strategy enhances the models' ability to generate human-like
responses, it also compromises their ability to solve some tasks. Furthermore,
our findings indicate that there is still room for improvement in areas such as
model robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NoisyHate: Benchmarking Content Moderation Machine Learning Models with Human-Written Perturbations Online. (arXiv:2303.10430v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10430">
<div class="article-summary-box-inner">
<span><p>Online texts with toxic content are a threat in social media that might cause
cyber harassment. Although many platforms applied measures, such as machine
learning-based hate-speech detection systems, to diminish their effect, those
toxic content publishers can still evade the system by modifying the spelling
of toxic words. Those modified words are also known as human-written text
perturbations. Many research works developed certain techniques to generate
adversarial samples to help the machine learning models obtain the ability to
recognize those perturbations. However, there is still a gap between those
machine-generated perturbations and human-written perturbations. In this paper,
we introduce a benchmark test set containing human-written perturbations online
for toxic speech detection models. We also recruited a group of workers to
evaluate the quality of this test set and dropped low-quality samples.
Meanwhile, to check if our perturbation can be normalized to its clean version,
we applied spell corrector algorithms on this dataset. Finally, we test this
data on state-of-the-art language models, such as BERT and RoBERTa, and black
box APIs, such as perspective API, to demonstrate the adversarial attack with
real human-written perturbations is still effective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stop Words for Processing Software Engineering Documents: Do they Matter?. (arXiv:2303.10439v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10439">
<div class="article-summary-box-inner">
<span><p>Stop words, which are considered non-predictive, are often eliminated in
natural language processing tasks. However, the definition of uninformative
vocabulary is vague, so most algorithms use general knowledge-based stop lists
to remove stop words. There is an ongoing debate among academics about the
usefulness of stop word elimination, especially in domain-specific settings. In
this work, we investigate the usefulness of stop word removal in a software
engineering context. To do this, we replicate and experiment with three
software engineering research tools from related work. Additionally, we
construct a corpus of software engineering domain-related text from 10,000
Stack Overflow questions and identify 200 domain-specific stop words using
traditional information-theoretic methods. Our results show that the use of
domain-specific stop words significantly improved the performance of research
tools compared to the use of a general stop list and that 17 out of 19
evaluation measures showed better performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GazeReader: Detecting Unknown Word Using Webcam for English as a Second Language (ESL) Learners. (arXiv:2303.10443v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10443">
<div class="article-summary-box-inner">
<span><p>Automatic unknown word detection techniques can enable new applications for
assisting English as a Second Language (ESL) learners, thus improving their
reading experiences. However, most modern unknown word detection methods
require dedicated eye-tracking devices with high precision that are not easily
accessible to end-users. In this work, we propose GazeReader, an unknown word
detection method only using a webcam. GazeReader tracks the learner's gaze and
then applies a transformer-based machine learning model that encodes the text
information to locate the unknown word. We applied knowledge enhancement
including term frequency, part of speech, and named entity recognition to
improve the performance. The user study indicates that the accuracy and
F1-score of our method were 98.09% and 75.73%, respectively. Lastly, we
explored the design scope for ESL reading and discussed the findings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models. (arXiv:2303.10464v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10464">
<div class="article-summary-box-inner">
<span><p>The pre-training and fine-tuning paradigm has contributed to a number of
breakthroughs in Natural Language Processing (NLP). Instead of directly
training on a downstream task, language models are first pre-trained on large
datasets with cross-domain knowledge (e.g., Pile, MassiveText, etc.) and then
fine-tuned on task-specific data (e.g., natural language generation, text
summarization, etc.). Scaling the model and dataset size has helped improve the
performance of LLMs, but unfortunately, this also leads to highly prohibitive
computational costs. Pre-training LLMs often require orders of magnitude more
FLOPs than fine-tuning and the model capacity often remains the same between
the two phases. To achieve training efficiency w.r.t training FLOPs, we propose
to decouple the model capacity between the two phases and introduce Sparse
Pre-training and Dense Fine-tuning (SPDF). In this work, we show the benefits
of using unstructured weight sparsity to train only a subset of weights during
pre-training (Sparse Pre-training) and then recover the representational
capacity by allowing the zeroed weights to learn (Dense Fine-tuning). We
demonstrate that we can induce up to 75% sparsity into a 1.3B parameter GPT-3
XL model resulting in a 2.5x reduction in pre-training FLOPs, without a
significant loss in accuracy on the downstream tasks relative to the dense
baseline. By rigorously evaluating multiple downstream tasks, we also establish
a relationship between sparsity, task complexity, and dataset size. Our work
presents a promising direction to train large GPT models at a fraction of the
training FLOPs using weight sparsity while retaining the benefits of
pre-trained textual representations for downstream tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning. (arXiv:2303.10475v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10475">
<div class="article-summary-box-inner">
<span><p>Task semantics can be expressed by a set of input-to-output examples or a
piece of textual instruction. Conventional machine learning approaches for
natural language processing (NLP) mainly rely on the availability of
large-scale sets of task-specific examples. Two issues arise: first, collecting
task-specific labeled examples does not apply to scenarios where tasks may be
too complicated or costly to annotate, or the system is required to handle a
new task immediately; second, this is not user-friendly since end-users are
probably more willing to provide task description rather than a set of examples
before using the system. Therefore, the community is paying increasing interest
in a new supervision-seeking paradigm for NLP: learning from task instructions.
Despite its impressive progress, there are some common issues that the
community struggles with. This survey paper tries to summarize the current
research on instruction learning, particularly, by answering the following
questions: (i) what is task instruction, and what instruction types exist? (ii)
how to model instructions? (iii) what factors influence and explain the
instructions' performance? (iv) what challenges remain in instruction learning?
To our knowledge, this is the first comprehensive survey about textual
instructions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Deep Learning System for Domain-specific speech Recognition. (arXiv:2303.10510v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10510">
<div class="article-summary-box-inner">
<span><p>As human-machine voice interfaces provide easy access to increasingly
intelligent machines, many state-of-the-art automatic speech recognition (ASR)
systems are proposed. However, commercial ASR systems usually have poor
performance on domain-specific speech especially under low-resource settings.
The author works with pre-trained DeepSpeech2 and Wav2Vec2 acoustic models to
develop benefit-specific ASR systems. The domain-specific data are collected
using proposed semi-supervised learning annotation with little human
intervention. The best performance comes from a fine-tuned Wav2Vec2-Large-LV60
acoustic model with an external KenLM, which surpasses the Google and AWS ASR
systems on benefit-specific speech. The viability of using error prone ASR
transcriptions as part of spoken language understanding (SLU) is also
investigated. Results of a benefit-specific natural language understanding
(NLU) task show that the domain-specific fine-tuned ASR system can outperform
the commercial ASR systems even when its transcriptions have higher word error
rate (WER), and the results between fine-tuned ASR and human transcriptions are
similar.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning. (arXiv:2303.10512v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10512">
<div class="article-summary-box-inner">
<span><p>Fine-tuning large pre-trained language models on downstream tasks has become
an important paradigm in NLP. However, common practice fine-tunes all of the
parameters in a pre-trained model, which becomes prohibitive when a large
number of downstream tasks are present. Therefore, many fine-tuning methods are
proposed to learn incremental updates of pre-trained weights in a parameter
efficient way, e.g., low-rank increments. These methods often evenly distribute
the budget of incremental updates across all pre-trained weight matrices, and
overlook the varying importance of different weight parameters. As a
consequence, the fine-tuning performance is suboptimal. To bridge this gap, we
propose AdaLoRA, which adaptively allocates the parameter budget among weight
matrices according to their importance score. In particular, AdaLoRA
parameterizes the incremental updates in the form of singular value
decomposition. Such a novel approach allows us to effectively prune the
singular values of unimportant updates, which is essentially to reduce their
parameter budget but circumvent intensive exact SVD computations. We conduct
extensive experiments with several pre-trained models on natural language
processing, question answering, and natural language generation to validate the
effectiveness of AdaLoRA. Results demonstrate that AdaLoRA manifests notable
improvement over baselines, especially in the low budget settings. Our code is
publicly available at https://github.com/QingruZhang/AdaLoRA .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Two Kinds of Recall. (arXiv:2303.10527v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10527">
<div class="article-summary-box-inner">
<span><p>It is an established assumption that pattern-based models are good at
precision, while learning based models are better at recall. But is that really
the case? I argue that there are two kinds of recall: d-recall, reflecting
diversity, and e-recall, reflecting exhaustiveness. I demonstrate through
experiments that while neural methods are indeed significantly better at
d-recall, it is sometimes the case that pattern-based methods are still
substantially better at e-recall. Ideal methods should aim for both kinds, and
this ideal should in turn be reflected in our evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How People Respond to the COVID-19 Pandemic on Twitter: A Comparative Analysis of Emotional Expressions from US and India. (arXiv:2303.10560v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10560">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic has claimed millions of lives worldwide and elicited
heightened emotions. This study examines the expression of various emotions
pertaining to COVID-19 in the United States and India as manifested in over 54
million tweets, covering the fifteen-month period from February 2020 through
April 2021, a period which includes the beginnings of the huge and disastrous
increase in COVID-19 cases that started to ravage India in March 2021.
Employing pre-trained emotion analysis and topic modeling algorithms, four
distinct types of emotions (fear, anger, happiness, and sadness) and their
time- and location-associated variations were examined. Results revealed
significant country differences and temporal changes in the relative
proportions of fear, anger, and happiness, with fear declining and anger and
happiness fluctuating in 2020 until new situations over the first four months
of 2021 reversed the trends. Detected differences are discussed briefly in
terms of the latent topics revealed and through the lens of appraisal theories
of emotions, and the implications of the findings are discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extracting Incidents, Effects, and Requested Advice from MeToo Posts. (arXiv:2303.10573v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10573">
<div class="article-summary-box-inner">
<span><p>Survivors of sexual harassment frequently share their experiences on social
media, revealing their feelings and emotions and seeking advice. We observed
that on Reddit, survivors regularly share long posts that describe a
combination of (i) a sexual harassment incident, (ii) its effect on the
survivor, including their feelings and emotions, and (iii) the advice being
sought. We term such posts MeToo posts, even though they may not be so tagged
and may appear in diverse subreddits. A prospective helper (such as a counselor
or even a casual reader) must understand a survivor's needs from such posts.
But long posts can be time-consuming to read and respond to.
</p>
<p>Accordingly, we address the problem of extracting key information from a long
MeToo post. We develop a natural language-based model to identify sentences
from a post that describe any of the above three categories.
</p>
<p>On ten-fold cross-validation of a dataset, our model achieves a macro F1
score of 0.82.
</p>
<p>In addition, we contribute MeThree, a dataset comprising 8,947 labeled
sentences extracted from Reddit posts. We apply the LIWC-22 toolkit on MeThree
to understand how different language patterns in sentences of the three
categories can reveal differences in emotional tone, authenticity, and other
aspects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward Artificial Empathy for Human-Centered Design: A Framework. (arXiv:2303.10583v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10583">
<div class="article-summary-box-inner">
<span><p>In the early stages of the design process, designers explore opportunities by
discovering unmet needs and developing innovative concepts as potential
solutions. From a human-centered design perspective, designers must develop
empathy with people to truly understand their needs. However, developing
empathy is a complex and subjective process that relies heavily on the
designer's empathetic capability. Therefore, the development of empathetic
understanding is intuitive, and the discovery of underlying needs is often
serendipitous. This paper aims to provide insights from artificial intelligence
research to indicate the future direction of AI-driven human-centered design,
taking into account the essential role of empathy. Specifically, we conduct an
interdisciplinary investigation of research areas such as data-driven user
studies, empathetic understanding development, and artificial empathy. Based on
this foundation, we discuss the role that artificial empathy can play in
human-centered design and propose an artificial empathy framework for
human-centered design. Building on the mechanisms behind empathy and insights
from empathetic design research, the framework aims to break down the rather
complex and subjective concept of empathy into components and modules that can
potentially be modeled computationally. Furthermore, we discuss the expected
benefits of developing such systems and identify current research gaps to
encourage future research efforts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CTRAN: CNN-Transformer-based Network for Natural Language Understanding. (arXiv:2303.10606v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10606">
<div class="article-summary-box-inner">
<span><p>Intent-detection and slot-filling are the two main tasks in natural language
understanding. In this study, we propose CTRAN, a novel encoder-decoder
CNN-Transformer-based architecture for intent-detection and slot-filling. In
the encoder, we use BERT, followed by several convolutional layers, and
rearrange the output using window feature sequence. We use stacked Transformer
encoders after the window feature sequence. For the intent-detection decoder,
we utilize self-attention followed by a linear layer. In the slot-filling
decoder, we introduce the aligned Transformer decoder, which utilizes a zero
diagonal mask, aligning output tags with input tokens. We apply our network on
ATIS and SNIPS, and surpass the current state-of-the-art in slot-filling on
both datasets. Furthermore, we incorporate the language model as word
embeddings, and show that this strategy yields a better result when compared to
the language model as an encoder.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bangla Grammatical Error Detection Using T5 Transformer Model. (arXiv:2303.10612v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10612">
<div class="article-summary-box-inner">
<span><p>This paper presents a method for detecting grammatical errors in Bangla using
a Text-to-Text Transfer Transformer (T5) Language Model, using the small
variant of BanglaT5, fine-tuned on a corpus of 9385 sentences where errors were
bracketed by the dedicated demarcation symbol. The T5 model was primarily
designed for translation and is not specifically designed for this task, so
extensive post-processing was necessary to adapt it to the task of error
detection. Our experiments show that the T5 model can achieve low Levenshtein
Distance in detecting grammatical errors in Bangla, but post-processing is
essential to achieve optimal performance. The final average Levenshtein
Distance after post-processing the output of the fine-tuned model was 1.0394 on
a test set of 5000 sentences. This paper also presents a detailed analysis of
the errors detected by the model and discusses the challenges of adapting a
translation model for grammar. Our approach can be extended to other languages,
demonstrating the potential of T5 models for detecting grammatical errors in a
wide range of languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What Makes Sentences Semantically Related: A Textual Relatedness Dataset and Empirical Study. (arXiv:2110.04845v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04845">
<div class="article-summary-box-inner">
<span><p>The degree of semantic relatedness of two units of language has long been
considered fundamental to understanding meaning. Additionally, automatically
determining relatedness has many applications such as question answering and
summarization. However, prior NLP work has largely focused on semantic
similarity, a subset of relatedness, because of a lack of relatedness datasets.
In this paper, we introduce a dataset for Semantic Textual Relatedness,
STR-2022, that has 5,500 English sentence pairs manually annotated using a
comparative annotation framework, resulting in fine-grained scores. We show
that human intuition regarding relatedness of sentence pairs is highly
reliable, with a repeat annotation correlation of 0.84. We use the dataset to
explore questions on what makes sentences semantically related. We also show
the utility of STR-2022 for evaluating automatic methods of sentence
representation and for various downstream NLP tasks.
</p>
<p>Our dataset, data statement, and annotation questionnaire can be found at:
https://doi.org/10.5281/zenodo.7599667
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Learning for Event Extraction with Memory-based Loss Prediction Model. (arXiv:2112.03073v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.03073">
<div class="article-summary-box-inner">
<span><p>Event extraction (EE) plays an important role in many industrial application
scenarios, and high-quality EE methods require a large amount of manual
annotation data to train supervised learning models. However, the cost of
obtaining annotation data is very high, especially for annotation of domain
events, which requires the participation of experts from corresponding domain.
So we introduce active learning (AL) technology to reduce the cost of event
annotation. But the existing AL methods have two main problems, which make them
not well used for event extraction. Firstly, the existing pool-based selection
strategies have limitations in terms of computational cost and sample validity.
Secondly, the existing evaluation of sample importance lacks the use of local
sample information. In this paper, we present a novel deep AL method for EE. We
propose a batch-based selection strategy and a Memory-Based Loss Prediction
model (MBLP) to select unlabeled samples efficiently. During the selection
process, we use an internal-external sample loss ranking method to evaluate the
sample importance by using local information. Finally, we propose a delayed
training strategy to train the MBLP model. Extensive experiments are performed
on three domain datasets, and our method outperforms other state-of-the-art
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextual Semantic Embeddings for Ontology Subsumption Prediction. (arXiv:2202.09791v4 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.09791">
<div class="article-summary-box-inner">
<span><p>Automating ontology construction and curation is an important but challenging
task in knowledge engineering and artificial intelligence. Prediction by
machine learning techniques such as contextual semantic embedding is a
promising direction, but the relevant research is still preliminary especially
for expressive ontologies in Web Ontology Language (OWL). In this paper, we
present a new subsumption prediction method named BERTSubs for classes of OWL
ontology. It exploits the pre-trained language model BERT to compute contextual
embeddings of a class, where customized templates are proposed to incorporate
the class context (e.g., neighbouring classes) and the logical existential
restriction. BERTSubs is able to predict multiple kinds of subsumers including
named classes from the same ontology or another ontology, and existential
restrictions from the same ontology. Extensive evaluation on five real-world
ontologies for three different subsumption tasks has shown the effectiveness of
the templates and that BERTSubs can dramatically outperform the baselines that
use (literal-aware) knowledge graph embeddings, non-contextual word embeddings
and the state-of-the-art OWL ontology embeddings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NELA-GT-2022: A Large Multi-Labelled News Dataset for The Study of Misinformation in News Articles. (arXiv:2203.05659v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.05659">
<div class="article-summary-box-inner">
<span><p>In this paper, we present the fifth installment of the NELA-GT datasets,
NELA-GT-2022. The dataset contains 1,778,361 articles from 361 outlets between
January 1st, 2022 and December 31st, 2022. Just as in past releases of the
dataset, NELA-GT-2022 includes outlet-level veracity labels from Media
Bias/Fact Check and tweets embedded in collected news articles. The
NELA-GT-2022 dataset can be found at: https://doi.org/10.7910/DVN/AMCV2H
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward a realistic model of speech processing in the brain with self-supervised learning. (arXiv:2206.01685v2 [q-bio.NC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.01685">
<div class="article-summary-box-inner">
<span><p>Several deep neural networks have recently been shown to generate activations
similar to those of the brain in response to the same input. These algorithms,
however, remain largely implausible: they require (1) extraordinarily large
amounts of data, (2) unobtainable supervised labels, (3) textual rather than
raw sensory input, and / or (4) implausibly large memory (e.g. thousands of
contextual words). These elements highlight the need to identify algorithms
that, under these limitations, would suffice to account for both behavioral and
brain responses. Focusing on the issue of speech processing, we here
hypothesize that self-supervised algorithms trained on the raw waveform
constitute a promising candidate. Specifically, we compare a recent
self-supervised architecture, Wav2Vec 2.0, to the brain activity of 412
English, French, and Mandarin individuals recorded with functional Magnetic
Resonance Imaging (fMRI), while they listened to ~1h of audio books. Our
results are four-fold. First, we show that this algorithm learns brain-like
representations with as little as 600 hours of unlabelled speech -- a quantity
comparable to what infants can be exposed to during language acquisition.
Second, its functional hierarchy aligns with the cortical hierarchy of speech
processing. Third, different training regimes reveal a functional
specialization akin to the cortex: Wav2Vec 2.0 learns sound-generic,
speech-specific and language-specific representations similar to those of the
prefrontal and temporal cortices. Fourth, we confirm the similarity of this
specialization with the behavior of 386 additional participants. These
elements, resulting from the largest neuroimaging benchmark to date, show how
self-supervised learning can account for a rich organization of speech
processing in the brain, and thus delineate a path to identify the laws of
language acquisition which shape the human brain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Maximum Linear Arrangement Problem for trees under projectivity and planarity. (arXiv:2206.06924v4 [cs.DS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.06924">
<div class="article-summary-box-inner">
<span><p>A linear arrangement is a mapping $\pi$ from the $n$ vertices of a graph $G$
to $n$ distinct consecutive integers. Linear arrangements can be represented by
drawing the vertices along a horizontal line and drawing the edges as
semicircles above said line. In this setting, the length of an edge is defined
as the absolute value of the difference between the positions of its two
vertices in the arrangement, and the cost of an arrangement as the sum of all
edge lengths. Here we study two variants of the Maximum Linear Arrangement
problem (MaxLA), which consists of finding an arrangement that maximizes the
cost. In the planar variant for free trees, vertices have to be arranged in
such a way that there are no edge crossings. In the projective variant for
rooted trees, arrangements have to be planar and the root of the tree cannot be
covered by any edge. In this paper we present algorithms that are linear in
time and space to solve planar and projective MaxLA for trees. We also prove
several properties of maximum projective and planar arrangements, and show that
caterpillar trees maximize planar MaxLA over all trees of a fixed size thereby
generalizing a previous extremal result on trees.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GraphCFC: A Directed Graph based Cross-modal Feature Complementation Approach for Multimodal Conversational Emotion Recognition. (arXiv:2207.12261v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.12261">
<div class="article-summary-box-inner">
<span><p>Emotion Recognition in Conversation (ERC) plays a significant part in
Human-Computer Interaction (HCI) systems since it can provide empathetic
services. Multimodal ERC can mitigate the drawbacks of uni-modal approaches.
Recently, Graph Neural Networks (GNNs) have been widely used in a variety of
fields due to their superior performance in relation modeling. In multimodal
ERC, GNNs are capable of extracting both long-distance contextual information
and inter-modal interactive information. Unfortunately, since existing methods
such as MMGCN directly fuse multiple modalities, redundant information may be
generated and diverse information may be lost. In this work, we present a
directed Graph based Cross-modal Feature Complementation (GraphCFC) module that
can efficiently model contextual and interactive information. GraphCFC
alleviates the problem of heterogeneity gap in multimodal fusion by utilizing
multiple subspace extractors and Pair-wise Cross-modal Complementary (PairCC)
strategy. We extract various types of edges from the constructed graph for
encoding, thus enabling GNNs to extract crucial contextual and interactive
information more accurately when performing message passing. Furthermore, we
design a GNN structure called GAT-MLP, which can provide a new unified network
framework for multimodal learning. The experimental results on two benchmark
datasets show that our GraphCFC outperforms the state-of-the-art (SOTA)
approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EcoFormer: Energy-Saving Attention with Linear Complexity. (arXiv:2209.09004v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.09004">
<div class="article-summary-box-inner">
<span><p>Transformer is a transformative framework that models sequential data and has
achieved remarkable performance on a wide range of tasks, but with high
computational and energy cost. To improve its efficiency, a popular choice is
to compress the models via binarization which constrains the floating-point
values into binary ones to save resource consumption owing to cheap bitwise
operations significantly. However, existing binarization methods only aim at
minimizing the information loss for the input distribution statistically, while
ignoring the pairwise similarity modeling at the core of the attention. To this
end, we propose a new binarization paradigm customized to high-dimensional
softmax attention via kernelized hashing, called EcoFormer, to map the original
queries and keys into low-dimensional binary codes in Hamming space. The
kernelized hash functions are learned to match the ground-truth similarity
relations extracted from the attention map in a self-supervised way. Based on
the equivalence between the inner product of binary codes and the Hamming
distance as well as the associative property of matrix multiplication, we can
approximate the attention in linear complexity by expressing it as a
dot-product of binary codes. Moreover, the compact binary representations of
queries and keys enable us to replace most of the expensive multiply-accumulate
operations in attention with simple accumulations to save considerable on-chip
energy footprint on edge devices. Extensive experiments on both vision and
language tasks show that EcoFormer consistently achieves comparable performance
with standard attentions while consuming much fewer resources. For example,
based on PVTv2-B0 and ImageNet-1K, Ecoformer achieves a 73% on-chip energy
footprint reduction with only a 0.33% performance drop compared to the standard
attention. Code is available at https://github.com/ziplab/EcoFormer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Construction and Applications of Billion-Scale Pre-Trained Multimodal Business Knowledge Graph. (arXiv:2209.15214v6 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.15214">
<div class="article-summary-box-inner">
<span><p>Business Knowledge Graphs (KGs) are important to many enterprises today,
providing factual knowledge and structured data that steer many products and
make them more intelligent. Despite their promising benefits, building business
KG necessitates solving prohibitive issues of deficient structure and multiple
modalities. In this paper, we advance the understanding of the practical
challenges related to building KG in non-trivial real-world systems. We
introduce the process of building an open business knowledge graph (OpenBG)
derived from a well-known enterprise, Alibaba Group. Specifically, we define a
core ontology to cover various abstract products and consumption demands, with
fine-grained taxonomy and multimodal facts in deployed applications. OpenBG is
an open business KG of unprecedented scale: 2.6 billion triples with more than
88 million entities covering over 1 million core classes/concepts and 2,681
types of relations. We release all the open resources (OpenBG benchmarks)
derived from it for the community and report experimental results of KG-centric
tasks. We also run up an online competition based on OpenBG benchmarks, and has
attracted thousands of teams. We further pre-train OpenBG and apply it to many
KG- enhanced downstream tasks in business scenarios, demonstrating the
effectiveness of billion-scale multimodal knowledge for e-commerce. All the
resources with codes have been released at
\url{https://github.com/OpenBGBenchmark/OpenBG}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MTEB: Massive Text Embedding Benchmark. (arXiv:2210.07316v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07316">
<div class="article-summary-box-inner">
<span><p>Text embeddings are commonly evaluated on a small set of datasets from a
single task not covering their possible applications to other tasks. It is
unclear whether state-of-the-art embeddings on semantic textual similarity
(STS) can be equally well applied to other tasks like clustering or reranking.
This makes progress in the field difficult to track, as various models are
constantly being proposed without proper evaluation. To solve this problem, we
introduce the Massive Text Embedding Benchmark (MTEB). MTEB spans 8 embedding
tasks covering a total of 58 datasets and 112 languages. Through the
benchmarking of 33 models on MTEB, we establish the most comprehensive
benchmark of text embeddings to date. We find that no particular text embedding
method dominates across all tasks. This suggests that the field has yet to
converge on a universal text embedding method and scale it up sufficiently to
provide state-of-the-art results on all embedding tasks. MTEB comes with
open-source code and a public leaderboard at
https://github.com/embeddings-benchmark/mteb.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PACIFIC: Towards Proactive Conversational Question Answering over Tabular and Textual Data in Finance. (arXiv:2210.08817v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08817">
<div class="article-summary-box-inner">
<span><p>To facilitate conversational question answering (CQA) over hybrid contexts in
finance, we present a new dataset, named PACIFIC. Compared with existing CQA
datasets, PACIFIC exhibits three key features: (i) proactivity, (ii) numerical
reasoning, and (iii) hybrid context of tables and text. A new task is defined
accordingly to study Proactive Conversational Question Answering (PCQA), which
combines clarification question generation and CQA. In addition, we propose a
novel method, namely UniPCQA, to adapt a hybrid format of input and output
content in PCQA into the Seq2Seq problem, including the reformulation of the
numerical reasoning process as code generation. UniPCQA performs multi-task
learning over all sub-tasks in PCQA and incorporates a simple ensemble strategy
to alleviate the error propagation issue in the multi-task learning by
cross-validating top-$k$ sampled Seq2Seq outputs. We benchmark the PACIFIC
dataset with extensive baselines and provide comprehensive evaluations on each
sub-task of PCQA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Privately Fine-Tuning Large Language Models with Differential Privacy. (arXiv:2210.15042v3 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.15042">
<div class="article-summary-box-inner">
<span><p>Pre-trained Large Language Models (LLMs) are an integral part of modern AI
that have led to breakthrough performances in complex AI tasks. Major AI
companies with expensive infrastructures are able to develop and train these
large models with billions and millions of parameters from scratch. Third
parties, researchers, and practitioners are increasingly adopting these
pre-trained models and fine-tuning them on their private data to accomplish
their downstream AI tasks. However, it has been shown that an adversary can
extract/reconstruct the exact training samples from these LLMs, which can lead
to revealing personally identifiable information. The issue has raised deep
concerns about the privacy of LLMs. Differential privacy (DP) provides a
rigorous framework that allows adding noise in the process of training or
fine-tuning LLMs such that extracting the training data becomes infeasible
(i.e., with a cryptographically small success probability). While the
theoretical privacy guarantees offered in most extant studies assume learning
models from scratch through many training iterations in an asymptotic setting,
this assumption does not hold in fine-tuning scenarios in which the number of
training iterations is significantly smaller. To address the gap, we present
\ewtune, a DP framework for fine-tuning LLMs based on Edgeworth accountant with
finite-sample privacy guarantees. Our results across four well-established
natural language understanding (NLU) tasks show that while \ewtune~adds privacy
guarantees to LLM fine-tuning process, it directly contributes to decreasing
the induced noise to up to 5.6\% and improves the state-of-the-art LLMs
performance by up to 1.1\% across all NLU tasks. We have open-sourced our
implementations for wide adoption and public testing purposes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VieCap4H-VLSP 2021: ObjectAoA-Enhancing performance of Object Relation Transformer with Attention on Attention for Vietnamese image captioning. (arXiv:2211.05405v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.05405">
<div class="article-summary-box-inner">
<span><p>Image captioning is currently a challenging task that requires the ability to
both understand visual information and use human language to describe this
visual information in the image. In this paper, we propose an efficient way to
improve the image understanding ability of transformer-based method by
extending Object Relation Transformer architecture with Attention on Attention
mechanism. Experiments on the VieCap4H dataset show that our proposed method
significantly outperforms its original structure on both the public test and
private test of the Image Captioning shared task held by VLSP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models. (arXiv:2212.04088v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04088">
<div class="article-summary-box-inner">
<span><p>This study focuses on using large language models (LLMs) as a planner for
embodied agents that can follow natural language instructions to complete
complex tasks in a visually-perceived environment. The high data cost and poor
sample efficiency of existing methods hinders the development of versatile
agents that are capable of many tasks and can learn new tasks quickly. In this
work, we propose a novel method, LLM-Planner, that harnesses the power of large
language models to do few-shot planning for embodied agents. We further propose
a simple but effective way to enhance LLMs with physical grounding to generate
and update plans that are grounded in the current environment. Experiments on
the ALFRED dataset show that our method can achieve very competitive few-shot
performance: Despite using less than 0.5% of paired training data, LLM-Planner
achieves competitive performance with recent baselines that are trained using
the full training data. Existing methods can barely complete any task
successfully under the same few-shot setting. Our work opens the door for
developing versatile and sample-efficient embodied agents that can quickly
learn many tasks. Website: https://dki-lab.github.io/LLM-Planner
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MN-DS: A Multilabeled News Dataset for News Articles Hierarchical Classification. (arXiv:2212.12061v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.12061">
<div class="article-summary-box-inner">
<span><p>This article presents a dataset of 10,917 news articles with hierarchical
news categories collected between January 1st 2019, and December 31st 2019. We
manually labelled the articles based on a hierarchical taxonomy with 17
first-level and 109 second-level categories. This dataset can be used to train
machine learning models for automatically classifying news articles by topic.
This dataset can be helpful for researchers working on news structuring,
classification, and predicting future events based on released news.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Error-Guided Correction Model for Chinese Spelling Error Correction. (arXiv:2301.06323v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.06323">
<div class="article-summary-box-inner">
<span><p>Although existing neural network approaches have achieved great success on
Chinese spelling correction, there is still room to improve. The model is
required to avoid over-correction and to distinguish a correct token from its
phonological and visually similar ones. In this paper, we propose an
error-guided correction model (EGCM) to improve Chinese spelling correction. By
borrowing the powerful ability of BERT, we propose a novel zero-shot error
detection method to do a preliminary detection, which guides our model to
attend more on the probably wrong tokens in encoding and to avoid modifying the
correct tokens in generating. Furthermore, we introduce a new loss function to
integrate the error confusion set, which enables our model to distinguish
easily misused tokens. Moreover, our model supports highly parallel decoding to
meet real application requirements. Experiments are conducted on widely used
benchmarks. Our model achieves superior performance against state-of-the-art
approaches by a remarkable margin, on both the correction quality and
computation speed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is ChatGPT A Good Translator? Yes With GPT-4 As The Engine. (arXiv:2301.08745v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.08745">
<div class="article-summary-box-inner">
<span><p>This report provides a preliminary evaluation of ChatGPT for machine
translation, including translation prompt, multilingual translation, and
translation robustness. We adopt the prompts advised by ChatGPT to trigger its
translation ability and find that the candidate prompts generally work well and
show minor performance differences. By evaluating on a number of benchmark test
sets, we find that ChatGPT performs competitively with commercial translation
products (e.g., Google Translate) on high-resource European languages but lags
behind significantly on low-resource or distant languages. For distant
languages, we explore an interesting strategy named $\mathbf{pivot~prompting}$
that asks ChatGPT to translate the source sentence into a high-resource pivot
language before into the target language, which improves the translation
performance significantly. As for the translation robustness, ChatGPT does not
perform as well as the commercial systems on biomedical abstracts or Reddit
comments but exhibits good results on spoken language. With the launch of the
GPT-4 engine, the translation performance of ChatGPT is significantly boosted,
becoming comparable to commercial translation products, even for distant
languages. In other words,
$\mathbf{ChatGPT~has~already~become~a~good~translator!}$ Scripts and data:
https://github.com/wxjiao/Is-ChatGPT-A-Good-Translator
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FGSI: Distant Supervision for Relation Extraction method based on Fine-Grained Semantic Information. (arXiv:2302.02078v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.02078">
<div class="article-summary-box-inner">
<span><p>The main purpose of relation extraction is to extract the semantic
relationships between tagged pairs of entities in a sentence, which plays an
important role in the semantic understanding of sentences and the construction
of knowledge graphs. In this paper, we propose that the key semantic
information within a sentence plays a key role in the relationship extraction
of entities. We propose the hypothesis that the key semantic information inside
the sentence plays a key role in entity relationship extraction. And based on
this hypothesis, we split the sentence into three segments according to the
location of the entity from the inside of the sentence, and find the
fine-grained semantic features inside the sentence through the intra-sentence
attention mechanism to reduce the interference of irrelevant noise information.
The proposed relational extraction model can make full use of the available
positive semantic information. The experimental results show that the proposed
relation extraction model improves the accuracy-recall curves and P@N values
compared with existing methods, which proves the effectiveness of this model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning from Noisy Crowd Labels with Logics. (arXiv:2302.06337v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.06337">
<div class="article-summary-box-inner">
<span><p>This paper explores the integration of symbolic logic knowledge into deep
neural networks for learning from noisy crowd labels. We introduce Logic-guided
Learning from Noisy Crowd Labels (Logic-LNCL), an EM-alike iterative logic
knowledge distillation framework that learns from both noisy labeled data and
logic rules of interest. Unlike traditional EM methods, our framework contains
a ``pseudo-E-step'' that distills from the logic rules a new type of learning
target, which is then used in the ``pseudo-M-step'' for training the
classifier. Extensive evaluations on two real-world datasets for text sentiment
classification and named entity recognition demonstrate that the proposed
framework improves the state-of-the-art and provides a new solution to learning
from noisy crowd labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AugGPT: Leveraging ChatGPT for Text Data Augmentation. (arXiv:2302.13007v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.13007">
<div class="article-summary-box-inner">
<span><p>Text data augmentation is an effective strategy for overcoming the challenge
of limited sample sizes in many natural language processing (NLP) tasks. This
challenge is especially prominent in the few-shot learning scenario, where the
data in the target domain is generally much scarcer and of lowered quality. A
natural and widely-used strategy to mitigate such challenges is to perform data
augmentation to better capture the data invariance and increase the sample
size. However, current text data augmentation methods either can't ensure the
correct labeling of the generated data (lacking faithfulness) or can't ensure
sufficient diversity in the generated data (lacking compactness), or both.
Inspired by the recent success of large language models, especially the
development of ChatGPT, which demonstrated improved language comprehension
abilities, in this work, we propose a text data augmentation approach based on
ChatGPT (named AugGPT). AugGPT rephrases each sentence in the training samples
into multiple conceptually similar but semantically different samples. The
augmented samples can then be used in downstream model training. Experiment
results on few-shot learning text classification tasks show the superior
performance of the proposed AugGPT approach over state-of-the-art text data
augmentation methods in terms of testing accuracy and distribution of the
augmented samples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uzbek text's correspondence with the educational potential of pupils: a case study of the School corpus. (arXiv:2303.00465v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.00465">
<div class="article-summary-box-inner">
<span><p>One of the major challenges of an educational system is choosing appropriate
content considering pupils' age and intellectual potential. In this article the
experiment of primary school grades (from 1st to 4th grades) is considered for
automatically determining the correspondence of an educational materials
recommended for pupils by using the School corpus where it includes the dataset
of 25 school textbooks confirmed by the Ministry of preschool and school
education of the Republic of Uzbekistan. In this case, TF-IDF scores of the
texts are determined, they are converted into a vector representation, and the
given educational materials are compared with the corresponding class of the
School corpus using the cosine similarity algorithm. Based on the results of
the calculation, it is determined whether the given educational material is
appropriate or not appropriate for the pupils' educational potential.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interactive Text Generation. (arXiv:2303.00908v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.00908">
<div class="article-summary-box-inner">
<span><p>Users interact with text, image, code, or other editors on a daily basis.
However, machine learning models are rarely trained in the settings that
reflect the interactivity between users and their editor. This is
understandable as training AI models with real users is not only slow and
costly, but what these models learn may be specific to user interface design
choices. Unfortunately, this means most of the research on text, code, and
image generation has focused on non-interactive settings, whereby the model is
expected to get everything right without accounting for any input from a user
who may be willing to help.
</p>
<p>We introduce a new Interactive Text Generation task that allows training
generation models interactively without the costs of involving real users, by
using user simulators that provide edits that guide the model towards a given
target text. We train our interactive models using Imitation Learning, and our
experiments against competitive non-interactive generation models show that
models trained interactively are superior to their non-interactive
counterparts, even when all models are given the same budget of user inputs or
edits.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Science of Detecting LLM-Generated Texts. (arXiv:2303.07205v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.07205">
<div class="article-summary-box-inner">
<span><p>The emergence of large language models (LLMs) has resulted in the production
of LLM-generated texts that is highly sophisticated and almost
indistinguishable from texts written by humans. However, this has also sparked
concerns about the potential misuse of such texts, such as spreading
misinformation and causing disruptions in the education system. Although many
detection approaches have been proposed, a comprehensive understanding of the
achievements and challenges is still lacking. This survey aims to provide an
overview of existing LLM-generated text detection techniques and enhance the
control and regulation of language generation models. Furthermore, we emphasize
crucial considerations for future research, including the development of
comprehensive evaluation metrics and the threat posed by open-source LLMs, to
drive progress in the area of LLM-generated text detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Translating Radiology Reports into Plain Language using ChatGPT and GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential. (arXiv:2303.09038v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09038">
<div class="article-summary-box-inner">
<span><p>The large language model called ChatGPT has drawn extensively attention
because of its human-like expression and reasoning abilities. In this study, we
investigate the feasibility of using ChatGPT in experiments on using ChatGPT to
translate radiology reports into plain language for patients and healthcare
providers so that they are educated for improved healthcare. Radiology reports
from 62 low-dose chest CT lung cancer screening scans and 76 brain MRI
metastases screening scans were collected in the first half of February for
this study. According to the evaluation by radiologists, ChatGPT can
successfully translate radiology reports into plain language with an average
score of 4.27 in the five-point system with 0.08 places of information missing
and 0.07 places of misinformation. In terms of the suggestions provided by
ChatGPT, they are general relevant such as keeping following-up with doctors
and closely monitoring any symptoms, and for about 37% of 138 cases in total
ChatGPT offers specific suggestions based on findings in the report. ChatGPT
also presents some randomness in its responses with occasionally
over-simplified or neglected information, which can be mitigated using a more
detailed prompt. Furthermore, ChatGPT results are compared with a newly
released large model GPT-4, showing that GPT-4 can significantly improve the
quality of translated reports. Our results show that it is feasible to utilize
large language models in clinical education, and further efforts are needed to
address limitations and maximize their potential.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-03-21 23:11:37.948126830 UTC">2023-03-21 23:11:37 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>