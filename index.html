<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-03-22T01:30:00Z">03-22</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Reflexion: an autonomous agent with dynamic memory and self-reflection. (arXiv:2303.11366v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11366">
<div class="article-summary-box-inner">
<span><p>Recent advancements in decision-making large language model (LLM) agents have
demonstrated impressive performance across various benchmarks. However, these
state-of-the-art approaches typically necessitate internal model fine-tuning,
external model fine-tuning, or policy optimization over a defined state space.
Implementing these methods can prove challenging due to the scarcity of
high-quality training data or the lack of well-defined state space. Moreover,
these agents do not possess certain qualities inherent to human decision-making
processes, specifically the ability to learn from mistakes. Self-reflection
allows humans to efficiently solve novel problems through a process of trial
and error. Building on recent research, we propose Reflexion, an approach that
endows an agent with dynamic memory and self-reflection capabilities to enhance
its existing reasoning trace and task-specific action choice abilities. To
achieve full automation, we introduce a straightforward yet effective heuristic
that enables the agent to pinpoint hallucination instances, avoid repetition in
action sequences, and, in some environments, construct an internal memory map
of the given environment. To assess our approach, we evaluate the agent's
ability to complete decision-making tasks in AlfWorld environments and
knowledge-intensive, search-based question-and-answer tasks in HotPotQA
environments. We observe success rates of 97% and 51%, respectively, and
provide a discussion on the emergent property of self-reflection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action. (arXiv:2303.11381v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11381">
<div class="article-summary-box-inner">
<span><p>We propose MM-REACT, a system paradigm that integrates ChatGPT with a pool of
vision experts to achieve multimodal reasoning and action. In this paper, we
define and explore a comprehensive list of advanced vision tasks that are
intriguing to solve, but may exceed the capabilities of existing vision and
vision-language models. To achieve such advanced visual intelligence, MM-REACT
introduces a textual prompt design that can represent text descriptions,
textualized spatial coordinates, and aligned file names for dense visual
signals such as images and videos. MM-REACT's prompt design allows language
models to accept, associate, and process multimodal information, thereby
facilitating the synergetic combination of ChatGPT and various vision experts.
Zero-shot experiments demonstrate MM-REACT's effectiveness in addressing the
specified capabilities of interests and its wide application in different
scenarios that require advanced visual understanding. Furthermore, we discuss
and compare MM-REACT's system paradigm with an alternative approach that
extends language models for multimodal scenarios through joint finetuning.
Code, demo, video, and visualization are available at
https://multimodal-react.github.io/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">eP-ALM: Efficient Perceptual Augmentation of Language Models. (arXiv:2303.11403v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11403">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have so far impressed the world, with
unprecedented capabilities that emerge in models at large scales. On the vision
side, transformer models (i.e., ViT) are following the same trend, achieving
the best performance on challenging benchmarks. With the abundance of such
unimodal models, a natural question arises; do we need also to follow this
trend to tackle multimodal tasks? In this work, we propose to rather direct
effort to efficient adaptations of existing models, and propose to augment
Language Models with perception. Existing approaches for adapting pretrained
models for vision-language tasks still rely on several key components that
hinder their efficiency. In particular, they still train a large number of
parameters, rely on large multimodal pretraining, use encoders (e.g., CLIP)
trained on huge image-text datasets, and add significant inference overhead. In
addition, most of these approaches have focused on Zero-Shot and In Context
Learning, with little to no effort on direct finetuning. We investigate the
minimal computational effort needed to adapt unimodal models for multimodal
tasks and propose a new challenging setup, alongside different approaches, that
efficiently adapts unimodal pretrained models. We show that by freezing more
than 99\% of total parameters, training only one linear projection layer, and
prepending only one trainable token, our approach (dubbed eP-ALM) significantly
outperforms other baselines on VQA and Captioning across Image, Video, and
Audio modalities, following the proposed setup. The code will be available
here: https://github.com/mshukor/eP-ALM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mind meets machine: Unravelling GPT-4's cognitive psychology. (arXiv:2303.11436v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11436">
<div class="article-summary-box-inner">
<span><p>Commonsense reasoning is a basic ingredient of intelligence in humans,
empowering the ability to deduce conclusions based on the observations of
surroundings. Large language models (LLMs) are emerging as potent tools
increasingly capable of performing human-level tasks. The recent development in
the form of GPT-4 and its demonstrated success in tasks complex to humans such
as medical exam, bar exam and others has led to an increased confidence in the
LLMs to become perfect instruments of intelligence. Though, the GPT-4 paper has
shown performance on some common sense reasoning tasks, a comprehensive
assessment of GPT-4 on common sense reasoning tasks, particularly on the
existing well-established datasets is missing. In this study, we focus on the
evaluation of GPT-4's performance on a set of common sense reasoning questions
from the widely used CommonsenseQA dataset along with tools from cognitive
psychology. In doing so, we understand how GPT-4 processes and integrates
common sense knowledge with contextual information, providing insight into the
underlying cognitive processes that enable its ability to generate common sense
responses. We show that GPT-4 exhibits a high level of accuracy in answering
common sense questions, outperforming its predecessor, GPT-3 and GPT-3.5. We
show that the accuracy of GPT-4 on CommonSenseQA is 83 % and it has been shown
in the original study that human accuracy over the same data was 89 %.
Although, GPT-4 falls short of the human performance, it is a substantial
improvement from the original 56.5 % in the original language model used by the
CommonSenseQA study. Our results strengthen the already available assessments
and confidence on GPT-4's common sense reasoning abilities which have
significant potential to revolutionize the field of AI, by enabling machines to
bridge the gap between human and machine reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Minimizing Fuzzy Interpretations in Fuzzy Description Logics by Using Crisp Bisimulations. (arXiv:2303.11438v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11438">
<div class="article-summary-box-inner">
<span><p>The problem of minimizing finite fuzzy interpretations in fuzzy description
logics (FDLs) is worth studying. For example, the structure of a fuzzy/weighted
social network can be treated as a fuzzy interpretation in FDLs, where actors
are individuals and actions are roles. Minimizing the structure of a
fuzzy/weighted social network makes it more compact, thus making network
analysis tasks more efficient. In this work, we study the problem of minimizing
a finite fuzzy interpretation in a FDL by using the largest crisp
auto-bisimulation. The considered FDLs use the Baaz projection operator and
their semantics is specified using an abstract algebra of fuzzy truth values,
which can be any linear and complete residuated lattice. We provide an
efficient algorithm with a complexity of $O((m \log{l} + n) \log{n})$ for
minimizing a given finite fuzzy interpretation $\mathcal{I}$, where $n$ is the
size of the domain of $\mathcal{I}$, $m$ is number of nonzero instances of
atomic roles of $\mathcal{I}$ and $l$ is the number of different fuzzy values
used for instances of atomic roles of $\mathcal{I}$. We prove that the fuzzy
interpretation returned by the algorithm is minimal among the ones that
preserve fuzzy TBoxes and ABoxes under certain conditions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models and Simple, Stupid Bugs. (arXiv:2303.11455v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11455">
<div class="article-summary-box-inner">
<span><p>With the advent of powerful neural language models, AI-based systems to
assist developers in coding tasks are becoming widely available; Copilot is one
such system. Copilot uses Codex, a large language model (LLM), to complete code
conditioned on a preceding "prompt". Codex, however, is trained on public
GitHub repositories, viz., on code that may include bugs and vulnerabilities.
Previous studies [1], [2] show Codex reproduces vulnerabilities seen in
training. In this study, we examine how prone Codex is to generate an
interesting bug category, single statement bugs, commonly referred to as
simple, stupid bugs or SStuBs in the MSR community. We find that Codex and
similar LLMs do help avoid some SStuBs, but do produce known, verbatim SStuBs
as much as 2x as likely than known, verbatim correct code. We explore the
consequences of the Codex generated SStuBs and propose avoidance strategies
that suggest the possibility of reducing the production of known, verbatim
SStubs, and increase the possibility of producing known, verbatim fixes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Model Behavior: A Comprehensive Survey. (arXiv:2303.11504v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11504">
<div class="article-summary-box-inner">
<span><p>Transformer language models have received widespread public attention, yet
their generated text is often surprising even to NLP researchers. In this
survey, we discuss over 250 recent studies of English language model behavior
before task-specific fine-tuning. Language models possess basic capabilities in
syntax, semantics, pragmatics, world knowledge, and reasoning, but these
capabilities are sensitive to specific inputs and surface features. Despite
dramatic increases in generated text quality as models scale to hundreds of
billions of parameters, the models are still prone to unfactual responses,
commonsense errors, memorized text, and social biases. Many of these weaknesses
can be framed as over-generalizations or under-generalizations of learned
patterns in text. We synthesize recent results to highlight what is currently
known about what large language models can and cannot do.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SIFT: Sparse Iso-FLOP Transformations for Maximizing Training Efficiency. (arXiv:2303.11525v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11525">
<div class="article-summary-box-inner">
<span><p>Recent works have explored the use of weight sparsity to improve the training
efficiency (test accuracy w.r.t training FLOPs) of deep neural networks (DNNs).
These works aim to reduce training FLOPs but training with sparse weights often
leads to accuracy loss or requires longer train schedules, making the resulting
training efficiency less clear. In contrast, we focus on using sparsity to
increase accuracy while using the same FLOPS as the dense model and show
training efficiency gains through higher accuracy. In this work, we introduce
SIFT, a family of Sparse Iso-FLOP Transformations which are used as drop-in
replacements for dense layers to improve their representational capacity and
FLOP efficiency. Each transformation is parameterized by a single parameter
(sparsity level) and provides a larger search space to find optimal sparse
masks. Without changing any training hyperparameters, replacing dense layers
with SIFT leads to significant improvements across computer vision (CV) and
natural language processing (NLP) tasks, including ResNet-18 on ImageNet
(+3.5%) and GPT-3 Small on WikiText-103 (-0.4 PPL), both matching larger dense
model variants with 2x or more FLOPs. To the best of our knowledge, this is the
first work to demonstrate the use of sparsity for improving accuracy of dense
models via a simple-to-use set of sparse transformations. Code is available at:
https://github.com/CerebrasResearch/SIFT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Difficulty in learning chirality for Transformer fed with SMILES. (arXiv:2303.11593v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11593">
<div class="article-summary-box-inner">
<span><p>Recent years have seen development of descriptor generation based on
representation learning of extremely diverse molecules, especially those that
apply natural language processing (NLP) models to SMILES, a literal
representation of molecular structure. However, little research has been done
on how these models understand chemical structure. To address this, we
investigated the relationship between the learning progress of SMILES and
chemical structure using a representative NLP model, the Transformer. The
results suggest that while the Transformer learns partial structures of
molecules quickly, it requires extended training to understand overall
structures. Consistently, the accuracy of molecular property predictions using
descriptors generated from models at different learning steps was similar from
the beginning to the end of training. Furthermore, we found that the
Transformer requires particularly long training to learn chirality and
sometimes stagnates with low translation accuracy due to misunderstanding of
enantiomers. These findings are expected to deepen understanding of NLP models
in chemistry.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformers in Speech Processing: A Survey. (arXiv:2303.11607v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11607">
<div class="article-summary-box-inner">
<span><p>The remarkable success of transformers in the field of natural language
processing has sparked the interest of the speech-processing community, leading
to an exploration of their potential for modeling long-range dependencies
within speech sequences. Recently, transformers have gained prominence across
various speech-related domains, including automatic speech recognition, speech
synthesis, speech translation, speech para-linguistics, speech enhancement,
spoken dialogue systems, and numerous multimodal applications. In this paper,
we present a comprehensive survey that aims to bridge research studies from
diverse subfields within speech technology. By consolidating findings from
across the speech technology landscape, we provide a valuable resource for
researchers interested in harnessing the power of transformers to advance the
field. We identify the challenges encountered by transformers in speech
processing while also offering insights into potential solutions to address
these issues.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Heterogeneous-Branch Collaborative Learning for Dialogue Generation. (arXiv:2303.11621v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11621">
<div class="article-summary-box-inner">
<span><p>With the development of deep learning, advanced dialogue generation methods
usually require a greater amount of computational resources. One promising
approach to obtaining a high-performance and lightweight model is knowledge
distillation, which relies heavily on the pre-trained powerful teacher.
Collaborative learning, also known as online knowledge distillation, is an
effective way to conduct one-stage group distillation in the absence of a
well-trained large teacher model. However, previous work has a severe branch
homogeneity problem due to the same training objective and the independent
identical training sets. To alleviate this problem, we consider the dialogue
attributes in the training of network branches. Each branch learns the
attribute-related features based on the selected subset. Furthermore, we
propose a dual group-based knowledge distillation method, consisting of
positive distillation and negative distillation, to further diversify the
features of different branches in a steadily and interpretable way. The
proposed approach significantly improves branch heterogeneity and outperforms
state-of-the-art collaborative learning methods on two widely used open-domain
dialogue datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Content Retrievability in Search with Controllable Query Generation. (arXiv:2303.11648v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11648">
<div class="article-summary-box-inner">
<span><p>An important goal of online platforms is to enable content discovery, i.e.
allow users to find a catalog entity they were not familiar with. A
pre-requisite to discover an entity, e.g. a book, with a search engine is that
the entity is retrievable, i.e. there are queries for which the system will
surface such entity in the top results. However, machine-learned search engines
have a high retrievability bias, where the majority of the queries return the
same entities. This happens partly due to the predominance of narrow intent
queries, where users create queries using the title of an already known entity,
e.g. in book search 'harry potter'. The amount of broad queries where users
want to discover new entities, e.g. in music search 'chill lyrical electronica
with an atmospheric feeling to it', and have a higher tolerance to what they
might find, is small in comparison. We focus here on two factors that have a
negative impact on the retrievability of the entities (I) the training data
used for dense retrieval models and (II) the distribution of narrow and broad
intent queries issued in the system. We propose CtrlQGen, a method that
generates queries for a chosen underlying intent-narrow or broad. We can use
CtrlQGen to improve factor (I) by generating training data for dense retrieval
models comprised of diverse synthetic queries. CtrlQGen can also be used to
deal with factor (II) by suggesting queries with broader intents to users. Our
results on datasets from the domains of music, podcasts, and books reveal that
we can significantly decrease the retrievability bias of a dense retrieval
model when using CtrlQGen. First, by using the generated queries as training
data for dense models we make 9% of the entities retrievable (go from zero to
non-zero retrievability). Second, by suggesting broader queries to users, we
can make 12% of the entities retrievable in the best case.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simple Yet Effective Synthetic Dataset Construction for Unsupervised Opinion Summarization. (arXiv:2303.11660v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11660">
<div class="article-summary-box-inner">
<span><p>Opinion summarization provides an important solution for summarizing opinions
expressed among a large number of reviews. However, generating aspect-specific
and general summaries is challenging due to the lack of annotated data. In this
work, we propose two simple yet effective unsupervised approaches to generate
both aspect-specific and general opinion summaries by training on synthetic
datasets constructed with aspect-related review contents. Our first approach,
Seed Words Based Leave-One-Out (SW-LOO), identifies aspect-related portions of
reviews simply by exact-matching aspect seed words and outperforms existing
methods by 3.4 ROUGE-L points on SPACE and 0.5 ROUGE-1 point on OPOSUM+ for
aspect-specific opinion summarization. Our second approach, Natural Language
Inference Based Leave-One-Out (NLI-LOO) identifies aspect-related sentences
utilizing an NLI model in a more general setting without using seed words and
outperforms existing approaches by 1.2 ROUGE-L points on SPACE for
aspect-specific opinion summarization and remains competitive on other metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Open-domain Paradox for Chatbots: Common Ground as the Basis for Human-like Dialogue. (arXiv:2303.11708v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11708">
<div class="article-summary-box-inner">
<span><p>There is a surge in interest in the development of open-domain chatbots,
driven by the recent advancements of large language models. The "openness" of
the dialogue is expected to be maximized by providing minimal information to
the users about the common ground they can expect, including the presumed joint
activity. However, evidence suggests that the effect is the opposite. Asking
users to "just chat about anything" results in a very narrow form of dialogue,
which we refer to as the "open-domain paradox". In this paper, we explain this
paradox through the theory of common ground as the basis for human-like
communication. Furthermore, we question the assumptions behind open-domain
chatbots and identify paths forward for enabling common ground in
human-computer dialogue.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEAPT: Learning Adaptive Prefix-to-prefix Translation For Simultaneous Machine Translation. (arXiv:2303.11750v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11750">
<div class="article-summary-box-inner">
<span><p>Simultaneous machine translation, which aims at a real-time translation, is
useful in many live scenarios but very challenging due to the trade-off between
accuracy and latency. To achieve the balance for both, the model needs to wait
for appropriate streaming text (READ policy) and then generates its translation
(WRITE policy). However, WRITE policies of previous work either are specific to
the method itself due to the end-to-end training or suffer from the input
mismatch between training and decoding for the non-end-to-end training.
Therefore, it is essential to learn a generic and better WRITE policy for
simultaneous machine translation. Inspired by strategies utilized by human
interpreters and "wait" policies, we propose a novel adaptive prefix-to-prefix
training policy called LEAPT, which allows our machine translation model to
learn how to translate source sentence prefixes and make use of the future
context. Experiments show that our proposed methods greatly outperform
competitive baselines and achieve promising results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chinese Intermediate English Learners outdid ChatGPT in deep cohesion: Evidence from English narrative writing. (arXiv:2303.11812v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11812">
<div class="article-summary-box-inner">
<span><p>ChatGPT is a publicly available chatbot that can quickly generate texts on
given topics, but it is unknown whether the chatbot is really superior to human
writers in all aspects of writing and whether its writing quality can be
prominently improved on the basis of updating commands. Consequently, this
study compared the writing performance on a narrative topic by ChatGPT and
Chinese intermediate English (CIE) learners so as to reveal the chatbot's
advantage and disadvantage in writing. The data were analyzed in terms of five
discourse components using Coh-Metrix (a special instrument for analyzing
language discourses), and the results revealed that ChatGPT performed better
than human writers in narrativity, word concreteness, and referential cohesion,
but worse in syntactic simplicity and deep cohesion in its initial version.
After more revision commands were updated, while the resulting version was
facilitated in syntactic simplicity, yet it is still lagged far behind CIE
learners' writing in deep cohesion. In addition, the correlation analysis of
the discourse components suggests that narrativity was correlated with
referential cohesion in both ChatGPT and human writers, but the correlations
varied within each group.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Cross-Domain Rumor Detection with Contrastive Learning and Cross-Attention. (arXiv:2303.11945v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11945">
<div class="article-summary-box-inner">
<span><p>Massive rumors usually appear along with breaking news or trending topics,
seriously hindering the truth. Existing rumor detection methods are mostly
focused on the same domain, and thus have poor performance in cross-domain
scenarios due to domain shift. In this work, we propose an end-to-end
instance-wise and prototype-wise contrastive learning model with a
cross-attention mechanism for cross-domain rumor detection. The model not only
performs cross-domain feature alignment but also enforces target samples to
align with the corresponding prototypes of a given source domain. Since target
labels in a target domain are unavailable, we use a clustering-based approach
with carefully initialized centers by a batch of source domain samples to
produce pseudo labels. Moreover, we use a cross-attention mechanism on a pair
of source data and target data with the same labels to learn domain-invariant
representations. Because the samples in a domain pair tend to express similar
semantic patterns, especially on the people's attitudes (e.g., supporting or
denying) towards the same category of rumors, the discrepancy between a pair of
the source domain and target domain will be decreased. We conduct experiments
on four groups of cross-domain datasets and show that our proposed model
achieves state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Logical Reasoning over Natural Language as Knowledge Representation: A Survey. (arXiv:2303.12023v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.12023">
<div class="article-summary-box-inner">
<span><p>Logical reasoning is central to human cognition and intelligence. Past
research of logical reasoning within AI uses formal language as knowledge
representation~(and symbolic reasoners). However, reasoning with formal
language has proved challenging~(e.g., brittleness and knowledge-acquisition
bottleneck). This paper provides a comprehensive overview on a new paradigm of
logical reasoning, which uses natural language as knowledge representation~(and
pretrained language models as reasoners), including philosophical definition
and categorization of logical reasoning, advantages of the new paradigm,
benchmarks and methods, challenges of the new paradigm, desirable tasks &amp;
methods in the future, and relation to related NLP fields. This new paradigm is
promising since it not only alleviates many challenges of formal representation
but also has advantages over end-to-end neural methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">cTBL: Augmenting Large Language Models for Conversational Tables. (arXiv:2303.12024v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.12024">
<div class="article-summary-box-inner">
<span><p>An open challenge in multimodal conversational AI requires augmenting large
language models with information from textual and non-textual sources for
multi-turn dialogue. To address this problem, this paper introduces
Conversational Tables (cTBL), a three-step encoder-decoder approach to retrieve
tabular information and generate dialogue responses grounded on the retrieved
information. cTBL uses Transformer encoder embeddings for Dense Table Retrieval
and obtains up to 5% relative improvement in Top-1 and Top-3 accuracy over
sparse retrieval on the HyrbiDialogue dataset. Additionally, cTBL performs
tabular knowledge retrieval using both encoder and decoder models, resulting in
up to 46% relative improvement in ROUGE scores and better human evaluation for
response generation on HyrbiDialogue.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Wearing Masks Implies Refuting Trump?: Towards Target-specific User Stance Prediction across Events in COVID-19 and US Election 2020. (arXiv:2303.12029v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.12029">
<div class="article-summary-box-inner">
<span><p>People who share similar opinions towards controversial topics could form an
echo chamber and may share similar political views toward other topics as well.
The existence of such connections, which we call connected behavior, gives
researchers a unique opportunity to predict how one would behave for a future
event given their past behaviors. In this work, we propose a framework to
conduct connected behavior analysis. Neural stance detection models are trained
on Twitter data collected on three seemingly independent topics, i.e., wearing
a mask, racial equality, and Trump, to detect people's stance, which we
consider as their online behavior in each topic-related event. Our results
reveal a strong connection between the stances toward the three topical events
and demonstrate the power of past behaviors in predicting one's future
behavior.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grading Conversational Responses Of Chatbots. (arXiv:2303.12038v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.12038">
<div class="article-summary-box-inner">
<span><p>Chatbots have long been capable of answering basic questions and even
responding to obscure prompts, but recently their improvements have been far
more significant. Modern chatbots like Open AIs ChatGPT3 not only have the
ability to answer basic questions but can write code and movie scripts and
imitate well-known people. In this paper, we analyze ChatGPTs' responses to
various questions from a dataset of queries from the popular Quora forum. We
submitted sixty questions to ChatGPT and scored the answers based on three
industry-standard metrics for grading machine translation: BLEU, METEOR, and
ROUGE. These metrics allow us to compare the machine responses with the most
upvoted human answer to the same question to assess ChatGPT's ability to submit
a humanistic reply. The results showed that while the responses and translation
abilities of ChatGPT are remarkable, they still fall short of what a typical
human reaction would be.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Can Be Used to Estimate the Ideologies of Politicians in a Zero-Shot Learning Setting. (arXiv:2303.12057v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.12057">
<div class="article-summary-box-inner">
<span><p>The mass aggregation of knowledge embedded in large language models (LLMs)
holds the promise of new solutions to problems of observability and measurement
in the social sciences. We examine the utility of one such model for a
particularly difficult measurement task: measuring the latent ideology of
lawmakers, which allows us to better understand functions that are core to
democracy, such as how politics shape policy and how political actors represent
their constituents. We scale the senators of the 116th United States Congress
along the liberal-conservative spectrum by prompting ChatGPT to select the more
liberal (or conservative) senator in pairwise comparisons. We show that the LLM
produced stable answers across repeated iterations, did not hallucinate, and
was not simply regurgitating information from a single source. This new scale
strongly correlates with pre-existing liberal-conservative scales such as
NOMINATE, but also differs in several important ways, such as correctly placing
senators who vote against their party for far-left or far-right ideological
reasons on the extreme ends. The scale also highly correlates with ideological
measures based on campaign giving and political activists' perceptions of these
senators. In addition to the potential for better-automated data collection and
information retrieval, our results suggest LLMs are likely to open new avenues
for measuring latent constructs like ideology that rely on aggregating large
quantities of data from public sources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VideoXum: Cross-modal Visual and Textural Summarization of Videos. (arXiv:2303.12060v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.12060">
<div class="article-summary-box-inner">
<span><p>Video summarization aims to distill the most important information from a
source video to produce either an abridged clip or a textual narrative.
Traditionally, different methods have been proposed depending on whether the
output is a video or text, thus ignoring the correlation between the two
semantically related tasks of visual summarization and textual summarization.
We propose a new joint video and text summarization task. The goal is to
generate both a shortened video clip along with the corresponding textual
summary from a long video, collectively referred to as a cross-modal summary.
The generated shortened video clip and text narratives should be semantically
well aligned. To this end, we first build a large-scale human-annotated dataset
-- VideoXum (X refers to different modalities). The dataset is reannotated
based on ActivityNet. After we filter out the videos that do not meet the
length requirements, 14,001 long videos remain in our new dataset. Each video
in our reannotated dataset has human-annotated video summaries and the
corresponding narrative summaries. We then design a novel end-to-end model --
VTSUM-BILP to address the challenges of our proposed task. Moreover, we propose
a new metric called VT-CLIPScore to help evaluate the semantic consistency of
cross-modality summary. The proposed model achieves promising performance on
this new task and establishes a benchmark for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tracking, exploring and analyzing recent developments in German-language online press in the face of the coronavirus crisis: cOWIDplus Analysis and cOWIDplus Viewer. (arXiv:2005.13316v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.13316">
<div class="article-summary-box-inner">
<span><p>The coronavirus pandemic may be the largest crisis the world has had to face
since World War II. It does not come as a surprise that it is also having an
impact on language as our primary communication tool. We present three
inter-connected resources that are designed to capture and illustrate these
effects on a subset of the German language: An RSS corpus of German-language
newsfeeds (with freely available untruncated unigram frequency lists), a static
but continuously updated HTML page tracking the diversity of the used
vocabulary and a web application that enables other researchers and the broader
public to explore these effects without any or with little knowledge of corpus
representation/exploration or statistical analyses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing. (arXiv:2111.09543v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.09543">
<div class="article-summary-box-inner">
<span><p>This paper presents a new pre-trained language model, DeBERTaV3, which
improves the original DeBERTa model by replacing mask language modeling (MLM)
with replaced token detection (RTD), a more sample-efficient pre-training task.
Our analysis shows that vanilla embedding sharing in ELECTRA hurts training
efficiency and model performance. This is because the training losses of the
discriminator and the generator pull token embeddings in different directions,
creating the "tug-of-war" dynamics. We thus propose a new gradient-disentangled
embedding sharing method that avoids the tug-of-war dynamics, improving both
training efficiency and the quality of the pre-trained model. We have
pre-trained DeBERTaV3 using the same settings as DeBERTa to demonstrate its
exceptional performance on a wide range of downstream natural language
understanding (NLU) tasks. Taking the GLUE benchmark with eight tasks as an
example, the DeBERTaV3 Large model achieves a 91.37% average score, which is
1.37% over DeBERTa and 1.91% over ELECTRA, setting a new state-of-the-art
(SOTA) among the models with a similar structure. Furthermore, we have
pre-trained a multi-lingual model mDeBERTa and observed a larger improvement
over strong baselines compared to English models. For example, the mDeBERTa
Base achieves a 79.8% zero-shot cross-lingual accuracy on XNLI and a 3.6%
improvement over XLM-R Base, creating a new SOTA on this benchmark. We have
made our pre-trained models and inference code publicly available at
https://github.com/microsoft/DeBERTa.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-trained Token-replaced Detection Model as Few-shot Learner. (arXiv:2203.03235v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.03235">
<div class="article-summary-box-inner">
<span><p>Pre-trained masked language models have demonstrated remarkable ability as
few-shot learners. In this paper, as an alternative, we propose a novel
approach to few-shot learning with pre-trained token-replaced detection models
like ELECTRA. In this approach, we reformulate a classification or a regression
task as a token-replaced detection problem. Specifically, we first define a
template and label description words for each task and put them into the input
to form a natural language prompt. Then, we employ the pre-trained
token-replaced detection model to predict which label description word is the
most original (i.e., least replaced) among all label description words in the
prompt. A systematic evaluation on 16 datasets demonstrates that our approach
outperforms few-shot learners with pre-trained masked language models in both
one-sentence and two-sentence learning tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Token-level Contrastive Framework for Sign Language Translation. (arXiv:2204.04916v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04916">
<div class="article-summary-box-inner">
<span><p>Sign Language Translation (SLT) is a promising technology to bridge the
communication gap between the deaf and the hearing people. Recently,
researchers have adopted Neural Machine Translation (NMT) methods, which
usually require large-scale corpus for training, to achieve SLT. However, the
publicly available SLT corpus is very limited, which causes the collapse of the
token representations and the inaccuracy of the generated tokens. To alleviate
this issue, we propose ConSLT, a novel token-level \textbf{Con}trastive
learning framework for \textbf{S}ign \textbf{L}anguage \textbf{T}ranslation ,
which learns effective token representations by incorporating token-level
contrastive learning into the SLT decoding process. Concretely, ConSLT treats
each token and its counterpart generated by different dropout masks as positive
pairs during decoding, and then randomly samples $K$ tokens in the vocabulary
that are not in the current sentence to construct negative examples. We conduct
comprehensive experiments on two benchmarks (PHOENIX14T and CSL-Daily) for both
end-to-end and cascaded settings. The experimental results demonstrate that
ConSLT can achieve better translation quality than the strong baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Inclusivity, Equity, and Accessibility of NLP Technology: A Case Study for Indian Languages. (arXiv:2205.12676v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12676">
<div class="article-summary-box-inner">
<span><p>In order for NLP technology to be widely applicable, fair, and useful, it
needs to serve a diverse set of speakers across the world's languages, be
equitable, i.e., not unduly biased towards any particular language, and be
inclusive of all users, particularly in low-resource settings where compute
constraints are common. In this paper, we propose an evaluation paradigm that
assesses NLP technologies across all three dimensions. While diversity and
inclusion have received attention in recent literature, equity is currently
unexplored. We propose to address this gap using the Gini coefficient, a
well-established metric used for estimating societal wealth inequality. Using
our paradigm, we highlight the distressed state of current technologies for
Indian (IN) languages (a linguistically large and diverse set, with a varied
speaker population), across all three dimensions. To improve upon these
metrics, we demonstrate the importance of region-specific choices in model
building and dataset creation, and more importantly, propose a novel,
generalisable approach to optimal resource allocation during fine-tuning.
Finally, we discuss steps to mitigate these biases and encourage the community
to employ multi-faceted evaluation when building linguistically diverse and
equitable technologies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Maximum Linear Arrangement Problem for trees under projectivity and planarity. (arXiv:2206.06924v5 [cs.DS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.06924">
<div class="article-summary-box-inner">
<span><p>A linear arrangement is a mapping $\pi$ from the $n$ vertices of a graph $G$
to $n$ distinct consecutive integers. Linear arrangements can be represented by
drawing the vertices along a horizontal line and drawing the edges as
semicircles above said line. In this setting, the length of an edge is defined
as the absolute value of the difference between the positions of its two
vertices in the arrangement, and the cost of an arrangement as the sum of all
edge lengths. Here we study two variants of the Maximum Linear Arrangement
problem (MaxLA), which consists of finding an arrangement that maximizes the
cost. In the planar variant for free trees, vertices have to be arranged in
such a way that there are no edge crossings. In the projective variant for
rooted trees, arrangements have to be planar and the root of the tree cannot be
covered by any edge. In this paper we present algorithms that are linear in
time and space to solve planar and projective MaxLA for trees. We also prove
several properties of maximum projective and planar arrangements, and show that
caterpillar trees maximize planar MaxLA over all trees of a fixed size thereby
generalizing a previous extremal result on trees.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mitigating Covertly Unsafe Text within Natural Language Systems. (arXiv:2210.09306v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.09306">
<div class="article-summary-box-inner">
<span><p>An increasingly prevalent problem for intelligent technologies is text
safety, as uncontrolled systems may generate recommendations to their users
that lead to injury or life-threatening consequences. However, the degree of
explicitness of a generated statement that can cause physical harm varies. In
this paper, we distinguish types of text that can lead to physical harm and
establish one particularly underexplored category: covertly unsafe text. Then,
we further break down this category with respect to the system's information
and discuss solutions to mitigate the generation of text in each of these
subcategories. Ultimately, our work defines the problem of covertly unsafe
language that causes physical harm and argues that this subtle yet dangerous
issue needs to be prioritized by stakeholders and regulators. We highlight
mitigation strategies to inspire future researchers to tackle this challenging
problem and help improve safety within smart systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Collecting Interactive Multi-modal Datasets for Grounded Language Understanding. (arXiv:2211.06552v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.06552">
<div class="article-summary-box-inner">
<span><p>Human intelligence can remarkably adapt quickly to new tasks and
environments. Starting from a very young age, humans acquire new skills and
learn how to solve new tasks either by imitating the behavior of others or by
following provided natural language instructions. To facilitate research which
can enable similar capabilities in machines, we made the following
contributions (1) formalized the collaborative embodied agent using natural
language task; (2) developed a tool for extensive and scalable data collection;
and (3) collected the first dataset for interactive grounded language
understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PromptCap: Prompt-Guided Image Captioning for VQA with GPT-3. (arXiv:2211.09699v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09699">
<div class="article-summary-box-inner">
<span><p>Knowledge-based visual question answering (VQA) involves questions that
require world knowledge beyond the image to yield the correct answer. Large
language models (LMs) like GPT-3 are particularly helpful for this task because
of their strong knowledge retrieval and reasoning capabilities. To enable LM to
understand images, prior work uses a captioning model to convert images into
text. However, when summarizing an image in a single caption sentence, which
visual entities to describe are often underspecified. Generic image captions
often miss visual details essential for the LM to answer visual questions
correctly. To address this challenge, we propose PromptCap (Prompt-guided image
Captioning), a captioning model designed to serve as a better connector between
images and black-box LMs. Different from generic captions, PromptCap takes a
natural-language prompt to control the visual entities to describe in the
generated caption. The prompt contains a question that the caption should aid
in answering. To avoid extra annotation, PromptCap is trained by examples
synthesized with GPT-3 and existing datasets. We demonstrate PromptCap's
effectiveness on an existing pipeline in which GPT-3 is prompted with image
captions to carry out VQA. PromptCap outperforms generic captions by a large
margin and achieves state-of-the-art accuracy on knowledge-based VQA tasks
(60.4% on OK-VQA and 59.6% on A-OKVQA). Zero-shot results on WebQA show that
PromptCap generalizes well to unseen domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">I Can't Believe There's No Images! Learning Visual Tasks Using only Language Data. (arXiv:2211.09778v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09778">
<div class="article-summary-box-inner">
<span><p>Many high-level skills that are required for computer vision tasks, such as
parsing questions, comparing and contrasting semantics, and writing
descriptions, are also required in other domains such as natural language
processing. In this paper, we ask whether it is possible to learn those skills
from textual data and then transfer them to vision tasks without ever training
on visual training data. Key to our approach is exploiting the joint embedding
space of contrastively trained vision and language encoders. In practice, there
can be systematic differences between embedding spaces for different modalities
in contrastive models, and we analyze how these differences affect our approach
and study strategies to mitigate this concern. We produce models using only
text training data on four representative tasks: image captioning, visual
entailment, visual question answering and visual news, and evaluate them on
standard benchmarks using images. We find these models generally perform close
to models trained on images, while surpassing prior work for captioning and
visual entailment in this text only setting by over 9 points, and outperforming
all prior work on visual news by over 30 points. We also showcase a variety of
stylistic image captioning models that are trained using no image data and no
human-curated language data, but instead using readily-available text data from
books, the web, or language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counteracts: Testing Stereotypical Representation in Pre-trained Language Models. (arXiv:2301.04347v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.04347">
<div class="article-summary-box-inner">
<span><p>Language models have demonstrated strong performance on various natural
language understanding tasks. Similar to humans, language models could also
have their own bias that is learned from the training data. As more and more
downstream tasks integrate language models as part of the pipeline, it is
necessary to understand the internal stereotypical representation and the
methods to mitigate the negative effects. In this paper, we proposed a simple
method to test the internal stereotypical representation in pre-trained
language models using counterexamples. We mainly focused on gender bias, but
the method can be extended to other types of bias. We evaluated models on 9
different cloze-style prompts consisting of knowledge and base prompts. Our
results indicate that pre-trained language models show a certain amount of
robustness when using unrelated knowledge, and prefer shallow linguistic cues,
such as word position and syntactic structure, to alter the internal
stereotypical representation. Such findings shed light on how to manipulate
language models in a neutral approach for both finetuning and evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense Video Captioning. (arXiv:2302.14115v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.14115">
<div class="article-summary-box-inner">
<span><p>In this work, we introduce Vid2Seq, a multi-modal single-stage dense event
captioning model pretrained on narrated videos which are readily-available at
scale. The Vid2Seq architecture augments a language model with special time
tokens, allowing it to seamlessly predict event boundaries and textual
descriptions in the same output sequence. Such a unified model requires
large-scale training data, which is not available in current annotated
datasets. We show that it is possible to leverage unlabeled narrated videos for
dense video captioning, by reformulating sentence boundaries of transcribed
speech as pseudo event boundaries, and using the transcribed speech sentences
as pseudo event captions. The resulting Vid2Seq model pretrained on the
YT-Temporal-1B dataset improves the state of the art on a variety of dense
video captioning benchmarks including YouCook2, ViTT and ActivityNet Captions.
Vid2Seq also generalizes well to the tasks of video paragraph captioning and
video clip captioning, and to few-shot settings. Our code is publicly available
at https://antoyang.github.io/vid2seq.html.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QAID: Question Answering Inspired Few-shot Intent Detection. (arXiv:2303.01593v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01593">
<div class="article-summary-box-inner">
<span><p>Intent detection with semantically similar fine-grained intents is a
challenging task. To address it, we reformulate intent detection as a
question-answering retrieval task by treating utterances and intent names as
questions and answers. To that end, we utilize a question-answering retrieval
architecture and adopt a two stages training schema with batch contrastive
loss. In the pre-training stage, we improve query representations through
self-supervised training. Then, in the fine-tuning stage, we increase
contextualized token-level similarity scores between queries and answers from
the same intent. Our results on three few-shot intent detection benchmarks
achieve state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT Is on the Horizon: Could a Large Language Model Be All We Need for Intelligent Transportation?. (arXiv:2303.05382v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.05382">
<div class="article-summary-box-inner">
<span><p>ChatGPT, developed by OpenAI, is one of the milestone large language models
(LLMs) with 6 billion parameters. ChatGPT has demonstrated the impressive
language understanding capability of LLM, particularly in generating
conversational response. As LLMs start to gain more attention in various
research or engineering domains, it is time to envision how LLM may
revolutionize the way we approach intelligent transportation systems. This
paper explores the future applications of LLM in addressing key transportation
problems. By leveraging LLM with cross-modal encoder, an intelligent system can
also process traffic data from different modalities and execute transportation
operations through an LLM. We present and validate these potential
transportation applications equipped by LLM. To further demonstrate this
potential, we also provide a concrete smartphone-based crash report
auto-generation and analysis framework as a use case. Despite the potential
benefits, challenges related to data privacy, data quality, and model bias must
be considered. Overall, the use of LLM in intelligent transport systems holds
promise for more efficient, intelligent, and sustainable transportation systems
that further improve daily life around the world.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-Efficient Learning of Natural Language to Linear Temporal Logic Translators for Robot Task Specification. (arXiv:2303.08006v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08006">
<div class="article-summary-box-inner">
<span><p>To make robots accessible to a broad audience, it is critical to endow them
with the ability to take universal modes of communication, like commands given
in natural language, and extract a concrete desired task specification, defined
using a formal language like linear temporal logic (LTL). In this paper, we
present a learning-based approach for translating from natural language
commands to LTL specifications with very limited human-labeled training data.
This is in stark contrast to existing natural-language to LTL translators,
which require large human-labeled datasets, often in the form of labeled pairs
of LTL formulas and natural language commands, to train the translator. To
reduce reliance on human data, our approach generates a large synthetic
training dataset through algorithmic generation of LTL formulas, conversion to
structured English, and then exploiting the paraphrasing capabilities of modern
large language models (LLMs) to synthesize a diverse corpus of natural language
commands corresponding to the LTL formulas. We use this generated data to
finetune an LLM and apply a constrained decoding procedure at inference time to
ensure the returned LTL formula is syntactically correct. We evaluate our
approach on three existing LTL/natural language datasets and show that we can
translate natural language commands at 75\% accuracy with far less human data
($\le$12 annotations). Moreover, when training on large human-annotated
datasets, our method achieves higher test accuracy (95\% on average) than prior
work. Finally, we show the translated formulas can be used to plan
long-horizon, multi-stage tasks on a 12D quadrotor.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GLEN: General-Purpose Event Detection for Thousands of Types. (arXiv:2303.09093v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09093">
<div class="article-summary-box-inner">
<span><p>The development of event extraction systems has been hindered by the absence
of wide-coverage, large-scale datasets. To make event extraction systems more
accessible, we build a general-purpose event detection dataset GLEN, which
covers 3,465 different event types, making it over 20x larger in ontology than
any current dataset. GLEN is created by utilizing the DWD Overlay, which
provides a mapping between Wikidata Qnodes and PropBank rolesets. This enables
us to use the abundant existing annotation for PropBank as distant supervision.
In addition, we also propose a new multi-stage event detection model
specifically designed to handle the large ontology size and partial labels in
GLEN. We show that our model exhibits superior performance (~10% F1 gain)
compared to both conventional classification baselines and newer
definition-based models. Finally, we perform error analysis and show that label
noise is still the largest challenge for improving performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning. (arXiv:2303.10475v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10475">
<div class="article-summary-box-inner">
<span><p>Task semantics can be expressed by a set of input-to-output examples or a
piece of textual instruction. Conventional machine learning approaches for
natural language processing (NLP) mainly rely on the availability of
large-scale sets of task-specific examples. Two issues arise: first, collecting
task-specific labeled examples does not apply to scenarios where tasks may be
too complicated or costly to annotate, or the system is required to handle a
new task immediately; second, this is not user-friendly since end-users are
probably more willing to provide task description rather than a set of examples
before using the system. Therefore, the community is paying increasing interest
in a new supervision-seeking paradigm for NLP: learning from task instructions.
Despite its impressive progress, there are some common issues that the
community struggles with. This survey paper tries to summarize the current
research on instruction learning, particularly, by answering the following
questions: (i) what is task instruction, and what instruction types exist? (ii)
how to model instructions? (iii) what factors influence and explain the
instructions' performance? (iv) what challenges remain in instruction learning?
To our knowledge, this is the first comprehensive survey about textual
instructions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DocRED-FE: A Document-Level Fine-Grained Entity And Relation Extraction Dataset. (arXiv:2303.11141v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11141">
<div class="article-summary-box-inner">
<span><p>Joint entity and relation extraction (JERE) is one of the most important
tasks in information extraction. However, most existing works focus on
sentence-level coarse-grained JERE, which have limitations in real-world
scenarios. In this paper, we construct a large-scale document-level
fine-grained JERE dataset DocRED-FE, which improves DocRED with Fine-Grained
Entity Type. Specifically, we redesign a hierarchical entity type schema
including 11 coarse-grained types and 119 fine-grained types, and then
re-annotate DocRED manually according to this schema. Through comprehensive
experiments we find that: (1) DocRED-FE is challenging to existing JERE models;
(2) Our fine-grained entity types promote relation classification. We make
DocRED-FE with instruction and the code for our baselines publicly available at
https://github.com/PKU-TANGENT/DOCRED-FE.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-03-22 23:09:57.757055060 UTC">2023-03-22 23:09:57 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>