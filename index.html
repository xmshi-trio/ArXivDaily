<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-05-15T01:30:00Z">05-15</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Quran Recitation Recognition using End-to-End Deep Learning. (arXiv:2305.07034v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07034">
<div class="article-summary-box-inner">
<span><p>The Quran is the holy scripture of Islam, and its recitation is an important
aspect of the religion. Recognizing the recitation of the Holy Quran
automatically is a challenging task due to its unique rules that are not
applied in normal speaking speeches. A lot of research has been done in this
domain, but previous works have detected recitation errors as a classification
task or used traditional automatic speech recognition (ASR). In this paper, we
proposed a novel end-to-end deep learning model for recognizing the recitation
of the Holy Quran. The proposed model is a CNN-Bidirectional GRU encoder that
uses CTC as an objective function, and a character-based decoder which is a
beam search decoder. Moreover, all previous works were done on small private
datasets consisting of short verses and a few chapters of the Holy Quran. As a
result of using private datasets, no comparisons were done. To overcome this
issue, we used a public dataset that has recently been published (Ar-DAD) and
contains about 37 chapters that were recited by 30 reciters, with different
recitation speeds and different types of pronunciation rules. The proposed
model performance was evaluated using the most common evaluation metrics in
speech recognition, word error rate (WER), and character error rate (CER). The
results were 8.34% WER and 2.42% CER. We hope this research will be a baseline
for comparisons with future research on this public new dataset (Ar-DAD).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Contrastive Learning with Noise-Guided Attack: Towards Continual Relation Extraction in the Wild. (arXiv:2305.07085v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07085">
<div class="article-summary-box-inner">
<span><p>The principle of continual relation extraction~(CRE) involves adapting to
emerging novel relations while preserving od knowledge. While current endeavors
in CRE succeed in preserving old knowledge, they tend to fail when exposed to
contaminated data streams. We assume this is attributed to their reliance on an
artificial hypothesis that the data stream has no annotation errors, which
hinders real-world applications for CRE. Considering the ubiquity of noisy
labels in real-world datasets, in this paper, we formalize a more practical
learning scenario, termed as \textit{noisy-CRE}. Building upon this challenging
setting, we develop a noise-resistant contrastive framework named as
\textbf{N}oise-guided \textbf{a}ttack in \textbf{C}ontrative
\textbf{L}earning~(NaCL) to learn incremental corrupted relations. Compared to
direct noise discarding or inaccessible noise relabeling, we present modifying
the feature space to match the given noisy labels via attacking can better
enrich contrastive representations. Extensive empirical validations highlight
that NaCL can achieve consistent performance improvements with increasing noise
rates, outperforming state-of-the-art baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are Machine Rationales (Not) Useful to Humans? Measuring and Improving Human Utility of Free-Text Rationales. (arXiv:2305.07095v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07095">
<div class="article-summary-box-inner">
<span><p>Among the remarkable emergent capabilities of large language models (LMs) is
free-text rationalization; beyond a certain scale, large LMs are capable of
generating seemingly useful rationalizations, which in turn, can dramatically
enhance their performances on leaderboards. This phenomenon raises a question:
can machine generated rationales also be useful for humans, especially when lay
humans try to answer questions based on those machine rationales? We observe
that human utility of existing rationales is far from satisfactory, and
expensive to estimate with human studies. Existing metrics like task
performance of the LM generating the rationales, or similarity between
generated and gold rationales are not good indicators of their human utility.
While we observe that certain properties of rationales like conciseness and
novelty are correlated with their human utility, estimating them without human
involvement is challenging. We show that, by estimating a rationale's
helpfulness in answering similar unseen instances, we can measure its human
utility to a better extent. We also translate this finding into an automated
score, GEN-U, that we propose, which can help improve LMs' ability to generate
rationales with better human utility, while maintaining most of its task
performance. Lastly, we release all code and collected data with this project.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Overinformative Question Answering by Humans and Machines. (arXiv:2305.07151v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07151">
<div class="article-summary-box-inner">
<span><p>When faced with a polar question, speakers often provide overinformative
answers going beyond a simple "yes" or "no". But what principles guide the
selection of additional information? In this paper, we provide experimental
evidence from two studies suggesting that overinformativeness in human
answering is driven by considerations of relevance to the questioner's goals
which they flexibly adjust given the functional context in which the question
is uttered. We take these human results as a strong benchmark for investigating
question-answering performance in state-of-the-art neural language models,
conducting an extensive evaluation on items from human experiments. We find
that most models fail to adjust their answering behavior in a human-like way
and tend to include irrelevant information. We show that GPT-3 is highly
sensitive to the form of the prompt and only achieves human-like answer
patterns when guided by an example and cognitively-motivated explanation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Zero and Few-shot Techniques for Intent Classification. (arXiv:2305.07157v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07157">
<div class="article-summary-box-inner">
<span><p>Conversational NLU providers often need to scale to thousands of
intent-classification models where new customers often face the cold-start
problem. Scaling to so many customers puts a constraint on storage space as
well. In this paper, we explore four different zero and few-shot intent
classification approaches with this low-resource constraint: 1) domain
adaptation, 2) data augmentation, 3) zero-shot intent classification using
descriptions large language models (LLMs), and 4) parameter-efficient
fine-tuning of instruction-finetuned language models. Our results show that all
these approaches are effective to different degrees in low-resource settings.
Parameter-efficient fine-tuning using T-few recipe (Liu et al., 2022) on
Flan-T5 (Chang et al., 2022) yields the best performance even with just one
sample per intent. We also show that the zero-shot method of prompting LLMs
using intent descriptions
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OneCAD: One Classifier for All image Datasets using multimodal learning. (arXiv:2305.07167v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07167">
<div class="article-summary-box-inner">
<span><p>Vision-Transformers (ViTs) and Convolutional neural networks (CNNs) are
widely used Deep Neural Networks (DNNs) for classification task. These model
architectures are dependent on the number of classes in the dataset it was
trained on. Any change in number of classes leads to change (partial or full)
in the model's architecture. This work addresses the question: Is it possible
to create a number-of-class-agnostic model architecture?. This allows model's
architecture to be independent of the dataset it is trained on. This work
highlights the issues with the current architectures (ViTs and CNNs). Also,
proposes a training and inference framework OneCAD (One Classifier for All
image Datasets) to achieve close-to number-of-class-agnostic transformer model.
To best of our knowledge this is the first work to use Mask-Image-Modeling
(MIM) with multimodal learning for classification task to create a DNN model
architecture agnostic to the number of classes. Preliminary results are shown
on natural and medical image datasets. Datasets: MNIST, CIFAR10, CIFAR100 and
COVIDx. Code will soon be publicly available on github.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Asymmetric feature interaction for interpreting model predictions. (arXiv:2305.07224v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07224">
<div class="article-summary-box-inner">
<span><p>In natural language processing (NLP), deep neural networks (DNNs) could model
complex interactions between context and have achieved impressive results on a
range of NLP tasks. Prior works on feature interaction attribution mainly focus
on studying symmetric interaction that only explains the additional influence
of a set of words in combination, which fails to capture asymmetric influence
that contributes to model prediction. In this work, we propose an asymmetric
feature interaction attribution explanation model that aims to explore
asymmetric higher-order feature interactions in the inference of deep neural
NLP models. By representing our explanation with an directed interaction graph,
we experimentally demonstrate interpretability of the graph to discover
asymmetric feature interactions. Experimental results on two sentiment
classification datasets show the superiority of our model against the
state-of-the-art feature interaction attribution methods in identifying
influential features for model predictions. Our code is available at
https://github.com/StillLu/ASIV.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Giant Language Brains Just Aren't Enough! Domain Pizzazz with Knowledge Sparkle Dust. (arXiv:2305.07230v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07230">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have significantly advanced the field of natural
language processing, with GPT models at the forefront. While their remarkable
performance spans a range of tasks, adapting LLMs for real-world business
scenarios still poses challenges warranting further investigation. This paper
presents an empirical analysis aimed at bridging the gap in adapting LLMs to
practical use cases. To do that, we select the question answering (QA) task of
insurance as a case study due to its challenge of reasoning. Based on the task
we design a new model relied on LLMs which are empowered by domain-specific
knowledge extracted from insurance policy rulebooks. The domain-specific
knowledge helps LLMs to understand new concepts of insurance for domain
adaptation. Preliminary results on real QA pairs show that knowledge
enhancement from policy rulebooks significantly improves the reasoning ability
of GPT-3.5 of 50.4% in terms of accuracy. The analysis also indicates that
existing public knowledge bases, e.g., DBPedia is beneficial for knowledge
enhancement. Our findings reveal that the inherent complexity of business
scenarios often necessitates the incorporation of domain-specific knowledge and
external resources for effective problem-solving.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Better speech synthesis through scaling. (arXiv:2305.07243v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07243">
<div class="article-summary-box-inner">
<span><p>In recent years, the field of image generation has been revolutionized by the
application of autoregressive transformers and DDPMs. These approaches model
the process of image generation as a step-wise probabilistic processes and
leverage large amounts of compute and data to learn the image distribution.
This methodology of improving performance need not be confined to images. This
paper describes a way to apply advances in the image generative domain to
speech synthesis. The result is TorToise -- an expressive, multi-voice
text-to-speech system.
</p>
<p>All model code and trained weights have been open-sourced at
https://github.com/neonbjb/tortoise-tts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gaussian Prior Reinforcement Learning for Nested Named Entity Recognition. (arXiv:2305.07266v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07266">
<div class="article-summary-box-inner">
<span><p>Named Entity Recognition (NER) is a well and widely studied task in natural
language processing. Recently, the nested NER has attracted more attention
since its practicality and difficulty. Existing works for nested NER ignore the
recognition order and boundary position relation of nested entities. To address
these issues, we propose a novel seq2seq model named GPRL, which formulates the
nested NER task as an entity triplet sequence generation process. GPRL adopts
the reinforcement learning method to generate entity triplets decoupling the
entity order in gold labels and expects to learn a reasonable recognition order
of entities via trial and error. Based on statistics of boundary distance for
nested entities, GPRL designs a Gaussian prior to represent the boundary
distance distribution between nested entities and adjust the output probability
distribution of nested boundary tokens. Experiments on three nested NER
datasets demonstrate that GPRL outperforms previous nested NER models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Harvesting Event Schemas from Large Language Models. (arXiv:2305.07280v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07280">
<div class="article-summary-box-inner">
<span><p>Event schema provides a conceptual, structural and formal language to
represent events and model the world event knowledge. Unfortunately, it is
challenging to automatically induce high-quality and high-coverage event
schemas due to the open nature of real-world events, the diversity of event
expressions, and the sparsity of event knowledge. In this paper, we propose a
new paradigm for event schema induction -- knowledge harvesting from
large-scale pre-trained language models, which can effectively resolve the
above challenges by discovering, conceptualizing and structuralizing event
schemas from PLMs. And an Event Schema Harvester (ESHer) is designed to
automatically induce high-quality event schemas via in-context generation-based
conceptualization, confidence-aware schema structuralization and graph-based
schema aggregation. Empirical results show that ESHer can induce high-quality
and high-coverage event schemas on varying domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open-WikiTable: Dataset for Open Domain Question Answering with Complex Reasoning over Table. (arXiv:2305.07288v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07288">
<div class="article-summary-box-inner">
<span><p>Despite recent interest in open domain question answering (ODQA) over tables,
many studies still rely on datasets that are not truly optimal for the task
with respect to utilizing structural nature of table. These datasets assume
answers reside as a single cell value and do not necessitate exploring over
multiple cells such as aggregation, comparison, and sorting. Thus, we release
Open-WikiTable, the first ODQA dataset that requires complex reasoning over
tables. Open-WikiTable is built upon WikiSQL and WikiTableQuestions to be
applicable in the open-domain setting. As each question is coupled with both
textual answers and SQL queries, Open-WikiTable opens up a wide range of
possibilities for future research, as both reader and parser methods can be
applied. The dataset and code are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RepCL: Exploring Effective Representation for Continual Text Classification. (arXiv:2305.07289v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07289">
<div class="article-summary-box-inner">
<span><p>Continual learning (CL) aims to constantly learn new knowledge over time
while avoiding catastrophic forgetting on old tasks. In this work, we focus on
continual text classification under the class-incremental setting. Recent CL
studies find that the representations learned in one task may not be effective
for other tasks, namely representation bias problem. For the first time we
formally analyze representation bias from an information bottleneck perspective
and suggest that exploiting representations with more class-relevant
information could alleviate the bias. To this end, we propose a novel
replay-based continual text classification method, RepCL. Our approach utilizes
contrastive and generative representation learning objectives to capture more
class-relevant features. In addition, RepCL introduces an adversarial replay
strategy to alleviate the overfitting problem of replay. Experiments
demonstrate that RepCL effectively alleviates forgetting and achieves
state-of-the-art performance on three text classification tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Relational Hyperbolic Word Embeddings from Natural Language Definitions. (arXiv:2305.07303v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07303">
<div class="article-summary-box-inner">
<span><p>Neural-based word embeddings using solely distributional information have
consistently produced useful meaning representations for downstream tasks.
However, existing approaches often result in representations that are hard to
interpret and control. Natural language definitions, on the other side, possess
a recursive, self-explanatory semantic structure that can support novel
representation learning paradigms able to preserve explicit conceptual
relations and constraints in the vector space.
</p>
<p>This paper proposes a neuro-symbolic, multi-relational framework to learn
word embeddings exclusively from natural language definitions by jointly
mapping defined and defining terms along with their corresponding semantic
relations. By automatically extracting the relations from definitions corpora
and formalising the learning problem via a translational objective, we
specialise the framework in hyperbolic space to capture the hierarchical and
multi-resolution structure induced by the definitions. An extensive empirical
analysis demonstrates that the framework can help impose the desired structural
constraints while preserving the mapping required for controllable and
interpretable semantic navigation. Moreover, the experiments reveal the
superiority of the hyperbolic word embeddings over the euclidean counterparts
and demonstrate that the multi-relational framework can obtain competitive
results when compared to state-of-the-art neural approaches (including
Transformers), with the advantage of being significantly more efficient and
intrinsically interpretable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Zero-shot Multilingual Neural Machine Translation by Leveraging Cross-lingual Consistency Regularization. (arXiv:2305.07310v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07310">
<div class="article-summary-box-inner">
<span><p>The multilingual neural machine translation (NMT) model has a promising
capability of zero-shot translation, where it could directly translate between
language pairs unseen during training. For good transfer performance from
supervised directions to zero-shot directions, the multilingual NMT model is
expected to learn universal representations across different languages. This
paper introduces a cross-lingual consistency regularization, CrossConST, to
bridge the representation gap among different languages and boost zero-shot
translation performance. The theoretical analysis shows that CrossConST
implicitly maximizes the probability distribution for zero-shot translation,
and the experimental results on both low-resource and high-resource benchmarks
show that CrossConST consistently improves the translation performance. The
experimental analysis also proves that CrossConST could close the sentence
representation gap and better align the representation space. Given the
universality and simplicity of CrossConST, we believe it can serve as a strong
baseline for future multilingual NMT research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MedGPTEval: A Dataset and Benchmark to Evaluate Responses of Large Language Models in Medicine. (arXiv:2305.07340v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07340">
<div class="article-summary-box-inner">
<span><p>METHODS: First, a set of evaluation criteria is designed based on a
comprehensive literature review. Second, existing candidate criteria are
optimized for using a Delphi method by five experts in medicine and
engineering. Third, three clinical experts design a set of medical datasets to
interact with LLMs. Finally, benchmarking experiments are conducted on the
datasets. The responses generated by chatbots based on LLMs are recorded for
blind evaluations by five licensed medical experts. RESULTS: The obtained
evaluation criteria cover medical professional capabilities, social
comprehensive capabilities, contextual capabilities, and computational
robustness, with sixteen detailed indicators. The medical datasets include
twenty-seven medical dialogues and seven case reports in Chinese. Three
chatbots are evaluated, ChatGPT by OpenAI, ERNIE Bot by Baidu Inc., and Doctor
PuJiang (Dr. PJ) by Shanghai Artificial Intelligence Laboratory. Experimental
results show that Dr. PJ outperforms ChatGPT and ERNIE Bot in both
multiple-turn medical dialogue and case report scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Model-based Programming: Redefining the Atomic Unit of Programming for the Deep Learning Era. (arXiv:2305.07341v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07341">
<div class="article-summary-box-inner">
<span><p>This paper introduces and explores a new programming paradigm, Model-based
Programming, designed to address the challenges inherent in applying deep
learning models to real-world applications. Despite recent significant
successes of deep learning models across a range of tasks, their deployment in
real business scenarios remains fraught with difficulties, such as complex
model training, large computational resource requirements, and integration
issues with existing programming languages. To ameliorate these challenges, we
propose the concept of 'Model-based Programming' and present a novel
programming language - M Language, tailored to a prospective model-centered
programming paradigm. M Language treats models as basic computational units,
enabling developers to concentrate more on crucial tasks such as model loading,
fine-tuning, evaluation, and deployment, thereby enhancing the efficiency of
creating deep learning applications. We posit that this innovative programming
paradigm will stimulate the extensive application and advancement of deep
learning technology and provide a robust foundation for a model-driven future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ZARA: Improving Few-Shot Self-Rationalization for Small Language Models. (arXiv:2305.07355v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07355">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) that jointly generate end-task answers as well as
free-text rationales are known as self-rationalization models. Recent works
demonstrate great performance gain for self-rationalization by few-shot
prompting LMs with rationale-augmented exemplars. However, the ability to
benefit from explanations only emerges with large-scale LMs, which have poor
accessibility. In this work, we explore the less-studied setting of leveraging
explanations for small LMs to improve few-shot self-rationalization. We first
revisit the relationship between rationales and answers. Inspired by the
implicit mental process of how human beings assess explanations, we present a
novel approach, Zero-shot Augmentation of Rationale-Answer pairs (ZARA), to
automatically construct pseudo-parallel data for self-training by reducing the
problem of plausibility judgement to natural language inference. Experimental
results show ZARA achieves SOTA performance on the FEB benchmark, for both the
task accuracy and the explanation metric. In addition, we conduct human and
quantitative evaluation validating ZARA's ability to automatically identify
plausible and accurate rationale-answer pairs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Versatile and Efficient Visual Knowledge Injection into Pre-trained Language Models with Cross-Modal Adapters. (arXiv:2305.07358v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07358">
<div class="article-summary-box-inner">
<span><p>Humans learn language via multi-modal knowledge. However, due to the
text-only pre-training scheme, most existing pre-trained language models (PLMs)
are hindered from the multi-modal information.
</p>
<p>To inject visual knowledge into PLMs, existing methods incorporate either the
text or image encoder of vision-language models (VLMs) to encode the visual
information and update all the original parameters of PLMs for knowledge
fusion.
</p>
<p>In this paper, we propose a new plug-and-play module, X-adapter, to flexibly
leverage the aligned visual and textual knowledge learned in pre-trained VLMs
and efficiently inject them into PLMs.
</p>
<p>Specifically, we insert X-adapters into PLMs, and only the added parameters
are updated during adaptation.
</p>
<p>To fully exploit the potential in VLMs, X-adapters consist of two
sub-modules, V-expert and T-expert, to fuse VLMs' image and text
representations, respectively.
</p>
<p>We can opt for activating different sub-modules depending on the downstream
tasks.
</p>
<p>Experimental results show that our method can significantly improve the
performance on object-color reasoning and natural language understanding (NLU)
tasks compared with PLM baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving the Quality of Neural Machine Translation Through Proper Translation of Name Entities. (arXiv:2305.07360v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07360">
<div class="article-summary-box-inner">
<span><p>In this paper, we have shown a method of improving the quality of neural
machine translation by translating/transliterating name entities as a
preprocessing step. Through experiments we have shown the performance gain of
our system. For evaluation we considered three types of name entities viz
person names, location names and organization names. The system was able to
correctly translate mostly all the name entities. For person names the accuracy
was 99.86%, for location names the accuracy was 99.63% and for organization
names the accuracy was 99.05%. Overall, the accuracy of the system was 99.52%
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Transliteration between Sindhi Scripts from Devanagari to Perso-Arabic. (arXiv:2305.07365v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07365">
<div class="article-summary-box-inner">
<span><p>In this paper, we have shown a script conversion (transliteration) technique
that converts Sindhi text in the Devanagari script to the Perso-Arabic script.
We showed this by incorporating a hybrid approach where some part of the text
is converted using a rule base and in case an ambiguity arises then a
probabilistic model is used to resolve the same. Using this approach, the
system achieved an overall accuracy of 99.64%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interactive Text-to-SQL Generation via Editable Step-by-Step Explanations. (arXiv:2305.07372v1 [cs.DB])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07372">
<div class="article-summary-box-inner">
<span><p>Relational databases play an important role in this Big Data era. However, it
is challenging for non-experts to fully unleash the analytical power of
relational databases, since they are not familiar with database languages such
as SQL. Many techniques have been proposed to automatically generate SQL from
natural language, but they suffer from two issues: (1) they still make many
mistakes, particularly for complex queries, and (2) they do not provide a
flexible way for non-expert users to validate and refine the incorrect queries.
To address these issues, we introduce a new interaction mechanism that allows
users directly edit a step-by-step explanation of an incorrect SQL to fix SQL
errors. Experiments on the Spider benchmark show that our approach outperforms
three SOTA approaches by at least 31.6% in terms of execution accuracy. A user
study with 24 participants further shows that our approach helped users solve
significantly more SQL tasks with less time and higher confidence,
demonstrating its potential to expand access to databases, particularly for
non-experts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Implications of Deep Circuits in Improving Quality of Quantum Question Answering. (arXiv:2305.07374v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07374">
<div class="article-summary-box-inner">
<span><p>Question Answering (QA) has proved to be an arduous challenge in the area of
natural language processing (NLP) and artificial intelligence (AI). Many
attempts have been made to develop complete solutions for QA as well as
improving significant sub-modules of the QA systems to improve the overall
performance through the course of time. Questions are the most important piece
of QA, because knowing the question is equivalent to knowing what counts as an
answer (Harrah in Philos Sci, 1961 [1]). In this work, we have attempted to
understand questions in a better way by using Quantum Machine Learning (QML).
The properties of Quantum Computing (QC) have enabled classically intractable
data processing. So, in this paper, we have performed question classification
on questions from two classes of SelQA (Selection-based Question Answering)
dataset using quantum-based classifier algorithms-quantum support vector
machine (QSVM) and variational quantum classifier (VQC) from Qiskit (Quantum
Information Science toolKIT) for Python. We perform classification with both
classifiers in almost similar environments and study the effects of circuit
depths while comparing the results of both classifiers. We also use these
classification results with our own rule-based QA system and observe
significant performance improvement. Hence, this experiment has helped in
improving the quality of QA in general.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation. (arXiv:2305.07375v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07375">
<div class="article-summary-box-inner">
<span><p>Causal reasoning ability is crucial for numerous NLP applications. Despite
the impressive emerging ability of ChatGPT in various NLP tasks, it is unclear
how well ChatGPT performs in causal reasoning. In this paper, we conduct the
first comprehensive evaluation of the ChatGPT's causal reasoning capabilities.
Experiments show that ChatGPT is not a good causal reasoner, but a good causal
interpreter. Besides, ChatGPT has a serious hallucination on causal reasoning,
possibly due to the reporting biases between causal and non-causal
relationships in natural language, as well as ChatGPT's upgrading processes,
such as RLHF. The In-Context Learning (ICL) and Chain-of-Though (COT)
techniques can further exacerbate such causal hallucination. Additionally, the
causal reasoning ability of ChatGPT is sensitive to the words used to express
the causal concept in prompts, and close-ended prompts perform better than
open-ended prompts. For events in sentences, ChatGPT excels at capturing
explicit causality rather than implicit causality, and performs better in
sentences with lower event density and smaller lexical distance between events.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Surfacing Biases in Large Language Models using Contrastive Input Decoding. (arXiv:2305.07378v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07378">
<div class="article-summary-box-inner">
<span><p>Ensuring that large language models (LMs) are fair, robust and useful
requires an understanding of how different modifications to their inputs impact
the model's behaviour. In the context of open-text generation tasks, however,
such an evaluation is not trivial. For example, when introducing a model with
an input text and a perturbed, "contrastive" version of it, meaningful
differences in the next-token predictions may not be revealed with standard
decoding strategies. With this motivation in mind, we propose Contrastive Input
Decoding (CID): a decoding algorithm to generate text given two inputs, where
the generated text is likely given one input but unlikely given the other. In
this way, the contrastive generations can highlight potentially subtle
differences in how the LM output differs for the two inputs in a simple and
interpretable manner. We use CID to highlight context-specific biases that are
hard to detect with standard decoding strategies and quantify the effect of
different input perturbations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating the Sensitivity of Automatic Speech Recognition Systems to Phonetic Variation in L2 Englishes. (arXiv:2305.07389v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07389">
<div class="article-summary-box-inner">
<span><p>Automatic Speech Recognition (ASR) systems exhibit the best performance on
speech that is similar to that on which it was trained. As such,
underrepresented varieties including regional dialects, minority-speakers, and
low-resource languages, see much higher word error rates (WERs) than those
varieties seen as 'prestigious', 'mainstream', or 'standard'. This can act as a
barrier to incorporating ASR technology into the annotation process for
large-scale linguistic research since the manual correction of the erroneous
automated transcripts can be just as time and resource consuming as manual
transcriptions. A deeper understanding of the behaviour of an ASR system is
thus beneficial from a speech technology standpoint, in terms of improving ASR
accuracy, and from an annotation standpoint, where knowing the likely errors
made by an ASR system can aid in this manual correction. This work demonstrates
a method of probing an ASR system to discover how it handles phonetic variation
across a number of L2 Englishes. Specifically, how particular phonetic
realisations which were rare or absent in the system's training data can lead
to phoneme level misrecognitions and contribute to higher WERs. It is
demonstrated that the behaviour of the ASR is systematic and consistent across
speakers with similar spoken varieties (in this case the same L1) and phoneme
substitution errors are typically in agreement with human annotators. By
identifying problematic productions specific weaknesses can be addressed by
sourcing such realisations for training and fine-tuning thus making the system
more robust to pronunciation variation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompt Learning to Mitigate Catastrophic Forgetting in Cross-lingual Transfer for Open-domain Dialogue Generation. (arXiv:2305.07393v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07393">
<div class="article-summary-box-inner">
<span><p>Dialogue systems for non-English languages have long been under-explored. In
this paper, we take the first step to investigate few-shot cross-lingual
transfer learning (FS-XLT) and multitask learning (MTL) in the context of
open-domain dialogue generation for non-English languages with limited data. We
observed catastrophic forgetting in both FS-XLT and MTL for all 6 languages in
our preliminary experiments. To mitigate the issue, we propose a simple yet
effective prompt learning approach that can preserve the multilinguality of
multilingual pre-trained language model (mPLM) in FS-XLT and MTL by bridging
the gap between pre-training and fine-tuning with Fixed-prompt LM Tuning and
our hand-crafted prompts. Experimental results on all 6 languages in terms of
both automatic and human evaluations demonstrate the effectiveness of our
approach. Our code is available at https://github.com/JeremyLeiLiu/XLinguDial.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Refinement via Interaction Between Search Engines and Large Language Models. (arXiv:2305.07402v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07402">
<div class="article-summary-box-inner">
<span><p>Information retrieval (IR) plays a crucial role in locating relevant
resources from vast amounts of data, and its applications have evolved from
traditional knowledge bases to modern search engines (SEs). The emergence of
large language models (LLMs) has further revolutionized the field by enabling
users to interact with search systems in natural language. In this paper, we
explore the advantages and disadvantages of LLMs and SEs, highlighting their
respective strengths in understanding user-issued queries and retrieving
up-to-date information. To leverage the benefits of both paradigms while
circumventing their limitations, we propose InteR, a novel framework that
facilitates knowledge refinement through interaction between SEs and LLMs.
InteR allows SEs to refine knowledge in query using LLM-generated summaries and
enables LLMs to enhance prompts using SE-retrieved documents. This iterative
refinement process augments the inputs of SEs and LLMs, leading to more
accurate retrieval. Experimental evaluations on two large-scale retrieval
benchmarks demonstrate that InteR achieves superior zero-shot document
retrieval performance compared to state-of-the-art methods, regardless of the
use of relevance judgement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Two-in-One: A Model Hijacking Attack Against Text Generation Models. (arXiv:2305.07406v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07406">
<div class="article-summary-box-inner">
<span><p>Machine learning has progressed significantly in various applications ranging
from face recognition to text generation. However, its success has been
accompanied by different attacks. Recently a new attack has been proposed which
raises both accountability and parasitic computing risks, namely the model
hijacking attack. Nevertheless, this attack has only focused on image
classification tasks. In this work, we broaden the scope of this attack to
include text generation and classification models, hence showing its broader
applicability. More concretely, we propose a new model hijacking attack, Ditto,
that can hijack different text classification tasks into multiple generation
ones, e.g., language translation, text summarization, and language modeling. We
use a range of text benchmark datasets such as SST-2, TweetEval, AGnews, QNLI,
and IMDB to evaluate the performance of our attacks. Our results show that by
using Ditto, an adversary can successfully hijack text generation models
without jeopardizing their utility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Instance Smoothed Contrastive Learning for Unsupervised Sentence Embedding. (arXiv:2305.07424v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07424">
<div class="article-summary-box-inner">
<span><p>Contrastive learning-based methods, such as unsup-SimCSE, have achieved
state-of-the-art (SOTA) performances in learning unsupervised sentence
embeddings. However, in previous studies, each embedding used for contrastive
learning only derived from one sentence instance, and we call these embeddings
instance-level embeddings. In other words, each embedding is regarded as a
unique class of its own, whichmay hurt the generalization performance. In this
study, we propose IS-CSE (instance smoothing contrastive sentence embedding) to
smooth the boundaries of embeddings in the feature space. Specifically, we
retrieve embeddings from a dynamic memory buffer according to the semantic
similarity to get a positive embedding group. Then embeddings in the group are
aggregated by a self-attention operation to produce a smoothed instance
embedding for further analysis. We evaluate our method on standard semantic
text similarity (STS) tasks and achieve an average of 78.30%, 79.47%, 77.73%,
and 79.42% Spearman's correlation on the base of BERT-base, BERT-large,
RoBERTa-base, and RoBERTa-large respectively, a 2.05%, 1.06%, 1.16% and 0.52%
improvement compared to unsup-SimCSE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QVoice: Arabic Speech Pronunciation Learning Application. (arXiv:2305.07445v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07445">
<div class="article-summary-box-inner">
<span><p>This paper introduces a novel Arabic pronunciation learning application
QVoice, powered with end-to-end mispronunciation detection and feedback
generator module. The application is designed to support non-native Arabic
speakers in enhancing their pronunciation skills, while also helping native
speakers mitigate any potential influence from regional dialects on their
Modern Standard Arabic (MSA) pronunciation. QVoice employs various learning
cues to aid learners in comprehending meaning, drawing connections with their
existing knowledge of English language, and offers detailed feedback for
pronunciation correction, along with contextual examples showcasing word usage.
The learning cues featured in QVoice encompass a wide range of meaningful
information, such as visualizations of phrases/words and their translations, as
well as phonetic transcriptions and transliterations. QVoice provides
pronunciation feedback at the character level and assesses performance at the
word level.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation. (arXiv:2305.07455v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07455">
<div class="article-summary-box-inner">
<span><p>Most of the speech translation models heavily rely on parallel data, which is
hard to collect especially for low-resource languages. To tackle this issue, we
propose to build a cascaded speech translation system without leveraging any
kind of paired data. We use fully unpaired data to train our unsupervised
systems and evaluate our results on CoVoST 2 and CVSS. The results show that
our work is comparable with some other early supervised methods in some
language pairs. While cascaded systems always suffer from severe error
propagation problems, we proposed denoising back-translation (DBT), a novel
approach to building robust unsupervised neural machine translation (UNMT). DBT
successfully increases the BLEU score by 0.7--0.9 in all three translation
directions. Moreover, we simplified the pipeline of our cascaded system to
reduce inference latency and conducted a comprehensive analysis of every part
of our work. We also demonstrate our unsupervised speech translation results on
the established website.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Perturbation-based QE: An Explainable, Unsupervised Word-level Quality Estimation Method for Blackbox Machine Translation. (arXiv:2305.07457v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07457">
<div class="article-summary-box-inner">
<span><p>Quality Estimation (QE) is the task of predicting the quality of Machine
Translation (MT) system output, without using any gold-standard translation
references. State-of-the-art QE models are supervised: they require
human-labeled quality of some MT system output on some datasets for training,
making them domain-dependent and MT-system-dependent. There has been research
on unsupervised QE, which requires glass-box access to the MT systems, or
parallel MT data to generate synthetic errors for training QE models. In this
paper, we present Perturbation-based QE - a word-level Quality Estimation
approach that works simply by analyzing MT system output on perturbed input
source sentences. Our approach is unsupervised, explainable, and can evaluate
any type of blackbox MT systems, including the currently prominent large
language models (LLMs) with opaque internal processes. For language directions
with no labeled QE data, our approach has similar or better performance than
the zero-shot supervised approach on the WMT21 shared task. Our approach is
better at detecting gender bias and word-sense-disambiguation errors in
translation than supervised QE, indicating its robustness to out-of-domain
usage. The performance gap is larger when detecting errors on a nontraditional
translation-prompting LLM, indicating that our approach is more generalizable
to different MT systems. We give examples demonstrating our approach's
explainability power, where it shows which input source words have influence on
a certain MT output word.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BactInt: A domain driven transfer learning approach and a corpus for extracting inter-bacterial interactions from biomedical text. (arXiv:2305.07468v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07468">
<div class="article-summary-box-inner">
<span><p>The community of different types of microbes present in a biological niche
plays a very important role in functioning of the system. The crosstalk or
interactions among the different microbes contributes to the building blocks of
such microbial community structures. Evidence reported in biomedical text
serves as a reliable source for predicting such interactions. However, going
through the vast and ever-increasing volume of biomedical literature is an
intimidating and time consuming process. This necessitates development of
automated methods capable of accurately extracting bacterial relations reported
in biomedical literature. In this paper, we introduce a method for automated
extraction of microbial interactions (specifically between bacteria) from
biomedical literature along with ways of using transfer learning to improve its
accuracy. We also describe a pipeline using which relations among specific
bacteria groups can be mined. Additionally, we introduce the first publicly
available dataset which can be used to develop bacterial interaction extraction
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comprehensive Solution Program Centric Pretraining for Table-and-Text Hybrid Numerical Reasoning. (arXiv:2305.07475v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07475">
<div class="article-summary-box-inner">
<span><p>Numerical reasoning over table-and-text hybrid passages, such as financial
reports, poses significant challenges and has numerous potential applications.
Noise and irrelevant variables in the model input have been a hindrance to its
performance. Additionally, coarse-grained supervision of the whole solution
program has impeded the model's ability to learn the underlying numerical
reasoning process. In this paper, we propose three pretraining tasks that
operate at both the whole program and sub-program level: Variable Integrity
Ranking, which guides the model to focus on useful variables; Variable Operator
Prediction, which decomposes the supervision into fine-grained single operator
prediction; and Variable Keyphrase Masking, which encourages the model to
identify key evidence that sub-programs are derived from. Experimental results
demonstrate the effectiveness of our proposed methods, surpassing
transformer-based model baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced MiniGPT-4. (arXiv:2305.07490v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07490">
<div class="article-summary-box-inner">
<span><p>In recent years, large language models (LLMs) have made significant progress
in natural language processing (NLP), with models like ChatGPT and GPT-4
achieving impressive capabilities in various linguistic tasks. However,
training models on such a large scale is challenging, and finding datasets that
match the model's scale is often difficult. Fine-tuning and training models
with fewer parameters using novel methods have emerged as promising approaches
to overcome these challenges. One such model is MiniGPT-4, which achieves
comparable vision-language understanding to GPT-4 by leveraging novel
pre-training models and innovative training strategies. However, the model
still faces some challenges in image understanding, particularly in artistic
pictures. A novel multimodal model called ArtGPT-4 has been proposed to address
these limitations. ArtGPT-4 was trained on image-text pairs using a Tesla A100
device in just 2 hours, using only about 200 GB of data. The model can depict
images with an artistic flair and generate visual code, including aesthetically
pleasing HTML/CSS web pages. Furthermore, the article proposes novel benchmarks
for evaluating the performance of vision-language models. In the subsequent
evaluation methods, ArtGPT-4 scored more than 1 point higher than the current
\textbf{state-of-the-art} model and was only 0.25 points lower than artists on
a 6-point scale. Our code and pre-trained model are available at
\url{https://huggingface.co/Tyrannosaurus/ArtGPT-4}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Analysis of Adapter Efficiency. (arXiv:2305.07491v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07491">
<div class="article-summary-box-inner">
<span><p>Adapters have been positioned as a parameter-efficient fine-tuning (PEFT)
approach, whereby a minimal number of parameters are added to the model and
fine-tuned. However, adapters have not been sufficiently analyzed to understand
if PEFT translates to benefits in training/deployment efficiency and
maintainability/extensibility. Through extensive experiments on many adapters,
tasks, and languages in supervised and cross-lingual zero-shot settings, we
clearly show that for Natural Language Understanding (NLU) tasks, the parameter
efficiency in adapters does not translate to efficiency gains compared to full
fine-tuning of models. More precisely, adapters are relatively expensive to
train and have slightly higher deployment latency. Furthermore, the
maintainability/extensibility benefits of adapters can be achieved with simpler
approaches like multi-task training via full fine-tuning, which also provide
relatively faster training times. We, therefore, recommend that for moderately
sized models for NLU tasks, practitioners should rely on full fine-tuning or
multi-task training rather than using adapters. Our code is available at
https://github.com/AI4Bharat/adapter-efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LeXFiles and LegalLAMA: Facilitating English Multinational Legal Language Model Development. (arXiv:2305.07507v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07507">
<div class="article-summary-box-inner">
<span><p>In this work, we conduct a detailed analysis on the performance of
legal-oriented pre-trained language models (PLMs). We examine the interplay
between their original objective, acquired knowledge, and legal language
understanding capacities which we define as the upstream, probing, and
downstream performance, respectively. We consider not only the models' size but
also the pre-training corpora used as important dimensions in our study. To
this end, we release a multinational English legal corpus (LeXFiles) and a
legal knowledge probing benchmark (LegalLAMA) to facilitate training and
detailed analysis of legal-oriented PLMs. We release two new legal PLMs trained
on LeXFiles and evaluate them alongside others on LegalLAMA and LexGLUE. We
find that probing performance strongly correlates with upstream performance in
related legal topics. On the other hand, downstream performance is mainly
driven by the model's size and prior legal knowledge which can be estimated by
upstream and probing performance. Based on these findings, we can conclude that
both dimensions are important for those seeking the development of
domain-specific PLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Measuring Progress in Fine-grained Vision-and-Language Understanding. (arXiv:2305.07558v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07558">
<div class="article-summary-box-inner">
<span><p>While pretraining on large-scale image-text data from the Web has facilitated
rapid progress on many vision-and-language (V&amp;L) tasks, recent work has
demonstrated that pretrained models lack "fine-grained" understanding, such as
the ability to recognise relationships, verbs, and numbers in images. This has
resulted in an increased interest in the community to either develop new
benchmarks or models for such capabilities. To better understand and quantify
progress in this direction, we investigate four competitive V&amp;L models on four
fine-grained benchmarks. Through our analysis, we find that X-VLM (Zeng et al.,
2022) consistently outperforms other baselines, and that modelling innovations
can impact performance more than scaling Web data, which even degrades
performance sometimes. Through a deeper investigation of X-VLM, we highlight
the importance of both novel losses and rich data sources for learning
fine-grained skills. Finally, we inspect training dynamics, and discover that
for some tasks, performance peaks early in training or significantly
fluctuates, never converging.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Memory Model for Question Answering from Streaming Data Supported by Rehearsal and Anticipation of Coreference Information. (arXiv:2305.07565v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07565">
<div class="article-summary-box-inner">
<span><p>Existing question answering methods often assume that the input content
(e.g., documents or videos) is always accessible to solve the task.
Alternatively, memory networks were introduced to mimic the human process of
incremental comprehension and compression of the information in a
fixed-capacity memory. However, these models only learn how to maintain memory
by backpropagating errors in the answers through the entire network. Instead,
it has been suggested that humans have effective mechanisms to boost their
memorization capacities, such as rehearsal and anticipation. Drawing
inspiration from these, we propose a memory model that performs rehearsal and
anticipation while processing inputs to memorize important information for
solving question answering tasks from streaming data. The proposed mechanisms
are applied self-supervised during training through masked modeling tasks
focused on coreference information. We validate our model on a short-sequence
(bAbI) dataset as well as large-sequence textual (NarrativeQA) and video
(ActivityNet-QA) question answering datasets, where it achieves substantial
improvements over previous memory network approaches. Furthermore, our ablation
study confirms the proposed mechanisms' importance for memory models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation. (arXiv:2305.07609v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07609">
<div class="article-summary-box-inner">
<span><p>The remarkable achievements of Large Language Models (LLMs) have led to the
emergence of a novel recommendation paradigm -- Recommendation via LLM
(RecLLM). Nevertheless, it is important to note that LLMs may contain social
prejudices, and therefore, the fairness of recommendations made by RecLLM
requires further investigation. To avoid the potential risks of RecLLM, it is
imperative to evaluate the fairness of RecLLM with respect to various sensitive
attributes on the user side. Due to the differences between the RecLLM paradigm
and the traditional recommendation paradigm, it is problematic to directly use
the fairness benchmark of traditional recommendation. To address the dilemma,
we propose a novel benchmark called Fairness of Recommendation via LLM
(FaiRLLM). This benchmark comprises carefully crafted metrics and a dataset
that accounts for eight sensitive attributes1 in two recommendation scenarios:
music and movies. By utilizing our FaiRLLM benchmark, we conducted an
evaluation of ChatGPT and discovered that it still exhibits unfairness to some
sensitive attributes when generating recommendations. Our code and dataset can
be found at https://github.com/jizhi-zhang/FaiRLLM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Sentiment Analysis: A Survey. (arXiv:2305.07611v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07611">
<div class="article-summary-box-inner">
<span><p>Multimodal sentiment analysis has become an important research area in the
field of artificial intelligence. With the latest advances in deep learning,
this technology has reached new heights. It has great potential for both
application and research, making it a popular research topic. This review
provides an overview of the definition, background, and development of
multimodal sentiment analysis. It also covers recent datasets and advanced
models, emphasizing the challenges and future prospects of this technology.
Finally, it looks ahead to future research directions. It should be noted that
this review provides constructive suggestions for promising research directions
and building better performing multimodal sentiment analysis models, which can
help researchers in this field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NevIR: Negation in Neural Information Retrieval. (arXiv:2305.07614v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07614">
<div class="article-summary-box-inner">
<span><p>Negation is a common everyday phenomena and has been a consistent area of
weakness for language models (LMs). Although the Information Retrieval (IR)
community has adopted LMs as the backbone of modern IR architectures, there has
been little to no research in understanding how negation impacts neural IR. We
therefore construct a straightforward benchmark on this theme: asking IR models
to rank two documents that differ only by negation. We show that the results
vary widely according to the type of IR architecture: cross-encoders perform
best, followed by late-interaction models, and in last place are bi-encoder and
sparse neural architectures. We find that most current information retrieval
models do not consider negation, performing similarly or worse than randomly
ranking. We show that although the obvious approach of continued fine-tuning on
a dataset of contrastive documents containing negations increases performance
(as does model size), there is still a large gap between machine and human
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What are the Desired Characteristics of Calibration Sets? Identifying Correlates on Long Form Scientific Summarization. (arXiv:2305.07615v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07615">
<div class="article-summary-box-inner">
<span><p>Summarization models often generate text that is poorly calibrated to quality
metrics because they are trained to maximize the likelihood of a single
reference (MLE). To address this, recent work has added a calibration step,
which exposes a model to its own ranked outputs to improve relevance or, in a
separate line of work, contrasts positive and negative sets to improve
faithfulness. While effective, much of this work has focused on how to generate
and optimize these sets. Less is known about why one setup is more effective
than another. In this work, we uncover the underlying characteristics of
effective sets. For each training instance, we form a large, diverse pool of
candidates and systematically vary the subsets used for calibration
fine-tuning. Each selection strategy targets distinct aspects of the sets, such
as lexical diversity or the size of the gap between positive and negatives. On
three diverse scientific long-form summarization datasets (spanning biomedical,
clinical, and chemical domains), we find, among others, that faithfulness
calibration is optimal when the negative sets are extractive and more likely to
be generated, whereas for relevance calibration, the metric margin between
candidates should be maximized and surprise--the disagreement between model and
metric defined candidate rankings--minimized. Code to create, select, and
optimize calibration sets is available at
https://github.com/griff4692/calibrating-summaries
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PALR: Personalization Aware LLMs for Recommendation. (arXiv:2305.07622v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07622">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have recently received significant attention for
their exceptional capabilities. Despite extensive efforts in developing
general-purpose LLMs that can be utilized in various natural language
processing (NLP) tasks, there has been less research exploring their potential
in recommender systems. In this paper, we propose a novel framework, named
PALR, which aiming to combine user history behaviors (such as clicks,
purchases, ratings, etc.) with LLMs to generate user preferred items.
Specifically, we first use user/item interactions as guidance for candidate
retrieval. Then we adopt a LLM-based ranking model to generate recommended
items. Unlike existing approaches that typically adopt general-purpose LLMs for
zero/few-shot recommendation testing or training on small-sized language models
(with less than 1 billion parameters), which cannot fully elicit LLMs'
reasoning abilities and leverage rich item side parametric knowledge, we
fine-tune a 7 billion parameters LLM for the ranking purpose. This model takes
retrieval candidates in natural language format as input, with instruction
which explicitly asking to select results from input candidates during
inference. Our experimental results demonstrate that our solution outperforms
state-of-the-art models on various sequential recommendation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text2Cohort: Democratizing the NCI Imaging Data Commons with Natural Language Cohort Discovery. (arXiv:2305.07637v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07637">
<div class="article-summary-box-inner">
<span><p>The Imaging Data Commons (IDC) is a cloud-based database that provides
researchers with open access to cancer imaging data and tools for analysis,
with the goal of facilitating collaboration in medical imaging research.
However, querying the IDC database for cohort discovery and access to imaging
data has a significant learning curve for researchers due to its complex and
technical nature. We developed Text2Cohort, a large language model (LLM) based
toolkit to facilitate natural language cohort discovery by translating user
input into IDC database queries through prompt engineering and returning the
query's response to the user. Furthermore, autocorrection is implemented to
resolve syntax and semantic errors in queries by passing the errors back to the
model for interpretation and correction. We evaluate Text2Cohort on 50 natural
language user inputs ranging from information extraction to cohort discovery.
The resulting queries and outputs were verified by two computer scientists to
measure Text2Cohort's accuracy and F1 score. Text2Cohort successfully generated
queries and their responses with an 88% accuracy and F1 score of 0.94. However,
it failed to generate queries for six user inputs due to syntax and semantic
errors. Our results indicate that Text2Cohort succeeded at generating queries
with correct responses, but occasionally failed due to a poor understanding of
the data schema. Despite these shortcomings, Text2Cohort demonstrates the
utility of LLMs to enable researchers to discover and curate cohorts using data
hosted on IDC with incredible accuracy using natural language in a more
intuitive and user-friendly way, thus democratizing access to the IDC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A decomposition of book structure through ousiometric fluctuations in cumulative word-time. (arXiv:2208.09496v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.09496">
<div class="article-summary-box-inner">
<span><p>While quantitative methods have been used to examine changes in word usage in
books, studies have focused on overall trends, such as the shapes of
narratives, which are independent of book length. We instead look at how words
change over the course of a book as a function of the number of words, rather
than the fraction of the book, completed at any given point; we define this
measure as "cumulative word-time". Using ousiometrics, a reinterpretation of
the valence-arousal-dominance framework of meaning obtained from semantic
differentials, we convert text into time series of power and danger scores in
cumulative word-time. Each time series is then decomposed using empirical mode
decomposition into a sum of constituent oscillatory modes and a non-oscillatory
trend. By comparing the decomposition of the original power and danger time
series with those derived from shuffled text, we find that shorter books
exhibit only a general trend, while longer books have fluctuations in addition
to the general trend. These fluctuations typically have a period of a few
thousand words regardless of the book length or library classification code,
but vary depending on the content and structure of the book. Our findings
suggest that, in the ousiometric sense, longer books are not expanded versions
of shorter books, but are more similar in structure to a concatenation of
shorter texts. Further, they are consistent with editorial practices that
require longer texts to be broken down into sections, such as chapters. Our
method also provides a data-driven denoising approach that works for texts of
various lengths, in contrast to the more traditional approach of using large
window sizes that may inadvertently smooth out relevant information, especially
for shorter texts. These results open up avenues for future work in
computational literary analysis, particularly the measurement of a basic unit
of narrative.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discourse Analysis via Questions and Answers: Parsing Dependency Structures of Questions Under Discussion. (arXiv:2210.05905v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.05905">
<div class="article-summary-box-inner">
<span><p>Automatic discourse processing is bottlenecked by data: current discourse
formalisms pose highly demanding annotation tasks involving large taxonomies of
discourse relations, making them inaccessible to lay annotators. This work
instead adopts the linguistic framework of Questions Under Discussion (QUD) for
discourse analysis and seeks to derive QUD structures automatically. QUD views
each sentence as an answer to a question triggered in prior context; thus, we
characterize relationships between sentences as free-form questions, in
contrast to exhaustive fine-grained taxonomies. We develop the
first-of-its-kind QUD parser that derives a dependency structure of questions
over full documents, trained using a large, crowdsourced question-answering
dataset DCQA (Ko et al., 2022). Human evaluation results show that QUD
dependency parsing is possible for language models trained with this
crowdsourced, generalizable annotation scheme. We illustrate how our QUD
structure is distinct from RST trees, and demonstrate the utility of QUD
analysis in the context of document simplification. Our findings show that QUD
parsing is an appealing alternative for automatic discourse processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning. (arXiv:2211.03044v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.03044">
<div class="article-summary-box-inner">
<span><p>Recent studies have revealed the intriguing few-shot learning ability of
pretrained language models (PLMs): They can quickly adapt to a new task when
fine-tuned on a small amount of labeled data formulated as prompts, without
requiring abundant task-specific annotations. Despite their promising
performance, most existing few-shot approaches that only learn from the small
training set still underperform fully supervised training by nontrivial
margins. In this work, we study few-shot learning with PLMs from a different
perspective: We first tune an autoregressive PLM on the few-shot samples and
then use it as a generator to synthesize a large amount of novel training
samples which augment the original training set. To encourage the generator to
produce label-discriminative samples, we train it via weighted maximum
likelihood where the weight of each token is automatically adjusted based on a
discriminative meta-learning objective. A classification PLM can then be
fine-tuned on both the few-shot and the synthetic samples with regularization
for better generalization and stability. Our approach FewGen achieves an
overall better result across seven classification tasks of the GLUE benchmark
than existing few-shot learning methods, improving no-augmentation methods by
5+ average points, and outperforming augmentation methods by 3+ average points.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-distribution Generalization Perspective. (arXiv:2211.08073v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.08073">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PLMs) are known to improve the generalization
performance of natural language understanding models by leveraging large
amounts of data during the pre-training phase. However, the out-of-distribution
(OOD) generalization problem remains a challenge in many NLP tasks, limiting
the real-world deployment of these methods. This paper presents the first
attempt at creating a unified benchmark named \method for evaluating OOD
robustness in NLP models, highlighting the importance of OOD robustness and
providing insights on how to measure the robustness of a model and how to
improve it. The benchmark includes 13 publicly available datasets for OOD
testing, and evaluations are conducted on 8 classic NLP tasks over 21 popularly
used PLMs, including GPT-3 and GPT-3.5. Our findings confirm the need for
improved OOD accuracy in NLP tasks, as significant performance degradation was
observed in all settings compared to in-distribution (ID) accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RHO ($\rho$): Reducing Hallucination in Open-domain Dialogues with Knowledge Grounding. (arXiv:2212.01588v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01588">
<div class="article-summary-box-inner">
<span><p>Dialogue systems can leverage large pre-trained language models and knowledge
to generate fluent and informative responses. However, these models are still
prone to produce hallucinated responses not supported by the input source,
which greatly hinders their application. The heterogeneity between external
knowledge and dialogue context challenges representation learning and source
integration, and further contributes to unfaithfulness. To handle this
challenge and generate more faithful responses, this paper presents RHO
($\rho$) utilizing the representations of linked entities and relation
predicates from a knowledge graph (KG). We propose (1) local knowledge
grounding to combine textual embeddings with the corresponding KG embeddings;
and (2) global knowledge grounding to equip RHO with multi-hop reasoning
abilities via the attention mechanism. In addition, we devise a response
re-ranking technique based on walks over KG sub-graphs for better
conversational reasoning. Experimental results on OpenDialKG show that our
approach significantly outperforms state-of-the-art methods on both automatic
and human evaluation by a large margin, especially in hallucination reduction
(17.54% in FeQA).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PLUE: Language Understanding Evaluation Benchmark for Privacy Policies in English. (arXiv:2212.10011v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10011">
<div class="article-summary-box-inner">
<span><p>Privacy policies provide individuals with information about their rights and
how their personal information is handled. Natural language understanding (NLU)
technologies can support individuals and practitioners to understand better
privacy practices described in lengthy and complex documents. However, existing
efforts that use NLU technologies are limited by processing the language in a
way exclusive to a single task focusing on certain privacy practices. To this
end, we introduce the Privacy Policy Language Understanding Evaluation (PLUE)
benchmark, a multi-task benchmark for evaluating the privacy policy language
understanding across various tasks. We also collect a large corpus of privacy
policies to enable privacy policy domain-specific language model pre-training.
We evaluate several generic pre-trained language models and continue
pre-training them on the collected corpus. We demonstrate that domain-specific
continual pre-training offers performance improvements across all tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPT-NER: Named Entity Recognition via Large Language Models. (arXiv:2304.10428v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10428">
<div class="article-summary-box-inner">
<span><p>Despite the fact that large-scale Language Models (LLM) have achieved SOTA
performances on a variety of NLP tasks, its performance on NER is still
significantly below supervised baselines. This is due to the gap between the
two tasks the NER and LLMs: the former is a sequence labeling task in nature
while the latter is a text-generation model.
</p>
<p>In this paper, we propose GPT-NER to resolve this issue. GPT-NER bridges the
gap by transforming the sequence labeling task to a generation task that can be
easily adapted by LLMs e.g., the task of finding location entities in the input
text "Columbus is a city" is transformed to generate the text sequence
"@@Columbus## is a city", where special tokens @@## marks the entity to
extract. To efficiently address the "hallucination" issue of LLMs, where LLMs
have a strong inclination to over-confidently label NULL inputs as entities, we
propose a self-verification strategy by prompting LLMs to ask itself whether
the extracted entities belong to a labeled entity tag.
</p>
<p>We conduct experiments on five widely adopted NER datasets, and GPT-NER
achieves comparable performances to fully supervised baselines, which is the
first time as far as we are concerned. More importantly, we find that GPT-NER
exhibits a greater ability in the low-resource and few-shot setups, when the
amount of training data is extremely scarce, GPT-NER performs significantly
better than supervised models. This demonstrates the capabilities of GPT-NER in
real-world NER applications where the number of labeled examples is limited.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations. (arXiv:2304.14827v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.14827">
<div class="article-summary-box-inner">
<span><p>This paper aims to quantitatively evaluate the performance of ChatGPT, an
interactive large language model, on inter-sentential relations such as
temporal relations, causal relations, and discourse relations. Given ChatGPT's
promising performance across various tasks, we conduct extensive evaluations on
the whole test sets of 13 datasets, including temporal and causal relations,
PDTB2.0-based and dialogue-based discourse relations, and downstream
applications on discourse understanding. To achieve reliable results, we adopt
three tailored prompt templates for each task, including the zero-shot prompt
template, zero-shot prompt engineering (PE) template, and in-context learning
(ICL) prompt template, to establish the initial baseline scores for all popular
sentence-pair relation classification tasks for the first time. We find that
ChatGPT exhibits strong performance in detecting and reasoning about causal
relations, while it may not be proficient in identifying the temporal order
between two events. It can recognize most discourse relations with existing
explicit discourse connectives, but the implicit discourse relation still
remains a challenging task. Meanwhile, ChatGPT performs poorly in the dialogue
discourse parsing task that requires structural understanding in a dialogue
before being aware of the discourse relation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neuromodulation Gated Transformer. (arXiv:2305.03232v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03232">
<div class="article-summary-box-inner">
<span><p>We introduce a novel architecture, the Neuromodulation Gated Transformer
(NGT), which is a simple implementation of neuromodulation in transformers via
a multiplicative effect. We compare it to baselines and show that it results in
the best average performance on the SuperGLUE benchmark validation sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MGR: Multi-generator based Rationalization. (arXiv:2305.04492v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04492">
<div class="article-summary-box-inner">
<span><p>Rationalization is to employ a generator and a predictor to construct a
self-explaining NLP model in which the generator selects a subset of
human-intelligible pieces of the input text to the following predictor.
However, rationalization suffers from two key challenges, i.e., spurious
correlation and degeneration, where the predictor overfits the spurious or
meaningless pieces solely selected by the not-yet well-trained generator and in
turn deteriorates the generator. Although many studies have been proposed to
address the two challenges, they are usually designed separately and do not
take both of them into account. In this paper, we propose a simple yet
effective method named MGR to simultaneously solve the two problems. The key
idea of MGR is to employ multiple generators such that the occurrence stability
of real pieces is improved and more meaningful pieces are delivered to the
predictor. Empirically, we show that MGR improves the F1 score by up to 20.9%
as compared to state-of-the-art methods. Codes are available at
https://github.com/jugechengzi/Rationalization-MGR .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models. (arXiv:2305.05189v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05189">
<div class="article-summary-box-inner">
<span><p>Diffusion models, which have emerged to become popular text-to-image
generation models, can produce high-quality and content-rich images guided by
textual prompts. However, there are limitations to semantic understanding and
commonsense reasoning in existing models when the input prompts are concise
narrative, resulting in low-quality image generation. To improve the capacities
for narrative prompts, we propose a simple-yet-effective parameter-efficient
fine-tuning approach called the Semantic Understanding and Reasoning adapter
(SUR-adapter) for pre-trained diffusion models. To reach this goal, we first
collect and annotate a new dataset SURD which consists of more than 57,000
semantically corrected multi-modal samples. Each sample contains a simple
narrative prompt, a complex keyword-based prompt, and a high-quality image.
Then, we align the semantic representation of narrative prompts to the complex
prompts and transfer knowledge of large language models (LLMs) to our
SUR-adapter via knowledge distillation so that it can acquire the powerful
semantic understanding and reasoning capabilities to build a high-quality
textual semantic representation for text-to-image generation. We conduct
experiments by integrating multiple LLMs and popular pre-trained diffusion
models to show the effectiveness of our approach in enabling diffusion models
to understand and reason concise natural language without image quality
degradation. Our approach can make text-to-image diffusion models easier to use
with better user experience, which demonstrates our approach has the potential
for further advancing the development of user-friendly text-to-image generation
models by bridging the semantic gap between simple narrative prompts and
complex keyword-based prompts. The code is released at
https://github.com/Qrange-group/SUR-adapter.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpretable multimodal sentiment analysis based on textual modality descriptions by using large-scale language models. (arXiv:2305.06162v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.06162">
<div class="article-summary-box-inner">
<span><p>Multimodal sentiment analysis is an important area for understanding the
user's internal states. Deep learning methods were effective, but the problem
of poor interpretability has gradually gained attention. Previous works have
attempted to use attention weights or vector distributions to provide
interpretability. However, their explanations were not intuitive and can be
influenced by different trained models. This study proposed a novel approach to
provide interpretability by converting nonverbal modalities into text
descriptions and by using large-scale language models for sentiment
predictions. This provides an intuitive approach to directly interpret what
models depend on with respect to making decisions from input texts, thus
significantly improving interpretability. Specifically, we convert descriptions
based on two feature patterns for the audio modality and discrete action units
for the facial modality. Experimental results on two sentiment analysis tasks
demonstrated that the proposed approach maintained, or even improved
effectiveness for sentiment analysis compared to baselines using conventional
features, with the highest improvement of 2.49% on the F1 score. The results
also showed that multimodal descriptions have similar characteristics on fusing
modalities as those of conventional fusion methods. The results demonstrated
that the proposed approach is interpretable and effective for multimodal
sentiment analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT-Like Large-Scale Foundation Models for Prognostics and Health Management: A Survey and Roadmaps. (arXiv:2305.06472v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.06472">
<div class="article-summary-box-inner">
<span><p>Prognostics and health management (PHM) technology plays a critical role in
industrial production and equipment maintenance by identifying and predicting
possible equipment failures and damages, thereby allowing necessary maintenance
measures to be taken to enhance equipment service life and reliability while
reducing production costs and downtime. In recent years, PHM technology based
on artificial intelligence (AI) has made remarkable achievements in the context
of the industrial IoT and big data, and it is widely used in various
industries, such as railway, energy, and aviation, for condition monitoring,
fault prediction, and health management. The emergence of large-scale
foundation models (LSF-Models) such as ChatGPT and DALLE-E marks the entry of
AI into a new era of AI-2.0 from AI-1.0, where deep models have rapidly evolved
from a research paradigm of single-modal, single-task, and limited-data to a
multi-modal, multi-task, massive data, and super-large model paradigm. ChatGPT
represents a landmark achievement in this research paradigm, offering hope for
general artificial intelligence due to its highly intelligent natural language
understanding ability. However, the PHM field lacks a consensus on how to
respond to this significant change in the AI field, and a systematic review and
roadmap is required to elucidate future development directions. To fill this
gap, this paper systematically expounds on the key components and latest
developments of LSF-Models. Then, we systematically answered how to build the
LSF-Model applicable to PHM tasks and outlined the challenges and future
development roadmaps for this research paradigm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Musketeer (All for One, and One for All): A Generalist Vision-Language Model with Task Explanation Prompts. (arXiv:2305.07019v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07019">
<div class="article-summary-box-inner">
<span><p>We present a sequence-to-sequence vision-language model whose parameters are
jointly trained on all tasks (all for one) and fully shared among multiple
tasks (one for all), resulting in a single model which we named Musketeer. The
integration of knowledge across heterogeneous tasks is enabled by a novel
feature called Task Explanation Prompt (TEP). TEP reduces interference among
tasks, allowing the model to focus on their shared structure. With a single
model, Musketeer achieves results comparable to or better than strong baselines
trained on single tasks, almost uniformly across multiple tasks.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-05-15 23:11:04.860072383 UTC">2023-05-15 23:11:04 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>