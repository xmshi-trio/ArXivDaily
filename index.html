<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-07-26T01:30:00Z">07-26</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Extracting Molecular Properties from Natural Language with Multimodal Contrastive Learning. (arXiv:2307.12996v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.12996">
<div class="article-summary-box-inner">
<span><p>Deep learning in computational biochemistry has traditionally focused on
molecular graphs neural representations; however, recent advances in language
models highlight how much scientific knowledge is encoded in text. To bridge
these two modalities, we investigate how molecular property information can be
transferred from natural language to graph representations. We study property
prediction performance gains after using contrastive learning to align neural
graph representations with representations of textual descriptions of their
characteristics. We implement neural relevance scoring strategies to improve
text retrieval, introduce a novel chemically-valid molecular graph augmentation
strategy inspired by organic reactions, and demonstrate improved performance on
downstream MoleculeNet property classification tasks. We achieve a +4.26% AUROC
gain versus models pre-trained on the graph modality alone, and a +1.54% gain
compared to recently proposed molecular graph/text contrastively trained MoMu
model (Su et al. 2022).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The potential of LLMs for coding with low-resource and domain-specific programming languages. (arXiv:2307.13018v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13018">
<div class="article-summary-box-inner">
<span><p>This paper presents a study on the feasibility of using large language models
(LLM) for coding with low-resource and domain-specific programming languages
that typically lack the amount of data required for effective LLM processing
techniques. This study focuses on the econometric scripting language named
hansl of the open-source software gretl and employs a proprietary LLM based on
GPT-3.5. Our findings suggest that LLMs can be a useful tool for writing,
understanding, improving, and documenting gretl code, which includes generating
descriptive docstrings for functions and providing precise explanations for
abstract and poorly documented econometric code. While the LLM showcased
promoting docstring-to-code translation capability, we also identify some
limitations, such as its inability to improve certain sections of code and to
write accurate unit tests. This study is a step towards leveraging the power of
LLMs to facilitate software development in low-resource programming languages
and ultimately to lower barriers to entry for their adoption.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Making Metadata More FAIR Using Large Language Models. (arXiv:2307.13085v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13085">
<div class="article-summary-box-inner">
<span><p>With the global increase in experimental data artifacts, harnessing them in a
unified fashion leads to a major stumbling block - bad metadata. To bridge this
gap, this work presents a Natural Language Processing (NLP) informed
application, called FAIRMetaText, that compares metadata. Specifically,
FAIRMetaText analyzes the natural language descriptions of metadata and
provides a mathematical similarity measure between two terms. This measure can
then be utilized for analyzing varied metadata, by suggesting terms for
compliance or grouping similar terms for identification of replaceable terms.
The efficacy of the algorithm is presented qualitatively and quantitatively on
publicly available research artifacts and demonstrates large gains across
metadata related tasks through an in-depth study of a wide variety of Large
Language Models (LLMs). This software can drastically reduce the human effort
in sifting through various natural language metadata while employing several
experimental datasets on the same topic.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to use LLMs for Text Analysis. (arXiv:2307.13106v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13106">
<div class="article-summary-box-inner">
<span><p>This guide introduces Large Language Models (LLM) as a highly versatile text
analysis method within the social sciences. As LLMs are easy-to-use, cheap,
fast, and applicable on a broad range of text analysis tasks, ranging from text
annotation and classification to sentiment analysis and critical discourse
analysis, many scholars believe that LLMs will transform how we do text
analysis. This how-to guide is aimed at students and researchers with limited
programming experience, and offers a simple introduction to how LLMs can be
used for text analysis in your own research project, as well as advice on best
practices. We will go through each of the steps of analyzing textual data with
LLMs using Python: installing the software, setting up the API, loading the
data, developing an analysis prompt, analyzing the text, and validating the
results. As an illustrative example, we will use the challenging task of
identifying populism in political texts, and show how LLMs move beyond the
existing state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explaining Math Word Problem Solvers. (arXiv:2307.13128v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13128">
<div class="article-summary-box-inner">
<span><p>Automated math word problem solvers based on neural networks have
successfully managed to obtain 70-80\% accuracy in solving arithmetic word
problems. However, it has been shown that these solvers may rely on superficial
patterns to obtain their equations. In order to determine what information math
word problem solvers use to generate solutions, we remove parts of the input
and measure the model's performance on the perturbed dataset. Our results show
that the model is not sensitive to the removal of many words from the input and
can still manage to find a correct answer when given a nonsense question. This
indicates that automatic solvers do not follow the semantic logic of math word
problems, and may be overfitting to the presence of specific words.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Opinion Mining Using Population-tuned Generative Language Models. (arXiv:2307.13173v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13173">
<div class="article-summary-box-inner">
<span><p>We present a novel method for mining opinions from text collections using
generative language models trained on data collected from different
populations. We describe the basic definitions, methodology and a generic
algorithm for opinion insight mining. We demonstrate the performance of our
method in an experiment where a pre-trained generative model is fine-tuned
using specifically tailored content with unnatural and fully annotated
opinions. We show that our approach can learn and transfer the opinions to the
semantic classes while maintaining the proportion of polarisation. Finally, we
demonstrate the usage of an insight mining system to scale up the discovery of
opinion insights from a real text corpus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Schema-Driven Actionable Insight Generation and Smart Recommendation. (arXiv:2307.13176v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13176">
<div class="article-summary-box-inner">
<span><p>In natural language generation (NLG), insight mining is seen as a
data-to-text task, where data is mined for interesting patterns and verbalised
into 'insight' statements. An 'over-generate and rank' paradigm is intuitively
used to generate such insights. The multidimensionality and subjectivity of
this process make it challenging. This paper introduces a schema-driven method
to generate actionable insights from data to drive growth and change. It also
introduces a technique to rank the insights to align with user interests based
on their feedback. We show preliminary qualitative results of the insights
generated using our technique and demonstrate its ability to adapt to feedback.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition. (arXiv:2307.13269v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13269">
<div class="article-summary-box-inner">
<span><p>Low-rank adaptations (LoRA) are often employed to fine-tune large language
models (LLMs) for new tasks. This paper investigates LoRA composability for
cross-task generalization and introduces LoraHub, a strategic framework devised
for the purposive assembly of LoRA modules trained on diverse given tasks, with
the objective of achieving adaptable performance on unseen tasks. With just a
few examples from a novel task, LoraHub enables the fluid combination of
multiple LoRA modules, eradicating the need for human expertise. Notably, the
composition requires neither additional model parameters nor gradients. Our
empirical results, derived from the Big-Bench Hard (BBH) benchmark, suggest
that LoraHub can effectively mimic the performance of in-context learning in
few-shot scenarios, excluding the necessity of in-context examples alongside
each inference input. A significant contribution of our research is the
fostering of a community for LoRA, where users can share their trained LoRA
modules, thereby facilitating their application to new tasks. We anticipate
this resource will widen access to and spur advancements in general
intelligence as well as LLMs in production. Code will be available at
https://github.com/sail-sg/lorahub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Intent Taxonomy of Legal Case Retrieval. (arXiv:2307.13298v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13298">
<div class="article-summary-box-inner">
<span><p>Legal case retrieval is a special Information Retrieval~(IR) task focusing on
legal case documents. Depending on the downstream tasks of the retrieved case
documents, users' information needs in legal case retrieval could be
significantly different from those in Web search and traditional ad-hoc
retrieval tasks. While there are several studies that retrieve legal cases
based on text similarity, the underlying search intents of legal retrieval
users, as shown in this paper, are more complicated than that yet mostly
unexplored. To this end, we present a novel hierarchical intent taxonomy of
legal case retrieval. It consists of five intent types categorized by three
criteria, i.e., search for Particular Case(s), Characterization, Penalty,
Procedure, and Interest. The taxonomy was constructed transparently and
evaluated extensively through interviews, editorial user studies, and query log
analysis. Through a laboratory user study, we reveal significant differences in
user behavior and satisfaction under different search intents in legal case
retrieval. Furthermore, we apply the proposed taxonomy to various downstream
legal retrieval tasks, e.g., result ranking and satisfaction prediction, and
demonstrate its effectiveness. Our work provides important insights into the
understanding of user intents in legal case retrieval and potentially leads to
better retrieval techniques in the legal domain, such as intent-aware ranking
strategies and evaluation methodologies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QuIP: 2-Bit Quantization of Large Language Models With Guarantees. (arXiv:2307.13304v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13304">
<div class="article-summary-box-inner">
<span><p>This work studies post-training parameter quantization in large language
models (LLMs). We introduce quantization with incoherence processing (QuIP), a
new method based on the insight that quantization benefits from incoherent
weight and Hessian matrices, i.e., from the weights and the directions in which
it is important to round them accurately being unaligned with the coordinate
axes. QuIP consists of two steps: (1) an adaptive rounding procedure minimizing
a quadratic proxy objective; (2) efficient pre- and post-processing that
ensures weight and Hessian incoherence via multiplication by random orthogonal
matrices. We complement QuIP with the first theoretical analysis for an
LLM-scale quantization algorithm, and show that our theory also applies to an
existing method, OPTQ. Empirically, we find that our incoherence preprocessing
improves several existing quantization algorithms and yields the first LLM
quantization methods that produce viable results using only two bits per
weight. Our code can be found at https://github.com/jerry-chee/QuIP .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analyzing Chain-of-Thought Prompting in Large Language Models via Gradient-based Feature Attributions. (arXiv:2307.13339v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13339">
<div class="article-summary-box-inner">
<span><p>Chain-of-thought (CoT) prompting has been shown to empirically improve the
accuracy of large language models (LLMs) on various question answering tasks.
While understanding why CoT prompting is effective is crucial to ensuring that
this phenomenon is a consequence of desired model behavior, little work has
addressed this; nonetheless, such an understanding is a critical prerequisite
for responsible model deployment. We address this question by leveraging
gradient-based feature attribution methods which produce saliency scores that
capture the influence of input tokens on model output. Specifically, we probe
several open-source LLMs to investigate whether CoT prompting affects the
relative importances they assign to particular input tokens. Our results
indicate that while CoT prompting does not increase the magnitude of saliency
scores attributed to semantically relevant tokens in the prompt compared to
standard few-shot prompting, it increases the robustness of saliency scores to
question perturbations and variations in model output.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Empower Your Model with Longer and Better Context Comprehension. (arXiv:2307.13365v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13365">
<div class="article-summary-box-inner">
<span><p>Recently, with the emergence of numerous Large Language Models (LLMs), the
implementation of AI has entered a new era. Irrespective of these models' own
capacity and structure, there is a growing demand for LLMs to possess enhanced
comprehension of longer and more complex contexts with relatively smaller
sizes. Models often encounter an upper limit when processing sequences of
sentences that extend beyond their comprehension capacity and result in
off-topic or even chaotic responses. While several recent works attempt to
address this issue in various ways, they rarely focus on "why models are unable
to compensate or strengthen their capabilities on their own". In this paper, we
thoroughly investigate the nature of information transfer within LLMs and
propose a novel technique called Attention Transition. This technique empowers
models to achieve longer and better context comprehension with minimal
additional training or impact on generation fluency. Our experiments are
conducted in XSum and achieve substantial improvement compared with the
original generation results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Embedding Models for Supervised Automatic Extraction and Classification of Named Entities in Scientific Acknowledgements. (arXiv:2307.13377v1 [cs.DL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13377">
<div class="article-summary-box-inner">
<span><p>Acknowledgments in scientific papers may give an insight into aspects of the
scientific community, such as reward systems, collaboration patterns, and
hidden research trends. The aim of the paper is to evaluate the performance of
different embedding models for the task of automatic extraction and
classification of acknowledged entities from the acknowledgment text in
scientific papers. We trained and implemented a named entity recognition (NER)
task using the Flair NLP framework. The training was conducted using three
default Flair NER models with four differently-sized corpora and different
versions of the Flair NLP framework. The Flair Embeddings model trained on the
medium corpus with the latest FLAIR version showed the best accuracy of 0.79.
Expanding the size of a training corpus from very small to medium size
massively increased the accuracy of all training algorithms, but further
expansion of the training corpus did not bring further improvement. Moreover,
the performance of the model slightly deteriorated. Our model is able to
recognize six entity types: funding agency, grant number, individuals,
university, corporation, and miscellaneous. The model works more precisely for
some entity types than for others; thus, individuals and grant numbers showed a
very good F1-Score over 0.9. Most of the previous works on acknowledgment
analysis were limited by the manual evaluation of data and therefore by the
amount of processed data. This model can be applied for the comprehensive
analysis of acknowledgment texts and may potentially make a great contribution
to the field of automated acknowledgment analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Bridging the Digital Language Divide. (arXiv:2307.13405v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13405">
<div class="article-summary-box-inner">
<span><p>It is a well-known fact that current AI-based language technology -- language
models, machine translation systems, multilingual dictionaries and corpora --
focuses on the world's 2-3% most widely spoken languages. Recent research
efforts have attempted to expand the coverage of AI technology to
`under-resourced languages.' The goal of our paper is to bring attention to a
phenomenon that we call linguistic bias: multilingual language processing
systems often exhibit a hardwired, yet usually involuntary and hidden
representational preference towards certain languages. Linguistic bias is
manifested in uneven per-language performance even in the case of similar test
conditions. We show that biased technology is often the result of research and
development methodologies that do not do justice to the complexity of the
languages being represented, and that can even become ethically problematic as
they disregard valuable aspects of diversity as well as the needs of the
language communities themselves. As our attempt at building diversity-aware
language resources, we present a new initiative that aims at reducing
linguistic bias through both technological design and methodology, based on an
eye-level collaboration with local communities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Resolving Word Ambiguity with Word Embeddings. (arXiv:2307.13417v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13417">
<div class="article-summary-box-inner">
<span><p>Ambiguity is ubiquitous in natural language. Resolving ambiguous meanings is
especially important in information retrieval tasks. While word embeddings
carry semantic information, they fail to handle ambiguity well. Transformer
models have been shown to handle word ambiguity for complex queries, but they
cannot be used to identify ambiguous words, e.g. for a 1-word query.
Furthermore, training these models is costly in terms of time, hardware
resources, and training data, prohibiting their use in specialized environments
with sensitive data. Word embeddings can be trained using moderate hardware
resources. This paper shows that applying DBSCAN clustering to the latent space
can identify ambiguous words and evaluate their level of ambiguity. An
automatic DBSCAN parameter selection leads to high-quality clusters, which are
semantically coherent and correspond well to the perceived meanings of a given
word.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Holistic Exploration on Universal Decompositional Semantic Parsing: Architecture, Data Augmentation, and LLM Paradigm. (arXiv:2307.13424v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13424">
<div class="article-summary-box-inner">
<span><p>In this paper, we conduct a holistic exploration of the Universal
Decompositional Semantic (UDS) Parsing. We first introduce a cascade model for
UDS parsing that decomposes the complex parsing task into semantically
appropriate subtasks. Our approach outperforms the prior models, while
significantly reducing inference time. We also incorporate syntactic
information and further optimized the architecture. Besides, different ways for
data augmentation are explored, which further improve the UDS Parsing. Lastly,
we conduct experiments to investigate the efficacy of ChatGPT in handling the
UDS task, revealing that it excels in attribute parsing but struggles in
relation parsing, and using ChatGPT for data augmentation yields suboptimal
results. Our code is available at https://github.com/hexuandeng/HExp4UDS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zshot: An Open-source Framework for Zero-Shot Named Entity Recognition and Relation Extraction. (arXiv:2307.13497v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13497">
<div class="article-summary-box-inner">
<span><p>The Zero-Shot Learning (ZSL) task pertains to the identification of entities
or relations in texts that were not seen during training. ZSL has emerged as a
critical research area due to the scarcity of labeled data in specific domains,
and its applications have grown significantly in recent years. With the advent
of large pretrained language models, several novel methods have been proposed,
resulting in substantial improvements in ZSL performance. There is a growing
demand, both in the research community and industry, for a comprehensive ZSL
framework that facilitates the development and accessibility of the latest
methods and pretrained models.In this study, we propose a novel ZSL framework
called Zshot that aims to address the aforementioned challenges. Our primary
objective is to provide a platform that allows researchers to compare different
state-of-the-art ZSL methods with standard benchmark datasets. Additionally, we
have designed our framework to support the industry with readily available APIs
for production under the standard SpaCy NLP pipeline. Our API is extendible and
evaluable, moreover, we include numerous enhancements such as boosting the
accuracy with pipeline ensembling and visualization utilities available as a
SpaCy extension.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios. (arXiv:2307.13528v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13528">
<div class="article-summary-box-inner">
<span><p>The emergence of generative pre-trained models has facilitated the synthesis
of high-quality text, but it has also posed challenges in identifying factual
errors in the generated text. In particular: (1) A wider range of tasks now
face an increasing risk of containing factual errors when handled by generative
models. (2) Generated texts tend to be lengthy and lack a clearly defined
granularity for individual facts. (3) There is a scarcity of explicit evidence
available during the process of fact checking. With the above challenges in
mind, in this paper, we propose FacTool, a task and domain agnostic framework
for detecting factual errors of texts generated by large language models (e.g.,
ChatGPT). Experiments on four different tasks (knowledge-based QA, code
generation, mathematical reasoning, and scientific literature review) show the
efficacy of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">XDLM: Cross-lingual Diffusion Language Model for Machine Translation. (arXiv:2307.13560v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13560">
<div class="article-summary-box-inner">
<span><p>Recently, diffusion models have excelled in image generation tasks and have
also been applied to neural language processing (NLP) for controllable text
generation. However, the application of diffusion models in a cross-lingual
setting is less unexplored. Additionally, while pretraining with diffusion
models has been studied within a single language, the potential of
cross-lingual pretraining remains understudied. To address these gaps, we
propose XDLM, a novel Cross-lingual diffusion model for machine translation,
consisting of pretraining and fine-tuning stages. In the pretraining stage, we
propose TLDM, a new training objective for mastering the mapping between
different languages; in the fine-tuning stage, we build up the translation
system based on the pretrained model. We evaluate the result on several machine
translation benchmarks and outperformed both diffusion and Transformer
baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPT-3 Models are Few-Shot Financial Reasoners. (arXiv:2307.13617v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13617">
<div class="article-summary-box-inner">
<span><p>Financial analysis is an important tool for evaluating company performance.
Practitioners work to answer financial questions to make profitable investment
decisions, and use advanced quantitative analyses to do so. As a result,
Financial Question Answering (QA) is a question answering task that requires
deep reasoning about numbers. Furthermore, it is unknown how well pre-trained
language models can reason in the financial domain. The current
state-of-the-art requires a retriever to collect relevant facts about the
financial question from the text and a generator to produce a valid financial
program and a final answer. However, recently large language models like GPT-3
have achieved state-of-the-art performance on wide variety of tasks with just a
few shot examples. We run several experiments with GPT-3 and find that a
separate retrieval model and logic engine continue to be essential components
to achieving SOTA performance in this task, particularly due to the precise
nature of financial questions and the complex information stored in financial
documents. With this understanding, our refined prompt-engineering approach on
GPT-3 achieves near SOTA accuracy without any fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contributions to the Improvement of Question Answering Systems in the Biomedical Domain. (arXiv:2307.13631v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13631">
<div class="article-summary-box-inner">
<span><p>This thesis work falls within the framework of question answering (QA) in the
biomedical domain where several specific challenges are addressed, such as
specialized lexicons and terminologies, the types of treated questions, and the
characteristics of targeted documents. We are particularly interested in
studying and improving methods that aim at finding accurate and short answers
to biomedical natural language questions from a large scale of biomedical
textual documents in English. QA aims at providing inquirers with direct, short
and precise answers to their natural language questions. In this Ph.D. thesis,
we propose four contributions to improve the performance of QA in the
biomedical domain. In our first contribution, we propose a machine
learning-based method for question type classification to determine the types
of given questions which enable to a biomedical QA system to use the
appropriate answer extraction method. We also propose an another machine
learning-based method to assign one or more topics (e.g., pharmacological,
test, treatment, etc.) to given questions in order to determine the semantic
types of the expected answers which are very useful in generating specific
answer retrieval strategies. In the second contribution, we first propose a
document retrieval method to retrieve a set of relevant documents that are
likely to contain the answers to biomedical questions from the MEDLINE
database. We then present a passage retrieval method to retrieve a set of
relevant passages to questions. In the third contribution, we propose specific
answer extraction methods to generate both exact and ideal answers. Finally, in
the fourth contribution, we develop a fully automated semantic biomedical QA
system called SemBioNLQA which is able to deal with a variety of natural
language questions and to generate appropriate answers by providing both exact
and ideal answers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Evaluation and Analysis Study for Chinese Spelling Check. (arXiv:2307.13655v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13655">
<div class="article-summary-box-inner">
<span><p>With the development of pre-trained models and the incorporation of phonetic
and graphic information, neural models have achieved high scores in Chinese
Spelling Check (CSC). However, it does not provide a comprehensive reflection
of the models' capability due to the limited test sets. In this study, we
abstract the representative model paradigm, implement it with nine structures
and experiment them on comprehensive test sets we constructed with different
purposes. We perform a detailed analysis of the results and find that: 1)
Fusing phonetic and graphic information reasonably is effective for CSC. 2)
Models are sensitive to the error distribution of the test set, which reflects
the shortcomings of models and reveals the direction we should work on. 3)
Whether or not the errors and contexts have been seen has a significant impact
on models. 4) The commonly used benchmark, SIGHAN, can not reliably evaluate
models' performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ARB: Advanced Reasoning Benchmark for Large Language Models. (arXiv:2307.13692v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13692">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have demonstrated remarkable performance on
various quantitative reasoning and knowledge benchmarks. However, many of these
benchmarks are losing utility as LLMs get increasingly high scores, despite not
yet reaching expert performance in these domains. We introduce ARB, a novel
benchmark composed of advanced reasoning problems in multiple fields. ARB
presents a more challenging test than prior benchmarks, featuring problems in
mathematics, physics, biology, chemistry, and law. As a subset of ARB, we
introduce a challenging set of math and physics problems which require advanced
symbolic reasoning and domain knowledge. We evaluate recent models such as
GPT-4 and Claude on ARB and demonstrate that current models score well below
50% on more demanding tasks. In order to improve both automatic and assisted
evaluation capabilities, we introduce a rubric-based evaluation approach,
allowing GPT-4 to score its own intermediate reasoning steps. Further, we
conduct a human evaluation of the symbolic subset of ARB, finding promising
agreement between annotators and GPT-4 rubric evaluation scores.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Large Language Models for Radiology Natural Language Processing. (arXiv:2307.13693v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13693">
<div class="article-summary-box-inner">
<span><p>The rise of large language models (LLMs) has marked a pivotal shift in the
field of natural language processing (NLP). LLMs have revolutionized a
multitude of domains, and they have made a significant impact in the medical
field. Large language models are now more abundant than ever, and many of these
models exhibit bilingual capabilities, proficient in both English and Chinese.
However, a comprehensive evaluation of these models remains to be conducted.
This lack of assessment is especially apparent within the context of radiology
NLP. This study seeks to bridge this gap by critically evaluating thirty two
LLMs in interpreting radiology reports, a crucial component of radiology NLP.
Specifically, the ability to derive impressions from radiologic findings is
assessed. The outcomes of this evaluation provide key insights into the
performance, strengths, and weaknesses of these LLMs, informing their practical
applications within the medical domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classification of Consumer Belief Statements From Social Media. (arXiv:2106.15498v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15498">
<div class="article-summary-box-inner">
<span><p>Social media offer plenty of information to perform market research in order
to meet the requirements of customers. One way how this research is conducted
is that a domain expert gathers and categorizes user-generated content into a
complex and fine-grained class structure. In many of such cases, little data
meets complex annotations. It is not yet fully understood how this can be
leveraged successfully for classification. We examine the classification
accuracy of expert labels when used with a) many fine-grained classes and b)
few abstract classes. For scenario b) we compare abstract class labels given by
the domain expert as baseline and by automatic hierarchical clustering. We
compare this to another baseline where the entire class structure is given by a
completely unsupervised clustering approach. By doing so, this work can serve
as an example of how complex expert annotations are potentially beneficial and
can be utilized in the most optimal way for opinion mining in highly specific
domains. By exploring across a range of techniques and experiments, we find
that automated class abstraction approaches in particular the unsupervised
approach performs remarkably well against domain expert baseline on text
classification tasks. This has the potential to inspire opinion mining
applications in order to support market researchers in practice and to inspire
fine-grained automated content analysis on a large scale.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SocialVisTUM: An Interactive Visualization Toolkit for Correlated Neural Topic Models on Social Media Opinion Mining. (arXiv:2110.10575v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.10575">
<div class="article-summary-box-inner">
<span><p>Recent research in opinion mining proposed word embedding-based topic
modeling methods that provide superior coherence compared to traditional topic
modeling. In this paper, we demonstrate how these methods can be used to
display correlated topic models on social media texts using SocialVisTUM, our
proposed interactive visualization toolkit. It displays a graph with topics as
nodes and their correlations as edges. Further details are displayed
interactively to support the exploration of large text collections, e.g.,
representative words and sentences of topics, topic and sentiment
distributions, hierarchical topic clustering, and customizable, predefined
topic labels. The toolkit optimizes automatically on custom data for optimal
coherence. We show a working instance of the toolkit on data crawled from
English social media discussions about organic food consumption. The
visualization confirms findings of a qualitative consumer research study.
SocialVisTUM and its training procedures are accessible online.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Analysis of Programming Course Evaluations Before and After the Introduction of an Autograder. (arXiv:2110.15134v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15134">
<div class="article-summary-box-inner">
<span><p>Commonly, introductory programming courses in higher education institutions
have hundreds of participating students eager to learn to program. The manual
effort for reviewing the submitted source code and for providing feedback can
no longer be managed. Manually reviewing the submitted homework can be
subjective and unfair, particularly if many tutors are responsible for grading.
Different autograders can help in this situation; however, there is a lack of
knowledge about how autograders can impact students' overall perception of
programming classes and teaching. This is relevant for course organizers and
institutions to keep their programming courses attractive while coping with
increasing students.
</p>
<p>This paper studies the answers to the standardized university evaluation
questionnaires of multiple large-scale foundational computer science courses
which recently introduced autograding. The differences before and after this
intervention are analyzed. By incorporating additional observations, we
hypothesize how the autograder might have contributed to the significant
changes in the data, such as, improved interactions between tutors and
students, improved overall course quality, improved learning success, increased
time spent, and reduced difficulty. This qualitative study aims to provide
hypotheses for future research to define and conduct quantitative surveys and
data analysis. The autograder technology can be validated as a teaching method
to improve student satisfaction with programming courses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Case Study and Qualitative Analysis of Simple Cross-Lingual Opinion Mining. (arXiv:2111.02259v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02259">
<div class="article-summary-box-inner">
<span><p>User-generated content from social media is produced in many languages,
making it technically challenging to compare the discussed themes from one
domain across different cultures and regions. It is relevant for domains in a
globalized world, such as market research, where people from two nations and
markets might have different requirements for a product. We propose a simple,
modern, and effective method for building a single topic model with sentiment
analysis capable of covering multiple languages simultanteously, based on a
pre-trained state-of-the-art deep neural network for natural language
understanding. To demonstrate its feasibility, we apply the model to newspaper
articles and user comments of a specific domain, i.e., organic food products
and related consumption behavior. The themes match across languages.
Additionally, we obtain an high proportion of stable and domain-relevant
topics, a meaningful relation between topics and their respective textual
contents, and an interpretable representation for social media documents.
Marketing can potentially benefit from our method, since it provides an
easy-to-use means of addressing specific customer interests from different
market regions around the globe. For reproducibility, we provide the code,
data, and results of our study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Annotator Bias Approximation on Crowdsourced Single-Label Sentiment Analysis. (arXiv:2111.02326v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.02326">
<div class="article-summary-box-inner">
<span><p>Sentiment analysis is often a crowdsourcing task prone to subjective labels
given by many annotators. It is not yet fully understood how the annotation
bias of each annotator can be modeled correctly with state-of-the-art methods.
However, resolving annotator bias precisely and reliably is the key to
understand annotators' labeling behavior and to successfully resolve
corresponding individual misconceptions and wrongdoings regarding the
annotation task. Our contribution is an explanation and improvement for precise
neural end-to-end bias modeling and ground truth estimation, which reduces an
undesired mismatch in that regard of the existing state-of-the-art.
Classification experiments show that it has potential to improve accuracy in
cases where each sample is annotated only by one single annotator. We provide
the whole source code publicly and release an own domain-specific sentiment
dataset containing 10,000 sentences discussing organic food products. These are
crawled from social media and are singly labeled by 10 non-expert annotators.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-Referential Games to Learn Compositional Learning Behaviours. (arXiv:2207.08012v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.08012">
<div class="article-summary-box-inner">
<span><p>Human beings use compositionality to generalise from past experiences to
novel experiences. We assume a separation of our experiences into fundamental
atomic components that can be recombined in novel ways to support our ability
to engage with novel experiences. We frame this as the ability to learn to
generalise compositionally, and we will refer to behaviours making use of this
ability as compositional learning behaviours (CLBs). A central problem to
learning CLBs is the resolution of a binding problem (BP). While it is another
feat of intelligence that human beings perform with ease, it is not the case
for state-of-the-art artificial agents. Thus, in order to build artificial
agents able to collaborate with human beings, we propose to develop a novel
benchmark to investigate agents' abilities to exhibit CLBs by solving a
domain-agnostic version of the BP. We take inspiration from the language
emergence and grounding framework of referential games and propose a
meta-learning extension of referential games, entitled Meta-Referential Games,
and use this framework to build our benchmark, that we name Symbolic Behaviour
Benchmark (S2B). We provide baseline results showing that our benchmark is a
compelling challenge that we hope will spur the research community towards
developing more capable artificial agents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revision Transformers: Instructing Language Models to Change their Values. (arXiv:2210.10332v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10332">
<div class="article-summary-box-inner">
<span><p>Current transformer language models (LM) are large-scale models with billions
of parameters. They have been shown to provide high performances on a variety
of tasks but are also prone to shortcut learning and bias. Addressing such
incorrect model behavior via parameter adjustments is very costly. This is
particularly problematic for updating dynamic concepts, such as moral values,
which vary culturally or interpersonally. In this work, we question the current
common practice of storing all information in the model parameters and propose
the Revision Transformer (RiT) to facilitate easy model updating. The specific
combination of a large-scale pre-trained LM that inherently but also diffusely
encodes world knowledge with a clear-structured revision engine makes it
possible to update the model's knowledge with little effort and the help of
user interaction. We exemplify RiT on a moral dataset and simulate user
feedback demonstrating strong performance in model revision even with small
data. This way, users can easily design a model regarding their preferences,
paving the way for more transparent AI models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Concept Algebra for Score-Based Conditional Models. (arXiv:2302.03693v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03693">
<div class="article-summary-box-inner">
<span><p>This paper concerns the structure of learned representations in text-guided
generative models, focusing on score-based models. Here, we focus on the idea
that concepts are encoded as subspaces (or directions) of some representation
space. We develop a mathematical formalization of this idea.Using this
formalism, we show there's a natural choice of representation with this
property, and we develop a simple method for identifying the part of the
representation corresponding to a given concept. In particular, this allows us
to manipulate the concepts expressed by the model through algebraic
manipulation of the representation. We demonstrate the idea with examples
text-guided image generation, using Stable Diffusion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stabilizing Transformer Training by Preventing Attention Entropy Collapse. (arXiv:2303.06296v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.06296">
<div class="article-summary-box-inner">
<span><p>Training stability is of great importance to Transformers. In this work, we
investigate the training dynamics of Transformers by examining the evolution of
the attention layers. In particular, we track the attention entropy for each
attention head during the course of training, which is a proxy for model
sharpness. We identify a common pattern across different architectures and
tasks, where low attention entropy is accompanied by high training instability,
which can take the form of oscillating loss or divergence. We denote the
pathologically low attention entropy, corresponding to highly concentrated
attention scores, as $\textit{entropy collapse}$. As a remedy, we propose
$\sigma$Reparam, a simple and efficient solution where we reparametrize all
linear layers with spectral normalization and an additional learned scalar. We
demonstrate that $\sigma$Reparam successfully prevents entropy collapse in the
attention layers, promoting more stable training. Additionally, we prove a
tight lower bound of the attention entropy, which decreases exponentially fast
with the spectral norm of the attention logits, providing additional motivation
for our approach. We conduct experiments with $\sigma$Reparam on image
classification, image self-supervised learning, machine translation, speech
recognition, and language modeling tasks. We show that $\sigma$Reparam provides
stability and robustness with respect to the choice of hyperparameters, going
so far as enabling training (a) a Vision Transformer {to competitive
performance} without warmup, weight decay, layer normalization or adaptive
optimizers; (b) deep architectures in machine translation and (c) speech
recognition to competitive performance without warmup and adaptive optimizers.
Code is available at \url{https://github.com/apple/ml-sigma-reparam}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DataComp: In search of the next generation of multimodal datasets. (arXiv:2304.14108v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.14108">
<div class="article-summary-box-inner">
<span><p>Multimodal datasets are a critical component in recent breakthroughs such as
Stable Diffusion and GPT-4, yet their design does not receive the same research
attention as model architectures or training algorithms. To address this
shortcoming in the ML ecosystem, we introduce DataComp, a testbed for dataset
experiments centered around a new candidate pool of 12.8 billion image-text
pairs from Common Crawl. Participants in our benchmark design new filtering
techniques or curate new data sources and then evaluate their new dataset by
running our standardized CLIP training code and testing the resulting model on
38 downstream test sets. Our benchmark consists of multiple compute scales
spanning four orders of magnitude, which enables the study of scaling trends
and makes the benchmark accessible to researchers with varying resources. Our
baseline experiments show that the DataComp workflow leads to better training
sets. In particular, our best baseline, DataComp-1B, enables training a CLIP
ViT-L/14 from scratch to 79.2% zero-shot accuracy on ImageNet, outperforming
OpenAI's CLIP ViT-L/14 by 3.7 percentage points while using the same training
procedure and compute. We release DataComp and all accompanying code at
www.datacomp.ai.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpretable Word Sense Representations via Definition Generation: The Case of Semantic Change Analysis. (arXiv:2305.11993v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11993">
<div class="article-summary-box-inner">
<span><p>We propose using automatically generated natural language definitions of
contextualised word usages as interpretable word and word sense
representations. Given a collection of usage examples for a target word, and
the corresponding data-driven usage clusters (i.e., word senses), a definition
is generated for each usage with a specialised Flan-T5 language model, and the
most prototypical definition in a usage cluster is chosen as the sense label.
</p>
<p>We demonstrate how the resulting sense labels can make existing approaches to
semantic change analysis more interpretable, and how they can allow users --
historical linguists, lexicographers, or social scientists -- to explore and
intuitively explain diachronic trajectories of word meaning. Semantic change
analysis is only one of many possible applications of the `definitions as
representations' paradigm. Beyond being human-readable, contextualised
definitions also outperform token or usage sentence embeddings in
word-in-context semantic similarity judgements, making them a new promising
type of lexical representation for NLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NormBank: A Knowledge Bank of Situational Social Norms. (arXiv:2305.17008v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17008">
<div class="article-summary-box-inner">
<span><p>We present NormBank, a knowledge bank of 155k situational norms. This
resource is designed to ground flexible normative reasoning for interactive,
assistive, and collaborative AI systems. Unlike prior commonsense resources,
NormBank grounds each inference within a multivalent sociocultural frame, which
includes the setting (e.g., restaurant), the agents' contingent roles (waiter,
customer), their attributes (age, gender), and other physical, social, and
cultural constraints (e.g., the temperature or the country of operation). In
total, NormBank contains 63k unique constraints from a taxonomy that we
introduce and iteratively refine here. Constraints then apply in different
combinations to frame social norms. Under these manipulations, norms are
non-monotonic - one can cancel an inference by updating its frame even
slightly. Still, we find evidence that neural models can help reliably extend
the scope and coverage of NormBank. We further demonstrate the utility of this
resource with a series of transfer experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale. (arXiv:2306.00017v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00017">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have achieved a milestone that undenia-bly
changed many held beliefs in artificial intelligence (AI). However, there
remains many limitations of these LLMs when it comes to true language
understanding, limitations that are a byproduct of the under-lying architecture
of deep neural networks. Moreover, and due to their subsymbolic nature,
whatever knowledge these models acquire about how language works will always be
buried in billions of microfeatures (weights), none of which is meaningful on
its own, making such models hopelessly unexplainable. To address these
limitations, we suggest com-bining the strength of symbolic representations
with what we believe to be the key to the success of LLMs, namely a successful
bottom-up re-verse engineering of language at scale. As such we argue for a
bottom-up reverse engineering of language in a symbolic setting. Hints on what
this project amounts to have been suggested by several authors, and we discuss
in some detail here how this project could be accomplished.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative User-Experience Research for Developing Domain-specific Natural Language Processing Applications. (arXiv:2306.16143v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.16143">
<div class="article-summary-box-inner">
<span><p>User experience (UX) is a part of human-computer interaction (HCI) research
and focuses on increasing intuitiveness, transparency, simplicity, and trust
for system users. Most of the UX research for machine learning (ML) or natural
language processing (NLP) focuses on a data-driven methodology, i.e., it fails
to focus on users' requirements, and engages domain users mainly for usability
evaluation. Moreover, more typical UX methods tailor the systems towards user
usability, unlike learning about the user needs first. The paper proposes a
methodology for integrating generative UX research into developing domain NLP
applications. Generative UX research employs domain users at the initial stages
of prototype development, i.e., ideation and concept evaluation, and the last
stage for evaluating the change in user value. In the case study, we report the
full-cycle prototype development of a domain-specific semantic search for daily
operations in the process industry. Our case study shows that involving domain
experts increases their interest and trust in the final NLP application.
Moreover, we show that synergetic UX+NLP research efficiently considers data-
and user-driven opportunities and constraints, which can be crucial for NLP
applications in narrow domains
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models. (arXiv:2307.08303v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.08303">
<div class="article-summary-box-inner">
<span><p>Dense retrieval (DR) converts queries and documents into dense embeddings and
measures the similarity between queries and documents in vector space. One of
the challenges in DR is the lack of domain-specific training data. While DR
models can learn from large-scale public datasets like MS MARCO through
transfer learning, evidence shows that not all DR models and domains can
benefit from transfer learning equally. Recently, some researchers have
resorted to large language models (LLMs) to improve the zero-shot and few-shot
DR models. However, the hard prompts or human-written prompts utilized in these
works cannot guarantee the good quality of generated weak queries. To tackle
this, we propose soft prompt tuning for augmenting DR (SPTAR): For each task,
we leverage soft prompt-tuning to optimize a task-specific soft prompt on
limited ground truth data and then prompt the LLMs to tag unlabeled documents
with weak queries, yielding enough weak document-query pairs to train
task-specific dense retrievers. We design a filter to select high-quality
example document-query pairs in the prompt to further improve the quality of
weak tagged queries. To the best of our knowledge, there is no prior work
utilizing soft prompt tuning to augment DR models. The experiments demonstrate
that SPTAR outperforms the unsupervised baselines BM25 and the recently
proposed LLMs-based augmentation method for DR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Retentive Network: A Successor to Transformer for Large Language Models. (arXiv:2307.08621v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.08621">
<div class="article-summary-box-inner">
<span><p>In this work, we propose Retentive Network (RetNet) as a foundation
architecture for large language models, simultaneously achieving training
parallelism, low-cost inference, and good performance. We theoretically derive
the connection between recurrence and attention. Then we propose the retention
mechanism for sequence modeling, which supports three computation paradigms,
i.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel
representation allows for training parallelism. The recurrent representation
enables low-cost $O(1)$ inference, which improves decoding throughput, latency,
and GPU memory without sacrificing performance. The chunkwise recurrent
representation facilitates efficient long-sequence modeling with linear
complexity, where each chunk is encoded parallelly while recurrently
summarizing the chunks. Experimental results on language modeling show that
RetNet achieves favorable scaling results, parallel training, low-cost
deployment, and efficient inference. The intriguing properties make RetNet a
strong successor to Transformer for large language models. Code will be
available at https://aka.ms/retnet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus. (arXiv:2307.11760v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11760">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have achieved significant performance in many
fields such as reasoning, language understanding, and math problem-solving, and
are regarded as a crucial step to artificial general intelligence (AGI).
However, the sensitivity of LLMs to prompts remains a major bottleneck for
their daily adoption. In this paper, we take inspiration from psychology and
propose EmotionPrompt to explore emotional intelligence to enhance the
performance of LLMs. EmotionPrompt operates on a remarkably straightforward
principle: the incorporation of emotional stimulus into prompts. Experimental
results demonstrate that our EmotionPrompt, using the same single prompt
templates, significantly outperforms original zero-shot prompt and
Zero-shot-CoT on 8 tasks with diverse models: ChatGPT, Vicuna-13b, Bloom, and
T5. Further, EmotionPrompt was observed to improve both truthfulness and
informativeness. We believe that EmotionPrompt heralds a novel avenue for
exploring interdisciplinary knowledge for humans-LLMs interaction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Question Decomposition Improves the Faithfulness of Model-Generated Reasoning. (arXiv:2307.11768v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11768">
<div class="article-summary-box-inner">
<span><p>As large language models (LLMs) perform more difficult tasks, it becomes
harder to verify the correctness and safety of their behavior. One approach to
help with this issue is to prompt LLMs to externalize their reasoning, e.g., by
having them generate step-by-step reasoning as they answer a question
(Chain-of-Thought; CoT). The reasoning may enable us to check the process that
models use to perform tasks. However, this approach relies on the stated
reasoning faithfully reflecting the model's actual reasoning, which is not
always the case. To improve over the faithfulness of CoT reasoning, we have
models generate reasoning by decomposing questions into subquestions.
Decomposition-based methods achieve strong performance on question-answering
tasks, sometimes approaching that of CoT while improving the faithfulness of
the model's stated reasoning on several recently-proposed metrics. By forcing
the model to answer simpler subquestions in separate contexts, we greatly
increase the faithfulness of model-generated reasoning over CoT, while still
achieving some of the performance gains of CoT. Our results show it is possible
to improve the faithfulness of model-generated reasoning; continued
improvements may lead to reasoning that enables us to verify the correctness
and safety of LLM behavior.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RRAML: Reinforced Retrieval Augmented Machine Learning. (arXiv:2307.12798v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.12798">
<div class="article-summary-box-inner">
<span><p>The emergence of large language models (LLMs) has revolutionized machine
learning and related fields, showcasing remarkable abilities in comprehending,
generating, and manipulating human language. However, their conventional usage
through API-based text prompt submissions imposes certain limitations in terms
of context constraints and external source availability. To address these
challenges, we propose a novel framework called Reinforced Retrieval Augmented
Machine Learning (RRAML). RRAML integrates the reasoning capabilities of LLMs
with supporting information retrieved by a purpose-built retriever from a vast
user-provided database. By leveraging recent advancements in reinforcement
learning, our method effectively addresses several critical challenges.
Firstly, it circumvents the need for accessing LLM gradients. Secondly, our
method alleviates the burden of retraining LLMs for specific tasks, as it is
often impractical or impossible due to restricted access to the model and the
computational intensity involved. Additionally we seamlessly link the
retriever's task with the reasoner, mitigating hallucinations and reducing
irrelevant, and potentially damaging retrieved documents. We believe that the
research agenda outlined in this paper has the potential to profoundly impact
the field of AI, democratizing access to and utilization of LLMs for a wide
range of entities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Corrections of Zipf's and Heaps' Laws Derived from Hapax Rate Models. (arXiv:2307.12896v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.12896">
<div class="article-summary-box-inner">
<span><p>The article introduces corrections to Zipf's and Heaps' laws based on
systematic models of the hapax rate. The derivation rests on two assumptions:
The first one is the standard urn model which predicts that marginal frequency
distributions for shorter texts look as if word tokens were sampled blindly
from a given longer text. The second assumption posits that the rate of hapaxes
is a simple function of the text size. Four such functions are discussed: the
constant model, the Davis model, the linear model, and the logistic model. It
is shown that the logistic model yields the best fit.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-07-26 23:10:32.157311277 UTC">2023-07-26 23:10:32 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>