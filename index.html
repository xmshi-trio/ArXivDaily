<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-08-03T01:30:00Z">08-03</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">The Bias Amplification Paradox in Text-to-Image Generation. (arXiv:2308.00755v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.00755">
<div class="article-summary-box-inner">
<span><p>Bias amplification is a phenomenon in which models increase imbalances
present in the training data. In this paper, we study bias amplification in the
text-to-image domain using Stable Diffusion by comparing gender ratios in
training vs. generated images. We find that the model appears to amplify
gender-occupation biases found in the training data (LAION). However, we
discover that amplification can largely be attributed to discrepancies between
training captions and model prompts. For example, an inherent difference is
that captions from the training data often contain explicit gender information
while the prompts we use do not, which leads to a distribution shift and
consequently impacts bias measures. Once we account for various distributional
differences between texts used for training and generation, we observe that
amplification decreases considerably. Our findings illustrate the challenges of
comparing biases in models and the data they are trained on, and highlight
confounding factors that contribute to bias amplification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Contrastive BERT Fine-tuning for Fusion-based Reviewed-Item Retrieval. (arXiv:2308.00762v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.00762">
<div class="article-summary-box-inner">
<span><p>As natural language interfaces enable users to express increasingly complex
natural language queries, there is a parallel explosion of user review content
that can allow users to better find items such as restaurants, books, or movies
that match these expressive queries. While Neural Information Retrieval (IR)
methods have provided state-of-the-art results for matching queries to
documents, they have not been extended to the task of Reviewed-Item Retrieval
(RIR), where query-review scores must be aggregated (or fused) into item-level
scores for ranking. In the absence of labeled RIR datasets, we extend Neural IR
methodology to RIR by leveraging self-supervised methods for contrastive
learning of BERT embeddings for both queries and reviews. Specifically,
contrastive learning requires a choice of positive and negative samples, where
the unique two-level structure of our item-review data combined with meta-data
affords us a rich structure for the selection of these samples. For contrastive
learning in a Late Fusion scenario, we investigate the use of positive review
samples from the same item and/or with the same rating, selection of hard
positive samples by choosing the least similar reviews from the same anchor
item, and selection of hard negative samples by choosing the most similar
reviews from different items. We also explore anchor sub-sampling and
augmenting with meta-data. For a more end-to-end Early Fusion approach, we
introduce contrastive item embedding learning to fuse reviews into single item
embeddings. Experimental results show that Late Fusion contrastive learning for
Neural RIR outperforms all other contrastive IR configurations, Neural IR, and
sparse retrieval baselines, thus demonstrating the power of exploiting the
two-level structure in Neural RIR approaches as well as the importance of
preserving the nuance of individual review content via Late Fusion methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GRDD: A Dataset for Greek Dialectal NLP. (arXiv:2308.00802v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.00802">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a dataset for the computational study of a number
of Modern Greek dialects. It consists of raw text data from four dialects of
Modern Greek, Cretan, Pontic, Northern Greek and Cypriot Greek. The dataset is
of considerable size, albeit imbalanced, and presents the first attempt to
create large scale dialectal resources of this type for Modern Greek dialects.
We then use the dataset to perform dialect idefntification. We experiment with
traditional ML algorithms, as well as simple DL architectures. The results show
very good performance on the task, potentially revealing that the dialects in
question have distinct enough characteristics allowing even simple ML models to
perform well on the task. Error analysis is performed for the top performing
algorithms showing that in a number of cases the errors are due to insufficient
dataset cleaning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiactTOD: Learning Generalizable Latent Dialogue Acts for Controllable Task-Oriented Dialogue Systems. (arXiv:2308.00878v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.00878">
<div class="article-summary-box-inner">
<span><p>Dialogue act annotations are important to improve response generation quality
in task-oriented dialogue systems. However, it can be challenging to use
dialogue acts to control response generation in a generalizable way because
different datasets and tasks may have incompatible annotations. While
alternative methods that utilize latent action spaces or reinforcement learning
do not require explicit annotations, they may lack interpretability or face
difficulties defining task-specific rewards. In this work, we present a novel
end-to-end latent dialogue act model (DiactTOD) that represents dialogue acts
in a latent space. DiactTOD, when pre-trained on a large corpus, is able to
predict and control dialogue acts to generate controllable responses using
these latent representations in a zero-shot fashion. Our approach demonstrates
state-of-the-art performance across a wide range of experimental settings on
the MultiWOZ dataset, including zero-shot, few-shot, and full data fine-tuning
with both end-to-end and policy optimization configurations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feature-aware conditional GAN for category text generation. (arXiv:2308.00939v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.00939">
<div class="article-summary-box-inner">
<span><p>Category text generation receives considerable attentions since it is
beneficial for various natural language processing tasks. Recently, the
generative adversarial network (GAN) has attained promising performance in text
generation, attributed to its adversarial training process. However, there are
several issues in text GANs, including discreteness, training instability, mode
collapse, lack of diversity and controllability etc. To address these issues,
this paper proposes a novel GAN framework, the feature-aware conditional GAN
(FA-GAN), for controllable category text generation. In FA-GAN, the generator
has a sequence-to-sequence structure for improving sentence diversity, which
consists of three encoders including a special feature-aware encoder and a
category-aware encoder, and one relational-memory-core-based decoder with the
Gumbel SoftMax activation function. The discriminator has an additional
category classification head. To generate sentences with specified categories,
the multi-class classification loss is supplemented in the adversarial
training. Comprehensive experiments have been conducted, and the results show
that FA-GAN consistently outperforms 10 state-of-the-art text generation
approaches on 6 text classification datasets. The case study demonstrates that
the synthetic sentences generated by FA-GAN can match the required categories
and are aware of the features of conditioned sentences, with good readability,
fluency, and text authenticity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teaching Smaller Language Models To Generalise To Unseen Compositional Questions. (arXiv:2308.00946v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.00946">
<div class="article-summary-box-inner">
<span><p>We equip a smaller Language Model to generalise to answering challenging
compositional questions that have not been seen in training. To do so we
propose a combination of multitask supervised pretraining on up to 93 tasks
designed to instill diverse reasoning abilities, and a dense retrieval system
that aims to retrieve a set of evidential paragraph fragments. Recent progress
in question-answering has been achieved either through prompting methods
against very large pretrained Language Models in zero or few-shot fashion, or
by fine-tuning smaller models, sometimes in conjunction with information
retrieval. We focus on the less explored question of the extent to which
zero-shot generalisation can be enabled in smaller models with retrieval
against a corpus within which sufficient information to answer a particular
question may not exist. We establish strong baselines in this setting for
diverse evaluation datasets (StrategyQA, CommonsenseQA, IIRC, DROP, Musique and
ARC-DA), and show that performance can be significantly improved by adding
retrieval-augmented training datasets which are designed to expose our models
to a variety of heuristic reasoning strategies such as weighing partial
evidence or ignoring an irrelevant context.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SALTTS: Leveraging Self-Supervised Speech Representations for improved Text-to-Speech Synthesis. (arXiv:2308.01018v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01018">
<div class="article-summary-box-inner">
<span><p>While FastSpeech2 aims to integrate aspects of speech such as pitch, energy,
and duration as conditional inputs, it still leaves scope for richer
representations. As a part of this work, we leverage representations from
various Self-Supervised Learning (SSL) models to enhance the quality of the
synthesized speech. In particular, we pass the FastSpeech2 encoder's
length-regulated outputs through a series of encoder layers with the objective
of reconstructing the SSL representations. In the SALTTS-parallel
implementation, the representations from this second encoder are used for an
auxiliary reconstruction loss with the SSL features. The SALTTS-cascade
implementation, however, passes these representations through the decoder in
addition to having the reconstruction loss. The richness of speech
characteristics from the SSL features reflects in the output speech quality,
with the objective and subjective evaluation measures of the proposed approach
outperforming the baseline FastSpeech2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chat Translation Error Detection for Assisting Cross-lingual Communications. (arXiv:2308.01044v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01044">
<div class="article-summary-box-inner">
<span><p>In this paper, we describe the development of a communication support system
that detects erroneous translations to facilitate crosslingual communications
due to the limitations of current machine chat translation methods. We trained
an error detector as the baseline of the system and constructed a new
Japanese-English bilingual chat corpus, BPersona-chat, which comprises
multiturn colloquial chats augmented with crowdsourced quality ratings. The
error detector can serve as an encouraging foundation for more advanced
erroneous translation detection systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Few-Shot Data Augmentation and Waterfall Prompting for Response Generation. (arXiv:2308.01080v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01080">
<div class="article-summary-box-inner">
<span><p>This paper discusses our approaches for task-oriented conversational
modelling using subjective knowledge, with a particular emphasis on response
generation. Our methodology was shaped by an extensive data analysis that
evaluated key factors such as response length, sentiment, and dialogue acts
present in the provided dataset. We used few-shot learning to augment the data
with newly generated subjective knowledge items and present three approaches
for DSTC11: (1) task-specific model exploration, (2) incorporation of the most
frequent question into all generated responses, and (3) a waterfall prompting
technique using a combination of both GPT-3 and ChatGPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Generic: Enhancing Image Captioning with Real-World Knowledge using Vision-Language Pre-Training Model. (arXiv:2308.01126v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01126">
<div class="article-summary-box-inner">
<span><p>Current captioning approaches tend to generate correct but "generic"
descriptions that lack real-world knowledge, e.g., named entities and
contextual information. Considering that Vision-Language Pre-Training (VLP)
models master massive such knowledge from large-scale web-harvested data, it is
promising to utilize the generalizability of VLP models to incorporate
knowledge into image descriptions. However, using VLP models faces challenges:
zero-shot inference suffers from knowledge hallucination that leads to
low-quality descriptions, but the generic bias in downstream task fine-tuning
hinders the VLP model from expressing knowledge. To address these concerns, we
propose a simple yet effective method called Knowledge-guided Replay
(K-Replay), which enables the retention of pre-training knowledge during
fine-tuning. Our approach consists of two parts: (1) a knowledge prediction
task on automatically collected replay exemplars to continuously awaken the VLP
model's memory about knowledge, thus preventing the model from collapsing into
the generic pattern; (2) a knowledge distillation constraint to improve the
faithfulness of generated descriptions hence alleviating the knowledge
hallucination. To evaluate knowledge-enhanced descriptions, we construct a
novel captioning benchmark KnowCap, containing knowledge of landmarks, famous
brands, special foods and movie characters. Experimental results show that our
approach effectively incorporates knowledge into descriptions, outperforming
strong VLP baseline by 20.9 points (78.7-&gt;99.6) in CIDEr score and 20.5
percentage points (34.0%-&gt;54.5%) in knowledge recognition accuracy. Our code
and data is available at https://github.com/njucckevin/KnowCap.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ADS-Cap: A Framework for Accurate and Diverse Stylized Captioning with Unpaired Stylistic Corpora. (arXiv:2308.01143v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01143">
<div class="article-summary-box-inner">
<span><p>Generating visually grounded image captions with specific linguistic styles
using unpaired stylistic corpora is a challenging task, especially since we
expect stylized captions with a wide variety of stylistic patterns. In this
paper, we propose a novel framework to generate Accurate and Diverse Stylized
Captions (ADS-Cap). Our ADS-Cap first uses a contrastive learning module to
align the image and text features, which unifies paired factual and unpaired
stylistic corpora during the training process. A conditional variational
auto-encoder is then used to automatically memorize diverse stylistic patterns
in latent space and enhance diversity through sampling. We also design a simple
but effective recheck module to boost style accuracy by filtering
style-specific captions. Experimental results on two widely used stylized image
captioning datasets show that regarding consistency with the image, style
accuracy and diversity, ADS-Cap achieves outstanding performances compared to
various baselines. We finally conduct extensive analyses to understand the
effectiveness of our method. Our code is available at
https://github.com/njucckevin/ADS-Cap.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Arithmetic with Language Models: from Memorization to Computation. (arXiv:2308.01154v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01154">
<div class="article-summary-box-inner">
<span><p>A better understanding of the emergent computation and problem-solving
capabilities of recent large language models is of paramount importance to
further improve them and broaden their applicability. This work investigates
how a language model, trained to predict the next token, can perform arithmetic
computations generalizing beyond training data. Binary addition and
multiplication constitute a good testbed for this purpose, since they require a
very small vocabulary and exhibit relevant input/output discontinuities making
smooth input interpolation ineffective for novel data. We successfully trained
a light language model to learn these tasks and ran a number of experiments to
investigate the extrapolation capabilities and internal information processing.
Our findings support the hypotheses that the language model works as an
Encoding-Regression-Decoding machine where the computation takes place in the
value space once the input token representation is mapped to an appropriate
internal representation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analysing the Resourcefulness of the Paragraph for Precedence Retrieval. (arXiv:2308.01203v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01203">
<div class="article-summary-box-inner">
<span><p>Developing methods for extracting relevant legal information to aid legal
practitioners is an active research area. In this regard, research efforts are
being made by leveraging different kinds of information, such as meta-data,
citations, keywords, sentences, paragraphs, etc. Similar to any text document,
legal documents are composed of paragraphs. In this paper, we have analyzed the
resourcefulness of paragraph-level information in capturing similarity among
judgments for improving the performance of precedence retrieval. We found that
the paragraph-level methods could capture the similarity among the judgments
with only a few paragraph interactions and exhibit more discriminating power
over the baseline document-level method. Moreover, the comparison results on
two benchmark datasets for the precedence retrieval on the Indian supreme court
judgments task show that the paragraph-level methods exhibit comparable
performance with the state-of-the-art methods
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Global Hierarchical Neural Networks using Hierarchical Softmax. (arXiv:2308.01210v1 [stat.ML])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01210">
<div class="article-summary-box-inner">
<span><p>This paper presents a framework in which hierarchical softmax is used to
create a global hierarchical classifier. The approach is applicable for any
classification task where there is a natural hierarchy among classes. We show
empirical results on four text classification datasets. In all datasets the
hierarchical softmax improved on the regular softmax used in a flat classifier
in terms of macro-F1 and macro-recall. In three out of four datasets
hierarchical softmax achieved a higher micro-accuracy and macro-precision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Multilingual Language Models Think Better in English?. (arXiv:2308.01223v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01223">
<div class="article-summary-box-inner">
<span><p>Translate-test is a popular technique to improve the performance of
multilingual language models. This approach works by translating the input into
English using an external machine translation system, and running inference
over the translated input. However, these improvements can be attributed to the
use of a separate translation system, which is typically trained on large
amounts of parallel data not seen by the language model. In this work, we
introduce a new approach called self-translate, which overcomes the need of an
external translation system by leveraging the few-shot translation capabilities
of multilingual language models. Experiments over 5 tasks show that
self-translate consistently outperforms direct inference, demonstrating that
language models are unable to leverage their full multilingual potential when
prompted in non-English languages. Our code is available at
https://github.com/juletx/self-translate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grounded Image Text Matching with Mismatched Relation Reasoning. (arXiv:2308.01236v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01236">
<div class="article-summary-box-inner">
<span><p>This paper introduces Grounded Image Text Matching with Mismatched Relation
(GITM-MR), a novel visual-linguistic joint task that evaluates the relation
understanding capabilities of transformer-based pre-trained models. GITM-MR
requires a model to first determine if an expression describes an image, then
localize referred objects or ground the mismatched parts of the text. We
provide a benchmark for evaluating pre-trained models on this task, with a
focus on the challenging settings of limited data and out-of-distribution
sentence lengths. Our evaluation demonstrates that pre-trained models lack data
efficiency and length generalization ability. To address this, we propose the
Relation-sensitive Correspondence Reasoning Network (RCRN), which incorporates
relation-aware reasoning via bi-directional message propagation guided by
language structure. RCRN can be interpreted as a modular program and delivers
strong performance in both length generalization and data efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation. (arXiv:2308.01240v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01240">
<div class="article-summary-box-inner">
<span><p>In this work, we evaluate 10 open-source instructed LLMs on four
representative code comprehension and generation tasks. We have the following
main findings. First, for the zero-shot setting, instructed LLMs are very
competitive on code comprehension and generation tasks and sometimes even
better than small SOTA models specifically fine-tuned on each downstream task.
We also find that larger instructed LLMs are not always better on code-related
tasks. Second, for the few-shot setting, we find that adding demonstration
examples substantially helps instructed LLMs perform better on most code
comprehension and generation tasks; however, the examples would sometimes
induce unstable or even worse performance. Furthermore, we find widely-used
BM25-based shot selection strategy significantly outperforms the basic random
selection or fixed selection only on generation problems. Third, for the
fine-tuning setting, we find that fine-tuning could further improve the model
performance on downstream code comprehension and generation tasks compared to
the zero-shot/one-shot performance. In addition, after being fine-tuned on the
same downstream task dataset, instructed LLMs outperform both the small SOTA
models and similar-scaled LLMs without instruction tuning. Based on our
findings, we further present practical implications on model and usage
recommendation, performance and cost trade-offs, and future direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models. (arXiv:2308.01263v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01263">
<div class="article-summary-box-inner">
<span><p>Without proper safeguards, large language models will readily follow
malicious instructions and generate toxic content. This motivates safety
efforts such as red-teaming and large-scale feedback learning, which aim to
make models both helpful and harmless. However, there is a tension between
these two objectives, since harmlessness requires models to refuse complying
with unsafe prompts, and thus not be helpful. Recent anecdotal evidence
suggests that some models may have struck a poor balance, so that even clearly
safe prompts are refused if they use similar language to unsafe prompts or
mention sensitive topics. In this paper, we introduce a new test suite called
XSTest to identify such eXaggerated Safety behaviours in a structured and
systematic way. In its current form, XSTest comprises 200 safe prompts across
ten prompt types that well-calibrated models should not refuse to comply with.
We describe XSTest's creation and composition, and use the test suite to
highlight systematic failure modes in a recently-released state-of-the-art
language model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the psychology of GPT-4's Moral and Legal Reasoning. (arXiv:2308.01264v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01264">
<div class="article-summary-box-inner">
<span><p>Large language models have been used as the foundation of highly
sophisticated artificial intelligences, capable of delivering human-like
responses to probes about legal and moral issues. However, these models are
unreliable guides to their own inner workings, and even the engineering teams
behind their creation are unable to explain exactly how they came to develop
all of the capabilities they currently have. The emerging field of machine
psychology seeks to gain insight into the processes and concepts that these
models possess. In this paper, we employ the methods of psychology to probe
into GPT-4's moral and legal reasoning. More specifically, we investigate the
similarities and differences between GPT-4 and humans when it comes to
intentionality ascriptions, judgments about causation, the morality of
deception, moral foundations, the impact of moral luck on legal judgments, the
concept of consent, and rule violation judgments. We find high correlations
between human and AI responses, but also several significant systematic
differences between them. We conclude with a discussion of the philosophical
implications of our findings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?. (arXiv:2308.01284v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01284">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) such as ChatGPT are increasingly being used for
various use cases, including text content generation at scale. Although
detection methods for such AI-generated text exist already, we investigate
ChatGPT's performance as a detector on such AI-generated text, inspired by
works that use ChatGPT as a data labeler or annotator. We evaluate the
zero-shot performance of ChatGPT in the task of human-written vs. AI-generated
text detection, and perform experiments on publicly available datasets. We
empirically investigate if ChatGPT is symmetrically effective in detecting
AI-generated or human-written text. Our findings provide insight on how ChatGPT
and similar LLMs may be leveraged in automated detection pipelines by simply
focusing on solving a specific aspect of the problem and deriving the rest from
that solution. All code and data is available at
\url{https://github.com/AmritaBh/ChatGPT-as-Detector}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes. (arXiv:2308.01313v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01313">
<div class="article-summary-box-inner">
<span><p>CLIP, as a foundational vision language model, is widely used in zero-shot
image classification due to its ability to understand various visual concepts
and natural language descriptions. However, how to fully leverage CLIP's
unprecedented human-like understanding capabilities to achieve better zero-shot
classification is still an open question. This paper draws inspiration from the
human visual perception process: a modern neuroscience view suggests that in
classifying an object, humans first infer its class-independent attributes
(e.g., background and orientation) which help separate the foreground object
from the background, and then make decisions based on this information.
Inspired by this, we observe that providing CLIP with contextual attributes
improves zero-shot classification and mitigates reliance on spurious features.
We also observe that CLIP itself can reasonably infer the attributes from an
image. With these observations, we propose a training-free, two-step zero-shot
classification method named PerceptionCLIP. Given an image, it first infers
contextual attributes (e.g., background) and then performs object
classification conditioning on them. Our experiments show that PerceptionCLIP
achieves better generalization, group robustness, and better interpretability.
For example, PerceptionCLIP with ViT-L/14 improves the worst group accuracy by
16.5% on the Waterbirds dataset and by 3.5% on CelebA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention Is All You Need. (arXiv:1706.03762v7 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1706.03762">
<div class="article-summary-box-inner">
<span><p>The dominant sequence transduction models are based on complex recurrent or
convolutional neural networks in an encoder-decoder configuration. The best
performing models also connect the encoder and decoder through an attention
mechanism. We propose a new simple network architecture, the Transformer, based
solely on attention mechanisms, dispensing with recurrence and convolutions
entirely. Experiments on two machine translation tasks show these models to be
superior in quality while being more parallelizable and requiring significantly
less time to train. Our model achieves 28.4 BLEU on the WMT 2014
English-to-German translation task, improving over the existing best results,
including ensembles by over 2 BLEU. On the WMT 2014 English-to-French
translation task, our model establishes a new single-model state-of-the-art
BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction
of the training costs of the best models from the literature. We show that the
Transformer generalizes well to other tasks by applying it successfully to
English constituency parsing both with large and limited training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DePA: Improving Non-autoregressive Machine Translation with Dependency-Aware Decoder. (arXiv:2203.16266v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.16266">
<div class="article-summary-box-inner">
<span><p>Non-autoregressive machine translation (NAT) models have lower translation
quality than autoregressive translation (AT) models because NAT decoders do not
depend on previous target tokens in the decoder input. We propose a novel and
general Dependency-Aware Decoder (DePA) to enhance target dependency modeling
in the decoder of fully NAT models from two perspectives: decoder
self-attention and decoder input. First, we propose an autoregressive
forward-backward pre-training phase before NAT training, which enables the NAT
decoder to gradually learn bidirectional target dependencies for the final NAT
training. Second, we transform the decoder input from the source language
representation space to the target language representation space through a
novel attentive transformation process, which enables the decoder to better
capture target dependencies. DePA can be applied to any fully NAT models.
Extensive experiments show that DePA consistently improves highly competitive
and state-of-the-art fully NAT models on widely used WMT and IWSLT benchmarks
by up to 1.88 BLEU gain, while maintaining the inference latency comparable to
other fully NAT models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improve Event Extraction via Self-Training with Gradient Guidance. (arXiv:2205.12490v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12490">
<div class="article-summary-box-inner">
<span><p>Data scarcity has been the main factor that hinders the progress of event
extraction. To overcome this issue, we propose a Self-Training with Feedback
(STF) framework that leverages the large-scale unlabeled data and acquires
feedback for each new event prediction from the unlabeled data by comparing it
to the Abstract Meaning Representation (AMR) graph of the same sentence.
Specifically, STF consists of (1) a base event extraction model trained on
existing event annotations and then applied to large-scale unlabeled corpora to
predict new event mentions as pseudo training samples, and (2) a novel scoring
model that takes in each new predicted event trigger, an argument, its argument
role, as well as their paths in the AMR graph to estimate a compatibility score
indicating the correctness of the pseudo label. The compatibility scores
further act as feedback to encourage or discourage the model learning on the
pseudo labels during self-training. Experimental results on three benchmark
datasets, including ACE05-E, ACE05-E+, and ERE, demonstrate the effectiveness
of the STF framework on event extraction, especially event argument extraction,
with significant performance gain over the base event extraction models and
strong baselines. Our experimental analysis further shows that STF is a generic
framework as it can be applied to improve most, if not all, event extraction
models by leveraging large-scale unlabeled data, even when high-quality AMR
graph annotations are not available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mass-Editing Memory in a Transformer. (arXiv:2210.07229v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07229">
<div class="article-summary-box-inner">
<span><p>Recent work has shown exciting promise in updating large language models with
new memories, so as to replace obsolete information or add specialized
knowledge. However, this line of work is predominantly limited to updating
single associations. We develop MEMIT, a method for directly updating a
language model with many memories, demonstrating experimentally that it can
scale up to thousands of associations for GPT-J (6B) and GPT-NeoX (20B),
exceeding prior work by orders of magnitude. Our code and data are at
https://memit.baulab.info.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Syntactic Surprisal From Neural Models Predicts, But Underestimates, Human Processing Difficulty From Syntactic Ambiguities. (arXiv:2210.12187v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12187">
<div class="article-summary-box-inner">
<span><p>Humans exhibit garden path effects: When reading sentences that are
temporarily structurally ambiguous, they slow down when the structure is
disambiguated in favor of the less preferred alternative. Surprisal theory
(Hale, 2001; Levy, 2008), a prominent explanation of this finding, proposes
that these slowdowns are due to the unpredictability of each of the words that
occur in these sentences. Challenging this hypothesis, van Schijndel &amp; Linzen
(2021) find that estimates of the cost of word predictability derived from
language models severely underestimate the magnitude of human garden path
effects. In this work, we consider whether this underestimation is due to the
fact that humans weight syntactic factors in their predictions more highly than
language models do. We propose a method for estimating syntactic predictability
from a language model, allowing us to weigh the cost of lexical and syntactic
predictability independently. We find that treating syntactic predictability
independently from lexical predictability indeed results in larger estimates of
garden path. At the same time, even when syntactic predictability is
independently weighted, surprisal still greatly underestimate the magnitude of
human garden path effects. Our results support the hypothesis that
predictability is not the only factor responsible for the processing cost
associated with garden path sentences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Thinking Fast and Slow in Large Language Models. (arXiv:2212.05206v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.05206">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) are currently at the forefront of intertwining
AI systems with human communication and everyday life. Therefore, it is of
great importance to evaluate their emerging abilities. In this study, we show
that LLMs like GPT-3 exhibit behavior that strikingly resembles human-like
intuition - and the cognitive errors that come with it. However, LLMs with
higher cognitive capabilities, in particular ChatGPT and GPT-4, learned to
avoid succumbing to these errors and perform in a hyperrational manner. For our
experiments, we probe LLMs with the Cognitive Reflection Test (CRT) as well as
semantic illusions that were originally designed to investigate intuitive
decision-making in humans. Our study demonstrates that investigating LLMs with
methods from psychology has the potential to reveal otherwise unknown emergent
traits.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Detecting Harmful Agendas in News Articles. (arXiv:2302.00102v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00102">
<div class="article-summary-box-inner">
<span><p>Manipulated news online is a growing problem which necessitates the use of
automated systems to curtail its spread. We argue that while misinformation and
disinformation detection have been studied, there has been a lack of investment
in the important open challenge of detecting harmful agendas in news articles;
identifying harmful agendas is critical to flag news campaigns with the
greatest potential for real world harm. Moreover, due to real concerns around
censorship, harmful agenda detectors must be interpretable to be effective. In
this work, we propose this new task and release a dataset, NewsAgendas, of
annotated news articles for agenda identification. We show how interpretable
systems can be effective on this task and demonstrate that they can perform
comparably to black-box models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adapting Prompt for Few-shot Table-to-Text Generation. (arXiv:2302.12468v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12468">
<div class="article-summary-box-inner">
<span><p>Pretrained language models (PLMs) have made remarkable progress in
table-to-text generation tasks. However, the lack of domain-specific knowledge
makes it challenging to bridge the topological gap between tabular data and
text, especially in real-world applications with limited resources. To mitigate
the limitation of insufficient labeled data, we propose a novel framework:
Adapt-Prompt-to-Generate (AdaPTGen). The core insight of AdaPTGen is to adapt
prompt templates of domain-specific knowledge into the model, which brings at
least three benefits: (1) it injects representation of normal table-related
descriptions to bridge the topological gap between tabular data and texts; (2)
it enables us to use large amounts of unlabeled domain-specific knowledge
fully, which can alleviate the PLMs' inherent shortcomings of lacking domain
knowledge; (3) it allows us to design various tasks to explore the
domain-specific knowledge. Extensive experiments and analyses are conducted on
three open-domain few-shot natural language generation (NLG) data sets: Humans,
Songs, and Books. Compared to previous state-of-the-art approaches, our model
achieves superior performance in terms of both fluency and accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Technical report: Graph Neural Networks go Grammatical. (arXiv:2303.01590v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01590">
<div class="article-summary-box-inner">
<span><p>This paper proposes a framework to formally link a fragment of an algebraic
language to a Graph Neural Network (GNN). It relies on Context Free Grammars
(CFG) to organise algebraic operations into generative rules that can be
translated into a GNN layer model. Since the rules and variables of a CFG
directly derived from a language contain redundancies, a grammar reduction
scheme is presented making tractable the translation into a GNN layer. Applying
this strategy, a grammar compliant with the third-order Weisfeiler-Lehman
(3-WL) test is defined from MATLANG. From this 3-WL CFG, we derive a provably
3-WL GNN model called G$^2$N$^2$. Moreover, this grammatical approach allows us
to provide algebraic formulas to count the cycles of length up to six and
chordal cycles at the edge level, which enlightens the counting power of 3-WL.
Several experiments illustrate that G$^2$N$^2$ efficiently outperforms other
3-WL GNNs on many downstream tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models are Strong Zero-Shot Retriever. (arXiv:2304.14233v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.14233">
<div class="article-summary-box-inner">
<span><p>In this work, we propose a simple method that applies a large language model
(LLM) to large-scale retrieval in zero-shot scenarios. Our method, the Language
language model as Retriever (LameR), is built upon no other neural models but
an LLM, while breaking brute-force combinations of retrievers with LLMs and
lifting the performance of zero-shot retrieval to be very competitive on
benchmark datasets. Essentially, we propose to augment a query with its
potential answers by prompting LLMs with a composition of the query and the
query's in-domain candidates. The candidates, regardless of correct or wrong,
are obtained by a vanilla retrieval procedure on the target collection. As a
part of the prompts, they are likely to help LLM generate more precise answers
by pattern imitation or candidate summarization. Even if all the candidates are
wrong, the prompts at least make LLM aware of in-collection patterns and
genres. Moreover, due to the low performance of a self-supervised retriever,
the LLM-based query augmentation becomes less effective as the retriever
bottlenecks the whole pipeline. Therefore, we propose to leverage a
non-parametric lexicon-based method (e.g., BM25) as the retrieval module to
capture query-document overlap in a literal fashion. As such, LameR makes the
retrieval procedure transparent to the LLM, thus circumventing the performance
bottleneck.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Small Language Models on PubMedQA via Generative Data Augmentation. (arXiv:2305.07804v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07804">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have made remarkable advancements in the field
of natural language processing. However, their increasing size poses challenges
in terms of computational cost. On the other hand, Small Language Models (SLMs)
are known for their efficiency, but they often struggle with limited capacity
and training data, especially in specific domains. In this paper, we introduce
a novel method aimed at improving SLMs in the medical domain using LLM-based
generative data augmentation. The objective of our approach is to develop more
efficient and capable models that are specifically tailored for specialized
applications. Through experiments conducted on the PubMedQA dataset, we
demonstrate the effectiveness of LLMs in refining and diversifying existing
question-answer pairs. This refinement process leads to improved performance in
a significantly smaller model after fine-tuning. Notably, our best SLM, with
under 1.6 billion parameters, outperforms the few-shot GPT-4 on the PubMedQA
dataset. Our code and generated data are publicly available to facilitate
further explorations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vistaar: Diverse Benchmarks and Training Sets for Indian Language ASR. (arXiv:2305.15386v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15386">
<div class="article-summary-box-inner">
<span><p>Improving ASR systems is necessary to make new LLM-based use-cases accessible
to people across the globe. In this paper, we focus on Indian languages, and
make the case that diverse benchmarks are required to evaluate and improve ASR
systems for Indian languages. To address this, we collate Vistaar as a set of
59 benchmarks across various language and domain combinations, on which we
evaluate 3 publicly available ASR systems and 2 commercial systems. We also
train IndicWhisper models by fine-tuning the Whisper models on publicly
available training datasets across 12 Indian languages totalling to 10.7K
hours. We show that IndicWhisper significantly improves on considered ASR
systems on the Vistaar benchmark. Indeed, IndicWhisper has the lowest WER in 39
out of the 59 benchmarks, with an average reduction of 4.1 WER. We open-source
all datasets, code and models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CamemBERT-bio: a Tasty French Language Model Better for your Health. (arXiv:2306.15550v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15550">
<div class="article-summary-box-inner">
<span><p>Clinical data in hospitals are increasingly accessible for research through
clinical data warehouses, however these documents are unstructured. It is
therefore necessary to extract information from medical reports to conduct
clinical studies. Transfer learning with BERT-like models such as CamemBERT has
allowed major advances, especially for named entity recognition. However, these
models are trained for plain language and are less efficient on biomedical
data. This is why we propose a new French public biomedical dataset on which we
have continued the pre-training of CamemBERT. Thus, we introduce a first
version of CamemBERT-bio, a specialized public model for the French biomedical
domain that shows 2.54 points of F1 score improvement on average on different
biomedical named entity recognition tasks. Our findings demonstrate the success
of continual pre-training from a French model and contrast with recent
proposals on the same domain and language. One of our key contributions
highlights the importance of using a standard evaluation protocol that enables
a clear view of the current state-of-the-art for French biomedical models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Design of Semantic Similarity Ensembles Using Grammatical Evolution. (arXiv:2307.00925v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.00925">
<div class="article-summary-box-inner">
<span><p>Semantic similarity measures are widely used in natural language processing
to catalyze various computer-related tasks. However, no single semantic
similarity measure is the most appropriate for all tasks, and researchers often
use ensemble strategies to ensure performance. This research work proposes a
method for automatically designing semantic similarity ensembles. In fact, our
proposed method uses grammatical evolution, for the first time, to
automatically select and aggregate measures from a pool of candidates to create
an ensemble that maximizes correlation to human judgment. The method is
evaluated on several benchmark datasets and compared to state-of-the-art
ensembles, showing that it can significantly improve similarity assessment
accuracy and outperform existing methods in some cases. As a result, our
research demonstrates the potential of using grammatical evolution to
automatically compare text and prove the benefits of using ensembles for
semantic similarity tasks. The source code that illustrates our approach can be
downloaded from https://github.com/jorge-martinez-gil/sesige.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03109">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) are gaining increasing popularity in both
academia and industry, owing to their unprecedented performance in various
applications. As LLMs continue to play a vital role in both research and daily
use, their evaluation becomes increasingly critical, not only at the task
level, but also at the society level for better understanding of their
potential risks. Over the past years, significant efforts have been made to
examine LLMs from various perspectives. This paper presents a comprehensive
review of these evaluation methods for LLMs, focusing on three key dimensions:
what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide
an overview from the perspective of evaluation tasks, encompassing general
natural language processing tasks, reasoning, medical usage, ethics,
educations, natural and social sciences, agent applications, and other areas.
Secondly, we answer the `where' and `how' questions by diving into the
evaluation methods and benchmarks, which serve as crucial components in
assessing performance of LLMs. Then, we summarize the success and failure cases
of LLMs in different tasks. Finally, we shed light on several future challenges
that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to
researchers in the realm of LLMs evaluation, thereby aiding the development of
more proficient LLMs. Our key point is that evaluation should be treated as an
essential discipline to better assist the development of LLMs. We consistently
maintain the related open-source materials at:
https://github.com/MLGroupJLU/LLM-eval-survey.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Integrated NPL Approach to Sentiment Analysis in Satisfaction Surveys. (arXiv:2307.11771v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11771">
<div class="article-summary-box-inner">
<span><p>The research project aims to apply an integrated approach to natural language
processing NLP to satisfaction surveys. It will focus on understanding and
extracting relevant information from survey responses, analyzing feelings, and
identifying recurring word patterns. NLP techniques will be used to determine
emotional polarity, classify responses into positive, negative, or neutral
categories, and use opinion mining to highlight participants opinions. This
approach will help identify the most relevant aspects for participants and
understand their opinions in relation to those specific aspects. A key
component of the research project will be the analysis of word patterns in
satisfaction survey responses using NPL. This analysis will provide a deeper
understanding of feelings, opinions, and themes and trends present in
respondents responses. The results obtained from this approach can be used to
identify areas for improvement, understand respondents preferences, and make
strategic decisions based on analysis to improve respondent satisfaction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback. (arXiv:2307.16039v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.16039">
<div class="article-summary-box-inner">
<span><p>A key technology for the development of large language models (LLMs) involves
instruction tuning that helps align the models' responses with human
expectations to realize impressive learning abilities. Two major approaches for
instruction tuning characterize supervised fine-tuning (SFT) and reinforcement
learning from human feedback (RLHF), which are currently applied to produce the
best commercial LLMs (e.g., ChatGPT). To improve the accessibility of LLMs for
research and development efforts, various instruction-tuned open-source LLMs
have also been introduced recently, e.g., Alpaca, Vicuna, to name a few.
However, existing open-source LLMs have only been instruction-tuned for English
and a few popular languages, thus hindering their impacts and accessibility to
many other languages in the world. Among a few very recent work to explore
instruction tuning for LLMs in multiple languages, SFT has been used as the
only approach to instruction-tune LLMs for multiple languages. This has left a
significant gap for fine-tuned LLMs based on RLHF in diverse languages and
raised important questions on how RLHF can boost the performance of
multilingual instruction tuning. To overcome this issue, we present Okapi, the
first system with instruction-tuned LLMs based on RLHF for multiple languages.
Okapi introduces instruction and response-ranked data in 26 diverse languages
to facilitate the experiments and development of future multilingual LLM
research. We also present benchmark datasets to enable the evaluation of
generative LLMs in multiple languages. Our experiments demonstrate the
advantages of RLHF for multilingual instruction over SFT for different base
models and datasets. Our framework and resources are released at
https://github.com/nlp-uoregon/Okapi.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension. (arXiv:2307.16125v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.16125">
<div class="article-summary-box-inner">
<span><p>Based on powerful Large Language Models (LLMs), recent generative Multimodal
Large Language Models (MLLMs) have gained prominence as a pivotal research
area, exhibiting remarkable capability for both comprehension and generation.
In this work, we address the evaluation of generative comprehension in MLLMs as
a preliminary step towards a comprehensive assessment of generative models, by
introducing a benchmark named SEED-Bench. SEED-Bench consists of 19K multiple
choice questions with accurate human annotations (x 6 larger than existing
benchmarks), which spans 12 evaluation dimensions including the comprehension
of both the image and video modality. We develop an advanced pipeline for
generating multiple-choice questions that target specific evaluation
dimensions, integrating both automatic filtering and manual verification
processes. Multiple-choice questions with groundtruth options derived from
human annotation enables an objective and efficient assessment of model
performance, eliminating the need for human or GPT intervention during
evaluation. We further evaluate the performance of 18 models across all 12
dimensions, covering both the spatial and temporal understanding. By revealing
the limitations of existing MLLMs through evaluation results, we aim for
SEED-Bench to provide insights for motivating future research. We will launch
and consistently maintain a leaderboard to provide a platform for the community
to assess and investigate model capability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Private Watermark for Large Language Models. (arXiv:2307.16230v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.16230">
<div class="article-summary-box-inner">
<span><p>Recently, text watermarking algorithms for large language models (LLMs) have
been mitigating the potential harms of text generated by the LLMs, including
fake news and copyright issues. However, the watermark detection of current
text algorithms requires the key from the generation process, making them
susceptible to breaches and counterfeiting. In this work, we propose the first
private watermarking algorithm, which extends the current text watermarking
algorithms by using two different neural networks respectively for watermark
generation and detection, rather than using the same key at both stages.
Meanwhile, part of the parameters of the watermark generation and detection
networks are shared, which makes the detection network achieve a high accuracy
very efficiently. Experiments show that our algorithm ensures high detection
accuracy with minimal impact on generation and detection speed, due to the
small parameter size of both networks. Additionally, our subsequent analysis
demonstrates the difficulty of reverting the watermark generation rules from
the detection network.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLMs4OL: Large Language Models for Ontology Learning. (arXiv:2307.16648v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.16648">
<div class="article-summary-box-inner">
<span><p>We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs)
for Ontology Learning (OL). LLMs have shown significant advancements in natural
language processing, demonstrating their ability to capture complex language
patterns in different knowledge domains. Our LLMs4OL paradigm investigates the
following hypothesis: \textit{Can LLMs effectively apply their language pattern
capturing capability to OL, which involves automatically extracting and
structuring knowledge from natural language text?} To test this hypothesis, we
conduct a comprehensive evaluation using the zero-shot prompting method. We
evaluate nine different LLM model families for three main OL tasks: term
typing, taxonomy discovery, and extraction of non-taxonomic relations.
Additionally, the evaluations encompass diverse genres of ontological
knowledge, including lexicosemantic knowledge in WordNet, geographical
knowledge in GeoNames, and medical knowledge in UMLS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AsdKB: A Chinese Knowledge Base for the Early Screening and Diagnosis of Autism Spectrum Disorder. (arXiv:2307.16773v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.16773">
<div class="article-summary-box-inner">
<span><p>To easily obtain the knowledge about autism spectrum disorder and help its
early screening and diagnosis, we create AsdKB, a Chinese knowledge base on
autism spectrum disorder. The knowledge base is built on top of various
sources, including 1) the disease knowledge from SNOMED CT and ICD-10 clinical
descriptions on mental and behavioural disorders, 2) the diagnostic knowledge
from DSM-5 and different screening tools recommended by social organizations
and medical institutes, and 3) the expert knowledge on professional physicians
and hospitals from the Web. AsdKB contains both ontological and factual
knowledge, and is accessible as Linked Data at https://w3id.org/asdkb/. The
potential applications of AsdKB are question answering, auxiliary diagnosis,
and expert recommendation, and we illustrate them with a prototype which can be
accessed at <a href="http://asdkb.org.cn/.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Semantically Enriched Embeddings for Knowledge Graph Completion. (arXiv:2308.00081v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.00081">
<div class="article-summary-box-inner">
<span><p>Embedding based Knowledge Graph (KG) Completion has gained much attention
over the past few years. Most of the current algorithms consider a KG as a
multidirectional labeled graph and lack the ability to capture the semantics
underlying the schematic information. In a separate development, a vast amount
of information has been captured within the Large Language Models (LLMs) which
has revolutionized the field of Artificial Intelligence. KGs could benefit from
these LLMs and vice versa. This vision paper discusses the existing algorithms
for KG completion based on the variations for generating KG embeddings. It
starts with discussing various KG completion algorithms such as transductive
and inductive link prediction and entity type prediction algorithms. It then
moves on to the algorithms utilizing type information within the KGs, LLMs, and
finally to algorithms capturing the semantics represented in different
description logic axioms. We conclude the paper with a critical reflection on
the current state of work in the community and give recommendations for future
directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ZRIGF: An Innovative Multimodal Framework for Zero-Resource Image-Grounded Dialogue Generation. (arXiv:2308.00400v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.00400">
<div class="article-summary-box-inner">
<span><p>Image-grounded dialogue systems benefit greatly from integrating visual
information, resulting in high-quality response generation. However, current
models struggle to effectively utilize such information in zero-resource
scenarios, mainly due to the disparity between image and text modalities. To
overcome this challenge, we propose an innovative multimodal framework, called
ZRIGF, which assimilates image-grounded information for dialogue generation in
zero-resource situations. ZRIGF implements a two-stage learning strategy,
comprising contrastive pre-training and generative pre-training. Contrastive
pre-training includes a text-image matching module that maps images and texts
into a unified encoded vector space, along with a text-assisted masked image
modeling module that preserves pre-training visual features and fosters further
multimodal feature alignment. Generative pre-training employs a multimodal
fusion module and an information transfer module to produce insightful
responses based on harmonized multimodal representations. Comprehensive
experiments conducted on both text-based and image-grounded dialogue datasets
demonstrate ZRIGF's efficacy in generating contextually pertinent and
informative responses. Furthermore, we adopt a fully zero-resource scenario in
the image-grounded dialogue dataset to demonstrate our framework's robust
generalization capabilities in novel domains. The code is available at
https://github.com/zhangbo-nlp/ZRIGF.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning. (arXiv:2308.00436v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.00436">
<div class="article-summary-box-inner">
<span><p>The recent progress in large language models (LLMs), especially the invention
of chain-of-thoughts (CoT) prompting, makes it possible to solve reasoning
problems. However, even the strongest LLMs are still struggling with more
complicated problems that require non-linear thinking and multi-step reasoning.
In this work, we explore whether LLMs have the ability to recognize their own
errors, without resorting to external resources. In particular, we investigate
whether they can be used to identify individual errors within a step-by-step
reasoning. To this end, we propose a zero-shot verification scheme to recognize
such errors. We then use this verification scheme to improve question-answering
performance, by using it to perform weighted voting on different generated
answers. We test the method on three math datasets-GSM8K, MathQA, and MATH-and
find that it successfully recognizes errors and, in turn, increases final
predictive performance.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-08-03 23:10:48.115675477 UTC">2023-08-03 23:10:48 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>