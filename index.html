<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-01-20T01:30:00Z">01-20</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding and Detecting Hallucinations in Neural Machine Translation via Model Introspection. (arXiv:2301.07779v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07779">
<div class="article-summary-box-inner">
<span><p>Neural sequence generation models are known to "hallucinate", by producing
outputs that are unrelated to the source text. These hallucinations are
potentially harmful, yet it remains unclear in what conditions they arise and
how to mitigate their impact. In this work, we first identify internal model
symptoms of hallucinations by analyzing the relative token contributions to the
generation in contrastive hallucinated vs. non-hallucinated outputs generated
via source perturbations. We then show that these symptoms are reliable
indicators of natural hallucinations, by using them to design a lightweight
hallucination detector which outperforms both model-free baselines and strong
classifiers based on quality estimation or large pre-trained models on manually
annotated English-Chinese and German-English translation test beds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic-aware Contrastive Learning for More Accurate Semantic Parsing. (arXiv:2301.07919v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07919">
<div class="article-summary-box-inner">
<span><p>Since the meaning representations are detailed and accurate annotations which
express fine-grained sequence-level semtantics, it is usually hard to train
discriminative semantic parsers via Maximum Likelihood Estimation (MLE) in an
autoregressive fashion. In this paper, we propose a semantic-aware contrastive
learning algorithm, which can learn to distinguish fine-grained meaning
representations and take the overall sequence-level semantic into
consideration. Specifically, a multi-level online sampling algorithm is
proposed to sample confusing and diverse instances. Three semantic-aware
similarity functions are designed to accurately measure the distance between
meaning representations as a whole. And a ranked contrastive loss is proposed
to pull the representations of the semantic-identical instances together and
push negative instances away. Experiments on two standard datasets show that
our approach achieves significant improvements over MLE baselines and gets
state-of-the-art performances by simply applying semantic-aware contrastive
learning on a vanilla Seq2Seq model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continuously Reliable Detection of New-Normal Misinformation: Semantic Masking and Contrastive Smoothing in High-Density Latent Regions. (arXiv:2301.07981v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07981">
<div class="article-summary-box-inner">
<span><p>Toxic misinformation campaigns have caused significant societal harm, e.g.,
affecting elections and COVID-19 information awareness. Unfortunately, despite
successes of (gold standard) retrospective studies of misinformation that
confirmed their harmful effects after the fact, they arrive too late for timely
intervention and reduction of such harm. By design, misinformation evades
retrospective classifiers by exploiting two properties we call new-normal: (1)
never-seen-before novelty that cause inescapable generalization challenges for
previous classifiers, and (2) massive but short campaigns that end before they
can be manually annotated for new classifier training. To tackle these
challenges, we propose UFIT, which combines two techniques: semantic masking of
strong signal keywords to reduce overfitting, and intra-proxy smoothness
regularization of high-density regions in the latent space to improve
reliability and maintain accuracy. Evaluation of UFIT on public new-normal
misinformation data shows over 30% improvement over existing approaches on
future (and unseen) campaigns. To the best of our knowledge, UFIT is the first
successful effort to achieve such high level of generalization on new-normal
misinformation data with minimal concession (1 to 5%) of accuracy compared to
oracles trained with full knowledge of all campaigns.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Keyword Embeddings for Query Suggestion. (arXiv:2301.08006v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.08006">
<div class="article-summary-box-inner">
<span><p>Nowadays, search engine users commonly rely on query suggestions to improve
their initial inputs. Current systems are very good at recommending lexical
adaptations or spelling corrections to users' queries. However, they often
struggle to suggest semantically related keywords given a user's query. The
construction of a detailed query is crucial in some tasks, such as legal
retrieval or academic search. In these scenarios, keyword suggestion methods
are critical to guide the user during the query formulation. This paper
proposes two novel models for the keyword suggestion task trained on scientific
literature. Our techniques adapt the architecture of Word2Vec and FastText to
generate keyword embeddings by leveraging documents' keyword co-occurrence.
Along with these models, we also present a specially tailored negative sampling
approach that exploits how keywords appear in academic publications. We devise
a ranking-based evaluation methodology following both known-item and ad-hoc
search scenarios. Finally, we evaluate our proposals against the
state-of-the-art word and sentence embedding models showing considerable
improvements over the baselines for the tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Machine Translation with Phrase Pair Injection and Corpus Filtering. (arXiv:2301.08008v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.08008">
<div class="article-summary-box-inner">
<span><p>In this paper, we show that the combination of Phrase Pair Injection and
Corpus Filtering boosts the performance of Neural Machine Translation (NMT)
systems. We extract parallel phrases and sentences from the pseudo-parallel
corpus and augment it with the parallel corpus to train the NMT models. With
the proposed approach, we observe an improvement in the Machine Translation
(MT) system for 3 low-resource language pairs, Hindi-Marathi, English-Marathi,
and English-Pashto, and 6 translation directions by up to 2.7 BLEU points, on
the FLORES test data. These BLEU score improvements are over the models trained
using the whole pseudo-parallel corpus augmented with the parallel corpus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Author as Character and Narrator: Deconstructing Personal Narratives from the r/AmITheAsshole Reddit Community. (arXiv:2301.08104v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.08104">
<div class="article-summary-box-inner">
<span><p>In the r/AmITheAsshole subreddit, people anonymously share first person
narratives that contain some moral dilemma or conflict and ask the community to
judge who is at fault (i.e., who is "the asshole"). In general, first person
narratives are a unique storytelling domain where the author is the narrator
(the person telling the story) but can also be a character (the person living
the story) and, thus, the author has two distinct voices presented in the
story. In this study, we identify linguistic and narrative features associated
with the author as the character or as a narrator. We use these features to
answer the following questions: (1) what makes an asshole character and (2)
what makes an asshole narrator? We extract both Author-as-Character features
(e.g., demographics, narrative event chain, and emotional arc) and
Author-as-Narrator features (i.e., the style and emotion of the story as a
whole) in order to identify which aspects of the narrative are correlated with
the final moral judgment. Our work shows that "assholes" as Characters frame
themselves as lacking agency with a more positive personal arc, while
"assholes" as Narrators will tell emotional and opinionated stories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Embeddings Sometimes Contain Typological Generalizations. (arXiv:2301.08115v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.08115">
<div class="article-summary-box-inner">
<span><p>To what extent can neural network models learn generalizations about language
structure, and how do we find out what they have learned? We explore these
questions by training neural models for a range of natural language processing
tasks on a massively multilingual dataset of Bible translations in 1295
languages. The learned language representations are then compared to existing
typological databases as well as to a novel set of quantitative syntactic and
morphological features obtained through annotation projection. We conclude that
some generalizations are surprisingly close to traditional features from
linguistic typology, but that most of our models, as well as those of previous
work, do not appear to have made linguistically meaningful generalizations.
Careful attention to details in the evaluation turns out to be essential to
avoid false positives. Furthermore, to encourage continued work in this field,
we release several resources covering most or all of the languages in our data:
(i) multiple sets of language representations, (ii) multilingual word
embeddings, (iii) projected and predicted syntactic and morphological features,
(iv) software to provide linguistically sound evaluations of language
representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Cohesive Distillation Architecture for Neural Language Models. (arXiv:2301.08130v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.08130">
<div class="article-summary-box-inner">
<span><p>A recent trend in Natural Language Processing is the exponential growth in
Language Model (LM) size, which prevents research groups without a necessary
hardware infrastructure from participating in the development process. This
study investigates methods for Knowledge Distillation (KD) to provide efficient
alternatives to large-scale models. In this context, KD means extracting
information about language encoded in a Neural Network and Lexical Knowledge
Databases. We developed two methods to test our hypothesis that efficient
architectures can gain knowledge from LMs and extract valuable information from
lexical sources. First, we present a technique to learn confident probability
distribution for Masked Language Modeling by prediction weighting of multiple
teacher networks. Second, we propose a method for Word Sense Disambiguation
(WSD) and lexical KD that is general enough to be adapted to many LMs. Our
results show that KD with multiple teachers leads to improved training
convergence. When using our lexical pre-training method, LM characteristics are
not lost, leading to increased performance in Natural Language Understanding
(NLU) tasks over the state-of-the-art while adding no parameters. Moreover, the
improved semantic understanding of our model increased the task performance
beyond WSD and NLU in a real-problem scenario (Plagiarism Detection). This
study suggests that sophisticated training methods and network architectures
can be superior over scaling trainable parameters. On this basis, we suggest
the research area should encourage the development and use of efficient models
and rate impacts resulting from growing LM size equally against task
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Music Playlist Title Generation Using Artist Information. (arXiv:2301.08145v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.08145">
<div class="article-summary-box-inner">
<span><p>Automatically generating or captioning music playlist titles given a set of
tracks is of significant interest in music streaming services as customized
playlists are widely used in personalized music recommendation, and
well-composed text titles attract users and help their music discovery. We
present an encoder-decoder model that generates a playlist title from a
sequence of music tracks. While previous work takes track IDs as tokenized
input for playlist title generation, we use artist IDs corresponding to the
tracks to mitigate the issue from the long-tail distribution of tracks included
in the playlist dataset. Also, we introduce a chronological data split method
to deal with newly-released tracks in real-world scenarios. Comparing the track
IDs and artist IDs as input sequences, we show that the artist-based approach
significantly enhances the performance in terms of word overlap, semantic
relevance, and diversity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What's happening in your neighborhood? A Weakly Supervised Approach to Detect Local News. (arXiv:2301.08146v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.08146">
<div class="article-summary-box-inner">
<span><p>Local news articles are a subset of news that impact users in a geographical
area, such as a city, county, or state. Detecting local news (Step 1) and
subsequently deciding its geographical location as well as radius of impact
(Step 2) are two important steps towards accurate local news recommendation.
Naive rule-based methods, such as detecting city names from the news title,
tend to give erroneous results due to lack of understanding of the news
content. Empowered by the latest development in natural language processing, we
develop an integrated pipeline that enables automatic local news detection and
content-based local news recommendations. In this paper, we focus on Step 1 of
the pipeline, which highlights: (1) a weakly supervised framework incorporated
with domain knowledge and auto data processing, and (2) scalability to
multi-lingual settings. Compared with Stanford CoreNLP NER model, our pipeline
has higher precision and recall evaluated on a real-world and human-labeled
dataset. This pipeline has potential to more precise local news to users, helps
local businesses get more exposure, and gives people more information about
their neighborhood safety.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI Insights into Theoretical Physics and the Swampland Program: A Journey Through the Cosmos with ChatGPT. (arXiv:2301.08155v1 [physics.pop-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.08155">
<div class="article-summary-box-inner">
<span><p>In this case study, we explore the capabilities and limitations of ChatGPT, a
natural language processing model developed by OpenAI, in the field of string
theoretical swampland conjectures. We find that it is effective at paraphrasing
and explaining concepts in a variety of styles, but not at genuinely connecting
concepts. It will provide false information with full confidence and make up
statements when necessary. However, its ingenious use of language can be
fruitful for identifying analogies and describing visual representations of
abstract concepts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">JCSE: Contrastive Learning of Japanese Sentence Embeddings and Its Applications. (arXiv:2301.08193v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.08193">
<div class="article-summary-box-inner">
<span><p>Contrastive learning is widely used for sentence representation learning.
Despite this prevalence, most studies have focused exclusively on English and
few concern domain adaptation for domain-specific downstream tasks, especially
for low-resource languages like Japanese, which are characterized by
insufficient target domain data and the lack of a proper training strategy. To
overcome this, we propose a novel Japanese sentence representation framework,
JCSE (derived from ``Contrastive learning of Sentence Embeddings for
Japanese''), that creates training data by generating sentences and
synthesizing them with sentences available in a target domain. Specifically, a
pre-trained data generator is finetuned to a target domain using our collected
corpus. It is then used to generate contradictory sentence pairs that are used
in contrastive learning for adapting a Japanese language model to a specific
task in the target domain.
</p>
<p>Another problem of Japanese sentence representation learning is the
difficulty of evaluating existing embedding methods due to the lack of
benchmark datasets. Thus, we establish a comprehensive Japanese Semantic
Textual Similarity (STS) benchmark on which various embedding models are
evaluated. Based on this benchmark result, multiple embedding methods are
chosen and compared with JCSE on two domain-specific tasks, STS in a clinical
domain and information retrieval in an educational domain. The results show
that JCSE achieves significant performance improvement surpassing direct
transfer and other training strategies. This empirically demonstrates JCSE's
effectiveness and practicability for downstream tasks of a low-resource
language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Training Vision Language BERTs with a Unified Conditional Model. (arXiv:2201.02010v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02010">
<div class="article-summary-box-inner">
<span><p>Natural language BERTs are trained with language corpus in a self-supervised
manner. Unlike natural language BERTs, vision language BERTs need paired data
to train, which restricts the scale of VL-BERT pretraining. We propose a
self-training approach that allows training VL-BERTs from unlabeled image data.
The proposed method starts with our unified conditional model -- a vision
language BERT model that can perform zero-shot conditional generation. Given
different conditions, the unified conditional model can generate captions,
dense captions, and even questions. We use the labeled image data to train a
teacher model and use the trained model to generate pseudo captions on
unlabeled image data. We then combine the labeled data and pseudo labeled data
to train a student model. The process is iterated by putting the student model
as a new teacher. By using the proposed self-training approach and only 300k
unlabeled extra data, we are able to get competitive or even better
performances compared to the models of similar model size trained with 3
million extra image data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Analysis of Semantically-Aligned Speech-Text Embeddings. (arXiv:2204.01235v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.01235">
<div class="article-summary-box-inner">
<span><p>Embeddings play an important role in end-to-end solutions for multi-modal
language processing problems. Although there has been some effort to understand
the properties of single-modality embedding spaces, particularly that of text,
their cross-modal counterparts are less understood. In this work, we study some
intrinsic properties of a joint speech-text embedding space, constructed by
minimizing the distance between paired utterance and transcription inputs in a
teacher-student model setup, that are informative for several prominent use
cases. We found that incorporating automatic speech recognition through both
pretraining and multitask scenarios aid semantic alignment significantly,
resulting in more tightly coupled embeddings. To analyse cross-modal embeddings
we utilise a quantitative retrieval accuracy metric for semantic alignment,
zero-shot classification for generalisability, and probing of the encoders to
observe the extent of knowledge transfer from one modality to another.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Life is a Circus and We are the Clowns: Automatically Finding Analogies between Situations and Processes. (arXiv:2210.12197v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12197">
<div class="article-summary-box-inner">
<span><p>Analogy-making gives rise to reasoning, abstraction, flexible categorization
and counterfactual inference -- abilities lacking in even the best AI systems
today. Much research has suggested that analogies are key to non-brittle
systems that can adapt to new domains. Despite their importance, analogies
received little attention in the NLP community, with most research focusing on
simple word analogies. Work that tackled more complex analogies relied heavily
on manually constructed, hard-to-scale input representations. In this work, we
explore a more realistic, challenging setup: our input is a pair of natural
language procedural texts, describing a situation or a process (e.g., how the
heart works/how a pump works). Our goal is to automatically extract entities
and their relations from the text and find a mapping between the different
domains based on relational similarity (e.g., blood is mapped to water). We
develop an interpretable, scalable algorithm and demonstrate that it identifies
the correct mappings 87% of the time for procedural texts and 94% for stories
from cognitive-psychology literature. We show it can extract analogies from a
large dataset of procedural texts, achieving 79% precision (analogy prevalence
in data: 3%). Lastly, we demonstrate that our algorithm is robust to
paraphrasing the input texts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InferEM: Inferring the Speaker's Intention for Empathetic Dialogue Generation. (arXiv:2212.06373v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.06373">
<div class="article-summary-box-inner">
<span><p>Current approaches to empathetic response generation typically encode the
entire dialogue history directly and put the output into a decoder to generate
friendly feedback. These methods focus on modelling contextual information but
neglect capturing the direct intention of the speaker. We argue that the last
utterance in the dialogue empirically conveys the intention of the speaker.
Consequently, we propose a novel model named InferEM for empathetic response
generation. We separately encode the last utterance and fuse it with the entire
dialogue through the multi-head attention based intention fusion module to
capture the speaker's intention. Besides, we utilize previous utterances to
predict the last utterance, which simulates human's psychology to guess what
the interlocutor may speak in advance. To balance the optimizing rates of the
utterance prediction and response generation, a multi-task learning strategy is
designed for InferEM. Experimental results demonstrate the plausibility and
validity of InferEM in improving empathetic expression.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-01-21 23:11:51.369435868 UTC">2023-01-21 23:11:51 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>