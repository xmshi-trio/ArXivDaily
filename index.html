<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-06-01T01:30:00Z">06-01</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Large language models improve Alzheimer's disease diagnosis using multi-modality data. (arXiv:2305.19280v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19280">
<div class="article-summary-box-inner">
<span><p>In diagnosing challenging conditions such as Alzheimer's disease (AD),
imaging is an important reference. Non-imaging patient data such as patient
information, genetic data, medication information, cognitive and memory tests
also play a very important role in diagnosis. Effect. However, limited by the
ability of artificial intelligence models to mine such information, most of the
existing models only use multi-modal image data, and cannot make full use of
non-image data. We use a currently very popular pre-trained large language
model (LLM) to enhance the model's ability to utilize non-image data, and
achieved SOTA results on the ADNI dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models. (arXiv:2305.19308v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19308">
<div class="article-summary-box-inner">
<span><p>Computer end users have spent billions of hours completing daily tasks like
tabular data processing and project timeline scheduling. Most of these tasks
are repetitive and error-prone, yet most end users lack the skill of automating
away these burdensome works. With the advent of large language models (LLMs),
directing software with natural language user requests become a reachable goal.
In this work, we propose a SheetCopilot agent which takes natural language task
and control spreadsheet to fulfill the requirements. We propose a set of atomic
actions as an abstraction of spreadsheet software functionalities. We further
design a state machine-based task planning framework for LLMs to robustly
interact with spreadsheets. We curate a representative dataset containing 221
spreadsheet control tasks and establish a fully automated evaluation pipeline
for rigorously benchmarking the ability of LLMs in software control tasks. Our
SheetCopilot correctly completes 44.3\% of tasks for a single generation,
outperforming the strong code generation baseline by a wide margin. Our project
page:https://sheetcopilot-demo.github.io/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Breeding Machine Translations: Evolutionary approach to survive and thrive in the world of automated evaluation. (arXiv:2305.19330v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19330">
<div class="article-summary-box-inner">
<span><p>We propose a genetic algorithm (GA) based method for modifying n-best lists
produced by a machine translation (MT) system. Our method offers an innovative
approach to improving MT quality and identifying weaknesses in evaluation
metrics. Using common GA operations (mutation and crossover) on a list of
hypotheses in combination with a fitness function (an arbitrary MT metric), we
obtain novel and diverse outputs with high metric scores. With a combination of
multiple MT metrics as the fitness function, the proposed method leads to an
increase in translation quality as measured by other held-out automatic
metrics. With a single metric (including popular ones such as COMET) as the
fitness function, we find blind spots and flaws in the metric. This allows for
an automated search for adversarial examples in an arbitrary metric, without
prior assumptions on the form of such example. As a demonstration of the
method, we create datasets of adversarial examples and use them to show that
reference-free COMET is substantially less robust than the reference-based
version.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses. (arXiv:2305.19339v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19339">
<div class="article-summary-box-inner">
<span><p>A human decision-maker benefits the most from an AI assistant that corrects
for their biases. For problems such as generating interpretation of a radiology
report given findings, a system predicting only highly likely outcomes may be
less useful, where such outcomes are already obvious to the user. To alleviate
biases in human decision-making, it is worth considering a broad differential
diagnosis, going beyond the most likely options. We introduce a new task, "less
likely brainstorming," that asks a model to generate outputs that humans think
are relevant but less likely to happen. We explore the task in two settings: a
brain MRI interpretation generation setting and an everyday commonsense
reasoning setting. We found that a baseline approach of training with less
likely hypotheses as targets generates outputs that humans evaluate as either
likely or irrelevant nearly half of the time; standard MLE training is not
effective. To tackle this problem, we propose a controlled text generation
method that uses a novel contrastive learning strategy to encourage models to
differentiate between generating likely and less likely outputs according to
humans. We compare our method with several state-of-the-art controlled text
generation models via automatic and human evaluations and show that our models'
capability of generating less likely outputs is improved.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">infoVerse: A Universal Framework for Dataset Characterization with Multidimensional Meta-information. (arXiv:2305.19344v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19344">
<div class="article-summary-box-inner">
<span><p>The success of NLP systems often relies on the availability of large,
high-quality datasets. However, not all samples in these datasets are equally
valuable for learning, as some may be redundant or noisy. Several methods for
characterizing datasets based on model-driven meta-information (e.g., model's
confidence) have been developed, but the relationship and complementary effects
of these methods have received less attention. In this paper, we introduce
infoVerse, a universal framework for dataset characterization, which provides a
new feature space that effectively captures multidimensional characteristics of
datasets by incorporating various model-driven meta-information. infoVerse
reveals distinctive regions of the dataset that are not apparent in the
original semantic space, hence guiding users (or models) in identifying which
samples to focus on for exploration, assessment, or annotation. Additionally,
we propose a novel sampling method on infoVerse to select a set of data points
that maximizes informativeness. In three real-world applications (data pruning,
active learning, and data annotation), the samples chosen on infoVerse space
consistently outperform strong baselines in all applications. Our code and demo
are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stable Anisotropic Regularization. (arXiv:2305.19358v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19358">
<div class="article-summary-box-inner">
<span><p>Given the success of Large Language Models (LLMs), there has been
considerable interest in studying the properties of model activations. The
literature overwhelmingly agrees that LLM representations are dominated by a
few ``outlier dimensions'' with exceedingly high variance and magnitude.
Several studies in Natural Language Processing (NLP) have sought to mitigate
the impact of such outlier dimensions and force LLMs to be isotropic (i.e.,
have uniform variance across all dimensions in embedding space). Isotropy is
thought to be a desirable property for LLMs that improves model performance and
more closely aligns textual representations with human intuition. However, many
of the claims regarding isotropy in NLP have been based on the average cosine
similarity of embeddings, which has recently been shown to be a flawed measure
of isotropy. In this paper, we propose I-STAR: IsoScore$^{\star}$-based STable
Anisotropic Regularization, a novel regularization method that can be used to
increase or decrease levels of isotropy in embedding space during training.
I-STAR uses IsoScore$^{\star}$, the first accurate measure of isotropy that is
both differentiable and stable on mini-batch computations. In contrast to
several previous works, we find that \textit{decreasing} isotropy in
contextualized embeddings improves performance on the majority of tasks and
models considered in this paper.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Blockwise Parallel Transformer for Long Context Large Models. (arXiv:2305.19370v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19370">
<div class="article-summary-box-inner">
<span><p>Transformers have emerged as the cornerstone of state-of-the-art natural
language processing models, showcasing exceptional performance across a wide
range of AI applications. However, the memory demands posed by the
self-attention mechanism and the large feedforward network in Transformers
limit their ability to handle long sequences, thereby creating challenges for
tasks involving multiple long sequences or long-term dependencies. We present a
distinct approach, Blockwise Parallel Transformer (BPT), that leverages
blockwise computation of self-attention and feedforward network fusion to
minimize memory costs. By processing longer input sequences while maintaining
memory efficiency, BPT enables training sequences up to 32 times longer than
vanilla Transformers and 2 to 4 times longer than previous memory-efficient
methods. Extensive experiments on language modeling and reinforcement learning
tasks demonstrate the effectiveness of BPT in reducing memory requirements and
improving performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mining Themes in Clinical Notes to Identify Phenotypes and to Predict Length of Stay in Patients admitted with Heart Failure. (arXiv:2305.19373v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19373">
<div class="article-summary-box-inner">
<span><p>Heart failure is a syndrome which occurs when the heart is not able to pump
blood and oxygen to support other organs in the body. Identifying the
underlying themes in the diagnostic codes and procedure reports of patients
admitted for heart failure could reveal the clinical phenotypes associated with
heart failure and to group patients based on their similar characteristics
which could also help in predicting patient outcomes like length of stay. These
clinical phenotypes usually have a probabilistic latent structure and hence, as
there has been no previous work on identifying phenotypes in clinical notes of
heart failure patients using a probabilistic framework and to predict length of
stay of these patients using data-driven artificial intelligence-based methods,
we apply natural language processing technique, topic modeling, to identify the
themes present in diagnostic codes and in procedure reports of 1,200 patients
admitted for heart failure at the University of Illinois Hospital and Health
Sciences System (UI Health). Topic modeling identified twelve themes each in
diagnostic codes and procedure reports which revealed information about
different phenotypes related to various perspectives about heart failure, to
study patients' profiles and to discover new relationships among medical
concepts. Each theme had a set of keywords and each clinical note was labeled
with two themes - one corresponding to its diagnostic code and the other
corresponding to its procedure reports along with their percentage
contribution. We used these themes and their percentage contribution to predict
length of stay. We found that the themes discovered in diagnostic codes and
procedure reports using topic modeling together were able to predict length of
stay of the patients with an accuracy of 61.1% and an Area under the Receiver
Operating Characteristic Curve (ROC AUC) value of 0.828.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantum Natural Language Processing based Sentiment Analysis using lambeq Toolkit. (arXiv:2305.19383v1 [quant-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19383">
<div class="article-summary-box-inner">
<span><p>Sentiment classification is one the best use case of classical natural
language processing (NLP) where we can witness its power in various daily life
domains such as banking, business and marketing industry. We already know how
classical AI and machine learning can change and improve technology. Quantum
natural language processing (QNLP) is a young and gradually emerging technology
which has the potential to provide quantum advantage for NLP tasks. In this
paper we show the first application of QNLP for sentiment analysis and achieve
perfect test set accuracy for three different kinds of simulations and a decent
accuracy for experiments ran on a noisy quantum device. We utilize the lambeq
QNLP toolkit and $t|ket&gt;$ by Cambridge Quantum (Quantinuum) to bring out the
results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative Modeling. (arXiv:2305.19395v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19395">
<div class="article-summary-box-inner">
<span><p>Learning from noisy labels is a challenge that arises in many real-world
applications where training data can contain incorrect or corrupted labels.
When fine-tuning language models with noisy labels, models can easily overfit
the label noise, leading to decreased performance. Most existing methods for
learning from noisy labels use static input features for denoising, but these
methods are limited by the information they can provide on true label
distributions and can result in biased or incorrect predictions. In this work,
we propose the Dynamics-Enhanced Generative Model (DyGen), which uses dynamic
patterns in the embedding space during the fine-tuning process of language
models to improve noisy label predictions. DyGen uses the variational
auto-encoding framework to infer the posterior distributions of true labels
from noisy labels and training dynamics. Additionally, a co-regularization
mechanism is used to minimize the impact of potentially noisy labels and
priors. DyGen demonstrates an average accuracy improvement of 3.10% on two
synthetic noise datasets and 1.48% on three real-world noise datasets compared
to the previous state-of-the-art. Extensive experiments and analyses show the
effectiveness of each component in DyGen. Our code is available for
reproducibility on GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Resource-Efficient Fine-Tuning Strategies for Automatic MOS Prediction in Text-to-Speech for Low-Resource Languages. (arXiv:2305.19396v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19396">
<div class="article-summary-box-inner">
<span><p>We train a MOS prediction model based on wav2vec 2.0 using the open-access
data sets BVCC and SOMOS. Our test with neural TTS data in the low-resource
language (LRL) West Frisian shows that pre-training on BVCC before fine-tuning
on SOMOS leads to the best accuracy for both fine-tuned and zero-shot
prediction. Further fine-tuning experiments show that using more than 30
percent of the total data does not lead to significant improvements. In
addition, fine-tuning with data from a single listener shows promising
system-level accuracy, supporting the viability of one-participant pilot tests.
These findings can all assist the resource-conscious development of TTS for
LRLs by progressing towards better zero-shot MOS prediction and informing the
design of listening tests, especially in early-stage evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextual Vision Transformers for Robust Representation Learning. (arXiv:2305.19402v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19402">
<div class="article-summary-box-inner">
<span><p>We present Contextual Vision Transformers (ContextViT), a method for
producing robust feature representations for images exhibiting grouped
structure such as covariates. ContextViT introduces an extra context token to
encode group-specific information, allowing the model to explain away
group-specific covariate structures while keeping core visual features shared
across groups. Specifically, given an input image, Context-ViT maps images that
share the same covariate into this context token appended to the input image
tokens to capture the effects of conditioning the model on group membership. We
furthermore introduce a context inference network to predict such tokens on the
fly given a few samples from a group distribution, enabling ContextViT to
generalize to new testing distributions at inference time. We illustrate the
performance of ContextViT through a diverse range of applications. In
supervised fine-tuning, we demonstrate that augmenting pre-trained ViTs with
additional context conditioning leads to significant improvements in
out-of-distribution generalization on iWildCam and FMoW. We also explored
self-supervised representation learning with ContextViT. Our experiments on the
Camelyon17 pathology imaging benchmark and the cpg-0000 microscopy imaging
benchmark demonstrate that ContextViT excels in learning stable image
featurizations amidst covariate shift, consistently outperforming its ViT
counterpart.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Examining risks of racial biases in NLP tools for child protective services. (arXiv:2305.19409v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19409">
<div class="article-summary-box-inner">
<span><p>Although much literature has established the presence of demographic bias in
natural language processing (NLP) models, most work relies on curated bias
metrics that may not be reflective of real-world applications. At the same
time, practitioners are increasingly using algorithmic tools in high-stakes
settings, with particular recent interest in NLP. In this work, we focus on one
such setting: child protective services (CPS). CPS workers often write copious
free-form text notes about families they are working with, and CPS agencies are
actively seeking to deploy NLP models to leverage these data. Given
well-established racial bias in this setting, we investigate possible ways
deployed NLP is liable to increase racial disparities. We specifically examine
word statistics within notes and algorithmic fairness in risk prediction,
coreference resolution, and named entity recognition (NER). We document
consistent algorithmic unfairness in NER models, possible algorithmic
unfairness in coreference resolution models, and little evidence of exacerbated
racial bias in risk prediction. While there is existing pronounced criticism of
risk prediction, our results expose previously undocumented risks of racial
bias in realistic information extraction systems, highlighting potential
concerns in deploying them, even though they may appear more benign. Our work
serves as a rare realistic examination of NLP algorithmic fairness in a
potential deployed setting and a timely investigation of a specific risk
associated with deploying NLP in CPS settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Multi-Instance Multi-Label Learning for Detecting Propaganda Techniques. (arXiv:2305.19419v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19419">
<div class="article-summary-box-inner">
<span><p>Since the introduction of the SemEval 2020 Task 11 (Martino et al., 2020a),
several approaches have been proposed in the literature for classifying
propaganda based on the rhetorical techniques used to influence readers. These
methods, however, classify one span at a time, ignoring dependencies from the
labels of other spans within the same context. In this paper, we approach
propaganda technique classification as a Multi-Instance Multi-Label (MIML)
learning problem (Zhou et al., 2012) and propose a simple RoBERTa-based model
(Zhuang et al., 2021) for classifying all spans in an article simultaneously.
Further, we note that, due to the annotation process where annotators
classified the spans by following a decision tree, there is an inherent
hierarchical relationship among the different techniques, which existing
approaches ignore. We incorporate these hierarchical label dependencies by
adding an auxiliary classifier for each node in the decision tree to the
training objective and ensembling the predictions from the original and
auxiliary classifiers at test time. Overall, our model leads to an absolute
improvement of 2.47% micro-F1 over the model from the shared task winning team
in a cross-validation setup and is the best performing non-ensemble model on
the shared task leaderboard.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ScoNe: Benchmarking Negation Reasoning in Language Models With Fine-Tuning and In-Context Learning. (arXiv:2305.19426v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19426">
<div class="article-summary-box-inner">
<span><p>A number of recent benchmarks seek to assess how well models handle natural
language negation. However, these benchmarks lack the controlled example
paradigms that would allow us to infer whether a model had learned how negation
morphemes semantically scope. To fill these analytical gaps, we present the
Scoped Negation NLI (ScoNe-NLI) benchmark, which contains contrast sets of six
examples with up to two negations where either zero, one, or both negative
morphemes affect the NLI label. We use ScoNe-NLI to assess fine-tuning and
in-context learning strategies. We find that RoBERTa and DeBERTa models solve
ScoNe-NLI after many shot fine-tuning. For in-context learning, we test
InstructGPT models and find that most prompt strategies are not successful,
including those using step-by-step reasoning. To better understand this result,
we extend ScoNe with ScoNe-NLG, a sentence completion test set that embeds
negation reasoning in short narratives. Here, InstructGPT is successful, which
reveals the model can correctly reason about negation, but struggles to do so
on prompt-adapted NLI examples outside of its core pretraining regime.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Impact of Positional Encoding on Length Generalization in Transformers. (arXiv:2305.19466v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19466">
<div class="article-summary-box-inner">
<span><p>Length generalization, the ability to generalize from small training context
sizes to larger ones, is a critical challenge in the development of
Transformer-based language models. Positional encoding (PE) has been identified
as a major factor influencing length generalization, but the exact impact of
different PE schemes on extrapolation in downstream tasks remains unclear. In
this paper, we conduct a systematic empirical study comparing the length
generalization performance of decoder-only Transformers with five different
position encoding approaches including Absolute Position Embedding (APE), T5's
Relative PE, ALiBi, and Rotary, in addition to Transformers without positional
encoding (NoPE). Our evaluation encompasses a battery of reasoning and
mathematical tasks. Our findings reveal that the most commonly used positional
encoding methods, such as ALiBi, Rotary, and APE, are not well suited for
length generalization in downstream tasks. More importantly, NoPE outperforms
other explicit positional encoding methods while requiring no additional
computation. We theoretically demonstrate that NoPE can represent both absolute
and relative PEs, but when trained with SGD, it mostly resembles T5's relative
PE attention patterns. Finally, we find that scratchpad is not always helpful
to solve length generalization and its format highly impacts the model's
performance. Overall, our work suggests that explicit position embeddings are
not essential for decoder-only Transformers to generalize well to longer
sequences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning. (arXiv:2305.19472v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19472">
<div class="article-summary-box-inner">
<span><p>Procedural planning, which entails decomposing a high-level goal into a
sequence of temporally ordered steps, is an important yet intricate task for
machines. It involves integrating common-sense knowledge to reason about
complex contextualized situations that are often counterfactual, e.g.
"scheduling a doctor's appointment without a phone". While current approaches
show encouraging results using large language models (LLMs), they are hindered
by drawbacks such as costly API calls and reproducibility issues. In this
paper, we advocate planning using smaller language models. We present PlaSma, a
novel two-pronged approach to endow small language models with procedural
knowledge and (counterfactual) planning capabilities. More concretely, we
develop symbolic procedural knowledge distillation to enhance the implicit
knowledge in small language models and an inference-time algorithm to
facilitate more structured and accurate reasoning. In addition, we introduce a
novel task, Counterfactual Planning, that requires a revision of a plan to cope
with a counterfactual situation. In both the original and counterfactual
setting, we show that orders-of-magnitude smaller models (770M-11B parameters)
can compete and often surpass their larger teacher models' capabilities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ethical Considerations for Machine Translation of Indigenous Languages: Giving a Voice to the Speakers. (arXiv:2305.19474v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19474">
<div class="article-summary-box-inner">
<span><p>In recent years machine translation has become very successful for
high-resource language pairs. This has also sparked new interest in research on
the automatic translation of low-resource languages, including Indigenous
languages. However, the latter are deeply related to the ethnic and cultural
groups that speak (or used to speak) them. The data collection, modeling and
deploying machine translation systems thus result in new ethical questions that
must be addressed. Motivated by this, we first survey the existing literature
on ethical considerations for the documentation, translation, and general
natural language processing for Indigenous languages. Afterward, we conduct and
analyze an interview study to shed light on the positions of community leaders,
teachers, and language activists regarding ethical concerns for the automatic
translation of their languages. Our results show that the inclusion, at
different degrees, of native speakers and community members is vital to
performing better and more ethical research on Indigenous languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Flow Graph Prediction of Open-Domain Procedural Texts. (arXiv:2305.19497v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19497">
<div class="article-summary-box-inner">
<span><p>Machine comprehension of procedural texts is essential for reasoning about
the steps and automating the procedures. However, this requires identifying
entities within a text and resolving the relationships between the entities.
Previous work focused on the cooking domain and proposed a framework to convert
a recipe text into a flow graph (FG) representation. In this work, we propose a
framework based on the recipe FG for flow graph prediction of open-domain
procedural texts. To investigate flow graph prediction performance in
non-cooking domains, we introduce the wikiHow-FG corpus from articles on
wikiHow, a website of how-to instruction articles. In experiments, we consider
using the existing recipe corpus and performing domain adaptation from the
cooking to the target domain. Experimental results show that the domain
adaptation models achieve higher performance than those trained only on the
cooking or target domain data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Lottery Prompts for Pre-trained Language Models. (arXiv:2305.19500v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19500">
<div class="article-summary-box-inner">
<span><p>Consistently scaling pre-trained language models (PLMs) imposes substantial
burdens on model adaptation, necessitating more efficient alternatives to
conventional fine-tuning. Given the advantage of prompting in the zero-shot
setting and the observed performance fluctuation among different prompts, we
explore the instance-level prompt and their generalizability. By searching
through the prompt space, we first validate the assumption that for every
instance, there is almost always a lottery prompt that induces the correct
prediction from the PLM, and such prompt can be obtained at a low cost thanks
to the inherent ability of PLMs. Meanwhile, we find that some strong lottery
prompts have high performance over the whole training set, and they are
equipped with distinguishable linguistic features. Lastly, we attempt to
generalize the searched strong lottery prompts to unseen data with prompt
ensembling method without any parameter tuning. Experiments are conducted on
various types of NLP classification tasks and demonstrate that the proposed
method can achieve comparable results with other gradient-free and
optimization-free baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-grained Text Style Transfer with Diffusion-Based Language Models. (arXiv:2305.19512v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19512">
<div class="article-summary-box-inner">
<span><p>Diffusion probabilistic models have shown great success in generating
high-quality images controllably, and researchers have tried to utilize this
controllability into text generation domain. Previous works on diffusion-based
language models have shown that they can be trained without external knowledge
(such as pre-trained weights) and still achieve stable performance and
controllability. In this paper, we trained a diffusion-based model on StylePTB
dataset, the standard benchmark for fine-grained text style transfers. The
tasks in StylePTB requires much more refined control over the output text
compared to tasks evaluated in previous works, and our model was able to
achieve state-of-the-art performance on StylePTB on both individual and
compositional transfers. Moreover, our model, trained on limited data from
StylePTB without external knowledge, outperforms previous works that utilized
pretrained weights, embeddings, and external grammar parsers, and this may
indicate that diffusion-based language models have great potential under
low-resource settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accurate and Structured Pruning for Efficient Automatic Speech Recognition. (arXiv:2305.19549v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19549">
<div class="article-summary-box-inner">
<span><p>Automatic Speech Recognition (ASR) has seen remarkable advancements with deep
neural networks, such as Transformer and Conformer. However, these models
typically have large model sizes and high inference costs, posing a challenge
to deploy on resource-limited devices. In this paper, we propose a novel
compression strategy that leverages structured pruning and knowledge
distillation to reduce the model size and inference cost of the Conformer model
while preserving high recognition performance. Our approach utilizes a set of
binary masks to indicate whether to retain or prune each Conformer module, and
employs L0 regularization to learn the optimal mask values. To further enhance
pruning performance, we use a layerwise distillation strategy to transfer
knowledge from unpruned to pruned models. Our method outperforms all pruning
baselines on the widely used LibriSpeech benchmark, achieving a 50% reduction
in model size and a 28% reduction in inference cost with minimal performance
loss.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Are Not Abstract Reasoners. (arXiv:2305.19555v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19555">
<div class="article-summary-box-inner">
<span><p>Large Language Models have shown tremendous performance on a large variety of
natural language processing tasks, ranging from text comprehension to common
sense reasoning. However, the mechanisms responsible for this success remain
unknown, and it is unclear whether LLMs can achieve human-like cognitive
capabilities or whether these models are still fundamentally limited. Abstract
reasoning is a fundamental task for cognition, consisting of finding and
applying a general pattern from few data. Evaluating deep neural architectures
on this task could give insight into their potential limitations regarding
reasoning and their broad generalisation abilities, yet this is currently an
under-explored area. In this paper, we perform extensive evaluations of
state-of-the-art LLMs on abstract reasoning tasks, showing that they achieve
very limited performance in contrast with other natural language tasks, and we
investigate the reasons for this difference. We apply techniques that have been
shown to improve performance on other NLP tasks and show that in most cases
their impact on abstract reasoning performance is limited. In the course of
this work, we have generated a new benchmark for evaluating language models on
abstract reasoning tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-Shot Automatic Pronunciation Assessment. (arXiv:2305.19563v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19563">
<div class="article-summary-box-inner">
<span><p>Automatic Pronunciation Assessment (APA) is vital for computer-assisted
language learning. Prior methods rely on annotated speech-text data to train
Automatic Speech Recognition (ASR) models or speech-score data to train
regression models. In this work, we propose a novel zero-shot APA method based
on the pre-trained acoustic model, HuBERT. Our method involves encoding speech
input and corrupting them via a masking module. We then employ the Transformer
encoder and apply k-means clustering to obtain token sequences. Finally, a
scoring module is designed to measure the number of wrongly recovered tokens.
Experimental results on speechocean762 demonstrate that the proposed method
achieves comparable performance to supervised regression baselines and
outperforms non-regression baselines in terms of Pearson Correlation
Coefficient (PCC). Additionally, we analyze how masking strategies affect the
performance of APA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DC CoMix TTS: An End-to-End Expressive TTS with Discrete Code Collaborated with Mixer. (arXiv:2305.19567v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19567">
<div class="article-summary-box-inner">
<span><p>Despite the huge successes made in neutral TTS, content-leakage remains a
challenge. In this paper, we propose a new input representation and simple
architecture to achieve improved prosody modeling. Inspired by the recent
success in the use of discrete code in TTS, we introduce discrete code to the
input of the reference encoder. Specifically, we leverage the vector quantizer
from the audio compression model to exploit the diverse acoustic information it
has already been trained on. In addition, we apply the modified MLP-Mixer to
the reference encoder, making the architecture lighter. As a result, we train
the prosody transfer TTS in an end-to-end manner. We prove the effectiveness of
our method through both subjective and objective evaluations. We demonstrate
that the reference encoder learns better speaker-independent prosody when
discrete code is utilized as input in the experiments. In addition, we obtain
comparable results even when fewer parameters are inputted.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Tag-Team Approach: Leveraging CLS and Language Tagging for Enhancing Multilingual ASR. (arXiv:2305.19584v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19584">
<div class="article-summary-box-inner">
<span><p>Building a multilingual Automated Speech Recognition (ASR) system in a
linguistically diverse country like India can be a challenging task due to the
differences in scripts and the limited availability of speech data. This
problem can be solved by exploiting the fact that many of these languages are
phonetically similar. These languages can be converted into a Common Label Set
(CLS) by mapping similar sounds to common labels. In this paper, new approaches
are explored and compared to improve the performance of CLS based multilingual
ASR model. Specific language information is infused in the ASR model by giving
Language ID or using CLS to Native script converter on top of the CLS
Multilingual model. These methods give a significant improvement in Word Error
Rate (WER) compared to the CLS baseline. These methods are further tried on
out-of-distribution data to check their robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LAIT: Efficient Multi-Segment Encoding in Transformers with Layer-Adjustable Interaction. (arXiv:2305.19585v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19585">
<div class="article-summary-box-inner">
<span><p>Transformer encoders contextualize token representations by attending to all
other tokens at each layer, leading to quadratic increase in compute effort
with the input length. In practice, however, the input text of many NLP tasks
can be seen as a sequence of related segments (e.g., the sequence of sentences
within a passage, or the hypothesis and premise in NLI). While attending across
these segments is highly beneficial for many tasks, we hypothesize that this
interaction can be delayed until later encoding stages.
</p>
<p>To this end, we introduce Layer-Adjustable Interactions in Transformers
(LAIT). Within LAIT, segmented inputs are first encoded independently, and then
jointly. This partial two-tower architecture bridges the gap between a Dual
Encoder's ability to pre-compute representations for segments and a fully
self-attentive Transformer's capacity to model cross-segment attention. The
LAIT framework effectively leverages existing pretrained Transformers and
converts them into the hybrid of the two aforementioned architectures, allowing
for easy and intuitive control over the performance-efficiency tradeoff.
Experimenting on a wide range of NLP tasks, we find LAIT able to reduce 30-50%
of the attention FLOPs on many tasks, while preserving high accuracy; in some
practical settings, LAIT could reduce actual latency by orders of magnitude.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SLABERT Talk Pretty One Day: Modeling Second Language Acquisition with BERT. (arXiv:2305.19589v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19589">
<div class="article-summary-box-inner">
<span><p>Second language acquisition (SLA) research has extensively studied
cross-linguistic transfer, the influence of linguistic structure of a speaker's
native language [L1] on the successful acquisition of a foreign language [L2].
Effects of such transfer can be positive (facilitating acquisition) or negative
(impeding acquisition). We find that NLP literature has not given enough
attention to the phenomenon of negative transfer. To understand patterns of
both positive and negative transfer between L1 and L2, we model sequential
second language acquisition in LMs. Further, we build a Mutlilingual Age
Ordered CHILDES (MAO-CHILDES) -- a dataset consisting of 5 typologically
diverse languages, i.e., German, French, Polish, Indonesian, and Japanese -- to
understand the degree to which native Child-Directed Speech (CDS) [L1] can help
or conflict with English language acquisition [L2]. To examine the impact of
native CDS, we use the TILT-based cross lingual transfer learning approach
established by Papadimitriou and Jurafsky (2020) and find that, as in human
SLA, language family distance predicts more negative transfer. Additionally, we
find that conversational speech data shows greater facilitation for language
acquisition than scripted speech data. Our findings call for further research
using our novel Transformer-based SLA models and we would like to encourage it
by releasing our code, data, and models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What does the Failure to Reason with "Respectively" in Zero/Few-Shot Settings Tell Us about Language Models?. (arXiv:2305.19597v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19597">
<div class="article-summary-box-inner">
<span><p>Humans can effortlessly understand the coordinate structure of sentences such
as "Niels Bohr and Kurt Cobain were born in Copenhagen and Seattle,
respectively". In the context of natural language inference (NLI), we examine
how language models (LMs) reason with respective readings (Gawron and Kehler,
2004) from two perspectives: syntactic-semantic and commonsense-world
knowledge. We propose a controlled synthetic dataset WikiResNLI and a naturally
occurring dataset NatResNLI to encompass various explicit and implicit
realizations of "respectively". We show that fine-tuned NLI models struggle
with understanding such readings without explicit supervision. While few-shot
learning is easy in the presence of explicit cues, longer training is required
when the reading is evoked implicitly, leaving models to rely on common sense
inferences. Furthermore, our fine-grained analysis indicates models fail to
generalize across different constructions. To conclude, we demonstrate that LMs
still lag behind humans in generalizing to the long tail of linguistic
constructions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Clean Label Backdoor Attacks and Defenses on Text Classification Systems. (arXiv:2305.19607v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19607">
<div class="article-summary-box-inner">
<span><p>Clean-label (CL) attack is a form of data poisoning attack where an adversary
modifies only the textual input of the training data, without requiring access
to the labeling function. CL attacks are relatively unexplored in NLP, as
compared to label flipping (LF) attacks, where the latter additionally requires
access to the labeling function as well. While CL attacks are more resilient to
data sanitization and manual relabeling methods than LF attacks, they often
demand as high as ten times the poisoning budget than LF attacks. In this work,
we first introduce an Adversarial Clean Label attack which can adversarially
perturb in-class training examples for poisoning the training set. We then show
that an adversary can significantly bring down the data requirements for a CL
attack, using the aforementioned approach, to as low as 20% of the data
otherwise required. We then systematically benchmark and analyze a number of
defense methods, for both LF and CL attacks, some previously employed solely
for LF attacks in the textual domain and others adapted from computer vision.
We find that text-specific defenses greatly vary in their effectiveness
depending on their properties.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adverbs, Surprisingly. (arXiv:2305.19650v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19650">
<div class="article-summary-box-inner">
<span><p>This paper begins with the premise that adverbs are neglected in
computational linguistics. This view derives from two analyses: a literature
review and a novel adverb dataset to probe a state-of-the-art language model,
thereby uncovering systematic gaps in accounts for adverb meaning. We suggest
that using Frame Semantics for characterizing word meaning, as in FrameNet,
provides a promising approach to adverb analysis, given its ability to describe
ambiguity, semantic roles, and null instantiation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unveiling Cross Modality Bias in Visual Question Answering: A Causal View with Possible Worlds VQA. (arXiv:2305.19664v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19664">
<div class="article-summary-box-inner">
<span><p>To increase the generalization capability of VQA systems, many recent studies
have tried to de-bias spurious language or vision associations that shortcut
the question or image to the answer. Despite these efforts, the literature
fails to address the confounding effect of vision and language simultaneously.
As a result, when they reduce bias learned from one modality, they usually
increase bias from the other. In this paper, we first model a confounding
effect that causes language and vision bias simultaneously, then propose a
counterfactual inference to remove the influence of this effect. The model
trained in this strategy can concurrently and efficiently reduce vision and
language bias. To the best of our knowledge, this is the first work to reduce
biases resulting from confounding effects of vision and language in VQA,
leveraging causal explain-away relations. We accompany our method with an
explain-away strategy, pushing the accuracy of the questions with numerical
answers results compared to existing methods that have been an open problem.
The proposed method outperforms the state-of-the-art methods in VQA-CP v2
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing Word Importance Using Models Trained for Semantic Tasks. (arXiv:2305.19689v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19689">
<div class="article-summary-box-inner">
<span><p>Many NLP tasks require to automatically identify the most significant words
in a text. In this work, we derive word significance from models trained to
solve semantic task: Natural Language Inference and Paraphrase Identification.
Using an attribution method aimed to explain the predictions of these models,
we derive importance scores for each input token. We evaluate their relevance
using a so-called cross-task evaluation: Analyzing the performance of one model
on an input masked according to the other model's weight, we show that our
method is robust with respect to the choice of the initial task. Additionally,
we investigate the scores from the syntax point of view and observe interesting
patterns, e.g. words closer to the root of a syntactic tree receive higher
importance scores. Altogether, these observations suggest that our method can
be used to identify important words in sentences without any explicit word
importance labeling in training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Building Extractive Question Answering System to Support Human-AI Health Coaching Model for Sleep Domain. (arXiv:2305.19707v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19707">
<div class="article-summary-box-inner">
<span><p>Non-communicable diseases (NCDs) are a leading cause of global deaths,
necessitating a focus on primary prevention and lifestyle behavior change.
Health coaching, coupled with Question Answering (QA) systems, has the
potential to transform preventive healthcare. This paper presents a
human-Artificial Intelligence (AI) health coaching model incorporating a
domain-specific extractive QA system. A sleep-focused dataset, SleepQA, was
manually assembled and used to fine-tune domain-specific BERT models. The QA
system was evaluated using automatic and human methods. A data-centric
framework enhanced the system's performance by improving passage retrieval and
question reformulation. Although the system did not outperform the baseline in
automatic evaluation, it excelled in the human evaluation of real-world
questions. Integration into a Human-AI health coaching model was tested in a
pilot Randomized Controlled Trial (RCT).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">XPhoneBERT: A Pre-trained Multilingual Model for Phoneme Representations for Text-to-Speech. (arXiv:2305.19709v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19709">
<div class="article-summary-box-inner">
<span><p>We present XPhoneBERT, the first multilingual model pre-trained to learn
phoneme representations for the downstream text-to-speech (TTS) task. Our
XPhoneBERT has the same model architecture as BERT-base, trained using the
RoBERTa pre-training approach on 330M phoneme-level sentences from nearly 100
languages and locales. Experimental results show that employing XPhoneBERT as
an input phoneme encoder significantly boosts the performance of a strong
neural TTS model in terms of naturalness and prosody and also helps produce
fairly high-quality speech with limited training data. We publicly release our
pre-trained XPhoneBERT with the hope that it would facilitate future research
and downstream TTS applications for multiple languages. Our XPhoneBERT model is
available at https://github.com/VinAIResearch/XPhoneBERT
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Red Teaming Language Model Detectors with Language Models. (arXiv:2305.19713v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19713">
<div class="article-summary-box-inner">
<span><p>The prevalence and high capacity of large language models (LLMs) present
significant safety and ethical risks when malicious users exploit them for
automated content generation. To prevent the potentially deceptive usage of
LLMs, recent works have proposed several algorithms to detect machine-generated
text. In this paper, we systematically test the reliability of the existing
detectors, by designing two types of attack strategies to fool the detectors:
1) replacing words with their synonyms based on the context; 2) altering the
writing style of generated text. These strategies are implemented by
instructing LLMs to generate synonymous word substitutions or writing
directives that modify the style without human involvement, and the LLMs
leveraged in the attack can also be protected by detectors. Our research
reveals that our attacks effectively compromise the performance of all tested
detectors, thereby underscoring the urgent need for the development of more
robust machine-generated text detection systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Base Question Answering for Space Debris Queries. (arXiv:2305.19734v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19734">
<div class="article-summary-box-inner">
<span><p>Space agencies execute complex satellite operations that need to be supported
by the technical knowledge contained in their extensive information systems.
Knowledge bases (KB) are an effective way of storing and accessing such
information at scale. In this work we present a system, developed for the
European Space Agency (ESA), that can answer complex natural language queries,
to support engineers in accessing the information contained in a KB that models
the orbital space debris environment. Our system is based on a pipeline which
first generates a sequence of basic database operations, called a %program
sketch, from a natural language question, then specializes the sketch into a
concrete query program with mentions of entities, attributes and relations, and
finally executes the program against the database. This pipeline decomposition
approach enables us to train the system by leveraging out-of-domain data and
semi-synthetic data generated by GPT-3, thus reducing overfitting and shortcut
learning even with limited amount of in-domain training data. Our code can be
found at \url{https://github.com/PaulDrm/DISCOSQA}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analyzing Text Representations by Measuring Task Alignment. (arXiv:2305.19747v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19747">
<div class="article-summary-box-inner">
<span><p>Textual representations based on pre-trained language models are key,
especially in few-shot learning scenarios. What makes a representation good for
text classification? Is it due to the geometric properties of the space or
because it is well aligned with the task? We hypothesize the second claim. To
test it, we develop a task alignment score based on hierarchical clustering
that measures alignment at different levels of granularity. Our experiments on
text classification validate our hypothesis by showing that task alignment can
explain the classification performance of a given representation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UKP-SQuARE: An Interactive Tool for Teaching Question Answering. (arXiv:2305.19748v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19748">
<div class="article-summary-box-inner">
<span><p>The exponential growth of question answering (QA) has made it an
indispensable topic in any Natural Language Processing (NLP) course.
Additionally, the breadth of QA derived from this exponential growth makes it
an ideal scenario for teaching related NLP topics such as information
retrieval, explainability, and adversarial attacks among others. In this paper,
we introduce UKP-SQuARE as a platform for QA education. This platform provides
an interactive environment where students can run, compare, and analyze various
QA models from different perspectives, such as general behavior,
explainability, and robustness. Therefore, students can get a first-hand
experience in different QA techniques during the class. Thanks to this, we
propose a learner-centered approach for QA education in which students
proactively learn theoretical concepts and acquire problem-solving skills
through interactive exploration, experimentation, and practical assignments,
rather than solely relying on traditional lectures. To evaluate the
effectiveness of UKP-SQuARE in teaching scenarios, we adopted it in a
postgraduate NLP course and surveyed the students after the course. Their
positive feedback shows the platform's effectiveness in their course and
invites a wider adoption.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text-to-Speech Pipeline for Swiss German -- A comparison. (arXiv:2305.19750v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19750">
<div class="article-summary-box-inner">
<span><p>In this work, we studied the synthesis of Swiss German speech using different
Text-to-Speech (TTS) models. We evaluated the TTS models on three corpora, and
we found, that VITS models performed best, hence, using them for further
testing. We also introduce a new method to evaluate TTS models by letting the
discriminator of a trained vocoder GAN model predict whether a given waveform
is human or synthesized. In summary, our best model delivers speech synthesis
for different Swiss German dialects with previously unachieved quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentence Simplification Using Paraphrase Corpus for Initialization. (arXiv:2305.19754v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19754">
<div class="article-summary-box-inner">
<span><p>Neural sentence simplification method based on sequence-to-sequence framework
has become the mainstream method for sentence simplification (SS) task.
Unfortunately, these methods are currently limited by the scarcity of parallel
SS corpus. In this paper, we focus on how to reduce the dependence on parallel
corpus by leveraging a careful initialization for neural SS methods from
paraphrase corpus. Our work is motivated by the following two findings: (1)
Paraphrase corpus includes a large proportion of sentence pairs belonging to SS
corpus. (2) We can construct large-scale pseudo parallel SS data by keeping
these sentence pairs with a higher complexity difference. Therefore, we propose
two strategies to initialize neural SS methods using paraphrase corpus. We
train three different neural SS methods with our initialization, which can
obtain substantial improvements on the available WikiLarge data compared with
themselves without initialization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Discrimination of Human and Neural Machine Translation in Multilingual Scenarios. (arXiv:2305.19757v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19757">
<div class="article-summary-box-inner">
<span><p>We tackle the task of automatically discriminating between human and machine
translations. As opposed to most previous work, we perform experiments in a
multilingual setting, considering multiple languages and multilingual
pretrained language models. We show that a classifier trained on parallel data
with a single source language (in our case German-English) can still perform
well on English translations that come from different source languages, even
when the machine translations were produced by other systems than the one it
was trained on. Additionally, we demonstrate that incorporating the source text
in the input of a multilingual classifier improves (i) its accuracy and (ii)
its robustness on cross-system evaluation, compared to a monolingual
classifier. Furthermore, we find that using training data from multiple source
languages (German, Russian, and Chinese) tends to improve the accuracy of both
monolingual and multilingual classifiers. Finally, we show that bilingual
classifiers and classifiers trained on multiple source languages benefit from
being trained on longer text sequences, rather than on sentences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simple yet Effective Code-Switching Language Identification with Multitask Pre-Training and Transfer Learning. (arXiv:2305.19759v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19759">
<div class="article-summary-box-inner">
<span><p>Code-switching, also called code-mixing, is the linguistics phenomenon where
in casual settings, multilingual speakers mix words from different languages in
one utterance. Due to its spontaneous nature, code-switching is extremely
low-resource, which makes it a challenging problem for language and speech
processing tasks. In such contexts, Code-Switching Language Identification
(CSLID) becomes a difficult but necessary task if we want to maximally leverage
existing monolingual tools for other tasks. In this work, we propose two novel
approaches toward improving language identification accuracy on an
English-Mandarin child-directed speech dataset. Our methods include a stacked
Residual CNN+GRU model and a multitask pre-training approach to use Automatic
Speech Recognition (ASR) as an auxiliary task for CSLID. Due to the
low-resource nature of code-switching, we also employ careful silver data
creation using monolingual corpora in both languages and up-sampling as data
augmentation. We focus on English-Mandarin code-switched data, but our method
works on any language pair. Our best model achieves a balanced accuracy of
0.781 on a real English-Mandarin code-switching child-directed speech corpus
and outperforms the previous baseline by 55.3%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recursive Metropolis-Hastings Naming Game: Symbol Emergence in a Multi-agent System based on Probabilistic Generative Models. (arXiv:2305.19761v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19761">
<div class="article-summary-box-inner">
<span><p>In the studies on symbol emergence and emergent communication in a population
of agents, a computational model was employed in which agents participate in
various language games. Among these, the Metropolis-Hastings naming game (MHNG)
possesses a notable mathematical property: symbol emergence through MHNG is
proven to be a decentralized Bayesian inference of representations shared by
the agents. However, the previously proposed MHNG is limited to a two-agent
scenario. This paper extends MHNG to an N-agent scenario. The main
contributions of this paper are twofold: (1) we propose the recursive
Metropolis-Hastings naming game (RMHNG) as an N-agent version of MHNG and
demonstrate that RMHNG is an approximate Bayesian inference method for the
posterior distribution over a latent variable shared by agents, similar to
MHNG; and (2) we empirically evaluate the performance of RMHNG on synthetic and
real image data, enabling multiple agents to develop and share a symbol system.
Furthermore, we introduce two types of approximations -- one-sample and
limited-length -- to reduce computational complexity while maintaining the
ability to explain communication in a population of agents. The experimental
findings showcased the efficacy of RMHNG as a decentralized Bayesian inference
for approximating the posterior distribution concerning latent variables, which
are jointly shared among agents, akin to MHNG. Moreover, the utilization of
RMHNG elucidated the agents' capacity to exchange symbols. Furthermore, the
study discovered that even the computationally simplified version of RMHNG
could enable symbols to emerge among the agents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention-Based Methods For Audio Question Answering. (arXiv:2305.19769v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19769">
<div class="article-summary-box-inner">
<span><p>Audio question answering (AQA) is the task of producing natural language
answers when a system is provided with audio and natural language questions. In
this paper, we propose neural network architectures based on self-attention and
cross-attention for the AQA task. The self-attention layers extract powerful
audio and textual representations. The cross-attention maps audio features that
are relevant to the textual features to produce answers. All our models are
trained on the recently proposed Clotho-AQA dataset for both binary yes/no
questions and single-word answer questions. Our results clearly show
improvement over the reference method reported in the original paper. On the
yes/no binary classification task, our proposed model achieves an accuracy of
68.3% compared to 62.7% in the reference model. For the single-word answers
multiclass classifier, our model produces a top-1 and top-5 accuracy of 57.9%
and 99.8% compared to 54.2% and 93.7% in the reference model respectively. We
further discuss some of the challenges in the Clotho-AQA dataset such as the
presence of the same answer word in multiple tenses, singular and plural forms,
and the presence of specific and generic answers to the same question. We
address these issues and present a revised version of the dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IDAS: Intent Discovery with Abstractive Summarization. (arXiv:2305.19783v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19783">
<div class="article-summary-box-inner">
<span><p>Intent discovery is the task of inferring latent intents from a set of
unlabeled utterances, and is a useful step towards the efficient creation of
new conversational agents. We show that recent competitive methods in intent
discovery can be outperformed by clustering utterances based on abstractive
summaries, i.e., "labels", that retain the core elements while removing
non-essential information. We contribute the IDAS approach, which collects a
set of descriptive utterance labels by prompting a Large Language Model,
starting from a well-chosen seed set of prototypical utterances, to bootstrap
an In-Context Learning procedure to generate labels for non-prototypical
utterances. The utterances and their resulting noisy labels are then encoded by
a frozen pre-trained encoder, and subsequently clustered to recover the latent
intents. For the unsupervised task (without any intent labels) IDAS outperforms
the state-of-the-art by up to +7.42% in standard cluster metrics for the
Banking, StackOverflow, and Transport datasets. For the semi-supervised task
(with labels for a subset of intents) IDAS surpasses 2 recent methods on the
CLINC benchmark without even using labeled data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Question Answering Modeling Improvements Hold Across Benchmarks?. (arXiv:2102.01065v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01065">
<div class="article-summary-box-inner">
<span><p>Do question answering (QA) modeling improvements (e.g., choice of
architecture and training procedure) hold consistently across the diverse
landscape of QA benchmarks? To study this question, we introduce the notion of
concurrence -- two benchmarks have high concurrence on a set of modeling
approaches if they rank the modeling approaches similarly. We measure the
concurrence between 32 QA benchmarks on a set of 20 diverse modeling approaches
and find that human-constructed benchmarks have high concurrence amongst
themselves, even if their passage and question distributions are very
different. Surprisingly, even downsampled human-constructed benchmarks (i.e.,
collecting less data) and programmatically-generated benchmarks (e.g.,
cloze-formatted examples) have high concurrence with human-constructed
benchmarks. These results indicate that, despite years of intense community
focus on a small number of benchmarks, the modeling improvements studied hold
broadly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AmbiFC: Fact-Checking Ambiguous Claims with Evidence. (arXiv:2104.00640v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00640">
<div class="article-summary-box-inner">
<span><p>Automated fact-checking systems in real-world scenarios must compare claims
with retrieved evidence to predict the veracity. The retrieved evidence may not
unambiguously support or refute the claim and yield diverse valid
interpretations. Existing fact-checking datasets necessitate that models
predict a single veracity label for each claim and lack the ability to manage
such ambiguity. We present AmbiFC, a large-scale fact-checking dataset with
realistic claims derived from real-world information needs. Our dataset
contains fine-grained evidence annotations of passages from complete Wikipedia
pages. We thoroughly analyze disagreements arising from ambiguous claims in
AmbiFC, observing a strong correlation of annotator disagreement with their
self-assessment and expert-annotated linguistic phenomena. We introduce the
task of evidence-based fact-checking for ambiguous claims with soft labels, and
compare three methodologies incorporating annotation signals with a
single-label classification approach. We find that a pipeline with annotation
distillation for sentence-level evidence selection and veracity prediction
yields the best performance. Models trained on ambiguous instances exhibit
improved performance dealing with the identified linguistic categories, and
acquire an understanding of nuanced differences among evidence sentences
associated with diverse veracity interpretations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decepticons: Corrupted Transformers Breach Privacy in Federated Learning for Language Models. (arXiv:2201.12675v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12675">
<div class="article-summary-box-inner">
<span><p>A central tenet of Federated learning (FL), which trains models without
centralizing user data, is privacy. However, previous work has shown that the
gradient updates used in FL can leak user information. While the most
industrial uses of FL are for text applications (e.g. keystroke prediction),
nearly all attacks on FL privacy have focused on simple image classifiers. We
propose a novel attack that reveals private user text by deploying malicious
parameter vectors, and which succeeds even with mini-batches, multiple users,
and long sequences. Unlike previous attacks on FL, the attack exploits
characteristics of both the Transformer architecture and the token embedding,
separately extracting tokens and positional embeddings to retrieve
high-fidelity text. This work suggests that FL on text, which has historically
been resistant to privacy attacks, is far more vulnerable than previously
thought.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Document Summarization with Centroid-Based Pretraining. (arXiv:2208.01006v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.01006">
<div class="article-summary-box-inner">
<span><p>In Multi-Document Summarization (MDS), the input can be modeled as a set of
documents, and the output is its summary. In this paper, we focus on
pretraining objectives for MDS. Specifically, we introduce a novel pretraining
objective, which involves selecting the ROUGE-based centroid of each document
cluster as a proxy for its summary. Our objective thus does not require human
written summaries and can be utilized for pretraining on a dataset consisting
solely of document sets. Through zero-shot, few-shot, and fully supervised
experiments on multiple MDS datasets, we show that our model Centrum is better
or comparable to a state-of-the-art model. We make the pretrained and
fine-tuned models freely available to the research community
https://github.com/ratishsp/centrum.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ILLUME: Rationalizing Vision-Language Models through Human Interactions. (arXiv:2208.08241v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.08241">
<div class="article-summary-box-inner">
<span><p>Bootstrapping from pre-trained language models has been proven to be an
efficient approach for building vision-language models (VLM) for tasks such as
image captioning or visual question answering. However, outputs of these models
rarely align with user's rationales for specific answers. In order to improve
this alignment and reinforce commonsense reasons, we propose a tuning paradigm
based on human interactions with machine-generated data. Our ILLUME executes
the following loop: Given an image-question-answer prompt, the VLM samples
multiple candidate rationales, and a human critic provides feedback via
preference selection, used for fine-tuning. This loop increases the training
data and gradually carves out the VLM's rationalization capabilities that are
aligned with human intent. Our exhaustive experiments demonstrate that ILLUME
is competitive with standard supervised finetuning while using significantly
fewer training data and only requiring minimal feedback.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Variational Open-Domain Question Answering. (arXiv:2210.06345v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06345">
<div class="article-summary-box-inner">
<span><p>Retrieval-augmented models have proven to be effective in natural language
processing tasks, yet there remains a lack of research on their optimization
using variational inference. We introduce the Variational Open-Domain (VOD)
framework for end-to-end training and evaluation of retrieval-augmented models,
focusing on open-domain question answering and language modelling. The VOD
objective, a self-normalized estimate of the R\'enyi variational bound,
approximates the task marginal likelihood and is evaluated under samples drawn
from an auxiliary sampling distribution (cached retriever and/or approximate
posterior). It remains tractable, even for retriever distributions defined on
large corpora. We demonstrate VOD's versatility by training reader-retriever
BERT-sized models on multiple-choice medical exam questions. On the MedMCQA
dataset, we outperform the domain-tuned Med-PaLM by +5.3% despite using
2.500$\times$ fewer parameters. Our retrieval-augmented BioLinkBERT model
scored 62.9% on the MedMCQA and 55.0% on the MedQA-USMLE. Last, we show the
effectiveness of our learned retriever component in the context of medical
semantic search.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are Sample-Efficient NLP Models More Robust?. (arXiv:2210.06456v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06456">
<div class="article-summary-box-inner">
<span><p>Recent results in image classification and extractive question answering have
observed that pre-trained models trained on less in-distribution data have
better out-of-distribution performance. However, it is unclear how broadly
these trends hold. We conduct a large empirical study across three tasks, three
broadly-applicable modeling interventions (increasing model size, using a
different adaptation method, and pre-training on more data), and 14 diverse
datasets to investigate the relationship between sample efficiency (amount of
data needed to reach a given ID accuracy) and robustness (how models fare on
OOD evaluation). We find that higher sample efficiency is only correlated with
better average OOD robustness on some modeling interventions and tasks, but not
others. On individual datasets, models with lower sample efficiency can even be
more robust. These results suggest that general-purpose methods for improving
sample efficiency are unlikely to yield universal OOD robustness improvements,
since such improvements are highly dataset- and task-dependent. Even in an era
of large, multi-purpose pretrained models, task-specific decisions may often be
necessary for OOD generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mention Annotations Alone Enable Efficient Domain Adaptation for Coreference Resolution. (arXiv:2210.07602v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07602">
<div class="article-summary-box-inner">
<span><p>Although recent neural models for coreference resolution have led to
substantial improvements on benchmark datasets, transferring these models to
new target domains containing out-of-vocabulary spans and requiring differing
annotation schemes remains challenging. Typical approaches involve continued
training on annotated target-domain data, but obtaining annotations is costly
and time-consuming. We show that annotating mentions alone is nearly twice as
fast as annotating full coreference chains. Accordingly, we propose a method
for efficiently adapting coreference models, which includes a high-precision
mention detection objective and requires annotating only mentions in the target
domain. Extensive evaluation across three English coreference datasets:
CoNLL-2012 (news/conversation), i2b2/VA (medical notes), and previously
unstudied child welfare notes, reveals that our approach facilitates
annotation-efficient transfer and results in a 7-14% improvement in average F1
without increasing annotator time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RARR: Researching and Revising What Language Models Say, Using Language Models. (arXiv:2210.08726v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08726">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) now excel at many tasks such as few-shot learning,
question answering, reasoning, and dialog. However, they sometimes generate
unsupported or misleading content. A user cannot easily determine whether their
outputs are trustworthy or not, because most LMs do not have any built-in
mechanism for attribution to external evidence. To enable attribution while
still preserving all the powerful advantages of recent generation models, we
propose RARR (Retrofit Attribution using Research and Revision), a system that
1) automatically finds attribution for the output of any text generation model
and 2) post-edits the output to fix unsupported content while preserving the
original output as much as possible. When applied to the output of several
state-of-the-art LMs on a diverse set of generation tasks, we find that RARR
significantly improves attribution while otherwise preserving the original
input to a much greater degree than previously explored edit models.
Furthermore, the implementation of RARR requires only a handful of training
examples, a large language model, and standard web search.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating context-invariance in unsupervised speech representations. (arXiv:2210.15775v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.15775">
<div class="article-summary-box-inner">
<span><p>Unsupervised speech representations have taken off, with benchmarks (SUPERB,
ZeroSpeech) demonstrating major progress on semi-supervised speech recognition,
speech synthesis, and speech-only language modelling. Inspiration comes from
the promise of ``discovering the phonemes'' of a language or a similar
low-bitrate encoding. However, one of the critical properties of phoneme
transcriptions is context-invariance: the phonetic context of a speech sound
can have massive influence on the way it is pronounced, while the text remains
stable. This is what allows tokens of the same word to have the same
transcriptions -- key to language understanding. Current benchmarks do not
measure context-invariance. We develop a new version of the ZeroSpeech ABX
benchmark that measures context-invariance, and apply it to recent
self-supervised representations. We demonstrate that the context-independence
of representations is predictive of the stability of word-level
representations. We suggest research concentrate on improving
context-independence of self-supervised and unsupervised representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MT4SSL: Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets. (arXiv:2211.07321v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.07321">
<div class="article-summary-box-inner">
<span><p>In this paper, we provide a new perspective on self-supervised speech models
from how the training targets are obtained. We generalize the targets extractor
into Offline Targets Extractor (Off-TE) and Online Targets Extractor (On-TE).
Based on this, we propose a new multi-tasking learning framework for
self-supervised learning, MT4SSL, which stands for Boosting Self-Supervised
Speech Representation Learning by Integrating Multiple Targets. MT4SSL uses the
K-means algorithm as an Off-TE and a teacher network without gradients as an
On-TE, respectively. Our model outperforms previous SSL methods by nontrivial
margins on the LibriSpeech benchmark, and is comparable to or even better than
the best-performing models with fewer data. Furthermore, we find that using
both Off-TE and On-TE results in better convergence in the pre-training phase.
With both effectiveness and efficiency, we think doing multi-task learning on
self-supervised speech models from our perspective is a promising trend.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformers learn in-context by gradient descent. (arXiv:2212.07677v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.07677">
<div class="article-summary-box-inner">
<span><p>At present, the mechanisms of in-context learning in Transformers are not
well understood and remain mostly an intuition. In this paper, we suggest that
training Transformers on auto-regressive objectives is closely related to
gradient-based meta-learning formulations. We start by providing a simple
weight construction that shows the equivalence of data transformations induced
by 1) a single linear self-attention layer and by 2) gradient-descent (GD) on a
regression loss. Motivated by that construction, we show empirically that when
training self-attention-only Transformers on simple regression tasks either the
models learned by GD and Transformers show great similarity or, remarkably, the
weights found by optimization match the construction. Thus we show how trained
Transformers become mesa-optimizers i.e. learn models by gradient descent in
their forward pass. This allows us, at least in the domain of regression
problems, to mechanistically understand the inner workings of in-context
learning in optimized Transformers. Building on this insight, we furthermore
identify how Transformers surpass the performance of plain gradient descent by
learning an iterative curvature correction and learn linear models on deep data
representations to solve non-linear regression tasks. Finally, we discuss
intriguing parallels to a mechanism identified to be crucial for in-context
learning termed induction-head (Olsson et al., 2022) and show how it could be
understood as a specific case of in-context learning by gradient descent
learning within Transformers. Code to reproduce the experiments can be found at
https://github.com/google-research/self-organising-systems/tree/master/transformers_learn_icl_by_gd .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DuNST: Dual Noisy Self Training for Semi-Supervised Controllable Text Generation. (arXiv:2212.08724v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.08724">
<div class="article-summary-box-inner">
<span><p>Self-training (ST) has prospered again in language understanding by
augmenting the fine-tuning of pre-trained language models when labeled data is
insufficient. However, it remains challenging to incorporate ST into
attribute-controllable language generation. Augmented by only self-generated
pseudo text, generation models over-emphasize exploitation of the previously
learned space, suffering from a constrained generalization boundary. We revisit
ST and propose a novel method, DuNST to alleviate this problem. DuNST jointly
models text generation and classification with a shared Variational AutoEncoder
and corrupts the generated pseudo text by two kinds of flexible noise to
disturb the space. In this way, our model could construct and utilize both
pseudo text from given labels and pseudo labels from available unlabeled text,
which are gradually refined during the ST process. We theoretically demonstrate
that DuNST can be regarded as enhancing exploration towards the potential real
text space, providing a guarantee of improved performance. Experiments on three
controllable generation tasks show that DuNST could significantly boost control
accuracy while maintaining comparable generation fluency and diversity against
several strong baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Lingual Retrieval Augmented Prompt for Low-Resource Languages. (arXiv:2212.09651v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09651">
<div class="article-summary-box-inner">
<span><p>Multilingual Pretrained Language Models (MPLMs) have shown their strong
multilinguality in recent empirical cross-lingual transfer studies. In this
paper, we propose the Prompts Augmented by Retrieval Crosslingually (PARC)
pipeline to improve the zero-shot performance on low-resource languages (LRLs)
by augmenting the context with semantically similar sentences retrieved from a
high-resource language (HRL) as prompts. PARC improves the zero-shot
performance on three downstream tasks (binary sentiment classification, topic
categorization and natural language inference) with multilingual parallel test
sets across 10 LRLs covering 6 language families in both unlabeled settings
(+5.1%) and labeled settings (+16.3%). PARC-labeled also outperforms the
finetuning baseline by 3.7%. We find a significant positive correlation between
cross-lingual transfer performance on one side, and the similarity between the
high- and low-resource languages as well as the amount of low-resource
pretraining data on the other side. A robustness analysis suggests that PARC
has the potential to achieve even stronger performance with more powerful
MPLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Synthetic Pre-Training Tasks for Neural Machine Translation. (arXiv:2212.09864v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09864">
<div class="article-summary-box-inner">
<span><p>Pre-training models with large crawled corpora can lead to issues such as
toxicity and bias, as well as copyright and privacy concerns. A promising way
of alleviating such concerns is to conduct pre-training with synthetic tasks
and data, since no real-world information is ingested by the model. Our goal in
this paper is to understand the factors that contribute to the effectiveness of
pre-training models when using synthetic resources, particularly in the context
of neural machine translation. We propose several novel approaches to
pre-training translation models that involve different levels of lexical and
structural knowledge, including: 1) generating obfuscated data from a large
parallel corpus 2) concatenating phrase pairs extracted from a small
word-aligned corpus, and 3) generating synthetic parallel data without real
human language corpora. Our experiments on multiple language pairs reveal that
pre-training benefits can be realized even with high levels of obfuscation or
purely synthetic parallel data. We hope the findings from our comprehensive
empirical analysis will shed light on understanding what matters for NMT
pre-training, as well as pave the way for the development of more efficient and
less toxic models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">I Cast Detect Thoughts: Learning to Converse and Guide with Intents and Theory-of-Mind in Dungeons and Dragons. (arXiv:2212.10060v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10060">
<div class="article-summary-box-inner">
<span><p>We propose a novel task, G4C, to study teacher-student natural language
interactions in a goal-driven and grounded environment. Dungeons and Dragons
(D&amp;D), a role-playing game, provides an ideal setting to investigate such
interactions. Here, the Dungeon Master (DM), i.e., the teacher, guides the
actions of several players -- students, each with their own personas and
abilities -- to achieve shared goals grounded in a fantasy world. Our approach
is to decompose and model these interactions into (1) the DM's intent to guide
players toward a given goal; (2) the DM's guidance utterance to the players
expressing this intent; and (3) a theory-of-mind (ToM) model that anticipates
the players' reaction to the guidance one turn into the future. We develop a
novel reinforcement learning (RL) method for training a DM that generates
guidance for players by rewarding utterances where the intent matches the
ToM-anticipated player actions. Human and automated evaluations show that a DM
trained to explicitly model intents and incorporate ToM of the players using RL
generates better-quality guidance that is 3x more likely to fulfill the DM's
intent than a vanilla natural language generation (NLG) approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ClarifyDelphi: Reinforced Clarification Questions with Defeasibility Rewards for Social and Moral Situations. (arXiv:2212.10409v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10409">
<div class="article-summary-box-inner">
<span><p>Context is everything, even in commonsense moral reasoning. Changing contexts
can flip the moral judgment of an action; "Lying to a friend" is wrong in
general, but may be morally acceptable if it is intended to protect their life.
</p>
<p>We present ClarifyDelphi, an interactive system that learns to ask
clarification questions (e.g., why did you lie to your friend?) in order to
elicit additional salient contexts of a social or moral situation. We posit
that questions whose potential answers lead to diverging moral judgments are
the most informative. Thus, we propose a reinforcement learning framework with
a defeasibility reward that aims to maximize the divergence between moral
judgments of hypothetical answers to a question. Human evaluation demonstrates
that our system generates more relevant, informative and defeasible questions
compared to competitive baselines. Our work is ultimately inspired by studies
in cognitive science that have investigated the flexibility in moral cognition
(i.e., the diverse contexts in which moral rules can be bent), and we hope that
research in this direction can assist both cognitive and computational
investigations of moral judgments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generic Temporal Reasoning with Differential Analysis and Explanation. (arXiv:2212.10467v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10467">
<div class="article-summary-box-inner">
<span><p>Temporal reasoning is the task of predicting temporal relations of event
pairs. While temporal reasoning models can perform reasonably well on in-domain
benchmarks, we have little idea of these systems' generalizability due to
existing datasets' limitations. In this work, we introduce a novel task named
TODAY that bridges this gap with temporal differential analysis, which as the
name suggests, evaluates whether systems can correctly understand the effect of
incremental changes. Specifically, TODAY introduces slight contextual changes
for given event pairs, and systems are asked to tell how this subtle contextual
change would affect relevant temporal relation distributions. To facilitate
learning, TODAY also annotates human explanations. We show that existing
models, including GPT-3.5, drop to random guessing on TODAY, suggesting that
they heavily rely on spurious information rather than proper reasoning for
temporal predictions. On the other hand, we show that TODAY's supervision style
and explanation annotations can be used in joint learning, encouraging models
to use more appropriate signals during training and thus outperform across
several benchmarks. TODAY can also be used to train models to solicit
incidental supervision from noisy sources such as GPT-3.5, thus moving us more
toward the goal of generic temporal reasoning systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continual Contrastive Finetuning Improves Low-Resource Relation Extraction. (arXiv:2212.10823v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10823">
<div class="article-summary-box-inner">
<span><p>Relation extraction (RE), which has relied on structurally annotated corpora
for model training, has been particularly challenging in low-resource scenarios
and domains. Recent literature has tackled low-resource RE by self-supervised
learning, where the solution involves pretraining the entity pair embedding by
RE-based objective and finetuning on labeled data by classification-based
objective. However, a critical challenge to this approach is the gap in
objectives, which prevents the RE model from fully utilizing the knowledge in
pretrained representations. In this paper, we aim at bridging the gap and
propose to pretrain and finetune the RE model using consistent objectives of
contrastive learning. Since in this kind of representation learning paradigm,
one relation may easily form multiple clusters in the representation space, we
further propose a multi-center contrastive loss that allows one relation to
form multiple clusters to better align with pretraining. Experiments on two
document-level RE datasets, BioRED and Re-DocRED, demonstrate the effectiveness
of our method. Particularly, when using 1% end-task training data, our method
outperforms PLM-based RE classifier by 10.5% and 6.1% on the two datasets,
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Matching Exemplar as Next Sentence Prediction (MeNSP): Zero-shot Prompt Learning for Automatic Scoring in Science Education. (arXiv:2301.08771v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.08771">
<div class="article-summary-box-inner">
<span><p>Developing models to automatically score students' written responses to
science problems is critical for science education. However, collecting and
labeling sufficient student responses for training models is time and
cost-consuming. Recent studies suggest that pre-trained language models can be
adapted to downstream tasks without fine-tuning with prompts. However, no
research has employed such a prompt approach in science education. As student
responses are presented with natural language, aligning the scoring procedure
as the next sentence prediction task using prompts can skip the costly
fine-tuning stage. In this study, we developed a zero-shot approach to
automatically score student responses via Matching Exemplars as Next Sentence
Prediction (MeNSP). This approach employs no training samples. We first apply
MeNSP in scoring three assessment tasks of scientific argumentation and found
machine-human scoring agreements, Cohen's Kappa ranges from 0.30 to 0.57, and
F1 score ranges from 0.54 to 0.81. To improve the performance, we extend our
research to the few-shots setting, either randomly selecting labeled student
responses or manually constructing responses to fine-tune the models. We find
that one task's performance is improved with more samples, Cohen's Kappa from
0.30 to 0.38, and F1 score from 0.54 to 0.59; for the two others, scoring
performance is not improved. We also find that randomly selected few-shots
perform better than the human expert-crafted approach. This study suggests that
MeNSP can yield referable automatic scoring for student responses while
significantly reducing the cost of model training. This method can benefit
low-stakes classroom assessment practices in science education. Future research
should further explore the applicability of the MeNSP in different types of
assessment tasks in science education and improve the model performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding INT4 Quantization for Transformer Models: Latency Speedup, Composability, and Failure Cases. (arXiv:2301.12017v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.12017">
<div class="article-summary-box-inner">
<span><p>Improving the deployment efficiency of transformer-based language models has
been challenging given their high computation and memory cost. While INT8
quantization has recently been shown to be effective in reducing both the
memory cost and latency while preserving model accuracy, it remains unclear
whether we can leverage INT4 (which doubles peak hardware throughput) to
achieve further latency improvement. In this study, we explore the feasibility
of employing INT4 weight and activation (W4A4) quantization for language
models. Our findings indicate that W4A4 quantization introduces no to
negligible accuracy degradation for encoder-only and encoder-decoder models,
but causes a significant accuracy drop for decoder-only models. To materialize
the performance gain using W4A4, we develop a highly optimized end-to-end W4A4
encoder inference pipeline supporting different quantization strategies. Our
INT4 pipeline is $8.5\times$ faster for latency-oriented scenarios and up to
$3\times$ for throughput-oriented scenarios compared to the inference of FP16,
and improves the SOTA BERT INT8 performance from FasterTransformer by up to
$1.7\times$. We provide insights into the failure cases when applying W4A4 to
decoder-only models, and further explore the compatibility of INT4 quantization
with other compression methods, like pruning and layer reduction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers. (arXiv:2301.13741v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.13741">
<div class="article-summary-box-inner">
<span><p>Real-world data contains a vast amount of multimodal information, among which
vision and language are the two most representative modalities. Moreover,
increasingly heavier models, \textit{e}.\textit{g}., Transformers, have
attracted the attention of researchers to model compression. However, how to
compress multimodal models, especially vison-language Transformers, is still
under-explored. This paper proposes the \textbf{U}nified and
\textbf{P}r\textbf{o}gressive \textbf{P}runing (\textbf{\emph{UPop}}) as a
universal vison-language Transformer compression framework, which incorporates
1) unifiedly searching multimodal subnets in a continuous optimization space
from the original model, which enables automatic assignment of pruning ratios
among compressible modalities and structures; 2) progressively searching and
retraining the subnet, which maintains convergence between the search and
retrain to attain higher compression ratios. Experiments on various tasks,
datasets, and model architectures demonstrate the effectiveness and versatility
of the proposed UPop framework. The code is available at
https://github.com/sdc17/UPop.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models. (arXiv:2301.13826v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.13826">
<div class="article-summary-box-inner">
<span><p>Recent text-to-image generative models have demonstrated an unparalleled
ability to generate diverse and creative imagery guided by a target text
prompt. While revolutionary, current state-of-the-art diffusion models may
still fail in generating images that fully convey the semantics in the given
text prompt. We analyze the publicly available Stable Diffusion model and
assess the existence of catastrophic neglect, where the model fails to generate
one or more of the subjects from the input prompt. Moreover, we find that in
some cases the model also fails to correctly bind attributes (e.g., colors) to
their corresponding subjects. To help mitigate these failure cases, we
introduce the concept of Generative Semantic Nursing (GSN), where we seek to
intervene in the generative process on the fly during inference time to improve
the faithfulness of the generated images. Using an attention-based formulation
of GSN, dubbed Attend-and-Excite, we guide the model to refine the
cross-attention units to attend to all subject tokens in the text prompt and
strengthen - or excite - their activations, encouraging the model to generate
all subjects described in the text prompt. We compare our approach to
alternative approaches and demonstrate that it conveys the desired concepts
more faithfully across a range of text prompts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Query-Utterance Attention with Joint modeling for Query-Focused Meeting Summarization. (arXiv:2303.04487v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04487">
<div class="article-summary-box-inner">
<span><p>Query-focused meeting summarization (QFMS) aims to generate summaries from
meeting transcripts in response to a given query. Previous works typically
concatenate the query with meeting transcripts and implicitly model the query
relevance only at the token level with attention mechanism. However, due to the
dilution of key query-relevant information caused by long meeting transcripts,
the original transformer-based model is insufficient to highlight the key parts
related to the query. In this paper, we propose a query-aware framework with
joint modeling token and utterance based on Query-Utterance Attention. It
calculates the utterance-level relevance to the query with a dense retrieval
module. Then both token-level query relevance and utterance-level query
relevance are combined and incorporated into the generation process with
attention mechanism explicitly. We show that the query relevance of different
granularities contributes to generating a summary more related to the query.
Experimental results on the QMSum dataset show that the proposed model achieves
new state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Partial Knowledge Base Inference in Biomedical Entity Linking. (arXiv:2303.10330v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10330">
<div class="article-summary-box-inner">
<span><p>Biomedical entity linking (EL) consists of named entity recognition (NER) and
named entity disambiguation (NED). EL models are trained on corpora labeled by
a predefined KB. However, it is a common scenario that only entities within a
subset of the KB are precious to stakeholders. We name this scenario partial
knowledge base inference: training an EL model with one KB and inferring on the
part of it without further training. In this work, we give a detailed
definition and evaluation procedures for this practically valuable but
significantly understudied scenario and evaluate methods from three
representative EL paradigms. We construct partial KB inference benchmarks and
witness a catastrophic degradation in EL performance due to dramatically
precision drop. Our findings reveal these EL paradigms can not correctly handle
unlinkable mentions (NIL), so they are not robust to partial KB inference. We
also propose two simple-and-effective redemption methods to combat the NIL
issue with little computational overhead.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">cTBLS: Augmenting Large Language Models with Conversational Tables. (arXiv:2303.12024v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.12024">
<div class="article-summary-box-inner">
<span><p>Optimizing accuracy and performance while eliminating hallucinations of
open-domain conversational large language models (LLMs) is an open research
challenge. A particularly promising direction is to augment and ground LLMs
with information from structured sources. This paper introduces Conversational
Tables (cTBLS), a three-step architecture to retrieve and generate dialogue
responses grounded on retrieved tabular information. cTBLS uses Transformer
encoder embeddings for Dense Table Retrieval and obtains up to 125% relative
improvement over the retriever in the previous state-of-the-art system on the
HyrbiDialogue dataset. cTBLS then uses a shared process between encoder and
decoder models to perform a coarse+fine tabular knowledge (e.g., cell) ranking
combined with a GPT-3.5 LLM response generator to yield a 2x relative
improvement in ROUGE scores. Finally, human evaluators prefer cTBLs +80% of the
time (coherency, fluency) and judge informativeness to be 4x better than the
previous state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Aligning a medium-size GPT model in English to a small closed domain in Spanish. (arXiv:2303.17649v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17649">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a methodology to align a medium-sized GPT model,
originally trained in English for an open domain, to a small closed domain in
Spanish. The application for which the model is finely tuned is the question
answering task. To achieve this we also needed to train and implement another
neural network (which we called the reward model) that could score and
determine whether an answer is appropriate for a given question. This component
served to improve the decoding and generation of the answers of the system.
Numerical metrics such as BLEU and perplexity were used to evaluate the model,
and human judgment was also used to compare the decoding technique with others.
Finally, the results favored the proposed method, and it was determined that it
is feasible to use a reward model to align the generation of responses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling. (arXiv:2304.01373v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.01373">
<div class="article-summary-box-inner">
<span><p>How do large language models (LLMs) develop and evolve over the course of
training? How do these patterns change as models scale? To answer these
questions, we introduce \textit{Pythia}, a suite of 16 LLMs all trained on
public data seen in the exact same order and ranging in size from 70M to 12B
parameters. We provide public access to 154 checkpoints for each one of the 16
models, alongside tools to download and reconstruct their exact training
dataloaders for further study. We intend \textit{Pythia} to facilitate research
in many areas, and we present several case studies including novel results in
memorization, term frequency effects on few-shot performance, and reducing
gender bias. We demonstrate that this highly controlled setup can be used to
yield novel insights toward LLMs and their training dynamics. Trained models,
analysis code, training code, and training data can be found at
\url{https://github.com/EleutherAI/pythia}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System. (arXiv:2305.02468v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02468">
<div class="article-summary-box-inner">
<span><p>Task-Oriented Dialogue (TOD) systems are designed to carry out specific tasks
by tracking dialogue states and generating appropriate responses to help users
achieve defined goals. Recently, end-to-end dialogue models pre-trained based
on large datasets have shown promising performance in the conversational
system. However, they share the same parameters to train tasks of the dialogue
system (NLU, DST, NLG), so debugging each task is challenging. Also, they
require a lot of effort to fine-tune large parameters to create a task-oriented
chatbot, making it difficult for non-experts to handle. Therefore, we intend to
train relatively lightweight and fast models compared to PLM. In this paper, we
propose an End-to-end TOD system with Task-Optimized Adapters which learn
independently per task, adding only small number of parameters after fixed
layers of pre-trained network. We also enhance the performance of the DST and
NLG modules through reinforcement learning, overcoming the learning curve that
has lacked at the adapter learning and enabling the natural and consistent
response generation that is appropriate for the goal. Our method is a
model-agnostic approach and does not require prompt-tuning as only input data
without a prompt. As results of the experiment, our method shows competitive
performance on the MultiWOZ benchmark compared to the existing end-to-end
models. In particular, we attain state-of-the-art performance on the DST task
of 2.2 dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accuracy on the Curve: On the Nonlinear Correlation of ML Performance Between Data Subpopulations. (arXiv:2305.02995v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02995">
<div class="article-summary-box-inner">
<span><p>Understanding the performance of machine learning (ML) models across diverse
data distributions is critically important for reliable applications. Despite
recent empirical studies positing a near-perfect linear correlation between
in-distribution (ID) and out-of-distribution (OOD) accuracies, we empirically
demonstrate that this correlation is more nuanced under subpopulation shifts.
Through rigorous experimentation and analysis across a variety of datasets,
models, and training epochs, we demonstrate that OOD performance often has a
nonlinear correlation with ID performance in subpopulation shifts. Our
findings, which contrast previous studies that have posited a linear
correlation in model performance during distribution shifts, reveal a "moon
shape" correlation (parabolic uptrend curve) between the test performance on
the majority subpopulation and the minority subpopulation. This non-trivial
nonlinear correlation holds across model architectures, hyperparameters,
training durations, and the imbalance between subpopulations. Furthermore, we
found that the nonlinearity of this "moon shape" is causally influenced by the
degree of spurious correlations in the training data. Our controlled
experiments show that stronger spurious correlation in the training data
creates more nonlinear performance correlation. We provide complementary
experimental and theoretical analyses for this phenomenon, and discuss its
implications for ML reliability and fairness. Our work highlights the
importance of understanding the nonlinear effects of model improvement on
performance in different subpopulations, and has the potential to inform the
development of more equitable and responsible machine learning models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Role of Global and Local Context in Named Entity Recognition. (arXiv:2305.03132v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03132">
<div class="article-summary-box-inner">
<span><p>Pre-trained transformer-based models have recently shown great performance
when applied to Named Entity Recognition (NER). As the complexity of their
self-attention mechanism prevents them from processing long documents at once,
these models are usually applied in a sequential fashion. Such an approach
unfortunately only incorporates local context and prevents leveraging global
document context in long documents such as novels, which might hinder
performance. In this article, we explore the impact of global document context,
and its relationships with local context. We find that correctly retrieving
global document context has a greater impact on performance than only
leveraging local context, prompting for further research on how to better
retrieve that context.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Hidden Mystery of OCR in Large Multimodal Models. (arXiv:2305.07895v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07895">
<div class="article-summary-box-inner">
<span><p>Large models have recently played a dominant role in natural language
processing and multimodal vision-language learning. It remains less explored
about their efficacy in text-related visual tasks. We conducted a comprehensive
study of existing publicly available multimodal models, evaluating their
performance in text recognition (document text, artistic text, handwritten
text, scene text), text-based visual question answering (document text, scene
text, and bilingual text), key information extraction (receipts, documents, and
nutrition facts) and handwritten mathematical expression recognition. Our
findings reveal strengths and weaknesses in these models, which primarily rely
on semantic understanding for word recognition and exhibit inferior perception
of individual character shapes. They also display indifference towards text
length and have limited capabilities in detecting fine-grained features in
images. Consequently, these results demonstrate that even the current most
powerful large multimodal models cannot match domain-specific methods in
traditional text tasks and face greater challenges in more complex tasks. Most
importantly, the baseline results showcased in this study could provide a
foundational framework for the conception and assessment of innovative
strategies targeted at enhancing zero-shot multimodal techniques. Evaluation
pipeline will be available at https://github.com/Yuliang-Liu/MultimodalOCR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QUEST: A Retrieval Dataset of Entity-Seeking Queries with Implicit Set Operations. (arXiv:2305.11694v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11694">
<div class="article-summary-box-inner">
<span><p>Formulating selective information needs results in queries that implicitly
specify set operations, such as intersection, union, and difference. For
instance, one might search for "shorebirds that are not sandpipers" or
"science-fiction films shot in England". To study the ability of retrieval
systems to meet such information needs, we construct QUEST, a dataset of 3357
natural language queries with implicit set operations, that map to a set of
entities corresponding to Wikipedia documents. The dataset challenges models to
match multiple constraints mentioned in queries with corresponding evidence in
documents and correctly perform various set operations. The dataset is
constructed semi-automatically using Wikipedia category names. Queries are
automatically composed from individual categories, then paraphrased and further
validated for naturalness and fluency by crowdworkers. Crowdworkers also assess
the relevance of entities based on their documents and highlight attribution of
query constraints to spans of document text. We analyze several modern
retrieval systems, finding that they often struggle on such queries. Queries
involving negation and conjunction are particularly challenging and systems are
further challenged with combinations of these operations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparison of Multilingual Self-Supervised and Weakly-Supervised Speech Pre-Training for Adaptation to Unseen Languages. (arXiv:2305.12606v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.12606">
<div class="article-summary-box-inner">
<span><p>Recent models such as XLS-R and Whisper have made multilingual speech
technologies more accessible by pre-training on audio from around 100 spoken
languages each. However, there are thousands of spoken languages worldwide, and
adapting to new languages is an important problem. In this work, we aim to
understand which model adapts better to languages unseen during pre-training.
We fine-tune both models on 13 unseen languages and 18 seen languages. Our
results show that the number of hours seen per language and language family
during pre-training is predictive of how the models compare, despite the
significant differences in the pre-training methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Bias and Fairness in NLP: How to have a fairer text classification?. (arXiv:2305.12829v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.12829">
<div class="article-summary-box-inner">
<span><p>In this paper, we provide a holistic analysis of the different sources of
bias, Upstream, Sample and Overampflication biases, in NLP models. We
investigate how they impact the fairness of the task of text classification. We
also investigate the impact of removing these biases using different debiasing
techniques on the fairness of text classification. We found that
overamplification bias is the most impactful bias on the fairness of text
classification. And that removing overamplification bias by fine-tuning the LM
models on a dataset with balanced representations of the different identity
groups leads to fairer text classification models. Finally, we build on our
findings and introduce practical guidelines on how to have a fairer text
classification model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion. (arXiv:2305.14652v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14652">
<div class="article-summary-box-inner">
<span><p>Video multimodal fusion aims to integrate multimodal signals in videos, such
as visual, audio and text, to make a complementary prediction with multiple
modalities contents. However, unlike other image-text multimodal tasks, video
has longer multimodal sequences with more redundancy and noise in both visual
and audio modalities. Prior denoising methods like forget gate are coarse in
the granularity of noise filtering. They often suppress the redundant and noisy
information at the risk of losing critical information. Therefore, we propose a
denoising bottleneck fusion (DBF) model for fine-grained video multimodal
fusion. On the one hand, we employ a bottleneck mechanism to filter out noise
and redundancy with a restrained receptive field. On the other hand, we use a
mutual information maximization module to regulate the filter-out module to
preserve key information within different modalities. Our DBF model achieves
significant improvement over current state-of-the-art baselines on multiple
benchmarks covering multimodal sentiment analysis and multimodal summarization
tasks. It proves that our model can effectively capture salient features from
noisy and redundant video, audio, and text inputs. The code for this paper is
publicly available at https://github.com/WSXRHFG/DBF.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do GPTs Produce Less Literal Translations?. (arXiv:2305.16806v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16806">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) such as GPT-3 have emerged as general-purpose
language models capable of addressing many natural language generation or
understanding tasks. On the task of Machine Translation (MT), multiple works
have investigated few-shot prompting mechanisms to elicit better translations
from LLMs. However, there has been relatively little investigation on how such
translations differ qualitatively from the translations generated by standard
Neural Machine Translation (NMT) models. In this work, we investigate these
differences in terms of the literalness of translations produced by the two
systems. Using literalness measures involving word alignment and monotonicity,
we find that translations out of English (E-X) from GPTs tend to be less
literal, while exhibiting similar or better scores on MT quality metrics. We
demonstrate that this finding is borne out in human evaluations as well. We
then show that these differences are especially pronounced when translating
sentences that contain idiomatic expressions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Computational Power of Decoder-Only Transformer Language Models. (arXiv:2305.17026v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17026">
<div class="article-summary-box-inner">
<span><p>This article presents a theoretical evaluation of the computational
universality of decoder-only transformer models. We extend the theoretical
literature on transformer models and show that decoder-only transformer
architectures (even with only a single layer and single attention head) are
Turing complete under reasonable assumptions. From the theoretical analysis, we
show sparsity/compressibility of the word embedding to be a necessary condition
for Turing completeness to hold.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Honey, I Shrunk the Language: Language Model Behavior at Reduced Scale. (arXiv:2305.17266v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17266">
<div class="article-summary-box-inner">
<span><p>In recent years, language models have drastically grown in size, and the
abilities of these models have been shown to improve with scale. The majority
of recent scaling laws studies focused on high-compute high-parameter count
settings, leaving the question of when these abilities begin to emerge largely
unanswered. In this paper, we investigate whether the effects of pre-training
can be observed when the problem size is reduced, modeling a smaller,
reduced-vocabulary language. We show the benefits of pre-training with masked
language modeling (MLM) objective in models as small as 1.25M parameters, and
establish a strong correlation between pre-training perplexity and downstream
performance (GLUE benchmark). We examine downscaling effects, extending scaling
laws to models as small as ~1M parameters. At this scale, we observe a break of
the power law for compute-optimal models and show that the MLM loss does not
scale smoothly with compute-cost (FLOPs) below $2.2 \times 10^{15}$ FLOPs. We
also find that adding layers does not always benefit downstream performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Framework For Refining Text Classification and Object Recognition from Academic Articles. (arXiv:2305.17401v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17401">
<div class="article-summary-box-inner">
<span><p>With the widespread use of the internet, it has become increasingly crucial
to extract specific information from vast amounts of academic articles
efficiently. Data mining techniques are generally employed to solve this issue.
However, data mining for academic articles is challenging since it requires
automatically extracting specific patterns in complex and unstructured layout
documents. Current data mining methods for academic articles employ
rule-based(RB) or machine learning(ML) approaches. However, using rule-based
methods incurs a high coding cost for complex typesetting articles. On the
other hand, simply using machine learning methods requires annotation work for
complex content types within the paper, which can be costly. Furthermore, only
using machine learning can lead to cases where patterns easily recognized by
rule-based methods are mistakenly extracted. To overcome these issues, from the
perspective of analyzing the standard layout and typesetting used in the
specified publication, we emphasize implementing specific methods for specific
characteristics in academic articles. We have developed a novel Text Block
Refinement Framework (TBRF), a machine learning and rule-based scheme hybrid.
We used the well-known ACL proceeding articles as experimental data for the
validation experiment. The experiment shows that our approach achieved over 95%
classification accuracy and 90% detection accuracy for tables and figures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Curse of Recursion: Training on Generated Data Makes Models Forget. (arXiv:2305.17493v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17493">
<div class="article-summary-box-inner">
<span><p>Stable Diffusion revolutionised image creation from descriptive text. GPT-2,
GPT-3(.5) and GPT-4 demonstrated astonishing performance across a variety of
language tasks. ChatGPT introduced such language models to the general public.
It is now clear that large language models (LLMs) are here to stay, and will
bring about drastic change in the whole ecosystem of online text and images. In
this paper we consider what the future might hold. What will happen to GPT-{n}
once LLMs contribute much of the language found online? We find that use of
model-generated content in training causes irreversible defects in the
resulting models, where tails of the original content distribution disappear.
We refer to this effect as Model Collapse and show that it can occur in
Variational Autoencoders, Gaussian Mixture Models and LLMs. We build
theoretical intuition behind the phenomenon and portray its ubiquity amongst
all learned generative models. We demonstrate that it has to be taken seriously
if we are to sustain the benefits of training from large-scale data scraped
from the web. Indeed, the value of data collected about genuine human
interactions with systems will be increasingly valuable in the presence of
content generated by LLMs in data crawled from the Internet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Practical PCG Through Large Language Models. (arXiv:2305.18243v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18243">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have proven to be useful tools in various
domains outside of the field of their inception, which was natural language
processing. In this study, we provide practical directions on how to use LLMs
to generate 2D-game rooms for an under-development game, named Metavoidal. Our
technique can harness the power of GPT-3 by Human-in-the-loop fine-tuning which
allows our method to create 37% Playable-Novel levels from as scarce data as
only 60 hand-designed rooms under a scenario of the non-trivial game, with
respect to (Procedural Content Generation) PCG, that has a good amount of local
and global constraints.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models. (arXiv:2305.18703v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18703">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have significantly advanced the field of natural
language processing (NLP), providing a highly useful, task-agnostic foundation
for a wide range of applications. The great promise of LLMs as general task
solvers motivated people to extend their functionality largely beyond just a
``chatbot'', and use it as an assistant or even replacement for domain experts
and tools in specific domains such as healthcare, finance, and education.
However, directly applying LLMs to solve sophisticated problems in specific
domains meets many hurdles, caused by the heterogeneity of domain data, the
sophistication of domain knowledge, the uniqueness of domain objectives, and
the diversity of the constraints (e.g., various social norms, cultural
conformity, religious beliefs, and ethical standards in the domain
applications). To fill such a gap, explosively-increase research, and practices
have been conducted in very recent years on the domain specialization of LLMs,
which, however, calls for a comprehensive and systematic review to better
summarizes and guide this promising domain. In this survey paper, first, we
propose a systematic taxonomy that categorizes the LLM domain-specialization
techniques based on the accessibility to LLMs and summarizes the framework for
all the subcategories as well as their relations and differences to each other.
We also present a comprehensive taxonomy of critical application domains that
can benefit from specialized LLMs, discussing their practical significance and
open challenges. Furthermore, we offer insights into the current research
status and future trends in this area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scalable Performance Analysis for Vision-Language Models. (arXiv:2305.18786v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18786">
<div class="article-summary-box-inner">
<span><p>Joint vision-language models have shown great performance over a diverse set
of tasks. However, little is known about their limitations, as the high
dimensional space learned by these models makes it difficult to identify
semantic errors. Recent work has addressed this problem by designing highly
controlled probing task benchmarks. Our paper introduces a more scalable
solution that relies on already annotated benchmarks. Our method consists of
extracting a large set of diverse features from a vision-language benchmark and
measuring their correlation with the output of the target model. We confirm
previous findings that CLIP behaves like a bag of words model and performs
better with nouns and verbs; we also uncover novel insights such as CLIP
getting confused by concrete words. Our framework is available at
https://github.com/MichiganNLP/Scalable-VLM-Probing and can be used with other
multimodal models and benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross Encoding as Augmentation: Towards Effective Educational Text Classification. (arXiv:2305.18977v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18977">
<div class="article-summary-box-inner">
<span><p>Text classification in education, usually called auto-tagging, is the
automated process of assigning relevant tags to educational content, such as
questions and textbooks. However, auto-tagging suffers from a data scarcity
problem, which stems from two major challenges: 1) it possesses a large tag
space and 2) it is multi-label. Though a retrieval approach is reportedly good
at low-resource scenarios, there have been fewer efforts to directly address
the data scarcity problem. To mitigate these issues, here we propose a novel
retrieval approach CEAA that provides effective learning in educational text
classification. Our main contributions are as follows: 1) we leverage transfer
learning from question-answering datasets, and 2) we propose a simple but
effective data augmentation method introducing cross-encoder style texts to a
bi-encoder architecture for more efficient inference. An extensive set of
experiments shows that our proposed method is effective in multi-label
scenarios and low-resource tags compared to state-of-the-art models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controlled Text Generation with Hidden Representation Transformations. (arXiv:2305.19230v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19230">
<div class="article-summary-box-inner">
<span><p>We propose CHRT (Control Hidden Representation Transformation) - a controlled
language generation framework that steers large language models to generate
text pertaining to certain attributes (such as toxicity). CHRT gains attribute
control by modifying the hidden representation of the base model through
learned transformations. We employ a contrastive-learning framework to learn
these transformations that can be combined to gain multi-attribute control. The
effectiveness of CHRT is experimentally shown by comparing it with seven
baselines over three attributes. CHRT outperforms all the baselines in the task
of detoxification, positive sentiment steering, and text simplification while
minimizing the loss in linguistic qualities. Further, our approach has the
lowest inference latency of only 0.01 seconds more than the base model, making
it the most suitable for high-performance production environments. We
open-source our code and release two novel datasets to further propel
controlled language generation research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grammar Prompting for Domain-Specific Language Generation with Large Language Models. (arXiv:2305.19234v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19234">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) can learn to perform a wide range of natural
language tasks from just a handful of in-context examples. However, for
generating strings from highly structured languages (e.g., semantic parsing to
complex domain-specific languages), it is challenging for the LLM to generalize
from just a few exemplars. We explore $\textbf{grammar prompting}$ as a simple
approach for enabling LLMs to use external knowledge and domain-specific
constraints, expressed through a grammar expressed in Backus--Naur Form (BNF),
during in-context learning. Grammar prompting augments each demonstration
example with a specialized grammar that is minimally sufficient for generating
the particular output example, where the specialized grammar is a subset of the
full DSL grammar. For inference, the LLM first predicts a BNF grammar given a
test input, and then generates the output according to the rules of the
grammar. Experiments demonstrate that grammar prompting can enable LLMs to
perform competitively on a diverse set of DSL generation tasks, including
semantic parsing (SMCalFlow, Overnight, GeoQuery), PDDL planning, and even
molecule generation (SMILES).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CONE: An Efficient COarse-to-fiNE Alignment Framework for Long Video Temporal Grounding. (arXiv:2209.10918v2 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.10918">
<div class="article-summary-box-inner">
<span><p>This paper tackles an emerging and challenging problem of long video temporal
grounding~(VTG) that localizes video moments related to a natural language (NL)
query. Compared with short videos, long videos are also highly demanded but
less explored, which brings new challenges in higher inference computation cost
and weaker multi-modal alignment. To address these challenges, we propose CONE,
an efficient COarse-to-fiNE alignment framework. CONE is a plug-and-play
framework on top of existing VTG models to handle long videos through a sliding
window mechanism. Specifically, CONE (1) introduces a query-guided window
selection strategy to speed up inference, and (2) proposes a coarse-to-fine
mechanism via a novel incorporation of contrastive learning to enhance
multi-modal alignment for long videos. Extensive experiments on two large-scale
long VTG benchmarks consistently show both substantial performance gains (e.g.,
from 3.13% to 6.87% on MAD) and state-of-the-art results. Analyses also reveal
higher efficiency as the query-guided window selection mechanism accelerates
inference time by 2x on Ego4D-NLQ and 15x on MAD while keeping SOTA results.
Codes have been released at https://github.com/houzhijian/CONE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-training for Speech Translation: CTC Meets Optimal Transport. (arXiv:2301.11716v2 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.11716">
<div class="article-summary-box-inner">
<span><p>The gap between speech and text modalities is a major challenge in
speech-to-text translation (ST). Different methods have been proposed to reduce
this gap, but most of them require architectural changes in ST training. In
this work, we propose to mitigate this issue at the pre-training stage,
requiring no change in the ST model. First, we show that the connectionist
temporal classification (CTC) loss can reduce the modality gap by design. We
provide a quantitative comparison with the more common cross-entropy loss,
showing that pre-training with CTC consistently achieves better final ST
accuracy. Nevertheless, CTC is only a partial solution and thus, in our second
contribution, we propose a novel pre-training method combining CTC and optimal
transport to further reduce this gap. Our method pre-trains a Siamese-like
model composed of two encoders, one for acoustic inputs and the other for
textual inputs, such that they produce representations that are close to each
other in the Wasserstein space. Extensive experiments on the standard CoVoST-2
and MuST-C datasets show that our pre-training method applied to the vanilla
encoder-decoder Transformer achieves state-of-the-art performance under the
no-external-data setting, and performs on par with recent strong multi-task
learning systems trained with external data. Finally, our method can also be
applied on top of these multi-task systems, leading to further improvements for
these models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AdaPlanner: Adaptive Planning from Feedback with Language Models. (arXiv:2305.16653v1 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16653">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have recently demonstrated the potential in
acting as autonomous agents for sequential decision-making tasks. However, most
existing methods either take actions greedily without planning or rely on
static plans that are not adaptable to environmental feedback. Consequently,
the sequential decision-making performance of LLM agents degenerates with
problem complexity and plan horizons increase. We propose a closed-loop
approach, AdaPlanner, which allows the LLM agent to refine its self-generated
plan adaptively in response to environmental feedback. In AdaPlanner, the LLM
agent adaptively refines its plan from feedback with both in-plan and
out-of-plan refinement strategies. To mitigate hallucination, we develop a
code-style LLM prompt structure that facilitates plan generation across a
variety of tasks, environments, and agent capabilities. Furthermore, we propose
a skill discovery mechanism that leverages successful plans as few-shot
exemplars, enabling the agent to plan and refine with fewer task
demonstrations. Our experiments in the ALFWorld and MiniWoB++ environments
demonstrate that AdaPlanner outperforms state-of-the-art baselines by 3.73% and
4.11% while utilizing 2x and 600x fewer samples, respectively.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-06-01 23:11:38.534355377 UTC">2023-06-01 23:11:38 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>