<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-03-09T01:30:00Z">03-09</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Gradient-Free Structured Pruning with Unlabeled Data. (arXiv:2303.04185v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04185">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have achieved great success in solving difficult
tasks across many domains, but such success comes with a high computation cost,
and inference latency. As developers and third parties customize these models,
the need to provide efficient inference has increased. Many efforts have
attempted to reduce inference cost through model compression techniques such as
pruning and distillation. However, these techniques either require labeled
data, or are time-consuming as they require the compressed model to be
retrained to regain accuracy. In this paper, we propose a gradient-free
structured pruning framework that uses only unlabeled data. An evaluation on
the GLUE and SQuAD benchmarks using BERT$_{BASE}$ and DistilBERT illustrates
the effectiveness of the proposed approach. By only using the weights of the
pre-trained model and unlabeled data, in a matter of a few minutes on a single
GPU, up to 40% of the original FLOP count can be reduced with less than a 4%
accuracy loss across all tasks considered.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SemEval-2023 Task 10: Explainable Detection of Online Sexism. (arXiv:2303.04222v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04222">
<div class="article-summary-box-inner">
<span><p>Online sexism is a widespread and harmful phenomenon. Automated tools can
assist the detection of sexism at scale. Binary detection, however, disregards
the diversity of sexist content, and fails to provide clear explanations for
why something is sexist. To address this issue, we introduce SemEval Task 10 on
the Explainable Detection of Online Sexism (EDOS). We make three main
contributions: i) a novel hierarchical taxonomy of sexist content, which
includes granular vectors of sexism to aid explainability; ii) a new dataset of
20,000 social media comments with fine-grained labels, along with larger
unlabelled datasets for model adaptation; and iii) baseline models as well as
an analysis of the methods, results and errors for participant submissions to
our task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT. (arXiv:2303.04226v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04226">
<div class="article-summary-box-inner">
<span><p>Recently, ChatGPT, along with DALL-E-2 and Codex,has been gaining significant
attention from society. As a result, many individuals have become interested in
related resources and are seeking to uncover the background and secrets behind
its impressive performance. In fact, ChatGPT and other Generative AI (GAI)
techniques belong to the category of Artificial Intelligence Generated Content
(AIGC), which involves the creation of digital content, such as images, music,
and natural language, through AI models. The goal of AIGC is to make the
content creation process more efficient and accessible, allowing for the
production of high-quality content at a faster pace. AIGC is achieved by
extracting and understanding intent information from instructions provided by
human, and generating the content according to its knowledge and the intent
information. In recent years, large-scale models have become increasingly
important in AIGC as they provide better intent extraction and thus, improved
generation results. With the growth of data and the size of the models, the
distribution that the model can learn becomes more comprehensive and closer to
reality, leading to more realistic and high-quality content generation. This
survey provides a comprehensive review on the history of generative models, and
basic components, recent advances in AIGC from unimodal interaction and
multimodal interaction. From the perspective of unimodality, we introduce the
generation tasks and relative models of text and image. From the perspective of
multimodality, we introduce the cross-application between the modalities
mentioned above. Finally, we discuss the existing open problems and future
challenges in AIGC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Natural Language Understanding Systems. A Critical Analysis. (arXiv:2303.04229v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04229">
<div class="article-summary-box-inner">
<span><p>The development of machines that {\guillemotleft}talk like
us{\guillemotright}, also known as Natural Language Understanding (NLU)
systems, is the Holy Grail of Artificial Intelligence (AI), since language is
the quintessence of human intelligence. The brief but intense life of NLU
research in AI and Natural Language Processing (NLP) is full of ups and downs,
with periods of high hopes that the Grail is finally within reach, typically
followed by phases of equally deep despair and disillusion. But never has the
trust that we can build {\guillemotleft}talking machines{\guillemotright} been
stronger than the one engendered by the last generation of NLU systems. But is
it gold all that glitters in AI? do state-of-the-art systems possess something
comparable to the human knowledge of language? Are we at the dawn of a new era,
in which the Grail is finally closer to us? In fact, the latest achievements of
AI systems have sparkled, or better renewed, an intense scientific debate on
their true language understanding capabilities. Some defend the idea that, yes,
we are on the right track, despite the limits that computational models still
show. Others are instead radically skeptic and even dismissal: The present
limits are not just contingent and temporary problems of NLU systems, but the
sign of the intrinsic inadequacy of the epistemological and technological
paradigm grounding them. This paper aims at contributing to such debate by
carrying out a critical analysis of the linguistic abilities of the most recent
NLU systems. I contend that they incorporate important aspects of the way
language is learnt and processed by humans, but at the same time they lack key
interpretive and inferential skills that it is unlikely they can attain unless
they are integrated with structured knowledge and the ability to exploit it for
language use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding. (arXiv:2303.04245v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04245">
<div class="article-summary-box-inner">
<span><p>While the successes of transformers across many domains are indisputable,
accurate understanding of the learning mechanics is still largely lacking.
Their capabilities have been probed on benchmarks which include a variety of
structured and reasoning tasks -- but mathematical understanding is lagging
substantially behind. Recent lines of work have begun studying representational
aspects of this question: that is, the size/depth/complexity of attention-based
networks to perform certain tasks. However, there is no guarantee the learning
dynamics will converge to the constructions proposed. In our paper, we provide
fine-grained mechanistic understanding of how transformers learn "semantic
structure", understood as capturing co-occurrence structure of words.
Precisely, we show, through a combination of experiments on synthetic data
modeled by Latent Dirichlet Allocation (LDA), Wikipedia data, and mathematical
analysis that the embedding layer and the self-attention layer encode the
topical structure. In the former case, this manifests as higher average inner
product of embeddings between same-topic words. In the latter, it manifests as
higher average pairwise attention between same-topic words. The mathematical
results involve several assumptions to make the analysis tractable, which we
verify on data, and might be of independent interest as well.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Prosody Transfer Models Transfer Prosody?. (arXiv:2303.04289v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04289">
<div class="article-summary-box-inner">
<span><p>Some recent models for Text-to-Speech synthesis aim to transfer the prosody
of a reference utterance to the generated target synthetic speech. This is done
by using a learned embedding of the reference utterance, which is used to
condition speech generation. During training, the reference utterance is
identical to the target utterance. Yet, during synthesis, these models are
often used to transfer prosody from a reference that differs from the text or
speaker being synthesized.
</p>
<p>To address this inconsistency, we propose to use a different, but
prosodically-related, utterance during training too. We believe this should
encourage the model to learn to transfer only those characteristics that the
reference and target have in common. If prosody transfer methods do indeed
transfer prosody they should be able to be trained in the way we propose.
However, results show that a model trained under these conditions performs
significantly worse than one trained using the target utterance as a reference.
To explain this, we hypothesize that prosody transfer models do not learn a
transferable representation of prosody, but rather an utterance-level
representation which is highly dependent on both the reference speaker and
reference text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does Synthetic Data Generation of LLMs Help Clinical Text Mining?. (arXiv:2303.04360v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04360">
<div class="article-summary-box-inner">
<span><p>Recent advancements in large language models (LLMs) have led to the
development of highly potent models like OpenAI's ChatGPT. These models have
exhibited exceptional performance in a variety of tasks, such as question
answering, essay composition, and code generation. However, their effectiveness
in the healthcare sector remains uncertain. In this study, we seek to
investigate the potential of ChatGPT to aid in clinical text mining by
examining its ability to extract structured information from unstructured
healthcare texts, with a focus on biological named entity recognition and
relation extraction. However, our preliminary results indicate that employing
ChatGPT directly for these tasks resulted in poor performance and raised
privacy concerns associated with uploading patients' information to the ChatGPT
API. To overcome these limitations, we propose a new training paradigm that
involves generating a vast quantity of high-quality synthetic data with labels
utilizing ChatGPT and fine-tuning a local model for the downstream task. Our
method has resulted in significant improvements in the performance of
downstream tasks, improving the F1-score from 23.37% to 63.99% for the named
entity recognition task and from 75.86% to 83.59% for the relation extraction
task. Furthermore, generating data using ChatGPT can significantly reduce the
time and effort required for data collection and labeling, as well as mitigate
data privacy concerns. In summary, the proposed framework presents a promising
solution to enhance the applicability of LLM models to clinical text mining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sample Efficient Multimodal Semantic Augmentation for Incremental Summarization. (arXiv:2303.04361v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04361">
<div class="article-summary-box-inner">
<span><p>In this work, we develop a prompting approach for incremental summarization
of task videos. We develop a sample-efficient few-shot approach for extracting
semantic concepts as an intermediate step. We leverage an existing model for
extracting the concepts from the images and extend it to videos and introduce a
clustering and querying approach for sample efficiency, motivated by the recent
advances in perceiver-based architectures. Our work provides further evidence
that an approach with richer input context with relevant entities and actions
from the videos and using these as prompts could enhance the summaries
generated by the model. We show the results on a relevant dataset and discuss
possible directions for the work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatically Auditing Large Language Models via Discrete Optimization. (arXiv:2303.04381v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04381">
<div class="article-summary-box-inner">
<span><p>Auditing large language models for unexpected behaviors is critical to
preempt catastrophic deployments, yet remains challenging. In this work, we
cast auditing as an optimization problem, where we automatically search for
input-output pairs that match a desired target behavior. For example, we might
aim to find a non-toxic input that starts with "Barack Obama" that a model maps
to a toxic output. This optimization problem is difficult to solve as the set
of feasible points is sparse, the space is discrete, and the language models we
audit are non-linear and high-dimensional. To combat these challenges, we
introduce a discrete optimization algorithm, ARCA, that jointly and efficiently
optimizes over inputs and outputs. Our approach automatically uncovers
derogatory completions about celebrities (e.g. "Barack Obama is a legalized
unborn" -&gt; "child murderer"), produces French inputs that complete to English
outputs, and finds inputs that generate a specific name. Our work offers a
promising new tool to uncover models' failure-modes before deployment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NASTyLinker: NIL-Aware Scalable Transformer-based Entity Linker. (arXiv:2303.04426v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04426">
<div class="article-summary-box-inner">
<span><p>Entity Linking (EL) is the task of detecting mentions of entities in text and
disambiguating them to a reference knowledge base. Most prevalent EL approaches
assume that the reference knowledge base is complete. In practice, however, it
is necessary to deal with the case of linking to an entity that is not
contained in the knowledge base (NIL entity). Recent works have shown that,
instead of focusing only on affinities between mentions and entities,
considering inter-mention affinities can be used to represent NIL entities by
producing clusters of mentions. At the same time, inter-mention affinities can
help to substantially improve linking performance for known entities. With
NASTyLinker, we introduce an EL approach that is aware of NIL-entities and
produces corresponding mention clusters while maintaining high linking
performance for known entities. The approach clusters mentions and entities
based on dense representations from Transformers and resolves conflicts (if
more than one entity is assigned to a cluster) by computing transitive
mention-entity affinities. We show the effectiveness and scalability of
NASTyLinker on NILK, a dataset that is explicitly constructed to evaluate EL
with respect to NIL-entities. Further, we apply the presented approach to an
actual EL task, namely to knowledge graph population by linking entities in
Wikipedia listings, and provide an analysis of the outcome.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Query-Utterance Attention with Joint modeling for Query-Focused Meeting Summarization. (arXiv:2303.04487v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04487">
<div class="article-summary-box-inner">
<span><p>Query-focused meeting summarization (QFMS) aims to generate summaries from
meeting transcripts in response to a given query. Previous works typically
concatenate the query with meeting transcripts and implicitly model the query
relevance only at the token level with attention mechanism. However, due to the
dilution of key query-relevant information caused by long meeting transcripts,
the original transformer-based model is insufficient to highlight the key parts
related to the query. In this paper, we propose a query-aware framework with
joint modeling token and utterance based on Query-Utterance Attention. It
calculates the utterance-level relevance to the query with a dense retrieval
module. Then both token-level query relevance and utterance-level query
relevance are combined and incorporated into the generation process with
attention mechanism explicitly. We show that the query relevance of different
granularities contributes to generating a summary more related to the query.
Experimental results on the QMSum dataset show that the proposed model achieves
new state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MenuCraft: Interactive Menu System Design with Large Language Models. (arXiv:2303.04496v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04496">
<div class="article-summary-box-inner">
<span><p>Menu system design is a challenging task involving many design options and
various human factors. For example, one crucial factor that designers need to
consider is the semantic and systematic relation of menu commands. However,
capturing these relations can be challenging due to limited available
resources. With the advancement of neural language models, large language
models can utilize their vast pre-existing knowledge in designing and refining
menu systems.
</p>
<p>In this paper, we propose MenuCraft, an AI-assisted designer for menu design
that enables collaboration between the designer and a dialogue system to design
menus. MenuCraft offers an interactive language-based menu design tool that
simplifies the menu design process and enables easy customization of design
options. MenuCraft supports a variety of interactions through dialog that
allows performing few-shot learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Student's t-Distribution: On Measuring the Inter-Rater Reliability When the Observations are Scarce. (arXiv:2303.04526v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04526">
<div class="article-summary-box-inner">
<span><p>In natural language processing (NLP) we always rely on human judgement as the
golden quality evaluation method. However, there has been an ongoing debate on
how to better evaluate inter-rater reliability (IRR) levels for certain
evaluation tasks, such as translation quality evaluation (TQE), especially when
the data samples (observations) are very scarce. In this work, we first
introduce the study on how to estimate the confidence interval for the
measurement value when only one data (evaluation) point is available. Then,
this leads to our example with two human-generated observational scores, for
which, we introduce ``Student's \textit{t}-Distribution'' method and explain
how to use it to measure the IRR score using only these two data points, as
well as the confidence intervals (CIs) of the quality evaluation. We give
quantitative analysis on how the evaluation confidence can be greatly improved
by introducing more observations, even if only one extra observation. We
encourage researchers to report their IRR scores in all possible means, e.g.
using Student's \textit{t}-Distribution method whenever possible; thus making
the NLP evaluation more meaningful, transparent, and trustworthy. This
\textit{t}-Distribution method can be also used outside of NLP fields to
measure IRR level for trustworthy evaluation of experimental investigations,
whenever the observational data is scarce.
</p>
<p>Keywords: Inter-Rater Reliability (IRR); Scarce Observations; Confidence
Intervals (CIs); Natural Language Processing (NLP); Translation Quality
Evaluation (TQE); Student's \textit{t}-Distribution
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Models of symbol emergence in communication: a conceptual review and a guide for avoiding local minima. (arXiv:2303.04544v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04544">
<div class="article-summary-box-inner">
<span><p>Computational simulations are a popular method for testing hypotheses about
the emergence of communication. This kind of research is performed in a variety
of traditions including language evolution, developmental psychology, cognitive
science, machine learning, robotics, etc. The motivations for the models are
different, but the operationalizations and methods used are often similar. We
identify the assumptions and explanatory targets of several most representative
models and summarise the known results. We claim that some of the assumptions
-- such as portraying meaning in terms of mapping, focusing on the descriptive
function of communication, modelling signals with amodal tokens -- may hinder
the success of modelling. Relaxing these assumptions and foregrounding the
interactions of embodied and situated agents allows one to systematise the
multiplicity of pressures under which symbolic systems evolve. In line with
this perspective, we sketch the road towards modelling the emergence of
meaningful symbolic communication, where symbols are simultaneously grounded in
action and perception and form an abstract system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extrapolative Controlled Sequence Generation via Iterative Refinement. (arXiv:2303.04562v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04562">
<div class="article-summary-box-inner">
<span><p>We study the problem of extrapolative controlled generation, i.e., generating
sequences with attribute values beyond the range seen in training. This task is
of significant importance in automated design, especially drug discovery, where
the goal is to design novel proteins that are \textit{better} (e.g., more
stable) than existing sequences. Thus, by definition, the target sequences and
their attribute values are out of the training distribution, posing challenges
to existing methods that aim to directly generate the target sequence. Instead,
in this work, we propose Iterative Controlled Extrapolation (ICE) which
iteratively makes local edits to a sequence to enable extrapolation. We train
the model on synthetically generated sequence pairs that demonstrate small
improvement in the attribute value. Results on one natural language task
(sentiment analysis) and two protein engineering tasks (ACE2 stability and AAV
fitness) show that ICE considerably outperforms state-of-the-art approaches
despite its simplicity. Our code and models are available at:
https://github.com/vishakhpk/iter-extrapolation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference. (arXiv:2303.04673v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04673">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) like GPT-3 have sparked significant interest in
their generative capabilities, leading to the development of various commercial
applications. The high cost of using the models drives application builders to
maximize the value of generation under a limited inference budget. This paper
presents a study of optimizing inference hyperparameters like the number of
responses, temperature and max tokens, which significantly affects the
utility/cost of text generation. We design a framework named EcoOptiGen which
leverages economical hyperparameter optimization and cost-based pruning.
Experiments with the latest GPT-3.5 models on a variety of tasks verify its
effectiveness. EcoOptiGen is implemented in the FLAML library:
https://github.com/microsoft/FLAML, and we provide one example of using it at:
https://microsoft.github.io/FLAML/docs/Examples/Integrate%20-%20OpenAI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-contained Beta-with-Spikes Approximation for Inference Under a Wright-Fisher Model. (arXiv:2303.04691v1 [q-bio.PE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04691">
<div class="article-summary-box-inner">
<span><p>We construct a reliable estimation of evolutionary parameters within the
Wright-Fisher model, which describes changes in allele frequencies due to
selection and genetic drift, from time-series data. Such data exists for
biological populations, for example via artificial evolution experiments, and
for the cultural evolution of behavior, such as linguistic corpora that
document historical usage of different words with similar meanings. Our method
of analysis builds on a Beta-with-Spikes approximation to the distribution of
allele frequencies predicted by the Wright-Fisher model. We introduce a
self-contained scheme for estimating the parameters in the approximation, and
demonstrate its robustness with synthetic data, especially in the
strong-selection and near-extinction regimes where previous approaches fail. We
further apply to allele frequency data for baker's yeast (Saccharomyces
cerevisiae), finding a significant signal of selection in cases where
independent evidence supports such a conclusion. We further demonstrate the
possibility of detecting time-points at which evolutionary parameters change in
the context of a historical spelling reform in the Spanish language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LaSER: Language-Specific Event Recommendation. (arXiv:2303.04712v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04712">
<div class="article-summary-box-inner">
<span><p>While societal events often impact people worldwide, a significant fraction
of events has a local focus that primarily affects specific language
communities. Examples include national elections, the development of the
Coronavirus pandemic in different countries, and local film festivals such as
the C\'esar Awards in France and the Moscow International Film Festival in
Russia. However, existing entity recommendation approaches do not sufficiently
address the language context of recommendation. This article introduces the
novel task of language-specific event recommendation, which aims to recommend
events relevant to the user query in the language-specific context. This task
can support essential information retrieval activities, including web
navigation and exploratory search, considering the language context of user
information needs. We propose LaSER, a novel approach toward language-specific
event recommendation. LaSER blends the language-specific latent representations
(embeddings) of entities and events and spatio-temporal event features in a
learning to rank model. This model is trained on publicly available Wikipedia
Clickstream data. The results of our user study demonstrate that LaSER
outperforms state-of-the-art recommendation baselines by up to 33 percentage
points in MAP@5 concerning the language-specific relevance of recommended
events.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extending the Pre-Training of BLOOM for Improved Support of Traditional Chinese: Models, Methods and Results. (arXiv:2303.04715v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04715">
<div class="article-summary-box-inner">
<span><p>In this paper we present the multilingual language model BLOOM-zh that
features enhanced support for Traditional Chinese. BLOOM-zh has its origins in
the open-source BLOOM models presented by BigScience in 2022. Starting from
released models, we extended the pre-training of BLOOM by additional 7.4
billion tokens in Traditional Chinese and English covering a variety of domains
such as news articles, books, encyclopedias, educational materials as well as
spoken language. In order to show the properties of BLOOM-zh, both existing and
newly created benchmark scenarios are used for evaluating the performance.
BLOOM-zh outperforms its predecessor on most Traditional Chinese benchmarks
while maintaining its English capability. We release all our models to the
research community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Risks of Stealing the Decoding Algorithms of Language Models. (arXiv:2303.04729v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04729">
<div class="article-summary-box-inner">
<span><p>A key component of generating text from modern language models (LM) is the
selection and tuning of decoding algorithms. These algorithms determine how to
generate text from the internal probability distribution generated by the LM.
The process of choosing a decoding algorithm and tuning its hyperparameters
takes significant time, manual effort, and computation, and it also requires
extensive human evaluation. Therefore, the identity and hyperparameters of such
decoding algorithms are considered to be extremely valuable to their owners. In
this work, we show, for the first time, that an adversary with typical API
access to an LM can steal the type and hyperparameters of its decoding
algorithms at very low monetary costs. Our attack is effective against popular
LMs used in text generation APIs, including GPT-2 and GPT-3. We demonstrate the
feasibility of stealing such information with only a few dollars, e.g.,
$\$0.8$, $\$1$, $\$4$, and $\$40$ for the four versions of GPT-3.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comprehensive Event Representations using Event Knowledge Graphs and Natural Language Processing. (arXiv:2303.04794v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04794">
<div class="article-summary-box-inner">
<span><p>Recent work has utilised knowledge-aware approaches to natural language
understanding, question answering, recommendation systems, and other tasks.
These approaches rely on well-constructed and large-scale knowledge graphs that
can be useful for many downstream applications and empower knowledge-aware
models with commonsense reasoning. Such knowledge graphs are constructed
through knowledge acquisition tasks such as relation extraction and knowledge
graph completion. This work seeks to utilise and build on the growing body of
work that uses findings from the field of natural language processing (NLP) to
extract knowledge from text and build knowledge graphs. The focus of this
research project is on how we can use transformer-based approaches to extract
and contextualise event information, matching it to existing ontologies, to
build a comprehensive knowledge of graph-based event representations.
Specifically, sub-event extraction is used as a way of creating sub-event-aware
event representations. These event representations are then further enriched
through fine-grained location extraction and contextualised through the
alignment of historically relevant quotes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effects of Parameter Norm Growth During Transformer Training: Inductive Bias from Gradient Descent. (arXiv:2010.09697v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09697">
<div class="article-summary-box-inner">
<span><p>The capacity of neural networks like the widely adopted transformer is known
to be very high. Evidence is emerging that they learn successfully due to
inductive bias in the training routine, typically a variant of gradient descent
(GD). To better understand this bias, we study the tendency for transformer
parameters to grow in magnitude ($\ell_2$ norm) during training, and its
implications for the emergent representations within self attention layers.
Empirically, we document norm growth in the training of transformer language
models, including T5 during its pretraining. As the parameters grow in
magnitude, we prove that the network approximates a discretized network with
saturated activation functions. Such "saturated" networks are known to have a
reduced capacity compared to the full network family that can be described in
terms of formal languages and automata. Our results suggest saturation is a new
characterization of an inductive bias implicit in GD of particular interest for
NLP. We leverage the emergent discrete structure in a saturated transformer to
analyze the role of different attention heads, finding that some focus locally
on a small number of positions, while other heads compute global averages,
allowing counting. We believe understanding the interplay between these two
capabilities may shed further light on the structure of computation within
large transformers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Concept Map Generation through Task-Guided Graph Translation. (arXiv:2110.15720v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15720">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed the rapid development of concept map generation
techniques due to their advantages in providing well-structured summarization
of knowledge from free texts. Traditional unsupervised methods do not generate
task-oriented concept maps, whereas deep generative models require large
amounts of training data. In this work, we present GT-D2G (Graph
Translation-based Document To Graph), an automatic concept map generation
framework that leverages generalized NLP pipelines to derive semantic-rich
initial graphs, and translates them into more concise structures under the weak
supervision of downstream task labels. The concept maps generated by GT-D2G can
provide interpretable summarization of structured knowledge for the input
texts, which are demonstrated through human evaluation and case studies on
three real-world corpora. Further experiments on the downstream task of
document classification show that GT-D2G beats other concept map generation
methods. Moreover, we specifically validate the labeling efficiency of GT-D2G
in the label-efficient learning setting and the flexibility of generated graph
sizes in controlled hyper-parameter studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Parallelism Tradeoff: Limitations of Log-Precision Transformers. (arXiv:2207.00729v3 [cs.CC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.00729">
<div class="article-summary-box-inner">
<span><p>Despite their omnipresence in modern NLP, characterizing the computational
power of transformer neural nets remains an interesting open question. We prove
that transformers whose arithmetic precision is logarithmic in the number of
input tokens (and whose feedforward nets are computable using space linear in
their input) can be simulated by constant-depth logspace-uniform threshold
circuits. This provides insight on the power of transformers using known
results in complexity theory. For example, if $\mathsf L \neq \mathsf P$ (i.e.,
not all poly-time problems can be solved using logarithmic space), then
transformers cannot even accurately solve linear equalities or check membership
in an arbitrary context-free grammar with empty productions. Our result
intuitively emerges from the transformer architecture's high parallelizability.
We thus speculatively introduce the idea of a fundamental parallelism tradeoff:
any model architecture as parallelizable as the transformer will obey
limitations similar to it. Since parallelism is key to training models at
massive scale, this suggests a potential inherent weakness of the scaling
paradigm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Out-of-Distribution Detection and Selective Generation for Conditional Language Models. (arXiv:2209.15558v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.15558">
<div class="article-summary-box-inner">
<span><p>Machine learning algorithms typically assume independent and identically
distributed samples in training and at test time. Much work has shown that
high-performing ML classifiers can degrade significantly and provide
overly-confident, wrong classification predictions, particularly for
out-of-distribution (OOD) inputs. Conditional language models (CLMs) are
predominantly trained to classify the next token in an output sequence, and may
suffer even worse degradation on OOD inputs as the prediction is done
auto-regressively over many steps. Furthermore, the space of potential
low-quality outputs is larger as arbitrary text can be generated and it is
important to know when to trust the generated output. We present a highly
accurate and lightweight OOD detection method for CLMs, and demonstrate its
effectiveness on abstractive summarization and translation. We also show how
our method can be used under the common and realistic setting of distribution
shift for selective generation (analogous to selective prediction for
classification) of high-quality outputs, while automatically abstaining from
low-quality ones, enabling safer deployment of generative language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grounding Language with Visual Affordances over Unstructured Data. (arXiv:2210.01911v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.01911">
<div class="article-summary-box-inner">
<span><p>Recent works have shown that Large Language Models (LLMs) can be applied to
ground natural language to a wide variety of robot skills. However, in
practice, learning multi-task, language-conditioned robotic skills typically
requires large-scale data collection and frequent human intervention to reset
the environment or help correcting the current policies. In this work, we
propose a novel approach to efficiently learn general-purpose
language-conditioned robot skills from unstructured, offline and reset-free
data in the real world by exploiting a self-supervised visuo-lingual affordance
model, which requires annotating as little as 1% of the total data with
language. We evaluate our method in extensive experiments both in simulated and
real-world robotic tasks, achieving state-of-the-art performance on the
challenging CALVIN benchmark and learning over 25 distinct visuomotor
manipulation tasks with a single policy in the real world. We find that when
paired with LLMs to break down abstract natural language instructions into
subgoals via few-shot prompting, our method is capable of completing
long-horizon, multi-tier tasks in the real world, while requiring an order of
magnitude less data than previous approaches. Code and videos are available at
<a href="http://hulc2.cs.uni-freiburg.de">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Language Maps for Robot Navigation. (arXiv:2210.05714v4 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.05714">
<div class="article-summary-box-inner">
<span><p>Grounding language to the visual observations of a navigating agent can be
performed using off-the-shelf visual-language models pretrained on
Internet-scale data (e.g., image captions). While this is useful for matching
images to natural language descriptions of object goals, it remains disjoint
from the process of mapping the environment, so that it lacks the spatial
precision of classic geometric maps. To address this problem, we propose
VLMaps, a spatial map representation that directly fuses pretrained
visual-language features with a 3D reconstruction of the physical world. VLMaps
can be autonomously built from video feed on robots using standard exploration
approaches and enables natural language indexing of the map without additional
labeled data. Specifically, when combined with large language models (LLMs),
VLMaps can be used to (i) translate natural language commands into a sequence
of open-vocabulary navigation goals (which, beyond prior work, can be spatial
by construction, e.g., "in between the sofa and TV" or "three meters to the
right of the chair") directly localized in the map, and (ii) can be shared
among multiple robots with different embodiments to generate new obstacle maps
on-the-fly (by using a list of obstacle categories). Extensive experiments
carried out in simulated and real world environments show that VLMaps enable
navigation according to more complex language instructions than existing
methods. Videos are available at https://vlmaps.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lila: A Unified Benchmark for Mathematical Reasoning. (arXiv:2210.17517v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.17517">
<div class="article-summary-box-inner">
<span><p>Mathematical reasoning skills are essential for general-purpose intelligent
systems to perform tasks from grocery shopping to climate modeling. Towards
evaluating and improving AI systems in this domain, we propose LILA, a unified
mathematical reasoning benchmark consisting of 23 diverse tasks along four
dimensions: (i) mathematical abilities e.g., arithmetic, calculus (ii) language
format e.g., question-answering, fill-in-the-blanks (iii) language diversity
e.g., no language, simple language (iv) external knowledge e.g., commonsense,
physics. We construct our benchmark by extending 20 datasets benchmark by
collecting task instructions and solutions in the form of Python programs,
thereby obtaining explainable solutions in addition to the correct answer. We
additionally introduce two evaluation datasets to measure out-of-distribution
performance and robustness to language perturbation. Finally, we introduce
BHASKARA, a general-purpose mathematical reasoning model trained on LILA.
Importantly, we find that multi-tasking leads to significant improvements
(average relative improvement of 21.83% F1 score vs. single-task models), while
the best performing model only obtains 60.40%, indicating the room for
improvement in general mathematical reasoning and understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VoP: Text-Video Co-operative Prompt Tuning for Cross-Modal Retrieval. (arXiv:2211.12764v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.12764">
<div class="article-summary-box-inner">
<span><p>Many recent studies leverage the pre-trained CLIP for text-video cross-modal
retrieval by tuning the backbone with additional heavy modules, which not only
brings huge computational burdens with much more parameters, but also leads to
the knowledge forgetting from upstream models.In this work, we propose the VoP:
Text-Video Co-operative Prompt Tuning for efficient tuning on the text-video
retrieval task. The proposed VoP is an end-to-end framework with both video &amp;
text prompts introducing, which can be regarded as a powerful baseline with
only 0.1% trainable parameters. Further, based on the spatio-temporal
characteristics of videos, we develop three novel video prompt mechanisms to
improve the performance with different scales of trainable parameters. The
basic idea of the VoP enhancement is to model the frame position, frame
context, and layer function with specific trainable prompts, respectively.
Extensive experiments show that compared to full fine-tuning, the enhanced VoP
achieves a 1.4% average R@1 gain across five text-video retrieval benchmarks
with 6x less parameter overhead. The code will be available at
https://github.com/bighuang624/VoP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SumREN: Summarizing Reported Speech about Events in News. (arXiv:2212.01146v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01146">
<div class="article-summary-box-inner">
<span><p>A primary objective of news articles is to establish the factual record for
an event, frequently achieved by conveying both the details of the specified
event (i.e., the 5 Ws; Who, What, Where, When and Why regarding the event) and
how people reacted to it (i.e., reported statements). However, existing work on
news summarization almost exclusively focuses on the event details. In this
work, we propose the novel task of summarizing the reactions of different
speakers, as expressed by their reported statements, to a given event. To this
end, we create a new multi-document summarization benchmark, SUMREN, comprising
745 summaries of reported statements from various public figures obtained from
633 news articles discussing 132 events. We propose an automatic silver
training data generation approach for our task, which helps smaller models like
BART achieve GPT-3 level performance on this task. Finally, we introduce a
pipeline-based framework for summarizing reported speech, which we empirically
show to generate summaries that are more abstractive and factual than baseline
query-focused summarization approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Adaptation of Transformer-Based Models using Unlabeled Data for Relevance and Polarity Classification of German Customer Feedback. (arXiv:2212.05764v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.05764">
<div class="article-summary-box-inner">
<span><p>Understanding customer feedback is becoming a necessity for companies to
identify problems and improve their products and services. Text classification
and sentiment analysis can play a major role in analyzing this data by using a
variety of machine and deep learning approaches. In this work, different
transformer-based models are utilized to explore how efficient these models are
when working with a German customer feedback dataset. In addition, these
pre-trained models are further analyzed to determine if adapting them to a
specific domain using unlabeled data can yield better results than
off-the-shelf pre-trained models. To evaluate the models, two downstream tasks
from the GermEval 2017 are considered. The experimental results show that
transformer-based models can reach significant improvements compared to a
fastText baseline and outperform the published scores and previous models. For
the subtask Relevance Classification, the best models achieve a micro-averaged
$F1$-Score of 96.1 % on the first test set and 95.9 % on the second one, and a
score of 85.1 % and 85.3 % for the subtask Polarity Classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AugTriever: Unsupervised Dense Retrieval by Scalable Data Augmentation. (arXiv:2212.08841v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.08841">
<div class="article-summary-box-inner">
<span><p>Dense retrievers have made significant strides in text retrieval and
open-domain question answering, even though most achievements were made
possible only with large amounts of human supervision. In this work, we aim to
develop unsupervised methods by proposing two methods that create pseudo
query-document pairs and train dense retrieval models in an annotation-free and
scalable manner: query extraction and transferred query generation. The former
method produces pseudo queries by selecting salient spans from the original
document. The latter utilizes generation models trained for other NLP tasks
(e.g., summarization) to produce pseudo queries. Extensive experiments show
that models trained with the proposed augmentation methods can perform
comparably well (or better) to multiple strong baselines. Combining those
strategies leads to further improvements, achieving the state-of-the-art
performance of unsupervised dense retrieval on both BEIR and ODQA datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04054">
<div class="article-summary-box-inner">
<span><p>Reliability of machine learning evaluation -- the consistency of observed
evaluation scores across replicated model training runs -- is affected by
several sources of nondeterminism which can be regarded as measurement noise.
Current tendencies to remove noise in order to enforce reproducibility of
research results neglect inherent nondeterminism at the implementation level
and disregard crucial interaction effects between algorithmic noise factors and
data properties. This limits the scope of conclusions that can be drawn from
such experiments. Instead of removing noise, we propose to incorporate several
sources of variance, including their interaction with data properties, into an
analysis of significance and reliability of machine learning evaluation, with
the aim to draw inferences beyond particular instances of trained models. We
show how to use linear mixed effects models (LMEMs) to analyze performance
evaluation scores, and to conduct statistical inference with a generalized
likelihood ratio test (GLRT). This allows us to incorporate arbitrary sources
of noise like meta-parameter variations into statistical significance testing,
and to assess performance differences conditional on data properties.
Furthermore, a variance component analysis (VCA) enables the analysis of the
contribution of noise sources to overall variance and the computation of a
reliability coefficient by the ratio of substantial to total variance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mask-guided BERT for Few Shot Text Classification. (arXiv:2302.10447v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10447">
<div class="article-summary-box-inner">
<span><p>Transformer-based language models have achieved significant success in
various domains. However, the data-intensive nature of the transformer
architecture requires much labeled data, which is challenging in low-resource
scenarios (i.e., few-shot learning (FSL)). The main challenge of FSL is the
difficulty of training robust models on small amounts of samples, which
frequently leads to overfitting. Here we present Mask-BERT, a simple and
modular framework to help BERT-based architectures tackle FSL. The proposed
approach fundamentally differs from existing FSL strategies such as prompt
tuning and meta-learning. The core idea is to selectively apply masks on text
inputs and filter out irrelevant information, which guides the model to focus
on discriminative tokens that influence prediction results. In addition, to
make the text representations from different categories more separable and the
text representations from the same category more compact, we introduce a
contrastive learning loss function. Experimental results on public-domain
benchmark datasets demonstrate the effectiveness of Mask-BERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Universal resources for quantum computing. (arXiv:2303.03715v2 [quant-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.03715">
<div class="article-summary-box-inner">
<span><p>Unravelling the source of quantum computing power has been a major goal in
the field of quantum information science. In recent years, the quantum resource
theory (QRT) has been established to characterize various quantum resources,
yet their roles in quantum computing tasks still require investigation. The
so-called universal quantum computing model (UQCM), e.g., the circuit model,
has been the main framework to guide the design of quantum algorithms, creation
of real quantum computers etc. In this work, we combine the study of UQCM
together with QRT. We find on one hand, using QRT can provide a
resource-theoretic characterization of a UQCM, the relation among models and
inspire new ones, and on the other hand, using UQCM offers a framework to apply
resources, study relation among resources and classify them.
</p>
<p>We develop the theory of universal resources in the setting of UQCM, and find
a rich spectrum of UQCMs and the corresponding universal resources. Depending
on a hierarchical structure of resource theories, we find models can be
classified into families. In this work, we study three natural families of
UQCMs in details: the amplitude family, the quasi-probability family, and the
Hamiltonian family. They include some well known models, like the
measurement-based model and adiabatic model, and also inspire new models such
as the contextual model we introduce. Each family contains at least a triplet
of models, and such a succinct structure of families of UQCMs offers a unifying
picture to investigate resources and design models. It also provides a rigorous
framework to resolve puzzles, such as the role of entanglement vs.
interference, and unravel resource-theoretic features of quantum algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Larger language models do in-context learning differently. (arXiv:2303.03846v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.03846">
<div class="article-summary-box-inner">
<span><p>We study how in-context learning (ICL) in language models is affected by
semantic priors versus input-label mappings. We investigate two setups-ICL with
flipped labels and ICL with semantically-unrelated labels-across various model
families (GPT-3, InstructGPT, Codex, PaLM, and Flan-PaLM). First, experiments
on ICL with flipped labels show that overriding semantic priors is an emergent
ability of model scale. While small language models ignore flipped labels
presented in-context and thus rely primarily on semantic priors from
pretraining, large models can override semantic priors when presented with
in-context exemplars that contradict priors, despite the stronger semantic
priors that larger models may hold. We next study semantically-unrelated label
ICL (SUL-ICL), in which labels are semantically unrelated to their inputs
(e.g., foo/bar instead of negative/positive), thereby forcing language models
to learn the input-label mappings shown in in-context exemplars in order to
perform the task. The ability to do SUL-ICL also emerges primarily with scale,
and large-enough language models can even perform linear classification in a
SUL-ICL setting. Finally, we evaluate instruction-tuned models and find that
instruction tuning strengthens both the use of semantic priors and the capacity
to learn input-label mappings, but more of the former.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT: Beginning of an End of Manual Linguistic Data Annotation? Use Case of Automatic Genre Identification. (arXiv:2303.03953v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.03953">
<div class="article-summary-box-inner">
<span><p>ChatGPT has shown strong capabilities in natural language generation tasks,
which naturally leads researchers to explore where its abilities end. In this
paper, we examine whether ChatGPT can be used for zero-shot text
classification, more specifically, automatic genre identification. We compare
ChatGPT with a multilingual XLM-RoBERTa language model that was fine-tuned on
datasets, manually annotated with genres. The models are compared on test sets
in two languages: English and Slovenian. Results show that ChatGPT outperforms
the fine-tuned model when applied to the dataset which was not seen before by
either of the models. Even when applied on Slovenian language as an
under-resourced language, ChatGPT's performance is no worse than when applied
to English. However, if the model is fully prompted in Slovenian, the
performance drops significantly, showing the current limitations of ChatGPT
usage on smaller languages. The presented results lead us to questioning
whether this is the beginning of an end of laborious manual annotation
campaigns even for smaller languages, such as Slovenian.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Describe me an Aucklet: Generating Grounded Perceptual Category Descriptions. (arXiv:2303.04053v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04053">
<div class="article-summary-box-inner">
<span><p>Human language users can generate descriptions of perceptual concepts beyond
instance-level representations and also use such descriptions to learn
provisional class-level representations. However, the ability of computational
models to learn and operate with class representations is under-investigated in
the language-and-vision field. In this paper, we train separate neural networks
to generate and interpret class-level descriptions. We then use the zero-shot
classification performance of the interpretation model as a measure of
communicative success and class-level conceptual grounding. We investigate the
performance of prototype- and exemplar-based neural representations grounded
category description. Finally, we show that communicative success reveals
performance issues in the generation model that are not captured by traditional
intrinsic NLG evaluation metrics, and argue that these issues can be traced to
a failure to properly ground language in vision at the class level. We observe
that the interpretation model performs better with descriptions that are low in
diversity on the class level, possibly indicating a strong reliance on
frequently occurring features.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-03-09 23:14:29.271797615 UTC">2023-03-09 23:14:29 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>