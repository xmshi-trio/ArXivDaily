<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-08-28T01:30:00Z">08-28</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Financial News Analytics Using Fine-Tuned Llama 2 GPT Model. (arXiv:2308.13032v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13032">
<div class="article-summary-box-inner">
<span><p>The paper considers the possibility to fine-tune Llama 2 Large Language Model
(LLM) for the multitask analysis of financial news. For fine-tuning, the
PEFT/LoRA based approach was used. In the study, the model was fine-tuned for
the following tasks: analysing a text from financial market perspectives,
highlighting main points of a text, summarizing a text and extracting named
entities with appropriate sentiments. The obtained results show that the
fine-tuned Llama 2 model can perform a multitask financial news analysis with a
specified structure of response, part of response can be a structured text and
another part of data can have JSON format for further processing. Extracted
sentiments for named entities can be considered as predictive features in
supervised machine learning models with quantitative target variables.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lexical Diversity in Kinship Across Languages and Dialects. (arXiv:2308.13056v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13056">
<div class="article-summary-box-inner">
<span><p>Languages are known to describe the world in diverse ways. Across lexicons,
diversity is pervasive, appearing through phenomena such as lexical gaps and
untranslatability. However, in computational resources, such as multilingual
lexical databases, diversity is hardly ever represented. In this paper, we
introduce a method to enrich computational lexicons with content relating to
linguistic diversity. The method is verified through two large-scale case
studies on kinship terminology, a domain known to be diverse across languages
and cultures: one case study deals with seven Arabic dialects, while the other
one with three Indonesian languages. Our results, made available as browseable
and downloadable computational resources, extend prior linguistics research on
kinship terminology, and provide insight into the extent of diversity even
within linguistically and culturally close communities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causal Parrots: Large Language Models May Talk Causality But Are Not Causal. (arXiv:2308.13067v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13067">
<div class="article-summary-box-inner">
<span><p>Some argue scale is all what is needed to achieve AI, covering even causal
models. We make it clear that large language models (LLMs) cannot be causal and
give reason onto why sometimes we might feel otherwise. To this end, we define
and exemplify a new subgroup of Structural Causal Model (SCM) that we call meta
SCM which encode causal facts about other SCM within their variables. We
conjecture that in the cases where LLM succeed in doing causal inference,
underlying was a respective meta SCM that exposed correlations between causal
facts in natural language on whose data the LLM was ultimately trained. If our
hypothesis holds true, then this would imply that LLMs are like parrots in that
they simply recite the causal knowledge embedded in the data. Our empirical
analysis provides favoring evidence that current LLMs are even weak `causal
parrots.'
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Formal specification terminology for demographic agent-based models of fixed-step single-clocked simulations. (arXiv:2308.13081v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13081">
<div class="article-summary-box-inner">
<span><p>This document presents adequate formal terminology for the mathematical
specification of a subset of Agent Based Models (ABMs) in the field of
Demography. The simulation of the targeted ABMs follows a fixed-step
single-clocked pattern. The proposed terminology further improves the model
understanding and can act as a stand-alone methodology for the specification
and optionally the documentation of a significant set of (demographic) ABMs.
Nevertheless, it is imaginable the this terminology probably with further
extensions can be merged with the largely-informal widely-used model
documentation and communication O.D.D. protocol [Grimm and et al., 2020,
Amouroux et al., 2010] to reduce many sources of ambiguity, hindering model
replications by other modelers. A published demographic model documentation,
largely simplified version of the Lone Parent Model [Gostoli and Silverman,
2020] is separately published in [Elsheikh, 2023b] as illustration for the
formal terminology. The model was implemented in the Julia language [Elsheikh,
2023a] based on the Agents.jl julia package [Datseris et al., 2022].
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards a Holistic Approach: Understanding Sociodemographic Biases in NLP Models using an Interdisciplinary Lens. (arXiv:2308.13089v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13089">
<div class="article-summary-box-inner">
<span><p>The rapid growth in the usage and applications of Natural Language Processing
(NLP) in various sociotechnical solutions has highlighted the need for a
comprehensive understanding of bias and its impact on society. While research
on bias in NLP has expanded, several challenges persist that require attention.
These include the limited focus on sociodemographic biases beyond race and
gender, the narrow scope of analysis predominantly centered on models, and the
technocentric implementation approaches. This paper addresses these challenges
and advocates for a more interdisciplinary approach to understanding bias in
NLP. The work is structured into three facets, each exploring a specific aspect
of bias in NLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentence Embedding Models for Ancient Greek Using Multilingual Knowledge Distillation. (arXiv:2308.13116v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13116">
<div class="article-summary-box-inner">
<span><p>Contextual language models have been trained on Classical languages,
including Ancient Greek and Latin, for tasks such as lemmatization,
morphological tagging, part of speech tagging, authorship attribution, and
detection of scribal errors. However, high-quality sentence embedding models
for these historical languages are significantly more difficult to achieve due
to the lack of training data. In this work, we use a multilingual knowledge
distillation approach to train BERT models to produce sentence embeddings for
Ancient Greek text. The state-of-the-art sentence embedding approaches for
high-resource languages use massive datasets, but our distillation approach
allows our Ancient Greek models to inherit the properties of these models while
using a relatively small amount of translated sentence data. We build a
parallel sentence dataset using a sentence-embedding alignment method to align
Ancient Greek documents with English translations, and use this dataset to
train our models. We evaluate our models on translation search, semantic
similarity, and semantic retrieval tasks and investigate translation bias. We
make our training and evaluation datasets freely available at
https://github.com/kevinkrahn/ancient-greek-datasets .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models. (arXiv:2308.13137v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13137">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have revolutionized natural language processing
tasks. However, their practical deployment is hindered by their immense memory
and computation requirements. Although recent post-training quantization (PTQ)
methods are effective in reducing memory footprint and improving the
computational efficiency of LLM, they hand-craft quantization parameters, which
leads to low performance and fails to deal with extremely low-bit quantization.
To tackle this issue, we introduce an Omnidirectionally calibrated Quantization
(OmniQuant) technique for LLMs, which achieves good performance in diverse
quantization settings while maintaining the computational efficiency of PTQ by
efficiently optimizing various quantization parameters. OmniQuant comprises two
innovative components including Learnable Weight Clipping (LWC) and Learnable
Equivalent Transformation (LET). LWC modulates the extreme values of weights by
optimizing the clipping threshold. Meanwhile, LET tackles activation outliers
by shifting the challenge of quantization from activations to weights through a
learnable equivalent transformation. Operating within a differentiable
framework using block-wise error minimization, OmniQuant can optimize the
quantization process efficiently for both weight-only and weight-activation
quantization. For instance, the LLaMA-2 model family with the size of 7-70B can
be processed with OmniQuant on a single A100-40G GPU within 1-16 hours using
128 samples. Extensive experiments validate OmniQuant's superior performance
across diverse quantization configurations such as W4A4, W6A6, W4A16, W3A16,
and W2A16. Additionally, OmniQuant demonstrates effectiveness in
instruction-tuned models and delivers notable improvements in inference speed
and memory reduction on real devices. Codes and models are available at
\url{https://github.com/OpenGVLab/OmniQuant}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MatchXML: An Efficient Text-label Matching Framework for Extreme Multi-label Text Classification. (arXiv:2308.13139v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13139">
<div class="article-summary-box-inner">
<span><p>The eXtreme Multi-label text Classification(XMC) refers to training a
classifier that assigns a text sample with relevant labels from an extremely
large-scale label set (e.g., millions of labels). We propose MatchXML, an
efficient text-label matching framework for XMC. We observe that the label
embeddings generated from the sparse Term Frequency-Inverse Document
Frequency(TF-IDF) features have several limitations. We thus propose label2vec
to effectively train the semantic dense label embeddings by the Skip-gram
model. The dense label embeddings are then used to build a Hierarchical Label
Tree by clustering. In fine-tuning the pre-trained encoder Transformer, we
formulate the multi-label text classification as a text-label matching problem
in a bipartite graph. We then extract the dense text representations from the
fine-tuned Transformer. Besides the fine-tuned dense text embeddings, we also
extract the static dense sentence embeddings from a pre-trained Sentence
Transformer. Finally, a linear ranker is trained by utilizing the sparse TF-IDF
features, the fine-tuned dense text representations and static dense sentence
features. Experimental results demonstrate that MatchXML achieves
state-of-the-art accuracy on five out of six datasets. As for the speed,
MatchXML outperforms the competing methods on all the six datasets. Our source
code is publicly available at https://github.com/huiyegit/MatchXML.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SciEval: A Multi-Level Large Language Model Evaluation Benchmark for Scientific Research. (arXiv:2308.13149v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13149">
<div class="article-summary-box-inner">
<span><p>Recently, there has been growing interest in using Large Language Models
(LLMs) for scientific research. Numerous benchmarks have been proposed to
evaluate the ability of LLMs for scientific research. However, current
benchmarks are mostly based on pre-collected objective questions. This design
suffers from data leakage problem and lacks the evaluation of subjective Q/A
ability. In this paper, we propose SciEval, a comprehensive and
multi-disciplinary evaluation benchmark to address these issues. Based on
Bloom's taxonomy, SciEval covers four dimensions to systematically evaluate
scientific research ability. In particular, we design a "dynamic" subset based
on scientific principles to prevent evaluation from potential data leakage.
Both objective and subjective questions are included in SciEval. These
characteristics make SciEval a more effective benchmark for scientific research
ability evaluation of LLMs. Comprehensive experiments on most advanced LLMs
show that, although GPT-4 achieves SOTA performance compared to other LLMs,
there is still substantial room for improvement, especially for dynamic
questions. The data and codes are now publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Measuring Spurious Correlation in Classification: 'Clever Hans' in Translationese. (arXiv:2308.13170v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13170">
<div class="article-summary-box-inner">
<span><p>Recent work has shown evidence of 'Clever Hans' behavior in high-performance
neural translationese classifiers, where BERT-based classifiers capitalize on
spurious correlations, in particular topic information, between data and target
classification labels, rather than genuine translationese signals.
Translationese signals are subtle (especially for professional translation) and
compete with many other signals in the data such as genre, style, author, and,
in particular, topic. This raises the general question of how much of the
performance of a classifier is really due to spurious correlations in the data
versus the signals actually targeted for by the classifier, especially for
subtle target signals and in challenging (low resource) data settings. We focus
on topic-based spurious correlation and approach the question from two
directions: (i) where we have no knowledge about spurious topic information and
its distribution in the data, (ii) where we have some indication about the
nature of spurious topic correlations. For (i) we develop a measure from first
principles capturing alignment of unsupervised topics with target
classification labels as an indication of spurious topic information in the
data. We show that our measure is the same as purity in clustering and propose
a 'topic floor' (as in a 'noise floor') for classification. For (ii) we
investigate masking of known spurious topic carriers in classification. Both
(i) and (ii) contribute to quantifying and (ii) to mitigating spurious
correlations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DISGO: Automatic End-to-End Evaluation for Scene Text OCR. (arXiv:2308.13173v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13173">
<div class="article-summary-box-inner">
<span><p>This paper discusses the challenges of optical character recognition (OCR) on
natural scenes, which is harder than OCR on documents due to the wild content
and various image backgrounds. We propose to uniformly use word error rates
(WER) as a new measurement for evaluating scene-text OCR, both end-to-end (e2e)
performance and individual system component performances. Particularly for the
e2e metric, we name it DISGO WER as it considers Deletion, Insertion,
Substitution, and Grouping/Ordering errors. Finally we propose to utilize the
concept of super blocks to automatically compute BLEU scores for e2e OCR
machine translation. The small SCUT public test set is used to demonstrate WER
performance by a modularized OCR system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Evaluate the Generalization of Detection? A Benchmark for Comprehensive Open-Vocabulary Detection. (arXiv:2308.13177v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13177">
<div class="article-summary-box-inner">
<span><p>Object detection (OD) in computer vision has made significant progress in
recent years, transitioning from closed-set labels to open-vocabulary detection
(OVD) based on large-scale vision-language pre-training (VLP). However, current
evaluation methods and datasets are limited to testing generalization over
object types and referral expressions, which do not provide a systematic,
fine-grained, and accurate benchmark of OVD models' abilities. In this paper,
we propose a new benchmark named OVDEval, which includes 9 sub-tasks and
introduces evaluations on commonsense knowledge, attribute understanding,
position understanding, object relation comprehension, and more. The dataset is
meticulously created to provide hard negatives that challenge models' true
understanding of visual and linguistic input. Additionally, we identify a
problem with the popular Average Precision (AP) metric when benchmarking models
on these fine-grained label datasets and propose a new metric called
Non-Maximum Suppression Average Precision (NMS-AP) to address this issue.
Extensive experimental results show that existing top OVD models all fail on
the new tasks except for simple object types, demonstrating the value of the
proposed dataset in pinpointing the weakness of current OVD models and guiding
future research. Furthermore, the proposed NMS-AP metric is verified by
experiments to provide a much more truthful evaluation of OVD models, whereas
traditional AP metrics yield deceptive results. Data is available at
\url{https://github.com/om-ai-lab/OVDEval}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chunk, Align, Select: A Simple Long-sequence Processing Method for Transformers. (arXiv:2308.13191v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13191">
<div class="article-summary-box-inner">
<span><p>Although dominant in natural language processing, transformer-based models
remain challenged by the task of long-sequence processing, because the
computational cost of self-attention operations in transformers swells
quadratically with the input sequence length. To alleviate the complexity of
long-sequence processing, we propose a simple framework to enable the
offthe-shelf pre-trained transformers to process much longer sequences, while
the computation and memory costs remain growing linearly with the input
sequence lengths. More specifically, our method divides each long-sequence
input into a batch of chunks, then aligns the interchunk information during the
encoding steps, and finally selects the most representative hidden states from
the encoder for the decoding process. To extract inter-chunk semantic
information, we align the start and end token embeddings among chunks in each
encoding transformer block. To learn an effective hidden selection policy, we
design a dual updating scheme inspired by reinforcement learning, which regards
the decoders of transformers as environments, and the downstream performance
metrics as the rewards to evaluate the hidden selection actions. Our empirical
results on real-world long-text summarization and reading comprehension tasks
demonstrate effective improvements compared to prior longsequence processing
baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Formalising Natural Language Quantifiers for Human-Robot Interactions. (arXiv:2308.13192v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13192">
<div class="article-summary-box-inner">
<span><p>We present a method for formalising quantifiers in natural language in the
context of human-robot interactions. The solution is based on first-order logic
extended with capabilities to represent the cardinality of variables, operating
similarly to generalised quantifiers. To demonstrate the method, we designed an
end-to-end system able to receive input as natural language, convert it into a
formal logical representation, evaluate it, and return a result or send a
command to a simulated robot.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Journey to the Center of the Knowledge Neurons: Discoveries of Language-Independent Knowledge Neurons and Degenerate Knowledge Neurons. (arXiv:2308.13198v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13198">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PLMs) contain vast amounts of factual knowledge,
but how the knowledge is stored in the parameters remains unclear. This paper
delves into the complex task of understanding how factual knowledge is stored
in multilingual PLMs, and introduces the Architecture-adapted Multilingual
Integrated Gradients method, which successfully localizes knowledge neurons
more precisely compared to current methods, and is more universal across
various architectures and languages. Moreover, we conduct an in-depth
exploration of knowledge neurons, leading to the following two important
discoveries: (1) The discovery of Language-Independent Knowledge Neurons, which
store factual knowledge in a form that transcends language. We design
cross-lingual knowledge editing experiments, demonstrating that the PLMs can
accomplish this task based on language-independent neurons; (2) The discovery
of Degenerate Knowledge Neurons, a novel type of neuron showing that different
knowledge neurons can store the same fact. Its property of functional overlap
endows the PLMs with a robust mastery of factual knowledge. We design
fact-checking experiments, proving that the degenerate knowledge neurons can
help the PLMs to detect wrong facts. Experiments corroborate these findings,
shedding light on the mechanisms of factual knowledge storage in multilingual
PLMs, and contribute valuable insights to the field. The source code will be
made publicly available for further research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM2KB: Constructing Knowledge Bases using instruction tuned context aware Large Language Models. (arXiv:2308.13207v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13207">
<div class="article-summary-box-inner">
<span><p>The advent of Large Language Models (LLM) has revolutionized the field of
natural language processing, enabling significant progress in various
applications. One key area of interest is the construction of Knowledge Bases
(KB) using these powerful models. Knowledge bases serve as repositories of
structured information, facilitating information retrieval and inference tasks.
Our paper proposes LLM2KB, a system for constructing knowledge bases using
large language models, with a focus on the Llama 2 architecture and the
Wikipedia dataset. We perform parameter efficient instruction tuning for
Llama-2-13b-chat and StableBeluga-13B by training small injection models that
have only 0.05 % of the parameters of the base models using the Low Rank
Adaptation (LoRA) technique. These injection models have been trained with
prompts that are engineered to utilize Wikipedia page contexts of subject
entities fetched using a Dense Passage Retrieval (DPR) algorithm, to answer
relevant object entities for a given subject entity and relation. Our best
performing model achieved an average F1 score of 0.6185 across 21 relations in
the LM-KBC challenge held at the ISWC 2023 conference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-Driven CoT: Exploring Faithful Reasoning in LLMs for Knowledge-intensive Question Answering. (arXiv:2308.13259v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13259">
<div class="article-summary-box-inner">
<span><p>Equipped with Chain-of-Thought (CoT), Large language models (LLMs) have shown
impressive reasoning ability in various downstream tasks. Even so, suffering
from hallucinations and the inability to access external knowledge, LLMs often
come with incorrect or unfaithful intermediate reasoning steps, especially in
the context of answering knowledge-intensive tasks such as KBQA. To alleviate
this issue, we propose a framework called Knowledge-Driven Chain-of-Thought
(KD-CoT) to verify and modify reasoning traces in CoT via interaction with
external knowledge, and thus overcome the hallucinations and error propagation.
Concretely, we formulate the CoT rationale process of LLMs into a structured
multi-round QA format. In each round, LLMs interact with a QA system that
retrieves external knowledge and produce faithful reasoning traces based on
retrieved precise answers. The structured CoT reasoning of LLMs is facilitated
by our developed KBQA CoT collection, which serves as in-context learning
demonstrations and can also be utilized as feedback augmentation to train a
robust retriever. Extensive experiments on WebQSP and ComplexWebQuestion
datasets demonstrate the effectiveness of proposed KD-CoT in task-solving
reasoning generation, which outperforms the vanilla CoT ICL with an absolute
success rate of 8.0% and 5.1%. Furthermore, our proposed feedback-augmented
retriever outperforms the state-of-the-art baselines for retrieving knowledge,
achieving significant improvement in Hit performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Construction Grammar and Language Models. (arXiv:2308.13315v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13315">
<div class="article-summary-box-inner">
<span><p>Recent progress in deep learning and natural language processing has given
rise to powerful models that are primarily trained on a cloze-like task and
show some evidence of having access to substantial linguistic information,
including some constructional knowledge. This groundbreaking discovery presents
an exciting opportunity for a synergistic relationship between computational
methods and Construction Grammar research. In this chapter, we explore three
distinct approaches to the interplay between computational methods and
Construction Grammar: (i) computational methods for text analysis, (ii)
computational Construction Grammar, and (iii) deep learning models, with a
particular focus on language models. We touch upon the first two approaches as
a contextual foundation for the use of computational methods before providing
an accessible, yet comprehensive overview of deep learning models, which also
addresses reservations construction grammarians may have. Additionally, we
delve into experiments that explore the emergence of constructionally relevant
information within these models while also examining the aspects of
Construction Grammar that may pose challenges for these models. This chapter
aims to foster collaboration between researchers in the fields of natural
language processing and Construction Grammar. By doing so, we hope to pave the
way for new insights and advancements in both these fields.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transforming the Output of Generative Pre-trained Transformer: The Influence of the PGI Framework on Attention Dynamics. (arXiv:2308.13317v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13317">
<div class="article-summary-box-inner">
<span><p>This paper presents a novel approach named Persona-Grouping-Intelligence
(PGI), which has been crafted to tackle the challenges posed by GPT models when
applied to real-world business issues. PGI leverages the inherent capabilities
of the GPT model to comprehend intricate language structures and generate
responses that are contextually relevant. The experiment occurred in a business
scenario where human intelligence was being underutilized due to less optimized
business processes. The primary objective of this approach is to leverage GPT
models to reduce the workload on humans in tasks that are extensive,
monotonous, and repetitive. Instead, the focus is redirected toward
decision-making activities. Remarkably, the experiment yielded an accuracy rate
of 93.81% in validating 4,000 responses generated by the model, underscoring
the effectiveness of the PGI strategies. Effectively addressing the issue of
underutilized human intelligence, this paradigm shift aligns business
environments with dynamic machine intelligence, enabling them to navigate the
intricacies of real-world challenges. This approach facilitates the practical
utilization of these models to tackle actual problems. The methodology offers
an opportunity to reshape the fundamental structure of business processes by
seamlessly integrating human decision-making with adaptable machine
intelligence. Consequently, this optimization enhances operational efficiency
and elevates strategic decision-making across diverse business contexts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decoupled Structure for Improved Adaptability of End-to-End Models. (arXiv:2308.13345v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13345">
<div class="article-summary-box-inner">
<span><p>Although end-to-end (E2E) trainable automatic speech recognition (ASR) has
shown great success by jointly learning acoustic and linguistic information, it
still suffers from the effect of domain shifts, thus limiting potential
applications. The E2E ASR model implicitly learns an internal language model
(LM) which characterises the training distribution of the source domain, and
the E2E trainable nature makes the internal LM difficult to adapt to the target
domain with text-only data To solve this problem, this paper proposes decoupled
structures for attention-based encoder-decoder (Decoupled-AED) and neural
transducer (Decoupled-Transducer) models, which can achieve flexible domain
adaptation in both offline and online scenarios while maintaining robust
intra-domain performance. To this end, the acoustic and linguistic parts of the
E2E model decoder (or prediction network) are decoupled, making the linguistic
component (i.e. internal LM) replaceable. When encountering a domain shift, the
internal LM can be directly replaced during inference by a target-domain LM,
without re-training or using domain-specific paired speech-text data.
Experiments for E2E ASR models trained on the LibriSpeech-100h corpus showed
that the proposed decoupled structure gave 15.1% and 17.2% relative word error
rate reductions on the TED-LIUM 2 and AESRC2020 corpora while still maintaining
performance on intra-domain data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Impact of Language Selection for Training and Evaluating Programming Language Models. (arXiv:2308.13354v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13354">
<div class="article-summary-box-inner">
<span><p>The recent advancements in Transformer-based Language Models have
demonstrated significant potential in enhancing the multilingual capabilities
of these models. The remarkable progress made in this domain not only applies
to natural language tasks but also extends to the domain of programming
languages. Despite the ability of these models to learn from multiple
languages, evaluations typically focus on particular combinations of the same
languages. In this study, we evaluate the similarity of programming languages
by analyzing their representations using a CodeBERT-based model. Our
experiments reveal that token representation in languages such as C++, Python,
and Java exhibit proximity to one another, whereas the same tokens in languages
such as Mathematica and R display significant dissimilarity. Our findings
suggest that this phenomenon can potentially result in performance challenges
when dealing with diverse languages. Thus, we recommend using our similarity
measure to select a diverse set of programming languages when training and
evaluating future models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing Keyness using Permutation Tests. (arXiv:2308.13383v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13383">
<div class="article-summary-box-inner">
<span><p>We propose a resampling-based approach for assessing keyness in corpus
linguistics based on suggestions by Gries (2006, 2022). Traditional approaches
based on hypothesis tests (e.g. Likelihood Ratio) model the copora as
independent identically distributed samples of tokens. This model does not
account for the often observed uneven distribution of occurences of a word
across a corpus. When occurences of a word are concentrated in few documents,
large values of LLR and similar scores are in fact much more likely than
accounted for by the token-by-token sampling model, leading to false positives.
</p>
<p>We replace the token-by-token sampling model by a model where corpora are
samples of documents rather than tokens, which is much closer to the way
corpora are actually assembled. We then use a permutation approach to
approximate the distribution of a given keyness score under the null hypothesis
of equal frequencies and obtain p-values for assessing significance. We do not
need any assumption on how the tokens are organized within or across documents,
and the approach works with basically *any* keyness score. Hence, appart from
obtaining more accurate p-values for scores like LLR, we can also assess
significance for e.g. the logratio which has been proposed as a measure of
effect size.
</p>
<p>An efficient implementation of the proposed approach is provided in the `R`
package `keyperm` available from github.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs. (arXiv:2308.13387v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13387">
<div class="article-summary-box-inner">
<span><p>With the rapid evolution of large language models (LLMs), new and
hard-to-predict harmful capabilities are emerging. This requires developers to
be able to identify risks through the evaluation of "dangerous capabilities" in
order to responsibly deploy LLMs. In this work, we collect the first
open-source dataset to evaluate safeguards in LLMs, and deploy safer
open-source LLMs at a low cost. Our dataset is curated and filtered to consist
only of instructions that responsible language models should not follow. We
annotate and assess the responses of six popular LLMs to these instructions.
Based on our annotation, we proceed to train several BERT-like classifiers, and
find that these small classifiers can achieve results that are comparable with
GPT-4 on automatic safety evaluation. Warning: this paper contains example data
that may be offensive, harmful, or biased.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EntropyRank: Unsupervised Keyphrase Extraction via Side-Information Optimization for Language Model-based Text Compression. (arXiv:2308.13399v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13399">
<div class="article-summary-box-inner">
<span><p>We propose an unsupervised method to extract keywords and keyphrases from
texts based on a pre-trained language model (LM) and Shannon's information
maximization. Specifically, our method extracts phrases having the highest
conditional entropy under the LM. The resulting set of keyphrases turns out to
solve a relevant information-theoretic problem: if provided as side
information, it leads to the expected minimal binary code length in compressing
the text using the LM and an entropy encoder. Alternately, the resulting set is
an approximation via a causal LM to the set of phrases that minimize the
entropy of the text when conditioned upon it. Empirically, the method provides
results comparable to the most commonly used methods in various keyphrase
extraction benchmark challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Poison of Alignment. (arXiv:2308.13449v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13449">
<div class="article-summary-box-inner">
<span><p>From the perspective of content safety issues, alignment has shown to limit
large language models' (LLMs) harmful content generation. This intentional
method of reinforcing models to not respond to certain user inputs seem to be
present in many modern open-source instruction tuning datasets such as
OpenAssistant or Guanaco. We introduce a novel insight to an instruction-tuned
model's performance affected by the presence of alignment in supervised
fine-tuning dataset. To be specific, we noticed that alignment acts as if it is
poisoning the instruction dataset. Experimentally, we demonstrate that aligned
answers significantly worsen the performance of the resulting fine-tuned
model's on various reasoning benchmarks such as Big Bench (BBH), Massive
Multitask Language Understanding (MMLU), Human Eval, and Discrete Reasoning
Over Paragraphs (DROP), performing worse than the counterpart tuned without
alignment by 4-33%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ARTIST: ARTificial Intelligence for Simplified Text. (arXiv:2308.13458v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13458">
<div class="article-summary-box-inner">
<span><p>Complex text is a major barrier for many citizens when accessing public
information and knowledge. While often done manually, Text Simplification is a
key Natural Language Processing task that aims for reducing the linguistic
complexity of a text while preserving the original meaning. Recent advances in
Generative Artificial Intelligence (AI) have enabled automatic text
simplification both on the lexical and syntactical levels. However, as
applications often focus on English, little is understood about the
effectiveness of Generative AI techniques on low-resource languages such as
Dutch. For this reason, we carry out empirical studies to understand the
benefits and limitations of applying generative technologies for text
simplification and provide the following outcomes: 1) the design and
implementation for a configurable text simplification pipeline that
orchestrates state-of-the-art generative text simplification models, domain and
reader adaptation, and visualisation modules; 2) insights and lessons learned,
showing the strengths of automatic text simplification while exposing the
challenges in handling cultural and commonsense knowledge. These outcomes
represent a first step in the exploration of Dutch text simplification and shed
light on future endeavours both for research and practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Knowledge and Reinforcement Learning for Enhanced Reliability of Language Models. (arXiv:2308.13467v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13467">
<div class="article-summary-box-inner">
<span><p>The Natural Language Processing(NLP) community has been using crowd sourcing
techniques to create benchmark datasets such as General Language Understanding
and Evaluation(GLUE) for training modern Language Models such as BERT. GLUE
tasks measure the reliability scores using inter annotator metrics i.e. Cohens
Kappa. However, the reliability aspect of LMs has often been overlooked. To
counter this problem, we explore a knowledge-guided LM ensembling approach that
leverages reinforcement learning to integrate knowledge from ConceptNet and
Wikipedia as knowledge graph embeddings. This approach mimics human annotators
resorting to external knowledge to compensate for information deficits in the
datasets. Across nine GLUE datasets, our research shows that ensembling
strengthens reliability and accuracy scores, outperforming state of the art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompting a Large Language Model to Generate Diverse Motivational Messages: A Comparison with Human-Written Messages. (arXiv:2308.13479v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13479">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) are increasingly capable and prevalent, and can
be used to produce creative content. The quality of content is influenced by
the prompt used, with more specific prompts that incorporate examples generally
producing better results. On from this, it could be seen that using
instructions written for crowdsourcing tasks (that are specific and include
examples to guide workers) could prove effective LLM prompts. To explore this,
we used a previous crowdsourcing pipeline that gave examples to people to help
them generate a collectively diverse corpus of motivational messages. We then
used this same pipeline to generate messages using GPT-4, and compared the
collective diversity of messages from: (1) crowd-writers, (2) GPT-4 using the
pipeline, and (3 &amp; 4) two baseline GPT-4 prompts. We found that the LLM prompts
using the crowdsourcing pipeline caused GPT-4 to produce more diverse messages
than the two baseline prompts. We also discuss implications from messages
generated by both human writers and LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ngambay-French Neural Machine Translation (sba-Fr). (arXiv:2308.13497v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13497">
<div class="article-summary-box-inner">
<span><p>In Africa, and the world at large, there is an increasing focus on developing
Neural Machine Translation (NMT) systems to overcome language barriers. NMT for
Low-resource language is particularly compelling as it involves learning with
limited labelled data. However, obtaining a well-aligned parallel corpus for
low-resource languages can be challenging. The disparity between the
technological advancement of a few global languages and the lack of research on
NMT for local languages in Chad is striking. End-to-end NMT trials on
low-resource Chad languages have not been attempted. Additionally, there is a
dearth of online and well-structured data gathering for research in Natural
Language Processing, unlike some African languages. However, a guided approach
for data gathering can produce bitext data for many Chadian language
translation pairs with well-known languages that have ample data. In this
project, we created the first sba-Fr Dataset, which is a corpus of
Ngambay-to-French translations, and fine-tuned three pre-trained models using
this dataset. Our experiments show that the M2M100 model outperforms other
models with high BLEU scores on both original and original+synthetic data. The
publicly available bitext dataset can be used for research purposes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training and Meta-Evaluating Machine Translation Evaluation Metrics at the Paragraph Level. (arXiv:2308.13506v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13506">
<div class="article-summary-box-inner">
<span><p>As research on machine translation moves to translating text beyond the
sentence level, it remains unclear how effective automatic evaluation metrics
are at scoring longer translations. In this work, we first propose a method for
creating paragraph-level data for training and meta-evaluating metrics from
existing sentence-level data. Then, we use these new datasets to benchmark
existing sentence-level metrics as well as train learned metrics at the
paragraph level. Interestingly, our experimental results demonstrate that using
sentence-level metrics to score entire paragraphs is equally as effective as
using a metric designed to work at the paragraph level. We speculate this
result can be attributed to properties of the task of reference-based
evaluation as well as limitations of our datasets with respect to capturing all
types of phenomena that occur in paragraph-level translations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT as Data Augmentation for Compositional Generalization: A Case Study in Open Intent Detection. (arXiv:2308.13517v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13517">
<div class="article-summary-box-inner">
<span><p>Open intent detection, a crucial aspect of natural language understanding,
involves the identification of previously unseen intents in user-generated
text. Despite the progress made in this field, challenges persist in handling
new combinations of language components, which is essential for compositional
generalization. In this paper, we present a case study exploring the use of
ChatGPT as a data augmentation technique to enhance compositional
generalization in open intent detection tasks. We begin by discussing the
limitations of existing benchmarks in evaluating this problem, highlighting the
need for constructing datasets for addressing compositional generalization in
open intent detection tasks. By incorporating synthetic data generated by
ChatGPT into the training process, we demonstrate that our approach can
effectively improve model performance. Rigorous evaluation of multiple
benchmarks reveals that our method outperforms existing techniques and
significantly enhances open intent detection capabilities. Our findings
underscore the potential of large language models like ChatGPT for data
augmentation in natural language understanding tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Simplified Variant of G\"odel's Ontological Argument. (arXiv:2202.06264v3 [cs.LO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.06264">
<div class="article-summary-box-inner">
<span><p>A simplified variant of G\"odel's ontological argument is presented. The
simplified argument is valid already in basic modal logics K or KT, it does not
suffer from modal collapse, and it avoids the rather complex predicates of
essence (Ess.) and necessary existence (NE) as used by G\"odel. The variant
presented has been obtained as a side result of a series of theory
simplification experiments conducted in interaction with a modern proof
assistant system. The starting point for these experiments was the computer
encoding of G\"odel's argument, and then automated reasoning techniques were
systematically applied to arrive at the simplified variant presented. The
presented work thus exemplifies a fruitful human-computer interaction in
computational metaphysics. Whether the presented result increases or decreases
the attractiveness and persuasiveness of the ontological argument is a question
I would like to pass on to philosophy and theology.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grammar-Based Grounded Lexicon Learning. (arXiv:2202.08806v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.08806">
<div class="article-summary-box-inner">
<span><p>We present Grammar-Based Grounded Lexicon Learning (G2L2), a lexicalist
approach toward learning a compositional and grounded meaning representation of
language from grounded data, such as paired images and texts. At the core of
G2L2 is a collection of lexicon entries, which map each word to a tuple of a
syntactic type and a neuro-symbolic semantic program. For example, the word
shiny has a syntactic type of adjective; its neuro-symbolic semantic program
has the symbolic form {\lambda}x. filter(x, SHINY), where the concept SHINY is
associated with a neural network embedding, which will be used to classify
shiny objects. Given an input sentence, G2L2 first looks up the lexicon entries
associated with each token. It then derives the meaning of the sentence as an
executable neuro-symbolic program by composing lexical meanings based on
syntax. The recovered meaning programs can be executed on grounded inputs. To
facilitate learning in an exponentially-growing compositional space, we
introduce a joint parsing and expected execution algorithm, which does local
marginalization over derivations to reduce the training time. We evaluate G2L2
on two domains: visual reasoning and language-driven navigation. Results show
that G2L2 can generalize from small amounts of data to novel compositions of
words.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales. (arXiv:2302.08961v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08961">
<div class="article-summary-box-inner">
<span><p>The quality of text-to-image generation is continuously improving, yet the
boundaries of its applicability are still unclear. In particular, refinement of
the text input with the objective of achieving better results - commonly called
prompt engineering - so far seems to have not been geared towards work with
pre-existing texts. We investigate whether text-to-image generation and prompt
engineering could be used to generate basic illustrations of popular
fairytales. Using Midjourney v4, we engage in action research with a dual aim:
to attempt to generate 5 believable illustrations for each of 5 popular
fairytales, and to define a prompt engineering process that starts from a
pre-existing text and arrives at an illustration of it. We arrive at a
tentative 4-stage process: i) initial prompt, ii) composition adjustment, iii)
style refinement, and iv) variation selection. We also discuss three reasons
why the generation model struggles with certain illustrations: difficulties
with counts, bias from stereotypical configurations and inability to depict
overly fantastic situations. Our findings are not limited to the specific
generation model and are intended to be generalisable to future ones.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding with GPT and Prototype Guidance. (arXiv:2303.16894v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.16894">
<div class="article-summary-box-inner">
<span><p>Understanding 3D scenes from multi-view inputs has been proven to alleviate
the view discrepancy issue in 3D visual grounding. However, existing methods
normally neglect the view cues embedded in the text modality and fail to weigh
the relative importance of different views. In this paper, we propose
ViewRefer, a multi-view framework for 3D visual grounding exploring how to
grasp the view knowledge from both text and 3D modalities. For the text branch,
ViewRefer leverages the diverse linguistic knowledge of large-scale language
models, e.g., GPT, to expand a single grounding text to multiple
geometry-consistent descriptions. Meanwhile, in the 3D modality, a transformer
fusion module with inter-view attention is introduced to boost the interaction
of objects across views. On top of that, we further present a set of learnable
multi-view prototypes, which memorize scene-agnostic knowledge for different
views, and enhance the framework from two perspectives: a view-guided attention
module for more robust text features, and a view-guided scoring strategy during
the final prediction. With our designed paradigm, ViewRefer achieves superior
performance on three benchmarks and surpasses the second-best by +2.8%, +1.5%,
and +1.35% on Sr3D, Nr3D, and ScanRefer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Approximating Online Human Evaluation of Social Chatbots with Prompting. (arXiv:2304.05253v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.05253">
<div class="article-summary-box-inner">
<span><p>As conversational models become increasingly available to the general public,
users are engaging with this technology in social interactions. Such
unprecedented interaction experiences may pose considerable social and
psychological risks to the users unless the technology is properly controlled.
This highlights the need for scalable and robust evaluation metrics for
conversational chatbots. Existing evaluation metrics aim to automate offline
user evaluation and approximate human judgment of pre-curated dialogs. However,
they are limited in their ability to capture subjective perceptions of users
who actually interact with the bots and might not generalize to real-world
settings. To address this limitation, we propose an approach to approximate
online human evaluation leveraging large language models (LLMs) from the GPT
family. We introduce a new Dialog system Evaluation framework based on
Prompting (DEP), which enables a fully automatic evaluation pipeline that
replicates live user studies and achieves an impressive correlation with human
judgment (up to Pearson r=0.95 on a system level). The DEP approach involves
collecting synthetic chat logs of evaluated bots with an LLM in the other-play
setting, where the LLM is carefully conditioned to follow a specific scenario.
We further explore different prompting approaches to produce evaluation scores
with the same LLM. The best performing prompts, which contain few-shot
demonstrations and instructions, show outstanding performance on the tested
dataset and demonstrate the ability to generalize to other dialog corpora.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PMC-LLaMA: Towards Building Open-source Language Models for Medicine. (arXiv:2304.14454v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.14454">
<div class="article-summary-box-inner">
<span><p>Recently, Large Language Models (LLMs) have showcased remarkable capabilities
in natural language understanding. While demonstrating proficiency in everyday
conversations and question-answering situations, these models frequently
struggle in domains that require precision, such as medical applications, due
to their lack of domain-specific knowledge. In this paper, we describe the
procedure for building a powerful, open-source language model specifically
designed for medicine applications, termed as PMC-LLaMA. Our contributions are
threefold: (i) we systematically investigate the process of adapting a
general-purpose foundation language model towards medical domain, this involves
data-centric knowledge injection through the integration of 4.8M biomedical
academic papers and 30K medical textbooks, as well as comprehensive fine-tuning
for alignment with domain-specific instructions; (ii) we contribute a
large-scale, comprehensive dataset for instruction tuning. This dataset
encompasses medical question-answering (QA), rationale for reasoning, and
conversational dialogues, comprising a total of 202M tokens; (iii) we conduct
thorough ablation studies to demonstrate the effectiveness of each proposed
component. While evaluating on various public medical question-answering
benchmarks, our lightweight PMCLLaMA, which consists of only 13 billion
parameters, exhibits superior performance, even surpassing ChatGPT. All models,
codes, datasets can be found in https://github.com/chaoyi-wu/PMC-LLaMA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds. (arXiv:2305.00969v4 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.00969">
<div class="article-summary-box-inner">
<span><p>This paper describes the Ubenwa CryCeleb dataset - a labeled collection of
infant cries, and the accompanying CryCeleb 2023 task - a public speaker
verification challenge based on infant cry sounds. We release for academic
usage more than 6 hours of manually segmented cry sounds from 786 newborns to
encourage research in infant cry analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion Synthesis. (arXiv:2305.00976v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.00976">
<div class="article-summary-box-inner">
<span><p>In this paper, we present TMR, a simple yet effective approach for text to 3D
human motion retrieval. While previous work has only treated retrieval as a
proxy evaluation metric, we tackle it as a standalone task. Our method extends
the state-of-the-art text-to-motion synthesis model TEMOS, and incorporates a
contrastive loss to better structure the cross-modal latent space. We show that
maintaining the motion generation loss, along with the contrastive training, is
crucial to obtain good performance. We introduce a benchmark for evaluation and
provide an in-depth analysis by reporting results on several protocols. Our
extensive experiments on the KIT-ML and HumanML3D datasets show that TMR
outperforms the prior work by a significant margin, for example reducing the
median rank from 54 to 19. Finally, we showcase the potential of our approach
on moment retrieval. Our code and models are publicly available at
https://mathis.petrovich.fr/tmr.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers. (arXiv:2305.07011v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07011">
<div class="article-summary-box-inner">
<span><p>We present Region-aware Open-vocabulary Vision Transformers (RO-ViT) - a
contrastive image-text pretraining recipe to bridge the gap between image-level
pretraining and open-vocabulary object detection. At the pretraining phase, we
propose to randomly crop and resize regions of positional embeddings instead of
using the whole image positional embeddings. This better matches the use of
positional embeddings at region-level in the detection finetuning phase. In
addition, we replace the common softmax cross entropy loss in contrastive
learning with focal loss to better learn the informative yet difficult
examples. Finally, we leverage recent advances in novel object proposals to
improve open-vocabulary detection finetuning. We evaluate our full model on the
LVIS and COCO open-vocabulary detection benchmarks and zero-shot transfer.
RO-ViT achieves a state-of-the-art 34.1 $AP_r$ on LVIS, surpassing the best
existing approach by +7.8 points in addition to competitive zero-shot transfer
detection. Surprisingly, RO-ViT improves the image-level representation as well
and achieves the state of the art on 9 out of 12 metrics on COCO and Flickr
image-text retrieval benchmarks, outperforming competitive approaches with
larger models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Estimate Model Transferability of Pre-Trained Speech Models?. (arXiv:2306.01015v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01015">
<div class="article-summary-box-inner">
<span><p>In this work, we introduce a "score-based assessment" framework for
estimating the transferability of pre-trained speech models (PSMs) for
fine-tuning target tasks. We leverage upon two representation theories,
Bayesian likelihood estimation and optimal transport, to generate rank scores
for the PSM candidates using the extracted representations. Our framework
efficiently computes transferability scores without actual fine-tuning of
candidate models or layers by making a temporal independent hypothesis. We
evaluate some popular supervised speech models (e.g., Conformer RNN-Transducer)
and self-supervised speech models (e.g., HuBERT) in cross-layer and cross-model
settings using public data. Experimental results show a high Spearman's rank
correlation and low $p$-value between our estimation framework and fine-tuning
ground truth. Our proposed transferability framework requires less
computational time and resources, making it a resource-saving and
time-efficient approach for tuning speech foundation models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SpeechGen: Unlocking the Generative Power of Speech Language Models with Prompts. (arXiv:2306.02207v3 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.02207">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have gained considerable attention for
Artificial Intelligence Generated Content (AIGC), particularly with the
emergence of ChatGPT. However, the direct adaptation of continuous speech to
LLMs that process discrete tokens remains an unsolved challenge, hindering the
application of LLMs for speech generation. The advanced speech LMs are in the
corner, as that speech signals encapsulate a wealth of information, including
speaker and emotion, beyond textual data alone. Prompt tuning has demonstrated
notable gains in parameter efficiency and competitive performance on some
speech classification tasks. However, the extent to which prompts can
effectively elicit generation tasks from speech LMs remains an open question.
In this paper, we present pioneering research that explores the application of
prompt tuning to stimulate speech LMs for various generation tasks, within a
unified framework called SpeechGen, with around 10M trainable parameters. The
proposed unified framework holds great promise for efficiency and
effectiveness, particularly with the imminent arrival of advanced speech LMs,
which will significantly enhance the capabilities of the framework. The code
and demos of SpeechGen will be available on the project website:
\url{https://ga642381.github.io/SpeechPrompt/speechgen}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain-specific ChatBots for Science using Embeddings. (arXiv:2306.10067v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.10067">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have emerged as powerful machine-learning
systems capable of handling a myriad of tasks. Tuned versions of these systems
have been turned into chatbots that can respond to user queries on a vast
diversity of topics, providing informative and creative replies. However, their
application to physical science research remains limited owing to their
incomplete knowledge in these areas, contrasted with the needs of rigor and
sourcing in science domains. Here, we demonstrate how existing methods and
software tools can be easily combined to yield a domain-specific chatbot. The
system ingests scientific documents in existing formats, and uses text
embedding lookup to provide the LLM with domain-specific contextual information
when composing its reply. We similarly demonstrate that existing image
embedding methods can be used for search and retrieval across publication
figures. These results confirm that LLMs are already suitable for use by
physical scientists in accelerating their research efforts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ACTI at EVALITA 2023: Overview of the Conspiracy Theory Identification Task. (arXiv:2307.06954v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.06954">
<div class="article-summary-box-inner">
<span><p>Conspiracy Theory Identication task is a new shared task proposed for the
first time at the Evalita 2023. The ACTI challenge, based exclusively on
comments published on conspiratorial channels of telegram, is divided into two
subtasks: (i) Conspiratorial Content Classification: identifying conspiratorial
content and (ii) Conspiratorial Category Classification about specific
conspiracy theory classification. A total of fifteen teams participated in the
task for a total of 81 submissions. We illustrate the best performing
approaches were based on the utilization of large language models. We finally
draw conclusions about the utilization of these models for counteracting the
spreading of misinformation in online platforms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decoding ChatGPT: A Taxonomy of Existing Research, Current Challenges, and Possible Future Directions. (arXiv:2307.14107v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.14107">
<div class="article-summary-box-inner">
<span><p>Chat Generative Pre-trained Transformer (ChatGPT) has gained significant
interest and attention since its launch in November 2022. It has shown
impressive performance in various domains, including passing exams and creative
writing. However, challenges and concerns related to biases and trust persist.
In this work, we present a comprehensive review of over 100 Scopus-indexed
publications on ChatGPT, aiming to provide a taxonomy of ChatGPT research and
explore its applications. We critically analyze the existing literature,
identifying common approaches employed in the studies. Additionally, we
investigate diverse application areas where ChatGPT has found utility, such as
healthcare, marketing and financial services, software engineering, academic
and scientific writing, research and education, environmental science, and
natural language processing. Through examining these applications, we gain
valuable insights into the potential of ChatGPT in addressing real-world
challenges. We also discuss crucial issues related to ChatGPT, including biases
and trustworthiness, emphasizing the need for further research and development
in these areas. Furthermore, we identify potential future directions for
ChatGPT research, proposing solutions to current challenges and speculating on
expected advancements. By fully leveraging the capabilities of ChatGPT, we can
unlock its potential across various domains, leading to advancements in
conversational AI and transformative impacts in society.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatMOF: An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks. (arXiv:2308.01423v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01423">
<div class="article-summary-box-inner">
<span><p>ChatMOF is an autonomous Artificial Intelligence (AI) system that is built to
predict and generate metal-organic frameworks (MOFs). By leveraging a
large-scale language model (GPT-4 and GPT-3.5-turbo), ChatMOF extracts key
details from textual inputs and delivers appropriate responses, thus
eliminating the necessity for rigid structured queries. The system is comprised
of three core components (i.e. an agent, a toolkit, and an evaluator) and it
forms a robust pipeline that manages a variety of tasks, including data
retrieval, property prediction, and structure generations. The study further
explores the merits and constraints of using large language models (LLMs) AI
system in material sciences using and showcases its transformative potential
for future advancements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmarking Neural Network Generalization for Grammar Induction. (arXiv:2308.08253v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.08253">
<div class="article-summary-box-inner">
<span><p>How well do neural networks generalize? Even for grammar induction tasks,
where the target generalization is fully known, previous works have left the
question open, testing very limited ranges beyond the training set and using
different success criteria. We provide a measure of neural network
generalization based on fully specified formal languages. Given a model and a
formal grammar, the method assigns a generalization score representing how well
a model generalizes to unseen samples in inverse relation to the amount of data
it was trained on. The benchmark includes languages such as $a^nb^n$,
$a^nb^nc^n$, $a^nb^mc^{n+m}$, and Dyck-1 and 2. We evaluate selected
architectures using the benchmark and find that networks trained with a Minimum
Description Length objective (MDL) generalize better and using less data than
networks trained using standard loss functions. The benchmark is available at
https://github.com/taucompling/bliss.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">cantnlp@LT-EDI-2023: Homophobia/Transphobia Detection in Social Media Comments using Spatio-Temporally Retrained Language Models. (arXiv:2308.10370v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.10370">
<div class="article-summary-box-inner">
<span><p>This paper describes our multiclass classification system developed as part
of the LTEDI@RANLP-2023 shared task. We used a BERT-based language model to
detect homophobic and transphobic content in social media comments across five
language conditions: English, Spanish, Hindi, Malayalam, and Tamil. We
retrained a transformer-based crosslanguage pretrained language model,
XLMRoBERTa, with spatially and temporally relevant social media language data.
We also retrained a subset of models with simulated script-mixed social media
language data with varied performance. We developed the best performing
seven-label classification system for Malayalam based on weighted macro
averaged F1 score (ranked first out of six) with variable performance for other
language and class-label conditions. We found the inclusion of this
spatio-temporal data improved the classification performance for all language
and task conditions when compared with the baseline. The results suggests that
transformer-based language classification systems are sensitive to
register-specific and language-specific retraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Authorship Representation Learning Capture Stylistic Features?. (arXiv:2308.11490v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.11490">
<div class="article-summary-box-inner">
<span><p>Automatically disentangling an author's style from the content of their
writing is a longstanding and possibly insurmountable problem in computational
linguistics. At the same time, the availability of large text corpora furnished
with author labels has recently enabled learning authorship representations in
a purely data-driven manner for authorship attribution, a task that ostensibly
depends to a greater extent on encoding writing style than encoding content.
However, success on this surrogate task does not ensure that such
representations capture writing style since authorship could also be correlated
with other latent variables, such as topic. In an effort to better understand
the nature of the information these representations convey, and specifically to
validate the hypothesis that they chiefly encode writing style, we
systematically probe these representations through a series of targeted
experiments. The results of these experiments suggest that representations
learned for the surrogate authorship prediction task are indeed sensitive to
writing style. As a consequence, authorship representations may be expected to
be robust to certain kinds of data shift, such as topic drift over time.
Additionally, our findings may open the door to downstream applications that
require stylistic representations, such as style transfer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Prototype Adapter for Vision-Language Models. (arXiv:2308.11507v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.11507">
<div class="article-summary-box-inner">
<span><p>Recently, large-scale pre-trained vision-language models (e.g. CLIP and
ALIGN) have demonstrated remarkable effectiveness in acquiring transferable
visual representations. To leverage the valuable knowledge encoded within these
models for downstream tasks, several fine-tuning approaches, including prompt
tuning methods and adapter-based methods, have been developed to adapt
vision-language models effectively with supervision. However, these methods
rely on the availability of annotated samples, which can be labor-intensive and
time-consuming to acquire, thus limiting scalability. To address this issue, in
this work, we design an unsupervised fine-tuning approach for vision-language
models called Unsupervised Prototype Adapter (UP-Adapter). Specifically, for
the unannotated target datasets, we leverage the text-image aligning capability
of CLIP to automatically select the most confident samples for each class.
Utilizing these selected samples, we generate class prototypes, which serve as
the initialization for the learnable prototype model. After fine-tuning, the
prototype model prediction is combined with the original CLIP's prediction by a
residual connection to perform downstream recognition tasks. Our extensive
experimental results on image recognition and domain generalization show that
the proposed unsupervised method outperforms 8-shot CoOp, 8-shot Tip-Adapter,
and also the state-of-the-art UPL method by large margins.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Deception: Reverse Penetrating the Semantic Firewall of Large Language Models. (arXiv:2308.11521v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.11521">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs), such as ChatGPT, have emerged with astonishing
capabilities approaching artificial general intelligence. While providing
convenience for various societal needs, LLMs have also lowered the cost of
generating harmful content. Consequently, LLM developers have deployed
semantic-level defenses to recognize and reject prompts that may lead to
inappropriate content. Unfortunately, these defenses are not foolproof, and
some attackers have crafted "jailbreak" prompts that temporarily hypnotize the
LLM into forgetting content defense rules and answering any improper questions.
To date, there is no clear explanation of the principles behind these
semantic-level attacks and defenses in both industry and academia.
</p>
<p>This paper investigates the LLM jailbreak problem and proposes an automatic
jailbreak method for the first time. We propose the concept of a semantic
firewall and provide three technical implementation approaches. Inspired by the
attack that penetrates traditional firewalls through reverse tunnels, we
introduce a "self-deception" attack that can bypass the semantic firewall by
inducing LLM to generate prompts that facilitate jailbreak. We generated a
total of 2,520 attack payloads in six languages (English, Russian, French,
Spanish, Chinese, and Arabic) across seven virtual scenarios, targeting the
three most common types of violations: violence, hate, and pornography. The
experiment was conducted on two models, namely the GPT-3.5-Turbo and GPT-4. The
success rates on the two models were 86.2% and 67%, while the failure rates
were 4.7% and 2.2%, respectively. This highlighted the effectiveness of the
proposed attack method. All experimental code and raw data will be released as
open-source to inspire future research. We believe that manipulating AI
behavior through carefully crafted prompts will become an important research
direction in the future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning. (arXiv:2308.12219v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.12219">
<div class="article-summary-box-inner">
<span><p>The recent surge of generative AI has been fueled by the generative power of
diffusion probabilistic models and the scalable capabilities of large language
models. Despite their potential, it remains elusive whether diffusion language
models can solve general language tasks comparable to their autoregressive
counterparts. This paper demonstrates that scaling diffusion models w.r.t.
data, sizes, and tasks can effectively make them strong language learners. We
build competent diffusion language models at scale by first acquiring knowledge
from massive data via masked language modeling pretraining thanks to their
intrinsic connections. We then reprogram pretrained masked language models into
diffusion language models via diffusive adaptation, wherein task-specific
finetuning and instruction finetuning are explored to unlock their versatility
in solving general language tasks. Experiments show that scaling diffusion
language models consistently improves performance across downstream language
tasks. We further discover that instruction finetuning can elicit zero-shot and
few-shot in-context learning abilities that help tackle many unseen tasks by
following natural language instructions, and show promise in advanced and
challenging abilities such as reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?. (arXiv:2308.12898v2 [cs.MM] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.12898">
<div class="article-summary-box-inner">
<span><p>The multimedia community has shown a significant interest in perceiving and
representing the physical world with multimodal pretrained neural network
models, and among them, the visual-language pertaining (VLP) is, currently, the
most captivating topic. However, there have been few endeavors dedicated to the
exploration of 1) whether essential linguistic knowledge (e.g., semantics and
syntax) can be extracted during VLP, and 2) how such linguistic knowledge
impact or enhance the multimodal alignment. In response, here we aim to
elucidate the impact of comprehensive linguistic knowledge, including semantic
expression and syntactic structure, on multimodal alignment. Specifically, we
design and release the SNARE, the first large-scale multimodal alignment
probing benchmark, to detect the vital linguistic components, e.g., lexical,
semantic, and syntax knowledge, containing four tasks: Semantic structure,
Negation logic, Attribute ownership, and Relationship composition. Based on our
proposed probing benchmarks, our holistic analyses of five advanced VLP models
illustrate that the VLP model: i) shows insensitivity towards complex syntax
structures and relies on content words for sentence comprehension; ii)
demonstrates limited comprehension of combinations between sentences and
negations; iii) faces challenges in determining the presence of actions or
spatial relationships within visual information and struggles with verifying
the correctness of triple combinations. We make our benchmark and code
available at \url{https://github.com/WangFei-2019/SNARE/}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Code Llama: Open Foundation Models for Code. (arXiv:2308.12950v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.12950">
<div class="article-summary-box-inner">
<span><p>We release Code Llama, a family of large language models for code based on
Llama 2 providing state-of-the-art performance among open models, infilling
capabilities, support for large input contexts, and zero-shot instruction
following ability for programming tasks. We provide multiple flavors to cover a
wide range of applications: foundation models (Code Llama), Python
specializations (Code Llama - Python), and instruction-following models (Code
Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained
on sequences of 16k tokens and show improvements on inputs with up to 100k
tokens. 7B and 13B Code Llama and Code Llama - Instruct variants support
infilling based on surrounding content. Code Llama reaches state-of-the-art
performance among open models on several code benchmarks, with scores of up to
53% and 55% on HumanEval and MBPP, respectively. Notably, Code Llama - Python
7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform
every other publicly available model on MultiPL-E. We release Code Llama under
a permissive license that allows for both research and commercial use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph-Based Recommendation System Enhanced with Community Detection. (arXiv:2201.03622v3 [cs.IR] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03622">
<div class="article-summary-box-inner">
<span><p>Many researchers have used tag information to improve the performance of
recommendation techniques in recommender systems. Examining the tags of users
will help to get their interests and leads to more accuracy in the
recommendations. Since user-defined tags are chosen freely and without any
restrictions, problems arise in determining their exact meaning and the
similarity of tags. However, using thesaurus and ontologies to find the meaning
of tags is not very efficient due to their free definition by users and the use
of different languages in many data sets. Therefore, this article uses
mathematical and statistical methods to determine lexical similarity and
co-occurrence tags solution to assign semantic similarity. On the other hand,
due to the change of users' interests over time this article has considered the
time of tag assignments in co-occurrence tags for determining similarity of
tags. Then the graph is created based on similarity of tags. For modeling the
interests of the users, the communities of tags are determined by using
community detection methods. So, recommendations based on the communities of
tags and similarity between resources are done. The performance of the proposed
method has been evaluated using two criteria of precision and recall through
evaluations on two public datasets. The evaluation results show that the
precision and recall of the proposed method have significantly improved,
compared to the other methods. According to the experimental results, the
criteria of recall and precision have been improved, on average by 5% and 7%
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Dialects Collide: How Socioeconomic Mixing Affects Language Use. (arXiv:2307.10016v1 [physics.soc-ph] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.10016">
<div class="article-summary-box-inner">
<span><p>The socioeconomic background of people and how they use standard forms of
language are not independent, as demonstrated in various sociolinguistic
studies. However, the extent to which these correlations may be influenced by
the mixing of people from different socioeconomic classes remains relatively
unexplored from a quantitative perspective. In this work we leverage geotagged
tweets and transferable computational methods to map deviations from standard
English on a large scale, in seven thousand administrative areas of England and
Wales. We combine these data with high-resolution income maps to assign a proxy
socioeconomic indicator to home-located users. Strikingly, across eight
metropolitan areas we find a consistent pattern suggesting that the more
different socioeconomic classes mix, the less interdependent the frequency of
their departures from standard grammar and their income become. Further, we
propose an agent-based model of linguistic variety adoption that sheds light on
the mechanisms that produce the observations seen in the data.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-08-28 23:10:54.733844447 UTC">2023-08-28 23:10:54 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>