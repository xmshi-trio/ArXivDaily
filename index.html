<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-08-14T01:30:00Z">08-14</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">PIPPA: A Partially Synthetic Conversational Dataset. (arXiv:2308.05884v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.05884">
<div class="article-summary-box-inner">
<span><p>With the emergence of increasingly powerful large language models, there is a
burgeoning interest in leveraging these models for casual conversation and
role-play applications. However, existing conversational and role-playing
datasets often fail to capture the diverse and nuanced interactions typically
exhibited by real-world role-play participants. To address this limitation and
contribute to the rapidly growing field, we introduce a partially-synthetic
dataset named PIPPA (Personal Interaction Pairs between People and AI). PIPPA
is a result of a community-driven crowdsourcing effort involving a group of
role-play enthusiasts. The dataset comprises over 1 million utterances that are
distributed across 26,000 conversation sessions and provides a rich resource
for researchers and AI developers to explore and refine conversational AI
systems in the context of role-play scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LittleMu: Deploying an Online Virtual Teaching Assistant via Heterogeneous Sources Integration and Chain of Teach Prompts. (arXiv:2308.05935v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.05935">
<div class="article-summary-box-inner">
<span><p>Teaching assistants have played essential roles in the long history of
education. However, few MOOC platforms are providing human or virtual teaching
assistants to support learning for massive online students due to the
complexity of real-world online education scenarios and the lack of training
data. In this paper, we present a virtual MOOC teaching assistant, LittleMu
with minimum labeled training data, to provide question answering and chit-chat
services. Consisting of two interactive modules of heterogeneous retrieval and
language model prompting, LittleMu first integrates structural, semi- and
unstructured knowledge sources to support accurate answers for a wide range of
questions. Then, we design delicate demonstrations named "Chain of Teach"
prompts to exploit the large-scale pre-trained model to handle complex
uncollected questions. Except for question answering, we develop other
educational services such as knowledge-grounded chit-chat. We test the system's
performance via both offline evaluation and online deployment. Since May 2020,
our LittleMu system has served over 80,000 users with over 300,000 queries from
over 500 courses on XuetangX MOOC platform, which continuously contributes to a
more convenient and fair education. Our code, services, and dataset will be
available at https://github.com/THU-KEG/VTA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tweet Sentiment Extraction using Viterbi Algorithm with Transfer Learning. (arXiv:2308.05973v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.05973">
<div class="article-summary-box-inner">
<span><p>Tweet sentiment extraction extracts the most significant portion of the
sentence, determining whether the sentiment is positive or negative. This
research aims to identify the part of tweet sentences that strikes any emotion.
To reach this objective, we continue improving the Viterbi algorithm previously
modified by the author to make it able to receive pre-trained model parameters.
We introduce the confidence score and vector as two indicators responsible for
evaluating the model internally before assessing the final results. We then
present a method to fine-tune this nonparametric model. We found that the model
gets highly explainable as the confidence score vector reveals precisely where
the least confidence predicted states are and if the modifications approved
ameliorate the confidence score or if the tuning is going in the wrong
direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimizing transformer-based machine translation model for single GPU training: a hyperparameter ablation study. (arXiv:2308.06017v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06017">
<div class="article-summary-box-inner">
<span><p>In machine translation tasks, the relationship between model complexity and
performance is often presumed to be linear, driving an increase in the number
of parameters and consequent demands for computational resources like multiple
GPUs. To explore this assumption, this study systematically investigates the
effects of hyperparameters through ablation on a sequence-to-sequence machine
translation pipeline, utilizing a single NVIDIA A100 GPU. Contrary to
expectations, our experiments reveal that combinations with the most parameters
were not necessarily the most effective. This unexpected insight prompted a
careful reduction in parameter sizes, uncovering "sweet spots" that enable
training sophisticated models on a single GPU without compromising translation
quality. The findings demonstrate an intricate relationship between
hyperparameter selection, model size, and computational resource needs. The
insights from this study contribute to the ongoing efforts to make machine
translation more accessible and cost-effective, emphasizing the importance of
precise hyperparameter tuning over mere scaling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models in Cryptocurrency Securities Cases: Can ChatGPT Replace Lawyers?. (arXiv:2308.06032v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06032">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) could enhance access to the legal system.
However, empirical research on their effectiveness in conducting legal tasks is
scant. We study securities cases involving cryptocurrencies as one of numerous
contexts where AI could support the legal process, studying LLMs' legal
reasoning and drafting capabilities. We examine whether a) an LLM can
accurately determine which laws are potentially being violated from a fact
pattern, and b) whether there is a difference in juror decision-making based on
complaints written by a lawyer compared to an LLM. We feed fact patterns from
real-life cases to GPT-3.5 and evaluate its ability to determine correct
potential violations from the scenario and exclude spurious violations. Second,
we had mock jurors assess complaints written by the LLM and lawyers. GPT-3.5's
legal reasoning skills proved weak, though we expect improvement in future
models, particularly given the violations it suggested tended to be correct (it
merely missed additional, correct violations). GPT-3.5 performed better at
legal drafting, and jurors' decisions were not statistically significantly
associated with the author of the document upon which they based their
decisions. Because LLMs cannot satisfactorily conduct legal reasoning tasks,
they would be unable to replace lawyers at this stage. However, their drafting
skills (though, perhaps, still inferior to lawyers), could provide access to
justice for more individuals by reducing the cost of legal services. Our
research is the first to systematically study LLMs' legal drafting and
reasoning capabilities in litigation, as well as in securities law and
cryptocurrency-related misconduct.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evidence of Human-Like Visual-Linguistic Integration in Multimodal Large Language Models During Predictive Language Processing. (arXiv:2308.06035v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06035">
<div class="article-summary-box-inner">
<span><p>The advanced language processing abilities of large language models (LLMs)
have stimulated debate over their capacity to replicate human-like cognitive
processes. One differentiating factor between language processing in LLMs and
humans is that language input is often grounded in more than one perceptual
modality, whereas most LLMs process solely text-based information. Multimodal
grounding allows humans to integrate - e.g. visual context with linguistic
information and thereby place constraints on the space of upcoming words,
reducing cognitive load and improving perception and comprehension. Recent
multimodal LLMs (mLLMs) combine visual and linguistic embedding spaces with a
transformer type attention mechanism for next-word prediction. To what extent
does predictive language processing based on multimodal input align in mLLMs
and humans? To answer this question, 200 human participants watched short
audio-visual clips and estimated the predictability of an upcoming verb or
noun. The same clips were processed by the mLLM CLIP, with predictability
scores based on a comparison of image and text feature vectors. Eye-tracking
was used to estimate what visual features participants attended to, and CLIP's
visual attention weights were recorded. We find that human estimates of
predictability align significantly with CLIP scores, but not for a unimodal LLM
of comparable parameter size. Further, alignment vanished when CLIP's visual
attention weights were perturbed, and when the same input was fed to a
multimodal model without attention. Analysing attention patterns, we find a
significant spatial overlap between CLIP's visual attention weights and human
eye-tracking data. Results suggest that comparable processes of integrating
multimodal information, guided by attention to relevant visual features,
supports predictive language processing in mLLMs and humans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Guide Human Experts via Personalized Large Language Models. (arXiv:2308.06039v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06039">
<div class="article-summary-box-inner">
<span><p>In learning to defer, a predictor identifies risky decisions and defers them
to a human expert. One key issue with this setup is that the expert may end up
over-relying on the machine's decisions, due to anchoring bias. At the same
time, whenever the machine chooses the deferral option the expert has to take
decisions entirely unassisted. As a remedy, we propose learning to guide (LTG),
an alternative framework in which -- rather than suggesting ready-made
decisions -- the machine provides guidance useful to guide decision-making, and
the human is entirely responsible for coming up with a decision. We also
introduce SLOG, an LTG implementation that leverages (a small amount of) human
supervision to convert a generic large language model into a module capable of
generating textual guidance, and present preliminary but promising results on a
medical diagnosis task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Case Study on Context Encoding in Multi-Encoder based Document-Level Neural Machine Translation. (arXiv:2308.06063v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06063">
<div class="article-summary-box-inner">
<span><p>Recent studies have shown that the multi-encoder models are agnostic to the
choice of context, and the context encoder generates noise which helps improve
the models in terms of BLEU score. In this paper, we further explore this idea
by evaluating with context-aware pronoun translation test set by training
multi-encoder models trained on three different context settings viz, previous
two sentences, random two sentences, and a mix of both as context.
Specifically, we evaluate the models on the ContraPro test set to study how
different contexts affect pronoun translation accuracy. The results show that
the model can perform well on the ContraPro test set even when the context is
random. We also analyze the source representations to study whether the context
encoder generates noise. Our analysis shows that the context encoder provides
sufficient information to learn discourse-level information. Additionally, we
observe that mixing the selected context (the previous two sentences in this
case) and the random context is generally better than the other settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fly-Swat or Cannon? Cost-Effective Language Model Choice via Meta-Modeling. (arXiv:2308.06077v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06077">
<div class="article-summary-box-inner">
<span><p>Generative language models (LMs) have become omnipresent across data science.
For a wide variety of tasks, inputs can be phrased as natural language prompts
for an LM, from whose output the solution can then be extracted. LM performance
has consistently been increasing with model size - but so has the monetary cost
of querying the ever larger models. Importantly, however, not all inputs are
equally hard: some require larger LMs for obtaining a satisfactory solution,
whereas for others smaller LMs suffice. Based on this fact, we design a
framework for Cost-Effective Language Model Choice (CELMOC). Given a set of
inputs and a set of candidate LMs, CELMOC judiciously assigns each input to an
LM predicted to do well on the input according to a so-called meta-model,
aiming to achieve high overall performance at low cost. The cost-performance
trade-off can be flexibly tuned by the user. Options include, among others,
maximizing total expected performance (or the number of processed inputs) while
staying within a given cost budget, or minimizing total cost while processing
all inputs. We evaluate CELMOC on 14 datasets covering five natural language
tasks, using four candidate LMs of vastly different size and cost. With CELMOC,
we match the performance of the largest available LM while achieving a cost
reduction of 63%. Via our publicly available library, researchers as well as
practitioners can thus save large amounts of money without sacrificing
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Conversation Models and How to Rein Them in: A Survey of Failures and Fixes. (arXiv:2308.06095v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06095">
<div class="article-summary-box-inner">
<span><p>Recent conditional language models are able to continue any kind of text
source in an often seemingly fluent way. This fact encouraged research in the
area of open-domain conversational systems that are based on powerful language
models and aim to imitate an interlocutor by generating appropriate
contributions to a written dialogue. From a linguistic perspective, however,
the complexity of contributing to a conversation is high. In this survey, we
interpret Grice's maxims of cooperative conversation from the perspective of
this specific research area and systematize the literature under the aspect of
what makes a contribution appropriate: A neural conversation model has to be
fluent, informative, consistent, coherent, and follow social norms. In order to
ensure these qualities, recent approaches try to tame the underlying language
models at various intervention points, such as data, training regime or
decoding. Sorted by these categories and intervention points, we discuss
promising attempts and suggest novel ways for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Zero-Shot Text Matching for Financial Auditing with Large Language Models. (arXiv:2308.06111v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06111">
<div class="article-summary-box-inner">
<span><p>Auditing financial documents is a very tedious and time-consuming process. As
of today, it can already be simplified by employing AI-based solutions to
recommend relevant text passages from a report for each legal requirement of
rigorous accounting standards. However, these methods need to be fine-tuned
regularly, and they require abundant annotated data, which is often lacking in
industrial environments. Hence, we present ZeroShotALI, a novel recommender
system that leverages a state-of-the-art large language model (LLM) in
conjunction with a domain-specifically optimized transformer-based
text-matching solution. We find that a two-step approach of first retrieving a
number of best matching document sections per legal requirement with a custom
BERT-based model and second filtering these selections using an LLM yields
significant performance improvements over existing approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lip2Vec: Efficient and Robust Visual Speech Recognition via Latent-to-Latent Visual to Audio Representation Mapping. (arXiv:2308.06112v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06112">
<div class="article-summary-box-inner">
<span><p>Visual Speech Recognition (VSR) differs from the common perception tasks as
it requires deeper reasoning over the video sequence, even by human experts.
Despite the recent advances in VSR, current approaches rely on labeled data to
fully train or finetune their models predicting the target speech. This hinders
their ability to generalize well beyond the training set and leads to
performance degeneration under out-of-distribution challenging scenarios.
Unlike previous works that involve auxiliary losses or complex training
procedures and architectures, we propose a simple approach, named Lip2Vec that
is based on learning a prior model. Given a robust visual speech encoder, this
network maps the encoded latent representations of the lip sequence to their
corresponding latents from the audio pair, which are sufficiently invariant for
effective text decoding. The generated audio representation is then decoded to
text using an off-the-shelf Audio Speech Recognition (ASR) model. The proposed
model compares favorably with fully-supervised learning methods on the LRS3
dataset achieving 26 WER. Unlike SoTA approaches, our model keeps a reasonable
performance on the VoxCeleb test set. We believe that reprogramming the VSR as
an ASR task narrows the performance gap between the two and paves the way for
more flexible formulations of lip reading.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Joint Speech-Text Representations Without Alignment. (arXiv:2308.06125v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06125">
<div class="article-summary-box-inner">
<span><p>The last year has seen astonishing progress in text-prompted image generation
premised on the idea of a cross-modal representation space in which the text
and image domains are represented jointly. In ASR, this idea has found
application as joint speech-text encoders that can scale to the capacities of
very large parameter models by being trained on both unpaired speech and text.
While these methods show promise, they have required special treatment of the
sequence-length mismatch inherent in speech and text, either by up-sampling
heuristics or an explicit alignment model. In this work, we offer evidence that
joint speech-text encoders naturally achieve consistent representations across
modalities by disregarding sequence length, and argue that consistency losses
could forgive length differences and simply assume the best alignment. We show
that such a loss improves downstream WER in both a large-parameter monolingual
and multilingual system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identification of the Relevance of Comments in Codes Using Bag of Words and Transformer Based Models. (arXiv:2308.06144v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06144">
<div class="article-summary-box-inner">
<span><p>The Forum for Information Retrieval (FIRE) started a shared task this year
for classification of comments of different code segments. This is binary text
classification task where the objective is to identify whether comments given
for certain code segments are relevant or not. The BioNLP-IISERB group at the
Indian Institute of Science Education and Research Bhopal (IISERB) participated
in this task and submitted five runs for five different models. The paper
presents the overview of the models and other significant findings on the
training corpus. The methods involve different feature engineering schemes and
text classification techniques. The performance of the classical bag of words
model and transformer-based models were explored to identify significant
features from the given training corpus. We have explored different classifiers
viz., random forest, support vector machine and logistic regression using the
bag of words model. Furthermore, the pre-trained transformer based models like
BERT, RoBERT and ALBERT were also used by fine-tuning them on the given
training corpus. The performance of different such models over the training
corpus were reported and the best five models were implemented on the given
test corpus. The empirical results show that the bag of words model outperforms
the transformer based models, however, the performance of our runs are not
reasonably well in both training and test corpus. This paper also addresses the
limitations of the models and scope for further improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task Conditioned BERT for Joint Intent Detection and Slot-filling. (arXiv:2308.06165v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06165">
<div class="article-summary-box-inner">
<span><p>Dialogue systems need to deal with the unpredictability of user intents to
track dialogue state and the heterogeneity of slots to understand user
preferences. In this paper we investigate the hypothesis that solving these
challenges as one unified model will allow the transfer of parameter support
data across the different tasks. The proposed principled model is based on a
Transformer encoder, trained on multiple tasks, and leveraged by a rich input
that conditions the model on the target inferences. Conditioning the
Transformer encoder on multiple target inferences over the same corpus, i.e.,
intent and multiple slot types, allows learning richer language interactions
than a single-task model would be able to. In fact, experimental results
demonstrate that conditioning the model on an increasing number of dialogue
inference tasks leads to improved results: on the MultiWOZ dataset, the joint
intent and slot detection can be improved by 3.2\% by conditioning on intent,
10.8\% by conditioning on slot and 14.4\% by conditioning on both intent and
slots. Moreover, on real conversations with Farfetch costumers, the proposed
conditioned BERT can achieve high joint-goal and intent detection performance
throughout a dialogue.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing Guest Nationality Composition from Hotel Reviews. (arXiv:2308.06175v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06175">
<div class="article-summary-box-inner">
<span><p>Many hotels target guest acquisition efforts to specific markets in order to
best anticipate individual preferences and needs of their guests. Likewise,
such strategic positioning is a prerequisite for efficient marketing budget
allocation. Official statistics report on the number of visitors from different
countries, but no fine-grained information on the guest composition of
individual businesses exists. There is, however, growing interest in such data
from competitors, suppliers, researchers and the general public. We demonstrate
how machine learning can be leveraged to extract references to guest
nationalities from unstructured text reviews in order to dynamically assess and
monitor the dynamics of guest composition of individual businesses. In
particular, we show that a rather simple architecture of pre-trained embeddings
and stacked LSTM layers provides a better performance-runtime tradeoff than
more complex state-of-the-art language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Text Classification on Free Text Comments in Patient-Reported Outcome Measures. (arXiv:2308.06199v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06199">
<div class="article-summary-box-inner">
<span><p>Free text comments (FTC) in patient-reported outcome measures (PROMs) data
are typically analysed using manual methods, such as content analysis, which is
labour-intensive and time-consuming. Machine learning analysis methods are
largely unsupervised, necessitating post-analysis interpretation. Weakly
supervised text classification (WSTC) can be a valuable method of analysis to
classify domain-specific text data in which there is limited labelled data. In
this paper, we apply five WSTC techniques to FTC in PROMs data to identify
health-related quality of life (HRQoL) themes reported by colorectal cancer
patients. The WSTC methods label all the themes mentioned in the FTC. The
results showed moderate performance on the PROMs data, mainly due to the
precision of the models, and variation between themes. Evaluation of the
classification performance illustrated the potential and limitations of keyword
based WSTC to label PROMs FTC when labelled data is limited.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Thinking Like an Expert:Multimodal Hypergraph-of-Thought (HoT) Reasoning to boost Foundation Modals. (arXiv:2308.06207v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06207">
<div class="article-summary-box-inner">
<span><p>Reasoning ability is one of the most crucial capabilities of a foundation
model, signifying its capacity to address complex reasoning tasks.
Chain-of-Thought (CoT) technique is widely regarded as one of the effective
methods for enhancing the reasoning ability of foundation models and has
garnered significant attention. However, the reasoning process of CoT is
linear, step-by-step, similar to personal logical reasoning, suitable for
solving general and slightly complicated problems. On the contrary, the
thinking pattern of an expert owns two prominent characteristics that cannot be
handled appropriately in CoT, i.e., high-order multi-hop reasoning and
multimodal comparative judgement. Therefore, the core motivation of this paper
is transcending CoT to construct a reasoning paradigm that can think like an
expert. The hyperedge of a hypergraph could connect various vertices, making it
naturally suitable for modelling high-order relationships. Inspired by this,
this paper innovatively proposes a multimodal Hypergraph-of-Thought (HoT)
reasoning paradigm, which enables the foundation models to possess the
expert-level ability of high-order multi-hop reasoning and multimodal
comparative judgement. Specifically, a textual hypergraph-of-thought is
constructed utilizing triple as the primary thought to model higher-order
relationships, and a hyperedge-of-thought is generated through multi-hop
walking paths to achieve multi-hop inference. Furthermore, we devise a visual
hypergraph-of-thought to interact with the textual hypergraph-of-thought via
Cross-modal Co-Attention Graph Learning for multimodal comparative
verification. Experimentations on the ScienceQA benchmark demonstrate the
proposed HoT-based T5 outperforms CoT-based GPT3.5 and chatGPT, which is on par
with CoT-based GPT4 with a lower model size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Large Language Model Enhanced Conversational Recommender System. (arXiv:2308.06212v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06212">
<div class="article-summary-box-inner">
<span><p>Conversational recommender systems (CRSs) aim to recommend high-quality items
to users through a dialogue interface. It usually contains multiple sub-tasks,
such as user preference elicitation, recommendation, explanation, and item
information search. To develop effective CRSs, there are some challenges: 1)
how to properly manage sub-tasks; 2) how to effectively solve different
sub-tasks; and 3) how to correctly generate responses that interact with users.
Recently, Large Language Models (LLMs) have exhibited an unprecedented ability
to reason and generate, presenting a new opportunity to develop more powerful
CRSs. In this work, we propose a new LLM-based CRS, referred to as LLMCRS, to
address the above challenges. For sub-task management, we leverage the
reasoning ability of LLM to effectively manage sub-task. For sub-task solving,
we collaborate LLM with expert models of different sub-tasks to achieve the
enhanced performance. For response generation, we utilize the generation
ability of LLM as a language interface to better interact with users.
Specifically, LLMCRS divides the workflow into four stages: sub-task detection,
model matching, sub-task execution, and response generation. LLMCRS also
designs schema-based instruction, demonstration-based instruction, dynamic
sub-task and model matching, and summary-based generation to instruct LLM to
generate desired results in the workflow. Finally, to adapt LLM to
conversational recommendations, we also propose to fine-tune LLM with
reinforcement learning from CRSs performance feedback, referred to as RLPF.
Experimental results on benchmark datasets show that LLMCRS with RLPF
outperforms the existing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KETM:A Knowledge-Enhanced Text Matching method. (arXiv:2308.06235v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06235">
<div class="article-summary-box-inner">
<span><p>Text matching is the task of matching two texts and determining the
relationship between them, which has extensive applications in natural language
processing tasks such as reading comprehension, and Question-Answering systems.
The mainstream approach is to compute text representations or to interact with
the text through attention mechanism, which is effective in text matching
tasks. However, the performance of these models is insufficient for texts that
require commonsense knowledge-based reasoning. To this end, in this paper, We
introduce a new model for text matching called the Knowledge Enhanced Text
Matching model (KETM), to enrich contextual representations with real-world
common-sense knowledge from external knowledge sources to enhance our model
understanding and reasoning. First, we use Wiktionary to retrieve the text word
definitions as our external knowledge. Secondly, we feed text and knowledge to
the text matching module to extract their feature vectors. The text matching
module is used as an interaction module by integrating the encoder layer, the
co-attention layer, and the aggregation layer. Specifically, the interaction
process is iterated several times to obtain in-depth interaction information
and extract the feature vectors of text and knowledge by multi-angle pooling.
Then, we fuse text and knowledge using a gating mechanism to learn the ratio of
text and knowledge fusion by a neural network that prevents noise generated by
knowledge. After that, experimental validation on four datasets are carried
out, and the experimental results show that our proposed model performs well on
all four datasets, and the performance of our method is improved compared to
the base model without adding external knowledge, which validates the
effectiveness of our proposed method. The code is available at
https://github.<a href="/abs/com/1094701">com/1094701</a>018/KETM
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Covid-19 Public Sentiment Analysis for Indian Tweets Classification. (arXiv:2308.06241v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06241">
<div class="article-summary-box-inner">
<span><p>When any extraordinary event takes place in the world wide area, it is the
social media that acts as the fastest carrier of the news along with the
consequences dealt with that event. One can gather much information through
social networks regarding the sentiments, behavior, and opinions of the people.
In this paper, we focus mainly on sentiment analysis of twitter data of India
which comprises of COVID-19 tweets. We show how Twitter data has been extracted
and then run sentimental analysis queries on it. This is helpful to analyze the
information in the tweets where opinions are highly unstructured,
heterogeneous, and are either positive or negative or neutral in some cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Alignment with Instruction Backtranslation. (arXiv:2308.06259v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06259">
<div class="article-summary-box-inner">
<span><p>We present a scalable method to build a high quality instruction following
language model by automatically labelling human-written text with corresponding
instructions. Our approach, named instruction backtranslation, starts with a
language model finetuned on a small amount of seed data, and a given web
corpus. The seed model is used to construct training examples by generating
instruction prompts for web documents (self-augmentation), and then selecting
high quality examples from among these candidates (self-curation). This data is
then used to finetune a stronger model. Finetuning LLaMa on two iterations of
our approach yields a model that outperforms all other LLaMa-based models on
the Alpaca leaderboard not relying on distillation data, demonstrating highly
effective self-alignment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Constraining Linear-chain CRFs to Regular Languages. (arXiv:2106.07306v6 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07306">
<div class="article-summary-box-inner">
<span><p>A major challenge in structured prediction is to represent the
interdependencies within output structures. When outputs are structured as
sequences, linear-chain conditional random fields (CRFs) are a widely used
model class which can learn \textit{local} dependencies in the output. However,
the CRF's Markov assumption makes it impossible for CRFs to represent
distributions with \textit{nonlocal} dependencies, and standard CRFs are unable
to respect nonlocal constraints of the data (such as global arity constraints
on output labels). We present a generalization of CRFs that can enforce a broad
class of constraints, including nonlocal ones, by specifying the space of
possible output structures as a regular language $\mathcal{L}$. The resulting
regular-constrained CRF (RegCCRF) has the same formal properties as a standard
CRF, but assigns zero probability to all label sequences not in $\mathcal{L}$.
Notably, RegCCRFs can incorporate their constraints during training, while
related models only enforce constraints during decoding. We prove that
constrained training is never worse than constrained decoding, and show
empirically that it can be substantially better in practice. Additionally, we
demonstrate a practical benefit on downstream tasks by incorporating a RegCCRF
into a deep neural model for semantic role labeling, exceeding state-of-the-art
results on a standard dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Compact End-to-End Model with Local and Global Context for Spoken Language Identification. (arXiv:2210.15781v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.15781">
<div class="article-summary-box-inner">
<span><p>We introduce TitaNet-LID, a compact end-to-end neural network for Spoken
Language Identification (LID) that is based on the ContextNet architecture.
TitaNet-LID employs 1D depth-wise separable convolutions and
Squeeze-and-Excitation layers to effectively capture local and global context
within an utterance. Despite its small size, TitaNet-LID achieves performance
similar to state-of-the-art models on the VoxLingua107 dataset while being 10
times smaller. Furthermore, it can be easily adapted to new acoustic conditions
and unseen languages through simple fine-tuning, achieving a state-of-the-art
accuracy of 88.2% on the FLEURS benchmark. Our model is scalable and can
achieve a better trade-off between accuracy and speed. TitaNet-LID performs
well even on short utterances less than 5s in length, indicating its robustness
to input length.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">There is more than one kind of robustness: Fooling Whisper with adversarial examples. (arXiv:2210.17316v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.17316">
<div class="article-summary-box-inner">
<span><p>Whisper is a recent Automatic Speech Recognition (ASR) model displaying
impressive robustness to both out-of-distribution inputs and random noise. In
this work, we show that this robustness does not carry over to adversarial
noise. We show that we can degrade Whisper performance dramatically, or even
transcribe a target sentence of our choice, by generating very small input
perturbations with Signal Noise Ratio of 35-45dB. We also show that by fooling
the Whisper language detector we can very easily degrade the performance of
multilingual models. These vulnerabilities of a widely popular open-source
model have practical security implications and emphasize the need for
adversarially robust ASR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Kuaipedia: a Large-scale Multi-modal Short-video Encyclopedia. (arXiv:2211.00732v3 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00732">
<div class="article-summary-box-inner">
<span><p>Online encyclopedias, such as Wikipedia, have been well-developed and
researched in the last two decades. One can find any attributes or other
information of a wiki item on a wiki page edited by a community of volunteers.
However, the traditional text, images and tables can hardly express some
aspects of an wiki item. For example, when we talk about ``Shiba Inu'', one may
care more about ``How to feed it'' or ``How to train it not to protect its
food''. Currently, short-video platforms have become a hallmark in the online
world. Whether you're on TikTok, Instagram, Kuaishou, or YouTube Shorts,
short-video apps have changed how we consume and create content today. Except
for producing short videos for entertainment, we can find more and more authors
sharing insightful knowledge widely across all walks of life. These short
videos, which we call knowledge videos, can easily express any aspects (e.g.
hair or how-to-feed) consumers want to know about an item (e.g. Shiba Inu), and
they can be systematically analyzed and organized like an online encyclopedia.
In this paper, we propose Kuaipedia, a large-scale multi-modal encyclopedia
consisting of items, aspects, and short videos lined to them, which was
extracted from billions of videos of Kuaishou (Kwai), a well-known short-video
platform in China. We first collected items from multiple sources and mined
user-centered aspects from millions of users' queries to build an item-aspect
tree. Then we propose a new task called ``multi-modal item-aspect linking'' as
an expansion of ``entity linking'' to link short videos into item-aspect pairs
and build the whole short-video encyclopedia. Intrinsic evaluations show that
our encyclopedia is of large scale and highly accurate. We also conduct
sufficient extrinsic experiments to show how Kuaipedia can help fundamental
applications such as entity typing and entity linking.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformers are Short Text Classifiers: A Study of Inductive Short Text Classifiers on Benchmarks and Real-world Datasets. (arXiv:2211.16878v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.16878">
<div class="article-summary-box-inner">
<span><p>Short text classification is a crucial and challenging aspect of Natural
Language Processing. For this reason, there are numerous highly specialized
short text classifiers. However, in recent short text research, State of the
Art (SOTA) methods for traditional text classification, particularly the pure
use of Transformers, have been unexploited. In this work, we examine the
performance of a variety of short text classifiers as well as the top
performing traditional text classifier. We further investigate the effects on
two new real-world short text datasets in an effort to address the issue of
becoming overly dependent on benchmark datasets with a limited number of
characteristics. Our experiments unambiguously demonstrate that Transformers
achieve SOTA accuracy on short text classification tasks, raising the question
of whether specialized short text techniques are necessary.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RT-1: Robotics Transformer for Real-World Control at Scale. (arXiv:2212.06817v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.06817">
<div class="article-summary-box-inner">
<span><p>By transferring knowledge from large, diverse, task-agnostic datasets, modern
machine learning models can solve specific downstream tasks either zero-shot or
with small task-specific datasets to a high level of performance. While this
capability has been demonstrated in other fields such as computer vision,
natural language processing or speech recognition, it remains to be shown in
robotics, where the generalization capabilities of the models are particularly
critical due to the difficulty of collecting real-world robotic data. We argue
that one of the keys to the success of such general robotic models lies with
open-ended task-agnostic training, combined with high-capacity architectures
that can absorb all of the diverse, robotic data. In this paper, we present a
model class, dubbed Robotics Transformer, that exhibits promising scalable
model properties. We verify our conclusions in a study of different model
classes and their ability to generalize as a function of the data size, model
size, and data diversity based on a large-scale data collection on real robots
performing real-world tasks. The project's website and videos can be found at
robotics-transformer1.github.io
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Which Features are Learned by CodeBert: An Empirical Study of the BERT-based Source Code Representation Learning. (arXiv:2301.08427v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.08427">
<div class="article-summary-box-inner">
<span><p>The Bidirectional Encoder Representations from Transformers (BERT) were
proposed in the natural language process (NLP) and shows promising results.
Recently researchers applied the BERT to source-code representation learning
and reported some good news on several downstream tasks. However, in this
paper, we illustrated that current methods cannot effectively understand the
logic of source codes. The representation of source code heavily relies on the
programmer-defined variable and function names. We design and implement a set
of experiments to demonstrate our conjecture and provide some insights for
future works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reveal the Unknown: Out-of-Knowledge-Base Mention Discovery with Entity Linking. (arXiv:2302.07189v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07189">
<div class="article-summary-box-inner">
<span><p>Discovering entity mentions that are out of a Knowledge Base (KB) from texts
plays a critical role in KB maintenance, but has not yet been fully explored.
The current methods are mostly limited to the simple threshold-based approach
and feature-based classification, and the datasets for evaluation are
relatively rare. We propose BLINKout, a new BERT-based Entity Linking (EL)
method which can identify mentions that do not have corresponding KB entities
by matching them to a special NIL entity. To better utilize BERT, we propose
new techniques including NIL entity representation and classification, with
synonym enhancement. We also apply KB Pruning and Versioning strategies to
automatically construct out-of-KB datasets from common in-KB EL datasets.
Results on five datasets of clinical notes, biomedical publications, and
Wikipedia articles in various domains show the advantages of BLINKout over
existing methods to identify out-of-KB mentions for the medical ontologies,
UMLS, SNOMED CT, and the general KB, WikiData.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-modal Contrastive Learning for Multimodal Fake News Detection. (arXiv:2302.14057v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.14057">
<div class="article-summary-box-inner">
<span><p>Automatic detection of multimodal fake news has gained a widespread attention
recently. Many existing approaches seek to fuse unimodal features to produce
multimodal news representations. However, the potential of powerful cross-modal
contrastive learning methods for fake news detection has not been well
exploited. Besides, how to aggregate features from different modalities to
boost the performance of the decision-making process is still an open question.
To address that, we propose COOLANT, a cross-modal contrastive learning
framework for multimodal fake news detection, aiming to achieve more accurate
image-text alignment. To further improve the alignment precision, we leverage
an auxiliary task to soften the loss term of negative samples during the
contrast process. A cross-modal fusion module is developed to learn the
cross-modality correlations. An attention mechanism with an attention guidance
module is implemented to help effectively and interpretably aggregate the
aligned unimodal representations and the cross-modality correlations. Finally,
we evaluate the COOLANT and conduct a comparative study on two widely used
datasets, Twitter and Weibo. The experimental results demonstrate that our
COOLANT outperforms previous approaches by a large margin and achieves new
state-of-the-art results on the two datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Verifying the Robustness of Automatic Credibility Assessment. (arXiv:2303.08032v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08032">
<div class="article-summary-box-inner">
<span><p>Text classification methods have been widely investigated as a way to detect
content of low credibility: fake news, social media bots, propaganda, etc.
Quite accurate models (likely based on deep neural networks) help in moderating
public electronic platforms and often cause content creators to face rejection
of their submissions or removal of already published texts. Having the
incentive to evade further detection, content creators try to come up with a
slightly modified version of the text (known as an attack with an adversarial
example) that exploit the weaknesses of classifiers and result in a different
output. Here we systematically test the robustness of popular text classifiers
against available attacking techniques and discover that, indeed, in some cases
insignificant changes in input text can mislead the models. We also introduce
BODEGA: a benchmark for testing both victim models and attack methods on four
misinformation detection tasks in an evaluation framework designed to simulate
real use-cases of content moderation. Finally, we manually analyse a subset
adversarial examples and check what kinds of modifications are used in
successful attacks. The BODEGA code and data is openly shared in hope of
enhancing the comparability and replicability of further research in this area
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Personalised Language Modelling of Screen Characters Using Rich Metadata Annotations. (arXiv:2303.16618v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.16618">
<div class="article-summary-box-inner">
<span><p>Language models that are sensitive to external context can more effectively
capture the speaking patterns of individuals with specific characteristics or
in particular environments. However, obtaining and leveraging such annotations
can be challenging. In this work, we show how to leverage rich character and
film annotations to personalise language models in a scalable manner. Our best
model can reduce perplexity by up to 6.5% compared to a parameter-matched
language model. Our approach performs on par with speaker-specific fine-tuning
when the fine-tuning data (i.e. past dialogue) for individual speakers is
available. On top of that, it also generalises well to a scenario with no such
data, relying on combinations of demographic characteristics expressed via
metadata. Our findings are consistent across two corpora, one of which is also
a contribution of this paper: Cornell-rich contains rich manual annotations for
863 speaking characters from the Cornell Movie Dialog Corpus, including
features such as characteristic quotes and character descriptions, along with
six automatically extracted metadata features for over 95% of the featured
films. Finally, we also present a cost-benefit analysis highlighting which
annotations are most cost-effective in reducing perplexity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ML-SUPERB: Multilingual Speech Universal PERformance Benchmark. (arXiv:2305.10615v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10615">
<div class="article-summary-box-inner">
<span><p>Speech processing Universal PERformance Benchmark (SUPERB) is a leaderboard
to benchmark the performance of Self-Supervised Learning (SSL) models on
various speech processing tasks. However, SUPERB largely considers English
speech in its evaluation. This paper presents multilingual SUPERB (ML-SUPERB),
covering 143 languages (ranging from high-resource to endangered), and
considering both automatic speech recognition and language identification.
Following the concept of SUPERB, ML-SUPERB utilizes frozen SSL features and
employs a simple framework for multilingual tasks by learning a shallow
downstream model. Similar to the SUPERB benchmark, we find speech SSL models
can significantly improve performance compared to FBANK features. Furthermore,
we find that multilingual models do not always perform better than their
monolingual counterparts. We will release ML-SUPERB as a challenge with
organized datasets and reproducible training scripts for future multilingual
representation research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trained Transformers Learn Linear Models In-Context. (arXiv:2306.09927v2 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.09927">
<div class="article-summary-box-inner">
<span><p>Attention-based neural networks such as transformers have demonstrated a
remarkable ability to exhibit in-context learning (ICL): Given a short prompt
sequence of tokens from an unseen task, they can formulate relevant per-token
and next-token predictions without any parameter updates. By embedding a
sequence of labeled training data and unlabeled test data as a prompt, this
allows for transformers to behave like supervised learning algorithms. Indeed,
recent work has shown that when training transformer architectures over random
instances of linear regression problems, these models' predictions mimic those
of ordinary least squares.
</p>
<p>Towards understanding the mechanisms underlying this phenomenon, we
investigate the dynamics of ICL in transformers with a single linear
self-attention layer trained by gradient flow on linear regression tasks. We
show that despite non-convexity, gradient flow with a suitable random
initialization finds a global minimum of the objective function. At this global
minimum, when given a test prompt of labeled examples from a new prediction
task, the transformer achieves prediction error competitive with the best
linear predictor over the test prompt distribution. We additionally
characterize the robustness of the trained transformer to a variety of
distribution shifts and show that although a number of shifts are tolerated,
shifts in the covariate distribution of the prompts are not. Motivated by this,
we consider a generalized ICL setting where the covariate distributions can
vary across prompts. We show that although gradient flow succeeds at finding a
global minimum in this setting, the trained transformer is still brittle under
mild covariate shifts. We complement this finding with experiments on large,
nonlinear transformer architectures which we show are more robust under
covariate shifts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ontology Enrichment from Texts: A Biomedical Dataset for Concept Discovery and Placement. (arXiv:2306.14704v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14704">
<div class="article-summary-box-inner">
<span><p>Mentions of new concepts appear regularly in texts and require automated
approaches to harvest and place them into Knowledge Bases (KB), e.g.,
ontologies and taxonomies. Existing datasets suffer from three issues, (i)
mostly assuming that a new concept is pre-discovered and cannot support
out-of-KB mention discovery; (ii) only using the concept label as the input
along with the KB and thus lacking the contexts of a concept label; and (iii)
mostly focusing on concept placement w.r.t a taxonomy of atomic concepts,
instead of complex concepts, i.e., with logical operators. To address these
issues, we propose a new benchmark, adapting MedMentions dataset (PubMed
abstracts) with SNOMED CT versions in 2014 and 2017 under the Diseases
sub-category and the broader categories of Clinical finding, Procedure, and
Pharmaceutical / biologic product. We provide usage on the evaluation with the
dataset for out-of-KB mention discovery and concept placement, adapting recent
Large Language Model based methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Domain Adaptation of Sentence Embeddings Using Adapters. (arXiv:2307.03104v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03104">
<div class="article-summary-box-inner">
<span><p>Sentence embeddings enable us to capture the semantic similarity of short
texts. Most sentence embedding models are trained for general semantic textual
similarity (STS) tasks. Therefore, to use sentence embeddings in a particular
domain, the model must be adapted to it in order to achieve good results.
Usually, this is done by fine-tuning the entire sentence embedding model for
the domain of interest. While this approach yields state-of-the-art results,
all of the model's weights are updated during fine-tuning, making this method
resource-intensive. Therefore, instead of fine-tuning entire sentence embedding
models for each target domain individually, we propose to train lightweight
adapters. These domain-specific adapters do not require fine-tuning all
underlying sentence embedding model parameters. Instead, we only train a small
number of additional parameters while keeping the weights of the underlying
sentence embedding model fixed. Training domain-specific adapters allows always
using the same base model and only exchanging the domain-specific adapters to
adapt sentence embeddings to a specific domain. We show that using adapters for
parameter-efficient domain adaptation of sentence embeddings yields competitive
performance within 1% of a domain-adapted, entirely fine-tuned sentence
embedding model while only training approximately 3.6% of the parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education. (arXiv:2307.12267v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.12267">
<div class="article-summary-box-inner">
<span><p>The recent large language models (LLMs), e.g., ChatGPT, have been able to
generate human-like and fluent responses when provided with specific
instructions. While admitting the convenience brought by technological
advancement, educators also have concerns that students might leverage LLMs to
complete their writing assignments and pass them off as their original work.
Although many AI content detection studies have been conducted as a result of
such concerns, most of these prior studies modeled AI content detection as a
classification problem, assuming that a text is either entirely human-written
or entirely AI-generated. In this study, we investigated AI content detection
in a rarely explored yet realistic setting where the text to be detected is
collaboratively written by human and generative LLMs (i.e., hybrid text). We
first formalized the detection task as identifying the transition points
between human-written content and AI-generated content from a given hybrid text
(boundary detection). Then we proposed a two-step approach where we (1)
separated AI-generated content from human-written content during the encoder
training process; and (2) calculated the distances between every two adjacent
prototypes and assumed that the boundaries exist between the two adjacent
prototypes that have the furthest distance from each other. Through extensive
experiments, we observed the following main findings: (1) the proposed approach
consistently outperformed the baseline methods across different experiment
settings; (2) the encoder training process can significantly boost the
performance of the proposed approach; (3) when detecting boundaries for
single-boundary hybrid essays, the proposed approach could be enhanced by
adopting a relatively large prototype size, leading to a 22% improvement in the
In-Domain evaluation and an 18% improvement in the Out-of-Domain evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting Perfect Quality Segments in MT Output with Fine-Tuned OpenAI LLM: Is it possible to capture editing distance patterns from historical data?. (arXiv:2308.00158v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.00158">
<div class="article-summary-box-inner">
<span><p>Translation Quality Estimation (TQE) is an important step before deploying
the output translation into usage. TQE is also critical in assessing machine
translation (MT) and human translation (HT) quality without seeing the
reference translations. In this work, we examine if the state-of-the-art large
language models (LLMs) can be fine-tuned for the TQE task and their capability.
We take ChatGPT as one example and approach TQE as a binary classification
task. Using English to Italian, German, French, Japanese, Dutch, Portuguese,
Turkish, and Chinese training corpora, our experimental results show that
fine-tuned ChatGPT via its API can achieve a relatively high score on
predicting translation quality, i.e. if the translation needs to be edited, but
there is definitely much space to improve the accuracy. English-Italiano
bilingual Abstract is available in the paper.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causality Guided Disentanglement for Cross-Platform Hate Speech Detection. (arXiv:2308.02080v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.02080">
<div class="article-summary-box-inner">
<span><p>Social media platforms, despite their value in promoting open discourse, are
often exploited to spread harmful content. Current deep learning and natural
language processing models used for detecting this harmful content overly rely
on domain-specific terms affecting their capabilities to adapt to generalizable
hate speech detection. This is because they tend to focus too narrowly on
particular linguistic signals or the use of certain categories of words.
Another significant challenge arises when platforms lack high-quality annotated
data for training, leading to a need for cross-platform models that can adapt
to different distribution shifts. Our research introduces a cross-platform hate
speech detection model capable of being trained on one platform's data and
generalizing to multiple unseen platforms. To achieve good generalizability
across platforms, one way is to disentangle the input representations into
invariant and platform-dependent features. We also argue that learning causal
relationships, which remain constant across diverse environments, can
significantly aid in understanding invariant representations in hate speech. By
disentangling input into platform-dependent features (useful for predicting
hate targets) and platform-independent features (used to predict the presence
of hate), we learn invariant representations resistant to distribution shifts.
These features are then used to predict hate speech across unseen platforms.
Our extensive experiments across four platforms highlight our model's enhanced
efficacy compared to existing state-of-the-art methods in detecting generalized
hate speech.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Generalist Foundation Model for Radiology. (arXiv:2308.02463v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.02463">
<div class="article-summary-box-inner">
<span><p>In this study, we aim to initiate the development of Radiology Foundation
Model, termed as RadFM.We consider the construction of foundational models from
the perspectives of data, model design, and evaluation thoroughly. Our
contribution can be concluded as follows: (i), we construct a large-scale
Medical Multi-modal Dataset, MedMD, consisting of 16M 2D and 3D medical scans.
To the best of our knowledge, this is the first multi-modal dataset containing
3D medical scans. (ii), We propose an architecture that enables visually
conditioned generative pre-training, allowing for the integration of text input
interleaved with 2D or 3D medical scans to generate response for diverse
radiologic tasks. The model was initially pre-trained on MedMD and subsequently
domain-specific fine-tuned on RadMD, a radiologic cleaned version of MedMD,
containing 3M radiologic visual-language pairs. (iii), we propose a new
evaluation benchmark that comprises five tasks, aiming to comprehensively
assess the capability of foundation models in handling practical clinical
problems. Our experimental results confirm that RadFM significantly outperforms
existing multi-modal foundation models. The codes, data, and model checkpoint
will all be made publicly available to promote further research and development
in the field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D-EX : A Unified Dataset of Definitions and Dictionary Examples. (arXiv:2308.03043v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.03043">
<div class="article-summary-box-inner">
<span><p>Definitions are a fundamental building block in lexicography, linguistics and
computational semantics. In NLP, they have been used for retrofitting word
embeddings or augmenting contextual representations in language models.
However, lexical resources containing definitions exhibit a wide range of
properties, which has implications in the behaviour of models trained and
evaluated on them. In this paper, we introduce 3D- EX , a dataset that aims to
fill this gap by combining well-known English resources into one centralized
knowledge repository in the form of &lt;term, definition, example&gt; triples. 3D- EX
is a unified evaluation framework with carefully pre-computed
train/validation/test splits to prevent memorization. We report experimental
results that suggest that this dataset could be effectively leveraged in
downstream NLP tasks. Code and data are available at
https://github.com/F-Almeman/3D-EX .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLASSLA-Stanza: The Next Step for Linguistic Processing of South Slavic Languages. (arXiv:2308.04255v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.04255">
<div class="article-summary-box-inner">
<span><p>We present CLASSLA-Stanza, a pipeline for automatic linguistic annotation of
the South Slavic languages, which is based on the Stanza natural language
processing pipeline. We describe the main improvements in CLASSLA-Stanza with
respect to Stanza, and give a detailed description of the model training
process for the latest 2.1 release of the pipeline. We also report performance
scores produced by the pipeline for different languages and varieties.
CLASSLA-Stanza exhibits consistently high performance across all the supported
languages and outperforms or expands its parent pipeline Stanza at all the
supported tasks. We also present the pipeline's new functionality enabling
efficient processing of web data and the reasons that led to its
implementation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating the Generation Capabilities of Large Chinese Language Models. (arXiv:2308.04823v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.04823">
<div class="article-summary-box-inner">
<span><p>This paper presents CG-Eval, the first comprehensive evaluation of the
generation capabilities of large Chinese language models across a wide range of
academic disciplines. The models' performance was assessed based on their
ability to generate accurate and relevant responses to different types of
questions in six disciplines, namely, Science and Engineering, Humanities and
Social Sciences, Mathematical Calculations, Medical Practitioner Qualification
Examination, Judicial Examination, and Certified Public Accountant Examination.
This paper also presents Gscore, a composite index derived from the weighted
sum of multiple metrics to measure the quality of model's generation against a
reference. The test data and test results can be found at
<a href="http://cgeval.besteasy.com/.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Machine Learning and Transformer-based Approaches for Deceptive Text Classification: A Comparative Analysis. (arXiv:2308.05476v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.05476">
<div class="article-summary-box-inner">
<span><p>Deceptive text classification is a critical task in natural language
processing that aims to identify deceptive o fraudulent content. This study
presents a comparative analysis of machine learning and transformer-based
approaches for deceptive text classification. We investigate the effectiveness
of traditional machine learning algorithms and state-of-the-art transformer
models, such as BERT, XLNET, DistilBERT, and RoBERTa, in detecting deceptive
text. A labeled dataset consisting of deceptive and non-deceptive texts is used
for training and evaluation purposes. Through extensive experimentation, we
compare the performance metrics, including accuracy, precision, recall, and F1
score, of the different approaches. The results of this study shed light on the
strengths and limitations of machine learning and transformer-based methods for
deceptive text classification, enabling researchers and practitioners to make
informed decisions when dealing with deceptive content.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM As DBA. (arXiv:2308.05481v2 [cs.DB] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.05481">
<div class="article-summary-box-inner">
<span><p>Database administrators (DBAs) play a crucial role in managing, maintaining
and optimizing a database system to ensure data availability, performance, and
reliability. However, it is hard and tedious for DBAs to manage a large number
of database instances (e.g., millions of instances on the cloud databases).
Recently large language models (LLMs) have shown great potential to understand
valuable documents and accordingly generate reasonable answers. Thus, we
propose D-Bot, a LLM-based database administrator that can continuously acquire
database maintenance experience from textual sources, and provide reasonable,
well-founded, in-time diagnosis and optimization advice for target databases.
This paper presents a revolutionary LLM-centric framework for database
maintenance, including (i) database maintenance knowledge detection from
documents and tools, (ii) tree of thought reasoning for root cause analysis,
and (iii) collaborative diagnosis among multiple LLMs. Our preliminary
experimental results that D-Bot can efficiently and effectively diagnose the
root causes and our code is available at
github.com/TsinghuaDatabaseGroup/DB-GPT.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-08-14 23:10:31.861157677 UTC">2023-08-14 23:10:31 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>