<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-09-27T01:30:00Z">09-27</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM. (arXiv:2309.14348v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14348">
<div class="article-summary-box-inner">
<span><p>Recently, Large Language Models (LLMs) have made significant advancements and
are now widely used across various domains. Unfortunately, there has been a
rising concern that LLMs can be misused to generate harmful or malicious
content. Though a line of research has focused on aligning LLMs with human
values and preventing them from producing inappropriate content, such
alignments are usually vulnerable and can be bypassed by alignment-breaking
attacks via adversarially optimized or handcrafted jailbreaking prompts. In
this work, we introduce a Robustly Aligned LLM (RA-LLM) to defend against
potential alignment-breaking attacks. RA-LLM can be directly constructed upon
an existing aligned LLM with a robust alignment checking function, without
requiring any expensive retraining or fine-tuning process of the original LLM.
Furthermore, we also provide a theoretical analysis for RA-LLM to verify its
effectiveness in defending against alignment-breaking attacks. Through
real-world experiments on open-source large language models, we demonstrate
that RA-LLM can successfully defend against both state-of-the-art adversarial
prompts and popular handcrafted jailbreaking prompts by reducing their attack
success rates from nearly 100\% to around 10\% or less.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PopBERT. Detecting populism and its host ideologies in the German Bundestag. (arXiv:2309.14355v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14355">
<div class="article-summary-box-inner">
<span><p>The rise of populism concerns many political scientists and practitioners,
yet the detection of its underlying language remains fragmentary. This paper
aims to provide a reliable, valid, and scalable approach to measure populist
stances. For that purpose, we created an annotated dataset based on
parliamentary speeches of the German Bundestag (2013 to 2021). Following the
ideational definition of populism, we label moralizing references to the
virtuous people or the corrupt elite as core dimensions of populist language.
To identify, in addition, how the thin ideology of populism is thickened, we
annotate how populist statements are attached to left-wing or right-wing host
ideologies. We then train a transformer-based model (PopBERT) as a multilabel
classifier to detect and quantify each dimension. A battery of validation
checks reveals that the model has a strong predictive accuracy, provides high
qualitative face validity, matches party rankings of expert surveys, and
detects out-of-sample text snippets correctly. PopBERT enables dynamic analyses
of how German-speaking politicians and parties use populist language as a
strategic device. Furthermore, the annotator-level data may also be applied in
cross-domain applications or to develop related classifiers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COCO-Counterfactuals: Automatically Constructed Counterfactual Examples for Image-Text Pairs. (arXiv:2309.14356v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14356">
<div class="article-summary-box-inner">
<span><p>Counterfactual examples have proven to be valuable in the field of natural
language processing (NLP) for both evaluating and improving the robustness of
language models to spurious correlations in datasets. Despite their
demonstrated utility for NLP, multimodal counterfactual examples have been
relatively unexplored due to the difficulty of creating paired image-text data
with minimal counterfactual changes. To address this challenge, we introduce a
scalable framework for automatic generation of counterfactual examples using
text-to-image diffusion models. We use our framework to create
COCO-Counterfactuals, a multimodal counterfactual dataset of paired image and
text captions based on the MS-COCO dataset. We validate the quality of
COCO-Counterfactuals through human evaluations and show that existing
multimodal models are challenged by our counterfactual image-text pairs.
Additionally, we demonstrate the usefulness of COCO-Counterfactuals for
improving out-of-domain generalization of multimodal vision-language models via
training data augmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diversifying Question Generation over Knowledge Base via External Natural Questions. (arXiv:2309.14362v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14362">
<div class="article-summary-box-inner">
<span><p>Previous methods on knowledge base question generation (KBQG) primarily focus
on enhancing the quality of a single generated question. Recognizing the
remarkable paraphrasing ability of humans, we contend that diverse texts should
convey the same semantics through varied expressions. The above insights make
diversifying question generation an intriguing task, where the first challenge
is evaluation metrics for diversity. Current metrics inadequately assess the
above diversity since they calculate the ratio of unique n-grams in the
generated question itself, which leans more towards measuring duplication
rather than true diversity. Accordingly, we devise a new diversity evaluation
metric, which measures the diversity among top-k generated questions for each
instance while ensuring their relevance to the ground truth. Clearly, the
second challenge is how to enhance diversifying question generation. To address
this challenge, we introduce a dual model framework interwoven by two selection
strategies to generate diverse questions leveraging external natural questions.
The main idea of our dual framework is to extract more diverse expressions and
integrate them into the generation model to enhance diversifying question
generation. Extensive experiments on widely used benchmarks for KBQG
demonstrate that our proposed approach generates highly diverse questions and
improves the performance of question answering tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An In-depth Survey of Large Language Model-based Artificial Intelligence Agents. (arXiv:2309.14365v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14365">
<div class="article-summary-box-inner">
<span><p>Due to the powerful capabilities demonstrated by large language model (LLM),
there has been a recent surge in efforts to integrate them with AI agents to
enhance their performance. In this paper, we have explored the core differences
and characteristics between LLM-based AI agents and traditional AI agents.
Specifically, we first compare the fundamental characteristics of these two
types of agents, clarifying the significant advantages of LLM-based agents in
handling natural language, knowledge storage, and reasoning capabilities.
Subsequently, we conducted an in-depth analysis of the key components of AI
agents, including planning, memory, and tool use. Particularly, for the crucial
component of memory, this paper introduced an innovative classification scheme,
not only departing from traditional classification methods but also providing a
fresh perspective on the design of an AI agent's memory system. We firmly
believe that in-depth research and understanding of these core components will
lay a solid foundation for the future advancement of AI agent technology. At
the end of the paper, we provide directional suggestions for further research
in this field, with the hope of offering valuable insights to scholars and
researchers in the field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human Transcription Quality Improvement. (arXiv:2309.14372v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14372">
<div class="article-summary-box-inner">
<span><p>High quality transcription data is crucial for training automatic speech
recognition (ASR) systems. However, the existing industry-level data collection
pipelines are expensive to researchers, while the quality of crowdsourced
transcription is low. In this paper, we propose a reliable method to collect
speech transcriptions. We introduce two mechanisms to improve transcription
quality: confidence estimation based reprocessing at labeling stage, and
automatic word error correction at post-labeling stage. We collect and release
LibriCrowd - a large-scale crowdsourced dataset of audio transcriptions on 100
hours of English speech. Experiment shows the Transcription WER is reduced by
over 50%. We further investigate the impact of transcription error on ASR model
performance and found a strong correlation. The transcription quality
improvement provides over 10% relative WER reduction for ASR models. We release
the dataset and code to benefit the research community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Text Classification-Based Approach for Evaluating and Enhancing the Machine Interpretability of Building Codes. (arXiv:2309.14374v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14374">
<div class="article-summary-box-inner">
<span><p>Interpreting regulatory documents or building codes into computer-processable
formats is essential for the intelligent design and construction of buildings
and infrastructures. Although automated rule interpretation (ARI) methods have
been investigated for years, most of them highly depend on the early and manual
filtering of interpretable clauses from a building code. While few of them
considered machine interpretability, which represents the potential to be
transformed into a computer-processable format, from both clause- and
document-level. Therefore, this research aims to propose a novel approach to
automatically evaluate and enhance the machine interpretability of single
clause and building codes. First, a few categories are introduced to classify
each clause in a building code considering the requirements for rule
interpretation, and a dataset is developed for model training. Then, an
efficient text classification model is developed based on a pretrained
domain-specific language model and transfer learning techniques. Finally, a
quantitative evaluation method is proposed to assess the overall
interpretability of building codes. Experiments show that the proposed text
classification algorithm outperforms the existing CNN- or RNN-based methods,
improving the F1-score from 72.16% to 93.60%. It is also illustrated that the
proposed classification method can enhance downstream ARI methods with an
improvement of 4%. Furthermore, analyzing the results of more than 150 building
codes in China showed that their average interpretability is 34.40%, which
implies that it is still hard to fully transform the entire regulatory document
into computer-processable formats. It is also argued that the interpretability
of building codes should be further improved both from the human side and the
machine side.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine-assisted mixed methods: augmenting humanities and social sciences with artificial intelligence. (arXiv:2309.14379v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14379">
<div class="article-summary-box-inner">
<span><p>The increasing capacities of large language models (LLMs) present an
unprecedented opportunity to scale up data analytics in the humanities and
social sciences, augmenting and automating qualitative analytic tasks
previously typically allocated to human labor. This contribution proposes a
systematic mixed methods framework to harness qualitative analytic expertise,
machine scalability, and rigorous quantification, with attention to
transparency and replicability. 16 machine-assisted case studies are showcased
as proof of concept. Tasks include linguistic and discourse analysis, lexical
semantic change detection, interview analysis, historical event cause inference
and text mining, detection of political stance, text and idea reuse, genre
composition in literature and film; social network inference, automated
lexicography, missing metadata augmentation, and multimodal visual cultural
analytics. In contrast to the focus on English in the emerging LLM
applicability literature, many examples here deal with scenarios involving
smaller languages and historical texts prone to digitization distortions. In
all but the most difficult tasks requiring expert knowledge, generative LLMs
can demonstrably serve as viable research instruments. LLM (and human)
annotations may contain errors and variation, but the agreement rate can and
should be accounted for in subsequent statistical modeling; a bootstrapping
approach is discussed. The replications among the case studies illustrate how
tasks previously requiring potentially months of team effort and complex
computational pipelines, can now be accomplished by an LLM-assisted scholar in
a fraction of the time. Importantly, this approach is not intended to replace,
but to augment researcher knowledge and skills. With these opportunities in
sight, qualitative expertise and the ability to pose insightful questions have
arguably never been more critical.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey of Social Bias in Vision-Language Models. (arXiv:2309.14381v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14381">
<div class="article-summary-box-inner">
<span><p>In recent years, the rapid advancement of machine learning (ML) models,
particularly transformer-based pre-trained models, has revolutionized Natural
Language Processing (NLP) and Computer Vision (CV) fields. However, researchers
have discovered that these models can inadvertently capture and reinforce
social biases present in their training datasets, leading to potential social
harms, such as uneven resource allocation and unfair representation of specific
social groups. Addressing these biases and ensuring fairness in artificial
intelligence (AI) systems has become a critical concern in the ML community.
</p>
<p>The recent introduction of pre-trained vision-and-language (VL) models in the
emerging multimodal field demands attention to the potential social biases
present in these models as well. Although VL models are susceptible to social
bias, there is a limited understanding compared to the extensive discussions on
bias in NLP and CV. This survey aims to provide researchers with a high-level
insight into the similarities and differences of social bias studies in
pre-trained models across NLP, CV, and VL. By examining these perspectives, the
survey aims to offer valuable guidelines on how to approach and mitigate social
bias in both unimodal and multimodal settings. The findings and recommendations
presented here can benefit the ML community, fostering the development of
fairer and non-biased AI models in various applications and research endeavors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Agree To Disagree. (arXiv:2309.14382v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14382">
<div class="article-summary-box-inner">
<span><p>How frequently do individuals thoroughly review terms and conditions before
proceeding to register for a service, install software, or access a website?
The majority of internet users do not engage in this practice. This trend is
not surprising, given that terms and conditions typically consist of lengthy
documents replete with intricate legal terminology and convoluted sentences. In
this paper, we introduce a Machine Learning-powered approach designed to
automatically parse and summarize critical information in a user-friendly
manner. This technology focuses on distilling the pertinent details that users
should contemplate before committing to an agreement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An AI Chatbot for Explaining Deep Reinforcement Learning Decisions of Service-oriented Systems. (arXiv:2309.14391v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14391">
<div class="article-summary-box-inner">
<span><p>Deep Reinforcement Learning (Deep RL) is increasingly used to cope with the
open-world assumption in service-oriented systems. Deep RL was successfully
applied to problems such as dynamic service composition, job scheduling, and
offloading, as well as service adaptation. While Deep RL offers many benefits,
understanding the decision-making of Deep RL is challenging because its learned
decision-making policy essentially appears as a black box. Yet, understanding
the decision-making of Deep RL is key to help service developers perform
debugging, support service providers to comply with relevant legal frameworks,
and facilitate service users to build trust. We introduce Chat4XAI to
facilitate the understanding of the decision-making of Deep RL by providing
natural-language explanations. Compared with visual explanations, the reported
benefits of natural-language explanations include better understandability for
non-technical users, increased user acceptance and trust, as well as more
efficient explanations. Chat4XAI leverages modern AI chatbot technology and
dedicated prompt engineering. Compared to earlier work on natural-language
explanations using classical software-based dialogue systems, using an AI
chatbot eliminates the need for eliciting and defining potential questions and
answers up-front. We prototypically realize Chat4XAI using OpenAI's ChatGPT API
and evaluate the fidelity and stability of its explanations using an adaptive
service exemplar.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language Models. (arXiv:2309.14393v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14393">
<div class="article-summary-box-inner">
<span><p>The carbon footprint associated with large language models (LLMs) is a
significant concern, encompassing emissions from their training, inference,
experimentation, and storage processes, including operational and embodied
carbon emissions. An essential aspect is accurately estimating the carbon
impact of emerging LLMs even before their training, which heavily relies on GPU
usage. Existing studies have reported the carbon footprint of LLM training, but
only one tool, mlco2, can predict the carbon footprint of new neural networks
prior to physical training. However, mlco2 has several serious limitations. It
cannot extend its estimation to dense or mixture-of-experts (MoE) LLMs,
disregards critical architectural parameters, focuses solely on GPUs, and
cannot model embodied carbon footprints. Addressing these gaps, we introduce
\textit{LLMCarbon}, an end-to-end carbon footprint projection model designed
for both dense and MoE LLMs. Compared to mlco2, LLMCarbon significantly
enhances the accuracy of carbon footprint estimations for various LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multiple Noises in Diffusion Model for Semi-Supervised Multi-Domain Translation. (arXiv:2309.14394v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14394">
<div class="article-summary-box-inner">
<span><p>Domain-to-domain translation involves generating a target domain sample given
a condition in the source domain. Most existing methods focus on fixed input
and output domains, i.e. they only work for specific configurations (i.e. for
two domains, either $D_1\rightarrow{}D_2$ or $D_2\rightarrow{}D_1$). This paper
proposes Multi-Domain Diffusion (MDD), a conditional diffusion framework for
multi-domain translation in a semi-supervised context. Unlike previous methods,
MDD does not require defining input and output domains, allowing translation
between any partition of domains within a set (such as $(D_1,
D_2)\rightarrow{}D_3$, $D_2\rightarrow{}(D_1, D_3)$, $D_3\rightarrow{}D_1$,
etc. for 3 domains), without the need to train separate models for each domain
configuration. The key idea behind MDD is to leverage the noise formulation of
diffusion models by incorporating one noise level per domain, which allows
missing domains to be modeled with noise in a natural way. This transforms the
training task from a simple reconstruction task to a domain translation task,
where the model relies on less noisy domains to reconstruct more noisy domains.
We present results on a multi-domain (with more than two domains) synthetic
image translation dataset with challenging semantic domain inversion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Seeing and hearing what has not been said; A multimodal client behavior classifier in Motivational Interviewing with interpretable fusion. (arXiv:2309.14398v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14398">
<div class="article-summary-box-inner">
<span><p>Motivational Interviewing (MI) is an approach to therapy that emphasizes
collaboration and encourages behavioral change. To evaluate the quality of an
MI conversation, client utterances can be classified using the MISC code as
either change talk, sustain talk, or follow/neutral talk. The proportion of
change talk in a MI conversation is positively correlated with therapy
outcomes, making accurate classification of client utterances essential. In
this paper, we present a classifier that accurately distinguishes between the
three MISC classes (change talk, sustain talk, and follow/neutral talk)
leveraging multimodal features such as text, prosody, facial expressivity, and
body expressivity. To train our model, we perform annotations on the publicly
available AnnoMI dataset to collect multimodal information, including text,
audio, facial expressivity, and body expressivity. Furthermore, we identify the
most important modalities in the decision-making process, providing valuable
insights into the interplay of different modalities during a MI conversation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Physics of Language Models: Part 3.2, Knowledge Manipulation. (arXiv:2309.14402v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14402">
<div class="article-summary-box-inner">
<span><p>Language models can store vast amounts of factual knowledge, but their
ability to use this knowledge for logical reasoning remains questionable. This
paper explores a language model's ability to manipulate its stored knowledge
during inference. We focus on four manipulation types: retrieval (e.g., "What
is person A's attribute X"), classification (e.g., "Is A's attribute X even or
odd?"), comparison (e.g., "Is A greater than B in attribute X?") and inverse
search (e.g., "Which person's attribute X equals T?")
</p>
<p>We observe that pre-trained language models like GPT2/3/4 excel in knowledge
retrieval but struggle with simple classification or comparison tasks unless
Chain of Thoughts (CoTs) are employed during both training and inference. They
also perform poorly in inverse knowledge search, irrespective of the prompts.
Our primary contribution is a synthetic dataset for a controlled experiment
that confirms these inherent weaknesses: a language model cannot efficiently
manipulate knowledge from pre-training data, even when such knowledge is
perfectly stored and fully extractable in the models, and despite adequate
instruct fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Online Active Learning For Sound Event Detection. (arXiv:2309.14460v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14460">
<div class="article-summary-box-inner">
<span><p>Data collection and annotation is a laborious, time-consuming prerequisite
for supervised machine learning tasks. Online Active Learning (OAL) is a
paradigm that addresses this issue by simultaneously minimizing the amount of
annotation required to train a classifier and adapting to changes in the data
over the duration of the data collection process. Prior work has indicated that
fluctuating class distributions and data drift are still common problems for
OAL. This work presents new loss functions that address these challenges when
OAL is applied to Sound Event Detection (SED). Experimental results from the
SONYC dataset and two Voice-Type Discrimination (VTD) corpora indicate that OAL
can reduce the time and effort required to train SED classifiers by a factor of
5 for SONYC, and that the new methods presented here successfully resolve
issues present in existing OAL methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explainable and Accurate Natural Language Understanding for Voice Assistants and Beyond. (arXiv:2309.14485v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14485">
<div class="article-summary-box-inner">
<span><p>Joint intent detection and slot filling, which is also termed as joint NLU
(Natural Language Understanding) is invaluable for smart voice assistants.
Recent advancements in this area have been heavily focusing on improving
accuracy using various techniques. Explainability is undoubtedly an important
aspect for deep learning-based models including joint NLU models. Without
explainability, their decisions are opaque to the outside world and hence, have
tendency to lack user trust. Therefore to bridge this gap, we transform the
full joint NLU model to be `inherently' explainable at granular levels without
compromising on accuracy. Further, as we enable the full joint NLU model
explainable, we show that our extension can be successfully used in other
general classification tasks. We demonstrate this using sentiment analysis and
named entity recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Automated Assessment Meets Automated Content Generation: Examining Text Quality in the Era of GPTs. (arXiv:2309.14488v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14488">
<div class="article-summary-box-inner">
<span><p>The use of machine learning (ML) models to assess and score textual data has
become increasingly pervasive in an array of contexts including natural
language processing, information retrieval, search and recommendation, and
credibility assessment of online content. A significant disruption at the
intersection of ML and text are text-generating large-language models such as
generative pre-trained transformers (GPTs). We empirically assess the
differences in how ML-based scoring models trained on human content assess the
quality of content generated by humans versus GPTs. To do so, we propose an
analysis framework that encompasses essay scoring ML-models, human and
ML-generated essays, and a statistical model that parsimoniously considers the
impact of type of respondent, prompt genre, and the ML model used for
assessment model. A rich testbed is utilized that encompasses 18,460
human-generated and GPT-based essays. Results of our benchmark analysis reveal
that transformer pretrained language models (PLMs) more accurately score human
essay quality as compared to CNN/RNN and feature-based ML methods.
Interestingly, we find that the transformer PLMs tend to score GPT-generated
text 10-15\% higher on average, relative to human-authored documents.
Conversely, traditional deep learning and feature-based ML models score human
text considerably higher. Further analysis reveals that although the
transformer PLMs are exclusively fine-tuned on human text, they more
prominently attend to certain tokens appearing only in GPT-generated text,
possibly due to familiarity/overlap in pre-training. Our framework and results
have implications for text classification settings where automated scoring of
text is likely to be disrupted by generative AI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classifying token frequencies using angular Minkowski $p$-distance. (arXiv:2309.14495v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14495">
<div class="article-summary-box-inner">
<span><p>Angular Minkowski $p$-distance is a dissimilarity measure that is obtained by
replacing Euclidean distance in the definition of cosine dissimilarity with
other Minkowski $p$-distances. Cosine dissimilarity is frequently used with
datasets containing token frequencies, and angular Minkowski $p$-distance may
potentially be an even better choice for certain tasks. In a case study based
on the 20-newsgroups dataset, we evaluate clasification performance for
classical weighted nearest neighbours, as well as fuzzy rough nearest
neighbours. In addition, we analyse the relationship between the hyperparameter
$p$, the dimensionality $m$ of the dataset, the number of neighbours $k$, the
choice of weights and the choice of classifier. We conclude that it is possible
to obtain substantially higher classification performance with angular
Minkowski $p$-distance with suitable values for $p$ than with classical cosine
dissimilarity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models. (arXiv:2309.14509v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14509">
<div class="article-summary-box-inner">
<span><p>Computation in a typical Transformer-based large language model (LLM) can be
characterized by batch size, hidden dimension, number of layers, and sequence
length. Until now, system works for accelerating LLM training have focused on
the first three dimensions: data parallelism for batch size, tensor parallelism
for hidden size and pipeline parallelism for model depth or layers. These
widely studied forms of parallelism are not targeted or optimized for long
sequence Transformer models. Given practical application needs for long
sequence LLM, renewed attentions are being drawn to sequence parallelism.
However, existing works in sequence parallelism are constrained by
memory-communication inefficiency, limiting their scalability to long sequence
large models. In this work, we introduce DeepSpeed-Ulysses, a novel, portable
and effective methodology for enabling highly efficient and scalable LLM
training with extremely long sequence length. DeepSpeed-Ulysses at its core
partitions input data along the sequence dimension and employs an efficient
all-to-all collective communication for attention computation. Theoretical
communication analysis shows that whereas other methods incur communication
overhead as sequence length increases, DeepSpeed-Ulysses maintains constant
communication volume when sequence length and compute devices are increased
proportionally. Furthermore, experimental evaluations show that
DeepSpeed-Ulysses trains 2.5X faster with 4X longer sequence length than the
existing method SOTA baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Watch Your Language: Large Language Models and Content Moderation. (arXiv:2309.14517v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14517">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have exploded in popularity due to their ability
to perform a wide array of natural language tasks. Text-based content
moderation is one LLM use case that has received recent enthusiasm, however,
there is little research investigating how LLMs perform in content moderation
settings. In this work, we evaluate a suite of modern, commercial LLMs (GPT-3,
GPT-3.5, GPT-4) on two common content moderation tasks: rule-based community
moderation and toxic content detection. For rule-based community moderation, we
construct 95 LLM moderation-engines prompted with rules from 95 Reddit
subcommunities and find that LLMs can be effective at rule-based moderation for
many communities, achieving a median accuracy of 64% and a median precision of
83%. For toxicity detection, we find that LLMs significantly outperform
existing commercially available toxicity classifiers. However, we also find
that recent increases in model size add only marginal benefit to toxicity
detection, suggesting a potential performance plateau for LLMs on toxicity
detection tasks. We conclude by outlining avenues for future work in studying
LLMs and content moderation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT Performance on Standardized Testing Exam -- A Proposed Strategy for Learners. (arXiv:2309.14519v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14519">
<div class="article-summary-box-inner">
<span><p>This study explores the problem solving capabilities of ChatGPT and its
prospective applications in standardized test preparation, focusing on the GRE
quantitative exam. Prior research has shown great potential for the utilization
of ChatGPT for academic purposes in revolutionizing the approach to studying
across various disciplines. We investigate how ChatGPT performs across various
question types in the GRE quantitative domain, and how modifying question
prompts impacts its accuracy. More specifically this study addressed two
research questions: 1. How does ChatGPT perform in answering GRE-based
quantitative questions across various content areas? 2. How does the accuracy
of ChatGPT vary with modifying the question prompts? The dataset consisting of
100 randomly selected GRE quantitative questions was collected from the ETS
official guide to GRE test preparation. We used quantitative evaluation to
answer our first research question, and t-test to examine the statistical
association between prompt modification and ChatGPT's accuracy. Results show a
statistical improvement in the ChatGPT's accuracy after applying instruction
priming and contextual prompts to the original questions. ChatGPT showed 84%
accuracy with the modified prompts compared to 69% with the original data. The
study discusses the areas where ChatGPT struggled with certain questions and
how modifications can be helpful for preparing for standardized tests like GRE
and provides future directions for prompt modifications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Aligning Large Multimodal Models with Factually Augmented RLHF. (arXiv:2309.14525v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14525">
<div class="article-summary-box-inner">
<span><p>Large Multimodal Models (LMM) are built across modalities and the
misalignment between two modalities can result in "hallucination", generating
textual outputs that are not grounded by the multimodal information in context.
To address the multimodal misalignment issue, we adapt the Reinforcement
Learning from Human Feedback (RLHF) from the text domain to the task of
vision-language alignment, where human annotators are asked to compare two
responses and pinpoint the more hallucinated one, and the vision-language model
is trained to maximize the simulated human rewards. We propose a new alignment
algorithm called Factually Augmented RLHF that augments the reward model with
additional factual information such as image captions and ground-truth
multi-choice options, which alleviates the reward hacking phenomenon in RLHF
and further improves the performance. We also enhance the GPT-4-generated
training data (for vision instruction tuning) with previously available
human-written image-text pairs to improve the general capabilities of our
model. To evaluate the proposed approach in real-world scenarios, we develop a
new evaluation benchmark MMHAL-BENCH with a special focus on penalizing
hallucinations. As the first LMM trained with RLHF, our approach achieves
remarkable improvement on the LLaVA-Bench dataset with the 94% performance
level of the text-only GPT-4 (while previous best methods can only achieve the
87% level), and an improvement by 60% on MMHAL-BENCH over other baselines. We
opensource our code, model, data at https://llava-rlhf.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Art or Artifice? Large Language Models and the False Promise of Creativity. (arXiv:2309.14556v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14556">
<div class="article-summary-box-inner">
<span><p>Researchers have argued that large language models (LLMs) exhibit
high-quality writing capabilities from blogs to stories. However, evaluating
objectively the creativity of a piece of writing is challenging. Inspired by
the Torrance Test of Creative Thinking (TTCT), which measures creativity as a
process, we use the Consensual Assessment Technique [3] and propose the
Torrance Test of Creative Writing (TTCW) to evaluate creativity as a product.
TTCW consists of 14 binary tests organized into the original dimensions of
Fluency, Flexibility, Originality, and Elaboration. We recruit 10 creative
writers and implement a human assessment of 48 stories written either by
professional authors or LLMs using TTCW. Our analysis shows that LLM-generated
stories pass 3-10X less TTCW tests than stories written by professionals. In
addition, we explore the use of LLMs as assessors to automate the TTCW
evaluation, revealing that none of the LLMs positively correlate with the
expert assessments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Introducing DictaLM -- A Large Generative Language Model for Modern Hebrew. (arXiv:2309.14568v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14568">
<div class="article-summary-box-inner">
<span><p>We present DictaLM, a large-scale language model tailored for Modern Hebrew.
Boasting 7B parameters, this model is predominantly trained on Hebrew-centric
data. As a commitment to promoting research and development in the Hebrew
language, we release both the foundation model and the instruct-tuned model
under a Creative Commons license. Concurrently, we introduce DictaLM-Rab,
another foundation model geared towards Rabbinic/Historical Hebrew. These
foundation models serve as ideal starting points for fine-tuning various
Hebrew-specific tasks, such as instruction, Q&amp;A, sentiment analysis, and more.
This release represents a preliminary step, offering an initial Hebrew LLM
model for the Hebrew NLP community to experiment with.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Post-training Quantization with FP8 Formats. (arXiv:2309.14592v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14592">
<div class="article-summary-box-inner">
<span><p>Recent advances in deep learning methods such as LLMs and Diffusion models
have created a need for improved quantization methods that can meet the
computational demands of these modern architectures while maintaining accuracy.
Towards this goal, we study the advantages of FP8 data formats for
post-training quantization across 75 unique network architectures covering a
wide range of tasks, including machine translation, language modeling, text
generation, image classification, generation, and segmentation. We examine
three different FP8 representations (E5M2, E4M3, and E3M4) to study the effects
of varying degrees of trade-off between dynamic range and precision on model
accuracy. Based on our extensive study, we developed a quantization workflow
that generalizes across different network architectures. Our empirical results
show that FP8 formats outperform INT8 in multiple aspects, including workload
coverage (92.64% vs. 65.87%), model accuracy and suitability for a broader
range of operations. Furthermore, our findings suggest that E4M3 is better
suited for NLP models, whereas E3M4 performs marginally better than E4M3 on
computer vision tasks. The code is publicly available on Intel Neural
Compressor: https://github.com/intel/neural-compressor.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Simple Text to Video Model via Transformer. (arXiv:2309.14683v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14683">
<div class="article-summary-box-inner">
<span><p>We present a general and simple text to video model based on Transformer.
Since both text and video are sequential data, we encode both texts and images
into the same hidden space, which are further fed into Transformer to capture
the temporal consistency and then decoder to generate either text or images.
Considering the image signal may become weak in the long sequence, we introduce
the U-Net to reconstruct image from its noised version. Specifically, we
increase the noise level to the original image in the long sequence, then use
the $down$ module from U-Net to encode noised images, which are further input
to transformer to predict next clear images. We also add a constraint to
promote motion between any generated image pair in the video. We use GPT2 and
test our approach on UCF101 dataset and show it can generate promising videos.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PLMM: Personal Large Models on Mobile Devices. (arXiv:2309.14726v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14726">
<div class="article-summary-box-inner">
<span><p>Inspired by Federated Learning, in this paper, we propose personal large
models that are distilled from traditional large language models but more
adaptive to local users' personal information such as education background and
hobbies. We classify the large language models into three levels: the personal
level, expert level and traditional level. The personal level models are
adaptive to users' personal information. They encrypt the users' input and
protect their privacy. The expert level models focus on merging specific
knowledge such as finance, IT and art. The traditional models focus on the
universal knowledge discovery and upgrading the expert models. In such
classifications, the personal models directly interact with the user. For the
whole system, the personal models have users' (encrypted) personal information.
Moreover, such models must be small enough to be performed on personal
computers or mobile devices. Finally, they also have to response in real-time
for better user experience and produce high quality results. The proposed
personal large models can be applied in a wide range of applications such as
language and vision tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparative Analysis of Artificial Intelligence for Indian Legal Question Answering (AILQA) Using Different Retrieval and QA Models. (arXiv:2309.14735v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14735">
<div class="article-summary-box-inner">
<span><p>Legal question-answering (QA) systems have the potential to revolutionize the
way legal professionals interact with case law documents. This paper conducts a
comparative analysis of existing artificial intelligence models for their
utility in answering legal questions within the Indian legal system,
specifically focusing on Indian Legal Question Answering (AILQA) and our study
investigates the efficacy of different retrieval and QA algorithms currently
available. Utilizing the OpenAI GPT model as a benchmark, along with query
prompts, our investigation shows that existing AILQA systems can automatically
interpret natural language queries from users and generate highly accurate
responses. This research is particularly focused on applications within the
Indian criminal justice domain, which has its own set of challenges due to its
complexity and resource constraints. In order to rigorously assess the
performance of these models, empirical evaluations are complemented by feedback
from practicing legal professionals, thereby offering a multifaceted view on
the capabilities and limitations of AI in the context of Indian legal
question-answering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Program Repair with Minimal Edits Using CodeT5. (arXiv:2309.14760v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14760">
<div class="article-summary-box-inner">
<span><p>Programmers often struggle to identify and fix bugs in their programs. In
recent years, many language models (LMs) have been proposed to fix erroneous
programs and support error recovery. However, the LMs tend to generate
solutions that differ from the original input programs. This leads to potential
comprehension difficulties for users. In this paper, we propose an approach to
suggest a correct program with minimal repair edits using CodeT5. We fine-tune
a pre-trained CodeT5 on code pairs of wrong and correct programs and evaluate
its performance with several baseline models. The experimental results show
that the fine-tuned CodeT5 achieves a pass@100 of 91.95% and an average edit
distance of the most similar correct program of 6.84, which indicates that at
least one correct program can be suggested by generating 100 candidate
programs. We demonstrate the effectiveness of LMs in suggesting program repair
with minimal edits for solving introductory programming problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConPET: Continual Parameter-Efficient Tuning for Large Language Models. (arXiv:2309.14763v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14763">
<div class="article-summary-box-inner">
<span><p>Continual learning necessitates the continual adaptation of models to newly
emerging tasks while minimizing the catastrophic forgetting of old ones. This
is extremely challenging for large language models (LLMs) with vanilla
full-parameter tuning due to high computation costs, memory consumption, and
forgetting issue. Inspired by the success of parameter-efficient tuning (PET),
we propose Continual Parameter-Efficient Tuning (ConPET), a generalizable
paradigm for continual task adaptation of LLMs with task-number-independent
training complexity. ConPET includes two versions with different application
scenarios. First, Static ConPET can adapt former continual learning methods
originally designed for relatively smaller models to LLMs through PET and a
dynamic replay strategy, which largely reduces the tuning costs and alleviates
the over-fitting and forgetting issue. Furthermore, to maintain scalability,
Dynamic ConPET adopts separate PET modules for different tasks and a PET module
selector for dynamic optimal selection. In our extensive experiments, the
adaptation of Static ConPET helps multiple former methods reduce the scale of
tunable parameters by over 3,000 times and surpass the PET-only baseline by at
least 5 points on five smaller benchmarks, while Dynamic ConPET gains its
advantage on the largest dataset. The codes and datasets are available at
https://github.com/Raincleared-Song/ConPET.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KERMIT: Knowledge Graph Completion of Enhanced Relation Modeling with Inverse Transformation. (arXiv:2309.14770v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14770">
<div class="article-summary-box-inner">
<span><p>Knowledge graph completion is a task that revolves around filling in missing
triples based on the information available in a knowledge graph. Among the
current studies, text-based methods complete the task by utilizing textual
descriptions of triples. However, this modeling approach may encounter
limitations, particularly when the description fails to accurately and
adequately express the intended meaning. To overcome these challenges, we
propose the augmentation of data through two additional mechanisms. Firstly, we
employ ChatGPT as an external knowledge base to generate coherent descriptions
to bridge the semantic gap between the queries and answers. Secondly, we
leverage inverse relations to create a symmetric graph, thereby creating extra
labeling and providing supplementary information for link prediction. This
approach offers additional insights into the relationships between entities.
Through these efforts, we have observed significant improvements in knowledge
graph completion, as these mechanisms enhance the richness and diversity of the
available data, leading to more accurate results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting In-Context Learning with Factual Knowledge. (arXiv:2309.14771v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14771">
<div class="article-summary-box-inner">
<span><p>In-Context Learning (ICL) over Large language models (LLMs) aims at solving
previously unseen tasks by conditioning on a few training examples, eliminating
the need for parameter updates and achieving competitive performance. In this
paper, we demonstrate that factual knowledge is imperative for the performance
of ICL in three core facets, i.e., the inherent knowledge learned in LLMs, the
factual knowledge derived from the selected in-context examples, and the
knowledge biases in LLMs for output generation. To unleash the power of LLMs in
few-shot learning scenarios, we introduce a novel Knowledgeable In-Context
Tuning (KICT) framework to further improve the performance of ICL: 1) injecting
factual knowledge to LLMs during continual self-supervised pre-training, 2)
judiciously selecting the examples with high knowledge relevance, and 3)
calibrating the prediction results based on prior knowledge. We evaluate the
proposed approaches on auto-regressive LLMs (e.g., GPT-style models) over
multiple text classification and question answering tasks. Experimental results
demonstrate that KICT substantially outperforms strong baselines, and improves
by more than 13% and 7% of accuracy on text classification and question
answering tasks, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BLIP-Adapter: Parameter-Efficient Transfer Learning for Mobile Screenshot Captioning. (arXiv:2309.14774v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14774">
<div class="article-summary-box-inner">
<span><p>This study aims to explore efficient tuning methods for the screenshot
captioning task. Recently, image captioning has seen significant advancements,
but research in captioning tasks for mobile screens remains relatively scarce.
Current datasets and use cases describing user behaviors within product
screenshots are notably limited. Consequently, we sought to fine-tune
pre-existing models for the screenshot captioning task. However, fine-tuning
large pre-trained models can be resource-intensive, requiring considerable
time, computational power, and storage due to the vast number of parameters in
image captioning models. To tackle this challenge, this study proposes a
combination of adapter methods, which necessitates tuning only the additional
modules on the model. These methods are originally designed for vision or
language tasks, and our intention is to apply them to address similar
challenges in screenshot captioning. By freezing the parameters of the image
caption models and training only the weights associated with the methods,
performance comparable to fine-tuning the entire model can be achieved, while
significantly reducing the number of parameters. This study represents the
first comprehensive investigation into the effectiveness of combining adapters
within the context of the screenshot captioning task. Through our experiments
and analyses, this study aims to provide valuable insights into the application
of adapters in vision-language models and contribute to the development of
efficient tuning techniques for the screenshot captioning task. Our study is
available at https://github.com/RainYuGG/BLIP-Adapter
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Small Language Models with Prompt-Learning Paradigm for Efficient Domain-Specific Text Classification. (arXiv:2309.14779v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14779">
<div class="article-summary-box-inner">
<span><p>Domain-specific text classification faces the challenge of scarce labeled
data due to the high cost of manual labeling. Prompt-learning, known for its
efficiency in few-shot scenarios, is proposed as an alternative to traditional
fine-tuning methods. And besides, although large language models (LLMs) have
gained prominence, small language models (SLMs, with under 1B parameters) offer
significant customizability, adaptability, and cost-effectiveness for
domain-specific tasks, given industry constraints. In this study, we
investigate the potential of SLMs combined with prompt-learning paradigm for
domain-specific text classification, specifically within customer-agent
interactions in retail. Our evaluations show that, in few-shot settings when
prompt-based model fine-tuning is possible, T5-base, a typical SLM with 220M
parameters, achieve approximately 75% accuracy with limited labeled data (up to
15% of full data), which shows great potentials of SLMs with prompt-learning.
Based on this, We further validate the effectiveness of active few-shot
sampling and the ensemble strategy in the prompt-learning pipeline that
contribute to a remarkable performance gain. Besides, in zero-shot settings
with a fixed model, we underscore a pivotal observation that, although the
GPT-3.5-turbo equipped with around 154B parameters garners an accuracy of
55.16%, the power of well designed prompts becomes evident when the
FLAN-T5-large, a model with a mere 0.5% of GPT-3.5-turbo's parameters, achieves
an accuracy exceeding 31% with the optimized prompt, a leap from its sub-18%
performance with an unoptimized one. Our findings underscore the promise of
prompt-learning in classification tasks with SLMs, emphasizing the benefits of
active few-shot sampling, and ensemble strategies in few-shot settings, and the
importance of prompt engineering in zero-shot settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-tuning and aligning question answering models for complex information extraction tasks. (arXiv:2309.14805v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14805">
<div class="article-summary-box-inner">
<span><p>The emergence of Large Language Models (LLMs) has boosted performance and
possibilities in various NLP tasks. While the usage of generative AI models
like ChatGPT opens up new opportunities for several business use cases, their
current tendency to hallucinate fake content strongly limits their
applicability to document analysis, such as information retrieval from
documents. In contrast, extractive language models like question answering (QA)
or passage retrieval models guarantee query results to be found within the
boundaries of an according context document, which makes them candidates for
more reliable information extraction in productive environments of companies.
In this work we propose an approach that uses and integrates extractive QA
models for improved feature extraction of German business documents such as
insurance reports or medical leaflets into a document analysis solution. We
further show that fine-tuning existing German QA models boosts performance for
tailored extraction tasks of complex linguistic features like damage cause
explanations or descriptions of medication appearance, even with using only a
small set of annotated data. Finally, we discuss the relevance of scoring
metrics for evaluating information extraction tasks and deduce a combined
metric from Levenshtein distance, F1-Score, Exact Match and ROUGE-L to mimic
the assessment criteria from human experts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Segmentation-Free Streaming Machine Translation. (arXiv:2309.14823v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14823">
<div class="article-summary-box-inner">
<span><p>Streaming Machine Translation (MT) is the task of translating an unbounded
input text stream in real-time. The traditional cascade approach, which
combines an Automatic Speech Recognition (ASR) and an MT system, relies on an
intermediate segmentation step which splits the transcription stream into
sentence-like units. However, the incorporation of a hard segmentation
constrains the MT system and is a source of errors. This paper proposes a
Segmentation-Free framework that enables the model to translate an unsegmented
source stream by delaying the segmentation decision until the translation has
been generated. Extensive experiments show how the proposed Segmentation-Free
framework has better quality-latency trade-off than competing approaches that
use an independent segmentation model. Software, data and models will be
released upon paper acceptance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robustness of the Random Language Model. (arXiv:2309.14913v1 [cond-mat.dis-nn])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14913">
<div class="article-summary-box-inner">
<span><p>The Random Language Model (De Giuli 2019) is an ensemble of stochastic
context-free grammars, quantifying the syntax of human and computer languages.
The model suggests a simple picture of first language learning as a type of
annealing in the vast space of potential languages. In its simplest
formulation, it implies a single continuous transition to grammatical syntax,
at which the symmetry among potential words and categories is spontaneously
broken. Here this picture is scrutinized by considering its robustness against
explicit symmetry breaking, an inevitable component of learning in the real
world. It is shown that the scenario is robust to such symmetry breaking.
Comparison with human data on the clustering coefficient of syntax networks
suggests that the observed transition is equivalent to that normally
experienced by children at age 24 months.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interactively Learning Social Media Representations Improves News Source Factuality Detection. (arXiv:2309.14966v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14966">
<div class="article-summary-box-inner">
<span><p>The rise of social media has enabled the widespread propagation of fake news,
text that is published with an intent to spread misinformation and sway
beliefs. Rapidly detecting fake news, especially as new events arise, is
important to prevent misinformation.
</p>
<p>While prior works have tackled this problem using supervised learning
systems, automatedly modeling the complexities of the social media landscape
that enables the spread of fake news is challenging. On the contrary, having
humans fact check all news is not scalable. Thus, in this paper, we propose to
approach this problem interactively, where humans can interact to help an
automated system learn a better social media representation quality. On real
world events, our experiments show performance improvements in detecting
factuality of news sources, even after few human interactions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Sexual Content at the Sentence Level in First Millennium Latin Texts. (arXiv:2309.14974v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14974">
<div class="article-summary-box-inner">
<span><p>In this study, we propose to evaluate the use of deep learning methods for
semantic classification at the sentence level to accelerate the process of
corpus building in the field of humanities and linguistics, a traditional and
time-consuming task. We introduce a novel corpus comprising around 2500
sentences spanning from 300 BCE to 900 CE including sexual semantics (medical,
erotica, etc.). We evaluate various sentence classification approaches and
different input embedding layers, and show that all consistently outperform
simple token-based searches. We explore the integration of idiolectal and
sociolectal metadata embeddings (centuries, author, type of writing), but find
that it leads to overfitting. Our results demonstrate the effectiveness of this
approach, achieving high precision and true positive rates (TPR) of
respectively 70.60% and 86.33% using HAN. We evaluate the impact of the dataset
size on the model performances (420 instead of 2013), and show that, while our
models perform worse, they still offer a high enough precision and TPR, even
without MLM, respectively 69% and 51%. Given the result, we provide an analysis
of the attention mechanism as a supporting added value for humanists in order
to produce more data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automating question generation from educational text. (arXiv:2309.15004v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15004">
<div class="article-summary-box-inner">
<span><p>The use of question-based activities (QBAs) is wide-spread in education,
traditionally forming an integral part of the learning and assessment process.
In this paper, we design and evaluate an automated question generation tool for
formative and summative assessment in schools. We present an expert survey of
one hundred and four teachers, demonstrating the need for automated generation
of QBAs, as a tool that can significantly reduce the workload of teachers and
facilitate personalized learning experiences. Leveraging the recent
advancements in generative AI, we then present a modular framework employing
transformer based language models for automatic generation of multiple-choice
questions (MCQs) from textual content. The presented solution, with distinct
modules for question generation, correct answer prediction, and distractor
formulation, enables us to evaluate different language models and generation
techniques. Finally, we perform an extensive quantitative and qualitative
evaluation, demonstrating trade-offs in the use of different techniques and
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Updated Corpora and Benchmarks for Long-Form Speech Recognition. (arXiv:2309.15013v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15013">
<div class="article-summary-box-inner">
<span><p>The vast majority of ASR research uses corpora in which both the training and
test data have been pre-segmented into utterances. In most real-word ASR
use-cases, however, test audio is not segmented, leading to a mismatch between
inference-time conditions and models trained on segmented utterances. In this
paper, we re-release three standard ASR corpora - TED-LIUM 3, Gigapeech, and
VoxPopuli-en - with updated transcription and alignments to enable their use
for long-form ASR research. We use these reconstituted corpora to study the
train-test mismatch problem for transducers and attention-based
encoder-decoders (AEDs), confirming that AEDs are more susceptible to this
issue. Finally, we benchmark a simple long-form training for these models,
showing its efficacy for model robustness under this domain shift.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Question-Answering Approach to Evaluate Legal Summaries. (arXiv:2309.15016v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15016">
<div class="article-summary-box-inner">
<span><p>Traditional evaluation metrics like ROUGE compare lexical overlap between the
reference and generated summaries without taking argumentative structure into
account, which is important for legal summaries. In this paper, we propose a
novel legal summarization evaluation framework that utilizes GPT-4 to generate
a set of question-answer pairs that cover main points and information in the
reference summary. GPT-4 is then used to generate answers based on the
generated summary for the questions from the reference summary. Finally, GPT-4
grades the answers from the reference summary and the generated summary. We
examined the correlation between GPT-4 grading with human grading. The results
suggest that this question-answering approach with GPT-4 can be a useful tool
for gauging the quality of the summary.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Model Alignment: A Survey. (arXiv:2309.15025v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15025">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed remarkable progress made in large language models
(LLMs). Such advancements, while garnering significant attention, have
concurrently elicited various concerns. The potential of these models is
undeniably vast; however, they may yield texts that are imprecise, misleading,
or even detrimental. Consequently, it becomes paramount to employ alignment
techniques to ensure these models to exhibit behaviors consistent with human
values.
</p>
<p>This survey endeavors to furnish an extensive exploration of alignment
methodologies designed for LLMs, in conjunction with the extant capability
research in this domain. Adopting the lens of AI alignment, we categorize the
prevailing methods and emergent proposals for the alignment of LLMs into outer
and inner alignment. We also probe into salient issues including the models'
interpretability, and potential vulnerabilities to adversarial attacks. To
assess LLM alignment, we present a wide variety of benchmarks and evaluation
methodologies. After discussing the state of alignment research for LLMs, we
finally cast a vision toward the future, contemplating the promising avenues of
research that lie ahead.
</p>
<p>Our aspiration for this survey extends beyond merely spurring research
interests in this realm. We also envision bridging the gap between the AI
alignment research community and the researchers engrossed in the capability
exploration of LLMs for both capable and safe LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Making PPO even better: Value-Guided Monte-Carlo Tree Search decoding. (arXiv:2309.15028v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15028">
<div class="article-summary-box-inner">
<span><p>Inference-time search algorithms such as Monte-Carlo Tree Search (MCTS) may
seem unnecessary when generating natural language text based on
state-of-the-art reinforcement learning such as Proximal Policy Optimization
(PPO). In this paper, we demonstrate that it is possible to get extra mileage
out of PPO by integrating MCTS on top. The key idea is not to throw out the
value network, a byproduct of PPO training for evaluating partial output
sequences, when decoding text out of the policy network. More concretely, we
present a novel value-guided decoding algorithm called PPO-MCTS, which can
integrate the value network from PPO to work closely with the policy network
during inference-time generation. Compared to prior approaches based on MCTS
for controlled text generation, the key strength of our approach is to reduce
the fundamental mismatch of the scoring mechanisms of the partial outputs
between training and test. Evaluation on four text generation tasks demonstrate
that PPO-MCTS greatly improves the preferability of generated text compared to
the standard practice of using only the PPO policy. Our results demonstrate the
promise of search algorithms even on top of the aligned language models from
PPO, and the under-explored benefit of the value network.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Natural Language based Context Modeling and Reasoning with LLMs: A Tutorial. (arXiv:2309.15074v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15074">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have become phenomenally surging, since
2018--two decades after introducing context-awareness into computing systems.
Through taking into account the situations of ubiquitous devices, users and the
societies, context-aware computing has enabled a wide spectrum of innovative
applications, such as assisted living, location-based social network services
and so on. To recognize contexts and make decisions for actions accordingly,
various artificial intelligence technologies, such as Ontology and OWL, have
been adopted as representations for context modeling and reasoning. Recently,
with the rise of LLMs and their improved natural language understanding and
reasoning capabilities, it has become feasible to model contexts using natural
language and perform context reasoning by interacting with LLMs such as ChatGPT
and GPT-4. In this tutorial, we demonstrate the use of texts, prompts, and
autonomous agents (AutoAgents) that enable LLMs to perform context modeling and
reasoning without requiring fine-tuning of the model. We organize and introduce
works in the related field, and name this computing paradigm as the LLM-driven
Context-aware Computing (LCaC). In the LCaC paradigm, users' requests, sensors
reading data, and the command to actuators are supposed to be represented as
texts. Given the text of users' request and sensor data, the AutoAgent models
the context by prompting and sends to the LLM for context reasoning. LLM
generates a plan of actions and responds to the AutoAgent, which later follows
the action plan to foster context-awareness. To prove the concepts, we use two
showcases--(1) operating a mobile z-arm in an apartment for assisted living,
and (2) planning a trip and scheduling the itinerary in a context-aware and
personalized manner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large Language Models. (arXiv:2309.15088v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15088">
<div class="article-summary-box-inner">
<span><p>Researchers have successfully applied large language models (LLMs) such as
ChatGPT to reranking in an information retrieval context, but to date, such
work has mostly been built on proprietary models hidden behind opaque API
endpoints. This approach yields experimental results that are not reproducible
and non-deterministic, threatening the veracity of outcomes that build on such
shaky foundations. To address this significant shortcoming, we present
RankVicuna, the first fully open-source LLM capable of performing high-quality
listwise reranking in a zero-shot setting. Experimental results on the TREC
2019 and 2020 Deep Learning Tracks show that we can achieve effectiveness
comparable to zero-shot reranking with GPT-3.5 with a much smaller 7B parameter
model, although our effectiveness remains slightly behind reranking with GPT-4.
We hope our work provides the foundation for future research on reranking with
modern LLMs. All the code necessary to reproduce our results is available at
https://github.com/castorini/rank_llm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided Planning. (arXiv:2309.15091v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15091">
<div class="article-summary-box-inner">
<span><p>Although recent text-to-video (T2V) generation methods have seen significant
advancements, most of these works focus on producing short video clips of a
single event with a single background (i.e., single-scene videos). Meanwhile,
recent large language models (LLMs) have demonstrated their capability in
generating layouts and programs to control downstream visual modules such as
image generation models. This raises an important question: can we leverage the
knowledge embedded in these LLMs for temporally consistent long video
generation? In this paper, we propose VideoDirectorGPT, a novel framework for
consistent multi-scene video generation that uses the knowledge of LLMs for
video content planning and grounded video generation. Specifically, given a
single text prompt, we first ask our video planner LLM (GPT-4) to expand it
into a 'video plan', which involves generating the scene descriptions, the
entities with their respective layouts, the background for each scene, and
consistency groupings of the entities and backgrounds. Next, guided by this
output from the video planner, our video generator, Layout2Vid, has explicit
control over spatial layouts and can maintain temporal consistency of
entities/backgrounds across scenes, while only trained with image-level
annotations. Our experiments demonstrate that VideoDirectorGPT framework
substantially improves layout and movement control in both single- and
multi-scene video generation and can generate multi-scene videos with visual
consistency across scenes, while achieving competitive performance with SOTAs
in open-domain single-scene T2V generation. We also demonstrate that our
framework can dynamically control the strength for layout guidance and can also
generate videos with user-provided images. We hope our framework can inspire
future work on better integrating the planning ability of LLMs into consistent
long video generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models. (arXiv:2309.15098v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15098">
<div class="article-summary-box-inner">
<span><p>We investigate the internal behavior of Transformer-based Large Language
Models (LLMs) when they generate factually incorrect text. We propose modeling
factual queries as Constraint Satisfaction Problems and use this framework to
investigate how the model interacts internally with factual constraints.
Specifically, we discover a strong positive relation between the model's
attention to constraint tokens and the factual accuracy of its responses. In
our curated suite of 11 datasets with over 40,000 prompts, we study the task of
predicting factual errors with the Llama-2 family across all scales (7B, 13B,
70B). We propose SAT Probe, a method probing self-attention patterns, that can
predict constraint satisfaction and factual errors, and allows early error
identification. The approach and findings demonstrate how using the mechanistic
understanding of factuality in LLMs can enhance reliability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Permutation invariant matrix statistics and computational language tasks. (arXiv:2202.06829v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.06829">
<div class="article-summary-box-inner">
<span><p>The Linguistic Matrix Theory programme introduced by Kartsaklis, Ramgoolam
and Sadrzadeh is an approach to the statistics of matrices that are generated
in type-driven distributional semantics, based on permutation invariant
polynomial functions which are regarded as the key observables encoding the
significant statistics. In this paper we generalize the previous results on the
approximate Gaussianity of matrix distributions arising from compositional
distributional semantics. We also introduce a geometry of observable vectors
for words, defined by exploiting the graph-theoretic basis for the permutation
invariants and the statistical characteristics of the ensemble of matrices
associated with the words. We describe successful applications of this unified
framework to a number of tasks in computational linguistics, associated with
the distinctions between synonyms, antonyms, hypernyms and hyponyms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disentangling Prosody Representations with Unsupervised Speech Reconstruction. (arXiv:2212.06972v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.06972">
<div class="article-summary-box-inner">
<span><p>Human speech can be characterized by different components, including semantic
content, speaker identity and prosodic information. Significant progress has
been made in disentangling representations for semantic content and speaker
identity in Automatic Speech Recognition (ASR) and speaker verification tasks
respectively. However, it is still an open challenging research question to
extract prosodic information because of the intrinsic association of different
attributes, such as timbre and rhythm, and because of the need for supervised
training schemes to achieve robust large-scale and speaker-independent ASR. The
aim of this paper is to address the disentanglement of emotional prosody from
speech based on unsupervised reconstruction. Specifically, we identify, design,
implement and integrate three crucial components in our proposed speech
reconstruction model Prosody2Vec: (1) a unit encoder that transforms speech
signals into discrete units for semantic content, (2) a pretrained speaker
verification model to generate speaker identity embeddings, and (3) a trainable
prosody encoder to learn prosody representations. We first pretrain the
Prosody2Vec representations on unlabelled emotional speech corpora, then
fine-tune the model on specific datasets to perform Speech Emotion Recognition
(SER) and Emotional Voice Conversion (EVC) tasks. Both objective (weighted and
unweighted accuracies) and subjective (mean opinion score) evaluations on the
EVC task suggest that Prosody2Vec effectively captures general prosodic
features that can be smoothly transferred to other emotional speech. In
addition, our SER experiments on the IEMOCAP dataset reveal that the prosody
features learned by Prosody2Vec are complementary and beneficial for the
performance of widely used speech pretraining models and surpass the
state-of-the-art methods when combining Prosody2Vec with HuBERT
representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v6 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.06569">
<div class="article-summary-box-inner">
<span><p>Recommendation foundation model utilizes large language models (LLM) for
recommendation by converting recommendation tasks into natural language tasks.
It enables generative recommendation which directly generates the item(s) to
recommend rather than calculating a ranking score for each and every candidate
item as in traditional recommendation models, simplifying the recommendation
pipeline from multi-stage filtering to single-stage filtering. To avoid
generating excessively long text and hallucinated recommendations when deciding
which item(s) to recommend, creating LLM-compatible item IDs to uniquely
identify each item is essential for recommendation foundation models. In this
study, we systematically examine the item ID creation and indexing problem for
recommendation foundation models, using P5 as an example of the backbone LLM.
To emphasize the importance of item indexing, we first discuss the issues of
several trivial item indexing methods, such as random indexing, title indexing,
and independent indexing. We then propose four simple yet effective solutions,
including sequential indexing, collaborative indexing, semantic (content-based)
indexing, and hybrid indexing. Our study highlights the significant influence
of item indexing methods on the performance of LLM-based recommendation, and
our results on real-world datasets validate the effectiveness of our proposed
solutions. The research also demonstrates how recent advances on language
modeling and traditional IR principles such as indexing can help each other for
better learning and inference. Source code and data are available at
https://github.com/Wenyueh/LLM-RecSys-ID.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly-Supervised Visual-Textual Grounding with Semantic Prior Refinement. (arXiv:2305.10913v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10913">
<div class="article-summary-box-inner">
<span><p>Using only image-sentence pairs, weakly-supervised visual-textual grounding
aims to learn region-phrase correspondences of the respective entity mentions.
Compared to the supervised approach, learning is more difficult since bounding
boxes and textual phrases correspondences are unavailable. In light of this, we
propose the Semantic Prior Refinement Model (SPRM), whose predictions are
obtained by combining the output of two main modules. The first untrained
module aims to return a rough alignment between textual phrases and bounding
boxes. The second trained module is composed of two sub-components that refine
the rough alignment to improve the accuracy of the final phrase-bounding box
alignments. The model is trained to maximize the multimodal similarity between
an image and a sentence, while minimizing the multimodal similarity of the same
sentence and a new unrelated image, carefully selected to help the most during
training. Our approach shows state-of-the-art results on two popular datasets,
Flickr30k Entities and ReferIt, shining especially on ReferIt with a 9.6%
absolute improvement. Moreover, thanks to the untrained component, it reaches
competitive performances just using a small fraction of training examples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Med-UniC: Unifying Cross-Lingual Medical Vision-Language Pre-Training by Diminishing Bias. (arXiv:2305.19894v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19894">
<div class="article-summary-box-inner">
<span><p>The scarcity of data presents a critical obstacle to the efficacy of medical
visionlanguage pre-training (VLP). A potential solution lies in the combination
of datasets from various language communities. Nevertheless, the main challenge
stems from the complexity of integrating diverse syntax and semantics,
language-specific medical terminology, and culture-specific implicit knowledge.
Therefore, one crucial aspect to consider is the presence of community bias
caused by different languages. This paper presents a novel framework named
Unifying Cross-Lingual Medical Vision-Language Pre-Training (Med-UniC),
designed to integrate multimodal medical data from the two most prevalent
languages, English and Spanish. Specifically, we propose Cross-lingual Text
Alignment Regularization (CTR) to explicitly unify cross-lingual semantic
representations of medical reports originating from diverse language
communities. CTR is optimized through latent language disentanglement,
rendering our optimization objective to not depend on negative samples, thereby
significantly mitigating the bias from determining positive-negative sample
pairs within analogous medical reports. Furthermore, it ensures that the
cross-lingual representation is not biased toward any specific language
community. Med-UniC reaches superior performance across 5 medical image tasks
and 10 datasets encompassing over 30 diseases, offering a versatile framework
for unifying multi-modal medical data within diverse linguistic communities.
The experimental outcomes highlight the presence of community bias in
cross-lingual VLP. Reducing this bias enhances the performance not only in
vision-language tasks but also in uni-modal visual tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MO-VLN: A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language Navigation. (arXiv:2306.10322v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.10322">
<div class="article-summary-box-inner">
<span><p>Given a natural language, a general robot has to comprehend the instruction
and find the target object or location based on visual observations even in
unexplored environments. Most agents rely on massive diverse training data to
achieve better generalization, which requires expensive labor. These agents
often focus on common objects and fewer tasks, thus are not intelligent enough
to handle different types of instructions. To facilitate research in open-set
vision-and-language navigation, we propose a benchmark named MO-VLN, aiming at
testing the effectiveness and generalization of the agent in the multi-task
setting. First, we develop a 3D simulator rendered by realistic scenarios using
Unreal Engine 5, containing more realistic lights and details. The simulator
contains three scenes, i.e., cafe, restaurant, and nursing house, of high value
in the industry. Besides, our simulator involves multiple uncommon objects,
such as takeaway cup and medical adhesive tape, which are more complicated
compared with existing environments. Inspired by the recent success of large
language models (e.g., ChatGPT, Vicuna), we construct diverse high-quality data
of instruction type without human annotation. Our benchmark MO-VLN provides
four tasks: 1) goal-conditioned navigation given a specific object category
(e.g., "fork"); 2) goal-conditioned navigation given simple instructions (e.g.,
"Search for and move towards a tennis ball"); 3) step-by-step instruction
following; 4) finding abstract object based on high-level instruction (e.g., "I
am thirsty").
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations. (arXiv:2307.06576v5 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.06576">
<div class="article-summary-box-inner">
<span><p>Precisely recommending candidate news articles to users has always been a
core challenge for personalized news recommendation systems. Most recent works
primarily focus on using advanced natural language processing techniques to
extract semantic information from rich textual data, employing content-based
methods derived from local historical news. However, this approach lacks a
global perspective, failing to account for users' hidden motivations and
behaviors beyond semantic information. To address this challenge, we propose a
novel model called GLORY (Global-LOcal news Recommendation sYstem), which
combines global representations learned from other users with local
representations to enhance personalized recommendation systems. We accomplish
this by constructing a Global-aware Historical News Encoder, which includes a
global news graph and employs gated graph neural networks to enrich news
representations, thereby fusing historical news representations by a historical
news aggregator. Similarly, we extend this approach to a Global Candidate News
Encoder, utilizing a global entity graph and a candidate news aggregator to
enhance candidate news representation. Evaluation results on two public news
datasets demonstrate that our method outperforms existing approaches.
Furthermore, our model offers more diverse recommendations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating the Catastrophic Forgetting in Multimodal Large Language Models. (arXiv:2309.10313v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.10313">
<div class="article-summary-box-inner">
<span><p>Following the success of GPT4, there has been a surge in interest in
multimodal large language model (MLLM) research. This line of research focuses
on developing general-purpose LLMs through fine-tuning pre-trained LLMs and
vision models. However, catastrophic forgetting, a notorious phenomenon where
the fine-tuned model fails to retain similar performance compared to the
pre-trained model, still remains an inherent problem in multimodal LLMs (MLLM).
In this paper, we introduce EMT: Evaluating MulTimodality for evaluating the
catastrophic forgetting in MLLMs, by treating each MLLM as an image classifier.
We first apply EMT to evaluate several open-source fine-tuned MLLMs and we
discover that almost all evaluated MLLMs fail to retain the same performance
levels as their vision encoders on standard image classification tasks.
Moreover, we continue fine-tuning LLaVA, an MLLM and utilize EMT to assess
performance throughout the fine-tuning. Interestingly, our results suggest that
early-stage fine-tuning on an image dataset improves performance across other
image datasets, by enhancing the alignment of text and visual features.
However, as fine-tuning proceeds, the MLLMs begin to hallucinate, resulting in
a significant loss of generalizability, even when the image encoder remains
frozen. Our results suggest that MLLMs have yet to demonstrate performance on
par with their vision models on standard image classification tasks and the
current MLLM fine-tuning procedure still has room for improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MBR and QE Finetuning: Training-time Distillation of the Best and Most Expensive Decoding Methods. (arXiv:2309.10966v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.10966">
<div class="article-summary-box-inner">
<span><p>Recent research in decoding methods for Natural Language Generation (NLG)
tasks has shown that MAP decoding is not optimal, because model probabilities
do not always align with human preferences. Stronger decoding methods,
including Quality Estimation (QE) reranking and Minimum Bayes' Risk (MBR)
decoding, have since been proposed to mitigate the model-perplexity-vs-quality
mismatch. While these decoding methods achieve state-of-the-art performance,
they are prohibitively expensive to compute. In this work, we propose MBR
finetuning and QE finetuning which distill the quality gains from these
decoding methods at training time, while using an efficient decoding algorithm
at inference time. Using the canonical NLG task of Neural Machine Translation
(NMT), we show that even with self-training, these finetuning methods
significantly outperform the base model. Moreover, when using an external LLM
as a teacher model, these finetuning methods outperform finetuning on
human-generated references. These findings suggest new ways to leverage
monolingual data to achieve improvements in model quality that are on par with,
or even exceed, improvements from human-curated data, while maintaining maximum
efficiency during decoding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Deep Learning for Scientific Imaging Interpretation. (arXiv:2309.12460v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.12460">
<div class="article-summary-box-inner">
<span><p>In the domain of scientific imaging, interpreting visual data often demands
an intricate combination of human expertise and deep comprehension of the
subject materials. This study presents a novel methodology to linguistically
emulate and subsequently evaluate human-like interactions with Scanning
Electron Microscopy (SEM) images, specifically of glass materials. Leveraging a
multimodal deep learning framework, our approach distills insights from both
textual and visual data harvested from peer-reviewed articles, further
augmented by the capabilities of GPT-4 for refined data synthesis and
evaluation. Despite inherent challenges--such as nuanced interpretations and
the limited availability of specialized datasets--our model (GlassLLaVA) excels
in crafting accurate interpretations, identifying key features, and detecting
defects in previously unseen SEM images. Moreover, we introduce versatile
evaluation metrics, suitable for an array of scientific imaging applications,
which allows for benchmarking against research-grounded answers. Benefiting
from the robustness of contemporary Large Language Models, our model adeptly
aligns with insights from research papers. This advancement not only
underscores considerable progress in bridging the gap between human and machine
interpretation in scientific imaging, but also hints at expansive avenues for
future research and broader application.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific Large Models. (arXiv:2309.13079v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13079">
<div class="article-summary-box-inner">
<span><p>With the advancement of deep learning technologies, general-purpose large
models such as GPT-4 have demonstrated exceptional capabilities across various
domains. Nevertheless, there remains a demand for high-quality, domain-specific
outputs in areas like healthcare, law, and finance. This paper first evaluates
the existing large models for specialized domains and discusses their
limitations. To cater to the specific needs of certain domains, we introduce
the ``MiChao-HuaFen 1.0'' pre-trained corpus dataset, tailored for the news and
governmental sectors. The dataset, sourced from publicly available internet
data from 2022, underwent multiple rounds of cleansing and processing to ensure
high quality and reliable origins, with provisions for consistent and stable
updates. This dataset not only supports the pre-training of large models for
Chinese vertical domains but also aids in propelling deep learning research and
applications in related fields.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Connecting Speech Encoder and Large Language Model for ASR. (arXiv:2309.13963v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13963">
<div class="article-summary-box-inner">
<span><p>The impressive capability and versatility of large language models (LLMs)
have aroused increasing attention in automatic speech recognition (ASR), with
several pioneering studies attempting to build integrated ASR models by
connecting a speech encoder with an LLM. This paper presents a comparative
study of three commonly used structures as connectors, including fully
connected layers, multi-head cross-attention, and Q-Former. Speech encoders
from the Whisper model series as well as LLMs from the Vicuna model series with
different model sizes were studied. Experiments were performed on the commonly
used LibriSpeech, Common Voice, and GigaSpeech datasets, where the LLMs with
Q-Formers demonstrated consistent and considerable word error rate (WER)
reductions over LLMs with other connector structures. Q-Former-based LLMs can
generalise well to out-of-domain datasets, where 12% relative WER reductions
over the Whisper baseline ASR model were achieved on the Eval2000 test set
without using any in-domain training data from Switchboard. Moreover, a novel
segment-level Q-Former is proposed to enable LLMs to recognise speech segments
with a duration exceeding the limitation of the encoders, which results in 17%
relative WER reductions over other connector structures on 90-second-long
speech data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InvestLM: A Large Language Model for Investment using Financial Domain Instruction Tuning. (arXiv:2309.13064v1 [q-fin.GN] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13064">
<div class="article-summary-box-inner">
<span><p>We present a new financial domain large language model, InvestLM, tuned on
LLaMA-65B (Touvron et al., 2023), using a carefully curated instruction dataset
related to financial investment. Inspired by less-is-more-for-alignment (Zhou
et al., 2023), we manually curate a small yet diverse instruction dataset,
covering a wide range of financial related topics, from Chartered Financial
Analyst (CFA) exam questions to SEC filings to Stackexchange quantitative
finance discussions. InvestLM shows strong capabilities in understanding
financial text and provides helpful responses to investment related questions.
Financial experts, including hedge fund managers and research analysts, rate
InvestLM's response as comparable to those of state-of-the-art commercial
models (GPT-3.5, GPT-4 and Claude-2). Zero-shot evaluation on a set of
financial NLP benchmarks demonstrates strong generalizability. From a research
perspective, this work suggests that a high-quality domain specific LLM can be
tuned using a small set of carefully curated instructions on a well-trained
foundation model, which is consistent with the Superficial Alignment Hypothesis
(Zhou et al., 2023). From a practical perspective, this work develops a
state-of-the-art financial domain LLM with superior capability in understanding
financial texts and providing helpful investment advice, potentially enhancing
the work efficiency of financial professionals. We release the model parameters
to the research community.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-09-27 23:11:02.478679027 UTC">2023-09-27 23:11:02 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>