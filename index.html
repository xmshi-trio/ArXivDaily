<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-02-16T01:30:00Z">02-16</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Artificial Intelligence in Psychology Research. (arXiv:2302.07267v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07267">
<div class="article-summary-box-inner">
<span><p>Large Language Models have vastly grown in capabilities. One potential
application of such AI systems is to support data collection in the social
sciences, where perfect experimental control is currently unfeasible and the
collection of large, representative datasets is generally expensive. In this
paper, we re-replicate 14 studies from the Many Labs 2 replication project
(Klein et al., 2018) with OpenAI's text-davinci-003 model, colloquially known
as GPT3.5. For the 10 studies that we could analyse, we collected a total of
10,136 responses, each of which was obtained by running GPT3.5 with the
corresponding study's survey inputted as text. We find that our GPT3.5-based
sample replicates 30% of the original results as well as 30% of the Many Labs 2
results, although there is heterogeneity in both these numbers (as we replicate
some original findings that Many Labs 2 did not and vice versa). We also find
that unlike the corresponding human subjects, GPT3.5 answered some survey
questions with extreme homogeneity$\unicode{x2013}$with zero variation in
different runs' responses$\unicode{x2013}$raising concerns that a hypothetical
AI-led future may in certain ways be subject to a diminished diversity of
thought. Overall, while our results suggest that Large Language Model
psychology studies are feasible, their findings should not be assumed to
straightforwardly generalise to the human case. Nevertheless, AI-based data
collection may eventually become a viable and economically relevant method in
the empirical social sciences, making the understanding of its capabilities and
applications central.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI Chat Assistants can Improve Conversations about Divisive Topics. (arXiv:2302.07268v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07268">
<div class="article-summary-box-inner">
<span><p>A rapidly increasing amount of human conversation occurs online. But
divisiveness and conflict can fester in text-based interactions on social media
platforms, in messaging apps, and on other digital forums. Such toxicity
increases polarization and, importantly, corrodes the capacity of diverse
societies to develop efficient solutions to complex social problems that impact
everyone. Scholars and civil society groups promote interventions that can make
interpersonal conversations less divisive or more productive in offline
settings, but scaling these efforts to the amount of discourse that occurs
online is extremely challenging. We present results of a large-scale experiment
that demonstrates how online conversations about divisive topics can be
improved with artificial intelligence tools. Specifically, we employ a large
language model to make real-time, evidence-based recommendations intended to
improve participants' perception of feeling understood in conversations. We
find that these interventions improve the reported quality of the conversation,
reduce political divisiveness, and improve the tone, without systematically
changing the content of the conversation or moving people's policy attitudes.
These findings have important implications for future research on social media,
political deliberation, and the growing community of scholars interested in the
place of artificial intelligence within computational social science.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TRESTLE: Toolkit for Reproducible Execution of Speech, Text and Language Experiments. (arXiv:2302.07322v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07322">
<div class="article-summary-box-inner">
<span><p>The evidence is growing that machine and deep learning methods can learn the
subtle differences between the language produced by people with various forms
of cognitive impairment such as dementia and cognitively healthy individuals.
Valuable public data repositories such as TalkBank have made it possible for
researchers in the computational community to join forces and learn from each
other to make significant advances in this area. However, due to variability in
approaches and data selection strategies used by various researchers, results
obtained by different groups have been difficult to compare directly. In this
paper, we present TRESTLE (\textbf{T}oolkit for \textbf{R}eproducible
\textbf{E}xecution of \textbf{S}peech \textbf{T}ext and \textbf{L}anguage
\textbf{E}xperiments), an open source platform that focuses on two datasets
from the TalkBank repository with dementia detection as an illustrative domain.
Successfully deployed in the hackallenge (Hackathon/Challenge) of the
International Workshop on Health Intelligence at AAAI 2022, TRESTLE provides a
precise digital blueprint of the data pre-processing and selection strategies
that can be reused via TRESTLE by other researchers seeking comparable results
with their peers and current state-of-the-art (SOTA) approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">READIN: A Chinese Multi-Task Benchmark with Realistic and Diverse Input Noises. (arXiv:2302.07324v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07324">
<div class="article-summary-box-inner">
<span><p>For many real-world applications, the user-generated inputs usually contain
various noises due to speech recognition errors caused by linguistic
variations1 or typographical errors (typos). Thus, it is crucial to test model
performance on data with realistic input noises to ensure robustness and
fairness. However, little study has been done to construct such benchmarks for
Chinese, where various language-specific input noises happen in the real world.
In order to fill this important gap, we construct READIN: a Chinese multi-task
benchmark with REalistic And Diverse Input Noises. READIN contains four diverse
tasks and requests annotators to re-enter the original test data with two
commonly used Chinese input methods: Pinyin input and speech input. We designed
our annotation pipeline to maximize diversity, for example by instructing the
annotators to use diverse input method editors (IMEs) for keyboard noises and
recruiting speakers from diverse dialectical groups for speech noises. We
experiment with a series of strong pretrained language models as well as robust
training methods, we find that these models often suffer significant
performance drops on READIN even with robustness methods like data
augmentation. As the first large-scale attempt in creating a benchmark with
noises geared towards user-generated inputs, we believe that READIN serves as
an important complement to existing Chinese NLP benchmarks. The source code and
dataset can be obtained from https://github.com/thunlp/READIN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ScatterShot: Interactive In-context Example Curation for Text Transformation. (arXiv:2302.07346v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07346">
<div class="article-summary-box-inner">
<span><p>The in-context learning capabilities of LLMs like GPT-3 allow annotators to
customize an LLM to their specific tasks with a small number of examples.
However, users tend to include only the most obvious patterns when crafting
examples, resulting in underspecified in-context functions that fall short on
unseen cases. Further, it is hard to know when "enough" examples have been
included even for known patterns. In this work, we present ScatterShot, an
interactive system for building high-quality demonstration sets for in-context
learning. ScatterShot iteratively slices unlabeled data into task-specific
patterns, samples informative inputs from underexplored or not-yet-saturated
slices in an active learning manner, and helps users label more efficiently
with the help of an LLM and the current example set. In simulation studies on
two text perturbation scenarios, ScatterShot sampling improves the resulting
few-shot functions by 4-5 percentage points over random sampling, with less
variance as more examples are added. In a user study, ScatterShot greatly helps
users in covering different patterns in the input space and labeling in-context
examples more efficiently, resulting in better in-context learning and less
user effort.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AutoBiasTest: Controllable Sentence Generation for Automated and Open-Ended Social Bias Testing in Language Models. (arXiv:2302.07371v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07371">
<div class="article-summary-box-inner">
<span><p>Social bias in Pretrained Language Models (PLMs) affects text generation and
other downstream NLP tasks. Existing bias testing methods rely predominantly on
manual templates or on expensive crowd-sourced data. We propose a novel
AutoBiasTest method that automatically generates sentences for testing bias in
PLMs, hence providing a flexible and low-cost alternative. Our approach uses
another PLM for generation and controls the generation of sentences by
conditioning on social group and attribute terms. We show that generated
sentences are natural and similar to human-produced content in terms of word
length and diversity. We illustrate that larger models used for generation
produce estimates of social bias with lower variance. We find that our bias
scores are well correlated with manual templates, but AutoBiasTest highlights
biases not captured by these templates due to more diverse and realistic test
sentences. By automating large-scale test sentence generation, we enable better
estimation of underlying bias distributions
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adding Instructions during Pretraining: Effective Way of Controlling Toxicity in Language Models. (arXiv:2302.07388v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07388">
<div class="article-summary-box-inner">
<span><p>Pretrained large language models have become indispensable for solving
various natural language processing (NLP) tasks. However, safely deploying them
in real world applications is challenging because they generate toxic content.
To address this challenge, we propose two novel pretraining data augmentation
strategies that significantly reduce model toxicity without compromising its
utility. Our two strategies are: (1) MEDA: adds raw toxicity score as meta-data
to the pretraining samples, and (2) INST: adds instructions to those samples
indicating their toxicity. Our results indicate that our best performing
strategy (INST) substantially reduces the toxicity probability up to 61% while
preserving the accuracy on five benchmark NLP tasks as well as improving AUC
scores on four bias detection tasks by 1.3%. We also demonstrate the
generalizability of our techniques by scaling the number of training samples
and the number of model parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. (arXiv:2302.07452v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07452">
<div class="article-summary-box-inner">
<span><p>Various techniques have been developed in recent years to improve dense
retrieval (DR), such as unsupervised contrastive learning and pseudo-query
generation. Existing DRs, however, often suffer from effectiveness tradeoffs
between supervised and zero-shot retrieval, which some argue was due to the
limited model capacity. We contradict this hypothesis and show that a
generalizable DR can be trained to achieve high accuracy in both supervised and
zero-shot retrieval without increasing model size. In particular, we
systematically examine the contrastive learning of DRs, under the framework of
Data Augmentation (DA). Our study shows that common DA practices such as query
augmentation with generative models and pseudo-relevance label creation using a
cross-encoder, are often inefficient and sub-optimal. We hence propose a new DA
approach with diverse queries and sources of supervision to progressively train
a generalizable DR. As a result, DRAGON, our dense retriever trained with
diverse augmentation, is the first BERT-base-sized DR to achieve
state-of-the-art effectiveness in both supervised and zero-shot evaluations and
even competes with models using more complex late interaction (ColBERTv2 and
SPLADE++).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Capacity for Moral Self-Correction in Large Language Models. (arXiv:2302.07459v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07459">
<div class="article-summary-box-inner">
<span><p>We test the hypothesis that language models trained with reinforcement
learning from human feedback (RLHF) have the capability to "morally
self-correct" -- to avoid producing harmful outputs -- if instructed to do so.
We find strong evidence in support of this hypothesis across three different
experiments, each of which reveal different facets of moral self-correction. We
find that the capability for moral self-correction emerges at 22B model
parameters, and typically improves with increasing model size and RLHF
training. We believe that at this level of scale, language models obtain two
capabilities that they can use for moral self-correction: (1) they can follow
instructions and (2) they can learn complex normative concepts of harm like
stereotyping, bias, and discrimination. As such, they can follow instructions
to avoid certain kinds of morally harmful outputs. We believe our results are
cause for cautious optimism regarding the ability to train language models to
abide by ethical principles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Envisioning the Next-Gen Document Reader. (arXiv:2302.07492v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07492">
<div class="article-summary-box-inner">
<span><p>People read digital documents on a daily basis to share, exchange, and
understand information in electronic settings. However, current document
readers create a static, isolated reading experience, which does not support
users' goals of gaining more knowledge and performing additional tasks through
document interaction. In this work, we present our vision for the next-gen
document reader that strives to enhance user understanding and create a more
connected, trustworthy information experience. We describe 18 NLP-powered
features to add to existing document readers and propose a novel plug-in
marketplace that allows users to further customize their reading experience, as
demonstrated through 3 exploratory UI prototypes available at
https://github.com/catherinesyeh/nextgen-prototypes
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Word class representations spontaneously emerge in a deep neural network trained on next word prediction. (arXiv:2302.07588v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07588">
<div class="article-summary-box-inner">
<span><p>How do humans learn language, and can the first language be learned at all?
These fundamental questions are still hotly debated. In contemporary
linguistics, there are two major schools of thought that give completely
opposite answers. According to Chomsky's theory of universal grammar, language
cannot be learned because children are not exposed to sufficient data in their
linguistic environment. In contrast, usage-based models of language assume a
profound relationship between language structure and language use. In
particular, contextual mental processing and mental representations are assumed
to have the cognitive capacity to capture the complexity of actual language use
at all levels. The prime example is syntax, i.e., the rules by which words are
assembled into larger units such as sentences. Typically, syntactic rules are
expressed as sequences of word classes. However, it remains unclear whether
word classes are innate, as implied by universal grammar, or whether they
emerge during language acquisition, as suggested by usage-based approaches.
Here, we address this issue from a machine learning and natural language
processing perspective. In particular, we trained an artificial deep neural
network on predicting the next word, provided sequences of consecutive words as
input. Subsequently, we analyzed the emerging activation patterns in the hidden
layers of the neural network. Strikingly, we find that the internal
representations of nine-word input sequences cluster according to the word
class of the tenth word to be predicted as output, even though the neural
network did not receive any explicit information about syntactic rules or word
classes during training. This surprising result suggests, that also in the
human brain, abstract representational categories such as word classes may
naturally emerge as a consequence of predictive coding and processing during
language acquisition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DP-BART for Privatized Text Rewriting under Local Differential Privacy. (arXiv:2302.07636v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07636">
<div class="article-summary-box-inner">
<span><p>Privatized text rewriting with local differential privacy (LDP) is a recent
approach that enables sharing of sensitive textual documents while formally
guaranteeing privacy protection to individuals. However, existing systems face
several issues, such as formal mathematical flaws, unrealistic privacy
guarantees, privatization of only individual words, as well as a lack of
transparency and reproducibility. In this paper, we propose a new system
'DP-BART' that largely outperforms existing LDP systems. Our approach uses a
novel clipping method, iterative pruning, and further training of internal
representations which drastically reduces the amount of noise required for DP
guarantees. We run experiments on five textual datasets of varying sizes,
rewriting them at different privacy guarantees and evaluating the rewritten
texts on downstream text classification tasks. Finally, we thoroughly discuss
the privatized text rewriting approach and its limitations, including the
problem of the strict text adjacency constraint in the LDP paradigm that leads
to the high noise requirement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On graph-based reentrancy-free semantic parsing. (arXiv:2302.07679v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07679">
<div class="article-summary-box-inner">
<span><p>We propose a novel graph-based approach for semantic parsing that resolves
two problems observed in the literature: (1) seq2seq models fail on
compositional generalization tasks; (2) previous work using phrase structure
parsers cannot cover all the semantic parses observed in treebanks. We prove
that both MAP inference and latent tag anchoring (required for
weakly-supervised learning) are NP-hard problems. We propose two optimization
algorithms based on constraint smoothing and conditional gradient to
approximately solve these inference problems. Experimentally, our approach
delivers state-of-the-art results on Geoquery, Scan and Clevr, both for i.i.d.
splits and for splits that test for compositional generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Enhanced Semantic Communication Receiver. (arXiv:2302.07727v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07727">
<div class="article-summary-box-inner">
<span><p>In recent years, with the rapid development of deep learning and natural
language processing technologies, semantic communication has become a topic of
great interest in the field of communication. Although existing deep learning
based semantic communication approaches have shown many advantages, they still
do not make sufficient use of prior knowledge. Moreover, most existing semantic
communication methods focus on the semantic encoding at the transmitter side,
while we believe that the semantic decoding capability of the receiver side
should also be concerned. In this paper, we propose a knowledge enhanced
semantic communication framework in which the receiver can more actively
utilize the prior knowledge in the knowledge base for semantic reasoning and
decoding, without extra modifications to the neural network structure of the
transmitter. Specifically, we design a transformer-based knowledge extractor to
find relevant factual triples for the received noisy signal. Extensive
simulation results on the WebNLG dataset demonstrate that the proposed receiver
yields superior performance on top of the knowledge graph enhanced decoding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AIDA: Legal Judgment Predictions for Non-Professional Fact Descriptions via Partial-and-Imbalanced Domain Adaptation. (arXiv:2302.07728v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07728">
<div class="article-summary-box-inner">
<span><p>In this paper, we study the problem of legal domain adaptation problem from
an imbalanced source domain to a partial target domain. The task aims to
improve legal judgment predictions for non-professional fact descriptions. We
formulate this task as a partial-and-imbalanced domain adaptation problem.
Though deep domain adaptation has achieved cutting-edge performance in many
unsupervised domain adaptation tasks. However, due to the negative transfer of
samples in non-shared classes, it is hard for current domain adaptation model
to solve the partial-and-imbalanced transfer problem. In this work, we explore
large-scale non-shared but related classes data in the source domain with a
hierarchy weighting adaptation to tackle this limitation. We propose to embed a
novel pArtial Imbalanced Domain Adaptation technique (AIDA) in the deep
learning model, which can jointly borrow sibling knowledge from non-shared
classes to shared classes in the source domain and further transfer the shared
classes knowledge from the source domain to the target domain. Experimental
results show that our model outperforms the state-of-the-art algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generation of Highlights from Research Papers Using Pointer-Generator Networks and SciBERT Embeddings. (arXiv:2302.07729v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07729">
<div class="article-summary-box-inner">
<span><p>Nowadays many research articles are prefaced with research highlights to
summarize the main findings of the paper. Highlights not only help researchers
precisely and quickly identify the contributions of a paper, they also enhance
the discoverability of the article via search engines. We aim to automatically
construct research highlights given certain segments of the research paper. We
use a pointer-generator network with coverage mechanism and a contextual
embedding layer at the input that encodes the input tokens into SciBERT
embeddings. We test our model on a benchmark dataset, CSPubSum and also present
MixSub, a new multi-disciplinary corpus of papers for automatic research
highlight generation. For both CSPubSum and MixSub, we have observed that the
proposed model achieves the best performance compared to related variants and
other models proposed in the literature. On the CSPubSum data set, our model
achieves the best performance when the input is only the abstract of a paper as
opposed to other segments of the paper. It produces ROUGE-1, ROUGE-2 and
ROUGE-L F1-scores of 38.26, 14.26 and 35.51, respectively, METEOR F1-score of
32.62, and BERTScore F1 of 86.65 which outperform all other baselines. On the
new MixSub data set, where only the abstract is the input, our proposed model
(when trained on the whole training corpus without distinguishing between the
subject categories) achieves ROUGE-1, ROUGE-2 and ROUGE-L F1-scores of 31.78,
9.76 and 29.3, respectively, METEOR F1-score of 24.00, and BERTScore F1 of
85.25, outperforming other models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer models: an introduction and catalog. (arXiv:2302.07730v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07730">
<div class="article-summary-box-inner">
<span><p>In the past few years we have seen the meteoric appearance of dozens of
models of the Transformer family, all of which have funny, but not
self-explanatory, names. The goal of this paper is to offer a somewhat
comprehensive but simple catalog and classification of the most popular
Transformer models. The paper also includes an introduction to the most
important aspects and innovation in Transformer models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews on Social Media. (arXiv:2302.07731v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07731">
<div class="article-summary-box-inner">
<span><p>Recent advances in generative models such as GPT may be used to fabricate
indistinguishable fake customer reviews at a much lower cost, thus posing
challenges for social media platforms to detect these machine-generated fake
reviews. We propose to leverage the high-quality elite restaurant reviews
verified by Yelp to generate fake reviews from the OpenAI GPT review creator
and ultimately fine-tune a GPT output detector to predict fake reviews that
significantly outperforms existing solutions. We further apply the model to
predict non-elite reviews and identify the patterns across several dimensions,
such as review, user and restaurant characteristics, and writing style. We show
that social media platforms are continuously challenged by machine-generated
fake reviews, although they may implement detection systems to filter out
suspicious reviews.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explaining text classifiers through progressive neighborhood approximation with realistic samples. (arXiv:2302.07733v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07733">
<div class="article-summary-box-inner">
<span><p>The importance of neighborhood construction in local explanation methods has
been already highlighted in the literature. And several attempts have been made
to improve neighborhood quality for high-dimensional data, for example, texts,
by adopting generative models. Although the generators produce more realistic
samples, the intuitive sampling approaches in the existing solutions leave the
latent space underexplored. To overcome this problem, our work, focusing on
local model-agnostic explanations for text classifiers, proposes a progressive
approximation approach that refines the neighborhood of a to-be-explained
decision with a careful two-stage interpolation using counterfactuals as
landmarks. We explicitly specify the two properties that should be satisfied by
generative models, the reconstruction ability and the locality-preserving
property, to guide the selection of generators for local explanation methods.
Moreover, noticing the opacity of generative models during the study, we
propose another method that implements progressive neighborhood approximation
with probability-based editions as an alternative to the generator-based
solution. The explanation results from both methods consist of word-level and
instance-level explanations benefiting from the realistic neighborhood. Through
exhaustive experiments, we qualitatively and quantitatively demonstrate the
effectiveness of the two proposed methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Targeted Attack on GPT-Neo for the SATML Language Model Data Extraction Challenge. (arXiv:2302.07735v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07735">
<div class="article-summary-box-inner">
<span><p>Previous work has shown that Large Language Models are susceptible to
so-called data extraction attacks. This allows an attacker to extract a sample
that was contained in the training data, which has massive privacy
implications. The construction of data extraction attacks is challenging,
current attacks are quite inefficient, and there exists a significant gap in
the extraction capabilities of untargeted attacks and memorization. Thus,
targeted attacks are proposed, which identify if a given sample from the
training data, is extractable from a model. In this work, we apply a targeted
data extraction attack to the SATML2023 Language Model Training Data Extraction
Challenge. We apply a two-step approach. In the first step, we maximise the
recall of the model and are able to extract the suffix for 69% of the samples.
In the second step, we use a classifier-based Membership Inference Attack on
the generations. Our AutoSklearn classifier achieves a precision of 0.841. The
full approach reaches a score of 0.405 recall at a 10% false positive rate,
which is an improvement of 34% over the baseline of 0.301.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is ChatGPT better than Human Annotators? Potential and Limitations of ChatGPT in Explaining Implicit Hate Speech. (arXiv:2302.07736v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07736">
<div class="article-summary-box-inner">
<span><p>Recent studies have alarmed that many online hate speeches are implicit. With
its subtle nature, the explainability of the detection of such hateful speech
has been a challenging problem. In this work, we examine whether ChatGPT can be
used for providing natural language explanations (NLEs) for implicit hateful
speech detection. We design our prompt to elicit concise ChatGPT-generated NLEs
and conduct user studies to evaluate their qualities by comparison with
human-generated NLEs. We discuss the potential and limitations of ChatGPT in
the context of implicit hateful speech research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Alloprof: a new French question-answer education dataset and its use in an information retrieval case study. (arXiv:2302.07738v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07738">
<div class="article-summary-box-inner">
<span><p>Teachers and students are increasingly relying on online learning resources
to supplement the ones provided in school. This increase in the breadth and
depth of available resources is a great thing for students, but only provided
they are able to find answers to their queries. Question-answering and
information retrieval systems have benefited from public datasets to train and
evaluate their algorithms, but most of these datasets have been in English text
written by and for adults. We introduce a new public French question-answering
dataset collected from Alloprof, a Quebec-based primary and high-school help
website, containing 29 349 questions and their explanations in a variety of
school subjects from 10 368 students, with more than half of the explanations
containing links to other questions or some of the 2 596 reference pages on the
website. We also present a case study of this dataset in an information
retrieval task. This dataset was collected on the Alloprof public forum, with
all questions verified for their appropriateness and the explanations verified
both for their appropriateness and their relevance to the question. To predict
relevant documents, architectures using pre-trained BERT models were fine-tuned
and evaluated. This dataset will allow researchers to develop
question-answering, information retrieval and other algorithms specifically for
the French speaking education context. Furthermore, the range of language
proficiency, images, mathematical symbols and spelling mistakes will
necessitate algorithms based on a multimodal comprehension. The case study we
present as a baseline shows an approach that relies on recent techniques
provides an acceptable performance level, but more work is necessary before it
can reliably be used and trusted in a production setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-Learning Triplet Network with Adaptive Margins for Few-Shot Named Entity Recognition. (arXiv:2302.07739v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07739">
<div class="article-summary-box-inner">
<span><p>Meta-learning methods have been widely used in few-shot named entity
recognition (NER), especially prototype-based methods. However, the Other(O)
class is difficult to be represented by a prototype vector because there are
generally a large number of samples in the class that have miscellaneous
semantics. To solve the problem, we propose MeTNet, which generates prototype
vectors for entity types only but not O-class. We design an improved triplet
network to map samples and prototype vectors into a low-dimensional space that
is easier to be classified and propose an adaptive margin for each entity type.
The margin plays as a radius and controls a region with adaptive size in the
low-dimensional space. Based on the regions, we propose a new inference
procedure to predict the label of a query instance. We conduct extensive
experiments in both in-domain and cross-domain settings to show the superiority
of MeTNet over other state-of-the-art methods. In particular, we release a
Chinese few-shot NER dataset FEW-COMM extracted from a well-known e-commerce
platform. To the best of our knowledge, this is the first Chinese few-shot NER
dataset. All the datasets and codes are provided at
https://github.com/hccngu/MeTNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Team Triple-Check at Factify 2: Parameter-Efficient Large Foundation Models with Feature Representations for Multi-Modal Fact Verification. (arXiv:2302.07740v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07740">
<div class="article-summary-box-inner">
<span><p>Multi-modal fact verification has become an important but challenging issue
on social media due to the mismatch between the text and images in the
misinformation of news content, which has been addressed by considering
cross-modalities to identify the veracity of the news in recent years. In this
paper, we propose the Pre-CoFactv2 framework with new parameter-efficient
foundation models for modeling fine-grained text and input embeddings with
lightening parameters, multi-modal multi-type fusion for not only capturing
relations for the same and different modalities but also for different types
(i.e., claim and document), and feature representations for explicitly
providing metadata for each sample. In addition, we introduce a unified
ensemble method to boost model performance by adjusting the importance of each
trained model with not only the weights but also the powers. Extensive
experiments show that Pre-CoFactv2 outperforms Pre-CoFact by a large margin and
achieved new state-of-the-art results at the Factify challenge at AAAI 2023. We
further illustrate model variations to verify the relative contributions of
different components. Our team won the first prize (F1-score: 81.82%) and we
made our code publicly available at
https://github.com/wwweiwei/Pre-CoFactv2-AAAI-2023.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Whats New? Identifying the Unfolding of New Events in Narratives. (arXiv:2302.07748v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07748">
<div class="article-summary-box-inner">
<span><p>Narratives include a rich source of events unfolding over time and context.
Automatic understanding of these events may provide a summarised comprehension
of the narrative for further computation (such as reasoning). In this paper, we
study the Information Status (IS) of the events and propose a novel challenging
task: the automatic identification of new events in a narrative. We define an
event as a triplet of subject, predicate, and object. The event is categorized
as new with respect to the discourse context and whether it can be inferred
through commonsense reasoning. We annotated a publicly available corpus of
narratives with the new events at sentence level using human annotators. We
present the annotation protocol and a study aiming at validating the quality of
the annotation and the difficulty of the task. We publish the annotated
dataset, annotation materials, and machine learning baseline models for the
task of new event extraction for narrative understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Measuring the Instability of Fine-Tuning. (arXiv:2302.07778v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07778">
<div class="article-summary-box-inner">
<span><p>Fine-tuning pre-trained language models on downstream tasks with varying
random seeds has been shown to be unstable, especially on small datasets. Many
previous studies have investigated this instability and proposed methods to
mitigate it. However, most studies only used the standard deviation of
performance scores (SD) as their measure, which is a narrow characterization of
instability. In this paper, we analyze SD and six other measures quantifying
instability at different levels of granularity. Moreover, we propose a
systematic framework to evaluate the validity of these measures. Finally, we
analyze the consistency and difference between different measures by
reassessing existing instability mitigation methods. We hope our results will
inform the development of better measurements of fine-tuning instability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Augmented Language Models: a Survey. (arXiv:2302.07842v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07842">
<div class="article-summary-box-inner">
<span><p>This survey reviews works in which language models (LMs) are augmented with
reasoning skills and the ability to use tools. The former is defined as
decomposing a potentially complex task into simpler subtasks while the latter
consists in calling external modules such as a code interpreter. LMs can
leverage these augmentations separately or in combination via heuristics, or
learn to do so from demonstrations. While adhering to a standard missing tokens
prediction objective, such augmented LMs can use various, possibly
non-parametric external modules to expand their context processing ability,
thus departing from the pure language modeling paradigm. We therefore refer to
them as Augmented Language Models (ALMs). The missing token objective allows
ALMs to learn to reason, use tools, and even act, while still performing
standard natural language tasks and even outperforming most regular LMs on
several benchmarks. In this work, after reviewing current advance in ALMs, we
conclude that this new research direction has the potential to address common
limitations of traditional LMs such as interpretability, consistency, and
scalability issues.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NL2CMD: An Updated Workflow for Natural Language to Bash Commands Translation. (arXiv:2302.07845v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07845">
<div class="article-summary-box-inner">
<span><p>Translating natural language into Bash Commands is an emerging research field
that has gained attention in recent years. Most efforts have focused on
producing more accurate translation models. To the best of our knowledge, only
two datasets are available, with one based on the other. Both datasets involve
scraping through known data sources (through platforms like stack overflow,
crowdsourcing, etc.) and hiring experts to validate and correct either the
English text or Bash Commands.
</p>
<p>This paper provides two contributions to research on synthesizing Bash
Commands from scratch. First, we describe a state-of-the-art translation model
used to generate Bash Commands from the corresponding English text. Second, we
introduce a new NL2CMD dataset that is automatically generated, involves
minimal human intervention, and is over six times larger than prior datasets.
Since the generation pipeline does not rely on existing Bash Commands, the
distribution and types of commands can be custom adjusted. Our empirical
results show how the scale and diversity of our dataset can offer unique
opportunities for semantic parsing researchers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dictionary-based Phrase-level Prompting of Large Language Models for Machine Translation. (arXiv:2302.07856v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07856">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) demonstrate remarkable machine translation (MT)
abilities via prompting, even though they were not explicitly trained for this
task. However, even given the incredible quantities of data they are trained
on, LLMs can struggle to translate inputs with rare words, which are common in
low resource or domain transfer scenarios. We show that LLM prompting can
provide an effective solution for rare words as well, by using prior knowledge
from bilingual dictionaries to provide control hints in the prompts. We propose
a novel method, DiPMT, that provides a set of possible translations for a
subset of the input words, thereby enabling fine-grained phrase-level prompted
control of the LLM. Extensive experiments show that DiPMT outperforms the
baseline both in low-resource MT, as well as for out-of-domain MT. We further
provide a qualitative analysis of the benefits and limitations of this
approach, including the overall level of controllability that is achieved.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Big Little Transformer Decoder. (arXiv:2302.07863v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07863">
<div class="article-summary-box-inner">
<span><p>The recent emergence of Large Language Models based on the Transformer
architecture has enabled dramatic advancements in the field of Natural Language
Processing. However, these models have long inference latency, which limits
their deployment, and which makes them prohibitively expensive for various
real-time applications. The inference latency is further exacerbated by
autoregressive generative tasks, as models need to run iteratively to generate
tokens sequentially without leveraging token-level parallelization. To address
this, we propose Big Little Decoder (BiLD), a framework that can improve
inference efficiency and latency for a wide range of text generation
applications. The BiLD framework contains two models with different sizes that
collaboratively generate text. The small model runs autoregressively to
generate text with a low inference cost, and the large model is only invoked
occasionally to refine the small model's inaccurate predictions in a
non-autoregressive manner. To coordinate the small and large models, BiLD
introduces two simple yet effective policies: (1) the fallback policy that
determines when to hand control over to the large model; and (2) the rollback
policy that determines when the large model needs to review and correct the
small model's inaccurate predictions. To evaluate our framework across
different tasks and models, we apply BiLD to various text generation scenarios
encompassing machine translation on IWSLT 2017 De-En and WMT 2014 De-En,
summarization on CNN/DailyMail, and language modeling on WikiText-2. On an
NVIDIA Titan Xp GPU, our framework achieves a speedup of up to 2.13x without
any performance drop, and it achieves up to 2.38x speedup with only ~1 point
degradation. Furthermore, our framework is fully plug-and-play as it does not
require any training or modifications to model architectures. Our code will be
open-sourced.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Deep Neural Networks Capture Compositionality in Arithmetic Reasoning?. (arXiv:2302.07866v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07866">
<div class="article-summary-box-inner">
<span><p>Compositionality is a pivotal property of symbolic reasoning. However, how
well recent neural models capture compositionality remains underexplored in the
symbolic reasoning tasks. This study empirically addresses this question by
systematically examining recently published pre-trained seq2seq models with a
carefully controlled dataset of multi-hop arithmetic symbolic reasoning. We
introduce a skill tree on compositionality in arithmetic symbolic reasoning
that defines the hierarchical levels of complexity along with three
compositionality dimensions: systematicity, productivity, and substitutivity.
Our experiments revealed that among the three types of composition, the models
struggled most with systematicity, performing poorly even with relatively
simple compositions. That difficulty was not resolved even after training the
models with intermediate reasoning steps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sub-Character Tokenization for Chinese Pretrained Language Models. (arXiv:2106.00400v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00400">
<div class="article-summary-box-inner">
<span><p>Tokenization is fundamental to pretrained language models (PLMs). Existing
tokenization methods for Chinese PLMs typically treat each character as an
indivisible token. However, they ignore the unique feature of the Chinese
writing system where additional linguistic information exists below the
character level, i.e., at the sub-character level. To utilize such information,
we propose sub-character (SubChar for short) tokenization. Specifically, we
first encode the input text by converting each Chinese character into a short
sequence based on its glyph or pronunciation, and then construct the vocabulary
based on the encoded text with sub-word segmentation. Experimental results show
that SubChar tokenizers have two main advantages over existing tokenizers: 1)
They can tokenize inputs into much shorter sequences, thus improving the
computational efficiency. 2) Pronunciation-based SubChar tokenizers can encode
Chinese homophones into the same transliteration sequences and produce the same
tokenization output, hence being robust to homophone typos. At the same time,
models trained with SubChar tokenizers perform competitively on downstream
tasks. We release our code and models at
https://github.com/thunlp/SubCharTokenization to facilitate future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural Language Generation. (arXiv:2106.05970v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05970">
<div class="article-summary-box-inner">
<span><p>Automatic evaluations for natural language generation (NLG) conventionally
rely on token-level or embedding-level comparisons with text references. This
differs from human language processing, for which visual imagination often
improves comprehension. In this work, we propose ImaginE, an imagination-based
automatic evaluation metric for natural language generation. With the help of
StableDiffusion, a state-of-the-art text-to-image generator, we automatically
generate an image as the embodied imagination for the text snippet and compute
the imagination similarity using contextual embeddings. Experiments spanning
several text generation tasks demonstrate that adding machine-generated images
with our ImaginE displays great potential in introducing multi-modal
information into NLG evaluation, and improves existing automatic metrics'
correlations with human similarity judgments in both reference-based and
reference-free evaluation scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Distantly-Supervised Named Entity Recognition with Self-Collaborative Denoising Learning. (arXiv:2110.04429v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04429">
<div class="article-summary-box-inner">
<span><p>Distantly supervised named entity recognition (DS-NER) efficiently reduces
labor costs but meanwhile intrinsically suffers from the label noise due to the
strong assumption of distant supervision. Typically, the wrongly labeled
instances comprise numbers of incomplete and inaccurate annotation noise, while
most prior denoising works are only concerned with one kind of noise and fail
to fully explore useful information in the whole training set. To address this
issue, we propose a robust learning paradigm named Self-Collaborative Denoising
Learning (SCDL), which jointly trains two teacher-student networks in a
mutually-beneficial manner to iteratively perform noisy label refinery. Each
network is designed to exploit reliable labels via self denoising, and two
networks communicate with each other to explore unreliable annotations by
collaborative denoising. Extensive experimental results on five real-world
datasets demonstrate that SCDL is superior to state-of-the-art DS-NER denoising
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gold Doesn't Always Glitter: Spectral Removal of Linear and Nonlinear Guarded Attribute Information. (arXiv:2203.07893v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07893">
<div class="article-summary-box-inner">
<span><p>We describe a simple and effective method (Spectral Attribute removaL; SAL)
to remove private or guarded information from neural representations. Our
method uses matrix decomposition to project the input representations into
directions with reduced covariance with the guarded information rather than
maximal covariance as factorization methods normally use. We begin with linear
information removal and proceed to generalize our algorithm to the case of
nonlinear information removal using kernels. Our experiments demonstrate that
our algorithm retains better main task performance after removing the guarded
information compared to previous work. In addition, our experiments demonstrate
that we need a relatively small amount of guarded attribute data to remove
information about these attributes, which lowers the exposure to sensitive data
and is more suitable for low-resource scenarios. Code is available at
https://github.com/jasonshaoshun/SAL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks. (arXiv:2204.02892v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.02892">
<div class="article-summary-box-inner">
<span><p>The field of Natural Language Processing has experienced a dramatic leap in
capabilities with the recent introduction of huge Language Models. Despite this
success, natural language problems that involve several compounded steps are
still practically unlearnable, even by the largest LMs. This complies with
experimental failures for end-to-end learning of composite problems that were
demonstrated in a variety of domains. An effective mitigation is to introduce
intermediate supervision for solving sub-tasks of the compounded problem.
Recently, several works have demonstrated high gains by taking a
straightforward approach for incorporating intermediate supervision in
compounded natural language problems: the sequence-to-sequence LM is fed with
an augmented input, in which the decomposed tasks' labels are simply
concatenated to the original input. In this paper, we prove a positive learning
result that motivates these recent efforts. We show that when concatenating
intermediate supervision to the input and training a sequence-to-sequence model
on this modified input, unlearnable composite problems can become learnable. We
show that this is true for any family of tasks which on the one hand, are
unlearnable, and on the other hand, can be decomposed into a polynomial number
of simple sub-tasks, each of which depends only on O(1) previous sub-task
results. Beyond motivating contemporary empirical efforts for incorporating
intermediate supervision in sequence-to-sequence language models, our positive
theoretical result is the first of its kind in the landscape of results on the
benefits of intermediate supervision for neural-network learning: Until now,
all theoretical results on the subject are negative, i.e., show cases where
learning is impossible without intermediate supervision, while our result is
positive, showing that learning is facilitated in the presence of intermediate
supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Multi-task Learning in Natural Language Processing: Regarding Task Relatedness and Training Methods. (arXiv:2204.03508v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.03508">
<div class="article-summary-box-inner">
<span><p>Multi-task learning (MTL) has become increasingly popular in natural language
processing (NLP) because it improves the performance of related tasks by
exploiting their commonalities and differences. Nevertheless, it is still not
understood very well how multi-task learning can be implemented based on the
relatedness of training tasks. In this survey, we review recent advances of
multi-task learning methods in NLP, with the aim of summarizing them into two
general multi-task training methods based on their task relatedness: (i) joint
training and (ii) multi-step training. We present examples in various NLP
downstream applications, summarize the task relationships and discuss future
directions of this promising topic.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Holistic Approach to Undesired Content Detection in the Real World. (arXiv:2208.03274v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.03274">
<div class="article-summary-box-inner">
<span><p>We present a holistic approach to building a robust and useful natural
language classification system for real-world content moderation. The success
of such a system relies on a chain of carefully designed and executed steps,
including the design of content taxonomies and labeling instructions, data
quality control, an active learning pipeline to capture rare events, and a
variety of methods to make the model robust and to avoid overfitting. Our
moderation system is trained to detect a broad set of categories of undesired
content, including sexual content, hateful content, violence, self-harm, and
harassment. This approach generalizes to a wide range of different content
taxonomies and can be used to create high-quality content classifiers that
outperform off-the-shelf models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PANCETTA: Phoneme Aware Neural Completion to Elicit Tongue Twisters Automatically. (arXiv:2209.06275v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.06275">
<div class="article-summary-box-inner">
<span><p>Tongue twisters are meaningful sentences that are difficult to pronounce. The
process of automatically generating tongue twisters is challenging since the
generated utterance must satisfy two conditions at once: phonetic difficulty
and semantic meaning. Furthermore, phonetic difficulty is itself hard to
characterize and is expressed in natural tongue twisters through a
heterogeneous mix of phenomena such as alliteration and homophony. In this
paper, we propose PANCETTA: Phoneme Aware Neural Completion to Elicit Tongue
Twisters Automatically. We leverage phoneme representations to capture the
notion of phonetic difficulty, and we train language models to generate
original tongue twisters on two proposed task settings. To do this, we curate a
dataset called PANCETTA, consisting of existing English tongue twisters.
Through automatic and human evaluation, as well as qualitative analysis, we
show that PANCETTA generates novel, phonetically difficult, fluent, and
semantically meaningful tongue twisters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Construction and Applications of Billion-Scale Pre-trained Multimodal Business Knowledge Graph. (arXiv:2209.15214v4 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.15214">
<div class="article-summary-box-inner">
<span><p>Business Knowledge Graphs (KGs) are important to many enterprises today,
providing factual knowledge and structured data that steer many products and
make them more intelligent. Despite their promising benefits, building business
KG necessitates solving prohibitive issues of deficient structure and multiple
modalities. In this paper, we advance the understanding of the practical
challenges related to building KG in non-trivial real-world systems. We
introduce the process of building an open business knowledge graph (OpenBG)
derived from a well-known enterprise, Alibaba Group. Specifically, we define a
core ontology to cover various abstract products and consumption demands, with
fine-grained taxonomy and multimodal facts in deployed applications. OpenBG is
an open business KG of unprecedented scale: 2.6 billion triples with more than
88 million entities covering over 1 million core classes/concepts and 2,681
types of relations. We release all the open resources (OpenBG benchmarks)
derived from it for the community and report experimental results of KG-centric
tasks. We also run up an online competition based on OpenBG benchmarks, and has
attracted thousands of teams. We further pre-train OpenBG and apply it to many
KG- enhanced downstream tasks in business scenarios, demonstrating the
effectiveness of billion-scale multimodal knowledge for e-commerce. All the
resources with codes have been released at
\url{https://github.com/OpenBGBenchmark/OpenBG}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Compositional Generalisation with Structured Reordering and Fertility Layers. (arXiv:2210.03183v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.03183">
<div class="article-summary-box-inner">
<span><p>Seq2seq models have been shown to struggle with compositional generalisation,
i.e. generalising to new and potentially more complex structures than seen
during training. Taking inspiration from grammar-based models that excel at
compositional generalisation, we present a flexible end-to-end differentiable
neural model that composes two structural operations: a fertility step, which
we introduce in this work, and a reordering step based on previous work (Wang
et al., 2021). To ensure differentiability, we use the expected value of each
step. Our model outperforms seq2seq models by a wide margin on challenging
compositional splits of realistic semantic parsing tasks that require
generalisation to longer examples. It also compares favourably to other models
targeting compositional generalisation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visualize Before You Write: Imagination-Guided Open-Ended Text Generation. (arXiv:2210.03765v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.03765">
<div class="article-summary-box-inner">
<span><p>Recent advances in text-to-image synthesis make it possible to visualize
machine imaginations for a given context. On the other hand, when generating
text, human writers are gifted at creative visualization, which enhances their
writings by forming imaginations as blueprints before putting down the stories
in words. Inspired by such a cognitive process, we ask the natural question of
whether we can endow machines with the same ability to utilize visual
information and construct a general picture of the context to guide text
generation. In this work, we propose iNLG that uses machine-generated images to
guide language models in open-ended text generation. The experiments and
analyses demonstrate the effectiveness of iNLG on open-ended text generation
tasks, including text completion, story generation, and concept-to-text
generation in both few-shot and full-data scenarios. Both automatic metrics and
human evaluations verify that the text snippets generated by our iNLG are
coherent and informative while displaying minor degeneration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompting GPT-3 To Be Reliable. (arXiv:2210.09150v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.09150">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) show impressive abilities via few-shot
prompting. Commercialized APIs such as OpenAI GPT-3 further increase their use
in real-world language applications. However, the crucial problem of how to
improve the reliability of GPT-3 is still under-explored. While reliability is
a broad and vaguely defined term, we decompose reliability into four main
facets that correspond to the existing framework of ML safety and are
well-recognized to be important: generalizability, social biases, calibration,
and factuality. Our core contribution is to establish simple and effective
prompts that improve GPT-3's reliability as it: 1) generalizes
out-of-distribution, 2) balances demographic distribution and uses natural
language instructions to reduce social biases, 3) calibrates output
probabilities, and 4) updates the LLM's factual knowledge and reasoning chains.
With appropriate prompts, GPT-3 is more reliable than smaller-scale supervised
models on all these facets. We release all processed datasets, evaluation
scripts, and model predictions. Our systematic empirical study not only sheds
new insights on the reliability of prompting LLMs, but more importantly, our
prompting strategies can help practitioners more reliably use LLMs like GPT-3.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PoKE: Prior Knowledge Enhanced Emotional Support Conversation with Latent Variable. (arXiv:2210.12640v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12640">
<div class="article-summary-box-inner">
<span><p>Emotional support conversation (ESC) task can utilize various support
strategies to help people relieve emotional distress and overcome the problem
they face, which has attracted much attention in these years. However, most
state-of-the-art works rely heavily on external commonsense knowledge to infer
the mental state of the user in every dialogue round. Although effective, they
may suffer from significant human effort, knowledge update and domain change in
a long run. Therefore, in this article, we focus on exploring the task itself
without using any external knowledge. We find all existing works ignore two
significant characteristics of ESC. (a) Abundant prior knowledge exists in
historical conversations, such as the responses to similar cases and the
general order of support strategies, which has a great reference value for
current conversation. (b) There is a one-to-many mapping relationship between
context and support strategy, i.e.multiple strategies are reasonable for a
single context. It lays a better foundation for the diversity of generations.
Taking into account these two key factors, we propose Prior Knowledge Enhanced
emotional support model with latent variable, PoKE. The proposed model fully
taps the potential of prior knowledge in terms of exemplars and strategy
sequence and then utilizes a latent variable to model the one-to-many
relationship of strategy. Furthermore, we introduce a memory schema to
incorporate the encoded knowledge into decoder. Experiment results on benchmark
dataset show that our PoKE outperforms existing baselines on both automatic
evaluation and human evaluation. Compared with the model using external
knowledge, PoKE still can make a slight improvement in some metrics. Further
experiments prove that abundant prior knowledge is conducive to high-quality
emotional support, and a well-learned latent variable is critical to the
diversity of generations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic?. (arXiv:2210.14699v2 [cs.SE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.14699">
<div class="article-summary-box-inner">
<span><p>Language models are promising solutions for tackling increasing complex
problems. In software engineering, they recently attracted attention in code
assistants, with programs automatically written in a given programming language
from a programming task description in natural language. They have the
potential to save time and effort when writing code. However, these systems are
currently poorly understood, preventing them from being used optimally. In this
paper, we investigate the various input parameters of two language models, and
conduct a study to understand if variations of these input parameters (e.g.
programming task description and the surrounding context, creativity of the
language model, number of generated solutions) can have a significant impact on
the quality of the generated programs. We design specific operators for varying
input parameters and apply them over two code assistants (Copilot and Codex)
and two benchmarks representing algorithmic problems (HumanEval and LeetCode).
Our results showed that varying the input parameters can significantly improve
the performance of language models. However, there is a tight dependency when
varying the temperature, the prompt and the number of generated solutions,
making potentially hard for developers to properly control the parameters to
obtain an optimal result. This work opens opportunities to propose (automated)
strategies for improving performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models. (arXiv:2211.10438v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.10438">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) show excellent performance but are compute- and
memory-intensive. Quantization can reduce memory and accelerate inference.
However, for LLMs beyond 100 billion parameters, existing methods cannot
maintain accuracy or do not run efficiently on hardware. We propose
SmoothQuant, a training-free, accuracy-preserving, and general-purpose
post-training quantization (PTQ) solution to enable 8-bit weight, 8-bit
activation (W8A8) quantization for LLMs. Based on the fact that weights are
easy to quantize while activations are not, SmoothQuant smooths the activation
outliers by offline migrating the quantization difficulty from activations to
weights with a mathematically equivalent transformation. SmoothQuant enables an
INT8 quantization of both weights and activations for all the matrix
multiplications in LLMs, including OPT-175B, BLOOM-176B, GLM-130B, and MT-NLG
530B. SmoothQuant has better hardware efficiency than existing techniques. We
demonstrate up to 1.56x speedup and 2x memory reduction for LLMs with
negligible loss in accuracy. We integrate SmoothQuant into FasterTransformer, a
state-of-the-art LLM serving framework, and achieve faster inference speed with
half the number of GPUs compared to FP16, enabling the serving of a 530B LLM
within a single node. Our work offers a turn-key solution that reduces hardware
costs and democratizes LLMs. Code is available at
https://github.com/mit-han-lab/smoothquant.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Paraphrase Acquisition from Image Captions. (arXiv:2301.11030v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.11030">
<div class="article-summary-box-inner">
<span><p>We propose to use image captions from the Web as a previously underutilized
resource for paraphrases (i.e., texts with the same "message") and to create
and analyze a corresponding dataset. When an image is reused on the Web, an
original caption is often assigned. We hypothesize that different captions for
the same image naturally form a set of mutual paraphrases. To demonstrate the
suitability of this idea, we analyze captions in the English Wikipedia, where
editors frequently relabel the same image for different articles. The paper
introduces the underlying mining technology, the resulting Wikipedia-IPC
dataset, and compares known paraphrase corpora with respect to their syntactic
and semantic paraphrase similarity to our new resource. In this context, we
introduce characteristic maps along the two similarity dimensions to identify
the style of paraphrases coming from different sources. An annotation study
demonstrates the high reliability of the algorithmically determined
characteristic maps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Protein Representation Learning via Knowledge Enhanced Primary Structure Modeling. (arXiv:2301.13154v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.13154">
<div class="article-summary-box-inner">
<span><p>Protein representation learning has primarily benefited from the remarkable
development of language models (LMs). Accordingly, pre-trained protein models
also suffer from a problem in LMs: a lack of factual knowledge. The recent
solution models the relationships between protein and associated knowledge
terms as the knowledge encoding objective. However, it fails to explore the
relationships at a more granular level, i.e., the token level. To mitigate
this, we propose Knowledge-exploited Auto-encoder for Protein (KeAP), which
performs token-level knowledge graph exploration for protein representation
learning. In practice, non-masked amino acids iteratively query the associated
knowledge tokens to extract and integrate helpful information for restoring
masked amino acids via attention. We show that KeAP can consistently outperform
the previous counterpart on 9 representative downstream applications, sometimes
surpassing it by large margins. These results suggest that KeAP provides an
alternative yet effective way to perform knowledge enhanced protein
representation learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Advancing Radiograph Representation Learning with Masked Record Modeling. (arXiv:2301.13155v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.13155">
<div class="article-summary-box-inner">
<span><p>Modern studies in radiograph representation learning rely on either
self-supervision to encode invariant semantics or associated radiology reports
to incorporate medical expertise, while the complementarity between them is
barely noticed. To explore this, we formulate the self- and report-completion
as two complementary objectives and present a unified framework based on masked
record modeling (MRM). In practice, MRM reconstructs masked image patches and
masked report tokens following a multi-task scheme to learn knowledge-enhanced
semantic representations. With MRM pre-training, we obtain pre-trained models
that can be well transferred to various radiography tasks. Specifically, we
find that MRM offers superior performance in label-efficient fine-tuning. For
instance, MRM achieves 88.5% mean AUC on CheXpert using 1% labeled data,
outperforming previous R$^2$L methods with 100% labels. On NIH ChestX-ray, MRM
outperforms the best performing counterpart by about 3% under small labeling
ratios. Besides, MRM surpasses self- and report-supervised pre-training in
identifying the pneumonia type and the pneumothorax area, sometimes by large
margins.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Nationality Bias in Text Generation. (arXiv:2302.02463v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.02463">
<div class="article-summary-box-inner">
<span><p>Little attention is placed on analyzing nationality bias in language models,
especially when nationality is highly used as a factor in increasing the
performance of social NLP models. This paper examines how a text generation
model, GPT-2, accentuates pre-existing societal biases about country-based
demonyms. We generate stories using GPT-2 for various nationalities and use
sensitivity analysis to explore how the number of internet users and the
country's economic status impacts the sentiment of the stories. To reduce the
propagation of biases through large language models (LLM), we explore the
debiasing method of adversarial triggering. Our results show that GPT-2
demonstrates significant bias against countries with lower internet users, and
adversarial triggering effectively reduces the same.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MAC: A unified framework boosting low resource automatic speech recognition. (arXiv:2302.03498v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03498">
<div class="article-summary-box-inner">
<span><p>We propose a unified framework for low resource automatic speech recognition
tasks named meta audio concatenation (MAC). It is easy to implement and can be
carried out in extremely low resource environments. Mathematically, we give a
clear description of MAC framework from the perspective of bayesian sampling.
In this framework, we leverage a novel concatenative synthesis text-to-speech
system to boost the low resource ASR task. By the concatenative synthesis
text-to-speech system, we can integrate language pronunciation rules and adjust
the TTS process. Furthermore, we propose a broad notion of meta audio set to
meet the modeling needs of different languages and different scenes when using
the system. Extensive experiments have demonstrated the great effectiveness of
MAC on low resource ASR tasks. For CTC greedy search, CTC prefix, attention,
and attention rescoring decode mode in Cantonese ASR task, Taiwanese ASR task,
and Japanese ASR task the MAC method can reduce the CER by more than 15\%.
Furthermore, in the ASR task, MAC beats wav2vec2 (with fine-tuning) on common
voice datasets of Cantonese and gets really competitive results on common voice
datasets of Taiwanese and Japanese. Among them, it is worth mentioning that we
achieve a \textbf{10.9\%} character error rate (CER) on the common voice
Cantonese ASR task, bringing about \textbf{30\%} relative improvement compared
to the wav2vec2 (with fine-tuning).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Characterizing Attribution and Fluency Tradeoffs for Retrieval-Augmented Large Language Models. (arXiv:2302.05578v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05578">
<div class="article-summary-box-inner">
<span><p>Despite recent progress, it has been difficult to prevent semantic
hallucinations in generative Large Language Models. One common solution to this
is augmenting LLMs with a retrieval system and making sure that the generated
output is attributable to the retrieved information. Given this new added
constraint, it is plausible to expect that the overall quality of the output
will be affected, for example, in terms of fluency. Can scaling language models
help?
</p>
<p>Here we examine the relationship between fluency and attribution in LLMs
prompted with retrieved evidence in knowledge-heavy dialog settings. Our
experiments were implemented with a set of auto-metrics that are aligned with
human preferences. They were used to evaluate a large set of generations,
produced under varying parameters of LLMs and supplied context.
</p>
<p>We show that larger models tend to do much better in both fluency and
attribution, and that (naively) using top-k retrieval versus top-1 retrieval
improves attribution but hurts fluency. We next propose a recipe that could
allow smaller models to both close the gap with larger models and preserve the
benefits of top-k retrieval while avoiding its drawbacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is ChatGPT a General-Purpose Natural Language Processing Task Solver?. (arXiv:2302.06476v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.06476">
<div class="article-summary-box-inner">
<span><p>Spurred by advancements in scale, large language models (LLMs) have
demonstrated the ability to perform a variety of natural language processing
(NLP) tasks zero-shot -- i.e., without adaptation on downstream data. Recently,
the debut of ChatGPT has drawn a great deal of attention from the natural
language processing (NLP) community due to the fact that it can generate
high-quality responses to human input and self-correct previous mistakes based
on subsequent conversations. However, it is not yet known whether ChatGPT can
serve as a generalist model that can perform many NLP tasks zero-shot. In this
work, we empirically analyze the zero-shot learning ability of ChatGPT by
evaluating it on 20 popular NLP datasets covering 7 representative task
categories. With extensive empirical studies, we demonstrate both the
effectiveness and limitations of the current version of ChatGPT. We find that
ChatGPT performs well on many tasks favoring reasoning capabilities (e.g.,
arithmetic reasoning) while it still faces challenges when solving specific
tasks such as sequence tagging. We additionally provide in-depth analysis
through qualitative case studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Learning Model Attribution Challenge. (arXiv:2302.06716v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.06716">
<div class="article-summary-box-inner">
<span><p>We present the findings of the Machine Learning Model Attribution Challenge
https://mlmac.io. Fine-tuned machine learning models may derive from other
trained models without obvious attribution characteristics. In this challenge,
participants identify the publicly-available base models that underlie a set of
anonymous, fine-tuned large language models (LLMs) using only textual output of
the models. Contestants aim to correctly attribute the most fine-tuned models,
with ties broken in the favor of contestants whose solutions use fewer calls to
the fine-tuned models' API. The most successful approaches were manual, as
participants observed similarities between model outputs and developed
attribution heuristics based on public documentation of the base models, though
several teams also submitted automated, statistical solutions.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-02-16 23:13:34.252573491 UTC">2023-02-16 23:13:34 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>