<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-05-30T01:30:00Z">05-30</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Ghost in the Minecraft: Generally Capable Agents for Open-World Enviroments via Large Language Models with Text-based Knowledge and Memory. (arXiv:2305.17144v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17144">
<div class="article-summary-box-inner">
<span><p>The captivating realm of Minecraft has attracted substantial research
interest in recent years, serving as a rich platform for developing intelligent
agents capable of functioning in open-world environments. However, the current
research landscape predominantly focuses on specific objectives, such as the
popular "ObtainDiamond" task, and has not yet shown effective generalization to
a broader spectrum of tasks. Furthermore, the current leading success rate for
the "ObtainDiamond" task stands at around 20%, highlighting the limitations of
Reinforcement Learning (RL) based controllers used in existing methods. To
tackle these challenges, we introduce Ghost in the Minecraft (GITM), a novel
framework integrates Large Language Models (LLMs) with text-based knowledge and
memory, aiming to create Generally Capable Agents (GCAs) in Minecraft. These
agents, equipped with the logic and common sense capabilities of LLMs, can
skillfully navigate complex, sparse-reward environments with text-based
interactions. We develop a set of structured actions and leverage LLMs to
generate action plans for the agents to execute. The resulting LLM-based agent
markedly surpasses previous methods, achieving a remarkable improvement of
+47.5% in success rate on the "ObtainDiamond" task, demonstrating superior
robustness compared to traditional RL-based controllers. Notably, our agent is
the first to procure all items in the Minecraft Overworld technology tree,
demonstrating its extensive capabilities. GITM does not need any GPU for
training, but a single CPU node with 32 CPU cores is enough. This research
shows the potential of LLMs in developing capable agents for handling
long-horizon, complex tasks and adapting to uncertainties in open-world
environments. See the project website at https://github.com/OpenGVLab/GITM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Heterogeneous Value Evaluation for Large Language Models. (arXiv:2305.17147v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17147">
<div class="article-summary-box-inner">
<span><p>The emergent capabilities of Large Language Models (LLMs) have made it
crucial to align their values with those of humans. Current methodologies
typically attempt alignment with a homogeneous human value and requires human
verification, yet lack consensus on the desired aspect and depth of alignment
and resulting human biases. In this paper, we propose A2EHV, an Automated
Alignment Evaluation with a Heterogeneous Value system that (1) is automated to
minimize individual human biases, and (2) allows assessments against various
target values to foster heterogeneous agents. Our approach pivots on the
concept of value rationality, which represents the ability for agents to
execute behaviors that satisfy a target value the most. The quantification of
value rationality is facilitated by the Social Value Orientation framework from
social psychology, which partitions the value space into four categories to
assess social preferences from agents' behaviors. We evaluate the value
rationality of eight mainstream LLMs and observe that large models are more
inclined to align neutral values compared to those with strong personal values.
By examining the behavior of these LLMs, we contribute to a deeper
understanding of value alignment within a heterogeneous value system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models. (arXiv:2305.17174v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17174">
<div class="article-summary-box-inner">
<span><p>Dogwhistles are coded expressions that simultaneously convey one meaning to a
broad audience and a second one, often hateful or provocative, to a narrow
in-group; they are deployed to evade both political repercussions and
algorithmic content moderation. For example, in the sentence 'we need to end
the cosmopolitan experiment,' the word 'cosmopolitan' likely means 'worldly' to
many, but secretly means 'Jewish' to a select few. We present the first
large-scale computational investigation of dogwhistles. We develop a typology
of dogwhistles, curate the largest-to-date glossary of over 300 dogwhistles
with rich contextual information and examples, and analyze their usage in
historical U.S. politicians' speeches. We then assess whether a large language
model (GPT-3) can identify dogwhistles and their meanings, and find that
GPT-3's performance varies widely across types of dogwhistles and targeted
groups. Finally, we show that harmful content containing dogwhistles avoids
toxicity detection, highlighting online risks of such coded language. This work
sheds light on the theoretical and applied importance of dogwhistles in both
NLP and computational social science, and provides resources for future
research in modeling dogwhistles and mitigating their online harms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tokenization Impacts Multilingual Language Modeling: Assessing Vocabulary Allocation and Overlap Across Languages. (arXiv:2305.17179v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17179">
<div class="article-summary-box-inner">
<span><p>Multilingual language models have recently gained attention as a promising
solution for representing multiple languages in a single model. In this paper,
we propose new criteria to evaluate the quality of lexical representation and
vocabulary overlap observed in sub-word tokenizers. Our findings show that the
overlap of vocabulary across languages can be actually detrimental to certain
downstream tasks (POS, dependency tree labeling). In contrast, NER and
sentence-level tasks (cross-lingual retrieval, NLI) benefit from sharing
vocabulary. We also observe that the coverage of the language-specific tokens
in the multilingual vocabulary significantly impacts the word-level tasks. Our
study offers a deeper understanding of the role of tokenizers in multilingual
language models and guidelines for future model developers to choose the most
suitable tokenizer for their specific application before undertaking costly
model pre-training
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Copying Problem of Unsupervised NMT: A Training Schedule with a Language Discriminator Loss. (arXiv:2305.17182v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17182">
<div class="article-summary-box-inner">
<span><p>Although unsupervised neural machine translation (UNMT) has achieved success
in many language pairs, the copying problem, i.e., directly copying some parts
of the input sentence as the translation, is common among distant language
pairs, especially when low-resource languages are involved. We find this issue
is closely related to an unexpected copying behavior during online
back-translation (BT). In this work, we propose a simple but effective training
schedule that incorporates a language discriminator loss. The loss imposes
constraints on the intermediate translation so that the translation is in the
desired language. By conducting extensive experiments on different language
pairs, including similar and distant, high and low-resource languages, we find
that our method alleviates the copying problem, thus improving the translation
performance on low-resource languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Entailment as Robust Self-Learner. (arXiv:2305.17197v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17197">
<div class="article-summary-box-inner">
<span><p>Entailment has been recognized as an important metric for evaluating natural
language understanding (NLU) models, and recent studies have found that
entailment pretraining benefits weakly supervised fine-tuning. In this work, we
design a prompting strategy that formulates a number of different NLU tasks as
contextual entailment. This approach improves the zero-shot adaptation of
pretrained entailment models. Secondly, we notice that self-training
entailment-based models with unlabeled data can significantly improve the
adaptation performance on downstream tasks. To achieve more stable improvement,
we propose the Simple Pseudo-Label Editing (SimPLE) algorithm for better
pseudo-labeling quality in self-training. We also found that both pretrained
entailment-based models and the self-trained models are robust against
adversarial evaluation data. Experiments on binary and multi-class
classification tasks show that SimPLE leads to more robust self-training
results, indicating that the self-trained entailment models are more efficient
and trustworthy than large language models on language understanding tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BIG-C: a Multimodal Multi-Purpose Dataset for Bemba. (arXiv:2305.17202v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17202">
<div class="article-summary-box-inner">
<span><p>We present BIG-C (Bemba Image Grounded Conversations), a large multimodal
dataset for Bemba. While Bemba is the most populous language of Zambia, it
exhibits a dearth of resources which render the development of language
technologies or language processing research almost impossible. The dataset is
comprised of multi-turn dialogues between Bemba speakers based on images,
transcribed and translated into English. There are more than 92,000
utterances/sentences, amounting to more than 180 hours of audio data with
corresponding transcriptions and English translations. We also provide
baselines on speech recognition (ASR), machine translation (MT) and speech
translation (ST) tasks, and sketch out other potential future multimodal uses
of our dataset. We hope that by making the dataset available to the research
community, this work will foster research and encourage collaboration across
the language, speech, and vision communities especially for languages outside
the "traditionally" used high-resourced ones. All data and code are publicly
available: https://github.com/csikasote/bigc.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coping with low data availability for social media crisis message categorisation. (arXiv:2305.17211v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17211">
<div class="article-summary-box-inner">
<span><p>During crisis situations, social media allows people to quickly share
information, including messages requesting help. This can be valuable to
emergency responders, who need to categorise and prioritise these messages
based on the type of assistance being requested. However, the high volume of
messages makes it difficult to filter and prioritise them without the use of
computational techniques. Fully supervised filtering techniques for crisis
message categorisation typically require a large amount of annotated training
data, but this can be difficult to obtain during an ongoing crisis and is
expensive in terms of time and labour to create.
</p>
<p>This thesis focuses on addressing the challenge of low data availability when
categorising crisis messages for emergency response. It first presents domain
adaptation as a solution for this problem, which involves learning a
categorisation model from annotated data from past crisis events (source
domain) and adapting it to categorise messages from an ongoing crisis event
(target domain). In many-to-many adaptation, where the model is trained on
multiple past events and adapted to multiple ongoing events, a multi-task
learning approach is proposed using pre-trained language models. This approach
outperforms baselines and an ensemble approach further improves performance...
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Images with Multimodal Language Models. (arXiv:2305.17216v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17216">
<div class="article-summary-box-inner">
<span><p>We propose a method to fuse frozen text-only large language models (LLMs)
with pre-trained image encoder and decoder models, by mapping between their
embedding spaces. Our model demonstrates a wide suite of multimodal
capabilities: image retrieval, novel image generation, and multimodal dialogue.
Ours is the first approach capable of conditioning on arbitrarily interleaved
image and text inputs to generate coherent image (and text) outputs. To achieve
strong performance on image generation, we propose an efficient mapping network
to ground the LLM to an off-the-shelf text-to-image generation model. This
mapping network translates hidden representations of text into the embedding
space of the visual models, enabling us to leverage the strong text
representations of the LLM for visual outputs. Our approach outperforms
baseline generation models on tasks with longer and more complex language. In
addition to novel image generation, our model is also capable of image
retrieval from a prespecified dataset, and decides whether to retrieve or
generate at inference time. This is done with a learnt decision module which
conditions on the hidden representations of the LLM. Our model exhibits a wider
range of capabilities compared to prior multimodal language models. It can
process image-and-text inputs, and produce retrieved images, generated images,
and generated text -- outperforming non-LLM based generation models across
several text-to-image tasks that measure context dependence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GVdoc: Graph-based Visual Document Classification. (arXiv:2305.17219v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17219">
<div class="article-summary-box-inner">
<span><p>The robustness of a model for real-world deployment is decided by how well it
performs on unseen data and distinguishes between in-domain and out-of-domain
samples. Visual document classifiers have shown impressive performance on
in-distribution test sets. However, they tend to have a hard time correctly
classifying and differentiating out-of-distribution examples. Image-based
classifiers lack the text component, whereas multi-modality transformer-based
models face the token serialization problem in visual documents due to their
diverse layouts. They also require a lot of computing power during inference,
making them impractical for many real-world applications. We propose, GVdoc, a
graph-based document classification model that addresses both of these
challenges. Our approach generates a document graph based on its layout, and
then trains a graph neural network to learn node and graph embeddings. Through
experiments, we show that our model, even with fewer parameters, outperforms
state-of-the-art models on out-of-distribution data while retaining comparable
performance on the in-distribution test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Federated Learning for Semantic Parsing: Task Formulation, Evaluation Setup, New Algorithms. (arXiv:2305.17221v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17221">
<div class="article-summary-box-inner">
<span><p>This paper studies a new task of federated learning (FL) for semantic
parsing, where multiple clients collaboratively train one global model without
sharing their semantic parsing data. By leveraging data from multiple clients,
the FL paradigm can be especially beneficial for clients that have little
training data to develop a data-hungry neural semantic parser on their own. We
propose an evaluation setup to study this task, where we re-purpose widely-used
single-domain text-to-SQL datasets as clients to form a realistic heterogeneous
FL setting and collaboratively train a global model. As standard FL algorithms
suffer from the high client heterogeneity in our realistic setup, we further
propose a novel LOss Reduction Adjusted Re-weighting (Lorar) mechanism to
mitigate the performance degradation, which adjusts each client's contribution
to the global model update based on its training loss reduction during each
round. Our intuition is that the larger the loss reduction, the further away
the current global model is from the client's local optimum, and the larger
weight the client should get. By applying Lorar to three widely adopted FL
algorithms (FedAvg, FedOPT and FedProx), we observe that their performance can
be improved substantially on average (4%-20% absolute gain under MacroAvg) and
that clients with smaller datasets enjoy larger performance gains. In addition,
the global model converges faster for almost all the clients.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning. (arXiv:2305.17256v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17256">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have recently shown great potential for
in-context learning, where LLMs learn a new task simply by conditioning on a
few input-label pairs (prompts). Despite their potential, our understanding of
the factors influencing end-task performance and the robustness of in-context
learning remains limited. This paper aims to bridge this knowledge gap by
investigating the reliance of LLMs on shortcuts or spurious correlations within
prompts. Through comprehensive experiments on classification and extraction
tasks, we reveal that LLMs are "lazy learners" that tend to exploit shortcuts
in prompts for downstream tasks. Additionally, we uncover a surprising finding
that larger models are more likely to utilize shortcuts in prompts during
inference. Our findings provide a new perspective on evaluating robustness in
in-context learning and pose new challenges for detecting and mitigating the
use of shortcuts in prompts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Honey, I Shrunk the Language: Language Model Behavior at Reduced Scale. (arXiv:2305.17266v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17266">
<div class="article-summary-box-inner">
<span><p>In recent years, language models have drastically grown in size, and the
abilities of these models have been shown to improve with scale. The majority
of recent scaling laws studies focused on high-compute high-parameter count
settings, leaving the question of when these abilities begin to emerge largely
unanswered. In this paper, we investigate whether the effects of pre-training
can be observed when the problem size is reduced, modeling a smaller,
reduced-vocabulary language. We show the benefits of pre-training with masked
language modeling (MLM) objective in models as small as 1.25M parameters, and
establish a strong correlation between pre-training perplexity and downstream
performance (GLUE benchmark). We examine downscaling effects, extending scaling
laws to models as small as ~1M parameters. At this scale, we observe a break of
the power law for compute-optimal models and show that the MLM loss does not
scale smoothly with compute-cost (FLOPs) below $2.2 \times 10^{15}$ FLOPs. We
also find that adding layers does not always benefit downstream performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CODET: A Benchmark for Contrastive Dialectal Evaluation of Machine Translation. (arXiv:2305.17267v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17267">
<div class="article-summary-box-inner">
<span><p>Neural machine translation (NMT) systems exhibit limited robustness in
handling source-side linguistic variations. Their performance tends to degrade
when faced with even slight deviations in language usage, such as different
domains or variations introduced by second-language speakers. It is intuitive
to extend this observation to encompass dialectal variations as well, but the
work allowing the community to evaluate MT systems on this dimension is
limited. To alleviate this issue, we compile and release \dataset, a
contrastive dialectal benchmark encompassing 882 different variations from nine
different languages. We also quantitatively demonstrate the challenges large MT
models face in effectively translating dialectal variants. We are releasing all
code and data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Metaphor Detection via Explicit Basic Meanings Modelling. (arXiv:2305.17268v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17268">
<div class="article-summary-box-inner">
<span><p>One noticeable trend in metaphor detection is the embrace of linguistic
theories such as the metaphor identification procedure (MIP) for model
architecture design. While MIP clearly defines that the metaphoricity of a
lexical unit is determined based on the contrast between its \textit{contextual
meaning} and its \textit{basic meaning}, existing work does not strictly follow
this principle, typically using the \textit{aggregated meaning} to approximate
the basic meaning of target words. In this paper, we propose a novel metaphor
detection method, which models the basic meaning of the word based on literal
annotation from the training set, and then compares this with the contextual
meaning in a target sentence to identify metaphors. Empirical results show that
our method outperforms the state-of-the-art method significantly by 1.0\% in F1
score. Moreover, our performance even reaches the theoretical upper bound on
the VUA18 benchmark for targets with basic annotations, which demonstrates the
importance of modelling basic meanings for metaphor detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Slide, Constrain, Parse, Repeat: Synchronous SlidingWindows for Document AMR Parsing. (arXiv:2305.17273v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17273">
<div class="article-summary-box-inner">
<span><p>The sliding window approach provides an elegant way to handle contexts of
sizes larger than the Transformer's input window, for tasks like language
modeling. Here we extend this approach to the sequence-to-sequence task of
document parsing. For this, we exploit recent progress in transition-based
parsing to implement a parser with synchronous sliding windows over source and
target. We develop an oracle and a parser for document-level AMR by expanding
on Structured-BART such that it leverages source-target alignments and
constrains decoding to guarantee synchronicity and consistency across
overlapping windows. We evaluate our oracle and parser using the Abstract
Meaning Representation (AMR) parsing 3.0 corpus. On the Multi-Sentence
development set of AMR 3.0, we show that our transition oracle loses only 8\%
of the gold cross-sentential links despite using a sliding window. In practice,
this approach also results in a high-quality document-level parser with
manageable memory requirements. Our proposed system performs on par with the
state-of-the-art pipeline approach for document-level AMR parsing task on
Multi-Sentence AMR 3.0 corpus while maintaining sentence-level parsing
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved Instruction Ordering in Recipe-Grounded Conversation. (arXiv:2305.17280v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17280">
<div class="article-summary-box-inner">
<span><p>In this paper, we study the task of instructional dialogue and focus on the
cooking domain. Analyzing the generated output of the GPT-J model, we reveal
that the primary challenge for a recipe-grounded dialog system is how to
provide the instructions in the correct order. We hypothesize that this is due
to the model's lack of understanding of user intent and inability to track the
instruction state (i.e., which step was last instructed). Therefore, we propose
to explore two auxiliary subtasks, namely User Intent Detection and Instruction
State Tracking, to support Response Generation with improved instruction
grounding. Experimenting with our newly collected dataset, ChattyChef, shows
that incorporating user intent and instruction state information helps the
response generation model mitigate the incorrect order issue. Furthermore, to
investigate whether ChatGPT has completely solved this task, we analyze its
outputs and find that it also makes mistakes (10.7% of the responses), about
half of which are out-of-order instructions. We will release ChattyChef to
facilitate further research in this area at:
https://github.com/octaviaguo/ChattyChef.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">External Language Model Integration for Factorized Neural Transducers. (arXiv:2305.17304v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17304">
<div class="article-summary-box-inner">
<span><p>We propose an adaptation method for factorized neural transducers (FNT) with
external language models. We demonstrate that both neural and n-gram external
LMs add significantly more value when linearly interpolated with predictor
output compared to shallow fusion, thus confirming that FNT forces the
predictor to act like regular language models. Further, we propose a method to
integrate class-based n-gram language models into FNT framework resulting in
accuracy gains similar to a hybrid setup. We show average gains of 18% WERR
with lexical adaptation across various scenarios and additive gains of up to
60% WERR in one entity-rich scenario through a combination of class-based
n-gram and neural LMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance. (arXiv:2305.17306v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17306">
<div class="article-summary-box-inner">
<span><p>As large language models (LLMs) are continuously being developed, their
evaluation becomes increasingly important yet challenging. This work proposes
Chain-of-Thought Hub, an open-source evaluation suite on the multi-step
reasoning capabilities of large language models. We are interested in this
setting for two reasons: (1) from the behavior of GPT and PaLM model family, we
observe that complex reasoning is likely to be a key differentiator between
weaker and stronger LLMs; (2) we envisage large language models to become the
next-generation computational platform and foster an ecosystem of LLM-based new
applications, this naturally requires the foundation models to perform complex
tasks that often involve the composition of linguistic and logical operations.
Our approach is to compile a suite of challenging reasoning benchmarks to track
the progress of LLMs. Our current results show that: (1) model scale clearly
correlates with reasoning capabilities; (2) As of May 2023, Claude-v1.3 and
PaLM-2 are the only two models that are comparable with GPT-4, while
open-sourced models still lag behind; (3) LLaMA-65B performs closely to
code-davinci-002, indicating that with successful further development such as
reinforcement learning from human feedback (RLHF), it has great potential to be
close to GPT-3.5-Turbo. Our results also suggest that for the open-source
efforts to catch up, the community may focus more on building better base
models and exploring RLHF.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Positive Scaling: How Negation Impacts Scaling Trends of Language Models. (arXiv:2305.17311v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17311">
<div class="article-summary-box-inner">
<span><p>Language models have been shown to exhibit positive scaling, where
performance improves as models are scaled up in terms of size, compute, or
data. In this work, we introduce NeQA, a dataset consisting of questions with
negation in which language models do not exhibit straightforward positive
scaling. We show that this task can exhibit inverse scaling, U-shaped scaling,
or positive scaling, and the three scaling trends shift in this order as we use
more powerful prompting methods or model families. We hypothesize that solving
NeQA depends on two subtasks: question answering (task 1) and negation
understanding (task 2). We find that task 1 has linear scaling, while task 2
has sigmoid-shaped scaling with an emergent transition point, and composing
these two scaling trends yields the final scaling trend of NeQA. Our work
reveals and provides a way to analyze the complex scaling trends of language
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Why Does Zero-Shot Cross-Lingual Generation Fail? An Explanation and a Solution. (arXiv:2305.17325v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17325">
<div class="article-summary-box-inner">
<span><p>Zero-shot cross-lingual transfer is when a multilingual model is trained to
perform a task in one language and then is applied to another language.
Although the zero-shot cross-lingual transfer approach has achieved success in
various classification tasks, its performance on natural language generation
tasks falls short in quality and sometimes outputs an incorrect language. In
our study, we show that the fine-tuning process learns language invariant
representations, which is beneficial for classification tasks but harmful for
generation tasks. Motivated by this, we propose a simple method to regularize
the model from learning language invariant representations and a method to
select model checkpoints without a development set in the target language, both
resulting in better generation quality. Experiments on three semantically
diverse generation tasks show that our method reduces the accidental
translation problem by 68% and improves the ROUGE-L score by 1.5 on average.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In. (arXiv:2305.17331v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17331">
<div class="article-summary-box-inner">
<span><p>Retrieval augmentation can aid language models (LMs) in knowledge-intensive
tasks by supplying them with external information. Prior works on retrieval
augmentation usually jointly fine-tune the retriever and the LM, making them
closely coupled. In this paper, we explore the scheme of generic retrieval
plug-in: the retriever is to assist target LMs that may not be known beforehand
or are unable to be fine-tuned together. To retrieve useful documents for
unseen target LMs, we propose augmentation-adapted retriever (AAR), which
learns LM's preferences obtained from a known source LM. Experiments on the
MMLU and PopQA datasets demonstrate that our AAR trained with a small source LM
is able to significantly improve the zero-shot generalization of larger target
LMs ranging from 250M Flan-T5 to 175B InstructGPT. Further analysis indicates
that the preferences of different LMs overlap, enabling AAR trained with a
single source LM to serve as a generic plug-in for various target LMs. Our code
is open-sourced at https://github.com/OpenMatch/Augmentation-Adapted-Retriever.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-Tuning Language Models with Just Forward Passes. (arXiv:2305.17333v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17333">
<div class="article-summary-box-inner">
<span><p>Fine-tuning language models (LMs) has yielded success on diverse downstream
tasks, but as LMs grow in size, backpropagation requires a prohibitively large
amount of memory. Zeroth-order (ZO) methods can in principle estimate gradients
using only two forward passes but are theorized to be catastrophically slow for
optimizing large models. In this work, we propose a memory-efficient
zerothorder optimizer (MeZO), adapting the classical ZO-SGD method to operate
in-place, thereby fine-tuning LMs with the same memory footprint as inference.
For example, with a single A100 80GB GPU, MeZO can train a 30-billion parameter
model, whereas fine-tuning with backpropagation can train only a 2.7B LM with
the same budget. We conduct comprehensive experiments across model types
(masked and autoregressive LMs), model scales (up to 66B), and downstream tasks
(classification, multiple-choice, and generation). Our results demonstrate that
(1) MeZO significantly outperforms in-context learning and linear probing; (2)
MeZO achieves comparable performance to fine-tuning with backpropagation across
multiple tasks, with up to 12x memory reduction; (3) MeZO is compatible with
both full-parameter and parameter-efficient tuning techniques such as LoRA and
prefix tuning; (4) MeZO can effectively optimize non-differentiable objectives
(e.g., maximizing accuracy or F1). We support our empirical findings with
theoretical insights, highlighting how adequate pre-training and task prompts
enable MeZO to fine-tune huge models, despite classical ZO analyses suggesting
otherwise.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmarking Diverse-Modal Entity Linking with Generative Models. (arXiv:2305.17337v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17337">
<div class="article-summary-box-inner">
<span><p>Entities can be expressed in diverse formats, such as texts, images, or
column names and cell values in tables. While existing entity linking (EL)
models work well on per modality configuration, such as text-only EL, visual
grounding, or schema linking, it is more challenging to design a unified model
for diverse modality configurations. To bring various modality configurations
together, we constructed a benchmark for diverse-modal EL (DMEL) from existing
EL datasets, covering all three modalities including text, image, and table. To
approach the DMEL task, we proposed a generative diverse-modal model (GDMM)
following a multimodal-encoder-decoder paradigm. Pre-training \Model with rich
corpora builds a solid foundation for DMEL without storing the entire KB for
inference. Fine-tuning GDMM builds a stronger DMEL baseline, outperforming
state-of-the-art task-specific EL models by 8.51 F1 score on average.
Additionally, extensive error analyses are conducted to highlight the
challenges of DMEL, facilitating future research on this task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QAMPARI: An Open-domain Question Answering Benchmark for Questions with Many Answers from Multiple Paragraphs. (arXiv:2205.12665v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12665">
<div class="article-summary-box-inner">
<span><p>Existing benchmarks for open-domain question answering (ODQA) typically focus
on questions whose answers can be extracted from a single paragraph. By
contrast, many natural questions, such as "What players were drafted by the
Brooklyn Nets?" have a list of answers. Answering such questions requires
retrieving and reading from many passages, in a large corpus. We introduce
QAMPARI, an ODQA benchmark, where question answers are lists of entities,
spread across many paragraphs. We created QAMPARI by (a) generating questions
with multiple answers from Wikipedia's knowledge graph and tables, (b)
automatically pairing answers with supporting evidence in Wikipedia paragraphs,
and (c) manually paraphrasing questions and validating each answer. We train
ODQA models from the retrieve-and-read family and find that QAMPARI is
challenging in terms of both passage retrieval and answer generation, reaching
an F1 score of 32.8 at best. Our results highlight the need for developing ODQA
models that handle a broad range of question types, including single and
multi-answer questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimizing Test-Time Query Representations for Dense Retrieval. (arXiv:2205.12680v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12680">
<div class="article-summary-box-inner">
<span><p>Recent developments of dense retrieval rely on quality representations of
queries and contexts from pre-trained query and context encoders. In this
paper, we introduce TOUR (Test-Time Optimization of Query Representations),
which further optimizes instance-level query representations guided by signals
from test-time retrieval results. We leverage a cross-encoder re-ranker to
provide fine-grained pseudo labels over retrieval results and iteratively
optimize query representations with gradient descent. Our theoretical analysis
reveals that TOUR can be viewed as a generalization of the classical Rocchio
algorithm for pseudo relevance feedback, and we present two variants that
leverage pseudo-labels as hard binary or soft continuous labels. We first apply
TOUR on phrase retrieval with our proposed phrase re-ranker, and also evaluate
its effectiveness on passage retrieval with an off-the-shelf re-ranker. TOUR
greatly improves end-to-end open-domain question answering accuracy, as well as
passage retrieval performance. TOUR also consistently improves direct
re-ranking by up to 2.0% while running 1.3-2.4x faster with an efficient
implementation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BITE: Textual Backdoor Attacks with Iterative Trigger Injection. (arXiv:2205.12700v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12700">
<div class="article-summary-box-inner">
<span><p>Backdoor attacks have become an emerging threat to NLP systems. By providing
poisoned training data, the adversary can embed a "backdoor" into the victim
model, which allows input instances satisfying certain textual patterns (e.g.,
containing a keyword) to be predicted as a target label of the adversary's
choice. In this paper, we demonstrate that it is possible to design a backdoor
attack that is both stealthy (i.e., hard to notice) and effective (i.e., has a
high attack success rate). We propose BITE, a backdoor attack that poisons the
training data to establish strong correlations between the target label and a
set of "trigger words". These trigger words are iteratively identified and
injected into the target-label instances through natural word-level
perturbations. The poisoned training data instruct the victim model to predict
the target label on inputs containing trigger words, forming the backdoor.
Experiments on four text classification datasets show that our proposed attack
is significantly more effective than baseline methods while maintaining decent
stealthiness, raising alarm on the usage of untrusted training data. We further
propose a defense method named DeBITE based on potential trigger word removal,
which outperforms existing methods in defending against BITE and generalizes
well to handling other backdoor attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MVP: Multi-task Supervised Pre-training for Natural Language Generation. (arXiv:2206.12131v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12131">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PLMs) have achieved remarkable success in
natural language generation (NLG) tasks. Up to now, most NLG-oriented PLMs are
pre-trained in an unsupervised manner using the large-scale general corpus. In
the meanwhile, an increasing number of models pre-trained with labeled data
(i.e. "supervised pre-training") showcase superior performance compared to
unsupervised pre-trained models. Motivated by the success of supervised
pre-training, we propose Multi-task superVised Pre-training (MVP) for natural
language generation. We collect a large-scale natural language generation
corpus, MVPCorpus, from $77$ datasets over $11$ diverse NLG tasks. Then we
unify these examples into a general text-to-text format to pre-train the text
generation model MVP in a supervised manner. For each task, we further
pre-train specific soft prompts to stimulate the model's capacity to perform a
specific task. Our MVP model can be seen as a practice that utilizes recent
instruction tuning on relatively small PLMs. Extensive experiments have
demonstrated the effectiveness and generality of our MVP model in a number of
NLG tasks, which achieves state-of-the-art performance on $13$ out of $17$
datasets, outperforming BART by $9.3\%$ and Flan-T5 by $5.8\%$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Generator-Ranker Learning for Natural Language Generation. (arXiv:2206.13974v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13974">
<div class="article-summary-box-inner">
<span><p>Generate-then-rank is a widely used mechanism for text generation, where a
generator produces multiple text candidates and a ranker chooses the best one
among the text candidates. However, existing methods usually train the
generator and the ranker individually, neglecting the mutual feedback that
could further enhance the generation quality. To tackle this limitation, we
propose JGR, a novel joint training algorithm that integrates the generator and
the ranker in a single framework. JGR optimizes the generator with a hybrid
objective that combines data likelihood and ranker reward, and trains the
ranker with a contrastive loss that compares the generator outputs. By
iteratively updating the generator and the ranker, JGR can effectively
harmonize their learning and enhance their quality jointly. We evaluate JGR on
various text generation tasks and demonstrate that it surpasses existing
methods on four public datasets across three common generation scenarios. Our
code and models are publicly available at
https://github.com/microsoft/ProphetNet/tree/master/JGR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Massively Multilingual Lexical Specialization of Multilingual Transformers. (arXiv:2208.01018v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.01018">
<div class="article-summary-box-inner">
<span><p>While pretrained language models (PLMs) primarily serve as general-purpose
text encoders that can be fine-tuned for a wide variety of downstream tasks,
recent work has shown that they can also be rewired to produce high-quality
word representations (i.e., static word embeddings) and yield good performance
in type-level lexical tasks. While existing work primarily focused on the
lexical specialization of monolingual PLMs with immense quantities of
monolingual constraints, in this work we expose massively multilingual
transformers (MMTs, e.g., mBERT or XLM-R) to multilingual lexical knowledge at
scale, leveraging BabelNet as the readily available rich source of multilingual
and cross-lingual type-level lexical knowledge. Concretely, we use BabelNet's
multilingual synsets to create synonym pairs (or synonym-gloss pairs) across 50
languages and then subject the MMTs (mBERT and XLM-R) to a lexical
specialization procedure guided by a contrastive objective. We show that such
massively multilingual lexical specialization brings substantial gains in two
standard cross-lingual lexical tasks, bilingual lexicon induction and
cross-lingual word similarity, as well as in cross-lingual sentence retrieval.
Crucially, we observe gains for languages unseen in specialization, indicating
that multilingual lexical specialization enables generalization to languages
with no lexical constraints. In a series of subsequent controlled experiments,
we show that the number of specialization constraints plays a much greater role
than the set of languages from which they originate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PaLI: A Jointly-Scaled Multilingual Language-Image Model. (arXiv:2209.06794v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.06794">
<div class="article-summary-box-inner">
<span><p>Effective scaling and a flexible task interface enable large language models
to excel at many tasks. We present PaLI (Pathways Language and Image model), a
model that extends this approach to the joint modeling of language and vision.
PaLI generates text based on visual and textual inputs, and with this interface
performs many vision, language, and multimodal tasks, in many languages. To
train PaLI, we make use of large pre-trained encoder-decoder language models
and Vision Transformers (ViTs). This allows us to capitalize on their existing
capabilities and leverage the substantial cost of training them. We find that
joint scaling of the vision and language components is important. Since
existing Transformers for language are much larger than their vision
counterparts, we train a large, 4-billion parameter ViT (ViT-e) to quantify the
benefits from even larger-capacity vision models. To train PaLI, we create a
large multilingual mix of pretraining tasks, based on a new image-text training
set containing 10B images and texts in over 100 languages. PaLI achieves
state-of-the-art in multiple vision and language tasks (such as captioning,
visual question-answering, scene-text understanding), while retaining a simple,
modular, and scalable design.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Whole Truth and Nothing But the Truth: Faithful and Controllable Dialogue Response Generation with Dataflow Transduction and Constrained Decoding. (arXiv:2209.07800v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.07800">
<div class="article-summary-box-inner">
<span><p>In a real-world dialogue system, generated text must be truthful and
informative while remaining fluent and adhering to a prescribed style.
Satisfying these constraints simultaneously is difficult for the two
predominant paradigms in language generation: neural language modeling and
rule-based generation. We describe a hybrid architecture for dialogue response
generation that combines the strengths of both paradigms. The first component
of this architecture is a rule-based content selection model defined using a
new formal framework called dataflow transduction, which uses declarative rules
to transduce a dialogue agent's actions and their results (represented as
dataflow graphs) into context-free grammars representing the space of
contextually acceptable responses. The second component is a constrained
decoding procedure that uses these grammars to constrain the output of a neural
language model, which selects fluent utterances. Our experiments show that this
system outperforms both rule-based and learned approaches in human evaluations
of fluency, relevance, and truthfulness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Augmentation Invariant Discrete Representation for Generative Spoken Language Modeling. (arXiv:2209.15483v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.15483">
<div class="article-summary-box-inner">
<span><p>Generative Spoken Language Modeling research focuses on optimizing speech
Language Models (LMs) using raw audio recordings without accessing any textual
supervision. Such speech LMs usually operate over discrete units obtained from
quantizing internal representations of self-supervised models. Although such
units show impressive modeling results, their robustness capabilities have not
been extensively investigated. This work focuses on improving the robustness of
discrete input representations for generative spoken language modeling. First,
we formally define how to measure the robustness of such representations to
various signal variations that do not alter the spoken information (e.g.,
time-stretch). Next, we empirically demonstrate how current state-of-the-art
representation models lack robustness to such variations. To overcome this, we
propose an effective and efficient method to learn robust discrete speech
representation for generative spoken language modeling. The proposed approach
is based on applying a set of signal transformations to the speech signal and
optimizing the model using an iterative pseudo-labeling scheme. Our method
significantly improves over the evaluated baselines when considering encoding
and modeling metrics. We additionally evaluate our method on the
speech-to-speech translation task, considering Spanish-English and
French-English translations, and show the proposed approach outperforms the
evaluated baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Annotation: Can Language Learners Contribute?. (arXiv:2210.06828v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06828">
<div class="article-summary-box-inner">
<span><p>Researchers have traditionally recruited native speakers to provide
annotations for widely used benchmark datasets. However, there are languages
for which recruiting native speakers can be difficult, and it would help to
find learners of those languages to annotate the data. In this paper, we
investigate whether language learners can contribute annotations to benchmark
datasets. In a carefully controlled annotation experiment, we recruit 36
language learners, provide two types of additional resources (dictionaries and
machine-translated sentences), and perform mini-tests to measure their language
proficiency. We target three languages, English, Korean, and Indonesian, and
the four NLP tasks of sentiment analysis, natural language inference, named
entity recognition, and machine reading comprehension. We find that language
learners, especially those with intermediate or advanced levels of language
proficiency, are able to provide fairly accurate labels with the help of
additional resources. Moreover, we show that data annotation improves learners'
language proficiency in terms of vocabulary and grammar. One implication of our
findings is that broadening the annotation task to include language learners
can open up the opportunity to build benchmark datasets for languages for which
it is difficult to recruit native speakers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dense-ATOMIC: Towards Densely-connected ATOMIC with High Knowledge Coverage and Massive Multi-hop Paths. (arXiv:2210.07621v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07621">
<div class="article-summary-box-inner">
<span><p>ATOMIC is a large-scale commonsense knowledge graph (CSKG) containing
everyday if-then knowledge triplets, i.e., {head event, relation, tail event}.
The one-hop annotation manner made ATOMIC a set of independent bipartite
graphs, which ignored the numerous links between events in different bipartite
graphs and consequently caused shortages in knowledge coverage and multi-hop
paths. In this work, we aim to construct Dense-ATOMIC with high knowledge
coverage and massive multi-hop paths. The events in ATOMIC are normalized to a
consistent pattern at first. We then propose a CSKG completion method called
Rel-CSKGC to predict the relation given the head event and the tail event of a
triplet, and train a CSKG completion model based on existing triplets in
ATOMIC. We finally utilize the model to complete the missing links in ATOMIC
and accordingly construct Dense-ATOMIC. Both automatic and human evaluation on
an annotated subgraph of ATOMIC demonstrate the advantage of Rel-CSKGC over
strong baselines. We further conduct extensive evaluations on Dense-ATOMIC in
terms of statistics, human evaluation, and simple downstream tasks, all proving
Dense-ATOMIC's advantages in Knowledge Coverage and Multi-hop Paths. Both the
source code of Rel-CSKGC and Dense-ATOMIC are publicly available on
https://github.com/NUSTM/Dense-ATOMIC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Solving Math Word Problems via Cooperative Reasoning induced Language Models. (arXiv:2210.16257v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.16257">
<div class="article-summary-box-inner">
<span><p>Large-scale pre-trained language models (PLMs) bring new opportunities to
challenging problems, especially those that need high-level intelligence, such
as the math word problem (MWPs). However, directly applying existing PLMs to
MWPs can fail as the generation process lacks sufficient supervision and thus
lacks fast adaptivity as humans. We notice that human reasoning has a dual
reasoning framework that consists of an immediate reaction system (system 1)
and a delicate reasoning system (system 2), where the entire reasoning is
determined by their interaction. This inspires us to develop a cooperative
reasoning-induced PLM for solving MWPs, called Cooperative Reasoning (CoRe),
resulting in a human-like reasoning architecture with system 1 as the generator
and system 2 as the verifier. In our approach, the generator is responsible for
generating reasoning paths, and the verifiers are used to supervise the
evaluation in order to obtain reliable feedback for the generator. We evaluate
our CoRe framework on several mathematical reasoning datasets and achieve
decent improvement over state-of-the-art methods, up to 9.6% increase over best
baselines. Our codes are available at https://github.com/TianHongZXY/CoRe
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Crosslingual Generalization through Multitask Finetuning. (arXiv:2211.01786v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.01786">
<div class="article-summary-box-inner">
<span><p>Multitask prompted finetuning (MTF) has been shown to help large language
models generalize to new tasks in a zero-shot setting, but so far explorations
of MTF have focused on English data and models. We apply MTF to the pretrained
multilingual BLOOM and mT5 model families to produce finetuned variants called
BLOOMZ and mT0. We find finetuning large multilingual language models on
English tasks with English prompts allows for task generalization to
non-English languages that appear only in the pretraining corpus. Finetuning on
multilingual tasks with English prompts further improves performance on English
and non-English tasks leading to various state-of-the-art zero-shot results. We
also investigate finetuning on multilingual tasks with prompts that have been
machine-translated from English to match the language of each dataset. We find
training on these machine-translated prompts leads to better performance on
human-written prompts in the respective languages. Surprisingly, we find models
are capable of zero-shot generalization to tasks in languages they have never
intentionally seen. We conjecture that the models are learning higher-level
capabilities that are both task- and language-agnostic. In addition, we
introduce xP3, a composite of supervised datasets in 46 languages with English
and machine-translated prompts. Our code, datasets and models are freely
available at https://github.com/bigscience-workshop/xmtf.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">lilGym: Natural Language Visual Reasoning with Reinforcement Learning. (arXiv:2211.01994v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.01994">
<div class="article-summary-box-inner">
<span><p>We present lilGym, a new benchmark for language-conditioned reinforcement
learning in visual environments. lilGym is based on 2,661 highly-compositional
human-written natural language statements grounded in an interactive visual
environment. We introduce a new approach for exact reward computation in every
possible world state by annotating all statements with executable Python
programs. Each statement is paired with multiple start states and reward
functions to form thousands of distinct Markov Decision Processes of varying
difficulty. We experiment with lilGym with different models and learning
regimes. Our results and analysis show that while existing methods are able to
achieve non-trivial performance, lilGym forms a challenging open problem.
lilGym is available at https://lil.nlp.cornell.edu/lilgym/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">mOKB6: A Multilingual Open Knowledge Base Completion Benchmark. (arXiv:2211.06959v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.06959">
<div class="article-summary-box-inner">
<span><p>Automated completion of open knowledge bases (Open KBs), which are
constructed from triples of the form (subject phrase, relation phrase, object
phrase), obtained via open information extraction (Open IE) system, are useful
for discovering novel facts that may not be directly present in the text.
However, research in Open KB completion (Open KBC) has so far been limited to
resource-rich languages like English. Using the latest advances in multilingual
Open IE, we construct the first multilingual Open KBC dataset, called mOKB6,
containing facts from Wikipedia in six languages (including English). Improving
the previous Open KB construction pipeline by doing multilingual coreference
resolution and keeping only entity-linked triples, we create a dense Open KB.
We experiment with several models for the task and observe a consistent benefit
of combining languages with the help of shared embedding space as well as
translations of facts. We also observe that current multilingual models
struggle to remember facts seen in languages of different scripts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UniSumm and SummZoo: Unified Model and Diverse Benchmark for Few-Shot Summarization. (arXiv:2211.09783v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09783">
<div class="article-summary-box-inner">
<span><p>The high annotation costs and diverse demands of various summarization tasks
motivate the development of few-shot summarization. However, despite the
emergence of many summarization tasks and datasets, the current training
paradigm for few-shot summarization systems ignores potentially shareable
knowledge in heterogeneous datasets. To this end, we propose \textsc{UniSumm},
a unified few-shot summarization model pre-trained with multiple summarization
tasks and can be prefix-tuned to excel at any few-shot summarization task.
Meanwhile, to better evaluate few-shot summarizers, under the principles of
diversity and robustness, we assemble and release a new benchmark
\textsc{SummZoo}. It consists of $8$ summarization tasks with multiple sets of
few-shot samples for each task, covering diverse domains. Experimental results
and analysis show that \textsc{UniSumm} outperforms strong baselines by a large
margin across all sub-tasks in \textsc{SummZoo} under both automatic and human
evaluations and achieves comparable results in human evaluation compared with a
GPT-3.5 model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controlling Styles in Neural Machine Translation with Activation Prompt. (arXiv:2212.08909v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.08909">
<div class="article-summary-box-inner">
<span><p>Controlling styles in neural machine translation (NMT) has attracted wide
attention, as it is crucial for enhancing user experience. Earlier studies on
this topic typically concentrate on regulating the level of formality and
achieve some progress in this area. However, they still encounter two major
challenges. The first is the difficulty in style evaluation. The style
comprises various aspects such as lexis, syntax, and others that provide
abundant information. Nevertheless, only formality has been thoroughly
investigated. The second challenge involves excessive dependence on incremental
adjustments, particularly when new styles are necessary. To address both
challenges, this paper presents a new benchmark and approach. A multiway
stylized machine translation (MSMT) benchmark is introduced, incorporating
diverse categories of styles across four linguistic domains. Then, we propose a
method named style activation prompt (StyleAP) by retrieving prompts from
stylized monolingual corpus, which does not require extra fine-tuning.
Experiments show that StyleAP could effectively control the style of
translation and achieve remarkable performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling Instance Interactions for Joint Information Extraction with Neural High-Order Conditional Random Field. (arXiv:2212.08929v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.08929">
<div class="article-summary-box-inner">
<span><p>Prior works on joint Information Extraction (IE) typically model instance
(e.g., event triggers, entities, roles, relations) interactions by
representation enhancement, type dependencies scoring, or global decoding. We
find that the previous models generally consider binary type dependency scoring
of a pair of instances, and leverage local search such as beam search to
approximate global solutions. To better integrate cross-instance interactions,
in this work, we introduce a joint IE framework (CRFIE) that formulates joint
IE as a high-order Conditional Random Field. Specifically, we design binary
factors and ternary factors to directly model interactions between not only a
pair of instances but also triplets. Then, these factors are utilized to
jointly predict labels of all instances. To address the intractability problem
of exact high-order inference, we incorporate a high-order neural decoder that
is unfolded from a mean-field variational inference method, which achieves
consistent learning and inference. The experimental results show that our
approach achieves consistent improvements on three IE tasks compared with our
baseline and prior work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Isotropy, Contextualization and Learning Dynamics of Contrastive-based Sentence Representation Learning. (arXiv:2212.09170v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09170">
<div class="article-summary-box-inner">
<span><p>Incorporating contrastive learning objectives in sentence representation
learning (SRL) has yielded significant improvements on many sentence-level NLP
tasks. However, it is not well understood why contrastive learning works for
learning sentence-level semantics. In this paper, we aim to help guide future
designs of sentence representation learning methods by taking a closer look at
contrastive SRL through the lens of isotropy, contextualization and learning
dynamics. We interpret its successes through the geometry of the representation
shifts and show that contrastive learning brings isotropy, and drives high
intra-sentence similarity: when in the same sentence, tokens converge to
similar positions in the semantic space. We also find that what we formalize as
"spurious contextualization" is mitigated for semantically meaningful tokens,
while augmented for functional ones. We find that the embedding space is
directed towards the origin during training, with more areas now better
defined. We ablate these findings by observing the learning dynamics with
different training temperatures, batch sizes and pooling methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PAL: Persona-Augmented Emotional Support Conversation Generation. (arXiv:2212.09235v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09235">
<div class="article-summary-box-inner">
<span><p>Due to the lack of human resources for mental health support, there is an
increasing demand for employing conversational agents for support. Recent work
has demonstrated the effectiveness of dialogue models in providing emotional
support. As previous studies have demonstrated that seekers' persona is an
important factor for effective support, we investigate whether there are
benefits to modeling such information in dialogue models for support. In this
paper, our empirical analysis verifies that persona has an important impact on
emotional support. Therefore, we propose a framework for dynamically inferring
and modeling seekers' persona. We first train a model for inferring the
seeker's persona from the conversation history. Accordingly, we propose PAL, a
model that leverages persona information and, in conjunction with our
strategy-based controllable generation method, provides personalized emotional
support. Automatic and manual evaluations demonstrate that PAL achieves
state-of-the-art results, outperforming the baselines on the studied benchmark.
Our code and data are publicly available at https://github.com/chengjl19/PAL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Extensible Plug-and-Play Method for Multi-Aspect Controllable Text Generation. (arXiv:2212.09387v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09387">
<div class="article-summary-box-inner">
<span><p>Recently, multi-aspect controllable text generation that controls the
generated text in multiple aspects (e.g., sentiment, topic, and keywords) has
attracted increasing attention. Although methods based on parameter efficient
tuning like prefix-tuning could achieve multi-aspect controlling in a
plug-and-play way, the mutual interference of multiple prefixes leads to
significant degeneration of constraints and limits their extensibility to
training-time unseen aspect combinations. In this work, we provide a
theoretical lower bound for the interference and empirically found that the
interference grows with the number of layers where prefixes are inserted. Based
on these analyses, we propose using trainable gates to normalize the
intervention of prefixes to restrain the growing interference. As a result,
controlling training-time unseen combinations of aspects can be realized by
simply concatenating corresponding plugins such that new constraints can be
extended at a lower cost. In addition, we propose a unified way to process both
categorical and free-form constraints. Experiments on text generation and
machine translation demonstrate the superiority of our approach over baselines
on constraint accuracy, text quality, and extensibility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BLOOM+1: Adding Language Support to BLOOM for Zero-Shot Prompting. (arXiv:2212.09535v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09535">
<div class="article-summary-box-inner">
<span><p>The BLOOM model is a large publicly available multilingual language model,
but its pretraining was limited to 46 languages. To extend the benefits of
BLOOM to other languages without incurring prohibitively large costs, it is
desirable to adapt BLOOM to new languages not seen during pretraining. In this
work, we apply existing language adaptation strategies to BLOOM and benchmark
its zero-shot prompting performance on eight new languages in a
resource-constrained setting. We find language adaptation to be effective at
improving zero-shot performance in new languages. Surprisingly, we find that
adapter-based finetuning is more effective than continued pretraining for large
models. In addition, we discover that prompting performance is not
significantly affected by language specifics, such as the writing system. It is
primarily determined by the size of the language adaptation data. We also add
new languages to BLOOMZ, which is a multitask finetuned version of BLOOM
capable of following task instructions zero-shot. We find including a new
language in the multitask fine-tuning mixture to be the most effective method
to teach BLOOMZ a new language. We conclude that with sufficient training data
language adaptation can generalize well to diverse languages. Our code is
available at https://github.com/bigscience-workshop/multilingual-modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09597">
<div class="article-summary-box-inner">
<span><p>Reasoning, as an essential ability for complex problem-solving, can provide
back-end support for various real-world applications, such as medical
diagnosis, negotiation, etc. This paper provides a comprehensive survey of
cutting-edge research on reasoning with language model prompting. We introduce
research works with comparisons and summaries and provide systematic resources
to help beginners. We also discuss the potential reasons for emerging such
reasoning abilities and highlight future research directions. Resources are
available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated
periodically).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training Trajectories of Language Models Across Scales. (arXiv:2212.09803v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09803">
<div class="article-summary-box-inner">
<span><p>Scaling up language models has led to unprecedented performance gains, but
little is understood about how the training dynamics change as models get
larger. How do language models of different sizes learn during pre-training?
Why do larger language models demonstrate more desirable behaviors? In this
paper, we analyze the intermediate training checkpoints of differently sized
OPT models (Zhang et al.,2022)--from 125M to 175B parameters--on next-token
prediction, sequence-level generation, and downstream tasks. We find that 1) at
a given perplexity and independent of model sizes, a similar subset of training
tokens see the most significant reduction in loss, with the rest stagnating or
showing double-descent behavior; 2) early in training, all models learn to
reduce the perplexity of grammatical sequences that contain hallucinations,
with small models halting at this suboptimal distribution and larger ones
eventually learning to assign these sequences lower probabilities; 3)
perplexity is a strong predictor of in-context learning performance on 74
multiple-choice tasks from BIG-Bench, and this holds independent of the model
size. Together, these results show that perplexity is more predictive of model
behaviors than model size or training computation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WeCheck: Strong Factual Consistency Checker via Weakly Supervised Learning. (arXiv:2212.10057v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10057">
<div class="article-summary-box-inner">
<span><p>A crucial issue of current text generation models is that they often
uncontrollably generate factually inconsistent text with respective of their
inputs. Limited by the lack of annotated data, existing works in evaluating
factual consistency directly transfer the reasoning ability of models trained
on other data-rich upstream tasks like question answering (QA) and natural
language inference (NLI) without any further adaptation. As a result, they
perform poorly on the real generated text and are biased heavily by their
single-source upstream tasks. To alleviate this problem, we propose a weakly
supervised framework that aggregates multiple resources to train a precise and
efficient factual metric, namely WeCheck. WeCheck first utilizes a generative
model to accurately label a real generated sample by aggregating its weak
labels, which are inferred from multiple resources. Then, we train the target
metric model with the weak supervision while taking noises into consideration.
Comprehensive experiments on a variety of tasks demonstrate the strong
performance of WeCheck, which achieves a 3.4\% absolute improvement over
previous state-of-the-art methods on TRUE benchmark on average.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DOC: Improving Long Story Coherence With Detailed Outline Control. (arXiv:2212.10077v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10077">
<div class="article-summary-box-inner">
<span><p>We propose the Detailed Outline Control (DOC) framework for improving
long-range plot coherence when automatically generating
several-thousand-word-long stories. DOC consists of two complementary
components: a detailed outliner and a detailed controller. The detailed
outliner creates a more detailed, hierarchically structured outline, shifting
creative burden from the main drafting procedure to the planning stage. The
detailed controller ensures the more detailed outline is still respected during
generation by controlling story passages to align with outline details. In
human evaluations of automatically generated stories, DOC substantially
outperforms a strong Re3 baseline (Yang et al., 2022) on plot coherence (22.5%
absolute gain), outline relevance (28.2%), and interestingness (20.7%). Humans
also judged DOC to be much more controllable in an interactive generation
setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Naamapadam: A Large-Scale Named Entity Annotated Data for Indic Languages. (arXiv:2212.10168v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10168">
<div class="article-summary-box-inner">
<span><p>We present, Naamapadam, the largest publicly available Named Entity
Recognition (NER) dataset for the 11 major Indian languages from two language
families. The dataset contains more than 400k sentences annotated with a total
of at least 100k entities from three standard entity categories (Person,
Location, and, Organization) for 9 out of the 11 languages. The training
dataset has been automatically created from the Samanantar parallel corpus by
projecting automatically tagged entities from an English sentence to the
corresponding Indian language translation. We also create manually annotated
testsets for 9 languages. We demonstrate the utility of the obtained dataset on
the Naamapadam-test dataset. We also release IndicNER, a multilingual IndicBERT
model fine-tuned on Naamapadam training set. IndicNER achieves an F1 score of
more than $80$ for $7$ out of $9$ test languages. The dataset and models are
available under open-source licences at
https://ai4bharat.iitm.ac.in/naamapadam.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories. (arXiv:2212.10511v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10511">
<div class="article-summary-box-inner">
<span><p>Despite their impressive performance on diverse tasks, large language models
(LMs) still struggle with tasks requiring rich world knowledge, implying the
limitations of relying solely on their parameters to encode a wealth of world
knowledge. This paper aims to understand LMs' strengths and limitations in
memorizing factual knowledge, by conducting large-scale knowledge probing
experiments of 10 models and 4 augmentation methods on PopQA, our new
open-domain QA dataset with 14k questions. We find that LMs struggle with less
popular factual knowledge, and that scaling fails to appreciably improve
memorization of factual knowledge in the long tail. We then show that
retrieval-augmented LMs largely outperform orders of magnitude larger LMs,
while unassisted LMs remain competitive in questions about high-popularity
entities. Based on those findings, we devise a simple, yet effective, method
for powerful and efficient retrieval-augmented LMs, which retrieves
non-parametric memories only when necessary. Experimental results show that
this significantly improves models' performance while reducing the inference
costs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detoxifying Text with MaRCo: Controllable Revision with Experts and Anti-Experts. (arXiv:2212.10543v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10543">
<div class="article-summary-box-inner">
<span><p>Text detoxification has the potential to mitigate the harms of toxicity by
rephrasing text to remove offensive meaning, but subtle toxicity remains
challenging to tackle. We introduce MaRCo, a detoxification algorithm that
combines controllable generation and text rewriting methods using a Product of
Experts with autoencoder language models (LMs). MaRCo uses likelihoods under a
non-toxic LM (expert) and a toxic LM (anti-expert) to find candidate words to
mask and potentially replace. We evaluate our method on several subtle toxicity
and microaggressions datasets, and show that it not only outperforms baselines
on automatic metrics, but MaRCo's rewrites are preferred 2.1 $\times$ more in
human evaluation. Its applicability to instances of subtle toxicity is
especially promising, demonstrating a path forward for addressing increasingly
elusive online hate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lego-MT: Towards Detachable Models in Massively Multilingual Machine Translation. (arXiv:2212.10551v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10551">
<div class="article-summary-box-inner">
<span><p>Multilingual neural machine translation (MNMT) aims to build a unified model
for many language directions. Existing monolithic models for MNMT encounter two
challenges: parameter interference among languages and inefficient inference
for large models. In this paper, we revisit the classic multi-way structures
and develop a detachable model by assigning each language (or group of
languages) to an individual branch that supports plug-and-play training and
inference. To address the needs of learning representations for all languages
in a unified space, we propose a novel efficient training recipe, upon which we
build an effective detachable model, Lego-MT. For a fair comparison, we collect
data from OPUS and build a translation benchmark covering 433 languages and
1.3B parallel data. Experiments show that Lego-MT with 1.2B parameters brings
an average gain of 3.2 spBLEU. It even outperforms M2M-100 with 12B parameters.
The proposed training recipe brings a 28.2$\times$ speedup over the
conventional multi-way training method.\footnote{
\url{https://github.com/CONE-MT/Lego-MT}.}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parsel: Algorithmic Reasoning with Language Models by Composing Decompositions. (arXiv:2212.10561v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10561">
<div class="article-summary-box-inner">
<span><p>Despite recent success in large language model (LLM) reasoning, LLMs struggle
with hierarchical multi-step reasoning tasks like generating complex programs.
For these tasks, humans often start with a high-level algorithmic design and
implement each part gradually. We introduce Parsel, a framework enabling
automatic implementation and validation of complex algorithms with code LLMs.
With Parsel, we automatically decompose algorithmic tasks into hierarchical
natural language function descriptions and then search over combinations of
possible function implementations using tests. We show that Parsel can be used
across domains requiring hierarchical reasoning, including program synthesis
and robotic planning. We find that, using Parsel, LLMs solve more
competition-level problems in the APPS dataset, resulting in pass rates over
75\% higher than prior results from directly sampling AlphaCode and Codex,
while often using a smaller sample budget. Moreover, with automatically
generated tests, we find that Parsel can improve the state-of-the-art pass@1
performance on HumanEval from 67\% to 85\%. We also find that LLM-generated
robotic plans using Parsel are more than twice as likely to be considered
accurate than directly generated plans. Lastly, we explore how Parsel addresses
LLM limitations and discuss how Parsel may be useful for human programmers. We
release our code at https://github.com/ezelikman/parsel
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SERENGETI: Massively Multilingual Language Models for Africa. (arXiv:2212.10785v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10785">
<div class="article-summary-box-inner">
<span><p>Multilingual pretrained language models (mPLMs) acquire valuable,
generalizable linguistic information during pretraining and have advanced the
state of the art on task-specific finetuning. To date, only ~31 out of ~2,000
African languages are covered in existing language models. We ameliorate this
limitation by developing SERENGETI, a massively multilingual language model
that covers 517 African languages and language varieties. We evaluate our novel
models on eight natural language understanding tasks across 20 datasets,
comparing to 4 mPLMs that cover 4-23 African languages. SERENGETI outperforms
other models on 11 datasets across the eights tasks, achieving 82.27 average
F_1. We also perform analyses of errors from our models, which allows us to
investigate the influence of language genealogy and linguistic similarity when
the models are applied under zero-shot settings. We will publicly release our
models for
research.\footnote{\href{https://github.com/UBC-NLP/serengeti}{https://github.com/UBC-NLP/serengeti}}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Resolving Indirect Referring Expressions for Entity Selection. (arXiv:2212.10933v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10933">
<div class="article-summary-box-inner">
<span><p>Recent advances in language modeling have enabled new conversational systems.
In particular, it is often desirable for people to make choices among specified
options when using such systems. We address this problem of reference
resolution, when people use natural expressions to choose between the entities.
For example, given the choice `Should we make a Simnel cake or a Pandan cake?'
a natural response from a dialog participant may be indirect: `let's make the
green one'. Such natural expressions have been little studied for reference
resolution. We argue that robustly understanding such language has large
potential for improving naturalness in dialog, recommendation, and search
systems. We create AltEntities (Alternative Entities), a new public dataset of
42K entity pairs and expressions (referring to one entity in the pair), and
develop models for the disambiguation problem. Consisting of indirect referring
expressions across three domains, our corpus enables for the first time the
study of how language models can be adapted to this task. We find they achieve
82%-87% accuracy in realistic settings, which while reasonable also invites
further advances.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Black-box language model explanation by context length probing. (arXiv:2212.14815v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.14815">
<div class="article-summary-box-inner">
<span><p>The increasingly widespread adoption of large language models has highlighted
the need for improving their explainability. We present context length probing,
a novel explanation technique for causal language models, based on tracking the
predictions of a model as a function of the length of available context, and
allowing to assign differential importance scores to different contexts. The
technique is model-agnostic and does not rely on access to model internals
beyond computing token-level probabilities. We apply context length probing to
large pre-trained language models and offer some initial analyses and insights,
including the potential for studying long-range dependencies. The source code
and an interactive demo of the method are available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Define, Evaluate, and Improve Task-Oriented Cognitive Capabilities for Instruction Generation Models. (arXiv:2301.05149v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.05149">
<div class="article-summary-box-inner">
<span><p>Recent work studies the cognitive capabilities of language models through
psychological tests designed for humans. While these studies are helpful for
understanding the general capabilities of these models, there is no guarantee
that a model possessing sufficient capabilities to pass those tests would
actually use those capabilities in performing real-life tasks. In this work, we
formulate task-oriented cognitive capabilities, which are human-like cognitive
capabilities that language models leverage to perform tasks. These capabilities
are (i) the ability to quickly generate good candidate utterances (the search
capability) (ii) the ability to predict how a listener interprets those
utterances and choose the most appropriate one (the pragmatic capability). We
design an evaluation scheme for comparing these capabilities of a language
model with those of a human. Applying this scheme to examine various models in
a navigation instruction generation problem, we find that their pragmatic
capability is severely lacking. This insight leads us to augment them with
better models of the listener and obtain a significant boost of 11% in success
rate in guiding real humans. Our work advocates for having a principled
procedure for aligning language models with humans that involves (i)
formulating task-oriented capabilities, (ii) devising a method to quantify
their deficiency, and (iii) iteratively improving them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Theme-driven Keyphrase Extraction to Analyze Social Media Discourse. (arXiv:2301.11508v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.11508">
<div class="article-summary-box-inner">
<span><p>Social media platforms are vital resources for sharing self-reported health
experiences, offering rich data on various health topics. Despite advancements
in Natural Language Processing (NLP) enabling large-scale social media data
analysis, a gap remains in applying keyphrase extraction to health-related
content. Keyphrase extraction is used to identify salient concepts in social
media discourse without being constrained by predefined entity classes. This
paper introduces a theme-driven keyphrase extraction framework tailored for
social media, a pioneering approach designed to capture clinically relevant
keyphrases from user-generated health texts. Themes are defined as broad
categories determined by the objectives of the extraction task. We formulate
this novel task of theme-driven keyphrase extraction and demonstrate its
potential for efficiently mining social media text for the use case of
treatment for opioid use disorder. This paper leverages qualitative and
quantitative analysis to demonstrate the feasibility of extracting actionable
insights from social media data and efficiently extracting keyphrases using
minimally supervised NLP models. Our contributions include the development of a
novel data collection and curation framework for theme-driven keyphrase
extraction and the creation of MOUD-Keyphrase, the first dataset of its kind
comprising human-annotated keyphrases from a Reddit community. We also identify
the scope of minimally supervised NLP models to extract keyphrases from social
media data efficiently. Lastly, we found that a large language model (ChatGPT)
outperforms unsupervised keyphrase extraction models, and we evaluate its
efficacy in this task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Speak from Text: Zero-Shot Multilingual Text-to-Speech with Unsupervised Text Pretraining. (arXiv:2301.12596v3 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.12596">
<div class="article-summary-box-inner">
<span><p>While neural text-to-speech (TTS) has achieved human-like natural synthetic
speech, multilingual TTS systems are limited to resource-rich languages due to
the need for paired text and studio-quality audio data. This paper proposes a
method for zero-shot multilingual TTS using text-only data for the target
language. The use of text-only data allows the development of TTS systems for
low-resource languages for which only textual resources are available, making
TTS accessible to thousands of languages. Inspired by the strong cross-lingual
transferability of multilingual language models, our framework first performs
masked language model pretraining with multilingual text-only data. Then we
train this model with a paired data in a supervised manner, while freezing a
language-aware embedding layer. This allows inference even for languages not
included in the paired data but present in the text-only data. Evaluation
results demonstrate highly intelligible zero-shot TTS with a character error
rate of less than 12% for an unseen language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Red teaming ChatGPT via Jailbreaking: Bias, Robustness, Reliability and Toxicity. (arXiv:2301.12867v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.12867">
<div class="article-summary-box-inner">
<span><p>Recent breakthroughs in natural language processing (NLP) have permitted the
synthesis and comprehension of coherent text in an open-ended way, therefore
translating the theoretical algorithms into practical applications. The large
language models (LLMs) have significantly impacted businesses such as report
summarization software and copywriters. Observations indicate, however, that
LLMs may exhibit social prejudice and toxicity, posing ethical and societal
dangers of consequences resulting from irresponsibility. Large-scale benchmarks
for accountable LLMs should consequently be developed. Although several
empirical investigations reveal the existence of a few ethical difficulties in
advanced LLMs, there is little systematic examination and user study of the
risks and harmful behaviors of current LLM usage. To further educate future
efforts on constructing ethical LLMs responsibly, we perform a qualitative
research method called ``red teaming'' on OpenAI's ChatGPT\footnote{In this
paper, ChatGPT refers to the version released on Dec 15th.} to better
understand the practical features of ethical dangers in recent LLMs. We analyze
ChatGPT comprehensively from four perspectives: 1) \textit{Bias} 2)
\textit{Reliability} 3) \textit{Robustness} 4) \textit{Toxicity}. In accordance
with our stated viewpoints, we empirically benchmark ChatGPT on multiple sample
datasets. We find that a significant number of ethical risks cannot be
addressed by existing benchmarks, and hence illustrate them via additional case
studies. In addition, we examine the implications of our findings on AI ethics
and harmal behaviors of ChatGPT, as well as future problems and practical
design considerations for responsible LLMs. We believe that our findings may
give light on future efforts to determine and mitigate the ethical hazards
posed by machines in LLM applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Transfer from Pre-trained Language Models to Cif-based Speech Recognizers via Hierarchical Distillation. (arXiv:2301.13003v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.13003">
<div class="article-summary-box-inner">
<span><p>Large-scale pre-trained language models (PLMs) have shown great potential in
natural language processing tasks. Leveraging the capabilities of PLMs to
enhance automatic speech recognition (ASR) systems has also emerged as a
promising research direction. However, previous works may be limited by the
inflexible structures of PLMs and the insufficient utilization of PLMs. To
alleviate these problems, we propose the hierarchical knowledge distillation
(HKD) on the continuous integrate-and-fire (CIF) based ASR models. To transfer
knowledge from PLMs to the ASR models, HKD employs cross-modal knowledge
distillation with contrastive loss at the acoustic level and knowledge
distillation with regression loss at the linguistic level. Compared with the
original CIF-based model, our method achieves 15% and 9% relative error rate
reduction on the AISHELL-1 and LibriSpeech datasets, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inductive Link Prediction for Both New Nodes and New Relation Types via Double Equivariance. (arXiv:2302.01313v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01313">
<div class="article-summary-box-inner">
<span><p>Despite recent advances in relational learning, the task of inductive link
prediction in discrete attributed multigraphs with both new nodes and new
relation types in test remains an open problem. In this work we tackle this
task by defining the concept of double exchangeability and its associated
double-permutation equivariant graph neural network that are equivariant to
permutations of both node identities and edge relations. Our neural
architecture imposes a structural representation of relations that can
inductively generalize from training nodes and relations to arbitrarily new
test nodes and relations, without the need for adaptation or retraining, thus
enabling a new direction in relational learning. Finally, we introduce a
general blueprint for such double equivariant representations and empirically
showcase its capability on two proposed real-world benchmarks that no existing
works can perform accurately.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SanskritShala: A Neural Sanskrit NLP Toolkit with Web-Based Interface for Pedagogical and Annotation Purposes. (arXiv:2302.09527v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.09527">
<div class="article-summary-box-inner">
<span><p>We present a neural Sanskrit Natural Language Processing (NLP) toolkit named
SanskritShala (a school of Sanskrit) to facilitate computational linguistic
analyses for several tasks such as word segmentation, morphological tagging,
dependency parsing, and compound type identification. Our systems currently
report state-of-the-art performance on available benchmark datasets for all
tasks. SanskritShala is deployed as a web-based application, which allows a
user to get real-time analysis for the given input. It is built with
easy-to-use interactive data annotation features that allow annotators to
correct the system predictions when it makes mistakes. We publicly release the
source codes of the 4 modules included in the toolkit, 7 word embedding models
that have been trained on publicly available Sanskrit corpora and multiple
annotated datasets such as word similarity, relatedness, categorization,
analogy prediction to assess intrinsic properties of word embeddings. So far as
we know, this is the first neural-based Sanskrit NLP toolkit that has a
web-based interface and a number of NLP modules. We are sure that the people
who are willing to work with Sanskrit will find it useful for pedagogical and
annotative purposes. SanskritShala is available at:
https://cnerg.iitkgp.ac.in/sanskritshala. The demo video of our platform can be
accessed at: https://youtu.be/x0X31Y9k0mw4.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inseq: An Interpretability Toolkit for Sequence Generation Models. (arXiv:2302.13942v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.13942">
<div class="article-summary-box-inner">
<span><p>Past work in natural language processing interpretability focused mainly on
popular classification tasks while largely overlooking generation settings,
partly due to a lack of dedicated tools. In this work, we introduce Inseq, a
Python library to democratize access to interpretability analyses of sequence
generation models. Inseq enables intuitive and optimized extraction of models'
internal information and feature importance scores for popular decoder-only and
encoder-decoder Transformers architectures. We showcase its potential by
adopting it to highlight gender biases in machine translation models and locate
factual knowledge inside GPT-2. Thanks to its extensible interface supporting
cutting-edge techniques such as contrastive feature attribution, Inseq can
drive future advances in explainable natural language generation, centralizing
good practices and enabling fair and reproducible model evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Prompting: A Unified Framework for Prompt Tuning. (arXiv:2303.02909v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.02909">
<div class="article-summary-box-inner">
<span><p>It has been demonstrated that the art of prompt tuning is highly effective in
efficiently extracting knowledge from pretrained foundation models,
encompassing pretrained language models (PLMs), vision pretrained models, and
vision-language (V-L) models. However, the efficacy of employing fixed soft
prompts with a predetermined position for concatenation with inputs for all
instances, irrespective of their inherent disparities, remains uncertain.
Variables such as the position, length, and representations of prompts across
diverse instances and tasks can substantially influence the performance of
prompt tuning. In this context, we provide a theoretical analysis, which
reveals that optimizing the position of the prompt to encompass the input can
capture additional semantic information that traditional prefix or postfix
prompt tuning methods fail to capture. Building upon our analysis, we present a
unified dynamic prompt (DP) tuning strategy that dynamically determines
different factors of prompts based on specific tasks and instances. To
accomplish this, we employ a lightweight learning network with Gumble-Softmax,
allowing us to learn instance-dependent guidance. Experimental results
underscore the significant performance improvement achieved by dynamic prompt
tuning across a wide range of tasks, including NLP tasks, vision recognition
tasks, and vision-language tasks. Furthermore, we establish the universal
applicability of our approach under full-data, few-shot, and multitask
scenarios. Codes are available at https://github.com/Xianjun-Yang/DPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CB2: Collaborative Natural Language Interaction Research Platform. (arXiv:2303.08127v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08127">
<div class="article-summary-box-inner">
<span><p>CB2 is a multi-agent platform to study collaborative natural language
interaction in a grounded task-oriented scenario. It includes a 3D game
environment, a backend server designed to serve trained models to human agents,
and various tools and processes to enable scalable studies. We deploy CB2 at
https://cb2.ai as a system demonstration with a learned instruction following
model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Direct and indirect evidence of compression of word lengths. Zipf's law of abbreviation revisited. (arXiv:2303.10128v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10128">
<div class="article-summary-box-inner">
<span><p>Zipf's law of abbreviation, the tendency of more frequent words to be
shorter, is one of the most solid candidates for a linguistic universal, in the
sense that it has the potential for being exceptionless or with a number of
exceptions that is vanishingly small compared to the number of languages on
Earth. Since Zipf's pioneering research, this law has been viewed as a
manifestation of a universal principle of communication, i.e. the minimization
of word lengths, to reduce the effort of communication. Here we revisit the
concordance of written language with the law of abbreviation. Crucially, we
provide wider evidence that the law holds also in speech (when word length is
measured in time), in particular in 46 languages from 14 linguistic families.
Agreement with the law of abbreviation provides indirect evidence of
compression of languages via the theoretical argument that the law of
abbreviation is a prediction of optimal coding. Motivated by the need of direct
evidence of compression, we derive a simple formula for a random baseline
indicating that word lengths are systematically below chance, across linguistic
families and writing systems, and independently of the unit of measurement
(length in characters or duration in time). Our work paves the way to measure
and compare the degree of optimality of word lengths in languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT4PCG Competition: Character-like Level Generation for Science Birds. (arXiv:2303.15662v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.15662">
<div class="article-summary-box-inner">
<span><p>This paper presents the first ChatGPT4PCG Competition at the 2023 IEEE
Conference on Games. The objective of this competition is for participants to
create effective prompts for ChatGPT--enabling it to generate Science Birds
levels with high stability and character-like qualities--fully using their
creativity as well as prompt engineering skills. ChatGPT is a conversational
agent developed by OpenAI. Science Birds is selected as the competition
platform because designing an Angry Birds-like level is not a trivial task due
to the in-game gravity; the quality of the levels is determined by their
stability. To lower the entry barrier to the competition, we limit the task to
the generation of capitalized English alphabetical characters. We also allow
only a single prompt to be used for generating all the characters. Here, the
quality of the generated levels is determined by their stability and similarity
to the given characters. A sample prompt is provided to participants for their
reference. An experiment is conducted to determine the effectiveness of several
modified versions of this sample prompt on level stability and similarity by
testing them on several characters. To the best of our knowledge, we believe
that ChatGPT4PCG is the first competition of its kind and hope to inspire
enthusiasm for prompt engineering in procedural content generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating and Detecting ChatGPT's Responses on Abstractive Summarization. (arXiv:2303.17650v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17650">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have gathered significant attention due to their
impressive performance on a variety of tasks. ChatGPT, developed by OpenAI, is
a recent addition to the family of language models and is being called a
disruptive technology by a few, owing to its human-like text-generation
capabilities. Although, many anecdotal examples across the internet have
evaluated ChatGPT's strength and weakness, only a few systematic research
studies exist. To contribute to the body of literature of systematic research
on ChatGPT, we evaluate the performance of ChatGPT on Abstractive Summarization
by the means of automated metrics and blinded human reviewers. We also build
automatic text classifiers to detect ChatGPT generated summaries. We found that
while text classification algorithms can distinguish between real and generated
summaries, humans are unable to distinguish between real summaries and those
produced by ChatGPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Program with Natural Language. (arXiv:2304.10464v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10464">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have shown remarkable performance in various
basic natural language tasks, which raises hope for achieving Artificial
General Intelligence. For completing the complex task, we still need a program
for the task first and then ask LLMs to follow the program to generate the
specific solution. We propose using natural language as a new programming
language to describe task procedures, making them easily understandable to both
humans and LLMs. ~The LLM is capable of directly generating natural language
programs, but these programs may still contain factual errors or incomplete
steps. Therefore, we further propose the Learning to Program (\text{LP}) method
to ask LLMs themselves to learn the natural language program based on the
training dataset of the complex task first and then use the learned program to
guide the inference. Our experiments on the reasoning tasks of five different
reasoning types (8 datasets) demonstrate the effectiveness of our approach.
Further, our analysis experiment shows that the learned program can be directly
used to guide another LLM to improve its performance, which reveals a new
transfer learning paradigm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Which Factors Predict the Chat Experience of a Natural Language Generation Dialogue Service?. (arXiv:2304.10785v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10785">
<div class="article-summary-box-inner">
<span><p>In this paper, we proposed a conceptual model to predict the chat experience
in a natural language generation dialog system. We evaluated the model with 120
participants with Partial Least Squares Structural Equation Modeling (PLS-SEM)
and obtained an R-square (R2) with 0.541. The model considers various factors,
including the prompts used for generation; coherence, sentiment, and similarity
in the conversation; and users' perceived dialog agents' favorability. We then
further explore the effectiveness of the subset of our proposed model. The
results showed that users' favorability and coherence, sentiment, and
similarity in the dialogue are positive predictors of users' chat experience.
Moreover, we found users may prefer dialog agents with characteristics of
Extroversion, Openness, Conscientiousness, Agreeableness, and Non-Neuroticism.
Through our research, an adaptive dialog system might use collected data to
infer factors in our model, predict the chat experience for users through these
factors, and optimize it by adjusting prompts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fundamental Limitations of Alignment in Large Language Models. (arXiv:2304.11082v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11082">
<div class="article-summary-box-inner">
<span><p>An important aspect in developing language models that interact with humans
is aligning their behavior to be useful and unharmful for their human users.
This is usually achieved by tuning the model in a way that enhances desired
behaviors and inhibits undesired ones, a process referred to as alignment. In
this paper, we propose a theoretical approach called Behavior Expectation
Bounds (BEB) which allows us to formally investigate several inherent
characteristics and limitations of alignment in large language models.
Importantly, we prove that for any behavior that has a finite probability of
being exhibited by the model, there exist prompts that can trigger the model
into outputting this behavior, with probability that increases with the length
of the prompt. This implies that any alignment process that attenuates
undesired behavior but does not remove it altogether, is not safe against
adversarial prompting attacks. Furthermore, our framework hints at the
mechanism by which leading alignment approaches such as reinforcement learning
from human feedback increase the LLM's proneness to being prompted into the
undesired behaviors. Moreover, we include the notion of personas in our BEB
framework, and find that behaviors which are generally very unlikely to be
exhibited by the model can be brought to the front by prompting the model to
behave as specific persona. This theoretical result is being experimentally
demonstrated in large scale by the so called contemporary "chatGPT jailbreaks",
where adversarial users trick the LLM into breaking its alignment guardrails by
triggering it into acting as a malicious persona. Our results expose
fundamental limitations in alignment of LLMs and bring to the forefront the
need to devise reliable mechanisms for ensuring AI safety.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model. (arXiv:2304.13731v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.13731">
<div class="article-summary-box-inner">
<span><p>The immense scale of the recent large language models (LLM) allows many
interesting properties, such as, instruction- and chain-of-thought-based
fine-tuning, that has significantly improved zero- and few-shot performance in
many natural language processing (NLP) tasks. Inspired by such successes, we
adopt such an instruction-tuned LLM Flan-T5 as the text encoder for
text-to-audio (TTA) generation -- a task where the goal is to generate an audio
from its textual description. The prior works on TTA either pre-trained a joint
text-audio encoder or used a non-instruction-tuned model, such as, T5.
Consequently, our latent diffusion model (LDM)-based approach TANGO outperforms
the state-of-the-art AudioLDM on most metrics and stays comparable on the rest
on AudioCaps test set, despite training the LDM on a 63 times smaller dataset
and keeping the text encoder frozen. This improvement might also be attributed
to the adoption of audio pressure level-based sound mixing for training set
augmentation, whereas the prior methods take a random mix.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information. (arXiv:2305.01788v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01788">
<div class="article-summary-box-inner">
<span><p>Visual Word Sense Disambiguation (VWSD) is a task to find the image that most
accurately depicts the correct sense of the target word for the given context.
Previously, image-text matching models often suffered from recognizing
polysemous words. This paper introduces an unsupervised VWSD approach that uses
gloss information of an external lexical knowledge-base, especially the sense
definitions. Specifically, we suggest employing Bayesian inference to
incorporate the sense definitions when sense information of the answer is not
provided. In addition, to ameliorate the out-of-dictionary (OOD) issue, we
propose a context-aware definition generation with GPT-3. Experimental results
show that the VWSD performance significantly increased with our Bayesian
inference-based approach. In addition, our context-aware definition generation
achieved prominent performance improvement in OOD examples exhibiting better
performance than the existing definition generation method. We will publish
source codes as soon as possible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vcc: Scaling Transformers to 128K Tokens or More by Prioritizing Important Tokens. (arXiv:2305.04241v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04241">
<div class="article-summary-box-inner">
<span><p>Transformers are central in modern natural language processing and computer
vision applications. Despite recent works devoted to reducing the quadratic
cost of such models (as a function of the sequence length), dealing with ultra
long sequences (e.g., with more than 16K tokens) remains challenging.
Applications such as answering questions based on a book or summarizing a
scientific article are inefficient or infeasible. Here, we propose to
significantly improve the efficiency of Transformers for ultra long sequences,
by compressing the sequence into a much smaller representation at each layer.
Specifically, by exploiting the fact that in many tasks, only a small subset of
special tokens (we call VIP-tokens) are most relevant to the final prediction,
we propose a VIP-token centric compression (VCC) scheme which selectively
compresses the sequence based on their impact on approximating the
representation of the VIP-tokens. Compared with competitive baselines, our
algorithm is not only efficient (achieving more than $3\times$ efficiency gain
compared to baselines on 4K and 16K lengths), but also offers
competitive/better performance on a large number of tasks. Further, we show
that our algorithm scales to 128K tokens (or more) while consistently offering
accuracy improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FACTIFY-5WQA: 5W Aspect-based Fact Verification through Question Answering. (arXiv:2305.04329v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04329">
<div class="article-summary-box-inner">
<span><p>Automatic fact verification has received significant attention recently.
Contemporary automatic fact-checking systems focus on estimating truthfulness
using numerical scores which are not human-interpretable. A human fact-checker
generally follows several logical steps to verify a verisimilitude claim and
conclude whether its truthful or a mere masquerade. Popular fact-checking
websites follow a common structure for fact categorization such as half true,
half false, false, pants on fire, etc. Therefore, it is necessary to have an
aspect-based (delineating which part(s) are true and which are false)
explainable system that can assist human fact-checkers in asking relevant
questions related to a fact, which can then be validated separately to reach a
final verdict. In this paper, we propose a 5W framework (who, what, when,
where, and why) for question-answer-based fact explainability. To that end, we
present a semi-automatically generated dataset called FACTIFY-5WQA, which
consists of 391, 041 facts along with relevant 5W QAs - underscoring our major
contribution to this paper. A semantic role labeling system has been utilized
to locate 5Ws, which generates QA pairs for claims using a masked language
model. Finally, we report a baseline QA system to automatically locate those
answers from evidence documents, which can serve as a baseline for future
research in the field. Lastly, we propose a robust fact verification system
that takes paraphrased claims and automatically validates them. The dataset and
the baseline model are available at https: //github.com/ankuranii/acl-5W-QA
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decker: Double Check with Heterogeneous Knowledge for Commonsense Fact Verification. (arXiv:2305.05921v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05921">
<div class="article-summary-box-inner">
<span><p>Commonsense fact verification, as a challenging branch of commonsense
question-answering (QA), aims to verify through facts whether a given
commonsense claim is correct or not. Answering commonsense questions
necessitates a combination of knowledge from various levels. However, existing
studies primarily rest on grasping either unstructured evidence or potential
reasoning paths from structured knowledge bases, yet failing to exploit the
benefits of heterogeneous knowledge simultaneously. In light of this, we
propose Decker, a commonsense fact verification model that is capable of
bridging heterogeneous knowledge by uncovering latent relationships between
structured and unstructured knowledge. Experimental results on two commonsense
fact verification benchmark datasets, CSQA2.0 and CREAK demonstrate the
effectiveness of our Decker and further analysis verifies its capability to
seize more precious information through reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-shot Faithful Factual Error Correction. (arXiv:2305.07982v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07982">
<div class="article-summary-box-inner">
<span><p>Faithfully correcting factual errors is critical for maintaining the
integrity of textual knowledge bases and preventing hallucinations in
sequence-to-sequence models. Drawing on humans' ability to identify and correct
factual errors, we present a zero-shot framework that formulates questions
about input claims, looks for correct answers in the given evidence, and
assesses the faithfulness of each correction based on its consistency with the
evidence. Our zero-shot framework outperforms fully-supervised approaches, as
demonstrated by experiments on the FEVER and SciFact datasets, where our
outputs are shown to be more faithful. More importantly, the decomposability
nature of our framework inherently provides interpretability. Additionally, to
reveal the most suitable metrics for evaluating factual error corrections, we
analyze the correlation between commonly used metrics with human judgments in
terms of three different dimensions regarding intelligibility and faithfulness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models. (arXiv:2305.08283v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.08283">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) are pretrained on diverse data sources, including news,
discussion forums, books, and online encyclopedias. A significant portion of
this data includes opinions and perspectives which, on one hand, celebrate
democracy and diversity of ideas, and on the other hand are inherently socially
biased. Our work develops new methods to (1) measure political biases in LMs
trained on such corpora, along social and economic axes, and (2) measure the
fairness of downstream NLP models trained on top of politically biased LMs. We
focus on hate speech and misinformation detection, aiming to empirically
quantify the effects of political (social, economic) biases in pretraining data
on the fairness of high-stakes social-oriented tasks. Our findings reveal that
pretrained LMs do have political leanings that reinforce the polarization
present in pretraining corpora, propagating social biases into hate speech
predictions and misinformation detectors. We discuss the implications of our
findings for NLP research and propose future directions to mitigate unfairness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Crosslingual Investigation of Conceptualization in 1335 Languages. (arXiv:2305.08475v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.08475">
<div class="article-summary-box-inner">
<span><p>Languages differ in how they divide up the world into concepts and words;
e.g., in contrast to English, Swahili has a single concept for `belly' and
`womb'. We investigate these differences in conceptualization across 1,335
languages by aligning concepts in a parallel corpus. To this end, we propose
Conceptualizer, a method that creates a bipartite directed alignment graph
between source language concepts and sets of target language strings. In a
detailed linguistic analysis across all languages for one concept (`bird') and
an evaluation on gold standard data for 32 Swadesh concepts, we show that
Conceptualizer has good alignment accuracy. We demonstrate the potential of
research on conceptualization in NLP with two experiments. (1) We define
crosslingual stability of a concept as the degree to which it has 1-1
correspondences across languages, and show that concreteness predicts
stability. (2) We represent each language by its conceptualization pattern for
83 concepts, and define a similarity measure on these representations. The
resulting measure for the conceptual similarity of two languages is
complementary to standard genealogical, typological, and surface similarity
measures. For four out of six language families, we can assign languages to
their correct family based on conceptual similarity with accuracy between 54%
and 87%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing. (arXiv:2305.09770v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09770">
<div class="article-summary-box-inner">
<span><p>While various AI explanation (XAI) methods have been proposed to interpret AI
systems, whether the state-of-the-art XAI methods are practically useful for
humans remains inconsistent findings. To improve the usefulness of XAI methods,
a line of studies identifies the gaps between the diverse and dynamic
real-world user needs with the status quo of XAI methods. Although prior
studies envision mitigating these gaps by integrating multiple XAI methods into
the universal XAI interfaces (e.g., conversational or GUI-based XAI systems),
there is a lack of work investigating how these systems should be designed to
meet practical user needs. In this study, we present ConvXAI, a conversational
XAI system that incorporates multiple XAI types, and empowers users to request
a variety of XAI questions via a universal XAI dialogue interface.
Particularly, we innovatively embed practical user needs (i.e., four principles
grounding on the formative study) into ConvXAI design to improve practical
usefulness. Further, we design the domain-specific language (DSL) to implement
the essential conversational XAI modules and release the core conversational
universal XAI API for generalization. The findings from two within-subjects
studies with 21 users show that ConvXAI is more useful for humans in perceiving
the understanding and writing improvement, and improving the writing process in
terms of productivity and sentence quality. Finally, this work contributes
insight into the design space of useful XAI, reveals humans' XAI usage patterns
with empirical evidence in practice, and identifies opportunities for future
useful XAI work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Post Hoc Explanations of Language Models Can Improve Language Models. (arXiv:2305.11426v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11426">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have demonstrated remarkable capabilities in
performing complex tasks. Moreover, recent research has shown that
incorporating human-annotated rationales (e.g., Chain-of-Thought prompting)
during in-context learning can significantly enhance the performance of these
models, particularly on tasks that require reasoning capabilities. However,
incorporating such rationales poses challenges in terms of scalability as this
requires a high degree of human involvement. In this work, we present a novel
framework, Amplifying Model Performance by Leveraging In-Context Learning with
Post Hoc Explanations (AMPLIFY), which addresses the aforementioned challenges
by automating the process of rationale generation. To this end, we leverage
post hoc explanation methods which output attribution scores (explanations)
capturing the influence of each of the input features on model predictions.
More specifically, we construct automated natural language rationales that
embed insights from post hoc explanations to provide corrective signals to
LLMs. Extensive experimentation with real-world datasets demonstrates that our
framework, AMPLIFY, leads to prediction accuracy improvements of about 10-25%
over a wide range of tasks, including those where prior approaches which rely
on human-annotated rationales such as Chain-of-Thought prompting fall short.
Our work makes one of the first attempts at highlighting the potential of post
hoc explanations as valuable tools for enhancing the effectiveness of LLMs.
Furthermore, we conduct additional empirical analyses and ablation studies to
demonstrate the impact of each of the components of AMPLIFY, which, in turn,
leads to critical insights for refining in-context learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextualized End-to-End Speech Recognition with Contextual Phrase Prediction Network. (arXiv:2305.12493v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.12493">
<div class="article-summary-box-inner">
<span><p>Contextual information plays a crucial role in speech recognition
technologies and incorporating it into the end-to-end speech recognition models
has drawn immense interest recently. However, previous deep bias methods lacked
explicit supervision for bias tasks. In this study, we introduce a contextual
phrase prediction network for an attention-based deep bias method. This network
predicts context phrases in utterances using contextual embeddings and
calculates bias loss to assist in the training of the contextualized model. Our
method achieved a significant word error rate (WER) reduction across various
end-to-end speech recognition models. Experiments on the LibriSpeech corpus
show that our proposed model obtains a 12.1% relative WER improvement over the
baseline model, and the WER of the context phrases decreases relatively by
40.5%. Moreover, by applying a context phrase filtering strategy, we also
effectively eliminate the WER degradation when using a larger biasing list.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Energy-based Language Models with Different Architectures and Training Methods for Speech Recognition. (arXiv:2305.12676v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.12676">
<div class="article-summary-box-inner">
<span><p>Energy-based language models (ELMs) parameterize an unnormalized distribution
for natural sentences and are radically different from popular autoregressive
language models (ALMs). As an important application, ELMs have been
successfully used as a means for calculating sentence scores in speech
recognition, but they all use less-modern CNN or LSTM networks. The recent
progress in Transformer networks and large pretrained models such as BERT and
GPT2 opens new possibility to further advancing ELMs. In this paper, we explore
different architectures of energy functions and different training methods to
investigate the capabilities of ELMs in rescoring for speech recognition, all
using large pretrained models as backbones.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Optimal Policy for Simultaneous Machine Translation via Binary Search. (arXiv:2305.12774v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.12774">
<div class="article-summary-box-inner">
<span><p>Simultaneous machine translation (SiMT) starts to output translation while
reading the source sentence and needs a precise policy to decide when to output
the generated translation. Therefore, the policy determines the number of
source tokens read during the translation of each target token. However, it is
difficult to learn a precise translation policy to achieve good latency-quality
trade-offs, because there is no golden policy corresponding to parallel
sentences as explicit supervision. In this paper, we present a new method for
constructing the optimal policy online via binary search. By employing explicit
supervision, our approach enables the SiMT model to learn the optimal policy,
which can guide the model in completing the translation during inference.
Experiments on four translation tasks show that our method can exceed strong
baselines across all latency scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gloss-Free End-to-End Sign Language Translation. (arXiv:2305.12876v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.12876">
<div class="article-summary-box-inner">
<span><p>In this paper, we tackle the problem of sign language translation (SLT)
without gloss annotations. Although intermediate representation like gloss has
been proven effective, gloss annotations are hard to acquire, especially in
large quantities. This limits the domain coverage of translation datasets, thus
handicapping real-world applications. To mitigate this problem, we design the
Gloss-Free End-to-end sign language translation framework (GloFE). Our method
improves the performance of SLT in the gloss-free setting by exploiting the
shared underlying semantics of signs and the corresponding spoken translation.
Common concepts are extracted from the text and used as a weak form of
intermediate representation. The global embedding of these concepts is used as
a query for cross-attention to find the corresponding information within the
learned visual features. In a contrastive manner, we encourage the similarity
of query results between samples containing such concepts and decrease those
that do not. We obtained state-of-the-art results on large-scale datasets,
including OpenASL and How2Sign. The code and model will be available at
https://github.com/HenryLittle/GloFE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text-to-SQL Error Correction with Language Models of Code. (arXiv:2305.13073v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.13073">
<div class="article-summary-box-inner">
<span><p>Despite recent progress in text-to-SQL parsing, current semantic parsers are
still not accurate enough for practical use. In this paper, we investigate how
to build automatic text-to-SQL error correction models. Noticing that
token-level edits are out of context and sometimes ambiguous, we propose
building clause-level edit models instead. Besides, while most language models
of code are not specifically pre-trained for SQL, they know common data
structures and their operations in programming languages such as Python. Thus,
we propose a novel representation for SQL queries and their edits that adheres
more closely to the pre-training corpora of language models of code. Our error
correction model improves the exact set match accuracy of different parsers by
2.4-6.5 and obtains up to 4.3 point absolute improvement over two strong
baselines. Our code and data are available at
https://github.com/OSU-NLP-Group/Auto-SQL-Correction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Response Length Perception and Sequence Scheduling: An LLM-Empowered LLM Inference Pipeline. (arXiv:2305.13144v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.13144">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have revolutionized the field of AI,
demonstrating unprecedented capacity across various tasks. However, the
inference process for LLMs comes with significant computational costs. In this
paper, we propose an efficient LLM inference pipeline that harnesses the power
of LLMs. Our approach begins by tapping into the potential of LLMs to
accurately perceive and predict the response length with minimal overhead. By
leveraging this information, we introduce an efficient sequence scheduling
technique that groups queries with similar response lengths into micro-batches.
We evaluate our approach on real-world instruction datasets using the
LLaMA-based model, and our results demonstrate an impressive 86% improvement in
inference throughput without compromising effectiveness. Notably, our method is
orthogonal to other inference acceleration techniques, making it a valuable
addition to many existing toolkits (e.g., FlashAttention, Quantization) for LLM
inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Context Pruning for Efficient and Interpretable Autoregressive Transformers. (arXiv:2305.15805v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15805">
<div class="article-summary-box-inner">
<span><p>Autoregressive Transformers adopted in Large Language Models (LLMs) are hard
to scale to long sequences. Despite several works trying to reduce their
computational cost, most of LLMs still adopt attention layers between all pairs
of tokens in the sequence, thus incurring a quadratic cost. In this study, we
present a novel approach that dynamically prunes contextual information while
preserving the model's expressiveness, resulting in reduced memory and
computational requirements during inference. Our method employs a learnable
mechanism that determines which uninformative tokens can be dropped from the
context at any point across the generation process. By doing so, our approach
not only addresses performance concerns but also enhances interpretability,
providing valuable insight into the model's decision-making process. Our
technique can be applied to existing pre-trained models through a
straightforward fine-tuning process, and the pruning strength can be specified
by a sparsity parameter. Notably, our empirical findings demonstrate that we
can effectively prune up to 80\% of the context without significant performance
degradation on downstream tasks, offering a valuable tool for mitigating
inference costs. Our reference implementation achieves up to $2\times$ increase
in inference throughput and even greater memory savings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MEMEX: Detecting Explanatory Evidence for Memes via Knowledge-Enriched Contextualization. (arXiv:2305.15913v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15913">
<div class="article-summary-box-inner">
<span><p>Memes are a powerful tool for communication over social media. Their affinity
for evolving across politics, history, and sociocultural phenomena makes them
an ideal communication vehicle. To comprehend the subtle message conveyed
within a meme, one must understand the background that facilitates its holistic
assimilation. Besides digital archiving of memes and their metadata by a few
websites like knowyourmeme.com, currently, there is no efficient way to deduce
a meme's context dynamically. In this work, we propose a novel task, MEMEX -
given a meme and a related document, the aim is to mine the context that
succinctly explains the background of the meme. At first, we develop MCC (Meme
Context Corpus), a novel dataset for MEMEX. Further, to benchmark MCC, we
propose MIME (MultImodal Meme Explainer), a multimodal neural framework that
uses common sense enriched meme representation and a layered approach to
capture the cross-modal semantic dependencies between the meme and the context.
MIME surpasses several unimodal and multimodal systems and yields an absolute
improvement of ~ 4% F1-score over the best baseline. Lastly, we conduct
detailed analyses of MIME's performance, highlighting the aspects that could
lead to optimal modeling of cross-modal contextual associations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emergence of a phonological bias in ChatGPT. (arXiv:2305.15929v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15929">
<div class="article-summary-box-inner">
<span><p>Current large language models, such as OpenAI's ChatGPT, have captured the
public's attention because how remarkable they are in the use of language.
Here, I demonstrate that ChatGPT displays phonological biases that are a
hallmark of human language processing. More concretely, just like humans,
ChatGPT has a consonant bias. That is, the chatbot has a tendency to use
consonants over vowels to identify words. This is observed across languages
that differ in their relative distribution of consonants and vowels such as
English and Spanish. Despite the differences in how current artificial
intelligence language models are trained to process linguistic stimuli and how
human infants acquire language, such training seems to be enough for the
emergence of a phonological bias in ChatGPT
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ASR and Emotional Speech: A Word-Level Investigation of the Mutual Impact of Speech and Emotion Recognition. (arXiv:2305.16065v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16065">
<div class="article-summary-box-inner">
<span><p>In Speech Emotion Recognition (SER), textual data is often used alongside
audio signals to address their inherent variability. However, the reliance on
human annotated text in most research hinders the development of practical SER
systems. To overcome this challenge, we investigate how Automatic Speech
Recognition (ASR) performs on emotional speech by analyzing the ASR performance
on emotion corpora and examining the distribution of word errors and confidence
scores in ASR transcripts to gain insight into how emotion affects ASR. We
utilize four ASR systems, namely Kaldi ASR, wav2vec2, Conformer, and Whisper,
and three corpora: IEMOCAP, MOSI, and MELD to ensure generalizability.
Additionally, we conduct text-based SER on ASR transcripts with increasing word
error rates to investigate how ASR affects SER. The objective of this study is
to uncover the relationship and mutual impact of ASR and SER, in order to
facilitate ASR adaptation to emotional speech and the use of SER in real world.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InterFormer: Interactive Local and Global Features Fusion for Automatic Speech Recognition. (arXiv:2305.16342v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16342">
<div class="article-summary-box-inner">
<span><p>The local and global features are both essential for automatic speech
recognition (ASR). Many recent methods have verified that simply combining
local and global features can further promote ASR performance. However, these
methods pay less attention to the interaction of local and global features, and
their series architectures are rigid to reflect local and global relationships.
To address these issues, this paper proposes InterFormer for interactive local
and global features fusion to learn a better representation for ASR.
Specifically, we combine the convolution block with the transformer block in a
parallel design. Besides, we propose a bidirectional feature interaction module
(BFIM) and a selective fusion module (SFM) to implement the interaction and
fusion of local and global features, respectively. Extensive experiments on
public ASR datasets demonstrate the effectiveness of our proposed InterFormer
and its superior performance over the other Transformer and Conformer models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Aligned Prefix Averaging for Domain Generalization in Abstractive Summarization. (arXiv:2305.16820v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16820">
<div class="article-summary-box-inner">
<span><p>Domain generalization is hitherto an underexplored area applied in
abstractive summarization. Moreover, most existing works on domain
generalization have sophisticated training algorithms. In this paper, we
propose a lightweight, weight averaging based, Domain Aligned Prefix Averaging
approach to domain generalization for abstractive summarization. Given a number
of source domains, our method first trains a prefix for each one of them. These
source prefixes generate summaries for a small number of target domain
documents. The similarity of the generated summaries to their corresponding
documents is used for calculating weights required to average source prefixes.
In DAPA, prefix tuning allows for lightweight finetuning, and weight averaging
allows for the computationally efficient addition of new source domains. When
evaluated on four diverse summarization domains, DAPA shows comparable or
better performance against the baselines, demonstrating the effectiveness of
its prefix averaging scheme.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models. (arXiv:2305.16986v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16986">
<div class="article-summary-box-inner">
<span><p>Trained with an unprecedented scale of data, large language models (LLMs)
like ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities
from model scaling. Such a trend underscored the potential of training LLMs
with unlimited language data, advancing the development of a universal embodied
agent. In this work, we introduce the NavGPT, a purely LLM-based
instruction-following navigation agent, to reveal the reasoning capability of
GPT models in complex embodied scenes by performing zero-shot sequential action
prediction for vision-and-language navigation (VLN). At each step, NavGPT takes
the textual descriptions of visual observations, navigation history, and future
explorable directions as inputs to reason the agent's current status, and makes
the decision to approach the target. Through comprehensive experiments, we
demonstrate NavGPT can explicitly perform high-level planning for navigation,
including decomposing instruction into sub-goal, integrating commonsense
knowledge relevant to navigation task resolution, identifying landmarks from
observed scenes, tracking navigation progress, and adapting to exceptions with
plan adjustment. Furthermore, we show that LLMs is capable of generating
high-quality navigational instructions from observations and actions along a
path, as well as drawing accurate top-down metric trajectory given the agent's
navigation history. Despite the performance of using NavGPT to zero-shot R2R
tasks still falling short of trained models, we suggest adapting multi-modality
inputs for LLMs to use as visual navigation agents and applying the explicit
reasoning of LLMs to benefit learning-based models.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-05-30 23:11:30.446105743 UTC">2023-05-30 23:11:30 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>