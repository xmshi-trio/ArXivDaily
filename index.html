<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-11-02T01:30:00Z">11-02</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Very Low Resource Sentence Alignment: Luhya and Swahili. (arXiv:2211.00046v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00046">
<div class="article-summary-box-inner">
<span><p>Language-agnostic sentence embeddings generated by pre-trained models such as
LASER and LaBSE are attractive options for mining large datasets to produce
parallel corpora for low-resource machine translation. We test LASER and LaBSE
in extracting bitext for two related low-resource African languages: Luhya and
Swahili. For this work, we created a new parallel set of nearly 8000
Luhya-English sentences which allows a new zero-shot test of LASER and LaBSE.
We find that LaBSE significantly outperforms LASER on both languages. Both
LASER and LaBSE however perform poorly at zero-shot alignment on Luhya,
achieving just 1.5% and 22.0% successful alignments respectively (P@1 score).
We fine-tune the embeddings on a small set of parallel Luhya sentences and show
significant gains, improving the LaBSE alignment accuracy to 53.3%. Further,
restricting the dataset to sentence embedding pairs with cosine similarity
above 0.7 yielded alignments with over 85% accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Sequences by Learning to Self-Correct. (arXiv:2211.00053v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00053">
<div class="article-summary-box-inner">
<span><p>Sequence generation applications require satisfying semantic constraints,
such as ensuring that programs are correct, using certain keywords, or avoiding
undesirable content. Language models, whether fine-tuned or prompted with
few-shot demonstrations, frequently violate these constraints, and lack a
mechanism to iteratively revise their outputs. Moreover, some powerful language
models are of extreme scale or inaccessible, making it inefficient, if not
infeasible, to update their parameters for task-specific adaptation. We present
Self-Correction, an approach that decouples an imperfect base generator (an
off-the-shelf language model or supervised sequence-to-sequence model) from a
separate corrector that learns to iteratively correct imperfect generations. To
train the corrector, we propose an online training procedure that can use
either scalar or natural language feedback on intermediate imperfect
generations. We show that Self-Correction improves upon the base generator in
three diverse generation tasks - mathematical program synthesis,
lexically-constrained generation, and toxicity control - even when the
corrector is much smaller than the base generator.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WHEN FLUE MEETS FLANG: Benchmarks and Large Pre-trained Language Model for Financial Domain. (arXiv:2211.00083v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00083">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models have shown impressive performance on a variety of
tasks and domains. Previous research on financial language models usually
employs a generic training scheme to train standard model architectures,
without completely leveraging the richness of the financial data. We propose a
novel domain specific Financial LANGuage model (FLANG) which uses financial
keywords and phrases for better masking, together with span boundary objective
and in-filing objective. Additionally, the evaluation benchmarks in the field
have been limited. To this end, we contribute the Financial Language
Understanding Evaluation (FLUE), an open-source comprehensive suite of
benchmarks for the financial domain. These include new benchmarks across 5 NLP
tasks in financial domain as well as common benchmarks used in the previous
research. Experiments on these benchmarks suggest that our model outperforms
those in prior literature on a variety of NLP tasks. Our models, code and
benchmark data are publicly available on Github and Huggingface.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An analysis of degenerating speech due to progressive dysarthria on ASR performance. (arXiv:2211.00089v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00089">
<div class="article-summary-box-inner">
<span><p>Although personalized automatic speech recognition (ASR) models have recently
been designed to recognize even severely impaired speech, model performance may
degrade over time for persons with degenerating speech. The aims of this study
were to (1) analyze the change of performance of ASR over time in individuals
with degrading speech, and (2) explore mitigation strategies to optimize
recognition throughout disease progression. Speech was recorded by four
individuals with degrading speech due to amyotrophic lateral sclerosis (ALS).
Word error rates (WER) across recording sessions were computed for three ASR
models: Unadapted Speaker Independent (U-SI), Adapted Speaker Independent
(A-SI), and Adapted Speaker Dependent (A-SD or personalized). The performance
of all three models degraded significantly over time as speech became more
impaired, but the performance of the A-SD model improved markedly when it was
updated with recordings from the severe stages of speech progression. Recording
additional utterances early in the disease before speech degraded significantly
did not improve the performance of A-SD models. Overall, our findings emphasize
the importance of continuous recording (and model retraining) when providing
personalized models for individuals with progressive speech impairments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-Efficient Cross-Lingual Transfer with Language-Specific Subnetworks. (arXiv:2211.00106v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00106">
<div class="article-summary-box-inner">
<span><p>Large multilingual language models typically share their parameters across
all languages, which enables cross-lingual task transfer, but learning can also
be hindered when training updates from different languages are in conflict. In
this paper, we propose novel methods for using language-specific subnetworks,
which control cross-lingual parameter sharing, to reduce conflicts and increase
positive transfer during fine-tuning. We introduce dynamic subnetworks, which
are jointly updated with the model, and we combine our methods with
meta-learning, an established, but complementary, technique for improving
cross-lingual transfer. Finally, we provide extensive analyses of how each of
our methods affects the models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Where to start? Analyzing the potential value of intermediate models. (arXiv:2211.00107v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00107">
<div class="article-summary-box-inner">
<span><p>Previous studies observed that finetuned models may be better base models
than the vanilla pretrained model. Such a model, finetuned on some source
dataset, may provide a better starting point for a new finetuning process on a
desired target dataset. Here, we perform a systematic analysis of this
\emph{intertraining} scheme, over a wide range of English classification tasks.
Surprisingly, our analysis suggests that the potential intertraining gain can
be analyzed \emph{independently} for the target dataset under consideration,
and for a base model being considered as a starting point. This is in contrast
to current perception that the alignment between the target dataset and the
source dataset used to generate the base model is a major factor in determining
intertraining success. We analyze different aspects that contribute to each.
Furthermore, we leverage our analysis to propose a practical and efficient
approach to determine if and how to select a base model in real-world settings.
Last, we release an updating ranking of best models in the HuggingFace hub per
architecture\anonm{remove this link: https://ibm.github.io/model-recycling/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Textless Direct Speech-to-Speech Translation with Discrete Speech Representation. (arXiv:2211.00115v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00115">
<div class="article-summary-box-inner">
<span><p>Research on speech-to-speech translation (S2ST) has progressed rapidly in
recent years. Many end-to-end systems have been proposed and show advantages
over conventional cascade systems, which are often composed of recognition,
translation and synthesis sub-systems. However, most of the end-to-end systems
still rely on intermediate textual supervision during training, which makes it
infeasible to work for languages without written forms. In this work, we
propose a novel model, Textless Translatotron, which is based on Translatotron
2, for training an end-to-end direct S2ST model without any textual
supervision. Instead of jointly training with an auxiliary task predicting
target phonemes as in Translatotron 2, the proposed model uses an auxiliary
task predicting discrete speech representations which are obtained from learned
or random speech quantizers. When a speech encoder pre-trained with
unsupervised speech data is used for both models, the proposed model obtains
translation quality nearly on-par with Translatotron 2 on the multilingual
CVSS-C corpus as well as the bilingual Fisher Spanish-English corpus. On the
latter, it outperforms the prior state-of-the-art textless model by +18.5 BLEU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TaTa: A Multilingual Table-to-Text Dataset for African Languages. (arXiv:2211.00142v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00142">
<div class="article-summary-box-inner">
<span><p>Existing data-to-text generation datasets are mostly limited to English. To
address this lack of data, we create Table-to-Text in African languages (TaTa),
the first large multilingual table-to-text dataset with a focus on African
languages. We created TaTa by transcribing figures and accompanying text in
bilingual reports by the Demographic and Health Surveys Program, followed by
professional translation to make the dataset fully parallel. TaTa includes
8,700 examples in nine languages including four African languages (Hausa, Igbo,
Swahili, and Yor\`ub\'a) and a zero-shot test language (Russian). We
additionally release screenshots of the original figures for future research on
multilingual multi-modal approaches. Through an in-depth human evaluation, we
show that TaTa is challenging for current models and that less than half the
outputs from an mT5-XXL-based model are understandable and attributable to the
source data. We further demonstrate that existing metrics perform poorly for
TaTa and introduce learned metrics that achieve a high correlation with human
judgments. We release all data and annotations at
https://github.com/google-research/url-nlp.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Close Look into the Calibration of Pre-trained Language Models. (arXiv:2211.00151v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00151">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PLMs) achieve remarkable performance on many
downstream tasks, but may fail in giving reliable estimates of their predictive
uncertainty. Given the lack of a comprehensive understanding of PLMs
calibration, we take a close look into this new research problem, aiming to
answer two questions: (1) Do PLMs learn to become calibrated in the training
process? (2) How effective are existing calibration methods? For the first
question, we conduct fine-grained control experiments to study the dynamic
change in PLMs' calibration performance in training. We consider six factors as
control variables, including dataset difficulty, available training samples,
training steps, the number of tunable parameters, model scale, and pretraining.
In experiments, we observe a consistent change in calibration performance
across six factors. We find that PLMs don't learn to become calibrated in
training, evidenced by the continual increase in confidence, no matter the
predictions are correct or not. We highlight that our finding presents some
contradiction with two established conclusions: (a) Larger PLMs are more
calibrated; (b) Pretraining improves model calibration. Next, we study the
effectiveness of existing calibration methods in mitigating the overconfidence
issue, in both in-distribution and various out-of-distribution settings.
Besides unlearnable calibration methods, we adapt two recently proposed
learnable methods that directly collect data to train models to have reasonable
confidence estimations. Also, we propose extended learnable methods based on
existing ones to further improve or maintain PLMs calibration without
sacrificing the original task performance. Experimental results show that
learnable methods significantly reduce PLMs' confidence in wrong predictions,
and our methods exhibit superior performance compared with previous methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do LSTMs See Gender? Probing the Ability of LSTMs to Learn Abstract Syntactic Rules. (arXiv:2211.00153v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00153">
<div class="article-summary-box-inner">
<span><p>LSTMs trained on next-word prediction can accurately perform linguistic tasks
that require tracking long-distance syntactic dependencies. Notably, model
accuracy approaches human performance on number agreement tasks (Gulordava et
al., 2018). However, we do not have a mechanistic understanding of how LSTMs
perform such linguistic tasks. Do LSTMs learn abstract grammatical rules, or do
they rely on simple heuristics? Here, we test gender agreement in French which
requires tracking both hierarchical syntactic structures and the inherent
gender of lexical units. Our model is able to reliably predict long-distance
gender agreement in two subject-predicate contexts: noun-adjective and
noun-passive-verb agreement. The model showed more inaccuracies on plural noun
phrases with gender attractors compared to singular cases, suggesting a
reliance on clues from gendered articles for agreement. Overall, our study
highlights key ways in which LSTMs deviate from human behaviour and questions
whether LSTMs genuinely learn abstract syntactic rules and categories. We
propose using gender agreement as a useful probe to investigate the underlying
mechanisms, internal representations, and linguistic capabilities of LSTM
language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Emotion Embeddings to Transfer Knowledge Between Emotions, Languages, and Annotation Formats. (arXiv:2211.00171v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00171">
<div class="article-summary-box-inner">
<span><p>The need for emotional inference from text continues to diversify as more and
more disciplines integrate emotions into their theories and applications. These
needs include inferring different emotion types, handling multiple languages,
and different annotation formats. A shared model between different
configurations would enable the sharing of knowledge and a decrease in training
costs, and would simplify the process of deploying emotion recognition models
in novel environments. In this work, we study how we can build a single model
that can transition between these different configurations by leveraging
multilingual models and Demux, a transformer-based model whose input includes
the emotions of interest, enabling us to dynamically change the emotions
predicted by the model. Demux also produces emotion embeddings, and performing
operations on them allows us to transition to clusters of emotions by pooling
the embeddings of each cluster. We show that Demux can simultaneously transfer
knowledge in a zero-shot manner to a new language, to a novel annotation format
and to unseen emotions. Code is available at
https://github.com/gchochla/Demux-MEmo .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Audio/Text Training for Transformer Rescorer of Streaming Speech Recognition. (arXiv:2211.00174v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00174">
<div class="article-summary-box-inner">
<span><p>Recently, there has been an increasing interest in two-pass streaming
end-to-end speech recognition (ASR) that incorporates a 2nd-pass rescoring
model on top of the conventional 1st-pass streaming ASR model to improve
recognition accuracy while keeping latency low. One of the latest 2nd-pass
rescoring model, Transformer Rescorer, takes the n-best initial outputs and
audio embeddings from the 1st-pass model, and then choose the best output by
re-scoring the n-best initial outputs. However, training this Transformer
Rescorer requires expensive paired audio-text training data because the model
uses audio embeddings as input. In this work, we present our Joint Audio/Text
training method for Transformer Rescorer, to leverage unpaired text-only data
which is relatively cheaper than paired audio-text data. We evaluate
Transformer Rescorer with our Joint Audio/Text training on Librispeech dataset
as well as our large-scale in-house dataset and show that our training method
can improve word error rate (WER) significantly compared to standard
Transformer Rescorer without requiring any extra model parameters or latency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CCS Explorer: Relevance Prediction, Extractive Summarization, and Named Entity Recognition from Clinical Cohort Studies. (arXiv:2211.00201v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00201">
<div class="article-summary-box-inner">
<span><p>Clinical Cohort Studies (CCS) are a great source of documented clinical
research. Ideally, a clinical expert will interpret these articles for
exploratory analysis ranging from drug discovery for evaluating the efficacy of
existing drugs in tackling emerging diseases to the first test of newly
developed drugs. However, more than 100 CCS articles are published on PubMed
every day. As a result, it can take days for a doctor to find articles and
extract relevant information. Can we find a way to quickly sift through the
long list of these articles faster and document the crucial takeaways from each
of these articles? In this work, we propose CCS Explorer, an end-to-end system
for relevance prediction of sentences, extractive summarization, and patient,
outcome, and intervention entity detection from CCS. CCS Explorer is packaged
in a web-based graphical user interface where the user can provide any disease
name. CCS Explorer then extracts and aggregates all relevant information from
articles on PubMed based on the results of an automatically generated query
produced on the back-end. CCS Explorer fine-tunes pre-trained language models
based on transformers with additional layers for each of these tasks. We
evaluate the models using two publicly available datasets. CCS Explorer obtains
a recall of 80.2%, AUC-ROC of 0.843, and an accuracy of 88.3% on sentence
relevance prediction using BioBERT and achieves an average Micro F1-Score of
77.8% on Patient, Intervention, Outcome detection (PIO) using PubMedBERT. Thus,
CCS Explorer can reliably extract relevant information to summarize articles,
saving time by ~ 660$\times$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Why Is It Hate Speech? Masked Rationale Prediction for Explainable Hate Speech Detection. (arXiv:2211.00243v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00243">
<div class="article-summary-box-inner">
<span><p>In a hate speech detection model, we should consider two critical aspects in
addition to detection performance-bias and explainability. Hate speech cannot
be identified based solely on the presence of specific words: the model should
be able to reason like humans and be explainable. To improve the performance
concerning the two aspects, we propose Masked Rationale Prediction (MRP) as an
intermediate task. MRP is a task to predict the masked human
rationales-snippets of a sentence that are grounds for human judgment-by
referring to surrounding tokens combined with their unmasked rationales. As the
model learns its reasoning ability based on rationales by MRP, it performs hate
speech detection robustly in terms of bias and explainability. The proposed
method generally achieves state-of-the-art performance in various metrics,
demonstrating its effectiveness for hate speech detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FADO: Feedback-Aware Double COntrolling Network for Emotional Support Conversation. (arXiv:2211.00250v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00250">
<div class="article-summary-box-inner">
<span><p>Emotional Support Conversation (ESConv) aims to reduce help-seekers'emotional
distress with the supportive strategy and response. It is essential for the
supporter to select an appropriate strategy with the feedback of the
help-seeker (e.g., emotion change during dialog turns, etc) in ESConv. However,
previous methods mainly focus on the dialog history to select the strategy and
ignore the help-seeker's feedback, leading to the wrong and user-irrelevant
strategy prediction. In addition, these approaches only model the
context-to-strategy flow and pay less attention to the strategy-to-context flow
that can focus on the strategy-related context for generating the
strategy-constrain response. In this paper, we propose a Feedback-Aware Double
COntrolling Network (FADO) to make a strategy schedule and generate the
supportive response. The core module in FADO consists of a dual-level feedback
strategy selector and a double control reader. Specifically, the dual-level
feedback strategy selector leverages the turn-level and conversation-level
feedback to encourage or penalize strategies. The double control reader
constructs the novel strategy-to-context flow for generating the
strategy-constrain response. Furthermore, a strategy dictionary is designed to
enrich the semantic information of the strategy and improve the quality of
strategy-constrain response. Experimental results on ESConv show that the
proposed FADO has achieved the state-of-the-art performance in terms of both
strategy selection and response generation. Our code is available at
https://github/after/reviewing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CARE: Causality Reasoning for Empathetic Responses by Conditional Graph Generation. (arXiv:2211.00255v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00255">
<div class="article-summary-box-inner">
<span><p>Recent approaches to empathetic response generation incorporate emotion
causalities to enhance comprehension of both the user's feelings and
experiences. However, these approaches suffer from two critical issues. First,
they only consider causalities between the user's emotion and the user's
experiences, and ignore those between the user's experiences. Second, they
neglect interdependence among causalities and reason them independently. To
solve the above problems, we expect to reason all plausible causalities
interdependently and simultaneously, given the user's emotion, dialogue
history, and future dialogue content. Then, we infuse these causalities into
response generation for empathetic responses. Specifically, we design a new
model, i.e., the Conditional Variational Graph Auto-Encoder (CVGAE), for the
causality reasoning, and adopt a multi-source attention mechanism in the
decoder for the causality infusion. We name the whole framework as CARE,
abbreviated for CAusality Reasoning for Empathetic conversation. Experimental
results indicate that our method achieves state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training Vision-Language Models with Less Bimodal Supervision. (arXiv:2211.00262v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00262">
<div class="article-summary-box-inner">
<span><p>Standard practice in pretraining multimodal models, such as vision-language
models, is to rely on pairs of aligned inputs from both modalities, for
example, aligned image-text pairs. However, such pairs can be difficult to
obtain in low-resource settings and for some modality pairs (e.g., structured
tables and images). In this work, we investigate the extent to which we can
reduce the reliance on such parallel data, which we term \emph{bimodal
supervision}, and use models that are pretrained on each modality
independently. We experiment with a high-performing vision-language model, and
analyze the effect of bimodal supervision on three vision-language tasks. We
find that on simpler tasks, such as VQAv2 and GQA, one can eliminate bimodal
supervision completely, suffering only a minor loss in performance. Conversely,
for NLVR2, which requires more complex reasoning, training without bimodal
supervision leads to random performance. Nevertheless, using only 5\% of the
bimodal data (142K images along with their captions), or leveraging weak
supervision in the form of a list of machine-generated labels for each image,
leads to only a moderate degradation compared to using 3M image-text pairs:
74\%$\rightarrow$$\sim$70\%. Our code is available at
https://github.com/eladsegal/less-bimodal-sup.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FRSUM: Towards Faithful Abstractive Summarization via Enhancing Factual Robustness. (arXiv:2211.00294v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00294">
<div class="article-summary-box-inner">
<span><p>Despite being able to generate fluent and grammatical text, current Seq2Seq
summarization models still suffering from the unfaithful generation problem. In
this paper, we study the faithfulness of existing systems from a new
perspective of factual robustness which is the ability to correctly generate
factual information over adversarial unfaithful information. We first measure a
model's factual robustness by its success rate to defend against adversarial
attacks when generating factual information. The factual robustness analysis on
a wide range of current systems shows its good consistency with human judgments
on faithfulness. Inspired by these findings, we propose to improve the
faithfulness of a model by enhancing its factual robustness. Specifically, we
propose a novel training strategy, namely FRSUM, which teaches the model to
defend against both explicit adversarial samples and implicit factual
adversarial perturbations. Extensive automatic and human evaluation results
show that FRSUM consistently improves the faithfulness of various Seq2Seq
models, such as T5, BART.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CONDAQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation. (arXiv:2211.00295v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00295">
<div class="article-summary-box-inner">
<span><p>The full power of human language-based communication cannot be realized
without negation. All human languages have some form of negation. Despite this,
negation remains a challenging phenomenon for current natural language
understanding systems. To facilitate the future development of models that can
process negation effectively, we present CONDAQA, the first English reading
comprehension dataset which requires reasoning about the implications of
negated statements in paragraphs. We collect paragraphs with diverse negation
cues, then have crowdworkers ask questions about the implications of the
negated statement in the passage. We also have workers make three kinds of
edits to the passage -- paraphrasing the negated statement, changing the scope
of the negation, and reversing the negation -- resulting in clusters of
question-answer pairs that are difficult for models to answer with spurious
shortcuts. CONDAQA features 14,182 question-answer pairs with over 200 unique
negation cues and is challenging for current state-of-the-art models. The best
performing model on CONDAQA (UnifiedQA-v2-3b) achieves only 42% on our
consistency metric, well below human performance which is 81%. We release our
dataset, along with fully-finetuned, few-shot, and zero-shot evaluations, to
facilitate the development of future NLP methods that work on negated language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recognizing Nested Entities from Flat Supervision: A New NER Subtask, Feasibility and Challenges. (arXiv:2211.00301v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00301">
<div class="article-summary-box-inner">
<span><p>Many recent named entity recognition (NER) studies criticize flat NER for its
non-overlapping assumption, and switch to investigating nested NER. However,
existing nested NER models heavily rely on training data annotated with nested
entities, while labeling such data is costly. This study proposes a new
subtask, nested-from-flat NER, which corresponds to a realistic application
scenario: given data annotated with flat entities only, one may still desire
the trained model capable of recognizing nested entities. To address this task,
we train span-based models and deliberately ignore the spans nested inside
labeled entities, since these spans are possibly unlabeled entities. With
nested entities removed from the training data, our model achieves 54.8%, 54.2%
and 41.1% F1 scores on the subset of spans within entities on ACE 2004, ACE
2005 and GENIA, respectively. This suggests the effectiveness of our approach
and the feasibility of the task. In addition, the model's performance on flat
entities is entirely unaffected. We further manually annotate the nested
entities in the test set of CoNLL 2003, creating a nested-from-flat NER
benchmark. Analysis results show that the main challenges stem from the data
and annotation inconsistencies between the flat and nested entities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speech-text based multi-modal training with bidirectional attention for improved speech recognition. (arXiv:2211.00325v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00325">
<div class="article-summary-box-inner">
<span><p>To let the state-of-the-art end-to-end ASR model enjoy data efficiency, as
well as much more unpaired text data by multi-modal training, one needs to
address two problems: 1) the synchronicity of feature sampling rates between
speech and language (aka text data); 2) the homogeneity of the learned
representations from two encoders. In this paper we propose to employ a novel
bidirectional attention mechanism (BiAM) to jointly learn both ASR encoder
(bottom layers) and text encoder with a multi-modal learning method. The BiAM
is to facilitate feature sampling rate exchange, realizing the quality of the
transformed features for the one kind to be measured in another space, with
diversified objective functions. As a result, the speech representations are
enriched with more linguistic information, while the representations generated
by the text encoder are more similar to corresponding speech ones, and
therefore the shared ASR models are more amenable for unpaired text data
pretraining. To validate the efficacy of the proposed method, we perform two
categories of experiments with or without extra unpaired text data.
Experimental results on Librispeech corpus show it can achieve up to 6.15% word
error rate reduction (WERR) with only paired data learning, while 9.23% WERR
when more unpaired text data is employed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Content-Aware Neural Text-To-Speech MOS Prediction Using Prosodic and Linguistic Features. (arXiv:2211.00342v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00342">
<div class="article-summary-box-inner">
<span><p>Current state-of-the-art methods for automatic synthetic speech evaluation
are based on MOS prediction neural models. Such MOS prediction models include
MOSNet and LDNet that use spectral features as input, and SSL-MOS that relies
on a pretrained self-supervised learning model that directly uses the speech
signal as input. In modern high-quality neural TTS systems, prosodic
appropriateness with regard to the spoken content is a decisive factor for
speech naturalness. For this reason, we propose to include prosodic and
linguistic features as additional inputs in MOS prediction systems, and
evaluate their impact on the prediction outcome. We consider phoneme level F0
and duration features as prosodic inputs, as well as Tacotron encoder outputs,
POS tags and BERT embeddings as higher-level linguistic inputs. All MOS
prediction systems are trained on SOMOS, a neural TTS-only dataset with
crowdsourced naturalness MOS evaluations. Results show that the proposed
additional features are beneficial in the MOS prediction task, by improving the
predicted MOS scores' correlation with the ground truths, both at
utterance-level and system-level predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anytime Generation of Counterfactual Explanations for Text Classification. (arXiv:2211.00369v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00369">
<div class="article-summary-box-inner">
<span><p>In many machine learning applications, it is important for the user to
understand the reasoning behind the recommendation or prediction of the
classifiers. The learned models, however, are often too complicated to be
understood by a human. Research from the social sciences indicates that humans
prefer counterfactual explanations over alternatives. In this paper, we present
a general framework for generating counterfactual explanations in the textual
domain. Our framework is model-agnostic, representation-agnostic,
domain-agnostic, and anytime. We model the task as a search problem in a space
where the initial state is the classified text, and the goal state is a text in
the complementary class. The operators transform a text by replacing parts of
it. Our framework includes domain-independent operators, but can also exploit
domain-specific knowledge through specialized operators. The search algorithm
attempts to find a text from the complementary class with minimal word-level
Levenshtein distance from the original classified object.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Gender-Ambiguous Text-to-Speech Voices. (arXiv:2211.00375v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00375">
<div class="article-summary-box-inner">
<span><p>The gender of a voice assistant or any voice user interface is a central
element of its perceived identity. While a female voice is a common choice,
there is an increasing interest in alternative approaches where the gender is
ambiguous rather than clearly identifying as female or male. This work
addresses the task of generating gender-ambiguous text-to-speech (TTS) voices
that do not correspond to any existing person. This is accomplished by sampling
from a latent speaker embeddings' space that was formed while training a
multilingual, multi-speaker TTS system on data from multiple male and female
speakers. Various options are investigated regarding the sampling process. In
our experiments, the effects of different sampling choices on the gender
ambiguity and the naturalness of the resulting voices are evaluated. The
proposed method is shown able to efficiently generate novel speakers that are
superior to a baseline averaged speaker embedding. To our knowledge, this is
the first systematic approach that can reliably generate a range of
gender-ambiguous voices to meet diverse user requirements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The future is different: Large pre-trained language models fail in prediction tasks. (arXiv:2211.00384v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00384">
<div class="article-summary-box-inner">
<span><p>Large pre-trained language models (LPLM) have shown spectacular success when
fine-tuned on downstream supervised tasks. Yet, it is known that their
performance can drastically drop when there is a distribution shift between the
data used during training and that used at inference time. In this paper we
focus on data distributions that naturally change over time and introduce four
new REDDIT datasets, namely the WALLSTREETBETS, ASKSCIENCE, THE DONALD, and
POLITICS sub-reddits. First, we empirically demonstrate that LPLM can display
average performance drops of about 88% (in the best case!) when predicting the
popularity of future posts from sub-reddits whose topic distribution changes
with time. We then introduce a simple methodology that leverages neural
variational dynamic topic models and attention mechanisms to infer temporal
language model representations for regression tasks. Our models display
performance drops of only about 40% in the worst cases (2% in the best ones)
when predicting the popularity of future posts, while using only about 7% of
the total number of parameters of LPLM and providing interpretable
representations that offer insight into real-world events, like the GameStop
short squeeze of 2021
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Order-sensitive Neural Constituency Parsing. (arXiv:2211.00421v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00421">
<div class="article-summary-box-inner">
<span><p>We propose a novel algorithm that improves on the previous neural span-based
CKY decoder for constituency parsing. In contrast to the traditional span-based
decoding, where spans are combined only based on the sum of their scores, we
introduce an order-sensitive strategy, where the span combination scores are
more carefully derived from an order-sensitive basis. Our decoder can be
regarded as a generalization over existing span-based decoder in determining a
finer-grain scoring scheme for the combination of lower-level spans into
higher-level spans, where we emphasize on the order of the lower-level spans
and use order-sensitive span scores as well as order-sensitive combination
grammar rule scores to enhance prediction accuracy. We implement the proposed
decoding strategy harnessing GPU parallelism and achieve a decoding speed on
par with state-of-the-art span-based parsers. Using the previous
state-of-the-art model without additional data as our baseline, we outperform
it and improve the F1 score on the Penn Treebank Dataset by 0.26% and on the
Chinese Treebank Dataset by 0.35%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VarMAE: Pre-training of Variational Masked Autoencoder for Domain-adaptive Language Understanding. (arXiv:2211.00430v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00430">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models have achieved promising performance on general
benchmarks, but underperform when migrated to a specific domain. Recent works
perform pre-training from scratch or continual pre-training on domain corpora.
However, in many specific domains, the limited corpus can hardly support
obtaining precise representations. To address this issue, we propose a novel
Transformer-based language model named VarMAE for domain-adaptive language
understanding. Under the masked autoencoding objective, we design a context
uncertainty learning module to encode the token's context into a smooth latent
distribution. The module can produce diverse and well-formed contextual
representations. Experiments on science- and finance-domain NLU tasks
demonstrate that VarMAE can be efficiently adapted to new domains with limited
resources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting the Practical Effectiveness of Constituency Parse Extraction from Pre-trained Language Models. (arXiv:2211.00479v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00479">
<div class="article-summary-box-inner">
<span><p>Constituency Parse Extraction from Pre-trained Language Models (CPE-PLM) is a
recent paradigm that attempts to induce constituency parse trees relying only
on the internal knowledge of pre-trained language models. While attractive in
the perspective that similar to in-context learning, it does not require
task-specific fine-tuning, the practical effectiveness of such an approach
still remains unclear, except that it can function as a probe for investigating
language models' inner workings. In this work, we mathematically reformulate
CPE-PLM and propose two advanced ensemble methods tailored for it,
demonstrating that the new parsing paradigm can be competitive with common
unsupervised parsers by introducing a set of heterogeneous PLMs combined using
our techniques. Furthermore, we explore some scenarios where the trees
generated by CPE-PLM are practically useful. Specifically, we show that CPE-PLM
is more effective than typical supervised parsers in few-shot settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast and parallel decoding for transducer. (arXiv:2211.00484v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00484">
<div class="article-summary-box-inner">
<span><p>The transducer architecture is becoming increasingly popular in the field of
speech recognition, because it is naturally streaming as well as high in
accuracy. One of the drawbacks of transducer is that it is difficult to decode
in a fast and parallel way due to an unconstrained number of symbols that can
be emitted per time step. In this work, we introduce a constrained version of
transducer loss to learn strictly monotonic alignments between the sequences;
we also improve the standard greedy search and beam search algorithms by
limiting the number of symbols that can be emitted per time step in transducer
decoding, making it more efficient to decode in parallel with batches.
Furthermore, we propose an finite state automaton-based (FSA) parallel beam
search algorithm that can run with graphs on GPU efficiently. The experiment
results show that we achieve slight word error rate (WER) improvement as well
as significant speedup in decoding. Our work is open-sourced and publicly
available\footnote{https://github.com/k2-fsa/icefall}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Delay-penalized transducer for low-latency streaming ASR. (arXiv:2211.00490v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00490">
<div class="article-summary-box-inner">
<span><p>In streaming automatic speech recognition (ASR), it is desirable to reduce
latency as much as possible while having minimum impact on recognition
accuracy. Although a few existing methods are able to achieve this goal, they
are difficult to implement due to their dependency on external alignments. In
this paper, we propose a simple way to penalize symbol delay in transducer
model, so that we can balance the trade-off between symbol delay and accuracy
for streaming models without external alignments. Specifically, our method adds
a small constant times (T/2 - t), where T is the number of frames and t is the
current frame, to all the non-blank log-probabilities (after normalization)
that are fed into the two dimensional transducer recursion. For both streaming
Conformer models and unidirectional long short-term memory (LSTM) models,
experimental results show that it can significantly reduce the symbol delay
with an acceptable performance degradation. Our method achieves similar
delay-accuracy trade-off to the previously published FastEmit, but we believe
our method is preferable because it has a better justification: it is
equivalent to penalizing the average symbol delay. Our work is open-sourced and
publicly available (https://github.com/k2-fsa/k2).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting Multi-Codebook Vector Quantization Indexes for Knowledge Distillation. (arXiv:2211.00508v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00508">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation(KD) is a common approach to improve model performance
in automatic speech recognition (ASR), where a student model is trained to
imitate the output behaviour of a teacher model. However, traditional KD
methods suffer from teacher label storage issue, especially when the training
corpora are large. Although on-the-fly teacher label generation tackles this
issue, the training speed is significantly slower as the teacher model has to
be evaluated every batch. In this paper, we reformulate the generation of
teacher label as a codec problem. We propose a novel Multi-codebook Vector
Quantization (MVQ) approach that compresses teacher embeddings to codebook
indexes (CI). Based on this, a KD training framework (MVQ-KD) is proposed where
a student model predicts the CI generated from the embeddings of a
self-supervised pre-trained teacher model. Experiments on the LibriSpeech
clean-100 hour show that MVQ-KD framework achieves comparable performance as
traditional KD methods (l1, l2), while requiring 256 times less storage. When
the full LibriSpeech dataset is used, MVQ-KD framework results in 13.8% and
8.2% relative word error rate reductions (WERRs) for non -streaming transducer
on test-clean and test-other and 4.0% and 4.9% for streaming transducer. The
implementation of this work is already released as a part of the open-source
project icefall.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">E2E Refined Dataset. (arXiv:2211.00513v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00513">
<div class="article-summary-box-inner">
<span><p>Although the well-known MR-to-text E2E dataset has been used by many
researchers, its MR-text pairs include many deletion/insertion/substitution
errors. Since such errors affect the quality of MR-to-text systems, they must
be fixed as much as possible. Therefore, we developed a refined dataset and
some python programs that convert the original E2E dataset into a refined
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TrimTail: Low-Latency Streaming ASR with Simple but Effective Spectrogram-Level Length Penalty. (arXiv:2211.00522v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00522">
<div class="article-summary-box-inner">
<span><p>In this paper, we present TrimTail, a simple but effective emission
regularization method to improve the latency of streaming ASR models. The core
idea of TrimTail is to apply length penalty (i.e., by trimming trailing frames,
see Fig. 1-(b)) directly on the spectrogram of input utterances, which does not
require any alignment. We demonstrate that TrimTail is computationally cheap
and can be applied online and optimized with any training loss or any model
architecture on any dataset without any extra effort by applying it on various
end-to-end streaming ASR networks either trained with CTC loss [1] or
Transducer loss [2]. We achieve 100 $\sim$ 200ms latency reduction with equal
or even better accuracy on both Aishell-1 and Librispeech. Moreover, by using
TrimTail, we can achieve a 400ms algorithmic improvement of User Sensitive
Delay (USD) with an accuracy loss of less than 0.2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning utterance-level representations through token-level acoustic latents prediction for Expressive Speech Synthesis. (arXiv:2211.00523v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00523">
<div class="article-summary-box-inner">
<span><p>This paper proposes an Expressive Speech Synthesis model that utilizes
token-level latent prosodic variables in order to capture and control
utterance-level attributes, such as character acting voice and speaking style.
Current works aim to explicitly factorize such fine-grained and utterance-level
speech attributes into different representations extracted by modules that
operate in the corresponding level. We show that the fine-grained latent space
also captures coarse-grained information, which is more evident as the
dimension of latent space increases in order to capture diverse prosodic
representations. Therefore, a trade-off arises between the diversity of the
token-level and utterance-level representations and their disentanglement. We
alleviate this issue by first capturing rich speech attributes into a
token-level latent space and then, separately train a prior network that given
the input text, learns utterance-level representations in order to predict the
phoneme-level, posterior latents extracted during the previous step. Both
qualitative and quantitative evaluations are used to demonstrate the
effectiveness of the proposed approach. Audio samples are available in our demo
page.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Graph-based Cross-modal Information Fusion for Neural Sign Language Translation. (arXiv:2211.00526v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00526">
<div class="article-summary-box-inner">
<span><p>Sign Language (SL), as the mother tongue of the deaf community, is a special
visual language that most hearing people cannot understand. In recent years,
neural Sign Language Translation (SLT), as a possible way for bridging
communication gap between the deaf and the hearing people, has attracted
widespread academic attention. We found that the current mainstream end-to-end
neural SLT models, which tries to learning language knowledge in a weakly
supervised manner, could not mine enough semantic information under the
condition of low data resources. Therefore, we propose to introduce additional
word-level semantic knowledge of sign language linguistics to assist in
improving current end-to-end neural SLT models. Concretely, we propose a novel
neural SLT model with multi-modal feature fusion based on the dynamic graph, in
which the cross-modal information, i.e. text and video, is first assembled as a
dynamic graph according to their correlation, and then the graph is processed
by a multi-modal graph encoder to generate the multi-modal embeddings for
further usage in the subsequent neural translation models. To the best of our
knowledge, we are the first to introduce graph neural networks, for fusing
multi-modal information, into neural sign language translation models.
Moreover, we conducted experiments on a publicly available popular SLT dataset
RWTH-PHOENIX-Weather-2014T. and the quantitative experiments show that our
method can improve the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ClassActionPrediction: A Challenging Benchmark for Legal Judgment Prediction of Class Action Cases in the US. (arXiv:2211.00582v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00582">
<div class="article-summary-box-inner">
<span><p>The research field of Legal Natural Language Processing (NLP) has been very
active recently, with Legal Judgment Prediction (LJP) becoming one of the most
extensively studied tasks. To date, most publicly released LJP datasets
originate from countries with civil law. In this work, we release, for the
first time, a challenging LJP dataset focused on class action cases in the US.
It is the first dataset in the common law system that focuses on the harder and
more realistic task involving the complaints as input instead of the often used
facts summary written by the court. Additionally, we study the difficulty of
the task by collecting expert human predictions, showing that even human
experts can only reach 53% accuracy on this dataset. Our Longformer model
clearly outperforms the human baseline (63%), despite only considering the
first 2,048 tokens. Furthermore, we perform a detailed error analysis and find
that the Longformer model is significantly better calibrated than the human
experts. Finally, we publicly release the dataset and the code used for the
experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">T5lephone: Bridging Speech and Text Self-supervised Models for Spoken Language Understanding via Phoneme level T5. (arXiv:2211.00586v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00586">
<div class="article-summary-box-inner">
<span><p>In Spoken language understanding (SLU), a natural solution is concatenating
pre-trained speech models (e.g. HuBERT) and pretrained language models (PLM,
e.g. T5). Most previous works use pretrained language models with subword-based
tokenization. However, the granularity of input units affects the alignment of
speech model outputs and language model inputs, and PLM with character-based
tokenization is underexplored. In this work, we conduct extensive studies on
how PLMs with different tokenization strategies affect spoken language
understanding task including spoken question answering (SQA) and speech
translation (ST). We further extend the idea to create T5lephone(pronounced as
telephone), a variant of T5 that is pretrained using phonemicized text. We
initialize T5lephone with existing PLMs to pretrain it using relatively
lightweight computational resources. We reached state-of-the-art on NMSQA, and
the T5lephone model exceeds T5 with other types of units on end-to-end SQA and
ST.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small. (arXiv:2211.00593v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00593">
<div class="article-summary-box-inner">
<span><p>Research in mechanistic interpretability seeks to explain behaviors of
machine learning models in terms of their internal components. However, most
previous work either focuses on simple behaviors in small models, or describes
complicated behaviors in larger models with broad strokes. In this work, we
bridge this gap by presenting an explanation for how GPT-2 small performs a
natural language task called indirect object identification (IOI). Our
explanation encompasses 26 attention heads grouped into 7 main classes, which
we discovered using a combination of interpretability approaches relying on
causal interventions. To our knowledge, this investigation is the largest
end-to-end attempt at reverse-engineering a natural behavior "in the wild" in a
language model. We evaluate the reliability of our explanation using three
quantitative criteria--faithfulness, completeness and minimality. Though these
criteria support our explanation, they also point to remaining gaps in our
understanding. Our work provides evidence that a mechanistic understanding of
large ML models is feasible, opening opportunities to scale our understanding
to both larger models and more complex tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Natural Language Deduction with Incomplete Information. (arXiv:2211.00614v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00614">
<div class="article-summary-box-inner">
<span><p>A growing body of work studies how to answer a question or verify a claim by
generating a natural language "proof": a chain of deductive inferences yielding
the answer based on a set of premises. However, these methods can only make
sound deductions when they follow from evidence that is given. We propose a new
system that can handle the underspecified setting where not all premises are
stated at the outset; that is, additional assumptions need to be materialized
to prove a claim. By using a natural language generation model to abductively
infer a premise given another premise and a conclusion, we can impute missing
pieces of evidence needed for the conclusion to be true. Our system searches
over two fringes in a bidirectional fashion, interleaving deductive
(forward-chaining) and abductive (backward-chaining) generation steps. We
sample multiple possible outputs for each step to achieve coverage of the
search space, at the same time ensuring correctness by filtering low-quality
generations with a round-trip validation procedure. Results on a modified
version of the EntailmentBank dataset and a new dataset called Everyday Norms:
Why Not? show that abductive generation with validation can recover premises
across in- and out-of-domain settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Preserving In-Context Learning ability in Large Language Model Fine-tuning. (arXiv:2211.00635v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00635">
<div class="article-summary-box-inner">
<span><p>Pretrained large language models (LLMs) are strong in-context learners that
are able to perform few-shot learning without changing model parameters.
However, as we show, fine-tuning an LLM on any specific task generally destroys
its in-context ability. We discover an important cause of this loss, format
specialization, where the model overfits to the format of the fine-tuned task
and is unable to output anything beyond this format. We further show that
format specialization happens at the beginning of fine-tuning. To solve this
problem, we propose Prompt Tuning with MOdel Tuning (ProMoT), a simple yet
effective two-stage fine-tuning framework that preserves in-context abilities
of the pretrained model. ProMoT first trains a soft prompt for the fine-tuning
target task, and then fine-tunes the model itself with this soft prompt
attached. ProMoT offloads task-specific formats into the soft prompt that can
be removed when doing other in-context tasks. We fine-tune mT5 XXL with ProMoT
on natural language inference (NLI) and English-French translation and evaluate
the in-context abilities of the resulting models on 8 different NLP tasks.
ProMoT achieves similar performance on the fine-tuned tasks compared with
vanilla fine-tuning, but with much less reduction of in-context learning
performances across the board. More importantly, ProMoT shows remarkable
generalization ability on tasks that have different formats, e.g. fine-tuning
on a NLI binary classification task improves the model's in-context ability to
do summarization (+0.53 Rouge-2 score compared to the pretrained model), making
ProMoT a promising method to build general purpose capabilities such as
grounding and reasoning into LLMs with small but high quality datasets. When
extended to sequential or multi-task training, ProMoT can achieve even better
out-of-domain generalization performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GENIE: Toward Reproducible and Standardized Human Evaluation for Text Generation. (arXiv:2101.06561v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06561">
<div class="article-summary-box-inner">
<span><p>While often assumed a gold standard, effective human evaluation of text
generation remains an important, open area for research. We revisit this
problem with a focus on producing consistent evaluations that are reproducible
-- over time and across different populations. We study this goal in different
stages of the human evaluation pipeline. In particular, we consider design
choices for the annotation interface used to elicit human judgments and their
impact on reproducibility. Furthermore, we develop an automated mechanism for
maintaining annotator quality via a probabilistic model that detects and
excludes noisy annotators. Putting these lessons together, we introduce GENIE:
a system for running standardized human evaluations across different generation
tasks. We instantiate GENIE with datasets representing four core challenges in
text generation: machine translation, summarization, commonsense reasoning, and
machine comprehension. For each task, GENIE offers a leaderboard that
automatically crowdsources annotations for submissions, evaluating them along
axes such as correctness, conciseness, and fluency. We have made the GENIE
leaderboards publicly available, and have already ranked 50 submissions from 10
different research groups. We hope GENIE encourages further progress toward
effective, standardized evaluations for text generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing the Transformer Decoder with Transition-based Syntax. (arXiv:2101.12640v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.12640">
<div class="article-summary-box-inner">
<span><p>Notwithstanding recent advances, syntactic generalization remains a challenge
for text decoders. While some studies showed gains from incorporating
source-side symbolic syntactic and semantic structure into text generation
Transformers, very little work addressed the decoding of such structure. We
propose a general approach for tree decoding using a transition-based approach.
Examining the challenging test case of incorporating Universal Dependencies
syntax into machine translation, we present substantial improvements on test
sets that focus on syntactic generalization, while presenting improved or
comparable performance on standard MT benchmarks. Further qualitative analysis
addresses cases where syntactic generalization in the vanilla Transformer
decoder is inadequate and demonstrates the advantages afforded by integrating
syntactic information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lower Perplexity is Not Always Human-Like. (arXiv:2106.01229v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01229">
<div class="article-summary-box-inner">
<span><p>In computational psycholinguistics, various language models have been
evaluated against human reading behavior (e.g., eye movement) to build
human-like computational models. However, most previous efforts have focused
almost exclusively on English, despite the recent trend towards linguistic
universal within the general community. In order to fill the gap, this paper
investigates whether the established results in computational psycholinguistics
can be generalized across languages. Specifically, we re-examine an established
generalization -- the lower perplexity a language model has, the more
human-like the language model is -- in Japanese with typologically different
structures from English. Our experiments demonstrate that this established
generalization exhibits a surprising lack of universality; namely, lower
perplexity is not always human-like. Moreover, this discrepancy between English
and Japanese is further explored from the perspective of (non-)uniform
information density. Overall, our results suggest that a cross-lingual
evaluation will be necessary to construct human-like computational models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating the Faithfulness of Importance Measures in NLP by Recursively Masking Allegedly Important Tokens and Retraining. (arXiv:2110.08412v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08412">
<div class="article-summary-box-inner">
<span><p>To explain NLP models a popular approach is to use importance measures, such
as attention, which inform input tokens are important for making a prediction.
However, an open question is how well these explanations accurately reflect a
model's logic, a property called faithfulness.
</p>
<p>To answer this question, we propose Recursive ROAR, a new faithfulness
metric. This works by recursively masking allegedly important tokens and then
retraining the model. The principle is that this should result in worse model
performance compared to masking random tokens. The result is a performance
curve given a masking-ratio. Furthermore, we propose a summarizing metric using
relative area-between-curves (RACU), which allows for easy comparison across
papers, models, and tasks.
</p>
<p>We evaluate 4 different importance measures on 8 different datasets, using
both LSTM-attention models and RoBERTa models. We find that the faithfulness of
importance measures is both model-dependent and task-dependent. This conclusion
contradicts previous evaluations in both computer vision and faithfulness of
attention literature.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Systematic Investigation of Commonsense Knowledge in Large Language Models. (arXiv:2111.00607v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00607">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) trained on large amounts of data have shown impressive
performance on many NLP tasks under the zero-shot and few-shot setup. Here we
aim to better understand the extent to which such models learn commonsense
knowledge -- a critical component of many NLP applications. We conduct a
systematic and rigorous zero-shot and few-shot commonsense evaluation of large
pre-trained LMs, where we: (i) carefully control for the LMs' ability to
exploit potential surface cues and annotation artefacts, and (ii) account for
variations in performance that arise from factors that are not related to
commonsense knowledge. Our findings highlight the limitations of pre-trained
LMs in acquiring commonsense knowledge without task-specific supervision;
furthermore, using larger models or few-shot evaluation are insufficient to
achieve human-level commonsense performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking the Authorship Verification Experimental Setups. (arXiv:2112.05125v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.05125">
<div class="article-summary-box-inner">
<span><p>One of the main drivers of the recent advances in authorship verification is
the PAN large-scale authorship dataset. Despite generating significant progress
in the field, inconsistent performance differences between the closed and open
test sets have been reported. To this end, we improve the experimental setup by
proposing five new public splits over the PAN dataset, specifically designed to
isolate and identify biases related to the text topic and to the author's
writing style. We evaluate several BERT-like baselines on these splits, showing
that such models are competitive with authorship verification state-of-the-art
methods. Furthermore, using explainable AI, we find that these baselines are
biased towards named entities. We show that models trained without the named
entities obtain better results and generalize better when tested on DarkReddit,
our new dataset for authorship verification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interactive Data Analysis with Next-step Natural Language Query Recommendation. (arXiv:2201.04868v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.04868">
<div class="article-summary-box-inner">
<span><p>Natural language interfaces (NLIs) provide users with a convenient way to
interactively analyze data through natural language queries. Nevertheless,
interactive data analysis is a demanding process, especially for novice data
analysts. When exploring large and complex SQL databases from different
domains, data analysts do not necessarily have sufficient knowledge about
different data tables and application domains. It makes them unable to
systematically elicit a series of topically-related and meaningful queries for
insight discovery in target domains. We develop a NLI with a step-wise query
recommendation module to assist users in choosing appropriate next-step
exploration actions. The system adopts a data-driven approach to suggest
semantically relevant and context-aware queries for application domains of
users' interest based on their query logs. Also, the system helps users
organize query histories and results into a dashboard to communicate the
discovered data insights. With a comparative user study, we show that our
system can facilitate a more effective and systematic data analysis process
than a baseline without the recommendation module.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speech Emotion Recognition using Multi-task learning and a multimodal dynamic fusion network. (arXiv:2203.16794v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.16794">
<div class="article-summary-box-inner">
<span><p>Emotion Recognition (ER) aims to classify human utterances into different
emotion categories. Based on early-fusion and self-attention-based multimodal
interaction between text and acoustic modalities, in this paper, we propose
MMER, a multimodal multitask learning approach for ER from individual
utterances in isolation. Our proposed MMER leverages a multimodal dynamic
fusion network that adds minimal parameters over an existing speech encoder to
leverage the semantic and syntactic properties hidden in text. Experiments on
the IEMOCAP benchmark show that our proposed model achieves state-of-the-art
performance. In addition, strong baselines and ablation studies prove the
effectiveness of our proposed approach. We make our code publicly available on
GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stretching Sentence-pair NLI Models to Reason over Long Documents and Clusters. (arXiv:2204.07447v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.07447">
<div class="article-summary-box-inner">
<span><p>Natural Language Inference (NLI) has been extensively studied by the NLP
community as a framework for estimating the semantic relation between sentence
pairs. While early work identified certain biases in NLI models, recent
advancements in modeling and datasets demonstrated promising performance. In
this work, we further explore the direct zero-shot applicability of NLI models
to real applications, beyond the sentence-pair setting they were trained on.
First, we analyze the robustness of these models to longer and out-of-domain
inputs. Then, we develop new aggregation methods to allow operating over full
documents, reaching state-of-the-art performance on the ContractNLI dataset.
Interestingly, we find NLI scores to provide strong retrieval signals, leading
to more relevant evidence extractions compared to common similarity-based
methods. Finally, we go further and investigate whole document clusters to
identify both discrepancies and consensus among sources. In a test case, we
find real inconsistencies between Wikipedia pages in different languages about
the same topic.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Calibrating Trust of Multi-Hop Question Answering Systems with Decompositional Probes. (arXiv:2204.07693v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.07693">
<div class="article-summary-box-inner">
<span><p>Multi-hop Question Answering (QA) is a challenging task since it requires an
accurate aggregation of information from multiple context paragraphs and a
thorough understanding of the underlying reasoning chains. Recent work in
multi-hop QA has shown that performance can be boosted by first decomposing the
questions into simpler, single-hop questions. In this paper, we explore one
additional utility of the multi-hop decomposition from the perspective of
explainable NLP: to create explanation by probing a neural QA model with them.
We hypothesize that in doing so, users will be better able to predict when the
underlying QA system will give the correct answer. Through human participant
studies, we verify that exposing the decomposition probes and answers to the
probes to users can increase their ability to predict system performance on a
question instance basis. We show that decomposition is an effective form of
probing QA systems as well as a promising approach to explanation generation.
In-depth analyses show the need for improvements in decomposition systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Natural Language to Code Translation with Execution. (arXiv:2204.11454v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11454">
<div class="article-summary-box-inner">
<span><p>Generative models of code, pretrained on large corpora of programs, have
shown great success in translating natural language to code (Chen et al., 2021;
Austin et al., 2021; Li et al., 2022, inter alia). While these models do not
explicitly incorporate program semantics (i.e., execution results) during
training, they are able to generate correct solutions for many problems.
However, choosing a single correct program from a generated set for each
problem remains challenging. In this work, we introduce execution result--based
minimum Bayes risk decoding (MBR-EXEC) for program selection and show that it
improves the few-shot performance of pretrained code models on
natural-language-to-code tasks. We select output programs from a generated
candidate set by marginalizing over program implementations that share the same
semantics. Because exact equivalence is intractable, we execute each program on
a small number of test inputs to approximate semantic equivalence. Across
datasets, execution or simulated execution significantly outperforms the
methods that do not involve program semantics. We find that MBR-EXEC
consistently improves over all execution-unaware selection methods, suggesting
it as an effective approach for natural language to code translation. We
open-source our code at github.com/facebookresearch/mbr-exec and data at
dl.fbaipublicfiles.com/mbr-exec/mbr-exec-release.zip
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge Graph Completion. (arXiv:2205.02357v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.02357">
<div class="article-summary-box-inner">
<span><p>Multimodal Knowledge Graphs (MKGs), which organize visual-text factual
knowledge, have recently been successfully applied to tasks such as information
retrieval, question answering, and recommendation system. Since most MKGs are
far from complete, extensive knowledge graph completion studies have been
proposed focusing on the multimodal entity, relation extraction and link
prediction. However, different tasks and modalities require changes to the
model architecture, and not all images/objects are relevant to text input,
which hinders the applicability to diverse real-world scenarios. In this paper,
we propose a hybrid transformer with multi-level fusion to address those
issues. Specifically, we leverage a hybrid transformer architecture with
unified input-output for diverse multimodal knowledge graph completion tasks.
Moreover, we propose multi-level fusion, which integrates visual and text
representation via coarse-grained prefix-guided interaction and fine-grained
correlation-aware fusion modules. We conduct extensive experiments to validate
that our MKGformer can obtain SOTA performance on four datasets of multimodal
link prediction, multimodal RE, and multimodal NER. Code is available in
https://github.com/zjunlp/MKGformer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Literal and Implied Subquestions to Fact-check Complex Claims. (arXiv:2205.06938v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06938">
<div class="article-summary-box-inner">
<span><p>Verifying complex political claims is a challenging task, especially when
politicians use various tactics to subtly misrepresent the facts. Automatic
fact-checking systems fall short here, and their predictions like "half-true"
are not very useful in isolation, since we have no idea which parts of the
claim are true and which are not. In this work, we focus on decomposing a
complex claim into a comprehensive set of yes-no subquestions whose answers
influence the veracity of the claim. We present ClaimDecomp, a dataset of
decompositions for over 1000 claims. Given a claim and its verification
paragraph written by fact-checkers, our trained annotators write subquestions
covering both explicit propositions of the original claim and its implicit
facets, such as asking about additional political context that changes our view
of the claim's veracity. We study whether state-of-the-art models can generate
such subquestions, showing that these models generate reasonable questions to
ask, but predicting the comprehensive set of subquestions from the original
claim without evidence remains challenging. We further show that these
subquestions can help identify relevant evidence to fact-check the full claim
and derive the veracity through their answers, suggesting that they can be
useful pieces of a fact-checking pipeline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Context Limitations Make Neural Language Models More Human-Like. (arXiv:2205.11463v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11463">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) have been used in cognitive modeling as well as
engineering studies -- they compute information-theoretic complexity metrics
that simulate humans' cognitive load during reading. This study highlights a
limitation of modern neural LMs as the model of choice for this purpose: there
is a discrepancy between their context access capacities and that of humans.
Our results showed that constraining the LMs' context access improved their
simulation of human reading behavior. We also showed that LM-human gaps in
context access were associated with specific syntactic constructions;
incorporating syntactic biases into LMs' context access might enhance their
cognitive plausibility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NaturalProver: Grounded Mathematical Proof Generation with Language Models. (arXiv:2205.12910v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12910">
<div class="article-summary-box-inner">
<span><p>Theorem proving in natural mathematical language - the mixture of symbolic
and natural language used by humans - plays a central role in mathematical
advances and education, and tests aspects of reasoning that are core to
intelligence. Yet it has remained underexplored with modern generative models.
We study large-scale language models on two new generation tasks: suggesting
the next step in a mathematical proof, and full proof generation. We develop
NaturalProver, a language model that generates proofs by conditioning on
background references (e.g. theorems and definitions that are either retrieved
or human-provided), and optionally enforces their presence with constrained
decoding. On theorems from the NaturalProofs benchmark, NaturalProver improves
the quality of next-step suggestions and generated proofs over fine-tuned
GPT-3, according to human evaluations from university-level mathematics
students. NaturalProver is capable of proving some theorems that require short
(2-6 step) proofs, and providing next-step suggestions that are rated as
correct and useful over 40% of the time, which is to our knowledge the first
demonstration of these capabilities using neural language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Unified Evaluation of Textual Backdoor Learning: Frameworks and Benchmarks. (arXiv:2206.08514v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08514">
<div class="article-summary-box-inner">
<span><p>Textual backdoor attacks are a kind of practical threat to NLP systems. By
injecting a backdoor in the training phase, the adversary could control model
predictions via predefined triggers. As various attack and defense models have
been proposed, it is of great significance to perform rigorous evaluations.
However, we highlight two issues in previous backdoor learning evaluations: (1)
The differences between real-world scenarios (e.g. releasing poisoned datasets
or models) are neglected, and we argue that each scenario has its own
constraints and concerns, thus requires specific evaluation protocols; (2) The
evaluation metrics only consider whether the attacks could flip the models'
predictions on poisoned samples and retain performances on benign samples, but
ignore that poisoned samples should also be stealthy and semantic-preserving.
To address these issues, we categorize existing works into three practical
scenarios in which attackers release datasets, pre-trained models, and
fine-tuned models respectively, then discuss their unique evaluation
methodologies. On metrics, to completely evaluate poisoned samples, we use
grammar error increase and perplexity difference for stealthiness, along with
text similarity for validity. After formalizing the frameworks, we develop an
open-source toolkit OpenBackdoor to foster the implementations and evaluations
of textual backdoor learning. With this toolkit, we perform extensive
experiments to benchmark attack and defense models under the suggested
paradigm. To facilitate the underexplored defenses against poisoned datasets,
we further propose CUBE, a simple yet strong clustering-based defense baseline.
We hope that our frameworks and benchmarks could serve as the cornerstones for
future model development and evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">nuQmm: Quantized MatMul for Efficient Inference of Large-Scale Generative Language Models. (arXiv:2206.09557v2 [cs.DC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09557">
<div class="article-summary-box-inner">
<span><p>The recent advance of self-supervised learning associated with the
Transformer architecture enables natural language processing (NLP) to exhibit
extremely low perplexity. Such powerful models demand ever-increasing model
size and, thus, large amounts of computations and memory footprints. In this
paper, we propose an efficient inference framework for large-scale generative
language models. As the key to reducing model size, we quantize weights by a
non-uniform quantization method. Then, quantized matrix multiplications are
accelerated by our proposed kernel, called nuQmm, which allows a wide trade-off
between compression ratio and accuracy. Our proposed nuQmm reduces the latency
of not only each GPU but also the entire inference of large LMs because a high
compression ratio (by low-bit quantization) mitigates the minimum required
number of GPUs. Assuming 2-bit quantization, we demonstrate that nuQmm can
reduce latency to generate each token for OPT-175B (that requires 8 GPUs
without nuQmm) by 47.3% using 8 GPUs or by 23.2% using only 2 GPUs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VeriDark: A Large-Scale Benchmark for Authorship Verification on the Dark Web. (arXiv:2207.03477v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.03477">
<div class="article-summary-box-inner">
<span><p>The DarkWeb represents a hotbed for illicit activity, where users communicate
on different market forums in order to exchange goods and services. Law
enforcement agencies benefit from forensic tools that perform authorship
analysis, in order to identify and profile users based on their textual
content. However, authorship analysis has been traditionally studied using
corpora featuring literary texts such as fragments from novels or fan fiction,
which may not be suitable in a cybercrime context. Moreover, the few works that
employ authorship analysis tools for cybercrime prevention usually employ
ad-hoc experimental setups and datasets. To address these issues, we release
VeriDark: a benchmark comprised of three large scale authorship verification
datasets and one authorship identification dataset obtained from user activity
from either Dark Web related Reddit communities or popular illicit Dark Web
market forums. We evaluate competitive NLP baselines on the three datasets and
perform an analysis of the predictions to better understand the limitations of
such approaches. We make the datasets and baselines publicly available at
https://github.com/bit-ml/VeriDark
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Large Language Models know what humans know?. (arXiv:2209.01515v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.01515">
<div class="article-summary-box-inner">
<span><p>Humans can attribute mental states to others, a capacity known as Theory of
Mind. However, it is unknown to what extent this ability results from an innate
biological endowment or from experience accrued through child development,
particularly exposure to language describing others' mental states. We test the
viability of the language exposure hypothesis by assessing whether models
exposed to large quantities of human language develop evidence of Theory of
Mind. In pre-registered analyses, we present a linguistic version of the False
Belief Task, widely used to assess Theory of Mind, to both human participants
and a state-of-the-art Large Language Model, GPT-3. Both are sensitive to
others' beliefs, but while the language model significantly exceeds chance
behavior, it does not perform as well as the humans, nor does it explain the
full extent of their behavior -- despite being exposed to more language than a
human would in a lifetime. This suggests that while statistical learning from
language exposure may in part explain how humans develop Theory of Mind, other
mechanisms are also responsible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Honest Students from Untrusted Teachers: Learning an Interpretable Question-Answering Pipeline from a Pretrained Language Model. (arXiv:2210.02498v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.02498">
<div class="article-summary-box-inner">
<span><p>Explainable question answering systems should produce not only accurate
answers but also rationales that justify their reasoning and allow humans to
check their work. But what sorts of rationales are useful and how can we train
systems to produce them? We propose a new style of rationale for open-book
question answering, called \emph{markup-and-mask}, which combines aspects of
extractive and free-text explanations. In the markup phase, the passage is
augmented with free-text markup that enables each sentence to stand on its own
outside the discourse context. In the masking phase, a sub-span of the
marked-up passage is selected. To train a system to produce markup-and-mask
rationales without annotations, we leverage in-context learning. Specifically,
we generate silver annotated data by sending a series of prompts to a frozen
pretrained language model, which acts as a teacher. We then fine-tune a smaller
student model by training on the subset of rationales that led to correct
answers. The student is "honest" in the sense that it is a pipeline: the
rationale acts as a bottleneck between the passage and the answer, while the
"untrusted" teacher operates under no such constraints. Thus, we offer a new
way to build trustworthy pipeline systems from a combination of end-task
annotations and frozen pretrained language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CORE: A Retrieve-then-Edit Framework for Counterfactual Data Generation. (arXiv:2210.04873v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04873">
<div class="article-summary-box-inner">
<span><p>Counterfactual data augmentation (CDA) -- i.e., adding minimally perturbed
inputs during training -- helps reduce model reliance on spurious correlations
and improves generalization to out-of-distribution (OOD) data. Prior work on
generating counterfactuals only considered restricted classes of perturbations,
limiting their effectiveness. We present COunterfactual Generation via
Retrieval and Editing (CORE), a retrieval-augmented generation framework for
creating diverse counterfactual perturbations for CDA. For each training
example, CORE first performs a dense retrieval over a task-related unlabeled
text corpus using a learned bi-encoder and extracts relevant counterfactual
excerpts. CORE then incorporates these into prompts to a large language model
with few-shot learning capabilities, for counterfactual editing. Conditioning
language model edits on naturally occurring data results in diverse
perturbations. Experiments on natural language inference and sentiment analysis
benchmarks show that CORE counterfactuals are more effective at improving
generalization to OOD data compared to other DA approaches. We also show that
the CORE retrieval framework can be used to encourage diversity in manually
authored perturbations
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Simple and Strong Baseline for End-to-End Neural RST-style Discourse Parsing. (arXiv:2210.08355v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08355">
<div class="article-summary-box-inner">
<span><p>To promote and further develop RST-style discourse parsing models, we need a
strong baseline that can be regarded as a reference for reporting reliable
experimental results. This paper explores a strong baseline by integrating
existing simple parsing strategies, top-down and bottom-up, with various
transformer-based pre-trained language models. The experimental results
obtained from two benchmark datasets demonstrate that the parsing performance
strongly relies on the pretrained language models rather than the parsing
strategies. In particular, the bottom-up parser achieves large performance
gains compared to the current best parser when employing DeBERTa. We further
reveal that language models with a span-masking scheme especially boost the
parsing performance through our analysis within intra- and multi-sentential
parsing, and nuclearity prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MCP: Self-supervised Pre-training for Personalized Chatbots with Multi-level Contrastive Sampling. (arXiv:2210.08753v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08753">
<div class="article-summary-box-inner">
<span><p>Personalized chatbots focus on endowing the chatbots with a consistent
personality to behave like real users and further act as personal assistants.
Previous studies have explored generating implicit user profiles from the
user's dialogue history for building personalized chatbots. However, these
studies only use the response generation loss to train the entire model, thus
it is prone to suffer from the problem of data sparsity. Besides, they
overemphasize the final generated response's quality while ignoring the
correlations and fusions between the user's dialogue history, leading to rough
data representations and performance degradation. To tackle these problems, we
propose a self-supervised learning framework MCP for capturing better
representations from users' dialogue history for personalized chatbots.
Specifically, we apply contrastive sampling methods to leverage the supervised
signals hidden in user dialog history, and generate the pre-training samples
for enhancing the model. We design three pre-training tasks based on three
types of contrastive pairs from user dialogue history, namely response pairs,
sequence augmentation pairs, and user pairs. We pre-train the utterance encoder
and the history encoder towards the contrastive objectives and use these
pre-trained encoders for generating user profiles while personalized response
generation. Experimental results on two real-world datasets show a significant
improvement in our proposed model MCP compared with the existing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MoSE: Modality Split and Ensemble for Multimodal Knowledge Graph Completion. (arXiv:2210.08821v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08821">
<div class="article-summary-box-inner">
<span><p>Multimodal knowledge graph completion (MKGC) aims to predict missing entities
in MKGs. Previous works usually share relation representation across
modalities. This results in mutual interference between modalities during
training, since for a pair of entities, the relation from one modality probably
contradicts that from another modality. Furthermore, making a unified
prediction based on the shared relation representation treats the input in
different modalities equally, while their importance to the MKGC task should be
different. In this paper, we propose MoSE, a Modality Split representation
learning and Ensemble inference framework for MKGC. Specifically, in the
training phase, we learn modality-split relation embeddings for each modality
instead of a single modality-shared one, which alleviates the modality
interference. Based on these embeddings, in the inference phase, we first make
modality-split predictions and then exploit various ensemble methods to combine
the predictions with different weights, which models the modality importance
dynamically. Experimental results on three KG datasets show that MoSE
outperforms state-of-the-art MKGC methods. Codes are available at
https://github.com/OreOZhao/MoSE4MKGC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Information-Transport-based Policy for Simultaneous Translation. (arXiv:2210.12357v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12357">
<div class="article-summary-box-inner">
<span><p>Simultaneous translation (ST) outputs translation while receiving the source
inputs, and hence requires a policy to determine whether to translate a target
token or wait for the next source token. The major challenge of ST is that each
target token can only be translated based on the current received source
tokens, where the received source information will directly affect the
translation quality. So naturally, how much source information is received for
the translation of the current target token is supposed to be the pivotal
evidence for the ST policy to decide between translating and waiting. In this
paper, we treat the translation as information transport from source to target
and accordingly propose an Information-Transport-based Simultaneous Translation
(ITST). ITST quantifies the transported information weight from each source
token to the current target token, and then decides whether to translate the
target token according to its accumulated received information. Experiments on
both text-to-text ST and speech-to-text ST (a.k.a., streaming speech
translation) tasks show that ITST outperforms strong baselines and achieves
state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unifying Data Perspectivism and Personalization: An Application to Social Norms. (arXiv:2210.14531v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.14531">
<div class="article-summary-box-inner">
<span><p>Instead of using a single ground truth for language processing tasks, several
recent studies have examined how to represent and predict the labels of the set
of annotators. However, often little or no information about annotators is
known, or the set of annotators is small. In this work, we examine a corpus of
social media posts about conflict from a set of 13k annotators and 210k
judgements of social norms. We provide a novel experimental setup that applies
personalization methods to the modeling of annotators and compare their
effectiveness for predicting the perception of social norms. We further provide
an analysis of performance across subsets of social situations that vary by the
closeness of the relationship between parties in conflict, and assess where
personalization helps the most.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can language models handle recursively nested grammatical structures? A case study on comparing models and humans. (arXiv:2210.15303v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.15303">
<div class="article-summary-box-inner">
<span><p>How should we compare the capabilities of language models and humans? Here, I
consider a case study: processing of recursively nested grammatical structures.
Prior work has suggested that language models cannot handle these structures as
reliably as humans can. However, the humans were provided with instructions and
training before being evaluated, while the language models were evaluated
zero-shot. I therefore attempt to more closely match the evaluation paradigms
by providing language models with few-shot prompts. A simple prompt, which
contains substantially less content than the human training, allows large
language models to consistently outperform the human results. The same prompt
even allows extrapolation to more deeply nested conditions than have been
tested in humans. Further, a reanalysis of the prior human experiments suggests
that the humans may not perform above chance at the difficult structures
initially. These results suggest that large language models can in fact process
recursively nested grammatical structures comparably to humans. This case study
highlights how discrepancies in the quantity of experiment-specific context can
confound comparisons of language models and humans. I use this case study to
reflect on the broader challenge of comparing human and model capabilities, and
to suggest that there is an important difference between evaluating cognitive
models of a specific phenomenon and evaluating broadly-trained models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reinforced Question Rewriting for Conversational Question Answering. (arXiv:2210.15777v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.15777">
<div class="article-summary-box-inner">
<span><p>Conversational Question Answering (CQA) aims to answer questions contained
within dialogues, which are not easily interpretable without context.
Developing a model to rewrite conversational questions into self-contained ones
is an emerging solution in industry settings as it allows using existing
single-turn QA systems to avoid training a CQA model from scratch. Previous
work trains rewriting models using human rewrites as supervision. However, such
objectives are disconnected with QA models and therefore more human-like
rewrites do not guarantee better QA performance. In this paper we propose using
QA feedback to supervise the rewriting model with reinforcement learning.
Experiments show that our approach can effectively improve QA performance over
baselines for both extractive and retrieval QA. Furthermore, human evaluation
shows that our method can generate more accurate and detailed rewrites when
compared to human annotations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SDCL: Self-Distillation Contrastive Learning for Chinese Spell Checking. (arXiv:2210.17168v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.17168">
<div class="article-summary-box-inner">
<span><p>Due to the ambiguity of homophones, Chinese Spell Checking (CSC) has
widespread applications. Existing systems typically utilize BERT for text
encoding. However, CSC requires the model to account for both phonetic and
graphemic information. To adapt BERT to the CSC task, we propose a token-level
self-distillation contrastive learning method. We employ BERT to encode both
the corrupted and corresponding correct sentence. Then, we use contrastive
learning loss to regularize corrupted tokens' hidden states to be closer to
counterparts in the correct sentence. On three CSC datasets, we confirmed our
method provides a significant improvement above baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention-Based Capsule Networks with Dynamic Routing for Relation Extraction. (arXiv:1812.11321v1 [cs.IR] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1812.11321">
<div class="article-summary-box-inner">
<span><p>A capsule is a group of neurons, whose activity vector represents the
instantiation parameters of a specific type of entity. In this paper, we
explore the capsule networks used for relation extraction in a multi-instance
multi-label learning framework and propose a novel neural approach based on
capsule networks with attention mechanisms. We evaluate our method with
different benchmarks, and it is demonstrated that our method improves the
precision of the predicted relations. Particularly, we show that capsule
networks improve multiple entity pairs relation extraction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks. (arXiv:1903.01306v1 [cs.IR] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1903.01306">
<div class="article-summary-box-inner">
<span><p>We propose a distance supervised relation extraction approach for
long-tailed, imbalanced data which is prevalent in real-world settings. Here,
the challenge is to learn accurate "few-shot" models for classes existing at
the tail of the class distribution, for which little data is available.
Inspired by the rich semantic correlations between classes at the long tail and
those at the head, we take advantage of the knowledge from data-rich classes at
the head of the distribution to boost the performance of the data-poor classes
at the tail. First, we propose to leverage implicit relational knowledge among
class labels from knowledge graph embeddings and learn explicit relational
knowledge using graph convolution networks. Second, we integrate that
relational knowledge into relation extraction model by coarse-to-fine
knowledge-aware attention mechanism. We demonstrate our results for a
large-scale benchmark dataset which show that our approach significantly
outperforms other baselines, especially for long-tail relations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction. (arXiv:2104.07650v6 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07650">
<div class="article-summary-box-inner">
<span><p>Recently, prompt-tuning has achieved promising results for specific few-shot
classification tasks. The core idea of prompt-tuning is to insert text pieces
(i.e., templates) into the input and transform a classification task into a
masked language modeling problem. However, for relation extraction, determining
an appropriate prompt template requires domain expertise, and it is cumbersome
and time-consuming to obtain a suitable label word. Furthermore, there exists
abundant semantic and prior knowledge among the relation labels that cannot be
ignored. To this end, we focus on incorporating knowledge among relation labels
into prompt-tuning for relation extraction and propose a Knowledge-aware
Prompt-tuning approach with synergistic optimization (KnowPrompt).
Specifically, we inject latent knowledge contained in relation labels into
prompt construction with learnable virtual type words and answer words. Then,
we synergistically optimize their representation with structured constraints.
Extensive experimental results on five datasets with standard and low-resource
settings demonstrate the effectiveness of our approach. Our code and datasets
are available in https://github.com/zjunlp/KnowPrompt for reproducibility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MLBiNet: A Cross-Sentence Collective Event Detection Network. (arXiv:2105.09458v3 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09458">
<div class="article-summary-box-inner">
<span><p>We consider the problem of collectively detecting multiple events,
particularly in cross-sentence settings. The key to dealing with the problem is
to encode semantic information and model event inter-dependency at a
document-level. In this paper, we reformulate it as a Seq2Seq task and propose
a Multi-Layer Bidirectional Network (MLBiNet) to capture the document-level
association of events and semantic information simultaneously. Specifically, a
bidirectional decoder is firstly devised to model event inter-dependency within
a sentence when decoding the event tag vector sequence. Secondly, an
information aggregation module is employed to aggregate sentence-level semantic
and event tag information. Finally, we stack multiple bidirectional decoders
and feed cross-sentence information, forming a multi-layer bidirectional
tagging architecture to iteratively propagate information across sentences. We
show that our approach provides significant improvement in performance compared
to the current state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AliCG: Fine-grained and Evolvable Conceptual Graph Construction for Semantic Search at Alibaba. (arXiv:2106.01686v2 [cs.AI] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01686">
<div class="article-summary-box-inner">
<span><p>Conceptual graphs, which is a particular type of Knowledge Graphs, play an
essential role in semantic search. Prior conceptual graph construction
approaches typically extract high-frequent, coarse-grained, and time-invariant
concepts from formal texts. In real applications, however, it is necessary to
extract less-frequent, fine-grained, and time-varying conceptual knowledge and
build taxonomy in an evolving manner. In this paper, we introduce an approach
to implementing and deploying the conceptual graph at Alibaba. Specifically, We
propose a framework called AliCG which is capable of a) extracting fine-grained
concepts by a novel bootstrapping with alignment consensus approach, b) mining
long-tail concepts with a novel low-resource phrase mining approach, c)
updating the graph dynamically via a concept distribution estimation method
based on implicit and explicit user behaviors. We have deployed the framework
at Alibaba UC Browser. Extensive offline evaluation as well as online A/B
testing demonstrate the efficacy of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark. (arXiv:2106.08087v6 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08087">
<div class="article-summary-box-inner">
<span><p>Artificial Intelligence (AI), along with the recent progress in biomedical
language understanding, is gradually changing medical practice. With the
development of biomedical language understanding benchmarks, AI applications
are widely used in the medical field. However, most benchmarks are limited to
English, which makes it challenging to replicate many of the successes in
English for other languages. To facilitate research in this direction, we
collect real-world biomedical data and present the first Chinese Biomedical
Language Understanding Evaluation (CBLUE) benchmark: a collection of natural
language understanding tasks including named entity recognition, information
extraction, clinical diagnosis normalization, single-sentence/sentence-pair
classification, and an associated online platform for model evaluation,
comparison, and analysis. To establish evaluation on these tasks, we report
empirical results with the current 11 pre-trained Chinese models, and
experimental results show that state-of-the-art neural models perform by far
worse than the human ceiling. Our benchmark is released at
\url{https://tianchi.aliyun.com/dataset/dataDetail?dataId=95414&amp;lang=en-us}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LightNER: A Lightweight Tuning Paradigm for Low-resource NER via Pluggable Prompting. (arXiv:2109.00720v5 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00720">
<div class="article-summary-box-inner">
<span><p>Most NER methods rely on extensive labeled data for model training, which
struggles in the low-resource scenarios with limited training data. Existing
dominant approaches usually suffer from the challenge that the target domain
has different label sets compared with a resource-rich source domain, which can
be concluded as class transfer and domain transfer. In this paper, we propose a
lightweight tuning paradigm for low-resource NER via pluggable prompting
(LightNER). Specifically, we construct the unified learnable verbalizer of
entity categories to generate the entity span sequence and entity categories
without any label-specific classifiers, thus addressing the class transfer
issue. We further propose a pluggable guidance module by incorporating
learnable parameters into the self-attention layer as guidance, which can
re-modulate the attention and adapt pre-trained weights. Note that we only tune
those inserted module with the whole parameter of the pre-trained language
model fixed, thus, making our approach lightweight and flexible for
low-resource scenarios and can better transfer knowledge across domains.
Experimental results show that LightNER can obtain comparable performance in
the standard supervised setting and outperform strong baselines in low-resource
settings. Code is in
https://github.com/zjunlp/DeepKE/tree/main/example/ner/few-shot.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepKE: A Deep Learning Based Knowledge Extraction Toolkit for Knowledge Base Population. (arXiv:2201.03335v5 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.03335">
<div class="article-summary-box-inner">
<span><p>We present an open-source and extensible knowledge extraction toolkit DeepKE,
supporting complicated low-resource, document-level and multimodal scenarios in
the knowledge base population. DeepKE implements various information extraction
tasks, including named entity recognition, relation extraction and attribute
extraction. With a unified framework, DeepKE allows developers and researchers
to customize datasets and models to extract information from unstructured data
according to their requirements. Specifically, DeepKE not only provides various
functional modules and model implementation for different tasks and scenarios
but also organizes all components by consistent frameworks to maintain
sufficient modularity and extensibility. We release the source code at GitHub
in https://github.com/zjunlp/DeepKE with Google Colab tutorials and
comprehensive documents for beginners. Besides, we present an online system in
<a href="http://deepke.openkg.cn/EN/re_doc_show.html">this http URL</a> for real-time extraction of various
tasks, and a demo video.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OntoProtein: Protein Pretraining With Gene Ontology Embedding. (arXiv:2201.11147v6 [q-bio.BM] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11147">
<div class="article-summary-box-inner">
<span><p>Self-supervised protein language models have proved their effectiveness in
learning the proteins representations. With the increasing computational power,
current protein language models pre-trained with millions of diverse sequences
can advance the parameter scale from million-level to billion-level and achieve
remarkable improvement. However, those prevailing approaches rarely consider
incorporating knowledge graphs (KGs), which can provide rich structured
knowledge facts for better protein representations. We argue that informative
biology knowledge in KGs can enhance protein representation with external
knowledge. In this work, we propose OntoProtein, the first general framework
that makes use of structure in GO (Gene Ontology) into protein pre-training
models. We construct a novel large-scale knowledge graph that consists of GO
and its related proteins, and gene annotation texts or protein sequences
describe all nodes in the graph. We propose novel contrastive learning with
knowledge-aware negative sampling to jointly optimize the knowledge graph and
protein embedding during pre-training. Experimental results show that
OntoProtein can surpass state-of-the-art methods with pre-trained protein
language models in TAPE benchmark and yield better performance compared with
baselines in protein-protein interaction and protein function prediction. Code
and datasets are available in https://github.com/zjunlp/OntoProtein.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Demonstration Tuning for Pre-trained Language Models. (arXiv:2204.04392v3 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04392">
<div class="article-summary-box-inner">
<span><p>Pretrained language models can be effectively stimulated by textual prompts
or demonstrations, especially in low-data scenarios. Recent works have focused
on automatically searching discrete or continuous prompts or optimized
verbalizers, yet studies for the demonstration are still limited. Concretely,
the demonstration examples are crucial for an excellent final performance of
prompt-tuning. In this paper, we propose a novel pluggable, extensible, and
efficient approach named contrastive demonstration tuning, which is free of
demonstration sampling. Furthermore, the proposed approach can be: (i) Plugged
into any previous prompt-tuning approaches; (ii) Extended to widespread
classification tasks with a large number of categories. Experimental results on
16 datasets illustrate that our method integrated with previous approaches
LM-BFF and P-tuning can yield better performance. Code is available in
https://github.com/zjunlp/PromptKG/tree/main/research/Demo-Tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relation Extraction as Open-book Examination: Retrieval-enhanced Prompt Tuning. (arXiv:2205.02355v1 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.02355">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models have contributed significantly to relation
extraction by demonstrating remarkable few-shot learning abilities. However,
prompt tuning methods for relation extraction may still fail to generalize to
those rare or hard patterns. Note that the previous parametric learning
paradigm can be viewed as memorization regarding training data as a book and
inference as the close-book test. Those long-tailed or hard patterns can hardly
be memorized in parameters given few-shot instances. To this end, we regard RE
as an open-book examination and propose a new semiparametric paradigm of
retrieval-enhanced prompt tuning for relation extraction. We construct an
open-book datastore for retrieval regarding prompt-based instance
representations and corresponding relation labels as memorized key-value pairs.
During inference, the model can infer relations by linearly interpolating the
base output of PLM with the non-parametric nearest neighbor distribution over
the datastore. In this way, our model not only infers relation through
knowledge stored in the weights during training but also assists
decision-making by unwinding and querying examples in the open-book datastore.
Extensive experiments on benchmark datasets show that our method can achieve
state-of-the-art in both standard supervised and few-shot settings. Code are
available in https://github.com/zjunlp/PromptKG/tree/main/research/RetrievalRE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning. (arXiv:2205.14704v3 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.14704">
<div class="article-summary-box-inner">
<span><p>Prompt learning approaches have made waves in natural language processing by
inducing better few-shot performance while they still follow a parametric-based
learning paradigm; the oblivion and rote memorization problems in learning may
encounter unstable generalization issues. Specifically, vanilla prompt learning
may struggle to utilize atypical instances by rote during fully-supervised
training or overfit shallow patterns with low-shot data. To alleviate such
limitations, we develop RetroPrompt with the motivation of decoupling knowledge
from memorization to help the model strike a balance between generalization and
memorization. In contrast with vanilla prompt learning, RetroPrompt constructs
an open-book knowledge-store from training instances and implements a retrieval
mechanism during the process of input, training and inference, thus equipping
the model with the ability to retrieve related contexts from the training
corpus as cues for enhancement. Extensive experiments demonstrate that
RetroPrompt can obtain better performance in both few-shot and zero-shot
settings. Besides, we further illustrate that our proposed RetroPrompt can
yield better generalization abilities with new datasets. Detailed analysis of
memorization indeed reveals RetroPrompt can reduce the reliance of language
models on memorization; thus, improving generalization for downstream tasks.
Code is available in
https://github.com/zjunlp/PromptKG/tree/main/research/RetroPrompt.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-modal Protein Knowledge Graph Construction and Applications. (arXiv:2207.10080v2 [q-bio.QM] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.10080">
<div class="article-summary-box-inner">
<span><p>Existing data-centric methods for protein science generally cannot
sufficiently capture and leverage biology knowledge, which may be crucial for
many protein tasks. To facilitate research in this field, we create
ProteinKG65, a knowledge graph for protein science. Using gene ontology and
Uniprot knowledge base as a basis, we transform and integrate various kinds of
knowledge with aligned descriptions and protein sequences, respectively, to GO
terms and protein entities. ProteinKG65 is mainly dedicated to providing a
specialized protein knowledge graph, bringing the knowledge of Gene Ontology to
protein function and structure prediction. The current version contains about
614,099 entities, 5,620,437 triples (including 5,510,437 protein-go triplets
and 110,000 GO-GO triplets). We also illustrate the potential applications of
ProteinKG65 with a prototype. Our dataset can be downloaded at
https://w3id.org/proteinkg65.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PromptKG: A Prompt Learning Framework for Knowledge Graph Representation Learning and Application. (arXiv:2210.00305v1 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.00305">
<div class="article-summary-box-inner">
<span><p>Knowledge Graphs (KGs) often have two characteristics: heterogeneous graph
structure and text-rich entity/relation information. KG representation models
should consider graph structures and text semantics, but no comprehensive
open-sourced framework is mainly designed for KG regarding informative text
description. In this paper, we present PromptKG, a prompt learning framework
for KG representation learning and application that equips the cutting-edge
text-based methods, integrates a new prompt learning model and supports various
tasks (e.g., knowledge graph completion, question answering, recommendation,
and knowledge probing). PromptKG is publicly open-sourced at
https://github.com/zjunlp/PromptKG with long-term technical support.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Realistic Low-resource Relation Extraction: A Benchmark with Empirical Baseline Study. (arXiv:2210.10678v1 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10678">
<div class="article-summary-box-inner">
<span><p>This paper presents an empirical study to build relation extraction systems
in low-resource settings. Based upon recent pre-trained language models, we
comprehensively investigate three schemes to evaluate the performance in
low-resource settings: (i) different types of prompt-based methods with
few-shot labeled data; (ii) diverse balancing methods to address the
long-tailed distribution issue; (iii) data augmentation technologies and
self-training to generate more labeled in-domain data. We create a benchmark
with 8 relation extraction (RE) datasets covering different languages, domains
and contexts and perform extensive comparisons over the proposed schemes with
combinations. Our experiments illustrate: (i) Though prompt-based tuning is
beneficial in low-resource RE, there is still much potential for improvement,
especially in extracting relations from cross-sentence contexts with multiple
relational triples; (ii) Balancing methods are not always helpful for RE with
long-tailed distribution; (iii) Data augmentation complements existing
baselines and can bring much performance gain, while self-training may not
consistently achieve advancement to low-resource RE. Code and datasets are in
https://github.com/zjunlp/LREBench.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-11-02 23:17:17.560797152 UTC">2022-11-02 23:17:17 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>