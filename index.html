<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-01-06T01:30:00Z">01-06</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">The political ideology of conversational AI: Converging evidence on ChatGPT's pro-environmental, left-libertarian orientation. (arXiv:2301.01768v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01768">
<div class="article-summary-box-inner">
<span><p>Conversational artificial intelligence (AI) disrupts how humans interact with
technology. Recently, OpenAI introduced ChatGPT, a state-of-the-art dialogue
model that can converse with its human counterparts with unprecedented
capabilities. ChatGPT has witnessed tremendous attention from the media,
academia, industry, and the general public, attracting more than a million
users within days of its release. However, its explosive adoption for
information search and as an automated decision aid underscores the importance
to understand its limitations and biases. This paper focuses on one of
democratic society's most important decision-making processes: political
elections. Prompting ChatGPT with 630 political statements from two leading
voting advice applications and the nation-agnostic political compass test in
three pre-registered experiments, we uncover ChatGPT's pro-environmental,
left-libertarian ideology. For example, ChatGPT would impose taxes on flights,
restrict rent increases, and legalize abortion. In the 2021 elections, it would
have voted most likely for the Greens both in Germany (B\"undnis 90/Die
Gr\"unen) and in the Netherlands (GroenLinks). Our findings are robust when
negating the prompts, reversing the order of the statements, varying prompt
formality, and across languages (English, German, Dutch, and Spanish). We
conclude by discussing the implications of politically biased conversational AI
on society.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MessageNet: Message Classification using Natural Language Processing and Meta-data. (arXiv:2301.01808v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01808">
<div class="article-summary-box-inner">
<span><p>In this paper we propose a new Deep Learning (DL) approach for message
classification. Our method is based on the state-of-the-art Natural Language
Processing (NLP) building blocks, combined with a novel technique for infusing
the meta-data input that is typically available in messages such as the sender
information, timestamps, attached image, audio, affiliations, and more. As we
demonstrate throughout the paper, going beyond the mere text by leveraging all
available channels in the message, could yield an improved representation and
higher classification accuracy. To achieve message representation, each type of
input is processed in a dedicated block in the neural network architecture that
is suitable for the data type. Such an implementation enables training all
blocks together simultaneously, and forming cross channels features in the
network. We show in the Experiments Section that in some cases, message's
meta-data holds an additional information that cannot be extracted just from
the text, and when using this information we achieve better performance.
Furthermore, we demonstrate that our multi-modality block approach outperforms
other approaches for injecting the meta data to the the text classifier.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parameter-Efficient Fine-Tuning Design Spaces. (arXiv:2301.01821v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01821">
<div class="article-summary-box-inner">
<span><p>Parameter-efficient fine-tuning aims to achieve performance comparable to
fine-tuning, using fewer trainable parameters. Several strategies (e.g.,
Adapters, prefix tuning, BitFit, and LoRA) have been proposed. However, their
designs are hand-crafted separately, and it remains unclear whether certain
design patterns exist for parameter-efficient fine-tuning. Thus, we present a
parameter-efficient fine-tuning design paradigm and discover design patterns
that are applicable to different experimental settings. Instead of focusing on
designing another individual tuning strategy, we introduce parameter-efficient
fine-tuning design spaces that parameterize tuning structures and tuning
strategies. Specifically, any design space is characterized by four components:
layer grouping, trainable parameter allocation, tunable groups, and strategy
assignment. Starting from an initial design space, we progressively refine the
space based on the model quality of each design choice and make greedy
selection at each stage over these four components. We discover the following
design patterns: (i) group layers in a spindle pattern; (ii) allocate the
number of trainable parameters to layers uniformly; (iii) tune all the groups;
(iv) assign proper tuning strategies to different groups. These design patterns
result in new parameter-efficient fine-tuning methods. We show experimentally
that these methods consistently and significantly outperform investigated
parameter-efficient fine-tuning strategies across different backbone models and
different tasks in natural language processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Critical Perspectives: A Benchmark Revealing Pitfalls in PerspectiveAPI. (arXiv:2301.01874v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01874">
<div class="article-summary-box-inner">
<span><p>Detecting "toxic" language in internet content is a pressing social and
technical challenge. In this work, we focus on PERSPECTIVE from Jigsaw, a
state-of-the-art tool that promises to score the "toxicity" of text, with a
recent model update that claims impressive results (Lees et al., 2022). We seek
to challenge certain normative claims about toxic language by proposing a new
benchmark, Selected Adversarial SemanticS, or SASS. We evaluate PERSPECTIVE on
SASS, and compare to low-effort alternatives, like zero-shot and few-shot GPT-3
prompt models, in binary classification settings. We find that PERSPECTIVE
exhibits troubling shortcomings across a number of our toxicity categories.
SASS provides a new tool for evaluating performance on previously undetected
toxic language that avoids common normative pitfalls. Our work leads us to
emphasize the importance of questioning assumptions made by tools already in
deployment for toxicity detection in order to anticipate and prevent disparate
harms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GIVL: Improving Geographical Inclusivity of Vision-Language Models with Pre-Training Methods. (arXiv:2301.01893v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01893">
<div class="article-summary-box-inner">
<span><p>A key goal for the advancement of AI is to develop technologies that serve
the needs not just of one group but of all communities regardless of their
geographical region. In fact, a significant proportion of knowledge is locally
shared by people from certain regions but may not apply equally in other
regions because of cultural differences. If a model is unaware of regional
characteristics, it may lead to performance disparity across regions and result
in bias against underrepresented groups. We propose GIVL, a Geographically
Inclusive Vision-and-Language Pre-trained model. There are two attributes of
geo-diverse visual concepts which can help to learn geo-diverse knowledge: 1)
concepts under similar categories have unique knowledge and visual
characteristics, 2) concepts with similar visual features may fall in
completely different categories. Motivated by the attributes, we design new
pre-training objectives Image Knowledge Matching (IKM) and Image Edit Checking
(IEC) to pre-train GIVL. Compared with similar-size models pre-trained with
similar scale of data, GIVL achieves state-of-the-art (SOTA) and more balanced
performance on geo-diverse V&amp;L tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topic Segmentation Model Focusing on Local Context. (arXiv:2301.01935v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01935">
<div class="article-summary-box-inner">
<span><p>Topic segmentation is important in understanding scientific documents since
it can not only provide better readability but also facilitate downstream tasks
such as information retrieval and question answering by creating appropriate
sections or paragraphs. In the topic segmentation task, topic coherence is
critical in predicting segmentation boundaries. Most of the existing models
have tried to exploit as many contexts as possible to extract useful
topic-related information. However, additional context does not always bring
promising results, because the local context between sentences becomes
incoherent despite more sentences being supplemented. To alleviate this issue,
we propose siamese sentence embedding layers which process two input sentences
independently to get appropriate amount of information without being hampered
by excessive information. Also, we adopt multi-task learning techniques
including Same Topic Prediction (STP), Topic Classification (TC) and Next
Sentence Prediction (NSP). When these three classification layers are combined
in a multi-task manner, they can make up for each other's limitations,
improving performance in all three tasks. We experiment different combinations
of the three layers and report how each layer affects other layers in the same
combination as well as the overall segmentation performance. The model we
proposed achieves the state-of-the-art result in the WikiSection dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SPRING: Situated Conversation Agent Pretrained with Multimodal Questions from Incremental Layout Graph. (arXiv:2301.01949v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01949">
<div class="article-summary-box-inner">
<span><p>Existing multimodal conversation agents have shown impressive abilities to
locate absolute positions or retrieve attributes in simple scenarios, but they
fail to perform well when complex relative positions and information alignments
are involved, which poses a bottleneck in response quality. In this paper, we
propose a Situated Conversation Agent Petrained with Multimodal Questions from
INcremental Layout Graph (SPRING) with abilities of reasoning multi-hops
spatial relations and connecting them with visual attributes in crowded
situated scenarios. Specifically, we design two types of Multimodal Question
Answering (MQA) tasks to pretrain the agent. All QA pairs utilized during
pretraining are generated from novel Incremental Layout Graphs (ILG). QA pair
difficulty labels automatically annotated by ILG are used to promote MQA-based
Curriculum Learning. Experimental results verify the SPRING's effectiveness,
showing that it significantly outperforms state-of-the-art approaches on both
SIMMC 1.0 and SIMMC 2.0 datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Code-switching: Linguistic and Social Perspectives for Language Technologies. (arXiv:2301.01967v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01967">
<div class="article-summary-box-inner">
<span><p>The analysis of data in which multiple languages are represented has gained
popularity among computational linguists in recent years. So far, much of this
research focuses mainly on the improvement of computational methods and largely
ignores linguistic and social aspects of C-S discussed across a wide range of
languages within the long-established literature in linguistics. To fill this
gap, we offer a survey of code-switching (C-S) covering the literature in
linguistics with a reflection on the key issues in language technologies. From
the linguistic perspective, we provide an overview of structural and functional
patterns of C-S focusing on the literature from European and Indian contexts as
highly multilingual areas. From the language technologies perspective, we
discuss how massive language models fail to represent diverse C-S types due to
lack of appropriate training data, lack of robust evaluation benchmarks for C-S
(across multilingual situations and types of C-S) and lack of end-to-end
systems that cover sociolinguistic aspects of C-S as well. Our survey will be a
step towards an outcome of mutual benefit for computational scientists and
linguists with a shared interest in multilingualism and C-S.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emotion-Cause Pair Extraction as Question Answering. (arXiv:2301.01982v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01982">
<div class="article-summary-box-inner">
<span><p>The task of Emotion-Cause Pair Extraction (ECPE) aims to extract all
potential emotion-cause pairs of a document without any annotation of emotion
or cause clauses. Previous approaches on ECPE have tried to improve
conventional two-step processing schemes by using complex architectures for
modeling emotion-cause interaction. In this paper, we cast the ECPE task to the
question answering (QA) problem and propose simple yet effective BERT-based
solutions to tackle it. Given a document, our Guided-QA model first predicts
the best emotion clause using a fixed question. Then the predicted emotion is
used as a question to predict the most potential cause for the emotion. We
evaluate our model on a standard ECPE corpus. The experimental results show
that despite its simplicity, our Guided-QA achieves promising results and is
easy to reproduce. The code of Guided-QA is also provided.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HIT-SCIR at MMNLU-22: Consistency Regularization for Multilingual Spoken Language Understanding. (arXiv:2301.02010v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.02010">
<div class="article-summary-box-inner">
<span><p>Multilingual spoken language understanding (SLU) consists of two sub-tasks,
namely intent detection and slot filling. To improve the performance of these
two sub-tasks, we propose to use consistency regularization based on a hybrid
data augmentation strategy. The consistency regularization enforces the
predicted distributions for an example and its semantically equivalent
augmentation to be consistent. We conduct experiments on the MASSIVE dataset
under both full-dataset and zero-shot settings. Experimental results
demonstrate that our proposed method improves the performance on both intent
detection and slot filling tasks. Our system\footnote{The code will be
available at \url{https://github.com/bozheng-hit/MMNLU-22-HIT-SCIR}.} ranked
1st in the MMNLU-22 competition under the full-dataset setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TextDescriptives: A Python package for calculating a large variety of statistics from text. (arXiv:2301.02057v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.02057">
<div class="article-summary-box-inner">
<span><p>TextDescriptives is a Python package for calculating a large variety of
statistics from text. It is built on top of spaCy and can be easily integrated
into existing workflows. The package has already been used for analysing the
linguistic stability of clinical texts, creating features for predicting
neuropsychiatric conditions, and analysing linguistic goals of primary school
students. This paper describes the package and its features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Table-to-Text Generation with Pretrained Language Model: A Table Structure Understanding and Text Deliberating Approach. (arXiv:2301.02071v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.02071">
<div class="article-summary-box-inner">
<span><p>Although remarkable progress on the neural table-to-text methods has been
made, the generalization issues hinder the applicability of these models due to
the limited source tables. Large-scale pretrained language models sound like a
promising solution to tackle such issues. However, how to effectively bridge
the gap between the structured table and the text input by fully leveraging
table information to fuel the pretrained model is still not well explored.
Besides, another challenge of integrating the deliberation mechanism into the
text-to-text pretrained model for solving the table-to-text task remains seldom
studied. In this paper, to implement the table-to-text generation with
pretrained language model, we propose a table structure understanding and text
deliberating approach, namely TASD. Specifically, we devise a three-layered
multi-head attention network to realize the table-structure-aware text
generation model with the help of the pretrained language model. Furthermore, a
multi-pass decoder framework is adopted to enhance the capability of polishing
generated text for table descriptions. The empirical studies, as well as human
evaluation, on two public datasets, validate that our approach can generate
faithful and fluent descriptive texts for different types of tables.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers. (arXiv:2301.02111v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.02111">
<div class="article-summary-box-inner">
<span><p>We introduce a language modeling approach for text to speech synthesis (TTS).
Specifically, we train a neural codec language model (called Vall-E) using
discrete codes derived from an off-the-shelf neural audio codec model, and
regard TTS as a conditional language modeling task rather than continuous
signal regression as in previous work. During the pre-training stage, we scale
up the TTS training data to 60K hours of English speech which is hundreds of
times larger than existing systems. Vall-E emerges in-context learning
capabilities and can be used to synthesize high-quality personalized speech
with only a 3-second enrolled recording of an unseen speaker as an acoustic
prompt. Experiment results show that Vall-E significantly outperforms the
state-of-the-art zero-shot TTS system in terms of speech naturalness and
speaker similarity. In addition, we find Vall-E could preserve the speaker's
emotion and acoustic environment of the acoustic prompt in synthesis. See
https://aka.ms/valle for demos of our work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anaphora Resolution in Dialogue: System Description (CODI-CRAC 2022 Shared Task). (arXiv:2301.02113v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.02113">
<div class="article-summary-box-inner">
<span><p>We describe three models submitted for the CODI-CRAC 2022 shared task. To
perform identity anaphora resolution, we test several combinations of the
incremental clustering approach based on the Workspace Coreference System (WCS)
with other coreference models. The best result is achieved by adding the
''cluster merging'' version of the coref-hoi model, which brings up to 10.33%
improvement 1 over vanilla WCS clustering. Discourse deixis resolution is
implemented as multi-task learning: we combine the learning objective of
corefhoi with anaphor type classification. We adapt the higher-order resolution
model introduced in Joshi et al. (2019) for bridging resolution given gold
mentions and anaphors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reprogramming Pretrained Language Models for Protein Sequence Representation Learning. (arXiv:2301.02120v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.02120">
<div class="article-summary-box-inner">
<span><p>Machine Learning-guided solutions for protein learning tasks have made
significant headway in recent years. However, success in scientific discovery
tasks is limited by the accessibility of well-defined and labeled in-domain
data. To tackle the low-data constraint, recent adaptions of deep learning
models pretrained on millions of protein sequences have shown promise; however,
the construction of such domain-specific large-scale model is computationally
expensive. Here, we propose Representation Learning via Dictionary Learning
(R2DL), an end-to-end representation learning framework in which we reprogram
deep models for alternate-domain tasks that can perform well on protein
property prediction with significantly fewer training samples. R2DL reprograms
a pretrained English language model to learn the embeddings of protein
sequences, by learning a sparse linear mapping between English and protein
sequence vocabulary embeddings. Our model can attain better accuracy and
significantly improve the data efficiency by up to $10^5$ times over the
baselines set by pretrained and standard supervised methods. To this end, we
reprogram an off-the-shelf pre-trained English language transformer and
benchmark it on a set of protein physicochemical prediction tasks (secondary
structure, stability, homology, stability) as well as on a biomedically
relevant set of protein function prediction tasks (antimicrobial, toxicity,
antibody affinity).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Autoformalization of Mathematics and Code Correctness: Experiments with Elementary Proofs. (arXiv:2301.02195v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.02195">
<div class="article-summary-box-inner">
<span><p>The ever-growing complexity of mathematical proofs makes their manual
verification by mathematicians very cognitively demanding. Autoformalization
seeks to address this by translating proofs written in natural language into a
formal representation that is computer-verifiable via interactive theorem
provers. In this paper, we introduce a semantic parsing approach, based on the
Universal Transformer architecture, that translates elementary mathematical
proofs into an equivalent formalization in the language of the Coq interactive
theorem prover. The same architecture is also trained to translate simple
imperative code decorated with Hoare triples into formally verifiable proofs of
correctness in Coq. Experiments on a limited domain of artificial and
human-written proofs show that the models generalize well to intermediate
lengths not seen during training and variations in natural language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MedKLIP: Medical Knowledge Enhanced Language-Image Pre-Training. (arXiv:2301.02228v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.02228">
<div class="article-summary-box-inner">
<span><p>In this paper, we consider the problem of enhancing self-supervised
visual-language pre-training (VLP) with medical-specific knowledge, by
exploiting the paired image-text reports from the radiological daily practice.
In particular, we make the following contributions: First, unlike existing
works that directly process the raw reports, we adopt a novel report filter to
extract the medical entities, avoiding unnecessary complexity from language
grammar and enhancing the supervision signals; Second, we propose a novel
entity embedding module by querying an external knowledge description base, to
exploit the rich context of additional information that the medical domain
affords, and implicitly build relationships between entities in the language
embedding space; Third, we propose a novel Transformer-based fusion model for
spatially aligning the entity description with visual signals at the image
patch level only with self-supervised learning, thus enabling the ability for
spatial grounding; Fourth, we conduct thorough experiments to validate the
effectiveness of our proposed architecture, and benchmark on numerous public
benchmarks e.g., ChestX-ray14, RSNA Pneumonia, SIIM-ACR Pneumothorax, COVIDx
CXR-2, COVID Rural, and EdemaSeverity. In both zero-shot and fine-tuning
settings, our model has demonstrated strong performance compared with the
former methods on disease classification and grounding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CiT: Curation in Training for Effective Vision-Language Data. (arXiv:2301.02241v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.02241">
<div class="article-summary-box-inner">
<span><p>Large vision-language models are generally applicable to many downstream
tasks, but come at an exorbitant training cost that only large institutions can
afford. This paper trades generality for efficiency and presents Curation in
Training (CiT), a simple and efficient vision-text learning algorithm that
couples a data objective into training. CiT automatically yields quality data
to speed-up contrastive image-text training and alleviates the need for an
offline data filtering pipeline, allowing broad data sources (including raw
image-text pairs from the web). CiT contains two loops: an outer loop curating
the training data and an inner loop consuming the curated training data. The
text encoder connects the two loops. Given metadata for tasks of interest,
e.g., class names, and a large pool of image-text pairs, CiT alternatively
selects relevant training data from the pool by measuring the similarity of
their text embeddings and embeddings of the metadata. In our experiments, we
observe that CiT can speed up training by over an order of magnitude,
especially if the raw data size is large.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Text Classification As Sub-Hierarchy Sequence Generation. (arXiv:2111.11104v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.11104">
<div class="article-summary-box-inner">
<span><p>Hierarchical text classification (HTC) is essential for various real
applications. However, HTC models are challenging to develop because they often
require processing a large volume of documents and labels with hierarchical
taxonomy. Recent HTC models based on deep learning have attempted to
incorporate hierarchy information into a model structure. Consequently, these
models are challenging to implement when the model parameters increase for a
large-scale hierarchy because the model structure depends on the hierarchy
size. To solve this problem, we formulate HTC as a sub-hierarchy sequence
generation to incorporate hierarchy information into a target label sequence
instead of the model structure. Subsequently, we propose the Hierarchy DECoder
(HiDEC), which decodes a text sequence into a sub-hierarchy sequence using
recursive hierarchy decoding, classifying all parents at the same level into
children at once. In addition, HiDEC is trained to use hierarchical path
information from a root to each leaf in a sub-hierarchy composed of the labels
of a target document via an attention mechanism and hierarchy-aware masking.
HiDEC achieved state-of-the-art performance with significantly fewer model
parameters than existing models on benchmark datasets, such as RCV1-v2, NYT,
and EURLEX57K.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AdaVocoder: Adaptive Vocoder for Custom Voice. (arXiv:2203.09825v3 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.09825">
<div class="article-summary-box-inner">
<span><p>Custom voice is to construct a personal speech synthesis system by adapting
the source speech synthesis model to the target model through the target few
recordings. The solution to constructing a custom voice is to combine an
adaptive acoustic model with a robust vocoder. However, training a robust
vocoder usually requires a multi-speaker dataset, which should include various
age groups and various timbres, so that the trained vocoder can be used for
unseen speakers. Collecting such a multi-speaker dataset is difficult, and the
dataset distribution always has a mismatch with the distribution of the target
speaker dataset. This paper proposes an adaptive vocoder for custom voice from
another novel perspective to solve the above problems. The adaptive vocoder
mainly uses a cross-domain consistency loss to solve the overfitting problem
encountered by the GAN-based neural vocoder in the transfer learning of
few-shot scenes. We construct two adaptive vocoders, AdaMelGAN and AdaHiFi-GAN.
First, We pre-train the source vocoder model on AISHELL3 and CSMSC datasets,
respectively. Then, fine-tune it on the internal dataset VXI-children with few
adaptation data. The empirical results show that a high-quality custom voice
system can be built by combining a adaptive acoustic model with a adaptive
vocoder.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sarcasm Detection Framework Using Context, Emotion and Sentiment Features. (arXiv:2211.13014v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.13014">
<div class="article-summary-box-inner">
<span><p>Sarcasm detection is an essential task that can help identify the actual
sentiment in user-generated data, such as discussion forums or tweets. Sarcasm
is a sophisticated form of linguistic expression because its surface meaning
usually contradicts its inner, deeper meaning. Such incongruity is the
essential component of sarcasm, however, it makes sarcasm detection quite a
challenging task. In this paper, we propose a model, that incorporates
different features to capture the incongruity intrinsic to sarcasm. We use a
pre-trained transformer and CNN to capture context features, and we use
transformers pre-trained on emotions detection and sentiment analysis tasks.
Our approach outperformed previous state-of-the-art results on four datasets
from social networking platforms and online media.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Scales Data Augmentation Approach In Natural Language Inference For Artifacts Mitigation And Pre-Trained Model Optimization. (arXiv:2212.08756v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.08756">
<div class="article-summary-box-inner">
<span><p>Machine learning models can reach high performance on benchmark natural
language processing (NLP) datasets but fail in more challenging settings. We
study this issue when a pre-trained model learns dataset artifacts in natural
language inference (NLI), the topic of studying the logical relationship
between a pair of text sequences. We provide a variety of techniques for
analyzing and locating dataset artifacts inside the crowdsourced Stanford
Natural Language Inference (SNLI) corpus. We study the stylistic pattern of
dataset artifacts in the SNLI. To mitigate dataset artifacts, we employ a
unique multi-scale data augmentation technique with two distinct frameworks: a
behavioral testing checklist at the sentence level and lexical synonym criteria
at the word level. Specifically, our combination method enhances our model's
resistance to perturbation testing, enabling it to continuously outperform the
pre-trained baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MicroBERT: Effective Training of Low-resource Monolingual BERTs through Parameter Reduction and Multitask Learning. (arXiv:2212.12510v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.12510">
<div class="article-summary-box-inner">
<span><p>Transformer language models (TLMs) are critical for most NLP tasks, but they
are difficult to create for low-resource languages because of how much
pretraining data they require. In this work, we investigate two techniques for
training monolingual TLMs in a low-resource setting: greatly reducing TLM size,
and complementing the masked language modeling objective with two
linguistically rich supervised tasks (part-of-speech tagging and dependency
parsing). Results from 7 diverse languages indicate that our model, MicroBERT,
is able to produce marked improvements in downstream task evaluations relative
to a typical monolingual TLM pretraining approach. Specifically, we find that
monolingual MicroBERT models achieve gains of up to 18% for parser LAS and 11%
for NER F1 compared to a multilingual baseline, mBERT, while having less than
1% of its parameter count. We conclude reducing TLM parameter count and using
labeled data for pretraining low-resource TLMs can yield large quality benefits
and in some cases produce models that outperform multilingual approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Second Thoughts are Best: Learning to Re-Align With Human Values from Text Edits. (arXiv:2301.00355v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.00355">
<div class="article-summary-box-inner">
<span><p>We present Second Thought, a new learning paradigm that enables language
models (LMs) to re-align with human values. By modeling the chain-of-edits
between value-unaligned and value-aligned text, with LM fine-tuning and
additional refinement through reinforcement learning, Second Thought not only
achieves superior performance in three value alignment benchmark datasets but
also shows strong human-value transfer learning ability in few-shot scenarios.
The generated editing steps also offer better interpretability and ease for
interactive error correction. Extensive human evaluations further confirm its
effectiveness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models as Corporate Lobbyists. (arXiv:2301.01181v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01181">
<div class="article-summary-box-inner">
<span><p>We demonstrate a proof-of-concept of a large language model conducting
corporate lobbying related activities. An autoregressive large language model
(OpenAI's text-davinci-003) determines if proposed U.S. Congressional bills are
relevant to specific public companies and provides explanations and confidence
levels. For the bills the model deems as relevant, the model drafts a letter to
the sponsor of the bill in an attempt to persuade the congressperson to make
changes to the proposed legislation. We use hundreds of ground-truth labels of
the relevance of a bill to a company to benchmark the performance of the model,
which outperforms the baseline of predicting the most common outcome of
irrelevance. We also benchmark the performance of the previous OpenAI GPT-3
model (text-davinci-002), which was state-of-the-art on many language tasks
until text-davinci-003 was recently released. The performance of
text-davinci-002 is worse than simply always predicting that a bill is
irrelevant to a company. These results suggest that, as large language models
continue to exhibit improved core natural language understanding capabilities,
performance on corporate lobbying related tasks will continue to improve. If AI
begins to influence law in a manner that is not a direct extension of human
intentions, this threatens the critical role that law as information could play
in aligning AI with humans. This paper explores how this is increasingly a
possibility. Initially, AI is being used to simply augment human lobbyists.
However, there may be a slow creep of less and less human oversight over
automated assessments of policy ideas and the written communication to
regulatory agencies and Congressional staffers. The core question raised is
where to draw the line between human-driven and AI-driven policy influence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Iterated Decomposition: Improving Science Q&A by Supervising Reasoning Processes. (arXiv:2301.01751v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01751">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) can perform complex reasoning either end-to-end, with
hidden latent state, or compositionally, with transparent intermediate state.
Composition offers benefits for interpretability and safety, but may need
workflow support and infrastructure to remain competitive. We describe iterated
decomposition, a human-in-the-loop workflow for developing and refining
compositional LM programs. We improve the performance of compositions by
zooming in on failing components and refining them through decomposition,
additional context, chain of thought, etc. To support this workflow, we develop
ICE, an open-source tool for visualizing the execution traces of LM programs.
We apply iterated decomposition to three real-world tasks and improve the
accuracy of LM programs over less compositional baselines: describing the
placebo used in a randomized controlled trial (25% to 65%), evaluating
participant adherence to a medical intervention (53% to 70%), and answering NLP
questions on the Qasper dataset (38% to 69%). These applications serve as case
studies for a workflow that, if automated, could keep ML systems interpretable
and safe even as they scale to increasingly complex tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UniHD at TSAR-2022 Shared Task: Is Compute All We Need for Lexical Simplification?. (arXiv:2301.01764v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01764">
<div class="article-summary-box-inner">
<span><p>Previous state-of-the-art models for lexical simplification consist of
complex pipelines with several components, each of which requires deep
technical knowledge and fine-tuned interaction to achieve its full potential.
As an alternative, we describe a frustratingly simple pipeline based on
prompted GPT-3 responses, beating competing approaches by a wide margin in
settings with few training instances. Our best-performing submission to the
English language track of the TSAR-2022 shared task consists of an ``ensemble''
of six different prompt templates with varying context levels. As a
late-breaking result, we further detail a language transfer technique that
allows simplification in languages other than English. Applied to the Spanish
and Portuguese subset, we achieve state-of-the-art results with only minor
modification to the original prompts. Aside from detailing the implementation
and setup, we spend the remainder of this work discussing the particularities
of prompting and implications for future work. Code for the experiments is
available online at https://github.com/dennlinger/TSAR-2022-Shared-Task
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-01-08 23:12:19.841064299 UTC">2023-01-08 23:12:19 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>