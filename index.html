<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-02-17T01:30:00Z">02-17</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Meeting the Needs of Low-Resource Languages: The Value of Automatic Alignments via Pretrained Models. (arXiv:2302.07912v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07912">
<div class="article-summary-box-inner">
<span><p>Large multilingual models have inspired a new class of word alignment
methods, which work well for the model's pretraining languages. However, the
languages most in need of automatic alignment are low-resource and, thus, not
typically included in the pretraining data. In this work, we ask: How do modern
aligners perform on unseen languages, and are they better than traditional
methods? We contribute gold-standard alignments for Bribri--Spanish,
Guarani--Spanish, Quechua--Spanish, and Shipibo-Konibo--Spanish. With these, we
evaluate state-of-the-art aligners with and without model adaptation to the
target language. Finally, we also evaluate the resulting alignments
extrinsically through two downstream tasks: named entity recognition and
part-of-speech tagging. We find that although transformer-based methods
generally outperform traditional models, the two classes of approach remain
competitive with each other.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Commonsense Reasoning for Conversational AI: A Survey of the State of the Art. (arXiv:2302.07926v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07926">
<div class="article-summary-box-inner">
<span><p>Large, transformer-based pretrained language models like BERT, GPT, and T5
have demonstrated a deep understanding of contextual semantics and language
syntax. Their success has enabled significant advances in conversational AI,
including the development of open-dialogue systems capable of coherent, salient
conversations which can answer questions, chat casually, and complete tasks.
However, state-of-the-art models still struggle with tasks that involve higher
levels of reasoning - including commonsense reasoning that humans find trivial.
This paper presents a survey of recent conversational AI research focused on
commonsense reasoning. The paper lists relevant training datasets and describes
the primary approaches to include commonsense in conversational AI. The paper
also discusses benchmarks used for evaluating commonsense in conversational AI
problems. Finally, the paper presents preliminary observations of the limited
commonsense capabilities of two state-of-the-art open dialogue models,
BlenderBot3 and LaMDA, and its negative effect on natural interactions. These
observations further motivate research on commonsense reasoning in
conversational AI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tree-Based Representation and Generation of Natural and Mathematical Language. (arXiv:2302.07974v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07974">
<div class="article-summary-box-inner">
<span><p>Mathematical language in scientific communications and educational scenarios
is important yet relatively understudied compared to natural languages. Recent
works on mathematical language focus either on representing stand-alone
mathematical expressions, especially in their natural tree format, or
mathematical reasoning in pre-trained natural language models. Existing works
on jointly modeling and generating natural and mathematical languages simply
treat mathematical expressions as text, without accounting for the rigid
structural properties of mathematical expressions. In this paper, we propose a
series of modifications to existing language models to jointly represent and
generate text and math: representing mathematical expressions as sequences of
node tokens in their operator tree format, using math symbol and tree position
embeddings to preserve the semantic and structural properties of mathematical
expressions, and using a constrained decoding method to generate mathematically
valid expressions. We ground our modifications in GPT-2, resulting in a model
MathGPT, and demonstrate that it outperforms baselines on mathematical
expression generation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">\`A-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting. (arXiv:2302.07994v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07994">
<div class="article-summary-box-inner">
<span><p>We introduce \`A-la-carte Prompt Tuning (APT), a transformer-based scheme to
tune prompts on distinct data so that they can be arbitrarily composed at
inference time. The individual prompts can be trained in isolation, possibly on
different devices, at different times, and on different distributions or
domains. Furthermore each prompt only contains information about the subset of
data it was exposed to during training. During inference, models can be
assembled based on arbitrary selections of data sources, which we call
"\`a-la-carte learning". \`A-la-carte learning enables constructing bespoke
models specific to each user's individual access rights and preferences. We can
add or remove information from the model by simply adding or removing the
corresponding prompts without retraining from scratch. We demonstrate that
\`a-la-carte built models achieve accuracy within $5\%$ of models trained on
the union of the respective sources, with comparable cost in terms of training
and inference time. For the continual learning benchmarks Split CIFAR-100 and
CORe50, we achieve state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks. (arXiv:2302.08043v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08043">
<div class="article-summary-box-inner">
<span><p>Graphs can model complex relationships between objects, enabling a myriad of
Web applications such as online page/article classification and social
recommendation. While graph neural networks(GNNs) have emerged as a powerful
tool for graph representation learning, in an end-to-end supervised setting,
their performance heavily rely on a large amount of task-specific supervision.
To reduce labeling requirement, the "pre-train, fine-tune" and "pre-train,
prompt" paradigms have become increasingly common. In particular, prompting is
a popular alternative to fine-tuning in natural language processing, which is
designed to narrow the gap between pre-training and downstream objectives in a
task-specific manner. However, existing study of prompting on graphs is still
limited, lacking a universal treatment to appeal to different downstream tasks.
In this paper, we propose GraphPrompt, a novel pre-training and prompting
framework on graphs. GraphPrompt not only unifies pre-training and downstream
tasks into a common task template, but also employs a learnable prompt to
assist a downstream task in locating the most relevant knowledge from the
pre-train model in a task-specific manner. Finally, we conduct extensive
experiments on five public datasets to evaluate and analyze GraphPrompt.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LabelPrompt: Effective Prompt-based Learning for Relation Classification. (arXiv:2302.08068v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08068">
<div class="article-summary-box-inner">
<span><p>Recently, prompt-based learning has become a very popular solution in many
Natural Language Processing (NLP) tasks by inserting a template into model
input, which converts the task into a cloze-style one to smoothing out
differences between the Pre-trained Language Model (PLM) and the current task.
But in the case of relation classification, it is difficult to map the masked
output to the relation labels because of its abundant semantic information,
e.g. org:founded_by''. Therefore, a pre-trained model still needs enough
labelled data to fit the relations. To mitigate this challenge, in this paper,
we present a novel prompt-based learning method, namely LabelPrompt, for the
relation classification task. It is an extraordinary intuitive approach by a
motivation: ``GIVE MODEL CHOICES!''. First, we define some additional tokens to
represent the relation labels, which regards these tokens as the verbalizer
with semantic initialisation and constructs them with a prompt template method.
Then we revisit the inconsistency of the predicted relation and the given
entities, an entity-aware module with the thought of contrastive learning is
designed to mitigate the problem. At last, we apply an attention query strategy
to self-attention layers to resolve two types of tokens, prompt tokens and
sequence tokens. The proposed strategy effectively improves the adaptation
capability of prompt-based learning in the relation classification task when
only a small labelled data is available. Extensive experimental results
obtained on several bench-marking datasets demonstrate the superiority of the
proposed LabelPrompt method, particularly in the few-shot scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Document Flattening: Beyond Concatenating Context for Document-Level Neural Machine Translation. (arXiv:2302.08079v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08079">
<div class="article-summary-box-inner">
<span><p>Existing work in document-level neural machine translation commonly
concatenates several consecutive sentences as a pseudo-document, and then
learns inter-sentential dependencies. This strategy limits the model's ability
to leverage information from distant context. We overcome this limitation with
a novel Document Flattening (DocFlat) technique that integrates Flat-Batch
Attention (FBA) and Neural Context Gate (NCG) into Transformer model to utilize
information beyond the pseudo-document boundaries. FBA allows the model to
attend to all the positions in the batch and learns the relationships between
positions explicitly and NCG identifies the useful information from the distant
context. We conduct comprehensive experiments and analyses on three benchmark
datasets for English-German translation, and validate the effectiveness of two
variants of DocFlat. Empirical results show that our approach outperforms
strong baselines with statistical significance on BLEU, COMET and accuracy on
the contrastive test set. The analyses highlight that DocFlat is highly
effective in capturing the long-range information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the Limits of ChatGPT for Query or Aspect-based Text Summarization. (arXiv:2302.08081v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08081">
<div class="article-summary-box-inner">
<span><p>Text summarization has been a crucial problem in natural language processing
(NLP) for several decades. It aims to condense lengthy documents into shorter
versions while retaining the most critical information. Various methods have
been proposed for text summarization, including extractive and abstractive
summarization. The emergence of large language models (LLMs) like GPT3 and
ChatGPT has recently created significant interest in using these models for
text summarization tasks. Recent studies \cite{goyal2022news,
zhang2023benchmarking} have shown that LLMs-generated news summaries are
already on par with humans. However, the performance of LLMs for more practical
applications like aspect or query-based summaries is underexplored. To fill
this gap, we conducted an evaluation of ChatGPT's performance on four widely
used benchmark datasets, encompassing diverse summaries from Reddit posts, news
articles, dialogue meetings, and stories. Our experiments reveal that ChatGPT's
performance is comparable to traditional fine-tuning methods in terms of Rouge
scores. Moreover, we highlight some unique differences between
ChatGPT-generated summaries and human references, providing valuable insights
into the superpower of ChatGPT for diverse text summarization tasks. Our
findings call for new directions in this area, and we plan to conduct further
research to systematically examine the characteristics of ChatGPT-generated
summaries through extensive human evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Multi-Object Positional Relationships via Emergent Communication. (arXiv:2302.08084v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08084">
<div class="article-summary-box-inner">
<span><p>The study of emergent communication has been dedicated to interactive
artificial intelligence. While existing work focuses on communication about
single objects or complex image scenes, we argue that communicating
relationships between multiple objects is important in more realistic tasks,
but understudied. In this paper, we try to fill this gap and focus on emergent
communication about positional relationships between two objects. We train
agents in the referential game where observations contain two objects, and find
that generalization is the major problem when the positional relationship is
involved. The key factor affecting the generalization ability of the emergent
language is the input variation between Speaker and Listener, which is realized
by a random image generator in our work. Further, we find that the learned
language can generalize well in a new multi-step MDP task where the positional
relationship describes the goal, and performs better than raw-pixel images as
well as pre-trained image features, verifying the strong generalization ability
of discrete sequences. We also show that language transfer from the referential
game performs better in the new task than learning language directly in this
task, implying the potential benefits of pre-training in referential games. All
in all, our experiments demonstrate the viability and merit of having agents
learn to communicate positional relationships between multiple objects through
emergent communication.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement. (arXiv:2302.08088v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08088">
<div class="article-summary-box-inner">
<span><p>Speech enhancement models have greatly progressed in recent years, but still
show limits in perceptual quality of their speech outputs. We propose an
objective for perceptual quality based on temporal acoustic parameters. These
are fundamental speech features that play an essential role in various
applications, including speaker recognition and paralinguistic analysis. We
provide a differentiable estimator for four categories of low-level acoustic
descriptors involving: frequency-related parameters, energy or
amplitude-related parameters, spectral balance parameters, and temporal
features. Unlike prior work that looks at aggregated acoustic parameters or a
few categories of acoustic parameters, our temporal acoustic parameter (TAP)
loss enables auxiliary optimization and improvement of many fine-grain speech
characteristics in enhancement workflows. We show that adding TAPLoss as an
auxiliary objective in speech enhancement produces speech with improved
perceptual quality and intelligibility. We use data from the Deep Noise
Suppression 2020 Challenge to demonstrate that both time-domain models and
time-frequency domain models can benefit from our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do We Still Need Clinical Language Models?. (arXiv:2302.08091v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08091">
<div class="article-summary-box-inner">
<span><p>Although recent advances in scaling large language models (LLMs) have
resulted in improvements on many NLP tasks, it remains unclear whether these
models trained primarily with general web text are the right tool in highly
specialized, safety critical domains such as clinical text. Recent results have
suggested that LLMs encode a surprising amount of medical knowledge. This
raises an important question regarding the utility of smaller domain-specific
language models. With the success of general-domain LLMs, is there still a need
for specialized clinical models? To investigate this question, we conduct an
extensive empirical analysis of 12 language models, ranging from 220M to 175B
parameters, measuring their performance on 3 different clinical tasks that test
their ability to parse and reason over electronic health records. As part of
our experiments, we train T5-Base and T5-Large models from scratch on clinical
notes from MIMIC III and IV to directly investigate the efficiency of clinical
tokens. We show that relatively small specialized clinical models substantially
outperform all in-context learning approaches, even when finetuned on limited
annotated data. Further, we find that pretraining on clinical tokens allows for
smaller, more parameter-efficient models that either match or outperform much
larger language models trained on general text. We release the code and the
models used under the PhysioNet Credentialed Health Data license and data use
agreement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Product Question Answering in E-Commerce: A Survey. (arXiv:2302.08092v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08092">
<div class="article-summary-box-inner">
<span><p>Product question answering (PQA), aiming to automatically provide instant
responses to customer's questions in E-Commerce platforms, has drawn increasing
attention in recent years. Compared with typical QA problems, PQA exhibits
unique challenges such as the subjectivity and reliability of user-generated
contents in E-commerce platforms. Therefore, various problem settings and novel
methods have been proposed to capture these special characteristics. In this
paper, we aim to systematically review existing research efforts on PQA.
Specifically, we categorize PQA studies into four problem settings in terms of
the form of provided answers. We analyze the pros and cons, as well as present
existing datasets and evaluation protocols for each setting. We further
summarize the most significant challenges that characterize PQA from general QA
applications and discuss their corresponding solutions. Finally, we conclude
this paper by providing the prospect on several future directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PAAPLoss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement. (arXiv:2302.08095v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08095">
<div class="article-summary-box-inner">
<span><p>Despite rapid advancement in recent years, current speech enhancement models
often produce speech that differs in perceptual quality from real clean speech.
We propose a learning objective that formalizes differences in perceptual
quality, by using domain knowledge of acoustic-phonetics. We identify temporal
acoustic parameters -- such as spectral tilt, spectral flux, shimmer, etc. --
that are non-differentiable, and we develop a neural network estimator that can
accurately predict their time-series values across an utterance. We also model
phoneme-specific weights for each feature, as the acoustic parameters are known
to show different behavior in different phonemes. We can add this criterion as
an auxiliary loss to any model that produces speech, to optimize speech outputs
to match the values of clean speech in these features. Experimentally we show
that it improves speech enhancement workflows in both time-domain and
time-frequency domain, as measured by standard evaluation metrics. We also
provide an analysis of phoneme-dependent improvement on acoustic parameters,
demonstrating the additional interpretability that our method provides. This
analysis can suggest which features are currently the bottleneck for
improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition. (arXiv:2302.08102v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08102">
<div class="article-summary-box-inner">
<span><p>Visual Speech Recognition (VSR) aims to infer speech into text depending on
lip movements alone. As it focuses on visual information to model the speech,
its performance is inherently sensitive to personal lip appearances and
movements, and this makes the VSR models show degraded performance when they
are applied to unseen speakers. In this paper, to remedy the performance
degradation of the VSR model on unseen speakers, we propose prompt tuning
methods of Deep Neural Networks (DNNs) for speaker-adaptive VSR. Specifically,
motivated by recent advances in Natural Language Processing (NLP), we finetune
prompts on adaptation data of target speakers instead of modifying the
pre-trained model parameters. Different from the previous prompt tuning methods
mainly limited to Transformer variant architecture, we explore different types
of prompts, the addition, the padding, and the concatenation form prompts that
can be applied to the VSR model which is composed of CNN and Transformer in
general. With the proposed prompt tuning, we show that the performance of the
pre-trained VSR model on unseen speakers can be largely improved by using a
small amount of adaptation data (e.g., less than 5 minutes), even if the
pre-trained model is already developed with large speaker variations. Moreover,
by analyzing the performance and parameters of different types of prompts, we
investigate when the prompt tuning is preferred over the finetuning methods.
The effectiveness of the proposed method is evaluated on both word- and
sentence-level VSR databases, LRW-ID and GRID.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Initialize: Can Meta Learning Improve Cross-task Generalization in Prompt Tuning?. (arXiv:2302.08143v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08143">
<div class="article-summary-box-inner">
<span><p>Prompt tuning (PT) which only tunes the embeddings of an additional sequence
of tokens per task, keeping the pre-trained language model (PLM) frozen, has
shown remarkable performance in few-shot learning. Despite this, PT has been
shown to rely heavily on good initialization of the prompt embeddings. In this
work, we study meta prompt tuning (MPT) to systematically explore how
meta-learning can help improve (if it can) cross-task generalization in PT
through learning to initialize the prompt embeddings from other relevant tasks.
We empirically analyze a representative set of meta learning algorithms in a
wide range of adaptation settings with different source/target task
configurations on a large set of few-shot tasks. With extensive experiments and
analysis, we demonstrate the effectiveness of MPT. We find the improvement to
be significant particularly on classification tasks. For other kinds of tasks
such as question answering, we observe that while MPT can outperform PT in most
cases, it does not always outperform multi-task learning. We further provide an
in-depth analysis from the perspective of task similarity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CluCDD:Contrastive Dialogue Disentanglement via Clustering. (arXiv:2302.08146v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08146">
<div class="article-summary-box-inner">
<span><p>A huge number of multi-participant dialogues happen online every day, which
leads to difficulty in understanding the nature of dialogue dynamics for both
humans and machines. Dialogue disentanglement aims at separating an entangled
dialogue into detached sessions, thus increasing the readability of long
disordered dialogue. Previous studies mainly focus on message-pair
classification and clustering in two-step methods, which cannot guarantee the
whole clustering performance in a dialogue. To address this challenge, we
propose a simple yet effective model named CluCDD, which aggregates utterances
by contrastive learning. More specifically, our model pulls utterances in the
same session together and pushes away utterances in different ones. Then a
clustering method is adopted to generate predicted clustering labels.
Comprehensive experiments conducted on the Movie Dialogue dataset and IRC
dataset demonstrate that our model achieves a new state-of-the-art result.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Empirical Investigation of Neural Symbolic Reasoning Strategies. (arXiv:2302.08148v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08148">
<div class="article-summary-box-inner">
<span><p>Neural reasoning accuracy improves when generating intermediate reasoning
steps. However, the source of this improvement is yet unclear. Here, we
investigate and factorize the benefit of generating intermediate steps for
symbolic reasoning. Specifically, we decompose the reasoning strategy w.r.t.
step granularity and chaining strategy. With a purely symbolic numerical
reasoning dataset (e.g., A=1, B=3, C=A+3, C?), we found that the choice of
reasoning strategies significantly affects the performance, with the gap
becoming even larger as the extrapolation length becomes longer. Surprisingly,
we also found that certain configurations lead to nearly perfect performance,
even in the case of length extrapolation. Our results indicate the importance
of further exploring effective strategies for neural reasoning models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reanalyzing L2 Preposition Learning with Bayesian Mixed Effects and a Large Language Model. (arXiv:2302.08150v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08150">
<div class="article-summary-box-inner">
<span><p>We use both Bayesian and neural models to dissect a data set of Chinese
learners' pre- and post-interventional responses to two tests measuring their
understanding of English prepositions. The results mostly replicate previous
findings from frequentist analyses and newly reveal crucial interactions
between student ability, task type, and stimulus sentence. Given the sparsity
of the data as well as high diversity among learners, the Bayesian method
proves most useful; but we also see potential in using language model
probabilities as predictors of grammaticality and learnability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Un mod{\`e}le de base de connaissances terminologiques. (arXiv:2302.08198v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08198">
<div class="article-summary-box-inner">
<span><p>In the present paper, we argue that Terminological Knowledge Bases (TKB) are
all the more useful for addressing various needs as they do not fulfill formal
criteria. Moreover, they intend to clarify the terminology of a given domain by
illustrating term uses in various contexts. Thus we designed a TKB structure
including 3 linked features: terms, concepts and texts, that present the
peculiar use of each term in the domain. Note that concepts are represented
into frames whose non-formal description is standardized. Associated with this
structure, we defined modeling criteria at the conceptual level. Finaly, we
discuss the situation of TKB with regard to ontologies, and the use of TKB for
the development of AI systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Aligning Language Models with Preferences through f-divergence Minimization. (arXiv:2302.08215v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08215">
<div class="article-summary-box-inner">
<span><p>Aligning language models with preferences can be posed as approximating a
target distribution representing some desired behavior. Existing approaches
differ both in the functional form of the target distribution and the algorithm
used to approximate it. For instance, Reinforcement Learning from Human
Feedback (RLHF) corresponds to minimizing a reverse KL from an implicit target
distribution arising from a KL penalty in the objective. On the other hand,
Generative Distributional Control (GDC) has an explicit target distribution and
minimizes a forward KL from it using the Distributional Policy Gradient (DPG)
algorithm. In this paper, we propose a new approach, f-DPG, which allows the
use of any f-divergence to approximate any target distribution. f-DPG unifies
both frameworks (RLHF, GDC) and the approximation methods (DPG, RL with KL
penalties). We show the practical benefits of various choices of divergence
objectives and demonstrate that there is no universally optimal objective but
that different divergences are good for approximating different targets. For
instance, we discover that for GDC, the Jensen-Shannon divergence frequently
outperforms forward KL divergence by a wide margin, leading to significant
improvements over prior work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dialogue State Distillation Network with Inter-Slot Contrastive Learning for Dialogue State Tracking. (arXiv:2302.08220v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08220">
<div class="article-summary-box-inner">
<span><p>In task-oriented dialogue systems, Dialogue State Tracking (DST) aims to
extract users' intentions from the dialogue history. Currently, most existing
approaches suffer from error propagation and are unable to dynamically select
relevant information when utilizing previous dialogue states. Moreover, the
relations between the updates of different slots provide vital clues for DST.
However, the existing approaches rely only on predefined graphs to indirectly
capture the relations. In this paper, we propose a Dialogue State Distillation
Network (DSDN) to utilize relevant information of previous dialogue states and
migrate the gap of utilization between training and testing. Thus, it can
dynamically exploit previous dialogue states and avoid introducing error
propagation simultaneously. Further, we propose an inter-slot contrastive
learning loss to effectively capture the slot co-update relations from dialogue
context. Experiments are conducted on the widely used MultiWOZ 2.0 and MultiWOZ
2.1 datasets. The experimental results show that our proposed model achieves
the state-of-the-art performance for DST.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Spoken Language Identification with Map-Mix. (arXiv:2302.08229v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08229">
<div class="article-summary-box-inner">
<span><p>The pre-trained multi-lingual XLSR model generalizes well for language
identification after fine-tuning on unseen languages. However, the performance
significantly degrades when the languages are not very distinct from each
other, for example, in the case of dialects. Low resource dialect
classification remains a challenging problem to solve. We present a new data
augmentation method that leverages model training dynamics of individual data
points to improve sampling for latent mixup. The method works well in
low-resource settings where generalization is paramount. Our datamaps-based
mixup technique, which we call Map-Mix improves weighted F1 scores by 2%
compared to the random mixup baseline and results in a significantly
well-calibrated model. The code for our method is open sourced on
https://github.com/skit-ai/Map-Mix.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tragic and Comical Networks. Clustering Dramatic Genres According to Structural Properties. (arXiv:2302.08258v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08258">
<div class="article-summary-box-inner">
<span><p>There is a growing tradition in the joint field of network studies and drama
history that produces interpretations from the character networks of the
plays.The potential of such an interpretation is that the diagrams provide a
different representation of the relationships between characters as compared to
reading the text or watching the performance. Our aim is to create a method
that is able to cluster texts with similar structures on the basis of the
play's well-interpretable and simple properties, independent from the number of
characters in the drama, or in other words, the size of the network. Finding
these features is the most important part of our research, as well as
establishing the appropriate statistical procedure to calculate the
similarities between the texts. Our data was downloaded from the DraCor
database and analyzed in R (we use the GerDracor and the ShakeDraCor
sub-collection). We want to propose a robust method based on the distribution
of words among characters; distribution of characters in scenes, average length
of speech acts, or character-specific and macro-level network properties such
as clusterization coefficient and network density. Based on these metrics a
supervised classification procedure is applied to the sub-collections to
classify comedies and tragedies using the Support Vector Machine (SVM) method.
Our research shows that this approach can also produce reliable results on a
small sample size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Retrieval-augmented Image Captioning. (arXiv:2302.08268v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08268">
<div class="article-summary-box-inner">
<span><p>Inspired by retrieval-augmented language generation and pretrained Vision and
Language (V&amp;L) encoders, we present a new approach to image captioning that
generates sentences given the input image and a set of captions retrieved from
a datastore, as opposed to the image alone. The encoder in our model jointly
processes the image and retrieved captions using a pretrained V&amp;L BERT, while
the decoder attends to the multimodal encoder representations, benefiting from
the extra textual evidence from the retrieved captions. Experimental results on
the COCO dataset show that image captioning can be effectively formulated from
this new perspective. Our model, named EXTRA, benefits from using captions
retrieved from the training dataset, and it can also benefit from using an
external dataset without the need for retraining. Ablation studies show that
retrieving a sufficient number of captions (e.g., k=5) can improve captioning
quality. Our work contributes towards using pretrained V&amp;L encoders for
generative tasks, instead of standard classification tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NUAA-QMUL-AIIT at Memotion 3: Multi-modal Fusion with Squeeze-and-Excitation for Internet Meme Emotion Analysis. (arXiv:2302.08326v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08326">
<div class="article-summary-box-inner">
<span><p>This paper describes the participation of our NUAA-QMUL-AIIT team in the
Memotion 3 shared task on meme emotion analysis. We propose a novel multi-modal
fusion method, Squeeze-and-Excitation Fusion (SEFusion), and embed it into our
system for emotion classification in memes. SEFusion is a simple fusion method
that employs fully connected layers, reshaping, and matrix multiplication.
SEFusion learns a weight for each modality and then applies it to its own
modality feature. We evaluate the performance of our system on the three
Memotion 3 sub-tasks. Among all participating systems in this Memotion 3 shared
task, our system ranked first on task A, fifth on task B, and second on task C.
Our proposed SEFusion provides the flexibility to fuse any features from
different modalities. The source code for our method is published on
https://github.com/xxxxxxxxy/memotion3-SEFusion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cluster-based Deep Ensemble Learning for Emotion Classification in Internet Memes. (arXiv:2302.08343v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08343">
<div class="article-summary-box-inner">
<span><p>Memes have gained popularity as a means to share visual ideas through the
Internet and social media by mixing text, images and videos, often for humorous
purposes. Research enabling automated analysis of memes has gained attention in
recent years, including among others the task of classifying the emotion
expressed in memes. In this paper, we propose a novel model, cluster-based deep
ensemble learning (CDEL), for emotion classification in memes. CDEL is a hybrid
model that leverages the benefits of a deep learning model in combination with
a clustering algorithm, which enhances the model with additional information
after clustering memes with similar facial features. We evaluate the
performance of CDEL on a benchmark dataset for emotion classification, proving
its effectiveness by outperforming a wide range of baseline models and
achieving state-of-the-art performance. Further evaluation through ablated
models demonstrates the effectiveness of the different components of CDEL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Event-based News Narrative Extraction. (arXiv:2302.08351v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08351">
<div class="article-summary-box-inner">
<span><p>Narratives are fundamental to our understanding of the world, providing us
with a natural structure for knowledge representation over time. Computational
narrative extraction is a subfield of artificial intelligence that makes heavy
use of information retrieval and natural language processing techniques.
Despite the importance of computational narrative extraction, relatively little
scholarly work exists on synthesizing previous research and strategizing future
research in the area. In particular, this article focuses on extracting news
narratives from an event-centric perspective. Extracting narratives from news
data has multiple applications in understanding the evolving information
landscape. This survey presents an extensive study of research in the area of
event-based news narrative extraction. In particular, we screened over 900
articles that yielded 54 relevant articles. These articles are synthesized and
organized by representation model, extraction criteria, and evaluation
approaches. Based on the reviewed studies, we identify recent trends, open
challenges, and potential research lines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conversation Style Transfer using Few-Shot Learning. (arXiv:2302.08362v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08362">
<div class="article-summary-box-inner">
<span><p>Conventional text style transfer approaches for natural language focus on
sentence-level style transfer without considering contextual information, and
the style is described with attributes (e.g., formality). When applying style
transfer on conversations such as task-oriented dialogues, existing approaches
suffer from these limitations as context can play an important role and the
style attributes are often difficult to define in conversations. In this paper,
we introduce conversation style transfer as a few-shot learning problem, where
the model learns to perform style transfer by observing only the target-style
dialogue examples. We propose a novel in-context learning approach to solve the
task with style-free dialogues as a pivot. Human evaluation shows that by
incorporating multi-turn context, the model is able to match the target style
while having better appropriateness and semantic correctness compared to
utterance-level style transfer. Additionally, we show that conversation style
transfer can also benefit downstream tasks. Results on multi-domain intent
classification tasks show improvement in F1 scores after transferring the style
of training data to match the style of test data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficiency 360: Efficient Vision Transformers. (arXiv:2302.08374v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08374">
<div class="article-summary-box-inner">
<span><p>Transformers are widely used for solving tasks in natural language
processing, computer vision, speech, and music domains. In this paper, we talk
about the efficiency of transformers in terms of memory (the number of
parameters), computation cost (number of floating points operations), and
performance of models, including accuracy, the robustness of the model, and
fair \&amp; bias-free features. We mainly discuss the vision transformer for the
image classification task. Our contribution is to introduce an efficient 360
framework, which includes various aspects of the vision transformer, to make it
more efficient for industrial applications. By considering those applications,
we categorize them into multiple dimensions such as privacy, robustness,
transparency, fairness, inclusiveness, continual learning, probabilistic
models, approximation, computational complexity, and spectral complexity. We
compare various vision transformer models based on their performance, the
number of parameters, and the number of floating point operations (FLOPs) on
multiple datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEALLA: Learning Lightweight Language-agnostic Sentence Embeddings with Knowledge Distillation. (arXiv:2302.08387v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08387">
<div class="article-summary-box-inner">
<span><p>Large-scale language-agnostic sentence embedding models such as LaBSE (Feng
et al., 2022) obtain state-of-the-art performance for parallel sentence
alignment. However, these large-scale models can suffer from inference speed
and computation overhead. This study systematically explores learning
language-agnostic sentence embeddings with lightweight models. We demonstrate
that a thin-deep encoder can construct robust low-dimensional sentence
embeddings for 109 languages. With our proposed distillation methods, we
achieve further improvements by incorporating knowledge from a teacher model.
Empirical results on Tatoeba, United Nations, and BUCC show the effectiveness
of our lightweight models. We release our lightweight language-agnostic
sentence embedding models LEALLA on TensorFlow Hub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks. (arXiv:2302.08399v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08399">
<div class="article-summary-box-inner">
<span><p>Intuitive psychology is a pillar of common-sense reasoning. The replication
of this reasoning in machine intelligence is an important stepping-stone on the
way to human-like artificial intelligence. Several recent tasks and benchmarks
for examining this reasoning in Large-Large Models have focused in particular
on belief attribution in Theory-of-Mind tasks. These tasks have shown both
successes and failures. We consider in particular a recent purported success
case, and show that small variations that maintain the principles of ToM turn
the results on their head. We argue that in general, the zero-hypothesis for
model evaluation in intuitive psychology should be skeptical, and that outlying
failure cases should outweigh average success rates. We also consider what
possible future successes on Theory-of-Mind tasks by more powerful LLMs would
mean for ToM tasks with people.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating and Improving the Coreference Capabilities of Machine Translation Models. (arXiv:2302.08464v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08464">
<div class="article-summary-box-inner">
<span><p>Machine translation (MT) requires a wide range of linguistic capabilities,
which current end-to-end models are expected to learn implicitly by observing
aligned sentences in bilingual corpora. In this work, we ask: \emph{How well do
MT models learn coreference resolution from implicit signal?} To answer this
question, we develop an evaluation methodology that derives coreference
clusters from MT output and evaluates them without requiring annotations in the
target language. We further evaluate several prominent open-source and
commercial MT systems, translating from English to six target languages, and
compare them to state-of-the-art coreference resolvers on three challenging
benchmarks. Our results show that the monolingual resolvers greatly outperform
MT models. Motivated by this result, we experiment with different methods for
incorporating the output of coreference resolution models in MT, showing
improvement over strong baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEVER: Learning to Verify Language-to-Code Generation with Execution. (arXiv:2302.08468v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08468">
<div class="article-summary-box-inner">
<span><p>The advent of pre-trained code language models (CodeLMs) has lead to
significant progress in language-to-code generation. State-of-the-art
approaches in this area combine CodeLM decoding with sample pruning and
reranking using test cases or heuristics based on the execution results.
However, it is challenging to obtain test cases for many real-world
language-to-code applications, and heuristics cannot well capture the semantic
features of the execution results, such as data type and value range, which
often indicates the correctness of the program. In this work, we propose LEVER,
a simple approach to improve language-to-code generation by learning to verify
the generated programs with their execution results. Specifically, we train
verifiers to determine whether a program sampled from the CodeLM is correct or
not based on the natural language input, the program itself and its execution
results. The sampled programs are reranked by combining the verification score
with the CodeLM generation probability, and marginalizing over programs with
the same execution results. On four datasets across the domains of table QA,
math QA and basic Python programming, LEVER consistently improves over the base
CodeLMs (4.6% to 10.9% with code-davinci-002) and achieves new state-of-the-art
results on all of them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Auditing large language models: a three-layered approach. (arXiv:2302.08500v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08500">
<div class="article-summary-box-inner">
<span><p>The emergence of large language models (LLMs) represents a major advance in
artificial intelligence (AI) research. However, the widespread use of LLMs is
also coupled with significant ethical and social challenges. Previous research
has pointed towards auditing as a promising governance mechanism to help ensure
that AI systems are designed and deployed in ways that are ethical, legal, and
technically robust. However, existing auditing procedures fail to address the
governance challenges posed by LLMs, which are adaptable to a wide range of
downstream tasks. To help bridge that gap, we offer three contributions in this
article. First, we establish the need to develop new auditing procedures that
capture the risks posed by LLMs by analysing the affordances and constraints of
existing auditing procedures. Second, we outline a blueprint to audit LLMs in
feasible and effective ways by drawing on best practices from IT governance and
system engineering. Specifically, we propose a three-layered approach, whereby
governance audits, model audits, and application audits complement and inform
each other. Finally, we discuss the limitations not only of our three-layered
approach but also of the prospect of auditing LLMs at all. Ultimately, this
article seeks to expand the methodological toolkit available to technology
providers and policymakers who wish to analyse and evaluate LLMs from
technical, ethical, and legal perspectives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pairwise Representation Learning for Event Coreference. (arXiv:2010.12808v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12808">
<div class="article-summary-box-inner">
<span><p>Natural Language Processing tasks such as resolving the coreference of events
require understanding the relations between two text snippets. These tasks are
typically formulated as (binary) classification problems over independently
induced representations of the text snippets. In this work, we develop a
Pairwise Representation Learning (PairwiseRL) scheme for the event mention
pairs, in which we jointly encode a pair of text snippets so that the
representation of each mention in the pair is induced in the context of the
other one. Furthermore, our representation supports a finer, structured
representation of the text snippet to facilitate encoding events and their
arguments. We show that PairwiseRL, despite its simplicity, outperforms the
prior state-of-the-art event coreference systems on both cross-document and
within-document event coreference benchmarks. We also conduct in-depth analysis
in terms of the improvement and the limitation of pairwise representation so as
to provide insights for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predictions For Pre-training Language Models. (arXiv:2011.09031v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09031">
<div class="article-summary-box-inner">
<span><p>Language model pre-training has proven to be useful in many language
understanding tasks. In this paper, we investigate whether it is still helpful
to add the self-training method in the pre-training step and the fine-tuning
step. Towards this goal, we propose a learning framework that making best use
of the unlabel data on the low-resource and high-resource labeled dataset. In
industry NLP applications, we have large amounts of data produced by users or
customers. Our learning framework is based on this large amounts of unlabel
data. First, We use the model fine-tuned on manually labeled dataset to predict
pseudo labels for the user-generated unlabeled data. Then we use the pseudo
labels to supervise the task-specific training on the large amounts of
user-generated data. We consider this task-specific training step on pseudo
labels as a pre-training step for the next fine-tuning step. At last, we
fine-tune on the manually labeled dataset upon the pre-trained model. In this
work, we first empirically show that our method is able to solidly improve the
performance by 3.6%, when the manually labeled fine-tuning dataset is
relatively small. Then we also show that our method still is able to improve
the performance further by 0.2%, when the manually labeled fine-tuning dataset
is relatively large enough. We argue that our method make the best use of the
unlabel data, which is superior to either pre-training or self-training alone.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Event Linking: Grounding Event Mentions to Wikipedia. (arXiv:2112.07888v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.07888">
<div class="article-summary-box-inner">
<span><p>Comprehending an article requires understanding its constituent events.
However, the context where an event is mentioned often lacks the details of
this event. A question arises: how can the reader obtain more knowledge about
this particular event in addition to what is provided by the local context in
the article?
</p>
<p>This work defines Event Linking, a new natural language understanding task at
the event level. Event linking tries to link an event mention appearing in an
article to the most appropriate Wikipedia page. This page is expected to
provide rich knowledge about what the event mention refers to. To standardize
the research in this new direction, we contribute in four-fold. First, this is
the first work in the community that formally defines Event Linking task.
Second, we collect a dataset for this new task. Specifically, we automatically
gather training set from Wikipedia, and then create two evaluation sets: one
from the Wikipedia domain, reporting the in-domain performance, and a second
from the real-world news domain, to evaluate out-of-domain performance. Third,
we retrain and evaluate two state-of-the-art (SOTA) entity linking models,
showing the challenges of event linking, and we propose an event-specific
linking system EVELINK to set a competitive result for the new task. Fourth, we
conduct a detailed and insightful analysis to help understand the task and the
limitation of the current model. Overall, as our analysis shows, Event Linking
is a considerably challenging and essential task requiring more effort from the
community. Data and code are available here:
https://github.com/CogComp/event-linking.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BITE: Textual Backdoor Attacks with Iterative Trigger Injection. (arXiv:2205.12700v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12700">
<div class="article-summary-box-inner">
<span><p>Backdoor attacks have become an emerging threat to NLP systems. By providing
poisoned training data, the adversary can embed a ``backdoor'' into the victim
model, which allows input instances satisfying certain textual patterns (e.g.,
containing a keyword) to be predicted as a target label of the adversary's
choice. In this paper, we demonstrate that it's possible to design a backdoor
attack that is both stealthy (i.e., hard to notice) and effective (i.e., has a
high attack success rate). We propose BITE, a backdoor attack that poisons the
training data to establish strong correlations between the target label and
some ``trigger words'', by iteratively injecting them into target-label
instances through natural word-level perturbations. The poisoned training data
instruct the victim model to predict the target label on inputs containing
trigger words, forming the backdoor. Experiments on four medium-sized text
classification datasets show that BITE is significantly more effective than
baselines while maintaining decent stealthiness, raising alarm on the usage of
untrusted training data. We further propose a defense method named DeBITE based
on potential trigger word removal, which outperforms existing methods on
defending BITE and generalizes well to defending other backdoor attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neuro-Symbolic Procedural Planning with Commonsense Prompting. (arXiv:2206.02928v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02928">
<div class="article-summary-box-inner">
<span><p>Procedural planning aims to implement complex high-level goals by
decomposition into sequential simpler low-level steps. Although procedural
planning is a basic skill set for humans in daily life, it remains a challenge
for large language models (LLMs) that lack a deep understanding of the
cause-effect relations in procedures. Previous methods require manual exemplars
to acquire procedural planning knowledge from LLMs in the zero-shot setting.
However, such elicited pre-trained knowledge in LLMs induces spurious
correlations between goals and steps, which impair the model generalization to
unseen tasks. In contrast, this paper proposes a neuro-symbolic procedural
PLANner (PLAN) that elicits procedural planning knowledge from the LLMs with
commonsense-infused prompting. To mitigate spurious goal-step correlations, we
use symbolic program executors on the latent procedural representations to
formalize prompts from commonsense knowledge bases as a causal intervention
toward the Structural Causal Model. Both automatic and human evaluations on
WikiHow and RobotHow show the superiority of PLAN on procedural planning
without further training or manual exemplars.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BigVGAN: A Universal Neural Vocoder with Large-Scale Training. (arXiv:2206.04658v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04658">
<div class="article-summary-box-inner">
<span><p>Despite recent progress in generative adversarial network (GAN)-based
vocoders, where the model generates raw waveform conditioned on acoustic
features, it is challenging to synthesize high-fidelity audio for numerous
speakers across various recording environments. In this work, we present
BigVGAN, a universal vocoder that generalizes well for various
out-of-distribution scenarios without fine-tuning. We introduce periodic
activation function and anti-aliased representation into the GAN generator,
which brings the desired inductive bias for audio synthesis and significantly
improves audio quality. In addition, we train our GAN vocoder at the largest
scale up to 112M parameters, which is unprecedented in the literature. We
identify and address the failure modes in large-scale GAN training for audio,
while maintaining high-fidelity output without over-regularization. Our
BigVGAN, trained only on clean speech (LibriTTS), achieves the state-of-the-art
performance for various zero-shot (out-of-distribution) conditions, including
unseen speakers, languages, recording environments, singing voices, music, and
instrumental audio. We release our code and model at:
https://github.com/NVIDIA/BigVGAN
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Write and Paint: Generative Vision-Language Models are Unified Modal Learners. (arXiv:2206.07699v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.07699">
<div class="article-summary-box-inner">
<span><p>Recent advances in vision-language pre-training have pushed the
state-of-the-art on various vision-language tasks, making machines more capable
of multi-modal writing (image-to-text generation) and painting (text-to-image
generation). However, few studies investigate if these two essential
capabilities can be learned together and boost each other, making a versatile
and powerful multi-modal foundation model. In this work, we disclose the
potential of symmetric generative vision-language pre-training in learning to
write and paint concurrently, and propose a new unified modal model, named
DaVinci, trained with prefix language modeling and prefix image modeling, a
simple generative self-supervised objective on image-text pairs. Thanks to the
proposed prefix multi-modal modeling framework, DaVinci is simple to train,
scalable to huge data, adaptable to both writing and painting tasks, and also
strong on other vision, text, and multi-modal understanding tasks. DaVinci
achieves competitive performance on a wide range of 27 generation/understanding
tasks and demonstrates the superiority of combining vision/language generative
pre-training. Furthermore, we carefully benchmark the performance of different
vision-language pre-training objectives on different scales of pre-training
datasets on a heterogeneous and broad distribution coverage. Our results
demonstrate the potential of exploiting self-supervision in both language and
vision inputs, and establish new, stronger baselines for future comparisons at
different data scales. The code and pre-trained models are available at
https://github.com/shizhediao/DaVinci.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recitation-Augmented Language Models. (arXiv:2210.01296v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.01296">
<div class="article-summary-box-inner">
<span><p>We propose a new paradigm to help Large Language Models (LLMs) generate more
accurate factual knowledge without retrieving from an external corpus, called
RECITation-augmented gEneration (RECITE). Different from retrieval-augmented
language models that retrieve relevant documents before generating the outputs,
given an input, RECITE first recites one or several relevant passages from
LLMs' own memory via sampling, and then produces the final answers. We show
that RECITE is a powerful paradigm for knowledge-intensive NLP tasks.
Specifically, we show that by utilizing recitation as the intermediate step, a
recite-and-answer scheme can achieve new state-of-the-art performance in
various closed-book question answering (CBQA) tasks. In experiments, we verify
the effectiveness of \method~on four pre-trained models (PaLM, UL2, OPT, and
Codex) and three CBQA tasks (Natural Questions, TriviaQA, and HotpotQA). Our
code is available at "https://github.com/Edward-Sun/RECITE".
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Disentangled Representations for Natural Language Definitions. (arXiv:2210.02898v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.02898">
<div class="article-summary-box-inner">
<span><p>Disentangling the encodings of neural models is a fundamental aspect for
improving interpretability, semantic control and downstream task performance in
Natural Language Processing. Currently, most disentanglement methods are
unsupervised or rely on synthetic datasets with known generative factors. We
argue that recurrent syntactic and semantic regularities in textual data can be
used to provide the models with both structural biases and generative factors.
We leverage the semantic structures present in a representative and
semantically dense category of sentence types, definitional sentences, for
training a Variational Autoencoder to learn disentangled representations. Our
experimental results show that the proposed model outperforms unsupervised
baselines on several qualitative and quantitative benchmarks for
disentanglement, and it also improves the results in the downstream task of
definition modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SODAPOP: Open-Ended Discovery of Social Biases in Social Commonsense Reasoning Models. (arXiv:2210.07269v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07269">
<div class="article-summary-box-inner">
<span><p>A common limitation of diagnostic tests for detecting social biases in NLP
models is that they may only detect stereotypic associations that are
pre-specified by the designer of the test. Since enumerating all possible
problematic associations is infeasible, it is likely these tests fail to detect
biases that are present in a model but not pre-specified by the designer. To
address this limitation, we propose SODAPOP (SOcial bias Discovery from Answers
about PeOPle) in social commonsense question-answering. Our pipeline generates
modified instances from the Social IQa dataset (Sap et al., 2019) by (1)
substituting names associated with different demographic groups, and (2)
generating many distractor answers from a masked language model. By using a
social commonsense model to score the generated distractors, we are able to
uncover the model's stereotypic associations between demographic groups and an
open set of words. We also test SODAPOP on debiased models and show the
limitations of multiple state-of-the-art debiasing algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods. (arXiv:2210.07321v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07321">
<div class="article-summary-box-inner">
<span><p>Machine generated text is increasingly difficult to distinguish from human
authored text. Powerful open-source models are freely available, and
user-friendly tools that democratize access to generative models are
proliferating. ChatGPT, which was released shortly after the first preprint of
this survey, epitomizes these trends. The great potential of state-of-the-art
natural language generation (NLG) systems is tempered by the multitude of
avenues for abuse. Detection of machine generated text is a key countermeasure
for reducing abuse of NLG models, with significant technical challenges and
numerous open problems. We provide a survey that includes both 1) an extensive
analysis of threat models posed by contemporary NLG systems, and 2) the most
complete review of machine generated text detection methods to date. This
survey places machine generated text within its cybersecurity and social
context, and provides strong guidance for future work addressing the most
critical threat models, and ensuring detection systems themselves demonstrate
trustworthiness through fairness, robustness, and accountability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can language models handle recursively nested grammatical structures? A case study on comparing models and humans. (arXiv:2210.15303v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.15303">
<div class="article-summary-box-inner">
<span><p>How should we compare the capabilities of language models (LMs) and humans? I
draw inspiration from comparative psychology to highlight some challenges. In
particular, I consider a case study: processing of recursively nested
grammatical structures. Prior work suggests that LMs cannot handle these
structures as reliably as humans can. However, the humans were provided with
instructions and training, while the LMs were evaluated zero-shot. I therefore
match the evaluation more closely. Providing large LMs with a simple prompt --
substantially less content than the human training -- allows the LMs to
consistently outperform the human results, and even to extrapolate to more
deeply nested conditions than were tested with humans. Further, reanalyzing the
prior human data suggests that the humans may not perform above chance at the
difficult structures initially. Thus, large LMs may indeed process recursively
nested grammatical structures as reliably as humans. This case study highlights
how discrepancies in the evaluation can confound comparisons of language models
and humans. I therefore reflect on the broader challenge of comparing human and
model capabilities, and highlight an important difference between evaluating
cognitive models and foundation models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WR-ONE2SET: Towards Well-Calibrated Keyphrase Generation. (arXiv:2211.06862v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.06862">
<div class="article-summary-box-inner">
<span><p>Keyphrase generation aims to automatically generate short phrases summarizing
an input document. The recently emerged ONE2SET paradigm (Ye et al., 2021)
generates keyphrases as a set and has achieved competitive performance.
Nevertheless, we observe serious calibration errors outputted by ONE2SET,
especially in the over-estimation of $\varnothing$ token (means "no
corresponding keyphrase"). In this paper, we deeply analyze this limitation and
identify two main reasons behind: 1) the parallel generation has to introduce
excessive $\varnothing$ as padding tokens into training instances; and 2) the
training mechanism assigning target to each slot is unstable and further
aggravates the $\varnothing$ token over-estimation. To make the model
well-calibrated, we propose WR-ONE2SET which extends ONE2SET with an adaptive
instance-level cost Weighting strategy and a target Re-assignment mechanism.
The former dynamically penalizes the over-estimated slots for different
instances thus smoothing the uneven training distribution. The latter refines
the original inappropriate assignment and reduces the supervisory signals of
over-estimated slots. Experimental results on commonly-used datasets
demonstrate the effectiveness and generality of our proposed paradigm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Easy to Decide, Hard to Agree: Reducing Disagreements Between Saliency Methods. (arXiv:2211.08369v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.08369">
<div class="article-summary-box-inner">
<span><p>A popular approach to unveiling the black box of neural NLP models is to
leverage saliency methods, which assign scalar importance scores to each input
component. A common practice for evaluating whether an interpretability method
is faithful and plausible has been to use evaluation-by-agreement -- multiple
methods agreeing on an explanation increases its credibility. However, recent
work has found that even saliency methods have weak rank correlations and
advocated for the use of alternative diagnostic methods. In our work, we
demonstrate that rank correlation is not a good fit for evaluating agreement
and argue that Pearson-$r$ is a better suited alternative. We show that
regularization techniques that increase faithfulness of attention explanations
also increase agreement between saliency methods. Through connecting our
findings to instance categories based on training dynamics we show that,
surprisingly, easy-to-learn instances exhibit low agreement in saliency method
explanations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reward Gaming in Conditional Text Generation. (arXiv:2211.08714v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.08714">
<div class="article-summary-box-inner">
<span><p>To align conditional text generation model outputs with desired behaviors,
there has been an increasing focus on training the model using reinforcement
learning (RL) with reward functions learned from human annotations. Under this
framework, we identify three common cases where high rewards are incorrectly
assigned to undesirable patterns: noise-induced spurious correlation, naturally
occurring spurious correlation, and covariate shift. We show that even though
learned metrics achieve high performance on the distribution of the data used
to train the reward function, the undesirable patterns may be amplified during
RL training of the text generation model. While there has been discussion about
reward gaming in the RL or safety community, in this discussion piece, we would
like to highlight reward gaming in the natural language generation (NLG)
community using concrete conditional text generation examples and discuss
potential fixes and areas for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Surrogate Gradient Spiking Neural Networks as Encoders for Large Vocabulary Continuous Speech Recognition. (arXiv:2212.01187v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01187">
<div class="article-summary-box-inner">
<span><p>Compared to conventional artificial neurons that produce dense and
real-valued responses, biologically-inspired spiking neurons transmit sparse
and binary information, which can also lead to energy-efficient
implementations. Recent research has shown that spiking neural networks can be
trained like standard recurrent neural networks using the surrogate gradient
method. They have shown promising results on speech command recognition tasks.
Using the same technique, we show that they are scalable to large vocabulary
continuous speech recognition, where they are capable of replacing LSTMs in the
encoder with only minor loss of performance. This suggests that they may be
applicable to more involved sequence-to-sequence tasks. Moreover, in contrast
to their recurrent non-spiking counterparts, they show robustness to exploding
gradient problems without the need to use gates.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Talking About Large Language Models. (arXiv:2212.03551v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03551">
<div class="article-summary-box-inner">
<span><p>Thanks to rapid progress in artificial intelligence, we have entered an era
when technology and philosophy intersect in interesting ways. Sitting squarely
at the centre of this intersection are large language models (LLMs). The more
adept LLMs become at mimicking human language, the more vulnerable we become to
anthropomorphism, to seeing the systems in which they are embedded as more
human-like than they really are. This trend is amplified by the natural
tendency to use philosophically loaded terms, such as "knows", "believes", and
"thinks", when describing these systems. To mitigate this trend, this paper
advocates the practice of repeatedly stepping back to remind ourselves of how
LLMs, and the systems of which they form a part, actually work. The hope is
that increased scientific precision will encourage more philosophical nuance in
the discourse around artificial intelligence, both within the field and in the
public sphere.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Choosing the Number of Topics in LDA Models -- A Monte Carlo Comparison of Selection Criteria. (arXiv:2212.14074v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.14074">
<div class="article-summary-box-inner">
<span><p>Selecting the number of topics in LDA models is considered to be a difficult
task, for which alternative approaches have been proposed. The performance of
the recently developed singular Bayesian information criterion (sBIC) is
evaluated and compared to the performance of alternative model selection
criteria. The sBIC is a generalization of the standard BIC that can be
implemented to singular statistical models. The comparison is based on Monte
Carlo simulations and carried out for several alternative settings, varying
with respect to the number of topics, the number of documents and the size of
documents in the corpora. Performance is measured using different criteria
which take into account the correct number of topics, but also whether the
relevant topics from the DGPs are identified. Practical recommendations for LDA
model selection in applications are derived.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neighborhood-Regularized Self-Training for Learning with Few Labels. (arXiv:2301.03726v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.03726">
<div class="article-summary-box-inner">
<span><p>Training deep neural networks (DNNs) with limited supervision has been a
popular research topic as it can significantly alleviate the annotation burden.
Self-training has been successfully applied in semi-supervised learning tasks,
but one drawback of self-training is that it is vulnerable to the label noise
from incorrect pseudo labels. Inspired by the fact that samples with similar
labels tend to share similar representations, we develop a neighborhood-based
sample selection approach to tackle the issue of noisy pseudo labels. We
further stabilize self-training via aggregating the predictions from different
rounds during sample selection. Experiments on eight tasks show that our
proposed method outperforms the strongest self-training baseline with 1.83% and
2.51% performance gain for text and graph datasets on average. Our further
analysis demonstrates that our proposed data selection strategy reduces the
noise of pseudo labels by 36.8% and saves 57.3% of the time when compared with
the best baseline. Our code and appendices will be uploaded to
https://github.com/ritaranx/NeST.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning Models to Study Sentence Comprehension in the Human Brain. (arXiv:2301.06340v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.06340">
<div class="article-summary-box-inner">
<span><p>Recent artificial neural networks that process natural language achieve
unprecedented performance in tasks requiring sentence-level understanding. As
such, they could be interesting models of the integration of linguistic
information in the human brain. We review works that compare these artificial
language models with human brain activity and we assess the extent to which
this approach has improved our understanding of the neural processes involved
in natural language comprehension. Two main results emerge. First, the neural
representation of word meaning aligns with the context-dependent, dense word
vectors used by the artificial neural networks. Second, the processing
hierarchy that emerges within artificial neural networks broadly matches the
brain, but is surprisingly inconsistent across studies. We discuss current
challenges in establishing artificial neural networks as process models of
natural language comprehension. We suggest exploiting the highly structured
representational geometry of artificial neural networks when mapping
representations to brain data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causal Reasoning of Entities and Events in Procedural Texts. (arXiv:2301.10896v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10896">
<div class="article-summary-box-inner">
<span><p>Entities and events are crucial to natural language reasoning and common in
procedural texts. Existing work has focused either exclusively on entity state
tracking (e.g., whether a pan is hot) or on event reasoning (e.g., whether one
would burn themselves by touching the pan), while these two tasks are often
causally related. We propose CREPE, the first benchmark on causal reasoning of
event plausibility and entity states. We show that most language models,
including GPT-3, perform close to chance at .35 F1, lagging far behind human at
.87 F1. We boost model performance to .59 F1 by creatively representing events
as programming languages while prompting language models pretrained on code. By
injecting the causal relations between entities and events as intermediate
reasoning steps in our representation, we further boost the performance to .67
F1. Our findings indicate not only the challenge that CREPE brings for language
models, but also the efficacy of code-like prompting combined with
chain-of-thought prompting for multihop event reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Chain-of-Thought Reasoning in Language Models. (arXiv:2302.00923v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00923">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have shown impressive performance on complex
reasoning by leveraging chain-of-thought (CoT) prompting to generate
intermediate reasoning chains as the rationale to infer the answer. However,
existing CoT studies have focused on the language modality. We propose
Multimodal-CoT that incorporates language (text) and vision (images) modalities
into a two-stage framework that separates rationale generation and answer
inference. In this way, answer inference can leverage better generated
rationales that are based on multimodal information. With Multimodal-CoT, our
model under 1 billion parameters outperforms the previous state-of-the-art LLM
(GPT-3.5) by 16% (75.17%-&gt;91.68%) on the ScienceQA benchmark and even surpasses
human performance. Code is publicly available available at
https://github.com/amazon-science/mm-cot.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UDApter -- Efficient Domain Adaptation Using Adapters. (arXiv:2302.03194v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03194">
<div class="article-summary-box-inner">
<span><p>We propose two methods to make unsupervised domain adaptation (UDA) more
parameter efficient using adapters, small bottleneck layers interspersed with
every layer of the large-scale pre-trained language model (PLM). The first
method deconstructs UDA into a two-step process: first by adding a domain
adapter to learn domain-invariant information and then by adding a task adapter
that uses domain-invariant information to learn task representations in the
source domain. The second method jointly learns a supervised classifier while
reducing the divergence measure. Compared to strong baselines, our simple
methods perform well in natural language inference (MNLI) and the cross-domain
sentiment classification task. We even outperform unsupervised domain
adaptation methods such as DANN and DSN in sentiment classification, and we are
within 0.85% F1 for natural language inference task, by fine-tuning only a
fraction of the full model parameters. We release our code at
https://github.com/declare-lab/domadapter
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04054">
<div class="article-summary-box-inner">
<span><p>Reliability of machine learning evaluation -- the consistency of observed
evaluation scores across replicated model training runs -- is affected by
several sources of nondeterminism which can be regarded as measurement noise.
Current tendencies to remove noise in order to enforce reproducibility of
research results neglect inherent nondeterminism at the implementation level
and disregard crucial interaction effects between algorithmic noise factors and
data properties. This limits the scope of conclusions that can be drawn from
such experiments. Instead of removing noise, we propose to incorporate several
sources of variance, including their interaction with data properties, into an
analysis of significance and reliability of machine learning evaluation, with
the aim to draw inferences beyond particular instances of trained models. We
show how to use linear mixed effects models (LMEMs) to analyze performance
evaluation scores, and to conduct statistical inference with a generalized
likelihood ratio test (GLRT). This allows us to incorporate arbitrary sources
of noise like meta-parameter variations into statistical significance testing,
and to assess performance differences conditional on data properties.
Furthermore, a variance component analysis (VCA) enables the analysis of the
contribution of noise sources to overall variance and the computation of a
reliability coefficient by the ratio of substantial to total variance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BLIAM: Literature-based Data Synthesis for Synergistic Drug Combination Prediction. (arXiv:2302.06860v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.06860">
<div class="article-summary-box-inner">
<span><p>Language models pre-trained on scientific literature corpora have
substantially advanced scientific discovery by offering high-quality feature
representations for downstream applications. However, these features are often
not interpretable, and thus can reveal limited insights to domain experts.
Instead of obtaining features from language models, we propose BLIAM, a
literature-based data synthesis approach to directly generate training data
points that are interpretable and model-agnostic to downstream applications.
The key idea of BLIAM is to create prompts using existing training data and
then use these prompts to synthesize new data points. BLIAM performs these two
steps iteratively as new data points will define more informative prompts and
new prompts will in turn synthesize more accurate data points. Notably,
literature-based data augmentation might introduce data leakage since labels of
test data points in downstream applications might have already been mentioned
in the language model corpus. To prevent such leakage, we introduce GDSC-combo,
a large-scale drug combination discovery dataset that was published after the
biomedical language model was trained. We found that BLIAM substantially
outperforms a non-augmented approach and manual prompting in this rigorous data
split setting. BLIAM can be further used to synthesize data points for novel
drugs and cell lines that were not even measured in biomedical experiments. In
addition to the promising prediction performance, the data points synthesized
by BLIAM are interpretable and model-agnostic, enabling in silico augmentation
for in vitro experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Artificial intelligence in psychology research. (arXiv:2302.07267v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07267">
<div class="article-summary-box-inner">
<span><p>Large Language Models have vastly grown in capabilities. One potential
application of such AI systems is to support data collection in the social
sciences, where perfect experimental control is currently unfeasible and the
collection of large, representative datasets is generally expensive. In this
paper, we re-replicate 14 studies from the Many Labs 2 replication project
(Klein et al., 2018) with OpenAI's text-davinci-003 model, colloquially known
as GPT3.5. For the 10 studies that we could analyse, we collected a total of
10,136 responses, each of which was obtained by running GPT3.5 with the
corresponding study's survey inputted as text. We find that our GPT3.5-based
sample replicates 30% of the original results as well as 30% of the Many Labs 2
results, although there is heterogeneity in both these numbers (as we replicate
some original findings that Many Labs 2 did not and vice versa). We also find
that unlike the corresponding human subjects, GPT3.5 answered some survey
questions with extreme homogeneity$\unicode{x2013}$with zero variation in
different runs' responses$\unicode{x2013}$raising concerns that a hypothetical
AI-led future may in certain ways be subject to a diminished diversity of
thought. Overall, while our results suggest that Large Language Model
psychology studies are feasible, their findings should not be assumed to
straightforwardly generalise to the human case. Nevertheless, AI-based data
collection may eventually become a viable and economically relevant method in
the empirical social sciences, making the understanding of its capabilities and
applications central.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer models: an introduction and catalog. (arXiv:2302.07730v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07730">
<div class="article-summary-box-inner">
<span><p>In the past few years we have seen the meteoric appearance of dozens of
models of the Transformer family, all of which have funny, but not
self-explanatory, names. The goal of this paper is to offer a somewhat
comprehensive but simple catalog and classification of the most popular
Transformer models. The paper also includes an introduction to the most
important aspects and innovation in Transformer models.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-02-18 23:12:16.135860199 UTC">2023-02-18 23:12:16 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>