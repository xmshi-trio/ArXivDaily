<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-02-13T01:30:00Z">02-13</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Binarized Neural Machine Translation. (arXiv:2302.04907v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04907">
<div class="article-summary-box-inner">
<span><p>The rapid scaling of language models is motivating research using
low-bitwidth quantization. In this work, we propose a novel binarization
technique for Transformers applied to machine translation (BMT), the first of
its kind. We identify and address the problem of inflated dot-product variance
when using one-bit weights and activations. Specifically, BMT leverages
additional LayerNorms and residual connections to improve binarization quality.
Experiments on the WMT dataset show that a one-bit weight-only Transformer can
achieve the same quality as a float one, while being 16x smaller in size.
One-bit activations incur varying degrees of quality drop, but mitigated by the
proposed architectural changes. We further conduct a scaling law study using
production-scale translation datasets, which shows that one-bit weight
Transformers scale and generalize well in both in-domain and out-of-domain
settings. Implementation in JAX/Flax will be open sourced.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Flexible, Model-Agnostic Method for Materials Data Extraction from Text Using General Purpose Language Models. (arXiv:2302.04914v1 [cond-mat.mtrl-sci])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04914">
<div class="article-summary-box-inner">
<span><p>Accurate and comprehensive material databases extracted from research papers
are critical for materials science and engineering but require significant
human effort to develop. In this paper we present a simple method of extracting
materials data from full texts of research papers suitable for quickly
developing modest-sized databases. The method requires minimal to no coding,
prior knowledge about the extracted property, or model training, and provides
high recall and almost perfect precision in the resultant database. The method
is fully automated except for one human-assisted step, which typically requires
just a few hours of human labor. The method builds on top of natural language
processing and large general language models but can work with almost any such
model. The language models GPT-3/3.5, bart and DeBERTaV3 are evaluated here for
comparison. We provide a detailed detailed analysis of the methods performance
in extracting bulk modulus data, obtaining up to 90% precision at 96% recall,
depending on the amount of human effort involved. We then demonstrate the
methods broader effectiveness by developing a database of critical cooling
rates for metallic glasses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">In-Context Learning with Many Demonstration Examples. (arXiv:2302.04931v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04931">
<div class="article-summary-box-inner">
<span><p>Large pre-training language models (PLMs) have shown promising in-context
learning abilities. However, due to the backbone transformer architecture,
existing PLMs are bottlenecked by the memory and computational cost when
scaling up to a large context size, leaving instruction tuning and in-context
learning of many demonstration examples, as well as long-range language
modeling under-explored. In this study, we propose a long-range language model
EVALM based on an efficient transformer mechanism. EVALM is trained with 8k
tokens per batch line and can test up to 256k-lengthed contexts with
extrapolation, 128 times to the limit of existing PLMs (e.g. GPT3). Based on
EVALM, we scale up the size of examples efficiently in both instruction tuning
and in-context learning to explore the boundary of the benefits from more
annotated data. Experimental results on a diverse set of tasks show that EVALM
achieves 4.1% higher accuracy on average, and the average length of achieving
the best accuracy score over tasks is around 12k. We find that in-context
learning can achieve higher performance with more demonstrations under
many-shot instruction tuning (8k), and further extending the length of
instructions (16k) can further improve the upper bound of scaling in-context
learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging supplementary text data to kick-start automatic speech recognition system development with limited transcriptions. (arXiv:2302.04975v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04975">
<div class="article-summary-box-inner">
<span><p>Recent research using pre-trained transformer models suggests that just 10
minutes of transcribed speech may be enough to fine-tune such a model for
automatic speech recognition (ASR) -- at least if we can also leverage vast
amounts of text data (803 million tokens). But is that much text data
necessary? We study the use of different amounts of text data, both for
creating a lexicon that constrains ASR decoding to possible words (e.g. *dogz
vs. dogs), and for training larger language models that bias the system toward
probable word sequences (e.g. too dogs vs. two dogs). We perform experiments
using 10 minutes of transcribed speech from English (for replicating prior
work) and two additional pairs of languages differing in the availability of
supplemental text data: Gronings and Frisian (~7.5M token corpora available),
and Besemah and Nasal (only small lexica available). For all languages, we
found that using only a lexicon did not appreciably improve ASR performance.
For Gronings and Frisian, we found that lexica and language models derived from
'novel-length' 80k token subcorpora reduced the word error rate (WER) to 39% on
average. Our findings suggest that where a text corpus in the upper tens of
thousands of tokens or more is available, fine-tuning a transformer model with
just tens of minutes of transcribed speech holds some promise towards obtaining
human-correctable transcriptions near the 30% WER rule-of-thumb.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AutoNMT: A Framework to Streamline the Research of Seq2Seq Models. (arXiv:2302.04981v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04981">
<div class="article-summary-box-inner">
<span><p>We present AutoNMT, a framework to streamline the research of seq-to-seq
models by automating the data pipeline (i.e., file management, data
preprocessing, and exploratory analysis), automating experimentation in a
toolkit-agnostic manner, which allows users to use either their own models or
existing seq-to-seq toolkits such as Fairseq or OpenNMT, and finally,
automating the report generation (plots and summaries). Furthermore, this
library comes with its own seq-to-seq toolkit so that users can easily
customize it for non-standard tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Event Temporal Relation Extraction with Bayesian Translational Model. (arXiv:2302.04985v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04985">
<div class="article-summary-box-inner">
<span><p>Existing models to extract temporal relations between events lack a
principled method to incorporate external knowledge. In this study, we
introduce Bayesian-Trans, a Bayesian learning-based method that models the
temporal relation representations as latent variables and infers their values
via Bayesian inference and translational functions. Compared to conventional
neural approaches, instead of performing point estimation to find the best set
parameters, the proposed model infers the parameters' posterior distribution
directly, enhancing the model's capability to encode and express uncertainty
about the predictions. Experimental results on the three widely used datasets
show that Bayesian-Trans outperforms existing approaches for event temporal
relation extraction. We additionally present detailed analyses on uncertainty
quantification, comparison of priors, and ablation studies, illustrating the
benefits of the proposed approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language-Aware Multilingual Machine Translation with Self-Supervised Learning. (arXiv:2302.05008v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05008">
<div class="article-summary-box-inner">
<span><p>Multilingual machine translation (MMT) benefits from cross-lingual transfer
but is a challenging multitask optimization problem. This is partly because
there is no clear framework to systematically learn language-specific
parameters. Self-supervised learning (SSL) approaches that leverage large
quantities of monolingual data (where parallel data is unavailable) have shown
promise by improving translation performance as complementary tasks to the MMT
task. However, jointly optimizing SSL and MMT tasks is even more challenging.
In this work, we first investigate how to utilize intra-distillation to learn
more *language-specific* parameters and then show the importance of these
language-specific parameters. Next, we propose a novel but simple SSL task,
concurrent denoising, that co-trains with the MMT task by concurrently
denoising monolingual data on both the encoder and decoder. Finally, we apply
intra-distillation to this co-training approach. Combining these two approaches
significantly improves MMT performance, outperforming three state-of-the-art
SSL methods by a large margin, e.g., 11.3\% and 3.7\% improvement on an
8-language and a 15-language benchmark compared with MASS, respectively
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is multi-modal vision supervision beneficial to language?. (arXiv:2302.05016v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05016">
<div class="article-summary-box-inner">
<span><p>Vision (image and video) - Language (VL) pre-training is the recent popular
paradigm that achieved state-of-the-art results on multi-modal tasks like
image-retrieval, video-retrieval, visual question answering etc. These models
are trained in an unsupervised way and greatly benefit from the complementary
modality supervision. In this paper, we explore if the language representations
trained using vision supervision perform better than vanilla language
representations on Natural Language Understanding and commonsense reasoning
benchmarks. We experiment with a diverse set of image-text models such as
ALBEF, BLIP, METER and video-text models like ALPRO, Frozen-in-Time (FiT),
VIOLET. We compare the performance of language representations of stand-alone
text encoders of these models to the language representations of text encoders
learnt through vision supervision. Our experiments suggest that vanilla
language representations show superior performance on most of the tasks. These
results shed light on the current drawbacks of the vision-language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting Desirable Revisions of Evidence and Reasoning in Argumentative Writing. (arXiv:2302.05039v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05039">
<div class="article-summary-box-inner">
<span><p>We develop models to classify desirable evidence and desirable reasoning
revisions in student argumentative writing. We explore two ways to improve
classifier performance - using the essay context of the revision, and using the
feedback students received before the revision. We perform both intrinsic and
extrinsic evaluation for each of our models and report a qualitative analysis.
Our results show that while a model using feedback information improves over a
baseline model, models utilizing context - either alone or with feedback - are
the most successful in identifying desirable revisions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PATCorrect: Non-autoregressive Phoneme-augmented Transformer for ASR Error Correction. (arXiv:2302.05040v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05040">
<div class="article-summary-box-inner">
<span><p>Speech-to-text errors made by automatic speech recognition (ASR) system
negatively impact downstream models relying on ASR transcriptions. Language
error correction models as a post-processing text editing approach have been
recently developed for refining the source sentences. However, efficient models
for correcting errors in ASR transcriptions that meet the low latency
requirements of industrial grade production systems have not been well studied.
In this work, we propose a novel non-autoregressive (NAR) error correction
approach to improve the transcription quality by reducing word error rate (WER)
and achieve robust performance across different upstream ASR systems. Our
approach augments the text encoding of the Transformer model with a phoneme
encoder that embeds pronunciation information. The representations from phoneme
encoder and text encoder are combined via multi-modal fusion before feeding
into the length tagging predictor for predicting target sequence lengths. The
joint encoders also provide inputs to the attention mechanism in the NAR
decoder. We experiment on 3 open-source ASR systems with varying speech-to-text
transcription quality and their erroneous transcriptions on 2 public English
corpus datasets. Results show that our PATCorrect (Phoneme Augmented
Transformer for ASR error Correction) consistently outperforms state-of-the-art
NAR error correction method on English corpus across different upstream ASR
systems. For example, PATCorrect achieves 11.62% WER reduction (WERR) averaged
on 3 ASR systems compared to 9.46% WERR achieved by other method using text
only modality and also achieves an inference latency comparable to other NAR
models at tens of millisecond scale, especially on GPU hardware, while still
being 4.2 - 6.7x times faster than autoregressive models on Common Voice and
LibriSpeech datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ControversialQA: Exploring Controversy in Question Answering. (arXiv:2302.05061v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05061">
<div class="article-summary-box-inner">
<span><p>Controversy is widespread online. Previous studies mainly define controversy
based on vague assumptions of its relation to sentiment such as hate speech and
offensive words. This paper introduces the first question-answering dataset
that defines content controversy by user perception, i.e., votes from plenty of
users. It contains nearly 10K questions, and each question has a best answer
and a most controversial answer. Experimental results reveal that controversy
detection in question answering is essential and challenging, and there is no
strong correlation between controversy and sentiment tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Selective In-Context Data Augmentation for Intent Detection using Pointwise V-Information. (arXiv:2302.05096v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05096">
<div class="article-summary-box-inner">
<span><p>This work focuses on in-context data augmentation for intent detection.
Having found that augmentation via in-context prompting of large pre-trained
language models (PLMs) alone does not improve performance, we introduce a novel
approach based on PLMs and pointwise V-information (PVI), a metric that can
measure the usefulness of a datapoint for training a model. Our method first
fine-tunes a PLM on a small seed of training data and then synthesizes new
datapoints - utterances that correspond to given intents. It then employs
intent-aware filtering, based on PVI, to remove datapoints that are not helpful
to the downstream intent classifier. Our method is thus able to leverage the
expressive power of large language models to produce diverse training data.
Empirical results demonstrate that our method can produce synthetic training
data that achieve state-of-the-art performance on three challenging intent
detection datasets under few-shot settings (1.28% absolute improvement in
5-shot and 1.18% absolute in 10-shot, on average) and perform on par with the
state-of-the-art in full-shot settings (within 0.01% absolute, on average).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Corpora Spoken Language Identification with Domain Diversification and Generalization. (arXiv:2302.05110v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05110">
<div class="article-summary-box-inner">
<span><p>This work addresses the cross-corpora generalization issue for the
low-resourced spoken language identification (LID) problem. We have conducted
the experiments in the context of Indian LID and identified strikingly poor
cross-corpora generalization due to corpora-dependent non-lingual biases. Our
contribution to this work is twofold. First, we propose domain diversification,
which diversifies the limited training data using different audio data
augmentation methods. We then propose the concept of maximally diversity-aware
cascaded augmentations and optimize the augmentation fold-factor for effective
diversification of the training data. Second, we introduce the idea of domain
generalization considering the augmentation methods as pseudo-domains. Towards
this, we investigate both domain-invariant and domain-aware approaches. Our LID
system is based on the state-of-the-art emphasized channel attention,
propagation, and aggregation based time delay neural network (ECAPA-TDNN)
architecture. We have conducted extensive experiments with three widely used
corpora for Indian LID research. In addition, we conduct a final blind
evaluation of our proposed methods on the Indian subset of VoxLingua107 corpus
collected in the wild. Our experiments demonstrate that the proposed domain
diversification is more promising over commonly used simple augmentation
methods. The study also reveals that domain generalization is a more effective
solution than domain diversification. We also notice that domain-aware learning
performs better for same-corpora LID, whereas domain-invariant learning is more
suitable for cross-corpora generalization. Compared to basic ECAPA-TDNN, its
proposed domain-invariant extensions improve the cross-corpora EER up to 5.23%.
In contrast, the proposed domain-aware extensions also improve performance for
same-corpora test scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Step by Step Loss Goes Very Far: Multi-Step Quantization for Adversarial Text Attacks. (arXiv:2302.05120v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05120">
<div class="article-summary-box-inner">
<span><p>We propose a novel gradient-based attack against transformer-based language
models that searches for an adversarial example in a continuous space of token
probabilities. Our algorithm mitigates the gap between adversarial loss for
continuous and discrete text representations by performing multi-step
quantization in a quantization-compensation loop. Experiments show that our
method significantly outperforms other approaches on various natural language
processing (NLP) tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Translating Natural Language to Planning Goals with Large-Language Models. (arXiv:2302.05128v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05128">
<div class="article-summary-box-inner">
<span><p>Recent large language models (LLMs) have demonstrated remarkable performance
on a variety of natural language processing (NLP) tasks, leading to intense
excitement about their applicability across various domains. Unfortunately,
recent work has also shown that LLMs are unable to perform accurate reasoning
nor solve planning problems, which may limit their usefulness for
robotics-related tasks. In this work, our central question is whether LLMs are
able to translate goals specified in natural language to a structured planning
language. If so, LLM can act as a natural interface between the planner and
human users; the translated goal can be handed to domain-independent AI
planners that are very effective at planning. Our empirical results on GPT 3.5
variants show that LLMs are much better suited towards translation rather than
planning. We find that LLMs are able to leverage commonsense knowledge and
reasoning to furnish missing details from under-specified goals (as is often
the case in natural language). However, our experiments also reveal that LLMs
can fail to generate goals in tasks that involve numerical or physical (e.g.,
spatial) reasoning, and that LLMs are sensitive to the prompts used. As such,
these models are promising for translation to structured planning languages,
but care should be taken in their use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Realistic Conversational Question Answering with Answer Selection based on Calibrated Confidence and Uncertainty Measurement. (arXiv:2302.05137v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05137">
<div class="article-summary-box-inner">
<span><p>Conversational Question Answering (ConvQA) models aim at answering a question
with its relevant paragraph and previous question-answer pairs that occurred
during conversation multiple times. To apply such models to a real-world
scenario, some existing work uses predicted answers, instead of unavailable
ground-truth answers, as the conversation history for inference. However, since
these models usually predict wrong answers, using all the predictions without
filtering significantly hampers the model performance. To address this problem,
we propose to filter out inaccurate answers in the conversation history based
on their estimated confidences and uncertainties from the ConvQA model, without
making any architectural changes. Moreover, to make the confidence and
uncertainty values more reliable, we propose to further calibrate them, thereby
smoothing the model predictions. We validate our models, Answer Selection-based
realistic Conversation Question Answering, on two standard ConvQA datasets, and
the results show that our models significantly outperform relevant baselines.
Code is available at: https://github.com/starsuzi/AS-ConvQA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Plan-then-Seam: Towards Efficient Table-to-Text Generation. (arXiv:2302.05138v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05138">
<div class="article-summary-box-inner">
<span><p>Table-to-text generation aims at automatically generating text to help people
conveniently obtain salient information in tables. Recent works explicitly
decompose the generation process into content planning and surface generation
stages, employing two autoregressive networks for them respectively. However,
they are computationally expensive due to the non-parallelizable nature of
autoregressive decoding and the redundant parameters of two networks. In this
paper, we propose the first totally non-autoregressive table-to-text model
(Plan-then-Seam, PTS) that produces its outputs in parallel with one single
network. PTS firstly writes and calibrates one plan of the content to be
generated with a novel rethinking pointer predictor, and then takes the plan as
the context for seaming to decode the description. These two steps share
parameters and perform iteratively to capture token inter-dependency while
keeping parallel decoding. Experiments on two public benchmarks show that PTS
achieves 3.0~5.6 times speedup for inference time, reducing 50% parameters,
while maintaining as least comparable performance against strong two-stage
table-to-text competitors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Wisdom of Hindsight Makes Language Models Better Instruction Followers. (arXiv:2302.05206v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05206">
<div class="article-summary-box-inner">
<span><p>Reinforcement learning has seen wide success in finetuning large language
models to better align with instructions via human feedback. The so-called
algorithm, Reinforcement Learning with Human Feedback (RLHF) demonstrates
impressive performance on the GPT series models. However, the underlying
Reinforcement Learning (RL) algorithm is complex and requires an additional
training pipeline for reward and value networks. In this paper, we consider an
alternative approach: converting feedback to instruction by relabeling the
original one and training the model for better alignment in a supervised
manner. Such an algorithm doesn't require any additional parameters except for
the original language model and maximally reuses the pretraining pipeline. To
achieve this, we formulate instruction alignment problem for language models as
a goal-reaching problem in decision making. We propose Hindsight Instruction
Relabeling (HIR), a novel algorithm for aligning language models with
instructions. The resulting two-stage algorithm shed light to a family of
reward-free approaches that utilize the hindsightly relabeled instructions
based on feedback. We evaluate the performance of HIR extensively on 12
challenging BigBench reasoning tasks and show that HIR outperforms the baseline
algorithms and is comparable to or even surpasses supervised finetuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Song of Ice and Fire: Analyzing Textual Autotelic Agents in ScienceWorld. (arXiv:2302.05244v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05244">
<div class="article-summary-box-inner">
<span><p>Building open-ended agents that can autonomously discover a diversity of
behaviours is one of the long-standing goals of artificial intelligence. This
challenge can be studied in the framework of autotelic RL agents, i.e. agents
that learn by selecting and pursuing their own goals, self-organizing a
learning curriculum. Recent work identified language has a key dimension of
autotelic learning, in particular because it enables abstract goal sampling and
guidance from social peers for hindsight relabelling. Within this perspective,
we study the following open scientific questions: What is the impact of
hindsight feedback from a social peer (e.g. selective vs. exhaustive)? How can
the agent learn from very rare language goal examples in its experience replay?
How can multiple forms of exploration be combined, and take advantage of easier
goals as stepping stones to reach harder ones? To address these questions, we
use ScienceWorld, a textual environment with rich abstract and combinatorial
physics. We show the importance of selectivity from the social peer's feedback;
that experience replay needs to over-sample examples of rare goals; and that
following self-generated goal sequences where the agent's competence is
intermediate leads to significant improvements in final performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rumor Classification through a Multimodal Fusion Framework and Ensemble Learning. (arXiv:2302.05289v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05289">
<div class="article-summary-box-inner">
<span><p>The proliferation of rumors on social media has become a major concern due to
its ability to create a devastating impact. Manually assessing the veracity of
social media messages is a very time-consuming task that can be much helped by
machine learning. Most message veracity verification methods only exploit
textual contents and metadata. Very few take both textual and visual contents,
and more particularly images, into account. Moreover, prior works have used
many classical machine learning models to detect rumors. However, although
recent studies have proven the effectiveness of ensemble machine learning
approaches, such models have seldom been applied. Thus, in this paper, we
propose a set of advanced image features that are inspired from the field of
image quality assessment, and introduce the Multimodal fusiON framework to
assess message veracIty in social neTwORks (MONITOR), which exploits all
message features by exploring various machine learning models. Moreover, we
demonstrate the effectiveness of ensemble learning algorithms for rumor
detection by using five metalearning models. Eventually, we conduct extensive
experiments on two real-world datasets. Results show that MONITOR outperforms
state-of-the-art machine learning baselines and that ensemble models
significantly increase MONITOR's performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Span-based Named Entity Recognition by Generating and Compressing Information. (arXiv:2302.05392v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05392">
<div class="article-summary-box-inner">
<span><p>The information bottleneck (IB) principle has been proven effective in
various NLP applications. The existing work, however, only used either
generative or information compression models to improve the performance of the
target task. In this paper, we propose to combine the two types of IB models
into one system to enhance Named Entity Recognition (NER). For one type of IB
model, we incorporate two unsupervised generative components, span
reconstruction and synonym generation, into a span-based NER system. The span
reconstruction ensures that the contextualised span representation keeps the
span information, while the synonym generation makes synonyms have similar
representations even in different contexts. For the other type of IB model, we
add a supervised IB layer that performs information compression into the system
to preserve useful features for NER in the resulting span representations.
Experiments on five different corpora indicate that jointly training both
generative and information compression models can enhance the performance of
the baseline span-based NER system. Our source code is publicly available at
https://github.com/nguyennth/joint-ib-models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Transformer Language Models for Contextual Commonsense Inference. (arXiv:2302.05406v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05406">
<div class="article-summary-box-inner">
<span><p>Contextualized or discourse aware commonsense inference is the task of
generating coherent commonsense assertions (i.e., facts) from a given story,
and a particular sentence from that story. Some problems with the task are:
lack of controllability for topics of the inferred facts; lack of commonsense
knowledge during training; and, possibly, hallucinated or false facts. In this
work, we utilize a transformer model for this task and develop techniques to
address the aforementioned problems in the task. We control the inference by
introducing a new technique we call "hinting". Hinting is a kind of language
model prompting, that utilizes both hard prompts (specific words) and soft
prompts (virtual learnable templates). This serves as a control signal to
advise the language model "what to talk about". Next, we establish a
methodology for performing joint inference with multiple commonsense knowledge
bases. Joint inference of commonsense requires care, because it is imprecise
and the level of generality is more flexible. You want to be sure that the
results "still make sense" for the context. To this end, we align the textual
version of assertions from three knowledge graphs (ConceptNet, ATOMIC2020, and
GLUCOSE) with a story and a target sentence. This combination allows us to
train a single model to perform joint inference with multiple knowledge graphs.
We show experimental results for the three knowledge graphs on joint inference.
Our final contribution is exploring a GAN architecture that generates the
contextualized commonsense assertions and scores them as to their plausibility
through a discriminator. The result is an integrated system for contextual
commonsense inference in stories, that can controllably generate plausible
commonsense assertions, and takes advantage of joint inference between multiple
commonsense knowledge bases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer-based Language Model Fine-tuning Methods for COVID-19 Fake News Detection. (arXiv:2101.05509v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05509">
<div class="article-summary-box-inner">
<span><p>With the pandemic of COVID-19, relevant fake news is spreading all over the
sky throughout the social media. Believing in them without discrimination can
cause great trouble to people's life. However, universal language models may
perform weakly in these fake news detection for lack of large-scale annotated
data and sufficient semantic understanding of domain-specific knowledge. While
the model trained on corresponding corpora is also mediocre for insufficient
learning. In this paper, we propose a novel transformer-based language model
fine-tuning approach for these fake news detection. First, the token vocabulary
of individual model is expanded for the actual semantics of professional
phrases. Second, we adapt the heated-up softmax loss to distinguish the
hard-mining samples, which are common for fake news because of the
disambiguation of short text. Then, we involve adversarial training to improve
the model's robustness. Last, the predicted features extracted by universal
language model RoBERTa and domain-specific model CT-BERT are fused by one
multiple layer perception to integrate fine-grained and high-level specific
representations. Quantitative experimental results evaluated on existing
COVID-19 fake news dataset show its superior performances compared to the
state-of-the-art methods among various evaluation metrics. Furthermore, the
best weighted average F1 score achieves 99.02%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dive into Deep Learning. (arXiv:2106.11342v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11342">
<div class="article-summary-box-inner">
<span><p>This open-source book represents our attempt to make deep learning
approachable, teaching readers the concepts, the context, and the code. The
entire book is drafted in Jupyter notebooks, seamlessly integrating exposition
figures, math, and interactive examples with self-contained code. Our goal is
to offer a resource that could (i) be freely available for everyone; (ii) offer
sufficient technical depth to provide a starting point on the path to actually
becoming an applied machine learning scientist; (iii) include runnable code,
showing readers how to solve problems in practice; (iv) allow for rapid
updates, both by us and also by the community at large; (v) be complemented by
a forum for interactive discussion of technical details and to answer
questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Small-Text: Active Learning for Text Classification in Python. (arXiv:2107.10314v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10314">
<div class="article-summary-box-inner">
<span><p>We present small-text, an easy-to-use active learning library written in
Python, which offers pool-based active learning for single- and multi-label
text classification in Python. It features many pre-implemented
state-of-the-art query strategies, including some that leverage the GPU.
Standardized interfaces allow the combination of a variety of classifiers,
query strategies, and stopping criteria, facilitating a quick mix and match,
and enabling a rapid development of both active learning experiments and
applications. In order to make various classifiers and query strategies
accessible for active learning, small-text integrates several well-known
machine learning libraries, namely scikit-learn, PyTorch, and Hugging Face
transformers. The latter integrations are optionally installable extensions, so
GPUs can be used but are not required. The library is publicly available under
the MIT License at https://github.com/webis-de/small-text, in version 1.1.1 at
the time of writing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Development of an Extractive Clinical Question Answering Dataset with Multi-Answer and Multi-Focus Questions. (arXiv:2201.02517v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02517">
<div class="article-summary-box-inner">
<span><p>Background: Extractive question-answering (EQA) is a useful natural language
processing (NLP) application for answering patient-specific questions by
locating answers in their clinical notes. Realistic clinical EQA can have
multiple answers to a single question and multiple focus points in one
question, which are lacking in the existing datasets for development of
artificial intelligence solutions. Objective: Create a dataset for developing
and evaluating clinical EQA systems that can handle natural multi-answer and
multi-focus questions. Methods: We leveraged the annotated relations from the
2018 National NLP Clinical Challenges (n2c2) corpus to generate an EQA dataset.
Specifically, the 1-to-N, M-to-1, and M-to-N drug-reason relations were
included to form the multi-answer and multi-focus QA entries, which represent
more complex and natural challenges in addition to the basic
one-drug-one-reason cases. A baseline solution was developed and tested on the
dataset. Results: The derived RxWhyQA dataset contains 96,939 QA entries. Among
the answerable questions, 25% require multiple answers, and 2% ask about
multiple drugs within one question. There are frequent cues observed around the
answers in the text, and 90% of the drug and reason terms occur within the same
or an adjacent sentence. The baseline EQA solution achieved a best f1-measure
of 0.72 on the entire dataset, and on specific subsets, it was: 0.93 on the
unanswerable questions, 0.48 on single-drug questions versus 0.60 on multi-drug
questions, 0.54 on the single-answer questions versus 0.43 on multi-answer
questions. Discussion: The RxWhyQA dataset can be used to train and evaluate
systems that need to handle multi-answer and multi-focus questions.
Specifically, multi-answer EQA appears to be challenging and therefore warrants
more investment in research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Should You Mask 15% in Masked Language Modeling?. (arXiv:2202.08005v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.08005">
<div class="article-summary-box-inner">
<span><p>Masked language models (MLMs) conventionally mask 15% of tokens due to the
belief that more masking would leave insufficient context to learn good
representations; this masking rate has been widely used, regardless of model
sizes or masking strategies. In this work, we revisit this important choice of
MLM pre-training. We first establish that 15% is not universally optimal, and
larger models should adopt a higher masking rate. Specifically, we find that
masking 40% outperforms 15% for BERT-large size models on GLUE and SQuAD.
Interestingly, an extremely high masking rate of 80% can still preserve 95%
fine-tuning performance and most of the accuracy in linguistic probing,
challenging the conventional wisdom about the role of the masking rate. We then
examine the interplay between masking rates and masking strategies and find
that uniform masking requires a higher masking rate compared to sophisticated
masking strategies such as span or PMI masking. Finally, we argue that
increasing the masking rate has two distinct effects: it leads to more
corruption, which makes the prediction task more difficult; it also enables
more predictions, which benefits optimization. Using this framework, we revisit
BERT's 80-10-10 corruption strategy. Together, our results contribute to a
better understanding of MLM pre-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relation Extraction with Weighted Contrastive Pre-training on Distant Supervision. (arXiv:2205.08770v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08770">
<div class="article-summary-box-inner">
<span><p>Contrastive pre-training on distant supervision has shown remarkable
effectiveness in improving supervised relation extraction tasks. However, the
existing methods ignore the intrinsic noise of distant supervision during the
pre-training stage. In this paper, we propose a weighted contrastive learning
method by leveraging the supervised data to estimate the reliability of
pre-training instances and explicitly reduce the effect of noise. Experimental
results on three supervised datasets demonstrate the advantages of our proposed
weighted contrastive learning approach compared to two state-of-the-art
non-weighted baselines.Our code and models are available at:
https://github.com/YukinoWan/WCL
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Normalization of Temporal Expressions with Masked Language Models. (arXiv:2205.10399v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10399">
<div class="article-summary-box-inner">
<span><p>The detection and normalization of temporal expressions is an important task
and preprocessing step for many applications. However, prior work on
normalization is rule-based, which severely limits the applicability in
real-world multilingual settings, due to the costly creation of new rules. We
propose a novel neural method for normalizing temporal expressions based on
masked language modeling. Our multilingual method outperforms prior rule-based
systems in many languages, and in particular, for low-resource languages with
performance improvements of up to 33 F1 on average compared to the state of the
art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LingMess: Linguistically Informed Multi Expert Scorers for Coreference Resolution. (arXiv:2205.12644v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12644">
<div class="article-summary-box-inner">
<span><p>While coreference resolution typically involves various linguistic
challenges, recent models are based on a single pairwise scorer for all types
of pairs. We present LingMess, a new coreference model that defines different
categories of coreference cases and optimize multiple pairwise scorers, where
each scorer learns a specific set of linguistic challenges. Our model
substantially improves pairwise scores for most categories and outperforms
cluster-level performance on Ontonotes and 5 additional datasets. Our model is
available in https://github.com/shon-otmazgin/lingmess-coref
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PROD: Progressive Distillation for Dense Retrieval. (arXiv:2209.13335v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.13335">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation is an effective way to transfer knowledge from a
strong teacher to an efficient student model. Ideally, we expect the better the
teacher is, the better the student. However, this expectation does not always
come true. It is common that a better teacher model results in a bad student
via distillation due to the nonnegligible gap between teacher and student. To
bridge the gap, we propose PROD, a PROgressive Distillation method, for dense
retrieval. PROD consists of a teacher progressive distillation and a data
progressive distillation to gradually improve the student. We conduct extensive
experiments on five widely-used benchmarks, MS MARCO Passage, TREC Passage 19,
TREC Document 19, MS MARCO Document and Natural Questions, where PROD achieves
the state-of-the-art within the distillation methods for dense retrieval. The
code and models will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PLOT: Prompt Learning with Optimal Transport for Vision-Language Models. (arXiv:2210.01253v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.01253">
<div class="article-summary-box-inner">
<span><p>With the increasing attention to large vision-language models such as CLIP,
there has been a significant amount of effort dedicated to building efficient
prompts. Unlike conventional methods of only learning one single prompt, we
propose to learn multiple comprehensive prompts to describe diverse
characteristics of categories such as intrinsic attributes or extrinsic
contexts. However, directly matching each prompt to the same visual feature is
problematic, as it pushes the prompts to converge to one point. To solve this
problem, we propose to apply optimal transport to match the vision and text
modalities. Specifically, we first model images and the categories with visual
and textual feature sets. Then, we apply a two-stage optimization strategy to
learn the prompts. In the inner loop, we optimize the optimal transport
distance to align visual features and prompts by the Sinkhorn algorithm, while
in the outer loop, we learn the prompts by this distance from the supervised
data. Extensive experiments are conducted on the few-shot recognition task and
the improvement demonstrates the superiority of our method. The code is
available at https://github.com/CHENGY12/PLOT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Designing Robust Transformers using Robust Kernel Density Estimation. (arXiv:2210.05794v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.05794">
<div class="article-summary-box-inner">
<span><p>Recent advances in Transformer architectures have empowered their empirical
success in a variety of tasks across different domains. However, existing works
mainly focus on predictive accuracy and computational cost, without considering
other practical issues, such as robustness to contaminated samples. Recent work
by Nguyen et al., (2022) has shown that the self-attention mechanism, which is
the center of the Transformer architecture, can be viewed as a non-parametric
estimator based on kernel density estimation (KDE). This motivates us to
leverage a set of robust kernel density estimation methods for alleviating the
issue of data contamination. Specifically, we introduce a series of
self-attention mechanisms that can be incorporated into different Transformer
architectures and discuss the special properties of each method. We then
perform extensive empirical studies on language modeling and image
classification tasks. Our methods demonstrate robust performance in multiple
scenarios while maintaining competitive results on clean datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incorporating Context into Subword Vocabularies. (arXiv:2210.07095v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07095">
<div class="article-summary-box-inner">
<span><p>Most current popular subword tokenizers are trained based on word frequency
statistics over a corpus, without considering information about co-occurrence
or context. Nevertheless, the resulting vocabularies are used in language
models' highly contextualized settings. We present SaGe, a tokenizer that
tailors subwords for their downstream use by baking in the contextualized
signal at the vocabulary creation phase. We show that SaGe does a better job
than current widespread tokenizers in keeping token contexts cohesive, while
not incurring a large price in terms of encoding efficiency or domain
robustness. SaGe improves performance on English GLUE classification tasks as
well as on NER, and on Inference and NER in Turkish, demonstrating its
robustness to language properties such as morphological exponence and
agglutination.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Watermarking Pre-trained Language Models with Backdooring. (arXiv:2210.07543v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07543">
<div class="article-summary-box-inner">
<span><p>Large pre-trained language models (PLMs) have proven to be a crucial
component of modern natural language processing systems. PLMs typically need to
be fine-tuned on task-specific downstream datasets, which makes it hard to
claim the ownership of PLMs and protect the developer's intellectual property
due to the catastrophic forgetting phenomenon. We show that PLMs can be
watermarked with a multi-task learning framework by embedding backdoors
triggered by specific inputs defined by the owners, and those watermarks are
hard to remove even though the watermarked PLMs are fine-tuned on multiple
downstream tasks. In addition to using some rare words as triggers, we also
show that the combination of common words can be used as backdoor triggers to
avoid them being easily detected. Extensive experiments on multiple datasets
demonstrate that the embedded watermarks can be robustly extracted with a high
success rate and less influenced by the follow-up fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Plausible May Not Be Faithful: Probing Object Hallucination in Vision-Language Pre-training. (arXiv:2210.07688v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07688">
<div class="article-summary-box-inner">
<span><p>Large-scale vision-language pre-trained (VLP) models are prone to hallucinate
non-existent visual objects when generating text based on visual information.
In this paper, we systematically study the object hallucination problem from
three aspects. First, we examine recent state-of-the-art VLP models, showing
that they still hallucinate frequently, and models achieving better scores on
standard metrics (e.g., CIDEr) could be more unfaithful. Second, we investigate
how different types of image encoding in VLP influence hallucination, including
region-based, grid-based, and patch-based. Surprisingly, we find that
patch-based features perform the best and smaller patch resolution yields a
non-trivial reduction in object hallucination. Third, we decouple various VLP
objectives and demonstrate that token-level image-text alignment and controlled
generation are crucial to reducing hallucination. Based on that, we propose a
simple yet effective VLP loss named ObjMLM to further mitigate object
hallucination. Results show that it reduces object hallucination by up to 17.4%
when tested on two benchmarks (COCO Caption for in-domain and NoCaps for
out-of-domain evaluation).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From exemplar to copy: the scribal appropriation of a Hadewijch manuscript computationally explored. (arXiv:2210.14061v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.14061">
<div class="article-summary-box-inner">
<span><p>This study is devoted to two of the oldest known manuscripts in which the
oeuvre of the medieval mystical author Hadewijch has been preserved: Brussels,
KBR, 2879-2880 (ms. A) and Brussels, KBR, 2877-2878 (ms. B). On the basis of
codicological and contextual arguments, it is assumed that the scribe who
produced B used A as an exemplar. While the similarities in both layout and
content between the two manuscripts are striking, the present article seeks to
identify the differences. After all, regardless of the intention to produce a
copy that closely follows the exemplar, subtle linguistic variation is
apparent. Divergences relate to spelling conventions, but also to the way in
which words are abbreviated (and the extent to which abbreviations occur). The
present study investigates the spelling profiles of the scribes who produced
mss. A and B in a computational way. In the first part of this study, we will
present both manuscripts in more detail, after which we will consider prior
research carried out on scribal profiling. The current study both builds and
expands on Kestemont (2015). Next, we outline the methodology used to analyse
and measure the degree of scribal appropriation that took place when ms. B was
copied off the exemplar ms. A. After this, we will discuss the results
obtained, focusing on the scribal variation that can be found both at the level
of individual words and n-grams. To this end, we use machine learning to
identify the most distinctive features that separate manuscript A from B.
Finally, we look at possible diachronic trends in the appropriation by B's
scribe of his exemplar. We argue that scribal takeovers in the exemplar impacts
the practice of the copying scribe, while transitions to a different content
matter cause little to no effect.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards human-compatible autonomous car: A study of non-verbal Turing test in automated driving with affective transition modelling. (arXiv:2212.02908v4 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02908">
<div class="article-summary-box-inner">
<span><p>Autonomous cars are indispensable when humans go further down the hands-free
route. Although existing literature highlights that the acceptance of the
autonomous car will increase if it drives in a human-like manner, sparse
research offers the naturalistic experience from a passenger's seat perspective
to examine the human likeness of current autonomous cars. The present study
tested whether the AI driver could create a human-like ride experience for
passengers based on 69 participants' feedback in a real-road scenario. We
designed a ride experience-based version of the non-verbal Turing test for
automated driving. Participants rode in autonomous cars (driven by either human
or AI drivers) as a passenger and judged whether the driver was human or AI.
The AI driver failed to pass our test because passengers detected the AI driver
above chance. In contrast, when the human driver drove the car, the passengers'
judgement was around chance. We further investigated how human passengers
ascribe humanness in our test. Based on Lewin's field theory, we advanced a
computational model combining signal detection theory with pre-trained language
models to predict passengers' humanness rating behaviour. We employed affective
transition between pre-study baseline emotions and corresponding post-stage
emotions as the signal strength of our model. Results showed that the
passengers' ascription of humanness would increase with the greater affective
transition. Our study suggested an important role of affective transition in
passengers' ascription of humanness, which might become a future direction for
autonomous driving.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sequence Generation with Label Augmentation for Relation Extraction. (arXiv:2212.14266v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.14266">
<div class="article-summary-box-inner">
<span><p>Sequence generation demonstrates promising performance in recent information
extraction efforts, by incorporating large-scale pre-trained Seq2Seq models.
This paper investigates the merits of employing sequence generation in relation
extraction, finding that with relation names or synonyms as generation targets,
their textual semantics and the correlation (in terms of word sequence pattern)
among them affect model performance. We then propose Relation Extraction with
Label Augmentation (RELA), a Seq2Seq model with automatic label augmentation
for RE. By saying label augmentation, we mean prod semantically synonyms for
each relation name as the generation target. Besides, we present an in-depth
analysis of the Seq2Seq model's behavior when dealing with RE. Experimental
results show that RELA achieves competitive results compared with previous
methods on four RE datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">tasksource: Structured Dataset Preprocessing Annotations for Frictionless Extreme Multi-Task Learning and Evaluation. (arXiv:2301.05948v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.05948">
<div class="article-summary-box-inner">
<span><p>The HuggingFace Datasets Hub hosts thousands of datasets. This provides
exciting opportunities for language model training and evaluation. However, the
datasets for a given type of task are stored with different schemas, and
harmonization is harder than it seems (https://xkcd.com/927/). Multi-task
training or evaluation requires manual work to fit data into task templates.
Various initiatives independently address this problem by releasing the
harmonized datasets or harmonization codes to preprocess datasets to the same
format. We identify patterns across previous preprocessings, e.g. mapping of
column names, and extraction of a specific sub-field from structured data in a
column, and propose a structured annotation framework that makes our
annotations fully exposed and not buried in unstructured code. We release a
dataset annotation framework and dataset annotations for more than 400 English
tasks (https://github.com/sileod/tasksource). These annotations provide
metadata, like the name of the columns that should be used as input or labels
for all datasets, and can save time for future dataset preprocessings, even if
they do not use our framework. We fine-tune a multi-task text encoder on all
tasksource tasks, outperforming every publicly available text encoder of
comparable size on an external evaluation
https://hf.co/sileod/deberta-v3-base-tasksource-nli.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Noisy Parallel Data Alignment. (arXiv:2301.09685v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09685">
<div class="article-summary-box-inner">
<span><p>An ongoing challenge in current natural language processing is how its major
advancements tend to disproportionately favor resource-rich languages, leaving
a significant number of under-resourced languages behind. Due to the lack of
resources required to train and evaluate models, most modern language
technologies are either nonexistent or unreliable to process endangered, local,
and non-standardized languages. Optical character recognition (OCR) is often
used to convert endangered language documents into machine-readable data.
However, such OCR output is typically noisy, and most word alignment models are
not built to work under such noisy conditions. In this work, we study the
existing word-level alignment models under noisy settings and aim to make them
more robust to noisy data. Our noise simulation and structural biasing method,
tested on multiple language pairs, manages to reduce the alignment error rate
on a state-of-the-art neural-based alignment model up to 59.6%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ViDeBERTa: A powerful pre-trained language model for Vietnamese. (arXiv:2301.10439v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10439">
<div class="article-summary-box-inner">
<span><p>This paper presents ViDeBERTa, a new pre-trained monolingual language model
for Vietnamese, with three versions - ViDeBERTa_xsmall, ViDeBERTa_base, and
ViDeBERTa_large, which are pre-trained on a large-scale corpus of high-quality
and diverse Vietnamese texts using DeBERTa architecture. Although many
successful pre-trained language models based on Transformer have been widely
proposed for the English language, there are still few pre-trained models for
Vietnamese, a low-resource language, that perform good results on downstream
tasks, especially Question answering. We fine-tune and evaluate our model on
three important natural language downstream tasks, Part-of-speech tagging,
Named-entity recognition, and Question answering. The empirical results
demonstrate that ViDeBERTa with far fewer parameters surpasses the previous
state-of-the-art models on multiple Vietnamese-specific natural language
understanding tasks. Notably, ViDeBERTa_base with 86M parameters, which is only
about 23% of PhoBERT_large with 370M parameters, still performs the same or
better results than the previous state-of-the-art model. Our ViDeBERTa models
are available at: https://github.com/HySonLab/ViDeBERTa.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-shot Clarifying Question Generation for Conversational Search. (arXiv:2301.12660v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.12660">
<div class="article-summary-box-inner">
<span><p>A long-standing challenge for search and conversational assistants is query
intention detection in ambiguous queries. Asking clarifying questions in
conversational search has been widely studied and considered an effective
solution to resolve query ambiguity. Existing work have explored various
approaches for clarifying question ranking and generation. However, due to the
lack of real conversational search data, they have to use artificial datasets
for training, which limits their generalizability to real-world search
scenarios. As a result, the industry has shown reluctance to implement them in
reality, further suspending the availability of real conversational search
interaction data. The above dilemma can be formulated as a cold start problem
of clarifying question generation and conversational search in general.
Furthermore, even if we do have large-scale conversational logs, it is not
realistic to gather training data that can comprehensively cover all possible
queries and topics in open-domain search scenarios. The risk of fitting bias
when training a clarifying question retrieval/generation model on
incomprehensive dataset is thus another important challenge.
</p>
<p>In this work, we innovatively explore generating clarifying questions in a
zero-shot setting to overcome the cold start problem and we propose a
constrained clarifying question generation system which uses both question
templates and query facets to guide the effective and precise question
generation. The experiment results show that our method outperforms existing
state-of-the-art zero-shot baselines by a large margin. Human annotations to
our model outputs also indicate our method generates 25.2\% more natural
questions, 18.1\% more useful questions, 6.1\% less unnatural and 4\% less
useless questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continual Learning of Language Models. (arXiv:2302.03241v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03241">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) have been instrumental for the rapid advance of natural
language processing. This paper studies continual learning of LMs, in
particular, continual domain-adaptive pre-training (or continual DAP-training).
Existing research has shown that further pre-training an LM using a domain
corpus to adapt the LM to the domain can improve the end-task performance in
the domain. This paper proposes a novel method to continually DAP-train an LM
with a sequence of unlabeled domain corpora to adapt the LM to these domains to
improve their end-task performances. The key novelty of our method is a
soft-masking mechanism that directly controls the update to the LM. A novel
proxy is also proposed to preserve the general knowledge in the original LM.
Additionally, it contrasts the representations of the previously learned domain
knowledge (including the general knowledge in the pre-trained LM) and the
knowledge from the current full network to achieve knowledge integration. The
method not only overcomes catastrophic forgetting, but also achieves knowledge
transfer to improve end-task performances. Empirical evaluation demonstrates
the effectiveness of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Categorical Archive of ChatGPT Failures. (arXiv:2302.03494v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03494">
<div class="article-summary-box-inner">
<span><p>Large language models have been demonstrated to be valuable in different
fields. ChatGPT, developed by OpenAI, has been trained using massive amounts of
data and simulates human conversation by comprehending context and generating
appropriate responses. It has garnered significant attention due to its ability
to effectively answer a broad range of human inquiries, with fluent and
comprehensive answers surpassing prior public chatbots in both security and
usefulness. However, a comprehensive analysis of ChatGPT's failures is lacking,
which is the focus of this study. Ten categories of failures, including
reasoning, factual errors, math, coding, and bias, are presented and discussed.
The risks, limitations, and societal implications of ChatGPT are also
highlighted. The goal of this study is to assist researchers and developers in
enhancing future language models and chatbots.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reliable Natural Language Understanding with Large Language Models and Answer Set Programming. (arXiv:2302.03780v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03780">
<div class="article-summary-box-inner">
<span><p>Humans understand language by extracting information (meaning) from
sentences, combining it with existing commonsense knowledge, and then
performing reasoning to draw conclusions. While large language models (LLMs)
such as GPT-3 and ChatGPT are able to leverage patterns in the text to solve a
variety of NLP tasks, they fall short in problems that require reasoning. They
also cannot reliably explain the answers generated for a given question. In
order to emulate humans better, we propose STAR, a framework that combines LLMs
with Answer Set Programming (ASP). We show how LLMs can be used to effectively
extract knowledge -- represented as predicates -- from language. Goal-directed
ASP is then employed to reliably reason over this knowledge. We apply the STAR
framework to three different NLU tasks requiring reasoning: qualitative
reasoning, mathematical reasoning, and goal-directed conversation. Our
experiments reveal that STAR is able to bridge the gap of reasoning in NLU
tasks, leading to significant performance improvements, especially for smaller
LLMs, i.e., LLMs with a smaller number of parameters. NLU applications
developed using the STAR framework are also explainable: along with the
predicates generated, a justification in the form of a proof tree can be
produced for a given output.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04054">
<div class="article-summary-box-inner">
<span><p>Reliability of machine learning evaluation -- the consistency of observed
evaluation scores across replicated model training runs -- is affected by
several sources of nondeterminism which can be regarded as measurement noise.
Current tendencies to remove noise in order to enforce reproducibility of
research results neglect inherent nondeterminism at the implementation level
and disregard crucial interaction effects between algorithmic noise factors and
data properties. This limits the scope of conclusions that can be drawn from
such experiments. Instead of removing noise, we propose to incorporate several
sources of variance, including their interaction with data properties, into an
analysis of significance and reliability of machine learning evaluation, with
the aim to draw inferences beyond particular instances of trained models. We
show how to use linear mixed effects models (LMEMs) to analyze performance
evaluation scores, and to conduct statistical inference with a generalized
likelihood ratio test (GLRT). This allows us to incorporate arbitrary sources
of noise like meta-parameter variations into statistical significance testing,
and to assess performance differences conditional on data properties.
Furthermore, a variance component analysis (VCA) enables the analysis of the
contribution of noise sources to overall variance and the computation of a
reliability coefficient by the ratio of substantial to total variance.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-02-13 23:13:07.328318779 UTC">2023-02-13 23:13:07 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>