<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-06-16T01:30:00Z">06-16</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Utilizing Social Media Attributes for Enhanced Keyword Detection: An IDF-LDA Model Applied to Sina Weibo. (arXiv:2306.07978v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.07978">
<div class="article-summary-box-inner">
<span><p>With the rapid development of social media such as Twitter and Weibo,
detecting keywords from a huge volume of text data streams in real-time has
become a critical problem. The keyword detection problem aims at searching
important information from massive text data to reflect the most important
events or topics. However, social media data usually has unique features: the
documents are usually short, the language is colloquial, and the data is likely
to have significant temporal patterns. Therefore, it could be challenging to
discover critical information from these text streams. In this paper, we
propose a novel method to address the keyword detection problem in social
media. Our model combines the Inverse Document Frequency (IDF) and Latent
Dirichlet Allocation (LDA) models to better cope with the distinct attributes
of social media data, such as the number of likes, comments, and retweets. By
weighting the importance of each document based on these attributes, our method
can effectively detect more representative keywords over time. Comprehensive
experiments conducted under various conditions on Weibo data illustrate that
our approach outperforms the baselines in various evaluation metrics, including
precision and recall for multiple problem settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MSSRNet: Manipulating Sequential Style Representation for Unsupervised Text Style Transfer. (arXiv:2306.07994v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.07994">
<div class="article-summary-box-inner">
<span><p>Unsupervised text style transfer task aims to rewrite a text into target
style while preserving its main content. Traditional methods rely on the use of
a fixed-sized vector to regulate text style, which is difficult to accurately
convey the style strength for each individual token. In fact, each token of a
text contains different style intensity and makes different contribution to the
overall style. Our proposed method addresses this issue by assigning individual
style vector to each token in a text, allowing for fine-grained control and
manipulation of the style strength. Additionally, an adversarial training
framework integrated with teacher-student learning is introduced to enhance
training stability and reduce the complexity of high-dimensional optimization.
The results of our experiments demonstrate the efficacy of our method in terms
of clearly improved style transfer accuracy and content preservation in both
two-style transfer and multi-style transfer settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Zero-Shot Detection of Low Prevalence Chest Pathologies using Domain Pre-trained Language Models. (arXiv:2306.08000v1 [physics.med-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08000">
<div class="article-summary-box-inner">
<span><p>Recent advances in zero-shot learning have enabled the use of paired
image-text data to replace structured labels, replacing the need for expert
annotated datasets. Models such as CLIP-based CheXzero utilize these
advancements in the domain of chest X-ray interpretation. We hypothesize that
domain pre-trained models such as CXR-BERT, BlueBERT, and ClinicalBERT offer
the potential to improve the performance of CLIP-like models with specific
domain knowledge by replacing BERT weights at the cost of breaking the original
model's alignment. We evaluate the performance of zero-shot classification
models with domain-specific pre-training for detecting low-prevalence
pathologies. Even though replacing the weights of the original CLIP-BERT
degrades model performance on commonly found pathologies, we show that
pre-trained text towers perform exceptionally better on low-prevalence
diseases. This motivates future ensemble models with a combination of
differently trained language models for maximal performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Scheme to classify Read and Spontaneous Speech. (arXiv:2306.08012v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08012">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic has led to an increased use of remote telephonic
interviews, making it important to distinguish between scripted and spontaneous
speech in audio recordings. In this paper, we propose a novel scheme for
identifying read and spontaneous speech. Our approach uses a pre-trained
DeepSpeech audio-to-alphabet recognition engine to generate a sequence of
alphabets from the audio. From these alphabets, we derive features that allow
us to discriminate between read and spontaneous speech. Our experimental
results show that even a small set of self-explanatory features can effectively
classify the two types of speech very effectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models. (arXiv:2306.08018v1 [q-bio.QM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08018">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs), with their remarkable task-handling
capabilities and innovative outputs, have catalyzed significant advancements
across a spectrum of fields. However, their proficiency within specialized
domains such as biomolecular studies remains limited. To address this
challenge, we introduce Mol-Instructions, a meticulously curated, comprehensive
instruction dataset expressly designed for the biomolecular realm.
Mol-Instructions is composed of three pivotal components: molecule-oriented
instructions, protein-oriented instructions, and biomolecular text
instructions, each curated to enhance the understanding and prediction
capabilities of LLMs concerning biomolecular features and behaviors. Through
extensive instruction tuning experiments on the representative LLM, we
underscore the potency of Mol-Instructions to enhance the adaptability and
cognitive acuity of large models within the complex sphere of biomolecular
studies, thereby promoting advancements in the biomolecular research community.
Mol-Instructions is made publicly accessible for future research endeavors and
will be subjected to continual updates for enhanced applicability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Curatr: A Platform for Semantic Analysis and Curation of Historical Literary Texts. (arXiv:2306.08020v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08020">
<div class="article-summary-box-inner">
<span><p>The increasing availability of digital collections of historical and
contemporary literature presents a wealth of possibilities for new research in
the humanities. The scale and diversity of such collections however, presents
particular challenges in identifying and extracting relevant content. This
paper presents Curatr, an online platform for the exploration and curation of
literature with machine learning-supported semantic search, designed within the
context of digital humanities scholarship. The platform provides a text mining
workflow that combines neural word embeddings with expert domain knowledge to
enable the generation of thematic lexicons, allowing researches to curate
relevant sub-corpora from a large corpus of 18th and 19th century digitised
texts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FLamE: Few-shot Learning from Natural Language Explanations. (arXiv:2306.08042v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08042">
<div class="article-summary-box-inner">
<span><p>Natural language explanations have the potential to provide rich information
that in principle guides model reasoning. Yet, recent work by Lampinen et al.
(2022) has shown limited utility of natural language explanations in improving
classification. To effectively learn from explanations, we present FLamE, a
two-stage few-shot learning framework that first generates explanations using
GPT-3, and then finetunes a smaller model (e.g., RoBERTa) with generated
explanations. Our experiments on natural language inference demonstrate
effectiveness over strong baselines, increasing accuracy by 17.6% over GPT-3
Babbage and 5.7% over GPT-3 Davinci in e-SNLI. Despite improving classification
performance, human evaluation surprisingly reveals that the majority of
generated explanations does not adequately justify classification decisions.
Additional analyses point to the important role of label-specific cues (e.g.,
"not know" for the neutral label) in generated explanations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AutoML in the Age of Large Language Models: Current Challenges, Future Opportunities and Risks. (arXiv:2306.08107v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08107">
<div class="article-summary-box-inner">
<span><p>The fields of both Natural Language Processing (NLP) and Automated Machine
Learning (AutoML) have achieved remarkable results over the past years. In NLP,
especially Large Language Models (LLMs) have experienced a rapid series of
breakthroughs very recently. We envision that the two fields can radically push
the boundaries of each other through tight integration. To showcase this
vision, we explore the potential of a symbiotic relationship between AutoML and
LLMs, shedding light on how they can benefit each other. In particular, we
investigate both the opportunities to enhance AutoML approaches with LLMs from
different perspectives and the challenges of leveraging AutoML to further
improve LLMs. To this end, we survey existing work, and we critically assess
risks. We strongly believe that the integration of the two fields has the
potential to disrupt both fields, NLP and AutoML. By highlighting conceivable
synergies, but also risks, we aim to foster further exploration at the
intersection of AutoML and LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CipherSniffer: Classifying Cipher Types. (arXiv:2306.08116v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08116">
<div class="article-summary-box-inner">
<span><p>Ciphers are a powerful tool for encrypting communication. There are many
different cipher types, which makes it computationally expensive to solve a
cipher using brute force. In this paper, we frame the decryption task as a
classification problem. We first create a dataset of transpositions,
substitutions, text reversals, word reversals, sentence shifts, and unencrypted
text. Then, we evaluate the performance of various tokenizer-model combinations
on this task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Black Box AI-Generated Plagiarism Detection: From Sentence to Document Level. (arXiv:2306.08122v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08122">
<div class="article-summary-box-inner">
<span><p>The increasing reliance on large language models (LLMs) in academic writing
has led to a rise in plagiarism. Existing AI-generated text classifiers have
limited accuracy and often produce false positives. We propose a novel approach
using natural language processing (NLP) techniques, offering quantifiable
metrics at both sentence and document levels for easier interpretation by human
evaluators. Our method employs a multi-faceted approach, generating multiple
paraphrased versions of a given question and inputting them into the LLM to
generate answers. By using a contrastive loss function based on cosine
similarity, we match generated sentences with those from the student's
response. Our approach achieves up to 94% accuracy in classifying human and AI
text, providing a robust and adaptable solution for plagiarism detection in
academic settings. This method improves with LLM advancements, reducing the
need for new model training or reconfiguration, and offers a more transparent
way of evaluating and detecting AI-generated text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PersonaPKT: Building Personalized Dialogue Agents via Parameter-efficient Knowledge Transfer. (arXiv:2306.08126v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08126">
<div class="article-summary-box-inner">
<span><p>Personalized dialogue agents (DAs) powered by large pre-trained language
models (PLMs) often rely on explicit persona descriptions to maintain
personality consistency. However, such descriptions may not always be available
or may pose privacy concerns. To tackle this bottleneck, we introduce
PersonaPKT, a lightweight transfer learning approach that can build
persona-consistent dialogue models without explicit persona descriptions. By
representing each persona as a continuous vector, PersonaPKT learns implicit
persona-specific features directly from a small number of dialogue samples
produced by the same persona, adding less than 0.1% trainable parameters for
each persona on top of the PLM backbone. Empirical results demonstrate that
PersonaPKT effectively builds personalized DAs with high storage efficiency,
outperforming various baselines in terms of persona consistency while
maintaining good response generation quality. In addition, it enhances privacy
protection by avoiding explicit persona descriptions. Overall, PersonaPKT is an
effective solution for creating personalized DAs that respect user privacy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AVIS: Autonomous Visual Information Seeking with Large Language Models. (arXiv:2306.08129v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08129">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose an autonomous information seeking visual question
answering framework, AVIS. Our method leverages a Large Language Model (LLM) to
dynamically strategize the utilization of external tools and to investigate
their outputs, thereby acquiring the indispensable knowledge needed to provide
answers to the posed questions. Responding to visual questions that necessitate
external knowledge, such as "What event is commemorated by the building
depicted in this image?", is a complex task. This task presents a combinatorial
search space that demands a sequence of actions, including invoking APIs,
analyzing their responses, and making informed decisions. We conduct a user
study to collect a variety of instances of human decision-making when faced
with this task. This data is then used to design a system comprised of three
components: an LLM-powered planner that dynamically determines which tool to
use next, an LLM-powered reasoner that analyzes and extracts key information
from the tool outputs, and a working memory component that retains the acquired
information throughout the process. The collected user behavior serves as a
guide for our system in two key ways. First, we create a transition graph by
analyzing the sequence of decisions made by users. This graph delineates
distinct states and confines the set of actions available at each state.
Second, we use examples of user decision-making to provide our LLM-powered
planner and reasoner with relevant contextual instances, enhancing their
capacity to make informed decisions. We show that AVIS achieves
state-of-the-art results on knowledge-intensive visual question answering
benchmarks such as Infoseek and OK-VQA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large-scale Language Model Rescoring on Long-form Data. (arXiv:2306.08133v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08133">
<div class="article-summary-box-inner">
<span><p>In this work, we study the impact of Large-scale Language Models (LLM) on
Automated Speech Recognition (ASR) of YouTube videos, which we use as a source
for long-form ASR. We demonstrate up to 8\% relative reduction in Word Error
Eate (WER) on US English (en-us) and code-switched Indian English (en-in)
long-form ASR test sets and a reduction of up to 30\% relative on Salient Term
Error Rate (STER) over a strong first-pass baseline that uses a maximum-entropy
based language model. Improved lattice processing that results in a lattice
with a proper (non-tree) digraph topology and carrying context from the 1-best
hypothesis of the previous segment(s) results in significant wins in rescoring
with LLMs. We also find that the gains in performance from the combination of
LLMs trained on vast quantities of available data (such as C4) and conventional
neural LMs is additive and significantly outperforms a strong first-pass
baseline with a maximum entropy LM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey on Sociodemographic Bias in Natural Language Processing. (arXiv:2306.08158v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08158">
<div class="article-summary-box-inner">
<span><p>Deep neural networks often learn unintended biases during training, which
might have harmful effects when deployed in real-world settings. This paper
surveys 209 papers on bias in NLP models, most of which address
sociodemographic bias. To better understand the distinction between bias and
real-world harm, we turn to ideas from psychology and behavioral economics to
propose a definition for sociodemographic bias. We identify three main
categories of NLP bias research: types of bias, quantifying bias, and
debiasing. We conclude that current approaches on quantifying bias face
reliability issues, that many of the bias metrics do not relate to real-world
biases, and that current debiasing techniques are superficial and hide bias
rather than removing it. Finally, we provide recommendations for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">h2oGPT: Democratizing Large Language Models. (arXiv:2306.08161v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08161">
<div class="article-summary-box-inner">
<span><p>Foundation Large Language Models (LLMs) such as GPT-4 represent a revolution
in AI due to their real-world applications though natural language processing.
However, they also pose many significant risks such as the presence of biased,
private, or harmful text, and the unauthorized inclusion of copyrighted
material.
</p>
<p>We introduce h2oGPT, a suite of open-source code repositories for the
creation and use of Large Language Models (LLMs) based on Generative Pretrained
Transformers (GPTs). The goal of this project is to create the world's best
truly open-source alternative to closed-source GPTs. In collaboration with and
as part of the incredible and unstoppable open-source community, we open-source
several fine-tuned h2oGPT models from 7 to 40 Billion parameters, ready for
commercial use under fully permissive Apache 2.0 licenses. Included in our
release is 100% private document search using natural language.
</p>
<p>Open-source language models help boost AI development and make it more
accessible and trustworthy. They lower entry hurdles, allowing people and
groups to tailor these models to their needs. This openness increases
innovation, transparency, and fairness. An open-source strategy is needed to
share AI benefits fairly, and H2O.ai will continue to democratize AI and LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">INT2.1: Towards Fine-Tunable Quantized Large Language Models with Error Correction through Low-Rank Adaptation. (arXiv:2306.08162v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08162">
<div class="article-summary-box-inner">
<span><p>We introduce a method that dramatically reduces fine-tuning VRAM requirements
and rectifies quantization errors in quantized Large Language Models. First, we
develop an extremely memory-efficient fine-tuning (EMEF) method for quantized
models using Low-Rank Adaptation (LoRA), and drawing upon it, we construct an
error-correcting algorithm designed to minimize errors induced by the
quantization process. Our method reduces the memory requirements by up to 5.6
times, which enables fine-tuning a 7 billion parameter Large Language Model
(LLM) on consumer laptops. At the same time, we propose a Low-Rank Error
Correction (LREC) method that exploits the added LoRA layers to ameliorate the
gap between the quantized model and its float point counterpart. Our error
correction framework leads to a fully functional INT2 quantized LLM with the
capacity to generate coherent English text. To the best of our knowledge, this
is the first INT2 Large Language Model that has been able to reach such a
performance. The overhead of our method is merely a 1.05 times increase in
model size, which translates to an effective precision of INT2.1. Also, our
method readily generalizes to other quantization standards, such as INT3, INT4,
and INT8, restoring their lost performance, which marks a significant milestone
in the field of model quantization. The strategies delineated in this paper
hold promising implications for the future development and optimization of
quantized models, marking a pivotal shift in the landscape of low-resource
machine learning computations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language models are not naysayers: An analysis of language models on negation benchmarks. (arXiv:2306.08189v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08189">
<div class="article-summary-box-inner">
<span><p>Negation has been shown to be a major bottleneck for masked language models,
such as BERT. However, whether this finding still holds for larger-sized
auto-regressive language models (``LLMs'') has not been studied
comprehensively. With the ever-increasing volume of research and applications
of LLMs, we take a step back to evaluate the ability of current-generation LLMs
to handle negation, a fundamental linguistic phenomenon that is central to
language understanding. We evaluate different LLMs -- including the open-source
GPT-neo, GPT-3, and InstructGPT -- against a wide range of negation benchmarks.
Through systematic experimentation with varying model sizes and prompts, we
show that LLMs have several limitations including insensitivity to the presence
of negation, an inability to capture the lexical semantics of negation, and a
failure to reason under negation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing the Effectiveness of GPT-3 in Detecting False Political Statements: A Case Study on the LIAR Dataset. (arXiv:2306.08190v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08190">
<div class="article-summary-box-inner">
<span><p>The detection of political fake statements is crucial for maintaining
information integrity and preventing the spread of misinformation in society.
Historically, state-of-the-art machine learning models employed various methods
for detecting deceptive statements. These methods include the use of metadata
(W. Wang et al., 2018), n-grams analysis (Singh et al., 2021), and linguistic
(Wu et al., 2022) and stylometric (Islam et al., 2020) features. Recent
advancements in large language models, such as GPT-3 (Brown et al., 2020) have
achieved state-of-the-art performance on a wide range of tasks. In this study,
we conducted experiments with GPT-3 on the LIAR dataset (W. Wang et al., 2018)
and achieved higher accuracy than state-of-the-art models without using any
additional meta or linguistic features. Additionally, we experimented with
zero-shot learning using a carefully designed prompt and achieved near
state-of-the-art performance. An advantage of this approach is that the model
provided evidence for its decision, which adds transparency to the model's
decision-making and offers a chance for users to verify the validity of the
evidence provided.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Operationalising Representation in Natural Language Processing. (arXiv:2306.08193v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08193">
<div class="article-summary-box-inner">
<span><p>Despite its centrality in the philosophy of cognitive science, there has been
little prior philosophical work engaging with the notion of representation in
contemporary NLP practice. This paper attempts to fill that lacuna: drawing on
ideas from cognitive science, I introduce a framework for evaluating the
representational claims made about components of neural NLP models, proposing
three criteria with which to evaluate whether a component of a model represents
a property and operationalising these criteria using probing classifiers, a
popular analysis technique in NLP (and deep learning more broadly).
</p>
<p>The project of operationalising a philosophically-informed notion of
representation should be of interest to both philosophers of science and NLP
practitioners. It affords philosophers a novel testing-ground for claims about
the nature of representation, and helps NLPers organise the large literature on
probing experiments, suggesting novel avenues for empirical research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Loss is All You Need to Recover Analogies as Parallel Lines. (arXiv:2306.08221v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08221">
<div class="article-summary-box-inner">
<span><p>While static word embedding models are known to represent linguistic
analogies as parallel lines in high-dimensional space, the underlying mechanism
as to why they result in such geometric structures remains obscure. We find
that an elementary contrastive-style method employed over distributional
information performs competitively with popular word embedding models on
analogy recovery tasks, while achieving dramatic speedups in training time.
Further, we demonstrate that a contrastive loss is sufficient to create these
parallel structures in word embeddings, and establish a precise relationship
between the co-occurrence statistics and the geometric structure of the
resulting word embeddings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WARM: A Weakly (+Semi) Supervised Model for Solving Math word Problems. (arXiv:2104.06722v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06722">
<div class="article-summary-box-inner">
<span><p>Solving math word problems (MWPs) is an important and challenging problem in
natural language processing. Existing approaches to solve MWPs require full
supervision in the form of intermediate equations. However, labeling every MWP
with its corresponding equations is a time-consuming and expensive task. In
order to address this challenge of equation annotation, we propose a weakly
supervised model for solving MWPs by requiring only the final answer as
supervision. We approach this problem by first learning to generate the
equation using the problem description and the final answer, which we
subsequently use to train a supervised MWP solver. We propose and compare
various weakly supervised techniques to learn to generate equations directly
from the problem description and answer. Through extensive experiments, we
demonstrate that without using equations for supervision, our approach achieves
accuracy gains of 4.5% and 32% over the state-of-the-art weakly supervised
approach, on the standard Math23K and AllArith datasets respectively.
Additionally, we curate and release new datasets of roughly 10k MWPs each in
English and in Hindi (a low resource language).These datasets are suitable for
training weakly supervised models. We also present an extension of WARMM to
semi-supervised learning and present further improvements on results, along
with insights.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-conditioning pre-trained language models. (arXiv:2110.02802v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.02802">
<div class="article-summary-box-inner">
<span><p>In this paper we aim to investigate the mechanisms that guide text generation
with pre-trained Transformer-based Language Models (TLMs). Grounded on the
Product of Experts formulation by Hinton (1999), we describe a generative
mechanism that exploits expert units which naturally exist in TLMs. Such units
are responsible for detecting concepts in the input and conditioning text
generation on such concepts. We describe how to identify expert units and how
to activate them during inference in order to induce any desired concept in the
generated output. We find that the activation of a surprisingly small amount of
units is sufficient to steer text generation (as little as 3 units in a model
with 345M parameters). While the objective of this work is to learn more about
how TLMs work, we show that our method is effective for conditioning without
fine-tuning or using extra parameters, even on fine-grained homograph concepts.
Additionally, we show that our method can be used to correct gender bias
present in the output of TLMs and achieves gender parity for all evaluated
contexts. We compare our method with FUDGE and PPLM-BoW, and show that our
approach is able to achieve gender parity at a lower perplexity. The proposed
method is accessible to a wide audience thanks to its simplicity and minimal
compute needs. The findings in this paper are a step forward in understanding
the generative mechanisms of TLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Focusing on Potential Named Entities During Active Label Acquisition. (arXiv:2111.03837v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.03837">
<div class="article-summary-box-inner">
<span><p>Named entity recognition (NER) aims to identify mentions of named entities in
an unstructured text and classify them into predefined named entity classes.
While deep learning-based pre-trained language models help to achieve good
predictive performances in NER, many domain-specific NER applications still
call for a substantial amount of labeled data. Active learning (AL), a general
framework for the label acquisition problem, has been used for NER tasks to
minimize the annotation cost without sacrificing model performance. However,
the heavily imbalanced class distribution of tokens introduces challenges in
designing effective AL querying methods for NER. We propose several AL sentence
query evaluation functions that pay more attention to potential positive
tokens, and evaluate these proposed functions with both sentence-based and
token-based cost evaluation strategies. We also propose a better data-driven
normalization approach to penalize sentences that are too long or too short.
Our experiments on three datasets from different domains reveal that the
proposed approach reduces the number of annotated tokens while achieving better
or comparable prediction performance with conventional methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detection of sepsis during emergency department triage using machine learning. (arXiv:2204.07657v6 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.07657">
<div class="article-summary-box-inner">
<span><p>Sepsis is a life-threatening condition with organ dysfunction and is a
leading cause of death and critical illness worldwide. Even a few hours of
delay in the treatment of sepsis results in increased mortality. Early
detection of sepsis during emergency department triage would allow early
initiation of lab analysis, antibiotic administration, and other sepsis
treatment protocols. The purpose of this study was to compare sepsis detection
performance at ED triage (prior to the use of laboratory diagnostics) of the
standard sepsis screening algorithm (SIRS with source of infection) and a
machine learning algorithm trained on EHR triage data. A machine learning model
(KATE Sepsis) was developed using patient encounters with triage data from
16participating hospitals. KATE Sepsis and standard screening were
retrospectively evaluated on the adult population of 512,949 medical records.
KATE Sepsis demonstrates an AUC of 0.9423 (0.9401 - 0.9441) with sensitivity of
71.09% (70.12% - 71.98%) and specificity of 94.81% (94.75% - 94.87%). Standard
screening demonstrates an AUC of 0.6826 (0.6774 - 0.6878) with sensitivity of
40.8% (39.71% - 41.86%) and specificity of 95.72% (95.68% - 95.78%). The KATE
Sepsis model trained to detect sepsis demonstrates 77.67% (75.78% -79.42%)
sensitivity in detecting severe sepsis and 86.95% (84.2% - 88.81%) sensitivity
in detecting septic shock. The standard screening protocol demonstrates 43.06%
(41% - 45.87%) sensitivity in detecting severe sepsis and40% (36.55% - 43.26%)
sensitivity in detecting septic shock. Future research should focus on the
prospective impact of KATE Sepsis on administration of antibiotics, readmission
rate, morbidity and mortality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Taxonomy of Prompt Modifiers for Text-To-Image Generation. (arXiv:2204.13988v3 [cs.MM] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.13988">
<div class="article-summary-box-inner">
<span><p>Text-to-image generation has seen an explosion of interest since 2021. Today,
beautiful and intriguing digital images and artworks can be synthesized from
textual inputs ("prompts") with deep generative models. Online communities
around text-to-image generation and AI generated art have quickly emerged. This
paper identifies six types of prompt modifiers used by practitioners in the
online community based on a 3-month ethnographic study. The novel taxonomy of
prompt modifiers provides researchers a conceptual starting point for
investigating the practice of text-to-image generation, but may also help
practitioners of AI generated art improve their images. We further outline how
prompt modifiers are applied in the practice of "prompt engineering." We
discuss research opportunities of this novel creative practice in the field of
Human-Computer Interaction (HCI). The paper concludes with a discussion of
broader implications of prompt engineering from the perspective of Human-AI
Interaction (HAI) in future applications beyond the use case of text-to-image
generation and AI generated art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PLAtE: A Large-scale Dataset for List Page Web Extraction. (arXiv:2205.12386v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12386">
<div class="article-summary-box-inner">
<span><p>Recently, neural models have been leveraged to significantly improve the
performance of information extraction from semi-structured websites. However, a
barrier for continued progress is the small number of datasets large enough to
train these models. In this work, we introduce the PLAtE (Pages of Lists
Attribute Extraction) benchmark dataset as a challenging new web extraction
task. PLAtE focuses on shopping data, specifically extractions from product
review pages with multiple items encompassing the tasks of: (1) finding
product-list segmentation boundaries and (2) extracting attributes for each
product. PLAtE is composed of 52, 898 items collected from 6, 694 pages and
156, 014 attributes, making it the first largescale list page web extraction
dataset. We use a multi-stage approach to collect and annotate the dataset and
adapt three state-of-the-art web extraction models to the two tasks comparing
their strengths and weaknesses both quantitatively and qualitatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Dynamic Contextualised Word Embeddings via Template-based Temporal Adaptation. (arXiv:2208.10734v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.10734">
<div class="article-summary-box-inner">
<span><p>Dynamic contextualised word embeddings (DCWEs) represent the temporal
semantic variations of words. We propose a method for learning DCWEs by
time-adapting a pretrained Masked Language Model (MLM) using time-sensitive
templates. Given two snapshots $C_1$ and $C_2$ of a corpus taken respectively
at two distinct timestamps $T_1$ and $T_2$, we first propose an unsupervised
method to select (a) \emph{pivot} terms related to both $C_1$ and $C_2$, and
(b) \emph{anchor} terms that are associated with a specific pivot term in each
individual snapshot. We then generate prompts by filling manually compiled
templates using the extracted pivot and anchor terms. Moreover, we propose an
automatic method to learn time-sensitive templates from $C_1$ and $C_2$,
without requiring any human supervision. Next, we use the generated prompts to
adapt a pretrained MLM to $T_2$ by fine-tuning using those prompts. Multiple
experiments show that our proposed method reduces the perplexity of test
sentences in $C_2$, outperforming the current state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SpeechLM: Enhanced Speech Pre-Training with Unpaired Textual Data. (arXiv:2209.15329v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.15329">
<div class="article-summary-box-inner">
<span><p>How to boost speech pre-training with textual data is an unsolved problem due
to the fact that speech and text are very different modalities with distinct
characteristics. In this paper, we propose a cross-modal Speech and Language
Model (SpeechLM) to explicitly align speech and text pre-training with a
pre-defined unified discrete representation. Specifically, we introduce two
alternative discrete tokenizers to bridge the speech and text modalities,
including phoneme-unit and hidden-unit tokenizers, which can be trained using a
small amount of paired speech-text data. Based on the trained tokenizers, we
convert the unlabeled speech and text data into tokens of phoneme units or
hidden units. The pre-training objective is designed to unify the speech and
the text into the same discrete semantic space with a unified Transformer
network. We evaluate SpeechLM on various spoken language processing tasks
including speech recognition, speech translation, and universal representation
evaluation framework SUPERB, demonstrating significant improvements on
content-related tasks. Code and models are available at
https://aka.ms/SpeechLM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MAMO: Masked Multimodal Modeling for Fine-Grained Vision-Language Representation Learning. (arXiv:2210.04183v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04183">
<div class="article-summary-box-inner">
<span><p>Multimodal representation learning has shown promising improvements on
various vision-language tasks. Most existing methods excel at building
global-level alignment between vision and language while lacking effective
fine-grained image-text interaction. In this paper, we propose a jointly masked
multimodal modeling method to learn fine-grained multimodal representations.
Our method performs joint masking on image-text input and integrates both
implicit and explicit targets for the masked signals to recover. The implicit
target provides a unified and debiased objective for vision and language, where
the model predicts latent multimodal representations of the unmasked input. The
explicit target further enriches the multimodal representations by recovering
high-level and semantically meaningful information: momentum visual features of
image patches and concepts of word tokens. Through such a masked modeling
process, our model not only learns fine-grained multimodal interaction, but
also avoids the semantic gap between high-level representations and low- or
mid-level prediction targets (e.g. image pixels), thus producing semantically
rich multimodal representations that perform well on both zero-shot and
fine-tuned settings. Our pre-trained model (named MAMO) achieves
state-of-the-art performance on various downstream vision-language tasks,
including image-text retrieval, visual question answering, visual reasoning,
and weakly-supervised visual grounding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting. (arXiv:2210.08964v3 [stat.ME] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08964">
<div class="article-summary-box-inner">
<span><p>This paper presents a new perspective on time series forecasting. In existing
time series forecasting methods, the models take a sequence of numerical values
as input and yield numerical values as output. The existing SOTA models are
largely based on the Transformer architecture, modified with multiple encoding
mechanisms to incorporate the context and semantics around the historical data.
Inspired by the successes of pre-trained language foundation models, we pose a
question about whether these models can also be adapted to solve time-series
forecasting. Thus, we propose a new forecasting paradigm: prompt-based time
series forecasting (PromptCast). In this novel task, the numerical input and
output are transformed into prompts and the forecasting task is framed in a
sentence-to-sentence manner, making it possible to directly apply language
models for forecasting purposes. To support and facilitate the research of this
task, we also present a large-scale dataset (PISA) that includes three
real-world forecasting scenarios. We evaluate different SOTA numerical-based
forecasting methods and language generation models. The benchmark results with
various forecasting settings demonstrate the proposed PromptCast with language
generation models is a promising research direction. Additionally, in
comparison to conventional numerical-based forecasting, PromptCast shows a much
better generalization ability under the zero-shot setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ATCO2 corpus: A Large-Scale Dataset for Research on Automatic Speech Recognition and Natural Language Understanding of Air Traffic Control Communications. (arXiv:2211.04054v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.04054">
<div class="article-summary-box-inner">
<span><p>Personal assistants, automatic speech recognizers and dialogue understanding
systems are becoming more critical in our interconnected digital world. A clear
example is air traffic control (ATC) communications. ATC aims at guiding
aircraft and controlling the airspace in a safe and optimal manner. These
voice-based dialogues are carried between an air traffic controller (ATCO) and
pilots via very-high frequency radio channels. In order to incorporate these
novel technologies into ATC (low-resource domain), large-scale annotated
datasets are required to develop the data-driven AI systems. Two examples are
automatic speech recognition (ASR) and natural language understanding (NLU). In
this paper, we introduce the ATCO2 corpus, a dataset that aims at fostering
research on the challenging ATC field, which has lagged behind due to lack of
annotated data. The ATCO2 corpus covers 1) data collection and pre-processing,
2) pseudo-annotations of speech data, and 3) extraction of ATC-related named
entities. The ATCO2 corpus is split into three subsets. 1) ATCO2-test-set
corpus contains 4 hours of ATC speech with manual transcripts and a subset with
gold annotations for named-entity recognition (callsign, command, value). 2)
The ATCO2-PL-set corpus consists of 5281 hours of unlabeled ATC data enriched
with automatic transcripts from an in-domain speech recognizer, contextual
information, speaker turn information, signal-to-noise ratio estimate and
English language detection score per sample. Both available for purchase
through ELDA at <a href="http://catalog.elra.info/en-us/repository/browse/ELRA-S0484.">this http URL</a> 3)
The ATCO2-test-set-1h corpus is a one-hour subset from the original test set
corpus, that we are offering for free at https://www.atco2.org/data. We expect
the ATCO2 corpus will foster research on robust ASR and NLU not only in the
field of ATC communications but also in the general research community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reducing Hallucinations in Neural Machine Translation with Feature Attribution. (arXiv:2211.09878v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09878">
<div class="article-summary-box-inner">
<span><p>Neural conditional language generation models achieve the state-of-the-art in
Neural Machine Translation (NMT) but are highly dependent on the quality of
parallel training dataset. When trained on low-quality datasets, these models
are prone to various error types, including hallucinations, i.e. outputs that
are fluent, but unrelated to the source sentences. These errors are
particularly dangerous, because on the surface the translation can be perceived
as a correct output, especially if the reader does not understand the source
language. We present a case study focusing on model understanding and
regularisation to reduce hallucinations in NMT. We first use feature
attribution methods to study the behaviour of an NMT model that produces
hallucinations. We then leverage these methods to propose a novel loss function
that substantially helps reduce hallucinations and does not require retraining
the model from scratch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inconsistency Ranking-based Noisy Label Detection for High-quality Data. (arXiv:2212.00239v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.00239">
<div class="article-summary-box-inner">
<span><p>The success of deep learning requires high-quality annotated and massive
data. However, the size and the quality of a dataset are usually a trade-off in
practice, as data collection and cleaning are expensive and time-consuming. In
real-world applications, especially those using crowdsourcing datasets, it is
important to exclude noisy labels. To address this, this paper proposes an
automatic noisy label detection (NLD) technique with inconsistency ranking for
high-quality data. We apply this technique to the automatic speaker
verification (ASV) task as a proof of concept. We investigate both inter-class
and intra-class inconsistency ranking and compare several metric learning loss
functions under different noise settings. Experimental results confirm that the
proposed solution could increase both the efficient and effective cleaning of
large-scale speaker recognition datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language. (arXiv:2212.07525v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.07525">
<div class="article-summary-box-inner">
<span><p>Current self-supervised learning algorithms are often modality-specific and
require large amounts of computational resources. To address these issues, we
increase the training efficiency of data2vec, a learning objective that
generalizes across several modalities. We do not encode masked tokens, use a
fast convolutional decoder and amortize the effort to build teacher
representations. data2vec 2.0 benefits from the rich contextualized target
representations introduced in data2vec which enable a fast self-supervised
learner. Experiments on ImageNet-1K image classification show that data2vec 2.0
matches the accuracy of Masked Autoencoders in 16.4x lower pre-training time,
on Librispeech speech recognition it performs as well as wav2vec 2.0 in 10.6x
less time, and on GLUE natural language understanding it matches a retrained
RoBERTa model in half the time. Trading some speed for accuracy results in
ImageNet-1K top-1 accuracy of 86.8\% with a ViT-L model trained for 150 epochs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DOC: Improving Long Story Coherence With Detailed Outline Control. (arXiv:2212.10077v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10077">
<div class="article-summary-box-inner">
<span><p>We propose the Detailed Outline Control (DOC) framework for improving
long-range plot coherence when automatically generating
several-thousand-word-long stories. DOC consists of two complementary
components: a detailed outliner and a detailed controller. The detailed
outliner creates a more detailed, hierarchically structured outline, shifting
creative burden from the main drafting procedure to the planning stage. The
detailed controller ensures the more detailed outline is still respected during
generation by controlling story passages to align with outline details. In
human evaluations of automatically generated stories, DOC substantially
outperforms a strong Re3 baseline (Yang et al., 2022) on plot coherence (22.5%
absolute gain), outline relevance (28.2%), and interestingness (20.7%). Humans
also judged DOC to be much more controllable in an interactive generation
setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Needle in a Haystack: An Analysis of High-Agreement Workers on MTurk for Summarization. (arXiv:2212.10397v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10397">
<div class="article-summary-box-inner">
<span><p>To prevent the costly and inefficient use of resources on low-quality
annotations, we want a method for creating a pool of dependable annotators who
can effectively complete difficult tasks, such as evaluating automatic
summarization. Thus, we investigate the recruitment of high-quality Amazon
Mechanical Turk workers via a two-step pipeline. We show that we can
successfully filter out subpar workers before they carry out the evaluations
and obtain high-agreement annotations with similar constraints on resources.
Although our workers demonstrate a strong consensus among themselves and
CloudResearch workers, their alignment with expert judgments on a subset of the
data is not as expected and needs further training in correctness. This paper
still serves as a best practice for the recruitment of qualified annotators in
other challenging annotation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is GPT-3 a Good Data Annotator?. (arXiv:2212.10450v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10450">
<div class="article-summary-box-inner">
<span><p>Data annotation is the process of labeling data that could be used to train
machine learning models. Having high-quality annotation is crucial, as it
allows the model to learn the relationship between the input data and the
desired output. GPT-3, a large-scale language model developed by OpenAI, has
demonstrated impressive zero- and few-shot performance on a wide range of NLP
tasks. It is therefore natural to wonder whether it can be used to effectively
annotate data for NLP tasks. In this paper, we evaluate the performance of
GPT-3 as a data annotator by comparing it with traditional data annotation
methods and analyzing its output on a range of tasks. Through this analysis, we
aim to provide insight into the potential of GPT-3 as a general-purpose data
annotator in NLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompt-Augmented Linear Probing: Scaling beyond the Limit of Few-shot In-Context Learners. (arXiv:2212.10873v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10873">
<div class="article-summary-box-inner">
<span><p>Through in-context learning (ICL), large-scale language models are effective
few-shot learners without additional model fine-tuning. However, the ICL
performance does not scale well with the number of available training samples
as it is limited by the inherent input length constraint of the underlying
language model. Meanwhile, many studies have revealed that language models are
also powerful feature extractors, allowing them to be utilized in a black-box
manner and enabling the linear probing paradigm, where lightweight
discriminators are trained on top of the pre-extracted input representations.
This paper proposes prompt-augmented linear probing (PALP), a hybrid of linear
probing and ICL, which leverages the best of both worlds. PALP inherits the
scalability of linear probing and the capability of enforcing language models
to derive more meaningful representations via tailoring input into a more
conceivable form. Throughout in-depth investigations on various datasets, we
verified that PALP significantly enhances the input representations closing the
gap between ICL in the data-hungry scenario and fine-tuning in the
data-abundant scenario with little training overhead, potentially making PALP a
strong alternative in a black-box scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Probing Out-of-Distribution Robustness of Language Models with Parameter-Efficient Transfer Learning. (arXiv:2301.11660v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.11660">
<div class="article-summary-box-inner">
<span><p>As the size of the pre-trained language model (PLM) continues to increase,
numerous parameter-efficient transfer learning methods have been proposed
recently to compensate for the tremendous cost of fine-tuning. Despite the
impressive results achieved by large pre-trained language models (PLMs) and
various parameter-efficient transfer learning (PETL) methods on sundry
benchmarks, it remains unclear if they can handle inputs that have been
distributionally shifted effectively. In this study, we systematically explore
how the ability to detect out-of-distribution (OOD) changes as the size of the
PLM grows or the transfer methods are altered. Specifically, we evaluated
various PETL techniques, including fine-tuning, Adapter, LoRA, and
prefix-tuning, on three different intention classification tasks, each
utilizing various language models with different scales.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grounding Language Models to Images for Multimodal Inputs and Outputs. (arXiv:2301.13823v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.13823">
<div class="article-summary-box-inner">
<span><p>We propose an efficient method to ground pretrained text-only language models
to the visual domain, enabling them to process arbitrarily interleaved
image-and-text data, and generate text interleaved with retrieved images. Our
method leverages the abilities of language models learnt from large scale
text-only pretraining, such as in-context learning and free-form text
generation. We keep the language model frozen, and finetune input and output
linear layers to enable cross-modality interactions. This allows our model to
process arbitrarily interleaved image-and-text inputs, and generate free-form
text interleaved with retrieved images. We achieve strong zero-shot performance
on grounded tasks such as contextual image retrieval and multimodal dialogue,
and showcase compelling interactive abilities. Our approach works with any
off-the-shelf language model and paves the way towards an effective, general
solution for leveraging pretrained language models in visually grounded
settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large language models predict human sensory judgments across six modalities. (arXiv:2302.01308v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01308">
<div class="article-summary-box-inner">
<span><p>Determining the extent to which the perceptual world can be recovered from
language is a longstanding problem in philosophy and cognitive science. We show
that state-of-the-art large language models can unlock new insights into this
problem by providing a lower bound on the amount of perceptual information that
can be extracted from language. Specifically, we elicit pairwise similarity
judgments from GPT models across six psychophysical datasets. We show that the
judgments are significantly correlated with human data across all domains,
recovering well-known representations like the color wheel and pitch spiral.
Surprisingly, we find that a model (GPT-4) co-trained on vision and language
does not necessarily lead to improvements specific to the visual modality. To
study the influence of specific languages on perception, we also apply the
models to a multilingual color-naming task. We find that GPT-4 replicates
cross-linguistic variation in English and Russian illuminating the interaction
of language and perception.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pretraining Language Models with Human Preferences. (arXiv:2302.08582v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08582">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) are pretrained to imitate internet text, including
content that would violate human preferences if generated by an LM: falsehoods,
offensive comments, personally identifiable information, low-quality or buggy
code, and more. Here, we explore alternative objectives for pretraining LMs in
a way that also guides them to generate text aligned with human preferences. We
benchmark five objectives for pretraining with human feedback across three
tasks and study how they affect the trade-off between alignment and
capabilities of pretrained LMs. We find a Pareto-optimal and simple approach
among those we explored: conditional training, or learning distribution over
tokens conditional on their human preference scores given by a reward model.
Conditional training reduces the rate of undesirable content by up to an order
of magnitude, both when generating without a prompt and with an
adversarially-chosen prompt. Moreover, conditional training maintains the
downstream task performance of standard LM pretraining, both before and after
task-specific finetuning. Pretraining with human feedback results in much
better preference satisfaction than standard LM pretraining followed by
finetuning with feedback, i.e., learning and then unlearning undesirable
behavior. Our results suggest that we should move beyond imitation learning
when pretraining LMs and incorporate human preferences from the start of
training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Transductions and Alignments with RNN Seq2seq Models. (arXiv:2303.06841v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.06841">
<div class="article-summary-box-inner">
<span><p>The paper studies the capabilities of Recurrent-Neural-Network sequence to
sequence (RNN seq2seq) models in learning four transduction tasks: identity,
reversal, total reduplication, and quadratic copying. These transductions are
traditionally well studied under finite state transducers and attributed with
increasing complexity. We find that RNN seq2seq models are only able to
approximate a mapping that fits the training or in-distribution data, instead
of learning the underlying functions. Although attention makes learning more
efficient and robust, it does not overcome the out-of-distribution
generalization limitation. We establish a novel complexity hierarchy for
learning the four tasks for attention-less RNN seq2seq models, which may be
understood in terms of the complexity hierarchy of formal languages, instead of
string transductions. RNN variants also play a role in the results. In
particular, we show that Simple RNN seq2seq models cannot count the input
length.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention. (arXiv:2303.16199v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.16199">
<div class="article-summary-box-inner">
<span><p>We present LLaMA-Adapter, a lightweight adaption method to efficiently
fine-tune LLaMA into an instruction-following model. Using 52K self-instruct
demonstrations, LLaMA-Adapter only introduces 1.2M learnable parameters upon
the frozen LLaMA 7B model, and costs less than one hour for fine-tuning on 8
A100 GPUs. Specifically, we adopt a set of learnable adaption prompts, and
prepend them to the word tokens at higher transformer layers. Then, a
zero-initialized attention mechanism with zero gating is proposed, which
adaptively injects the new instructional cues into LLaMA, while effectively
preserves its pre-trained knowledge. With our efficient training, LLaMA-Adapter
can generate high-quality responses, comparable to Alpaca with fully fine-tuned
7B parameters. Besides language commands, our approach can be simply extended
to multi-modal instructions for learning image-conditioned LLaMA model, which
achieves superior reasoning performance on ScienceQA and COCO Caption
benchmarks. Furthermore, we also evaluate the zero-initialized attention
mechanism for fine-tuning other pre-trained models (ViT, RoBERTa) on
traditional vision and language tasks, demonstrating the superior
generalization capacity of our approach. Code is released at
https://github.com/OpenGVLab/LLaMA-Adapter.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OpenAGI: When LLM Meets Domain Experts. (arXiv:2304.04370v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.04370">
<div class="article-summary-box-inner">
<span><p>Human intelligence has the remarkable ability to assemble basic skills into
complex ones so as to solve complex tasks. This ability is equally important
for Artificial Intelligence (AI), and thus, we assert that in addition to the
development of large, comprehensive intelligent models, it is equally crucial
to equip such models with the capability to harness various domain-specific
expert models for complex task-solving in the pursuit of Artificial General
Intelligence (AGI). Recent developments in Large Language Models (LLMs) have
demonstrated remarkable learning and reasoning abilities, making them promising
as a controller to select, synthesize, and execute external models to solve
complex tasks. In this project, we develop OpenAGI, an open-source AGI research
platform, specifically designed to offer complex, multi-step tasks and
accompanied by task-specific datasets, evaluation metrics, and a diverse range
of extensible models. OpenAGI formulates complex tasks as natural language
queries, serving as input to the LLM. The LLM subsequently selects,
synthesizes, and executes models provided by OpenAGI to address the task.
Furthermore, we propose a Reinforcement Learning from Task Feedback (RLTF)
mechanism, which uses the task-solving result as feedback to improve the LLM's
task-solving ability. Thus, the LLM is responsible for synthesizing various
external models for solving complex tasks, while RLTF provides feedback to
improve its task-solving ability, enabling a feedback loop for self-improving
AI. We believe that the paradigm of LLMs operating various expert models for
complex task-solving is a promising approach towards AGI. To facilitate the
community's long-term improvement and evaluation of AGI's ability, we
open-source the code, benchmark, and evaluation methods of the OpenAGI project
at https://github.com/agiresearch/OpenAGI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca. (arXiv:2304.08177v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.08177">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs), such as ChatGPT and GPT-4, have dramatically
transformed natural language processing research and shown promising strides
towards Artificial General Intelligence (AGI). Nonetheless, the high costs
associated with training and deploying LLMs present substantial obstacles to
transparent, accessible academic research. While several large language models,
such as LLaMA, have been open-sourced by the community, these predominantly
focus on English corpora, limiting their usefulness for other languages. In
this paper, we propose a method to augment LLaMA with capabilities for
understanding and generating Chinese text and its ability to follow
instructions. We achieve this by extending LLaMA's existing vocabulary with an
additional 20,000 Chinese tokens, thereby improving its encoding efficiency and
semantic understanding of Chinese. We further incorporate secondary
pre-training using Chinese data and fine-tune the model with Chinese
instruction datasets, significantly enhancing the model's ability to comprehend
and execute instructions. Our experimental results indicate that the newly
proposed model markedly enhances the original LLaMA's proficiency in
understanding and generating Chinese content. Additionally, the results on the
C-Eval dataset yield competitive performance among the models with several
times the size of ours. We have made our pre-trained models, training scripts,
and other resources available through GitHub, fostering open research for our
community. GitHub repository: https://github.com/ymcui/Chinese-LLaMA-Alpaca
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tool Learning with Foundation Models. (arXiv:2304.08354v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.08354">
<div class="article-summary-box-inner">
<span><p>Humans possess an extraordinary ability to create and utilize tools, allowing
them to overcome physical limitations and explore new frontiers. With the
advent of foundation models, AI systems have the potential to be equally adept
in tool use as humans. This paradigm, i.e., tool learning with foundation
models, combines the strengths of specialized tools and foundation models to
achieve enhanced accuracy, efficiency, and automation in problem-solving.
Despite its immense potential, there is still a lack of a comprehensive
understanding of key challenges, opportunities, and future endeavors in this
field. To this end, we present a systematic investigation of tool learning in
this paper. We first introduce the background of tool learning, including its
cognitive origins, the paradigm shift of foundation models, and the
complementary roles of tools and models. Then we recapitulate existing tool
learning research into tool-augmented and tool-oriented learning. We formulate
a general tool learning framework: starting from understanding the user
instruction, models should learn to decompose a complex task into several
subtasks, dynamically adjust their plan through reasoning, and effectively
conquer each sub-task by selecting appropriate tools. We also discuss how to
train models for improved tool-use capabilities and facilitate the
generalization in tool learning. Considering the lack of a systematic tool
learning evaluation in prior works, we experiment with 18 representative tools
and show the potential of current foundation models in skillfully utilizing
tools. Finally, we discuss several open problems that require further
investigation for tool learning. Overall, we hope this paper could inspire
future research in integrating tools with foundation models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextual Multilingual Spellchecker for User Queries. (arXiv:2305.01082v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01082">
<div class="article-summary-box-inner">
<span><p>Spellchecking is one of the most fundamental and widely used search features.
Correcting incorrectly spelled user queries not only enhances the user
experience but is expected by the user. However, most widely available
spellchecking solutions are either lower accuracy than state-of-the-art
solutions or too slow to be used for search use cases where latency is a key
requirement. Furthermore, most innovative recent architectures focus on English
and are not trained in a multilingual fashion and are trained for spell
correction in longer text, which is a different paradigm from spell correction
for user queries, where context is sparse (most queries are 1-2 words long).
Finally, since most enterprises have unique vocabularies such as product names,
off-the-shelf spelling solutions fall short of users' needs. In this work, we
build a multilingual spellchecker that is extremely fast and scalable and that
adapts its vocabulary and hence speller output based on a specific product's
needs. Furthermore, our speller out-performs general purpose spellers by a wide
margin on in-domain datasets. Our multilingual speller is used in search in
Adobe products, powering autocomplete in various applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPTutor: a ChatGPT-powered programming tool for code explanation. (arXiv:2305.01863v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01863">
<div class="article-summary-box-inner">
<span><p>Learning new programming skills requires tailored guidance. With the
emergence of advanced Natural Language Generation models like the ChatGPT API,
there is now a possibility of creating a convenient and personalized tutoring
system with AI for computer science education. This paper presents GPTutor, a
ChatGPT-powered programming tool, which is a Visual Studio Code extension using
the ChatGPT API to provide programming code explanations. By integrating Visual
Studio Code API, GPTutor can comprehensively analyze the provided code by
referencing the relevant source codes. As a result, GPTutor can use designed
prompts to explain the selected code with a pop-up message. GPTutor is now
published at the Visual Studio Code Extension Marketplace, and its source code
is openly accessible on GitHub. Preliminary evaluation indicates that GPTutor
delivers the most concise and accurate explanations compared to vanilla ChatGPT
and GitHub Copilot. Moreover, the feedback from students and teachers indicated
that GPTutor is user-friendly and can explain given codes satisfactorily.
Finally, we discuss possible future research directions for GPTutor. This
includes enhancing its performance and personalization via further prompt
programming, as well as evaluating the effectiveness of GPTutor with real
users.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the Influence of Language on Time-Reward Perceptions in Large Language Models: A Study Using GPT-3.5. (arXiv:2305.02531v3 [econ.GN] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02531">
<div class="article-summary-box-inner">
<span><p>Language has a strong influence on our perceptions of time and rewards. This
raises the question of whether large language models, when asked the same
question in different languages, show different preferences for rewards over
time and if their choices are similar to those of humans. In this study, we
analyze the responses of GPT-3.5 (hereafter referred to as GPT) to prompts in
multiple languages, exploring preferences between smaller, sooner rewards and
larger, later rewards. Our results show that GPT displays greater patience when
prompted in languages with weak future tense references (FTR), such as German
and Mandarin, compared to languages with strong FTR, like English and French.
These findings are consistent with the existing literature and suggest a
correlation between GPT's choices and the preferences of speakers of these
languages. However, further analysis reveals that the preference for earlier or
later rewards does not systematically change with reward gaps, indicating a
lexicographic preference for earlier payments. While GPT may capture intriguing
variations across languages, our findings indicate that the choices made by
these models do not correspond to those of human decision-makers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LMs stand their Ground: Investigating the Effect of Embodiment in Figurative Language Interpretation by Language Models. (arXiv:2305.03445v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03445">
<div class="article-summary-box-inner">
<span><p>Figurative language is a challenge for language models since its
interpretation is based on the use of words in a way that deviates from their
conventional order and meaning. Yet, humans can easily understand and interpret
metaphors, similes or idioms as they can be derived from embodied metaphors.
Language is a proxy for embodiment and if a metaphor is conventional and
lexicalised, it becomes easier for a system without a body to make sense of
embodied concepts. Yet, the intricate relation between embodiment and features
such as concreteness or age of acquisition has not been studied in the context
of figurative language interpretation concerning language models. Hence, the
presented study shows how larger language models perform better at interpreting
metaphoric sentences when the action of the metaphorical sentence is more
embodied. The analysis rules out multicollinearity with other features (e.g.
word length or concreteness) and provides initial evidence that larger language
models conceptualise embodied concepts to a degree that facilitates figurative
language understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interactive Text-to-SQL Generation via Editable Step-by-Step Explanations. (arXiv:2305.07372v2 [cs.DB] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07372">
<div class="article-summary-box-inner">
<span><p>Relational databases play an important role in this Big Data era. However, it
is challenging for non-experts to fully unleash the analytical power of
relational databases, since they are not familiar with database languages such
as SQL. Many techniques have been proposed to automatically generate SQL from
natural language, but they suffer from two issues: (1) they still make many
mistakes, particularly for complex queries, and (2) they do not provide a
flexible way for non-expert users to validate and refine the incorrect queries.
To address these issues, we introduce a new interaction mechanism that allows
users directly edit a step-by-step explanation of an incorrect SQL to fix SQL
errors. Experiments on the Spider benchmark show that our approach outperforms
three SOTA approaches by at least 31.6% in terms of execution accuracy. A user
study with 24 participants further shows that our approach helped users solve
significantly more SQL tasks with less time and higher confidence,
demonstrating its potential to expand access to databases, particularly for
non-experts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM-Pruner: On the Structural Pruning of Large Language Models. (arXiv:2305.11627v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11627">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have shown remarkable capabilities in language
understanding and generation. However, such impressive capability typically
comes with a substantial model size, which presents significant challenges in
both the deployment, inference, and training stages. With LLM being a
general-purpose task solver, we explore its compression in a task-agnostic
manner, which aims to preserve the multi-task solving and language generation
ability of the original LLM. One challenge to achieving this is the enormous
size of the training corpus of LLM, which makes both data transfer and model
post-training over-burdensome. Thus, we tackle the compression of LLMs within
the bound of two constraints: being task-agnostic and minimizing the reliance
on the original training dataset. Our method, named LLM-Pruner, adopts
structural pruning that selectively removes non-critical coupled structures
based on gradient information, maximally preserving the majority of the LLM's
functionality. To this end, the performance of pruned models can be efficiently
recovered through tuning techniques, LoRA, in merely 3 hours, requiring only
50K data. We validate the LLM-Pruner on three LLMs, including LLaMA, Vicuna,
and ChatGLM, and demonstrate that the compressed models still exhibit
satisfactory capabilities in zero-shot classification and generation. The code
is available at: https://github.com/horseee/LLM-Pruner
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WebIE: Faithful and Robust Information Extraction on the Web. (arXiv:2305.14293v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14293">
<div class="article-summary-box-inner">
<span><p>Extracting structured and grounded fact triples from raw text is a
fundamental task in Information Extraction (IE). Existing IE datasets are
typically collected from Wikipedia articles, using hyperlinks to link entities
to the Wikidata knowledge base. However, models trained only on Wikipedia have
limitations when applied to web domains, which often contain noisy text or text
that does not have any factual information. We present WebIE, the first
large-scale, entity-linked closed IE dataset consisting of 1.6M sentences
automatically collected from the English Common Crawl corpus. WebIE also
includes negative examples, i.e. sentences without fact triples, to better
reflect the data on the web. We annotate ~21K triples from WebIE through
crowdsourcing and introduce mWebIE, a translation of the annotated set in four
other languages: French, Spanish, Portuguese, and Hindi. We evaluate the
in-domain, out-of-domain, and zero-shot cross-lingual performance of generative
IE models and find models trained on WebIE show better generalisability. We
also propose three training strategies that use entity linking as an auxiliary
task. Our experiments show that adding Entity-Linking objectives improves the
faithfulness of our generative IE models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Diffusion Models in Natural Language Processing. (arXiv:2305.14671v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14671">
<div class="article-summary-box-inner">
<span><p>This survey paper provides a comprehensive review of the use of diffusion
models in natural language processing (NLP). Diffusion models are a class of
mathematical models that aim to capture the diffusion of information or signals
across a network or manifold. In NLP, diffusion models have been used in a
variety of applications, such as natural language generation, sentiment
analysis, topic modeling, and machine translation. This paper discusses the
different formulations of diffusion models used in NLP, their strengths and
limitations, and their applications. We also perform a thorough comparison
between diffusion models and alternative generative models, specifically
highlighting the autoregressive (AR) models, while also examining how diverse
architectures incorporate the Transformer in conjunction with diffusion models.
Compared to AR models, diffusion models have significant advantages for
parallel generation, text interpolation, token-level controls such as syntactic
structures and semantic contents, and robustness. Exploring further
permutations of integrating Transformers into diffusion models would be a
valuable pursuit. Also, the development of multimodal diffusion models and
large-scale diffusion language models with notable capabilities for few-shot
learning would be important directions for the future advance of diffusion
models in NLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bhasha-Abhijnaanam: Native-script and romanized Language Identification for 22 Indic languages. (arXiv:2305.15814v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15814">
<div class="article-summary-box-inner">
<span><p>We create publicly available language identification (LID) datasets and
models in all 22 Indian languages listed in the Indian constitution in both
native-script and romanized text. First, we create Bhasha-Abhijnaanam, a
language identification test set for native-script as well as romanized text
which spans all 22 Indic languages. We also train IndicLID, a language
identifier for all the above-mentioned languages in both native and romanized
script. For native-script text, it has better language coverage than existing
LIDs and is competitive or better than other LIDs. IndicLID is the first LID
for romanized text in Indian languages. Two major challenges for romanized text
LID are the lack of training data and low-LID performance when languages are
similar. We provide simple and effective solutions to these problems. In
general, there has been limited work on romanized text in any language, and our
findings are relevant to other languages that need romanized language
identification. Our models are publicly available at
https://ai4bharat.iitm.ac.in/indiclid under open-source licenses. Our training
and test sets are also publicly available at
https://ai4bharat.iitm.ac.in/bhasha-abhijnaanam under open-source licenses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scaling Data-Constrained Language Models. (arXiv:2305.16264v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16264">
<div class="article-summary-box-inner">
<span><p>The current trend of scaling language models involves increasing both
parameter count and training dataset size. Extrapolating this trend suggests
that training dataset size may soon be limited by the amount of text data
available on the internet. Motivated by this limit, we investigate scaling
language models in data-constrained regimes. Specifically, we run a large set
of experiments varying the extent of data repetition and compute budget,
ranging up to 900 billion training tokens and 9 billion parameter models. We
find that with constrained data for a fixed compute budget, training with up to
4 epochs of repeated data yields negligible changes to loss compared to having
unique data. However, with more repetition, the value of adding compute
eventually decays to zero. We propose and empirically validate a scaling law
for compute optimality that accounts for the decreasing value of repeated
tokens and excess parameters. Finally, we experiment with approaches mitigating
data scarcity, including augmenting the training dataset with code data or
removing commonly used filters. Models and datasets from our 400 training runs
are freely available at https://github.com/huggingface/datablations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GDA: Generative Data Augmentation Techniques for Relation Extraction Tasks. (arXiv:2305.16663v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16663">
<div class="article-summary-box-inner">
<span><p>Relation extraction (RE) tasks show promising performance in extracting
relations from two entities mentioned in sentences, given sufficient
annotations available during training. Such annotations would be
labor-intensive to obtain in practice. Existing work adopts data augmentation
techniques to generate pseudo-annotated sentences beyond limited annotations.
These techniques neither preserve the semantic consistency of the original
sentences when rule-based augmentations are adopted, nor preserve the syntax
structure of sentences when expressing relations using seq2seq models,
resulting in less diverse augmentations. In this work, we propose a dedicated
augmentation technique for relational texts, named GDA, which uses two
complementary modules to preserve both semantic consistency and syntax
structures. We adopt a generative formulation and design a multi-tasking
solution to achieve synergies. Furthermore, GDA adopts entity hints as the
prior knowledge of the generative model to augment diverse sentences.
Experimental results in three datasets under a low-resource setting showed that
GDA could bring {\em 2.0\%} F1 improvements compared with no augmentation
technique. Source code and data are available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Imagine: Visually-Augmented Natural Language Generation. (arXiv:2305.16944v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16944">
<div class="article-summary-box-inner">
<span><p>People often imagine relevant scenes to aid in the writing process. In this
work, we aim to utilize visual information for composition in the same manner
as humans. We propose a method, LIVE, that makes pre-trained language models
(PLMs) Learn to Imagine for Visuallyaugmented natural language gEneration.
First, we imagine the scene based on the text: we use a diffusion model to
synthesize high-quality images conditioned on the input texts. Second, we use
CLIP to determine whether the text can evoke the imagination in a posterior
way. Finally, our imagination is dynamic, and we conduct synthesis for each
sentence rather than generate only one image for an entire paragraph.
Technically, we propose a novel plug-and-play fusion layer to obtain
visually-augmented representations for each text. Our vision-text fusion layer
is compatible with Transformerbased architecture. We have conducted extensive
experiments on four generation tasks using BART and T5, and the automatic
results and human evaluation demonstrate the effectiveness of our proposed
method. We will release the code, model, and data at the link:
https://github.com/RUCAIBox/LIVE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Images with Multimodal Language Models. (arXiv:2305.17216v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17216">
<div class="article-summary-box-inner">
<span><p>We propose a method to fuse frozen text-only large language models (LLMs)
with pre-trained image encoder and decoder models, by mapping between their
embedding spaces. Our model demonstrates a wide suite of multimodal
capabilities: image retrieval, novel image generation, and multimodal dialogue.
Ours is the first approach capable of conditioning on arbitrarily interleaved
image and text inputs to generate coherent image (and text) outputs. To achieve
strong performance on image generation, we propose an efficient mapping network
to ground the LLM to an off-the-shelf text-to-image generation model. This
mapping network translates hidden representations of text into the embedding
space of the visual models, enabling us to leverage the strong text
representations of the LLM for visual outputs. Our approach outperforms
baseline generation models on tasks with longer and more complex language. In
addition to novel image generation, our model is also capable of image
retrieval from a prespecified dataset, and decides whether to retrieve or
generate at inference time. This is done with a learnt decision module which
conditions on the hidden representations of the LLM. Our model exhibits a wider
range of capabilities compared to prior multimodal language models. It can
process image-and-text inputs, and produce retrieved images, generated images,
and generated text -- outperforming non-LLM based generation models across
several text-to-image tasks that measure context dependence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parallel Neurosymbolic Integration with Concordia. (arXiv:2306.00480v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00480">
<div class="article-summary-box-inner">
<span><p>Parallel neurosymbolic architectures have been applied effectively in NLP by
distilling knowledge from a logic theory into a deep model.However, prior art
faces several limitations including supporting restricted forms of logic
theories and relying on the assumption of independence between the logic and
the deep network. We present Concordia, a framework overcoming the limitations
of prior art. Concordia is agnostic both to the deep network and the logic
theory offering support for a wide range of probabilistic theories. Our
framework can support supervised training of both components and unsupervised
training of the neural component. Concordia has been successfully applied to
tasks beyond NLP and data classification, improving the accuracy of
state-of-the-art on collective activity detection, entity linking and
recommendation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Hate Speech Benchmarks: From Data Curation to System Deployment. (arXiv:2306.01105v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01105">
<div class="article-summary-box-inner">
<span><p>Social media is awash with hateful content, much of which is often veiled
with linguistic and topical diversity. The benchmark datasets used for hate
speech detection do not account for such divagation as they are predominantly
compiled using hate lexicons. However, capturing hate signals becomes
challenging in neutrally-seeded malicious content. Thus, designing models and
datasets that mimic the real-world variability of hate warrants further
investigation.
</p>
<p>To this end, we present GOTHate, a large-scale code-mixed crowdsourced
dataset of around 51k posts for hate speech detection from Twitter. GOTHate is
neutrally seeded, encompassing different languages and topics. We conduct
detailed comparisons of GOTHate with the existing hate speech datasets,
highlighting its novelty. We benchmark it with 10 recent baselines. Our
extensive empirical and benchmarking experiments suggest that GOTHate is hard
to classify in a text-only setup. Thus, we investigate how adding endogenous
signals enhances the hate speech detection task. We augment GOTHate with the
user's timeline information and ego network, bringing the overall data source
closer to the real-world setup for understanding hateful content. Our proposed
solution HEN-mBERT is a modular, multilingual, mixture-of-experts model that
enriches the linguistic subspace with latent endogenous signals from history,
topology, and exemplars. HEN-mBERT transcends the best baseline by 2.5% and 5%
in overall macro-F1 and hate class F1, respectively. Inspired by our
experiments, in partnership with Wipro AI, we are developing a semi-automated
pipeline to detect hateful content as a part of their mission to tackle online
harm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Ready are Pre-trained Abstractive Models and LLMs for Legal Case Judgement Summarization?. (arXiv:2306.01248v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01248">
<div class="article-summary-box-inner">
<span><p>Automatic summarization of legal case judgements has traditionally been
attempted by using extractive summarization methods. However, in recent years,
abstractive summarization models are gaining popularity since they can generate
more natural and coherent summaries. Legal domain-specific pre-trained
abstractive summarization models are now available. Moreover, general-domain
pre-trained Large Language Models (LLMs), such as ChatGPT, are known to
generate high-quality text and have the capacity for text summarization. Hence
it is natural to ask if these models are ready for off-the-shelf application to
automatically generate abstractive summaries for case judgements. To explore
this question, we apply several state-of-the-art domain-specific abstractive
summarization models and general-domain LLMs on Indian court case judgements,
and check the quality of the generated summaries. In addition to standard
metrics for summary quality, we check for inconsistencies and hallucinations in
the summaries. We see that abstractive summarization models generally achieve
slightly higher scores than extractive models in terms of standard summary
evaluation metrics such as ROUGE and BLEU. However, we often find inconsistent
or hallucinated information in the generated abstractive summaries. Overall,
our investigation indicates that the pre-trained abstractive summarization
models and LLMs are not yet ready for fully automatic deployment for case
judgement summarization; rather a human-in-the-loop approach including manual
checks for inconsistencies is more suitable at present.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PassGPT: Password Modeling and (Guided) Generation with Large Language Models. (arXiv:2306.01545v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01545">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) successfully model natural language from vast
amounts of text without the need for explicit supervision. In this paper, we
investigate the efficacy of LLMs in modeling passwords. We present PassGPT, a
LLM trained on password leaks for password generation. PassGPT outperforms
existing methods based on generative adversarial networks (GAN) by guessing
twice as many previously unseen passwords. Furthermore, we introduce the
concept of guided password generation, where we leverage PassGPT sampling
procedure to generate passwords matching arbitrary constraints, a feat lacking
in current GAN-based strategies. Lastly, we conduct an in-depth analysis of the
entropy and probability distribution that PassGPT defines over passwords and
discuss their use in enhancing existing password strength estimators.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning from Partially Annotated Data: Example-aware Creation of Gap-filling Exercises for Language Learning. (arXiv:2306.01584v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01584">
<div class="article-summary-box-inner">
<span><p>Since performing exercises (including, e.g., practice tests) forms a crucial
component of learning, and creating such exercises requires non-trivial effort
from the teacher, there is a great value in automatic exercise generation in
digital tools in education. In this paper, we particularly focus on automatic
creation of gapfilling exercises for language learning, specifically grammar
exercises. Since providing any annotation in this domain requires human expert
effort, we aim to avoid it entirely and explore the task of converting existing
texts into new gap-filling exercises, purely based on an example exercise,
without explicit instruction or detailed annotation of the intended grammar
topics. We contribute (i) a novel neural network architecture specifically
designed for aforementioned gap-filling exercise generation task, and (ii) a
real-world benchmark dataset for French grammar. We show that our model for
this French grammar gap-filling exercise generation outperforms a competitive
baseline classifier by 8% in F1 percentage points, achieving an average F1
score of 82%. Our model implementation and the dataset are made publicly
available to foster future research, thus offering a standardized evaluation
and baseline solution of the proposed partially annotated data prediction task
in grammar exercise creation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MidMed: Towards Mixed-Type Dialogues for Medical Consultation. (arXiv:2306.02923v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.02923">
<div class="article-summary-box-inner">
<span><p>Most medical dialogue systems assume that patients have clear goals (medicine
querying, surgical operation querying, etc.) before medical consultation.
However, in many real scenarios, due to the lack of medical knowledge, it is
usually difficult for patients to determine clear goals with all necessary
slots. In this paper, we identify this challenge as how to construct medical
consultation dialogue systems to help patients clarify their goals. To mitigate
this challenge, we propose a novel task and create a human-to-human mixed-type
medical consultation dialogue corpus, termed MidMed, covering five dialogue
types: task-oriented dialogue for diagnosis, recommendation, knowledge-grounded
dialogue, QA, and chitchat. MidMed covers four departments
(otorhinolaryngology, ophthalmology, skin, and digestive system), with 8,175
dialogues. Furthermore, we build baselines on MidMed and propose an
instruction-guiding medical dialogue generation framework, termed InsMed, to
address this task. Experimental results show the effectiveness of InsMed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems. (arXiv:2306.04357v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.04357">
<div class="article-summary-box-inner">
<span><p>Dialogue response selection aims to select an appropriate response from
several candidates based on a given user and system utterance history. Recent
studies have been improving the accuracy of dialogue response selection through
post-training, mostly relying on naive masked language modeling methods.
However, the recently developed generative methods have shown promising text
representation capabilities in IR community, which could potentially lead to
better dialogue semantics modeling. Thus, in this paper, we propose Dial-MAE
(Dialogue Contextual Masking Auto-encoder), a straightforward yet effective
post-training technique tailored for dialogue response selection. Dial-MAE uses
an asymmetric encoder-decoder architecture that learns to better compress the
semantics of the dialogue into dialogue-dense vectors. The process of Dial-MAE
involves a deep encoder creating a dialogue embedding with the masked dialogue
context, followed by a shallow decoder that uses this embedding along with the
highly masked response to restore the original response. Our experiments have
demonstrated that Dial-MAE is highly effective, achieving state-of-the-art
performance on two commonly evaluated benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zambezi Voice: A Multilingual Speech Corpus for Zambian Languages. (arXiv:2306.04428v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.04428">
<div class="article-summary-box-inner">
<span><p>This work introduces Zambezi Voice, an open-source multilingual speech
resource for Zambian languages. It contains two collections of datasets:
unlabelled audio recordings of radio news and talk shows programs (160 hours)
and labelled data (over 80 hours) consisting of read speech recorded from text
sourced from publicly available literature books. The dataset is created for
speech recognition but can be extended to multilingual speech processing
research for both supervised and unsupervised learning approaches. To our
knowledge, this is the first multilingual speech dataset created for Zambian
languages. We exploit pretraining and cross-lingual transfer learning by
finetuning the Wav2Vec2.0 large-scale multilingual pre-trained model to build
end-to-end (E2E) speech recognition models for our baseline models. The dataset
is released publicly under a Creative Commons BY-NC-ND 4.0 license and can be
accessed via https://github.com/unza-speech-lab/zambezi-voice .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large Language Models. (arXiv:2306.04757v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.04757">
<div class="article-summary-box-inner">
<span><p>Instruction-tuned large language models have revolutionized natural language
processing and have shown great potential in applications such as
conversational agents. These models, such as GPT-4, can not only master
language but also solve complex tasks in areas like mathematics, coding,
medicine, and law. Despite their impressive capabilities, there is still a lack
of comprehensive understanding regarding their full potential, primarily due to
the black-box nature of many models and the absence of holistic evaluation
studies. To address these challenges, we present INSTRUCTEVAL, a more
comprehensive evaluation suite designed specifically for instruction-tuned
large language models. Unlike previous works, our evaluation involves a
rigorous assessment of models based on problem-solving, writing ability, and
alignment to human values. We take a holistic approach to analyze various
factors affecting model performance, including the pretraining foundation,
instruction-tuning data, and training methods. Our findings reveal that the
quality of instruction data is the most crucial factor in scaling model
performance. While open-source models demonstrate impressive writing abilities,
there is substantial room for improvement in problem-solving and alignment. We
are encouraged by the rapid development of models by the open-source community,
but we also highlight the need for rigorous evaluation to support claims made
about these models. Through INSTRUCTEVAL, we aim to foster a deeper
understanding of instruction-tuned models and advancements in their
capabilities. INSTRUCTEVAL is publicly available at
https://github.com/declare-lab/instruct-eval.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KIT's Multilingual Speech Translation System for IWSLT 2023. (arXiv:2306.05320v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.05320">
<div class="article-summary-box-inner">
<span><p>Many existing speech translation benchmarks focus on native-English speech in
high-quality recording conditions, which often do not match the conditions in
real-life use-cases. In this paper, we describe our speech translation system
for the multilingual track of IWSLT 2023, which evaluates translation quality
on scientific conference talks. The test condition features accented input
speech and terminology-dense contents. The task requires translation into 10
languages of varying amounts of resources. In absence of training data from the
target domain, we use a retrieval-based approach (kNN-MT) for effective
adaptation (+0.8 BLEU for speech translation). We also use adapters to easily
integrate incremental training data from data augmentation, and show that it
matches the performance of re-training. We observe that cascaded systems are
more easily adaptable towards specific target domains, due to their separate
modules. Our cascaded speech system substantially outperforms its end-to-end
counterpart on scientific talk translation, although their performance remains
similar on TED talks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in Language Models. (arXiv:2306.05659v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.05659">
<div class="article-summary-box-inner">
<span><p>Prompt-based learning has been proved to be an effective way in pre-trained
language models (PLMs), especially in low-resource scenarios like few-shot
settings. However, the trustworthiness of PLMs is of paramount significance and
potential vulnerabilities have been shown in prompt-based templates that could
mislead the predictions of language models, causing serious security concerns.
In this paper, we will shed light on some vulnerabilities of PLMs, by proposing
a prompt-based adversarial attack on manual templates in black box scenarios.
First of all, we design character-level and word-level heuristic approaches to
break manual templates separately. Then we present a greedy algorithm for the
attack based on the above heuristic destructive approaches. Finally, we
evaluate our approach with the classification tasks on three variants of BERT
series models and eight datasets. And comprehensive experimental results
justify the effectiveness of our approach in terms of attack success rate and
attack speed. Further experimental studies indicate that our proposed method
also displays good capabilities in scenarios with varying shot counts, template
lengths and query counts, exhibiting good generalizability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge Evaluation. (arXiv:2306.05783v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.05783">
<div class="article-summary-box-inner">
<span><p>New Natural Langauge Process~(NLP) benchmarks are urgently needed to align
with the rapid development of large language models (LLMs). We present Xiezhi,
the most comprehensive evaluation suite designed to assess holistic domain
knowledge. Xiezhi comprises multiple-choice questions across 516 diverse
disciplines ranging from 13 different subjects with 249,587 questions and
accompanied by Xiezhi-Specialty and Xiezhi-Interdiscipline, both with 15k
questions. We conduct evaluation of the 47 cutting-edge LLMs on Xiezhi. Results
indicate that LLMs exceed average performance of humans in science,
engineering, agronomy, medicine, and art, but fall short in economics,
jurisprudence, pedagogy, literature, history, and management. We anticipate
Xiezhi will help analyze important strengths and shortcomings of LLMs, and the
benchmark is released in~\url{https://github.com/MikeGu721/XiezhiBenchmark}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mind2Web: Towards a Generalist Agent for the Web. (arXiv:2306.06070v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.06070">
<div class="article-summary-box-inner">
<span><p>We introduce Mind2Web, the first dataset for developing and evaluating
generalist agents for the web that can follow language instructions to complete
complex tasks on any website. Existing datasets for web agents either use
simulated websites or only cover a limited set of websites and tasks, thus not
suitable for generalist web agents. With over 2,000 open-ended tasks collected
from 137 websites spanning 31 domains and crowdsourced action sequences for the
tasks, Mind2Web provides three necessary ingredients for building generalist
web agents: 1) diverse domains, websites, and tasks, 2) use of real-world
websites instead of simulated and simplified ones, and 3) a broad spectrum of
user interaction patterns. Based on Mind2Web, we conduct an initial exploration
of using large language models (LLMs) for building generalist web agents. While
the raw HTML of real-world websites are often too large to be fed to LLMs, we
show that first filtering it with a small LM significantly improves the
effectiveness and efficiency of LLMs. Our solution demonstrates a decent level
of performance, even on websites or entire domains the model has never seen
before, but there is still a substantial room to improve towards truly
generalizable agents. We open-source our dataset, model implementation, and
trained models (https://osu-nlp-group.github.io/Mind2Web) to facilitate further
research on building a generalist agent for the web.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Devil is in the Details: On the Pitfalls of Event Extraction Evaluation. (arXiv:2306.06918v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.06918">
<div class="article-summary-box-inner">
<span><p>Event extraction (EE) is a crucial task aiming at extracting events from
texts, which includes two subtasks: event detection (ED) and event argument
extraction (EAE). In this paper, we check the reliability of EE evaluations and
identify three major pitfalls: (1) The data preprocessing discrepancy makes the
evaluation results on the same dataset not directly comparable, but the data
preprocessing details are not widely noted and specified in papers. (2) The
output space discrepancy of different model paradigms makes different-paradigm
EE models lack grounds for comparison and also leads to unclear mapping issues
between predictions and annotations. (3) The absence of pipeline evaluation of
many EAE-only works makes them hard to be directly compared with EE works and
may not well reflect the model performance in real-world pipeline scenarios. We
demonstrate the significant influence of these pitfalls through comprehensive
meta-analyses of recent papers and empirical experiments. To avoid these
pitfalls, we suggest a series of remedies, including specifying data
preprocessing, standardizing outputs, and providing pipeline evaluation
results. To help implement these remedies, we develop a consistent evaluation
framework OMNIEVENT, which can be obtained from
https://github.com/THU-KEG/OmniEvent.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TrojPrompt: A Black-box Trojan Attack on Pre-trained Language Models. (arXiv:2306.06815v1 [cs.CR] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.06815">
<div class="article-summary-box-inner">
<span><p>Prompt learning has been proven to be highly effective in improving
pre-trained language model (PLM) adaptability, surpassing conventional
fine-tuning paradigms, and showing exceptional promise in an ever-growing
landscape of applications and APIs tailored for few-shot learning scenarios.
Despite the growing prominence of prompt learning-based APIs, their security
concerns remain underexplored. In this paper, we undertake a pioneering study
on the Trojan susceptibility of prompt-learning PLM APIs. We identified several
key challenges, including discrete-prompt, few-shot, and black-box settings,
which limit the applicability of existing backdoor attacks. To address these
challenges, we propose TrojPrompt, an automatic and black-box framework to
effectively generate universal and stealthy triggers and insert Trojans into
hard prompts. Specifically, we propose a universal API-driven trigger discovery
algorithm for generating universal triggers for various inputs by querying
victim PLM APIs using few-shot data samples. Furthermore, we introduce a novel
progressive trojan poisoning algorithm designed to generate poisoned prompts
that retain efficacy and transferability across a diverse range of models. Our
experiments and results demonstrate TrojPrompt's capacity to effectively insert
Trojans into text prompts in real-world black-box PLM APIs, while maintaining
exceptional performance on clean test sets and significantly outperforming
baseline models. Our work sheds light on the potential security risks in
current models and offers a potential defensive approach.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-06-16 23:11:37.366930769 UTC">2023-06-16 23:11:37 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>