<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-09-28T01:30:00Z">09-28</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Cognitive Maps and Planning in Large Language Models with CogEval. (arXiv:2309.15129v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15129">
<div class="article-summary-box-inner">
<span><p>Recently an influx of studies claim emergent cognitive abilities in large
language models (LLMs). Yet, most rely on anecdotes, overlook contamination of
training sets, or lack systematic Evaluation involving multiple tasks, control
conditions, multiple iterations, and statistical robustness tests. Here we make
two major contributions. First, we propose CogEval, a cognitive
science-inspired protocol for the systematic evaluation of cognitive capacities
in Large Language Models. The CogEval protocol can be followed for the
evaluation of various abilities. Second, here we follow CogEval to
systematically evaluate cognitive maps and planning ability across eight LLMs
(OpenAI GPT-4, GPT-3.5-turbo-175B, davinci-003-175B, Google Bard,
Cohere-xlarge-52.4B, Anthropic Claude-1-52B, LLaMA-13B, and Alpaca-7B). We base
our task prompts on human experiments, which offer both established construct
validity for evaluating planning, and are absent from LLM training sets. We
find that, while LLMs show apparent competence in a few planning tasks with
simpler structures, systematic evaluation reveals striking failure modes in
planning tasks, including hallucinations of invalid trajectories and getting
trapped in loops. These findings do not support the idea of emergent
out-of-the-box planning ability in LLMs. This could be because LLMs do not
understand the latent relational structures underlying planning problems, known
as cognitive maps, and fail at unrolling goal-directed trajectories based on
the underlying structure. Implications for application and future directions
are discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">STANCE-C3: Domain-adaptive Cross-target Stance Detection via Contrastive Learning and Counterfactual Generation. (arXiv:2309.15176v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15176">
<div class="article-summary-box-inner">
<span><p>Stance detection is the process of inferring a person's position or
standpoint on a specific issue to deduce prevailing perceptions toward topics
of general or controversial interest, such as health policies during the
COVID-19 pandemic. Existing models for stance detection are trained to perform
well for a single domain (e.g., COVID-19) and a specific target topic (e.g.,
masking protocols), but are generally ineffectual in other domains or targets
due to distributional shifts in the data. However, constructing
high-performing, domain-specific stance detection models requires an extensive
corpus of labeled data relevant to the targeted domain, yet such datasets are
not readily available. This poses a challenge as the process of annotating data
is costly and time-consuming. To address these challenges, we introduce a novel
stance detection model coined domain-adaptive Cross-target STANCE detection via
Contrastive learning and Counterfactual generation (STANCE-C3) that uses
counterfactual data augmentation to enhance domain-adaptive training by
enriching the target domain dataset during the training process and requiring
significantly less information from the new domain. We also propose a modified
self-supervised contrastive learning as a component of STANCE-C3 to prevent
overfitting for the existing domain and target and enable cross-target stance
detection. Through experiments on various datasets, we show that STANCE-C3
shows performance improvement over existing state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RAGAS: Automated Evaluation of Retrieval Augmented Generation. (arXiv:2309.15217v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15217">
<div class="article-summary-box-inner">
<span><p>We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework
for reference-free evaluation of Retrieval Augmented Generation (RAG)
pipelines. RAG systems are composed of a retrieval and an LLM based generation
module, and provide LLMs with knowledge from a reference textual database,
which enables them to act as a natural language layer between a user and
textual databases, reducing the risk of hallucinations. Evaluating RAG
architectures is, however, challenging because there are several dimensions to
consider: the ability of the retrieval system to identify relevant and focused
context passages, the ability of the LLM to exploit such passages in a faithful
way, or the quality of the generation itself. With RAGAs, we put forward a
suite of metrics which can be used to evaluate these different dimensions
\textit{without having to rely on ground truth human annotations}. We posit
that such a framework can crucially contribute to faster evaluation cycles of
RAG architectures, which is especially important given the fast adoption of
LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low-rank Adaptation of Large Language Model Rescoring for Parameter-Efficient Speech Recognition. (arXiv:2309.15223v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15223">
<div class="article-summary-box-inner">
<span><p>We propose a neural language modeling system based on low-rank adaptation
(LoRA) for speech recognition output rescoring. Although pretrained language
models (LMs) like BERT have shown superior performance in second-pass
rescoring, the high computational cost of scaling up the pretraining stage and
adapting the pretrained models to specific domains limit their practical use in
rescoring. Here we present a method based on low-rank decomposition to train a
rescoring BERT model and adapt it to new domains using only a fraction (0.08%)
of the pretrained parameters. These inserted matrices are optimized through a
discriminative training objective along with a correlation-based regularization
loss. The proposed low-rank adaptation Rescore-BERT (LoRB) architecture is
evaluated on LibriSpeech and internal datasets with decreased training times by
factors between 5.4 and 3.6.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Using Generated Privileged Information by Text-to-Image Diffusion Models. (arXiv:2309.15238v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15238">
<div class="article-summary-box-inner">
<span><p>Learning Using Privileged Information is a particular type of knowledge
distillation where the teacher model benefits from an additional data
representation during training, called privileged information, improving the
student model, which does not see the extra representation. However, privileged
information is rarely available in practice. To this end, we propose a text
classification framework that harnesses text-to-image diffusion models to
generate artificial privileged information. The generated images and the
original text samples are further used to train multimodal teacher models based
on state-of-the-art transformer-based architectures. Finally, the knowledge
from multimodal teachers is distilled into a text-based (unimodal) student.
Hence, by employing a generative model to produce synthetic data as privileged
information, we guide the training of the student model. Our framework, called
Learning Using Generated Privileged Information (LUGPI), yields noticeable
performance gains on four text classification data sets, demonstrating its
potential in text classification without any additional cost during inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">joint prediction and denoising for large-scale multilingual self-supervised learning. (arXiv:2309.15317v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15317">
<div class="article-summary-box-inner">
<span><p>Multilingual self-supervised learning (SSL) has often lagged behind
state-of-the-art (SOTA) methods due to the expenses and complexity required to
handle many languages. This further harms the reproducibility of SSL, which is
already limited to few research groups due to its resource usage. We show that
more powerful techniques can actually lead to more efficient pre-training,
opening SSL to more research groups. We propose WavLabLM, which extends WavLM's
joint prediction and denoising to 40k hours of data across 136 languages. To
build WavLabLM, we devise a novel multi-stage pre-training method, designed to
address the language imbalance of multilingual data. WavLabLM achieves
comparable performance to XLS-R on ML-SUPERB with less than 10% of the training
data, making SSL realizable with academic compute. We show that further
efficiency can be achieved with a vanilla HuBERT Base model, which can maintain
94% of XLS-R's performance with only 3% of the data, 4 GPUs, and limited
trials. We open-source all code and models in ESPnet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond the Chat: Executable and Verifiable Text-Editing with LLMs. (arXiv:2309.15337v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15337">
<div class="article-summary-box-inner">
<span><p>Conversational interfaces powered by Large Language Models (LLMs) have
recently become a popular way to obtain feedback during document editing.
However, standard chat-based conversational interfaces do not support
transparency and verifiability of the editing changes that they suggest. To
give the author more agency when editing with an LLM, we present InkSync, an
editing interface that suggests executable edits directly within the document
being edited. Because LLMs are known to introduce factual errors, Inksync also
supports a 3-stage approach to mitigate this risk: Warn authors when a
suggested edit introduces new information, help authors Verify the new
information's accuracy through external search, and allow an auditor to perform
an a-posteriori verification by Auditing the document via a trace of all
auto-generated content. Two usability studies confirm the effectiveness of
InkSync's components when compared to standard LLM-based chat interfaces,
leading to more accurate, more efficient editing, and improved user experience.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future. (arXiv:2309.15402v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15402">
<div class="article-summary-box-inner">
<span><p>Chain-of-thought reasoning, a cognitive process fundamental to human
intelligence, has garnered significant attention in the realm of artificial
intelligence and natural language processing. However, there still remains a
lack of a comprehensive survey for this arena. To this end, we take the first
step and present a thorough survey of this research field carefully and widely.
We use X-of-Thought to refer to Chain-of-Thought in a broad sense. In detail,
we systematically organize the current research according to the taxonomies of
methods, including XoT construction, XoT structure variants, and enhanced XoT.
Additionally, we describe XoT with frontier applications, covering planning,
tool use, and distillation. Furthermore, we address challenges and discuss some
future directions, including faithfulness, multi-modal, and theory. We hope
this survey serves as a valuable resource for researchers seeking to innovate
within the domain of chain-of-thought reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph Neural Prompting with Large Language Models. (arXiv:2309.15427v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15427">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have shown remarkable generalization capability
with exceptional performance in various language modeling tasks. However, they
still exhibit inherent limitations in precisely capturing and returning
grounded knowledge. While existing work has explored utilizing knowledge graphs
to enhance language modeling via joint training and customized model
architectures, applying this to LLMs is problematic owing to their large number
of parameters and high computational cost. In addition, how to leverage the
pre-trained LLMs and avoid training a customized model from scratch remains an
open question. In this work, we propose Graph Neural Prompting (GNP), a novel
plug-and-play method to assist pre-trained LLMs in learning beneficial
knowledge from KGs. GNP encompasses various designs, including a standard graph
neural network encoder, a cross-modality pooling module, a domain projector,
and a self-supervised link prediction objective. Extensive experiments on
multiple datasets demonstrate the superiority of GNP on both commonsense and
biomedical reasoning tasks across different LLM sizes and settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatCounselor: A Large Language Models for Mental Health Support. (arXiv:2309.15461v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15461">
<div class="article-summary-box-inner">
<span><p>This paper presents ChatCounselor, a large language model (LLM) solution
designed to provide mental health support. Unlike generic chatbots,
ChatCounselor is distinguished by its foundation in real conversations between
consulting clients and professional psychologists, enabling it to possess
specialized knowledge and counseling skills in the field of psychology. The
training dataset, Psych8k, was constructed from 260 in-depth interviews, each
spanning an hour. To assess the quality of counseling responses, the counseling
Bench was devised. Leveraging GPT-4 and meticulously crafted prompts based on
seven metrics of psychological counseling assessment, the model underwent
evaluation using a set of real-world counseling questions. Impressively,
ChatCounselor surpasses existing open-source models in the counseling Bench and
approaches the performance level of ChatGPT, showcasing the remarkable
enhancement in model capability attained through high-quality domain-specific
data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Multi-Scale Context Aggregation for Conversational Aspect-Based Sentiment Quadruple Analysis. (arXiv:2309.15476v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15476">
<div class="article-summary-box-inner">
<span><p>Conversational aspect-based sentiment quadruple analysis (DiaASQ) aims to
extract the quadruple of target-aspect-opinion-sentiment within a dialogue. In
DiaASQ, a quadruple's elements often cross multiple utterances. This situation
complicates the extraction process, emphasizing the need for an adequate
understanding of conversational context and interactions. However, existing
work independently encodes each utterance, thereby struggling to capture
long-range conversational context and overlooking the deep inter-utterance
dependencies. In this work, we propose a novel Dynamic Multi-scale Context
Aggregation network (DMCA) to address the challenges. Specifically, we first
utilize dialogue structure to generate multi-scale utterance windows for
capturing rich contextual information. After that, we design a Dynamic
Hierarchical Aggregation module (DHA) to integrate progressive cues between
them. In addition, we form a multi-stage loss strategy to improve model
performance and generalization ability. Extensive experimental results show
that the DMCA model outperforms baselines significantly and achieves
state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VideoAdviser: Video Knowledge Distillation for Multimodal Transfer Learning. (arXiv:2309.15494v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15494">
<div class="article-summary-box-inner">
<span><p>Multimodal transfer learning aims to transform pretrained representations of
diverse modalities into a common domain space for effective multimodal fusion.
However, conventional systems are typically built on the assumption that all
modalities exist, and the lack of modalities always leads to poor inference
performance. Furthermore, extracting pretrained embeddings for all modalities
is computationally inefficient for inference. In this work, to achieve high
efficiency-performance multimodal transfer learning, we propose VideoAdviser, a
video knowledge distillation method to transfer multimodal knowledge of
video-enhanced prompts from a multimodal fundamental model (teacher) to a
specific modal fundamental model (student). With an intuition that the best
learning performance comes with professional advisers and smart students, we
use a CLIP-based teacher model to provide expressive multimodal knowledge
supervision signals to a RoBERTa-based student model via optimizing a
step-distillation objective loss -- first step: the teacher distills multimodal
knowledge of video-enhanced prompts from classification logits to a regression
logit -- second step: the multimodal knowledge is distilled from the regression
logit of the teacher to the student. We evaluate our method in two challenging
multimodal tasks: video-level sentiment analysis (MOSI and MOSEI datasets) and
audio-visual retrieval (VEGAS dataset). The student (requiring only the text
modality as input) achieves an MAE score improvement of up to 12.3% for MOSI
and MOSEI. Our method further enhances the state-of-the-art method by 3.4% mAP
score for VEGAS without additional computations for inference. These results
suggest the strengths of our method for achieving high efficiency-performance
multimodal transfer learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">High-Fidelity Speech Synthesis with Minimal Supervision: All Using Diffusion Models. (arXiv:2309.15512v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15512">
<div class="article-summary-box-inner">
<span><p>Text-to-speech (TTS) methods have shown promising results in voice cloning,
but they require a large number of labeled text-speech pairs.
Minimally-supervised speech synthesis decouples TTS by combining two types of
discrete speech representations(semantic \&amp; acoustic) and using two
sequence-to-sequence tasks to enable training with minimal supervision.
However, existing methods suffer from information redundancy and dimension
explosion in semantic representation, and high-frequency waveform distortion in
discrete acoustic representation. Autoregressive frameworks exhibit typical
instability and uncontrollability issues. And non-autoregressive frameworks
suffer from prosodic averaging caused by duration prediction models. To address
these issues, we propose a minimally-supervised high-fidelity speech synthesis
method, where all modules are constructed based on the diffusion models. The
non-autoregressive framework enhances controllability, and the duration
diffusion model enables diversified prosodic expression. Contrastive
Token-Acoustic Pretraining (CTAP) is used as an intermediate semantic
representation to solve the problems of information redundancy and dimension
explosion in existing semantic coding methods. Mel-spectrogram is used as the
acoustic representation. Both semantic and acoustic representations are
predicted by continuous variable regression tasks to solve the problem of
high-frequency fine-grained waveform distortion. Experimental results show that
our proposed method outperforms the baseline method. We provide audio samples
on our website.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teaching Text-to-Image Models to Communicate. (arXiv:2309.15516v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15516">
<div class="article-summary-box-inner">
<span><p>Various works have been extensively studied in the research of text-to-image
generation. Although existing models perform well in text-to-image generation,
there are significant challenges when directly employing them to generate
images in dialogs. In this paper, we first highlight a new problem:
dialog-to-image generation, that is, given the dialog context, the model should
generate a realistic image which is consistent with the specified conversation
as response. To tackle the problem, we propose an efficient approach for
dialog-to-image generation without any intermediate translation, which
maximizes the extraction of the semantic information contained in the dialog.
Considering the characteristics of dialog structure, we put segment token
before each sentence in a turn of a dialog to differentiate different speakers.
Then, we fine-tune pre-trained text-to-image models to enable them to generate
images conditioning on processed dialog context. After fine-tuning, our
approach can consistently improve the performance of various models across
multiple metrics. Experimental results on public benchmark demonstrate the
effectiveness and practicability of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Direct Models for Simultaneous Translation and Automatic Subtitling: FBK@IWSLT2023. (arXiv:2309.15554v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15554">
<div class="article-summary-box-inner">
<span><p>This paper describes the FBK's participation in the Simultaneous Translation
and Automatic Subtitling tracks of the IWSLT 2023 Evaluation Campaign. Our
submission focused on the use of direct architectures to perform both tasks:
for the simultaneous one, we leveraged the knowledge already acquired by
offline-trained models and directly applied a policy to obtain the real-time
inference; for the subtitling one, we adapted the direct ST model to produce
well-formed subtitles and exploited the same architecture to produce timestamps
needed for the subtitle synchronization with audiovisual content. Our
English-German SimulST system shows a reduced computational-aware latency
compared to the one achieved by the top-ranked systems in the 2021 and 2022
rounds of the task, with gains of up to 3.5 BLEU. Our automatic subtitling
system outperforms the only existing solution based on a direct system by 3.7
and 1.7 SubER in English-German and English-Spanish respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Jointly Training Large Autoregressive Multimodal Models. (arXiv:2309.15564v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15564">
<div class="article-summary-box-inner">
<span><p>In recent years, advances in the large-scale pretraining of language and
text-to-image models have revolutionized the field of machine learning. Yet,
integrating these two modalities into a single, robust model capable of
generating seamless multimodal outputs remains a significant challenge. To
address this gap, we present the Joint Autoregressive Mixture (JAM) framework,
a modular approach that systematically fuses existing text and image generation
models. We also introduce a specialized, data-efficient instruction-tuning
strategy, tailored for mixed-modal generation tasks. Our final instruct-tuned
model demonstrates unparalleled performance in generating high-quality
multimodal outputs and represents the first model explicitly designed for this
purpose.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Multi-Label Aspect Category Detection Utilizing Prototypical Network with Sentence-Level Weighting and Label Augmentation. (arXiv:2309.15588v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15588">
<div class="article-summary-box-inner">
<span><p>Multi-label aspect category detection is intended to detect multiple aspect
categories occurring in a given sentence. Since aspect category detection often
suffers from limited datasets and data sparsity, the prototypical network with
attention mechanisms has been applied for few-shot aspect category detection.
Nevertheless, most of the prototypical networks used so far calculate the
prototypes by taking the mean value of all the instances in the support set.
This seems to ignore the variations between instances in multi-label aspect
category detection. Also, several related works utilize label text information
to enhance the attention mechanism. However, the label text information is
often short and limited, and not specific enough to discern categories. In this
paper, we first introduce support set attention along with the augmented label
information to mitigate the noise at word-level for each support set instance.
Moreover, we use a sentence-level attention mechanism that gives different
weights to each instance in the support set in order to compute prototypes by
weighted averaging. Finally, the calculated prototypes are further used in
conjunction with query instances to compute query attention and thereby
eliminate noises from the query set. Experimental results on the Yelp dataset
show that our proposed method is useful and outperforms all baselines in four
different scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Developing automatic verbatim transcripts for international multilingual meetings: an end-to-end solution. (arXiv:2309.15609v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15609">
<div class="article-summary-box-inner">
<span><p>This paper presents an end-to-end solution for the creation of fully
automated conference meeting transcripts and their machine translations into
various languages. This tool has been developed at the World Intellectual
Property Organization (WIPO) using in-house developed speech-to-text (S2T) and
machine translation (MT) components. Beyond describing data collection and
fine-tuning, resulting in a highly customized and robust system, this paper
describes the architecture and evolution of the technical components as well as
highlights the business impact and benefits from the user side. We also point
out particular challenges in the evolution and adoption of the system and how
the new approach created a new product and replaced existing established
workflows in conference management documentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NLPBench: Evaluating Large Language Models on Solving NLP Problems. (arXiv:2309.15630v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15630">
<div class="article-summary-box-inner">
<span><p>Recent developments in large language models (LLMs) have shown promise in
enhancing the capabilities of natural language processing (NLP). Despite these
successes, there remains a dearth of research dedicated to the NLP
problem-solving abilities of LLMs. To fill the gap in this area, we present a
unique benchmarking dataset, NLPBench, comprising 378 college-level NLP
questions spanning various NLP topics sourced from Yale University's prior
final exams. NLPBench includes questions with context, in which multiple
sub-questions share the same public information, and diverse question types,
including multiple choice, short answer, and math. Our evaluation, centered on
LLMs such as GPT-3.5/4, PaLM-2, and LLAMA-2, incorporates advanced prompting
strategies like the chain-of-thought (CoT) and tree-of-thought (ToT). Our study
reveals that the effectiveness of the advanced prompting strategies can be
inconsistent, occasionally damaging LLM performance, especially in smaller
models like the LLAMA-2 (13b). Furthermore, our manual assessment illuminated
specific shortcomings in LLMs' scientific problem-solving skills, with
weaknesses in logical decomposition and reasoning notably affecting results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Speech Recognition Error Correction with Large Language Models. (arXiv:2309.15649v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15649">
<div class="article-summary-box-inner">
<span><p>We explore the ability of large language models (LLMs) to act as ASR
post-processors that perform rescoring and error correction. Our focus is on
instruction prompting to let LLMs perform these task without fine-tuning, for
which we evaluate different prompting schemes, both zero- and few-shot
in-context learning, and a novel task-activating prompting (TAP) method that
combines instruction and demonstration. Using a pre-trained first-pass system
and rescoring output on two out-of-domain tasks (ATIS and WSJ), we show that
rescoring only by in-context learning with frozen LLMs achieves results that
are competitive with rescoring by domain-tuned LMs. By combining prompting
techniques with fine-tuning we achieve error rates below the N-best oracle
level, showcasing the generalization power of the LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conversational Feedback in Scripted versus Spontaneous Dialogues: A Comparative Analysis. (arXiv:2309.15656v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15656">
<div class="article-summary-box-inner">
<span><p>Scripted dialogues such as movie and TV subtitles constitute a widespread
source of training data for conversational NLP models. However, the linguistic
characteristics of those dialogues are notably different from those observed in
corpora of spontaneous interactions. This difference is particularly marked for
communicative feedback and grounding phenomena such as backchannels,
acknowledgments, or clarification requests. Such signals are known to
constitute a key part of the conversation flow and are used by the dialogue
participants to provide feedback to one another on their perception of the
ongoing interaction. This paper presents a quantitative analysis of such
communicative feedback phenomena in both subtitles and spontaneous
conversations. Based on dialogue data in English, French, German, Hungarian,
Italian, Japanese, Norwegian and Chinese, we extract both lexical statistics
and classification outputs obtained with a neural dialogue act tagger. Two main
findings of this empirical study are that (1) conversational feedback is
markedly less frequent in subtitles than in spontaneous dialogues and (2)
subtitles contain a higher proportion of negative feedback. Furthermore, we
show that dialogue responses generated by large language models also follow the
same underlying trends and include comparatively few occurrences of
communicative feedback, except when those models are explicitly fine-tuned on
spontaneous dialogues.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MONOVAB : An Annotated Corpus for Bangla Multi-label Emotion Detection. (arXiv:2309.15670v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15670">
<div class="article-summary-box-inner">
<span><p>In recent years, Sentiment Analysis (SA) and Emotion Recognition (ER) have
been increasingly popular in the Bangla language, which is the seventh most
spoken language throughout the entire world. However, the language is
structurally complicated, which makes this field arduous to extract emotions in
an accurate manner. Several distinct approaches such as the extraction of
positive and negative sentiments as well as multiclass emotions, have been
implemented in this field of study. Nevertheless, the extraction of multiple
sentiments is an almost untouched area in this language. Which involves
identifying several feelings based on a single piece of text. Therefore, this
study demonstrates a thorough method for constructing an annotated corpus based
on scrapped data from Facebook to bridge the gaps in this subject area to
overcome the challenges. To make this annotation more fruitful, the
context-based approach has been used. Bidirectional Encoder Representations
from Transformers (BERT), a well-known methodology of transformers, have been
shown the best results of all methods implemented. Finally, a web application
has been developed to demonstrate the performance of the pre-trained
top-performer model (BERT) for multi-label ER in Bangla.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speech collage: code-switched audio generation by collaging monolingual corpora. (arXiv:2309.15674v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15674">
<div class="article-summary-box-inner">
<span><p>Designing effective automatic speech recognition (ASR) systems for
Code-Switching (CS) often depends on the availability of the transcribed CS
resources. To address data scarcity, this paper introduces Speech Collage, a
method that synthesizes CS data from monolingual corpora by splicing audio
segments. We further improve the smoothness quality of audio generation using
an overlap-add approach. We investigate the impact of generated data on speech
recognition in two scenarios: using in-domain CS text and a zero-shot approach
with synthesized CS text. Empirical results highlight up to 34.4% and 16.2%
relative reductions in Mixed-Error Rate and Word-Error Rate for in-domain and
zero-shot scenarios, respectively. Lastly, we demonstrate that CS augmentation
bolsters the model's code-switching inclination and reduces its monolingual
bias.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing End-to-End Conversational Speech Translation Through Target Language Context Utilization. (arXiv:2309.15686v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15686">
<div class="article-summary-box-inner">
<span><p>Incorporating longer context has been shown to benefit machine translation,
but the inclusion of context in end-to-end speech translation (E2E-ST) remains
under-studied. To bridge this gap, we introduce target language context in
E2E-ST, enhancing coherence and overcoming memory constraints of extended audio
segments. Additionally, we propose context dropout to ensure robustness to the
absence of context, and further improve performance by adding speaker
information. Our proposed contextual E2E-ST outperforms the isolated
utterance-based E2E-ST approach. Lastly, we demonstrate that in conversational
speech, contextual information primarily contributes to capturing context
style, as well as resolving anaphora and named entities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HyPoradise: An Open Baseline for Generative Speech Recognition with Large Language Models. (arXiv:2309.15701v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15701">
<div class="article-summary-box-inner">
<span><p>Advancements in deep neural networks have allowed automatic speech
recognition (ASR) systems to attain human parity on several publicly available
clean speech datasets. However, even state-of-the-art ASR systems experience
performance degradation when confronted with adverse conditions, as a
well-trained acoustic model is sensitive to variations in the speech domain,
e.g., background noise. Intuitively, humans address this issue by relying on
their linguistic knowledge: the meaning of ambiguous spoken terms is usually
inferred from contextual cues thereby reducing the dependency on the auditory
system. Inspired by this observation, we introduce the first open-source
benchmark to utilize external large language models (LLMs) for ASR error
correction, where N-best decoding hypotheses provide informative elements for
true transcription prediction. This approach is a paradigm shift from the
traditional language model rescoring strategy that can only select one
candidate hypothesis as the output transcription. The proposed benchmark
contains a novel dataset, HyPoradise (HP), encompassing more than 334,000 pairs
of N-best hypotheses and corresponding accurate transcriptions across prevalent
speech domains. Given this dataset, we examine three types of error correction
techniques based on LLMs with varying amounts of labeled
hypotheses-transcription pairs, which gains a significant word error rate (WER)
reduction. Experimental evidence demonstrates the proposed technique achieves a
breakthrough by surpassing the upper bound of traditional re-ranking based
methods. More surprisingly, LLM with reasonable prompt and its generative
capability can even correct those tokens that are missing in N-best list. We
make our results publicly accessible for reproducible pipelines with released
pre-trained models, thus providing a new evaluation paradigm for ASR error
correction with LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT-BCI: Word-Level Neural State Classification Using GPT, EEG, and Eye-Tracking Biomarkers in Semantic Inference Reading Comprehension. (arXiv:2309.15714v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15714">
<div class="article-summary-box-inner">
<span><p>With the recent explosion of large language models (LLMs), such as Generative
Pretrained Transformers (GPT), the need to understand the ability of humans and
machines to comprehend semantic language meaning has entered a new phase. This
requires interdisciplinary research that bridges the fields of cognitive
science and natural language processing (NLP). This pilot study aims to provide
insights into individuals' neural states during a semantic relation
reading-comprehension task. We propose jointly analyzing LLMs, eye-gaze, and
electroencephalographic (EEG) data to study how the brain processes words with
varying degrees of relevance to a keyword during reading. We also use a feature
engineering approach to improve the fixation-related EEG data classification
while participants read words with high versus low relevance to the keyword.
The best validation accuracy in this word-level classification is over 60\%
across 12 subjects. Words of high relevance to the inference keyword had
significantly more eye fixations per word: 1.0584 compared to 0.6576 when
excluding no-fixation words, and 1.5126 compared to 1.4026 when including them.
This study represents the first attempt to classify brain states at a word
level using LLM knowledge. It provides valuable insights into human cognitive
abilities and the realm of Artificial General Intelligence (AGI), and offers
guidance for developing potential reading-assisted technologies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Experience and Evidence are the eyes of an excellent summarizer! Towards Knowledge Infused Multi-modal Clinical Conversation Summarization. (arXiv:2309.15739v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15739">
<div class="article-summary-box-inner">
<span><p>With the advancement of telemedicine, both researchers and medical
practitioners are working hand-in-hand to develop various techniques to
automate various medical operations, such as diagnosis report generation. In
this paper, we first present a multi-modal clinical conversation summary
generation task that takes a clinician-patient interaction (both textual and
visual information) and generates a succinct synopsis of the conversation. We
propose a knowledge-infused, multi-modal, multi-tasking medical domain
identification and clinical conversation summary generation
(MM-CliConSummation) framework. It leverages an adapter to infuse knowledge and
visual features and unify the fused feature vector using a gated mechanism.
Furthermore, we developed a multi-modal, multi-intent clinical conversation
summarization corpus annotated with intent, symptom, and summary. The extensive
set of experiments, both quantitatively and qualitatively, led to the following
findings: (a) critical significance of visuals, (b) more precise and medical
entity preserving summary with additional knowledge infusion, and (c) a
correlation between medical department identification and clinical synopsis
generation. Furthermore, the dataset and source code are available at
https://github.com/NLP-RL/MM-CliConSummation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Question answering using deep learning in low resource Indian language Marathi. (arXiv:2309.15779v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15779">
<div class="article-summary-box-inner">
<span><p>Precise answers are extracted from a text for a given input question in a
question answering system. Marathi question answering system is created in
recent studies by using ontology, rule base and machine learning based
approaches. Recently transformer models and transfer learning approaches are
used to solve question answering challenges. In this paper we investigate
different transformer models for creating a reading comprehension-based Marathi
question answering system. We have experimented on different pretrained Marathi
language multilingual and monolingual models like Multilingual Representations
for Indian Languages (MuRIL), MahaBERT, Indic Bidirectional Encoder
Representations from Transformers (IndicBERT) and fine-tuned it on a Marathi
reading comprehension-based data set. We got the best accuracy in a MuRIL
multilingual model with an EM score of 0.64 and F1 score of 0.74 by fine tuning
the model on the Marathi dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Model Routing with Benchmark Datasets. (arXiv:2309.15789v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15789">
<div class="article-summary-box-inner">
<span><p>There is a rapidly growing number of open-source Large Language Models (LLMs)
and benchmark datasets to compare them. While some models dominate these
benchmarks, no single model typically achieves the best accuracy in all tasks
and use cases. In this work, we address the challenge of selecting the best LLM
out of a collection of models for new tasks. We propose a new formulation for
the problem, in which benchmark datasets are repurposed to learn a "router"
model for this LLM selection, and we show that this problem can be reduced to a
collection of binary classification tasks. We demonstrate the utility and
limitations of learning model routers from various benchmark datasets, where we
consistently improve performance upon using any single model for all tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning from Flawed Data: Weakly Supervised Automatic Speech Recognition. (arXiv:2309.15796v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15796">
<div class="article-summary-box-inner">
<span><p>Training automatic speech recognition (ASR) systems requires large amounts of
well-curated paired data. However, human annotators usually perform
"non-verbatim" transcription, which can result in poorly trained models. In
this paper, we propose Omni-temporal Classification (OTC), a novel training
criterion that explicitly incorporates label uncertainties originating from
such weak supervision. This allows the model to effectively learn speech-text
alignments while accommodating errors present in the training transcripts. OTC
extends the conventional CTC objective for imperfect transcripts by leveraging
weighted finite state transducers. Through experiments conducted on the
LibriSpeech and LibriVox datasets, we demonstrate that training ASR models with
OTC avoids performance degradation even with transcripts containing up to 70%
errors, a scenario where CTC models fail completely. Our implementation is
available at https://github.com/k2-fsa/icefall.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study. (arXiv:2309.15800v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15800">
<div class="article-summary-box-inner">
<span><p>Speech signals, typically sampled at rates in the tens of thousands per
second, contain redundancies, evoking inefficiencies in sequence modeling.
High-dimensional speech features such as spectrograms are often used as the
input for the subsequent model. However, they can still be redundant. Recent
investigations proposed the use of discrete speech units derived from
self-supervised learning representations, which significantly compresses the
size of speech data. Applying various methods, such as de-duplication and
subword modeling, can further compress the speech sequence length. Hence,
training time is significantly reduced while retaining notable performance. In
this study, we undertake a comprehensive and systematic exploration into the
application of discrete units within end-to-end speech processing models.
Experiments on 12 automatic speech recognition, 3 speech translation, and 1
spoken language understanding corpora demonstrate that discrete units achieve
reasonably good results in almost all the settings. We intend to release our
configurations and trained models to foster future research efforts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lyra: Orchestrating Dual Correction in Automated Theorem Proving. (arXiv:2309.15806v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15806">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) present an intriguing avenue for exploration in
the field of formal theorem proving. Nevertheless, their full potential,
particularly concerning the mitigation of hallucinations and refinement through
prover error messages, remains an area that has yet to be thoroughly
investigated. To enhance the effectiveness of LLMs in the field, we introduce
the Lyra, a new framework that employs two distinct correction mechanisms: Tool
Correction (TC) and Conjecture Correction (CC). To implement Tool Correction in
the post-processing of formal proofs, we leverage prior knowledge to utilize
predefined prover tools (e.g., Sledgehammer) for guiding the replacement of
incorrect tools. Tool Correction significantly contributes to mitigating
hallucinations, thereby improving the overall accuracy of the proof. In
addition, we introduce Conjecture Correction, an error feedback mechanism
designed to interact with prover to refine formal proof conjectures with prover
error messages. Compared to the previous refinement framework, the proposed
Conjecture Correction refines generation with instruction but does not collect
paired (generation, error &amp; refinement) prompts. Our method has achieved
state-of-the-art (SOTA) performance on both miniF2F validation (48.0% -&gt; 55.3%)
and test (45.5% -&gt; 51.2%). We also present 3 IMO problems solved by Lyra. We
believe Tool Correction (post-process for hallucination mitigation) and
Conjecture Correction (subgoal adjustment from interaction with environment)
could provide a promising avenue for future research in this field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identifying the Risks of LM Agents with an LM-Emulated Sandbox. (arXiv:2309.15817v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15817">
<div class="article-summary-box-inner">
<span><p>Recent advances in Language Model (LM) agents and tool use, exemplified by
applications like ChatGPT Plugins, enable a rich set of capabilities but also
amplify potential risks - such as leaking private data or causing financial
losses. Identifying these risks is labor-intensive, necessitating implementing
the tools, manually setting up the environment for each test scenario, and
finding risky cases. As tools and agents become more complex, the high cost of
testing these agents will make it increasingly difficult to find high-stakes,
long-tailed risks. To address these challenges, we introduce ToolEmu: a
framework that uses an LM to emulate tool execution and enables the testing of
LM agents against a diverse range of tools and scenarios, without manual
instantiation. Alongside the emulator, we develop an LM-based automatic safety
evaluator that examines agent failures and quantifies associated risks. We test
both the tool emulator and evaluator through human evaluation and find that
68.8% of failures identified with ToolEmu would be valid real-world agent
failures. Using our curated initial benchmark consisting of 36 high-stakes
tools and 144 test cases, we provide a quantitative risk analysis of current LM
agents and identify numerous failures with potentially severe outcomes.
Notably, even the safest LM agent exhibits such failures 23.9% of the time
according to our evaluator, underscoring the need to develop safer LM agents
for real-world deployment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing. (arXiv:2309.15826v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15826">
<div class="article-summary-box-inner">
<span><p>Recent works in end-to-end speech-to-text translation (ST) have proposed
multi-tasking methods with soft parameter sharing which leverage machine
translation (MT) data via secondary encoders that map text inputs to an
eventual cross-modal representation. In this work, we instead propose a ST/MT
multi-tasking framework with hard parameter sharing in which all model
parameters are shared cross-modally. Our method reduces the speech-text
modality gap via a pre-processing stage which converts speech and text inputs
into two discrete token sequences of similar length -- this allows models to
indiscriminately process both modalities simply using a joint vocabulary. With
experiments on MuST-C, we demonstrate that our multi-tasking framework improves
attentional encoder-decoder, Connectionist Temporal Classification (CTC),
transducer, and joint CTC/attention models by an average of +0.5 BLEU without
any external MT data. Further, we show that this framework incorporates
external MT data, yielding +0.8 BLEU, and also improves transfer learning from
pre-trained textual models, yielding +1.8 BLEU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How We Define Harm Impacts Data Annotations: Explaining How Annotators Distinguish Hateful, Offensive, and Toxic Comments. (arXiv:2309.15827v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15827">
<div class="article-summary-box-inner">
<span><p>Computational social science research has made advances in machine learning
and natural language processing that support content moderators in detecting
harmful content. These advances often rely on training datasets annotated by
crowdworkers for harmful content. In designing instructions for annotation
tasks to generate training data for these algorithms, researchers often treat
the harm concepts that we train algorithms to detect - 'hateful', 'offensive',
'toxic', 'racist', 'sexist', etc. - as interchangeable. In this work, we
studied whether the way that researchers define 'harm' affects annotation
outcomes. Using Venn diagrams, information gain comparisons, and content
analyses, we reveal that annotators do not use the concepts 'hateful',
'offensive', and 'toxic' interchangeably. We identify that features of harm
definitions and annotators' individual characteristics explain much of how
annotators use these terms differently. Our results offer empirical evidence
discouraging the common practice of using harm concepts interchangeably in
content moderation research. Instead, researchers should make specific choices
about which harm concepts to analyze based on their research goals. Recognizing
that researchers are often resource constrained, we also encourage researchers
to provide information to bound their findings when their concepts of interest
differ from concepts that off-the-shelf harmful content detection algorithms
identify. Finally, we encourage algorithm providers to ensure their instruments
can adapt to contextually-specific content detection goals (e.g., soliciting
instrument users' feedback).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions. (arXiv:2309.15840v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15840">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) can "lie", which we define as outputting false
statements despite "knowing" the truth in a demonstrable sense. LLMs might
"lie", for example, when instructed to output misinformation. Here, we develop
a simple lie detector that requires neither access to the LLM's activations
(black-box) nor ground-truth knowledge of the fact in question. The detector
works by asking a predefined set of unrelated follow-up questions after a
suspected lie, and feeding the LLM's yes/no answers into a logistic regression
classifier. Despite its simplicity, this lie detector is highly accurate and
surprisingly general. When trained on examples from a single setting --
prompting GPT-3.5 to lie about factual questions -- the detector generalises
out-of-distribution to (1) other LLM architectures, (2) LLMs fine-tuned to lie,
(3) sycophantic lies, and (4) lies emerging in real-life scenarios such as
sales. These results indicate that LLMs have distinctive lie-related
behavioural patterns, consistent across architectures and contexts, which could
enable general-purpose lie detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disinformation Detection: An Evolving Challenge in the Age of LLMs. (arXiv:2309.15847v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15847">
<div class="article-summary-box-inner">
<span><p>The advent of generative Large Language Models (LLMs) such as ChatGPT has
catalyzed transformative advancements across multiple domains. However,
alongside these advancements, they have also introduced potential threats. One
critical concern is the misuse of LLMs by disinformation spreaders, leveraging
these models to generate highly persuasive yet misleading content that
challenges the disinformation detection system. This work aims to address this
issue by answering three research questions: (1) To what extent can the current
disinformation detection technique reliably detect LLM-generated
disinformation? (2) If traditional techniques prove less effective, can LLMs
themself be exploited to serve as a robust defense against advanced
disinformation? and, (3) Should both these strategies falter, what novel
approaches can be proposed to counter this burgeoning threat effectively? A
holistic exploration for the formation and detection of disinformation is
conducted to foster this line of research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Overcoming Referential Ambiguity in Language-Guided Goal-Conditioned Reinforcement Learning. (arXiv:2209.12758v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.12758">
<div class="article-summary-box-inner">
<span><p>Teaching an agent to perform new tasks using natural language can easily be
hindered by ambiguities in interpretation. When a teacher provides an
instruction to a learner about an object by referring to its features, the
learner can misunderstand the teacher's intentions, for instance if the
instruction ambiguously refer to features of the object, a phenomenon called
referential ambiguity. We study how two concepts derived from cognitive
sciences can help resolve those referential ambiguities: pedagogy (selecting
the right instructions) and pragmatism (learning the preferences of the other
agents using inductive reasoning). We apply those ideas to a teacher/learner
setup with two artificial agents on a simulated robotic task (block-stacking).
We show that these concepts improve sample efficiency for training the learner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Late Audio-Visual Fusion for In-The-Wild Speaker Diarization. (arXiv:2211.01299v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.01299">
<div class="article-summary-box-inner">
<span><p>Speaker diarization is well studied for constrained audios but little
explored for challenging in-the-wild videos, which have more speakers, shorter
utterances, and inconsistent on-screen speakers. We address this gap by
proposing an audio-visual diarization model which combines audio-only and
visual-centric sub-systems via late fusion. For audio, we show that an
attractor-based end-to-end system (EEND-EDA) performs remarkably well when
trained with our proposed recipe of a simulated proxy dataset, and propose an
improved version, EEND-EDA++, that uses attention in decoding and a speaker
recognition loss during training to better handle the larger number of
speakers. The visual-centric sub-system leverages facial attributes and
lip-audio synchrony for identity and speech activity estimation of on-screen
speakers. Both sub-systems surpass the state of the art (SOTA) by a large
margin, with the fused audio-visual system achieving a new SOTA on the AVA-AVD
benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPT-Neo for commonsense reasoning -- a theoretical and practical lens. (arXiv:2211.15593v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.15593">
<div class="article-summary-box-inner">
<span><p>Recent work has demonstrated substantial gains in pre-training large-language
models (LLMs) followed by supervised fine-tuning on the downstream task. In
this paper, we evaluate the performance of the GPT-neo model using $6$
commonsense reasoning benchmark tasks. We aim to examine the performance of
smaller models using the GPT-neo models against several larger model baselines
such as GPT-$3$, Llama-$2$, MPT and Falcon. Upon fine-tuning with the
appropriate set of hyperparameters, our model achieves competitive accuracy on
several tasks. We also investigate and substantiate our results using
attention-head visualization to better understand the model performance.
Finally, we conduct various robustness tests using various methods to gauge the
model performance under numerous settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Deep Learning System for Domain-specific Speech Recognition. (arXiv:2303.10510v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.10510">
<div class="article-summary-box-inner">
<span><p>As human-machine voice interfaces provide easy access to increasingly
intelligent machines, many state-of-the-art automatic speech recognition (ASR)
systems are proposed. However, commercial ASR systems usually have poor
performance on domain-specific speech especially under low-resource settings.
The author works with pre-trained DeepSpeech2 and Wav2Vec2 acoustic models to
develop benefit-specific ASR systems. The domain-specific data are collected
using proposed semi-supervised learning annotation with little human
intervention. The best performance comes from a fine-tuned Wav2Vec2-Large-LV60
acoustic model with an external KenLM, which surpasses the Google and AWS ASR
systems on benefit-specific speech. The viability of using error prone ASR
transcriptions as part of spoken language understanding (SLU) is also
investigated. Results of a benefit-specific natural language understanding
(NLU) task show that the domain-specific fine-tuned ASR system can outperform
the commercial ASR systems even when its transcriptions have higher word error
rate (WER), and the results between fine-tuned ASR and human transcriptions are
similar.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Can Be Used to Estimate the Latent Positions of Politicians. (arXiv:2303.12057v4 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.12057">
<div class="article-summary-box-inner">
<span><p>Existing approaches to estimating politicians' latent positions along
specific dimensions often fail when relevant data is limited. We leverage the
embedded knowledge in generative large language models (LLMs) to address this
challenge and measure lawmakers' positions along specific political or policy
dimensions. We prompt an instruction/dialogue-tuned LLM to pairwise compare
lawmakers and then scale the resulting graph using the Bradley-Terry model. We
estimate novel measures of U.S. senators' positions on liberal-conservative
ideology, gun control, and abortion. Our liberal-conservative scale, used to
validate LLM-driven scaling, strongly correlates with existing measures and
offsets interpretive gaps, suggesting LLMs synthesize relevant data from
internet and digitized media rather than memorizing existing measures. Our gun
control and abortion measures -- the first of their kind -- differ from the
liberal-conservative scale in face-valid ways and predict interest group
ratings and legislator votes better than ideology alone. Our findings suggest
LLMs hold promise for solving complex social science measurement problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers. (arXiv:2306.06531v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.06531">
<div class="article-summary-box-inner">
<span><p>For effective human-robot interaction, robots need to understand, plan, and
execute complex, long-horizon tasks described by natural language. Recent
advances in large language models (LLMs) have shown promise for translating
natural language into robot action sequences for complex tasks. However,
existing approaches either translate the natural language directly into robot
trajectories or factor the inference process by decomposing language into task
sub-goals and relying on a motion planner to execute each sub-goal. When
complex environmental and temporal constraints are involved, inference over
planning tasks must be performed jointly with motion plans using traditional
task-and-motion planning (TAMP) algorithms, making factorization into subgoals
untenable. Rather than using LLMs to directly plan task sub-goals, we instead
perform few-shot translation from natural language task descriptions to an
intermediate task representation that can then be consumed by a TAMP algorithm
to jointly solve the task and motion plan. To improve translation, we
automatically detect and correct both syntactic and semantic errors via
autoregressive re-prompting, resulting in significant improvements in task
completion. We show that our approach outperforms several methods using LLMs as
planners in complex task domains. See our project website
https://yongchao98.github.io/MIT-REALM-AutoTAMP/ for prompts, videos, and code.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Scale: the Diversity Coefficient as a Data Quality Metric Demonstrates LLMs are Pre-trained on Formally Diverse Data. (arXiv:2306.13840v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13840">
<div class="article-summary-box-inner">
<span><p>Current trends to pre-train capable Large Language Models (LLMs) mostly focus
on scaling of model and dataset size. However, the quality of pre-training data
is an important factor for training powerful LLMs, yet it is a nebulous concept
that has not been fully characterized. Therefore, we use the recently proposed
Task2Vec diversity coefficient to ground and understand formal aspects of data
quality, to go beyond scale alone. Specifically, we measure the diversity
coefficient of publicly available pre-training datasets to demonstrate that
their formal diversity is high when compared to theoretical lower and upper
bounds. In addition, to build confidence in the diversity coefficient, we
conduct interpretability experiments and find that the coefficient aligns with
intuitive properties of diversity, e.g., it increases as the number of latent
concepts increases. We conclude the diversity coefficient is reliable, show
it's high for publicly available LLM datasets, and conjecture it can be used to
build useful diverse datasets for LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Single and Multi-Speaker Cloned Voice Detection: From Perceptual to Learned Features. (arXiv:2307.07683v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.07683">
<div class="article-summary-box-inner">
<span><p>Synthetic-voice cloning technologies have seen significant advances in recent
years, giving rise to a range of potential harms. From small- and large-scale
financial fraud to disinformation campaigns, the need for reliable methods to
differentiate real and synthesized voices is imperative. We describe three
techniques for differentiating a real from a cloned voice designed to
impersonate a specific person. These three approaches differ in their feature
extraction stage with low-dimensional perceptual features offering high
interpretability but lower accuracy, to generic spectral features, and
end-to-end learned features offering less interpretability but higher accuracy.
We show the efficacy of these approaches when trained on a single speaker's
voice and when trained on multiple voices. The learned features consistently
yield an equal error rate between 0% and 4%, and are reasonably robust to
adversarial laundering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Distortion-free Watermarks for Language Models. (arXiv:2307.15593v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.15593">
<div class="article-summary-box-inner">
<span><p>We propose a methodology for planting watermarks in text from an
autoregressive language model that are robust to perturbations without changing
the distribution over text up to a certain maximum generation budget. We
generate watermarked text by mapping a sequence of random numbers -- which we
compute using a randomized watermark key -- to a sample from the language
model. To detect watermarked text, any party who knows the key can align the
text to the random number sequence. We instantiate our watermark methodology
with two sampling schemes: inverse transform sampling and exponential minimum
sampling. We apply these watermarks to three language models -- OPT-1.3B,
LLaMA-7B and Alpaca-7B -- to experimentally validate their statistical power
and robustness to various paraphrasing attacks. Notably, for both the OPT-1.3B
and LLaMA-7B models, we find we can reliably detect watermarked text ($p \leq
0.01$) from $35$ tokens even after corrupting between $40$-$50\%$ of the tokens
via random edits (i.e., substitutions, insertions or deletions). For the
Alpaca-7B model, we conduct a case study on the feasibility of watermarking
responses to typical user instructions. Due to the lower entropy of the
responses, detection is more difficult: around $25\%$ of the responses -- whose
median length is around $100$ tokens -- are detectable with $p \leq 0.01$, and
the watermark is also less robust to certain automated paraphrasing attacks we
implement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Advancing Beyond Identification: Multi-bit Watermark for Large Language Models. (arXiv:2308.00221v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.00221">
<div class="article-summary-box-inner">
<span><p>We propose a method to tackle misuses of large language models beyond the
identification of machine-generated text. While existing methods focus on
detection, some malicious misuses demand tracing the adversary user for
counteracting them. To address this, we propose Multi-bit Watermark via
Position Allocation, embedding traceable multi-bit information during language
model generation. Leveraging the benefits of zero-bit watermarking, our method
enables robust extraction of the watermark without any model access, embedding
and extraction of long messages ($\geq$ 32-bit) without finetuning, and
maintaining text quality, while allowing zero-bit detection all at the same
time. Moreover, our watermark is relatively robust under strong attacks like
interleaving human texts and paraphrasing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DS4DH at #SMM4H 2023: Zero-Shot Adverse Drug Events Normalization using Sentence Transformers and Reciprocal-Rank Fusion. (arXiv:2308.12877v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.12877">
<div class="article-summary-box-inner">
<span><p>This paper outlines the performance evaluation of a system for adverse drug
event normalization, developed by the Data Science for Digital Health (DS4DH)
group for the Social Media Mining for Health Applications (SMM4H) 2023 shared
task 5. Shared task 5 targeted the normalization of adverse drug event mentions
in Twitter to standard concepts of the Medical Dictionary for Regulatory
Activities terminology. Our system hinges on a two-stage approach: BERT
fine-tuning for entity recognition, followed by zero-shot normalization using
sentence transformers and reciprocal-rank fusion. The approach yielded a
precision of 44.9%, recall of 40.5%, and an F1-score of 42.6%. It outperformed
the median performance in shared task 5 by 10% and demonstrated the highest
performance among all participants. These results substantiate the
effectiveness of our approach and its potential application for adverse drug
event normalization in the realm of social media text mining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Speech Representation From Contrastive Token-Acoustic Pretraining. (arXiv:2309.00424v4 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00424">
<div class="article-summary-box-inner">
<span><p>For fine-grained generation and recognition tasks such as
minimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic
speech recognition (ASR), the intermediate representations extracted from
speech should serve as a "bridge" between text and acoustic information,
containing information from both modalities. The semantic content is
emphasized, while the paralinguistic information such as speaker identity and
acoustic details should be de-emphasized. However, existing methods for
extracting fine-grained intermediate representations from speech suffer from
issues of excessive redundancy and dimension explosion. Contrastive learning is
a good method for modeling intermediate representations from two modalities.
However, existing contrastive learning methods in the audio field focus on
extracting global descriptive information for downstream audio classification
tasks, making them unsuitable for TTS, VC, and ASR tasks. To address these
issues, we propose a method named "Contrastive Token-Acoustic Pretraining
(CTAP)", which uses two encoders to bring phoneme and speech into a joint
multimodal space, learning how to connect phoneme and speech at the frame
level. The CTAP model is trained on 210k speech and phoneme pairs, achieving
minimally-supervised TTS, VC, and ASR. The proposed CTAP method offers a
promising solution for fine-grained generation and recognition downstream tasks
in speech processing. We provide a website with audio samples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cognitive Architectures for Language Agents. (arXiv:2309.02427v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.02427">
<div class="article-summary-box-inner">
<span><p>Recent efforts have augmented large language models (LLMs) with external
resources (e.g., the Internet) or internal control flows (e.g., prompt
chaining) for tasks requiring grounding or reasoning, leading to a new class of
language agents. While these agents have achieved substantial empirical
success, we lack a systematic framework to organize existing agents and plan
future developments. In this paper, we draw on the rich history of cognitive
science and symbolic artificial intelligence to propose Cognitive Architectures
for Language Agents (CoALA). CoALA describes a language agent with modular
memory components, a structured action space to interact with internal memory
and external environments, and a generalized decision-making process to choose
actions. We use CoALA to retrospectively survey and organize a large body of
recent work, and prospectively identify actionable directions towards more
capable agents. Taken together, CoALA contextualizes today's language agents
within the broader history of AI and outlines a path towards language-based
general intelligence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs. (arXiv:2309.07311v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.07311">
<div class="article-summary-box-inner">
<span><p>Most interpretability research in NLP focuses on understanding the behavior
and features of a fully trained model. However, certain insights into model
behavior may only be accessible by observing the trajectory of the training
process. In this paper, we present a case study of syntax acquisition in masked
language models (MLMs). Our findings demonstrate how analyzing the evolution of
interpretable artifacts throughout training deepens our understanding of
emergent behavior. In particular, we study Syntactic Attention Structure (SAS),
a naturally emerging property of MLMs wherein specific Transformer heads tend
to focus on specific syntactic relations. We identify a brief window in
training when models abruptly acquire SAS and find that this window is
concurrent with a steep drop in loss. Moreover, SAS precipitates the subsequent
acquisition of linguistic capabilities. We then examine the causal role of SAS
by introducing a regularizer to manipulate SAS during training, and demonstrate
that SAS is necessary for the development of grammatical capabilities. We
further find that SAS competes with other beneficial traits and capabilities
during training, and that briefly suppressing SAS can improve model quality.
These findings reveal a real-world example of the relationship between
disadvantageous simplicity bias and interpretable breakthrough training
dynamics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Estimating Contamination via Perplexity: Quantifying Memorisation in Language Model Evaluation. (arXiv:2309.10677v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.10677">
<div class="article-summary-box-inner">
<span><p>Data contamination in model evaluation is getting increasingly prevalent as
the massive training corpora of large language models often unintentionally
include benchmark samples. Therefore, contamination analysis has became an
inevitable part of reliable model evaluation. However, existing method of
contamination analysis requires the access of the entire training data which is
often confidential for recent models. This prevent the community to rigorously
audit these models and conduct accurate assessment of their capability. In this
paper, we propose a novel method to quantify contamination without the access
of the full training set, that measure the extent of contamination with
perplexity. Our analysis provides evidence of significant memorisation of
recent foundation models in popular reading comprehension, summarisation
benchmarks, while multiple choice appears less contaminated.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MBR and QE Finetuning: Training-time Distillation of the Best and Most Expensive Decoding Methods. (arXiv:2309.10966v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.10966">
<div class="article-summary-box-inner">
<span><p>Recent research in decoding methods for Natural Language Generation (NLG)
tasks has shown that MAP decoding is not optimal, because model probabilities
do not always align with human preferences. Stronger decoding methods,
including Quality Estimation (QE) reranking and Minimum Bayes' Risk (MBR)
decoding, have since been proposed to mitigate the model-perplexity-vs-quality
mismatch. While these decoding methods achieve state-of-the-art performance,
they are prohibitively expensive to compute. In this work, we propose MBR
finetuning and QE finetuning which distill the quality gains from these
decoding methods at training time, while using an efficient decoding algorithm
at inference time. Using the canonical NLG task of Neural Machine Translation
(NMT), we show that even with self-training, these finetuning methods
significantly outperform the base model. Moreover, when using an external LLM
as a teacher model, these finetuning methods outperform finetuning on
human-generated references. These findings suggest new ways to leverage
monolingual data to achieve improvements in model quality that are on par with,
or even exceed, improvements from human-curated data, while maintaining maximum
efficiency during decoding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are Large Language Models Really Robust to Word-Level Perturbations?. (arXiv:2309.11166v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.11166">
<div class="article-summary-box-inner">
<span><p>The swift advancement in the scales and capabilities of Large Language Models
(LLMs) positions them as promising tools for a variety of downstream tasks. In
addition to the pursuit of better performance and the avoidance of violent
feedback on a certain prompt, to ensure the responsibility of the LLM, much
attention is drawn to the robustness of LLMs. However, existing evaluation
methods mostly rely on traditional question answering datasets with predefined
supervised labels, which do not align with the superior generation capabilities
of contemporary LLMs. To address this issue, we propose a novel rational
evaluation approach that leverages pre-trained reward models as diagnostic
tools to evaluate the longer conversation generated from more challenging open
questions by LLMs, which we refer to as the Reward Model for Reasonable
Robustness Evaluation (TREvaL). Longer conversations manifest the comprehensive
grasp of language models in terms of their proficiency in understanding
questions, a capability not entirely encompassed by individual words or
letters, which may exhibit oversimplification and inherent biases. Our
extensive empirical experiments demonstrate that TREvaL provides an innovative
method for evaluating the robustness of an LLM. Furthermore, our results
demonstrate that LLMs frequently exhibit vulnerability to word-level
perturbations that are commonplace in daily language usage. Notably, we are
surprised to discover that robustness tends to decrease as fine-tuning (SFT and
RLHF) is conducted. The code of TREval is available in
https://github.com/Harry-mic/TREvaL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SLHCat: Mapping Wikipedia Categories and Lists to DBpedia by Leveraging Semantic, Lexical, and Hierarchical Features. (arXiv:2309.11791v2 [cs.DL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.11791">
<div class="article-summary-box-inner">
<span><p>Wikipedia articles are hierarchically organized through categories and lists,
providing one of the most comprehensive and universal taxonomy, but its open
creation is causing redundancies and inconsistencies. Assigning DBPedia classes
to Wikipedia categories and lists can alleviate the problem, realizing a large
knowledge graph which is essential for categorizing digital contents through
entity linking and typing. However, the existing approach of CaLiGraph is
producing incomplete and non-fine grained mappings. In this paper, we tackle
the problem as ontology alignment, where structural information of knowledge
graphs and lexical and semantic features of ontology class names are utilized
to discover confident mappings, which are in turn utilized for finetuing
pretrained language models in a distant supervision fashion. Our method SLHCat
consists of two main parts: 1) Automatically generating training data by
leveraging knowledge graph structure, semantic similarities, and named entity
typing. 2) Finetuning and prompt-tuning of the pre-trained language model BERT
are carried out over the training data, to capture semantic and syntactic
properties of class names. Our model SLHCat is evaluated over a benchmark
dataset constructed by annotating 3000 fine-grained CaLiGraph-DBpedia mapping
pairs. SLHCat is outperforming the baseline model by a large margin of 25% in
accuracy, offering a practical solution for large-scale ontology mapping.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ALLURE: Auditing and Improving LLM-based Evaluation of Text using Iterative In-Context-Learning. (arXiv:2309.13701v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13701">
<div class="article-summary-box-inner">
<span><p>From grading papers to summarizing medical documents, large language models
(LLMs) are evermore used for evaluation of text generated by humans and AI
alike. However, despite their extensive utility, LLMs exhibit distinct failure
modes, necessitating a thorough audit and improvement of their text evaluation
capabilities. Here we introduce ALLURE, a systematic approach to Auditing Large
Language Models Understanding and Reasoning Errors. ALLURE involves comparing
LLM-generated evaluations with annotated data, and iteratively incorporating
instances of significant deviation into the evaluator, which leverages
in-context learning (ICL) to enhance and improve robust evaluation of text by
LLMs. Through this iterative process, we refine the performance of the
evaluator LLM, ultimately reducing reliance on human annotators in the
evaluation process. We anticipate ALLURE to serve diverse applications of LLMs
in various domains related to evaluation of textual data, such as medical
summarization, education, and and productivity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Seeing and hearing what has not been said; A multimodal client behavior classifier in Motivational Interviewing with interpretable fusion. (arXiv:2309.14398v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14398">
<div class="article-summary-box-inner">
<span><p>Motivational Interviewing (MI) is an approach to therapy that emphasizes
collaboration and encourages behavioral change. To evaluate the quality of an
MI conversation, client utterances can be classified using the MISC code as
either change talk, sustain talk, or follow/neutral talk. The proportion of
change talk in a MI conversation is positively correlated with therapy
outcomes, making accurate classification of client utterances essential. In
this paper, we present a classifier that accurately distinguishes between the
three MISC classes (change talk, sustain talk, and follow/neutral talk)
leveraging multimodal features such as text, prosody, facial expressivity, and
body expressivity. To train our model, we perform annotations on the publicly
available AnnoMI dataset to collect multimodal information, including text,
audio, facial expressivity, and body expressivity. Furthermore, we identify the
most important modalities in the decision-making process, providing valuable
insights into the interplay of different modalities during a MI conversation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Keyphrase Generation by BART Finetuning with Splitting and Shuffling. (arXiv:2309.06726v1 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.06726">
<div class="article-summary-box-inner">
<span><p>Keyphrase generation is a task of identifying a set of phrases that best
repre-sent the main topics or themes of a given text. Keyphrases are dividend
int pre-sent and absent keyphrases. Recent approaches utilizing
sequence-to-sequence models show effectiveness on absent keyphrase generation.
However, the per-formance is still limited due to the hardness of finding
absent keyphrases. In this paper, we propose Keyphrase-Focused BART, which
exploits the differ-ences between present and absent keyphrase generations, and
performs fine-tuning of two separate BART models for present and absent
keyphrases. We further show effective approaches of shuffling keyphrases and
candidate keyphrase ranking. For absent keyphrases, our Keyphrase-Focused BART
achieved new state-of-the-art score on F1@5 in two out of five keyphrase
gen-eration benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models. (arXiv:2309.14717v1 [cs.LG] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14717">
<div class="article-summary-box-inner">
<span><p>Recently years have witnessed a rapid development of large language models
(LLMs). Despite the strong ability in many language-understanding tasks, the
heavy computational burden largely restricts the application of LLMs especially
when one needs to deploy them onto edge devices. In this paper, we propose a
quantization-aware low-rank adaptation (QA-LoRA) algorithm. The motivation lies
in the imbalanced degrees of freedom of quantization and adaptation, and the
solution is to use group-wise operators which increase the degree of freedom of
quantization meanwhile decreasing that of adaptation. QA-LoRA is easily
implemented with a few lines of code, and it equips the original LoRA with
two-fold abilities: (i) during fine-tuning, the LLM's weights are quantized
(e.g., into INT4) to reduce time and memory usage; (ii) after fine-tuning, the
LLM and auxiliary weights are naturally integrated into a quantized model
without loss of accuracy. We apply QA-LoRA to the LLaMA and LLaMA2 model
families and validate its effectiveness in different fine-tuning datasets and
downstream scenarios. Code will be made available at
https://github.com/yuhuixu1993/qa-lora.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-09-28 23:11:09.326538027 UTC">2023-09-28 23:11:09 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>