<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-11-21T01:30:00Z">11-21</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">CoLI-Machine Learning Approaches for Code-mixed Language Identification at the Word Level in Kannada-English Texts. (arXiv:2211.09847v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09847">
<div class="article-summary-box-inner">
<span><p>The task of automatically identifying a language used in a given text is
called Language Identification (LI). India is a multilingual country and many
Indians especially youths are comfortable with Hindi and English, in addition
to their local languages. Hence, they often use more than one language to post
their comments on social media. Texts containing more than one language are
called "code-mixed texts" and are a good source of input for LI. Languages in
these texts may be mixed at sentence level, word level or even at sub-word
level. LI at word level is a sequence labeling problem where each and every
word in a sentence is tagged with one of the languages in the predefined set of
languages. In order to address word level LI in code-mixed Kannada-English
(Kn-En) texts, this work presents i) the construction of code-mixed Kn-En
dataset called CoLI-Kenglish dataset, ii) code-mixed Kn-En embedding and iii)
learning models using Machine Learning (ML), Deep Learning (DL) and Transfer
Learning (TL) approaches. Code-mixed Kn-En texts are extracted from Kannada
YouTube video comments to construct CoLI-Kenglish dataset and code-mixed Kn-En
embedding. The words in CoLI-Kenglish dataset are grouped into six major
categories, namely, "Kannada", "English", "Mixed-language", "Name", "Location"
and "Other". The learning models, namely, CoLI-vectors and CoLI-ngrams based on
ML, CoLI-BiLSTM based on DL and CoLI-ULMFiT based on TL approaches are built
and evaluated using CoLI-Kenglish dataset. The performances of the learning
models illustrated, the superiority of CoLI-ngrams model, compared to other
models with a macro average F1-score of 0.64. However, the results of all the
learning models were quite competitive with each other.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ProtSi: Prototypical Siamese Network with Data Augmentation for Few-Shot Subjective Answer Evaluation. (arXiv:2211.09855v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09855">
<div class="article-summary-box-inner">
<span><p>Subjective answer evaluation is a time-consuming and tedious task, and the
quality of the evaluation is heavily influenced by a variety of subjective
personal characteristics. Instead, machine evaluation can effectively assist
educators in saving time while also ensuring that evaluations are fair and
realistic. However, most existing methods using regular machine learning and
natural language processing techniques are generally hampered by a lack of
annotated answers and poor model interpretability, making them unsuitable for
real-world use. To solve these challenges, we propose ProtSi Network, a unique
semi-supervised architecture that for the first time uses few-shot learning to
subjective answer evaluation. To evaluate students' answers by similarity
prototypes, ProtSi Network simulates the natural process of evaluator scoring
answers by combining Siamese Network which consists of BERT and encoder layers
with Prototypical Network. We employed an unsupervised diverse paraphrasing
model ProtAugment, in order to prevent overfitting for effective few-shot text
classification. By integrating contrastive learning, the discriminative text
issue can be mitigated. Experiments on the Kaggle Short Scoring Dataset
demonstrate that the ProtSi Network outperforms the most recent baseline models
in terms of accuracy and quadratic weighted kappa.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reducing Hallucinations in Neural Machine Translation with Feature Attribution. (arXiv:2211.09878v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09878">
<div class="article-summary-box-inner">
<span><p>Neural conditional language generation models achieve the state-of-the-art in
Neural Machine Translation (NMT) but are highly dependent on the quality of
parallel training dataset. When trained on low-quality datasets, these models
are prone to various error types, including hallucinations, i.e. outputs that
are fluent, but unrelated to the source sentences. These errors are
particularly dangerous, because on the surface the translation can be perceived
as a correct output, especially if the reader does not understand the source
language. We present a case study focusing on model understanding and
regularisation to reduce hallucinations in NMT. We first use feature
attribution methods to study the behaviour of an NMT model that produces
hallucinations. We then leverage these methods to propose a novel loss function
that substantially helps reduce hallucinations and does not require retraining
the model from scratch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Summarizing Community-based Question-Answer Pairs. (arXiv:2211.09892v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09892">
<div class="article-summary-box-inner">
<span><p>Community-based Question Answering (CQA), which allows users to acquire their
desired information, has increasingly become an essential component of online
services in various domains such as E-commerce, travel, and dining. However, an
overwhelming number of CQA pairs makes it difficult for users without
particular intent to find useful information spread over CQA pairs. To help
users quickly digest the key information, we propose the novel CQA
summarization task that aims to create a concise summary from CQA pairs. To
this end, we first design a multi-stage data annotation process and create a
benchmark dataset, CoQASUM, based on the Amazon QA corpus. We then compare a
collection of extractive and abstractive summarization methods and establish a
strong baseline approach DedupLED for the CQA summarization task. Our
experiment further confirms two key challenges, sentence-type transfer and
deduplication removal, towards the CQA summarization task. Our data and code
are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Planning with Large Language Models via Corrective Re-prompting. (arXiv:2211.09935v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09935">
<div class="article-summary-box-inner">
<span><p>Extracting the common sense knowledge present in Large Language Models (LLMs)
offers a path to designing intelligent, embodied agents. Related works have
queried LLMs with a wide-range of contextual information, such as goals, sensor
observations and scene descriptions, to generate high-level action plans for
specific tasks; however these approaches often involve human intervention or
additional machinery to enable sensor-motor interactions. In this work, we
propose a prompting-based strategy for extracting executable plans from an LLM,
which leverages a novel and readily-accessible source of information:
precondition errors. Our approach assumes that actions are only afforded
execution in certain contexts, i.e., implicit preconditions must be met for an
action to execute (e.g., a door must be unlocked to open it), and that the
embodied agent has the ability to determine if the action is/is not executable
in the current context (e.g., detect if a precondition error is present). When
an agent is unable to execute an action, our approach re-prompts the LLM with
precondition error information to extract an executable corrective action to
achieve the intended goal in the current context. We evaluate our approach in
the VirtualHome simulation environment on 88 different tasks and 7 scenes. We
evaluate different prompt templates and compare to methods that naively
re-sample actions from the LLM. Our approach, using precondition errors,
improves executability and semantic correctness of plans, while also reducing
the number of re-prompts required when querying actions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explainability Via Causal Self-Talk. (arXiv:2211.09937v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09937">
<div class="article-summary-box-inner">
<span><p>Explaining the behavior of AI systems is an important problem that, in
practice, is generally avoided. While the XAI community has been developing an
abundance of techniques, most incur a set of costs that the wider deep learning
community has been unwilling to pay in most situations. We take a pragmatic
view of the issue, and define a set of desiderata that capture both the
ambitions of XAI and the practical constraints of deep learning. We describe an
effective way to satisfy all the desiderata: train the AI system to build a
causal model of itself. We develop an instance of this solution for Deep RL
agents: Causal Self-Talk. CST operates by training the agent to communicate
with itself across time. We implement this method in a simulated 3D
environment, and show how it enables agents to generate faithful and
semantically-meaningful explanations of their own behavior. Beyond
explanations, we also demonstrate that these learned models provide new ways of
building semantic control interfaces to AI systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Professional Presentation and Projected Power: A Case Study of Implicit Gender Information in English CVs. (arXiv:2211.09942v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09942">
<div class="article-summary-box-inner">
<span><p>Gender discrimination in hiring is a pertinent and persistent bias in
society, and a common motivating example for exploring bias in NLP. However,
the manifestation of gendered language in application materials has received
limited attention. This paper investigates the framing of skills and background
in CVs of self-identified men and women. We introduce a data set of 1.8K
authentic, English-language, CVs from the US, covering 16 occupations, allowing
us to partially control for the confound occupation-specific gender base rates.
We find that (1) women use more verbs evoking impressions of low power; and (2)
classifiers capture gender signal even after data balancing and removal of
pronouns and named entities, and this holds for both transformer-based and
linear classifiers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MelHuBERT: A simplified HuBERT on Mel spectrogram. (arXiv:2211.09944v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09944">
<div class="article-summary-box-inner">
<span><p>Self-supervised models have had great success in learning speech
representations that can generalize to various downstream tasks. HuBERT, in
particular, achieves strong performance while being relatively simple in
training compared to others. The original experimental setting is
computationally extensive, hindering the reproducibility of the models. It is
also unclear why certain design decisions are made, such as the ad-hoc loss
function, and whether these decisions have an impact on the learned
representations. We propose MelHuBERT, a simplified version of HuBERT that
takes Mel spectrograms as input, significantly reducing computation and memory
consumption. We study several aspects of training, including the loss function,
multi-stage training, and streaming options. Our result is a efficient yet
performant model that can be trained on a single GPU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Compressing Transformer-based self-supervised models for speech processing. (arXiv:2211.09949v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09949">
<div class="article-summary-box-inner">
<span><p>Despite the success of Transformers in self-supervised learning with
applications to various downstream tasks, the computational cost of training
and inference remains a major challenge for applying these models to a wide
spectrum of devices. Several isolated attempts have been made to compress
Transformers, prior to applying them to downstream tasks. In this work, we aim
to provide context for the isolated results, studying several commonly used
compression techniques, including weight pruning, head pruning, low-rank
approximation, and knowledge distillation. We report wall-clock time, the
number of parameters, and the number of multiply-accumulate operations for
these techniques, charting the landscape of compressing Transformer-based
self-supervised models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Explaining Subjective Ground of Individuals on Social Media. (arXiv:2211.09953v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09953">
<div class="article-summary-box-inner">
<span><p>Large-scale language models have been reducing the gap between machines and
humans in understanding the real world, yet understanding an individual's
theory of mind and behavior from text is far from being resolved.
</p>
<p>This research proposes a neural model -- Subjective Ground Attention -- that
learns subjective grounds of individuals and accounts for their judgments on
situations of others posted on social media. Using simple attention modules as
well as taking one's previous activities into consideration, we empirically
show that our model provides human-readable explanations of an individual's
subjective preference in judging social situations. We further qualitatively
evaluate the explanations generated by the model and claim that our model
learns an individual's subjective orientation towards abstract moral concepts
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Who Says Elephants Can't Run: Bringing Large Scale MoE Models into Cloud Scale Production. (arXiv:2211.10017v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.10017">
<div class="article-summary-box-inner">
<span><p>Mixture of Experts (MoE) models with conditional execution of sparsely
activated layers have enabled training models with a much larger number of
parameters. As a result, these models have achieved significantly better
quality on various natural language processing tasks including machine
translation. However, it remains challenging to deploy such models in real-life
scenarios due to the large memory requirements and inefficient inference. In
this work, we introduce a highly efficient inference framework with several
optimization approaches to accelerate the computation of sparse models and cut
down the memory consumption significantly. While we achieve up to 26x speed-up
in terms of throughput, we also reduce the model size almost to one eighth of
the original 32-bit float model by quantizing expert weights into 4-bit
integers. As a result, we are able to deploy 136x larger models with 27% less
cost and significantly better quality compared to the existing solutions. This
enables a paradigm shift in deploying large scale multilingual MoE transformers
models replacing the traditional practice of distilling teacher models into
dozens of smaller models per language or task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Dataset for Hyper-Relational Extraction and a Cube-Filling Approach. (arXiv:2211.10018v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.10018">
<div class="article-summary-box-inner">
<span><p>Relation extraction has the potential for large-scale knowledge graph
construction, but current methods do not consider the qualifier attributes for
each relation triplet, such as time, quantity or location. The qualifiers form
hyper-relational facts which better capture the rich and complex knowledge
graph structure. For example, the relation triplet (Leonard Parker, Educated
At, Harvard University) can be factually enriched by including the qualifier
(End Time, 1967). Hence, we propose the task of hyper-relational extraction to
extract more specific and complete facts from text. To support the task, we
construct HyperRED, a large-scale and general-purpose dataset. Existing models
cannot perform hyper-relational extraction as it requires a model to consider
the interaction between three entities. Hence, we propose CubeRE, a
cube-filling model inspired by table-filling approaches and explicitly
considers the interaction between relation triplets and qualifiers. To improve
model scalability and reduce negative class imbalance, we further propose a
cube-pruning method. Our experiments show that CubeRE outperforms strong
baselines and reveal possible directions for future research. Our code and data
are available at github.com/declare-lab/HyperRED.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Overview of the WANLP 2022 Shared Task on Propaganda Detection in Arabic. (arXiv:2211.10057v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.10057">
<div class="article-summary-box-inner">
<span><p>Propaganda is the expression of an opinion or an action by an individual or a
group deliberately designed to influence the opinions or the actions of other
individuals or groups with reference to predetermined ends, which is achieved
by means of well-defined rhetorical and psychological devices. Propaganda
techniques are commonly used in social media to manipulate or to mislead users.
Thus, there has been a lot of recent research on automatic detection of
propaganda techniques in text as well as in memes. However, so far the focus
has been primarily on English. With the aim to bridge this language gap, we ran
a shared task on detecting propaganda techniques in Arabic tweets as part of
the WANLP 2022 workshop, which included two subtasks. Subtask~1 asks to
identify the set of propaganda techniques used in a tweet, which is a
multilabel classification problem, while Subtask~2 asks to detect the
propaganda techniques used in a tweet together with the exact span(s) of text
in which each propaganda technique appears. The task attracted 63 team
registrations, and eventually 14 and 3 teams made submissions for subtask 1 and
2, respectively. Finally, 11 teams submitted system description papers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Metadata Might Make Language Models Better. (arXiv:2211.10086v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.10086">
<div class="article-summary-box-inner">
<span><p>This paper discusses the benefits of including metadata when training
language models on historical collections. Using 19th-century newspapers as a
case study, we extend the time-masking approach proposed by Rosin et al., 2022
and compare different strategies for inserting temporal, political and
geographical information into a Masked Language Model. After fine-tuning
several DistilBERT on enhanced input data, we provide a systematic evaluation
of these models on a set of evaluation tasks: pseudo-perplexity, metadata
mask-filling and supervised classification. We find that showing relevant
metadata to a language model has a beneficial impact and may even produce more
robust and fairer models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scaling Native Language Identification with Transformer Adapters. (arXiv:2211.10117v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.10117">
<div class="article-summary-box-inner">
<span><p>Native language identification (NLI) is the task of automatically identifying
the native language (L1) of an individual based on their language production in
a learned language. It is useful for a variety of purposes including marketing,
security and educational applications. NLI is usually framed as a multi-label
classification task, where numerous designed features are combined to achieve
state-of-the-art results. Recently deep generative approach based on
transformer decoders (GPT-2) outperformed its counterparts and achieved the
best results on the NLI benchmark datasets. We investigate this approach to
determine the practical implications compared to traditional state-of-the-art
NLI systems. We introduce transformer adapters to address memory limitations
and improve training/inference speed to scale NLI applications for production.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FiE: Building a Global Probability Space by Leveraging Early Fusion in Encoder for Open-Domain Question Answering. (arXiv:2211.10147v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.10147">
<div class="article-summary-box-inner">
<span><p>Generative models have recently started to outperform extractive models in
Open Domain Question Answering, largely by leveraging their decoder to attend
over multiple encoded passages and combining their information. However,
generative models tend to be larger than extractive models due to the need for
a decoder, run slower during inference due to auto-regressive decoder beam
search, and their generated output often suffers from hallucinations. We
propose to extend transformer encoders with the ability to fuse information
from multiple passages, using global representation to provide cross-sample
attention over all tokens across samples. Furthermore, we propose an
alternative answer span probability calculation to better aggregate answer
scores in the global space of all samples. Using our proposed method, we
outperform the current state-of-the-art method by $2.5$ Exact Match score on
the Natural Question dataset while using only $25\%$ of parameters and $35\%$
of the latency during inference, and $4.4$ Exact Match on WebQuestions dataset.
When coupled with synthetic data augmentation, we outperform larger models on
the TriviaQA dataset as well. The latency and parameter savings of our method
make it particularly attractive for open-domain question answering, as these
models are often compute-intensive.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Overview of the HASOC Subtrack at FIRE 2022: Offensive Language Identification in Marathi. (arXiv:2211.10163v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.10163">
<div class="article-summary-box-inner">
<span><p>The widespread of offensive content online has become a reason for great
concern in recent years, motivating researchers to develop robust systems
capable of identifying such content automatically. With the goal of carrying
out a fair evaluation of these systems, several international competitions have
been organized, providing the community with important benchmark data and
evaluation methods for various languages. Organized since 2019, the HASOC (Hate
Speech and Offensive Content Identification) shared task is one of these
initiatives. In its fourth iteration, HASOC 2022 included three subtracks for
English, Hindi, and Marathi. In this paper, we report the results of the HASOC
2022 Marathi subtrack which provided participants with a dataset containing
data from Twitter manually annotated using the popular OLID taxonomy. The
Marathi track featured three additional subtracks, each corresponding to one
level of the taxonomy: Task A - offensive content identification (offensive vs.
non-offensive); Task B - categorization of offensive types (targeted vs.
untargeted), and Task C - offensive target identification (individual vs. group
vs. others). Overall, 59 runs were submitted by 10 teams. The best systems
obtained an F1 of 0.9745 for Subtrack 3A, an F1 of 0.9207 for Subtrack 3B, and
F1 of 0.9607 for Subtrack 3C. The best performing algorithms were a mixture of
traditional and deep learning approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GoSum: Extractive Summarization of Long Documents by Reinforcement Learning and Graph Organized discourse state. (arXiv:2211.10247v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.10247">
<div class="article-summary-box-inner">
<span><p>Handling long texts with structural information and excluding redundancy
between summary sentences are essential in extractive document summarization.
In this work, we propose GoSum, a novel reinforcement-learning-based extractive
model for long-paper summarization. GoSum encodes states by building a
heterogeneous graph from different discourse levels for each input document. We
evaluate the model on two datasets of scientific articles summarization: PubMed
and arXiv where it outperforms all extractive summarization models and most of
the strong abstractive baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Context Variance Evaluation of Pretrained Language Models for Prompt-based Biomedical Knowledge Probing. (arXiv:2211.10265v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.10265">
<div class="article-summary-box-inner">
<span><p>Pretrained language models (PLMs) have motivated research on what kinds of
knowledge these models learn. Fill-in-the-blanks problem (e.g., cloze tests) is
a natural approach for gauging such knowledge. BioLAMA generates prompts for
biomedical factual knowledge triples and uses the Top-k accuracy metric to
evaluate different PLMs' knowledge. However, existing research has shown that
such prompt-based knowledge probing methods can only probe a lower bound of
knowledge. Many factors like prompt-based probing biases make the LAMA
benchmark unreliable and unstable. This problem is more prominent in BioLAMA.
The severe long-tailed distribution in vocabulary and large-N-M relation make
the performance gap between LAMA and BioLAMA remain notable. To address these,
we introduce context variance into the prompt generation and propose a new
rank-change-based evaluation metric. Different from the previous known-unknown
evaluation criteria, we propose the concept of "Misunderstand" in LAMA for the
first time. Through experiments on 12 PLMs, our context variance prompts and
Understand-Confuse-Misunderstand (UCM) metric makes BioLAMA more friendly to
large-N-M relations and rare relations. We also conducted a set of control
experiments to disentangle "understand" from just "read and copy".
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Copy Mechanism for Handling Knowledge Base Elements in SPARQL Neural Machine Translation. (arXiv:2211.10271v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.10271">
<div class="article-summary-box-inner">
<span><p>Neural Machine Translation (NMT) models from English to SPARQL are a
promising development for SPARQL query generation. However, current
architectures are unable to integrate the knowledge base (KB) schema and handle
questions on knowledge resources, classes, and properties unseen during
training, rendering them unusable outside the scope of topics covered in the
training set. Inspired by the performance gains in natural language processing
tasks, we propose to integrate a copy mechanism for neural SPARQL query
generation as a way to tackle this issue. We illustrate our proposal by adding
a copy layer and a dynamic knowledge base vocabulary to two Seq2Seq
architectures (CNNs and Transformers). This layer makes the models copy KB
elements directly from the questions, instead of generating them. We evaluate
our approach on state-of-the-art datasets, including datasets referencing
unknown KB elements and measure the accuracy of the copy-augmented
architectures. Our results show a considerable increase in performance on all
datasets compared to non-copy architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GENIUS: Sketch-based Language Model Pre-training via Extreme and Selective Masking for Text Generation and Augmentation. (arXiv:2211.10330v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.10330">
<div class="article-summary-box-inner">
<span><p>We introduce GENIUS: a conditional text generation model using sketches as
input, which can fill in the missing contexts for a given sketch (key
information consisting of textual spans, phrases, or words, concatenated by
mask tokens). GENIUS is pre-trained on a large-scale textual corpus with a
novel reconstruction from sketch objective using an extreme and selective
masking strategy, enabling it to generate diverse and high-quality texts given
sketches. Comparison with other competitive conditional language models (CLMs)
reveals the superiority of GENIUS's text generation quality. We further show
that GENIUS can be used as a strong and ready-to-use data augmentation tool for
various natural language processing (NLP) tasks. Most existing textual data
augmentation methods are either too conservative, by making small changes to
the original text, or too aggressive, by creating entirely new samples. With
GENIUS, we propose GeniusAug, which first extracts the target-aware sketches
from the original training set and then generates new samples based on the
sketches. Empirical experiments on 6 text classification datasets show that
GeniusAug significantly improves the models' performance in both
in-distribution (ID) and out-of-distribution (OOD) settings. We also
demonstrate the effectiveness of GeniusAug on named entity recognition (NER)
and machine reading comprehension (MRC) tasks. (Code and models are publicly
available at https://github.com/microsoft/SCGLab and
https://github.com/beyondguo/genius)
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CITADEL: Conditional Token Interaction via Dynamic Lexical Routing for Efficient and Effective Multi-Vector Retrieval. (arXiv:2211.10411v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.10411">
<div class="article-summary-box-inner">
<span><p>Multi-vector retrieval methods combine the merits of sparse (e.g. BM25) and
dense (e.g. DPR) retrievers and have achieved state-of-the-art performance on
various retrieval tasks. These methods, however, are orders of magnitude slower
and need much more space to store their indices compared to their single-vector
counterparts. In this paper, we unify different multi-vector retrieval models
from a token routing viewpoint and propose conditional token interaction via
dynamic lexical routing, namely CITADEL, for efficient and effective
multi-vector retrieval. CITADEL learns to route different token vectors to the
predicted lexical ``keys'' such that a query token vector only interacts with
document token vectors routed to the same key. This design significantly
reduces the computation cost while maintaining high accuracy. Notably, CITADEL
achieves the same or slightly better performance than the previous state of the
art, ColBERT-v2, on both in-domain (MS MARCO) and out-of-domain (BEIR)
evaluations, while being nearly 40 times faster. Code and data are available at
https://github.com/facebookresearch/dpr-scale.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PAL: Program-aided Language Models. (arXiv:2211.10435v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.10435">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have recently demonstrated an impressive ability
to perform arithmetic and symbolic reasoning tasks when provided with a few
examples at test time (few-shot prompting). Much of this success can be
attributed to prompting methods for reasoning, such as chain-of-thought, that
employ LLMs for both understanding the problem description by decomposing it
into steps, as well as solving each step of the problem. While LLMs seem to be
adept at this sort of step-by-step decomposition, LLMs often make logical and
arithmetic mistakes in the solution part, even when the problem is correctly
decomposed. We present Program-Aided Language models (PaL): a new method that
uses the LLM to understand natural language problems and generate programs as
the intermediate reasoning steps, but offloads the solution step to a
programmatic runtime such as a Python interpreter. With PaL, decomposing the
natural language problem into runnable steps remains the only learning task for
the LLM, while solving is delegated to the interpreter. We experiment with 12
reasoning tasks from BIG-Bench Hard and other benchmarks, including
mathematical reasoning, symbolic reasoning, and algorithmic problems. In all
these natural language reasoning tasks, generating code using an LLM and
reasoning using a Python interpreter leads to more accurate results than much
larger models, and we set new state-of-the-art results in all 12 benchmarks.
For example, PaL using Codex achieves state-of-the-art few-shot accuracy on the
GSM benchmark of math word problems when the model is allowed only a single
decoding, surpassing PaLM-540B with chain-of-thought prompting by an absolute
8% .In three reasoning tasks from the BIG-Bench Hard benchmark, PaL outperforms
CoT by 11%. On GSM-hard, a more challenging version of GSM that we create, PaL
outperforms chain-of-thought by an absolute 40%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models. (arXiv:2211.10438v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.10438">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) show excellent performance but are compute- and
memory-intensive. Quantization can reduce memory and accelerate inference.
However, for LLMs beyond 100 billion parameters, existing methods cannot
maintain accuracy or do not run efficiently on hardware. We propose
SmoothQuant, a training-free, accuracy-preserving, and general-purpose
post-training quantization (PTQ) solution to enable 8-bit weight, 8-bit
activation (W8A8) quantization for LLMs that can be implemented efficiently. We
observe that systematic outliers appear at fixed activation channels. Based on
the fact that weights are easy to quantize while activations are not,
SmoothQuant smooths the activation outliers by migrating the quantization
difficulty from activations to weights with a mathematically equivalent
transformation. SmoothQuant enables an INT8 quantization of both weights and
activations for all the GEMMs in LLMs, including OPT-175B, BLOOM-176B and
GLM-130B. SmoothQuant has better hardware efficiency than existing techniques
using mixed-precision activation quantization or weight-only quantization. We
demonstrate up to 1.56x speedup and 2x memory reduction for LLMs with
negligible loss in accuracy. Thanks to the hardware-friendly design, we
integrate SmoothQuant into FasterTransformer, a state-of-the-art LLM serving
framework, and achieve faster inference speed with half the number of GPUs
compared to FP16. Our work offers a turn-key solution that reduces hardware
costs and democratizes LLMs. Code will be released at:
https://github.com/mit-han-lab/smoothquant.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling chronic pain experiences from online reports using the Reddit Reports of Chronic Pain dataset. (arXiv:2108.10218v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10218">
<div class="article-summary-box-inner">
<span><p>Objective: Reveal and quantify qualities of reported experiences of chronic
pain on social media, from multiple pathological backgrounds, by means of the
novel Reddit Reports of Chronic Pain (RRCP) dataset, using Natural Language
Processing techniques. Materials and Methods: Define and validate the RRCP
dataset for a set of subreddits related to chronic pain. Identify the main
concerns discussed in each subreddit. Model each subreddit according to their
main concerns. Compare subreddit models. Results: The RRCP dataset comprises
86,537 Reddit submissions from 12 subreddits related to chronic pain (each
related to one pathological background). Each RRCP subreddit has various main
concerns. Some of these concerns are shared between multiple subreddits (e.g.,
the subreddit Sciatica semantically entails the subreddit backpain in their
various concerns, but not the other way around), whilst some concerns are
exclusive to specific subreddits (e.g., Interstitialcystitis and
CrohnsDisease). Discussion: These results suggest that the reported experience
of chronic pain, from multiple pathologies (i.e., subreddits), has concerns
relevant to all, and concerns exclusive to certain pathologies. Our analysis
details each of these concerns and their similarity relations. Conclusion:
Although limited by intrinsic qualities of the Reddit platform, to the best of
our knowledge, this is the first research work attempting to model the
linguistic expression of various chronic pain-inducing pathologies and
comparing these models to identify and quantify the similarities and
differences between the corresponding emergent chronic pain experiences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cheating Automatic Short Answer Grading: On the Adversarial Usage of Adjectives and Adverbs. (arXiv:2201.08318v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08318">
<div class="article-summary-box-inner">
<span><p>Automatic grading models are valued for the time and effort saved during the
instruction of large student bodies. Especially with the increasing
digitization of education and interest in large-scale standardized testing, the
popularity of automatic grading has risen to the point where commercial
solutions are widely available and used. However, for short answer formats,
automatic grading is challenging due to natural language ambiguity and
versatility. While automatic short answer grading models are beginning to
compare to human performance on some datasets, their robustness, especially to
adversarially manipulated data, is questionable. Exploitable vulnerabilities in
grading models can have far-reaching consequences ranging from cheating
students receiving undeserved credit to undermining automatic grading
altogether - even when most predictions are valid. In this paper, we devise a
black-box adversarial attack tailored to the educational short answer grading
scenario to investigate the grading models' robustness. In our attack, we
insert adjectives and adverbs into natural places of incorrect student answers,
fooling the model into predicting them as correct. We observed a loss of
prediction accuracy between 10 and 22 percentage points using the
state-of-the-art models BERT and T5. While our attack made answers appear less
natural to humans in our experiments, it did not significantly increase the
graders' suspicions of cheating. Based on our experiments, we provide
recommendations for utilizing automatic grading systems more safely in
practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AdaPrompt: Adaptive Model Training for Prompt-based NLP. (arXiv:2202.04824v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04824">
<div class="article-summary-box-inner">
<span><p>Prompt-based learning, with its capability to tackle zero-shot and few-shot
NLP tasks, has gained much attention in community. The main idea is to bridge
the gap between NLP downstream tasks and language modeling (LM), by mapping
these tasks into natural language prompts, which are then filled by pre-trained
language models (PLMs). However, for prompt learning, there are still two
salient gaps between NLP tasks and pretraining. First, prompt information is
not necessarily sufficiently present during LM pretraining. Second,
task-specific data are not necessarily well represented during pretraining. We
address these two issues by proposing AdaPrompt, adaptively retrieving external
data for continual pretraining of PLMs by making use of both task and prompt
characteristics. In addition, we make use of knowledge in Natural Language
Inference models for deriving adaptive verbalizers. Experimental results on
five NLP benchmarks show that AdaPrompt can improve over standard PLMs in
few-shot settings. In addition, in zero-shot settings, our method outperforms
standard prompt-based methods by up to 26.35\% relative error reduction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone. (arXiv:2206.07643v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.07643">
<div class="article-summary-box-inner">
<span><p>Vision-language (VL) pre-training has recently received considerable
attention. However, most existing end-to-end pre-training approaches either
only aim to tackle VL tasks such as image-text retrieval, visual question
answering (VQA) and image captioning that test high-level understanding of
images, or only target region-level understanding for tasks such as phrase
grounding and object detection. We present FIBER (Fusion-In-the-Backbone-based
transformER), a new VL model architecture that can seamlessly handle both these
types of tasks. Instead of having dedicated transformer layers for fusion after
the uni-modal backbones, FIBER pushes multimodal fusion deep into the model by
inserting cross-attention into the image and text backbones, bringing gains in
terms of memory and performance. In addition, unlike previous work that is
either only pre-trained on image-text data or on fine-grained data with
box-level annotations, we present a two-stage pre-training strategy that uses
both these kinds of data efficiently: (i) coarse-grained pre-training based on
image-text data; followed by (ii) fine-grained pre-training based on
image-text-box data. We conduct comprehensive experiments on a wide range of VL
tasks, ranging from VQA, image captioning, and retrieval, to phrase grounding,
referring expression comprehension, and object detection. Using deep multimodal
fusion coupled with the two-stage pre-training, FIBER provides consistent
performance improvements over strong baselines across all tasks, often
outperforming methods using magnitudes more data. Code is available at
https://github.com/microsoft/FIBER.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Algorithms for Weighted Pushdown Automata. (arXiv:2210.06884v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06884">
<div class="article-summary-box-inner">
<span><p>Weighted pushdown automata (WPDAs) are at the core of many natural language
processing tasks, like syntax-based statistical machine translation and
transition-based dependency parsing. As most existing dynamic programming
algorithms are designed for context-free grammars (CFGs), algorithms for PDAs
often resort to a PDA-to-CFG conversion. In this paper, we develop novel
algorithms that operate directly on WPDAs. Our algorithms are inspired by
Lang's algorithm, but use a more general definition of pushdown automaton and
either reduce the space requirements by a factor of $|\Gamma|$ (the size of the
stack alphabet) or reduce the runtime by a factor of more than $|Q|$ (the
number of states). When run on the same class of PDAs as Lang's algorithm, our
algorithm is both more space-efficient by a factor of $|\Gamma|$ and more
time-efficient by a factor of $|Q| \cdot |\Gamma|$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simulating realistic speech overlaps improves multi-talker ASR. (arXiv:2210.15715v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.15715">
<div class="article-summary-box-inner">
<span><p>Multi-talker automatic speech recognition (ASR) has been studied to generate
transcriptions of natural conversation including overlapping speech of multiple
speakers. Due to the difficulty in acquiring real conversation data with
high-quality human transcriptions, a na\"ive simulation of multi-talker speech
by randomly mixing multiple utterances was conventionally used for model
training. In this work, we propose an improved technique to simulate
multi-talker overlapping speech with realistic speech overlaps, where an
arbitrary pattern of speech overlaps is represented by a sequence of discrete
tokens. With this representation, speech overlapping patterns can be learned
from real conversations based on a statistical language model, such as N-gram,
which can be then used to generate multi-talker speech for training. In our
experiments, multi-talker ASR models trained with the proposed method show
consistent improvement on the word error rates across multiple datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning an Artificial Language for Knowledge-Sharing in Multilingual Translation. (arXiv:2211.01292v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.01292">
<div class="article-summary-box-inner">
<span><p>The cornerstone of multilingual neural translation is shared representations
across languages. Given the theoretically infinite representation power of
neural networks, semantically identical sentences are likely represented
differently. While representing sentences in the continuous latent space
ensures expressiveness, it introduces the risk of capturing of irrelevant
features which hinders the learning of a common representation. In this work,
we discretize the encoder output latent space of multilingual models by
assigning encoder states to entries in a codebook, which in effect represents
source sentences in a new artificial language. This discretization process not
only offers a new way to interpret the otherwise black-box model
representations, but, more importantly, gives potential for increasing
robustness in unseen testing conditions. We validate our approach on
large-scale experiments with realistic data volumes and domains. When tested in
zero-shot conditions, our approach is competitive with two strong alternatives
from the literature. We also use the learned artificial language to analyze
model behavior, and discover that using a similar bridge language increases
knowledge-sharing among the remaining languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SLATE: A Sequence Labeling Approach for Task Extraction from Free-form Inked Content. (arXiv:2211.04454v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.04454">
<div class="article-summary-box-inner">
<span><p>We present SLATE, a sequence labeling approach for extracting tasks from
free-form content such as digitally handwritten (or "inked") notes on a virtual
whiteboard. Our approach allows us to create a single, low-latency model to
simultaneously perform sentence segmentation and classification of these
sentences into task/non-task sentences. SLATE greatly outperforms a baseline
two-model (sentence segmentation followed by classification model) approach,
achieving a task F1 score of 84.4%, a sentence segmentation (boundary
similarity) score of 88.4% and three times lower latency compared to the
baseline. Furthermore, we provide insights into tackling challenges of
performing NLP on the inking domain. We release both our code and dataset for
this novel task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MEE: A Novel Multilingual Event Extraction Dataset. (arXiv:2211.05955v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.05955">
<div class="article-summary-box-inner">
<span><p>Event Extraction (EE) is one of the fundamental tasks in Information
Extraction (IE) that aims to recognize event mentions and their arguments
(i.e., participants) from text. Due to its importance, extensive methods and
resources have been developed for Event Extraction. However, one limitation of
current research for EE involves the under-exploration for non-English
languages in which the lack of high-quality multilingual EE datasets for model
training and evaluation has been the main hindrance. To address this
limitation, we propose a novel Multilingual Event Extraction dataset (MEE) that
provides annotation for more than 50K event mentions in 8 typologically
different languages. MEE comprehensively annotates data for entity mentions,
event triggers and event arguments. We conduct extensive experiments on the
proposed dataset to reveal challenges and opportunities for multilingual EE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MINION: a Large-Scale and Diverse Dataset for Multilingual Event Detection. (arXiv:2211.05958v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.05958">
<div class="article-summary-box-inner">
<span><p>Event Detection (ED) is the task of identifying and classifying trigger words
of event mentions in text. Despite considerable research efforts in recent
years for English text, the task of ED in other languages has been
significantly less explored. Switching to non-English languages, important
research questions for ED include how well existing ED models perform on
different languages, how challenging ED is in other languages, and how well ED
knowledge and annotation can be transferred across languages. To answer those
questions, it is crucial to obtain multilingual ED datasets that provide
consistent event annotation for multiple languages. There exist some
multilingual ED datasets; however, they tend to cover a handful of languages
and mainly focus on popular ones. Many languages are not covered in existing
multilingual ED datasets. In addition, the current datasets are often small and
not accessible to the public. To overcome those shortcomings, we introduce a
new large-scale multilingual dataset for ED (called MINION) that consistently
annotates events for 8 different languages; 5 of them have not been supported
by existing multilingual datasets. We also perform extensive experiments and
analysis to demonstrate the challenges and transferability of ED across
languages in MINION that in all call for more research effort in this area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Knowledge-Enhanced Pre-trained Language Models. (arXiv:2211.05994v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.05994">
<div class="article-summary-box-inner">
<span><p>Pre-trained Language Models (PLMs) which are trained on large text corpus via
self-supervised learning method, have yielded promising performance on various
tasks in Natural Language Processing (NLP). However, though PLMs with huge
parameters can effectively possess rich knowledge learned from massive training
text and benefit downstream tasks at the fine-tuning stage, they still have
some limitations such as poor reasoning ability due to the lack of external
knowledge. Research has been dedicated to incorporating knowledge into PLMs to
tackle these issues. In this paper, we present a comprehensive review of
Knowledge-Enhanced Pre-trained Language Models (KE-PLMs) to provide a clear
insight into this thriving field. We introduce appropriate taxonomies
respectively for Natural Language Understanding (NLU) and Natural Language
Generation (NLG) to highlight these two main tasks of NLP. For NLU, we divide
the types of knowledge into four categories: linguistic knowledge, text
knowledge, knowledge graph (KG), and rule knowledge. The KE-PLMs for NLG are
categorized into KG-based and retrieval-based methods. Finally, we point out
some promising future directions of KE-PLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-VQG: Generating Engaging Questions for Multiple Images. (arXiv:2211.07441v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.07441">
<div class="article-summary-box-inner">
<span><p>Generating engaging content has drawn much recent attention in the NLP
community. Asking questions is a natural way to respond to photos and promote
awareness. However, most answers to questions in traditional question-answering
(QA) datasets are factoids, which reduce individuals' willingness to answer.
Furthermore, traditional visual question generation (VQG) confines the source
data for question generation to single images, resulting in a limited ability
to comprehend time-series information of the underlying event. In this paper,
we propose generating engaging questions from multiple images. We present MVQG,
a new dataset, and establish a series of baselines, including both end-to-end
and dual-stage architectures. Results show that building stories behind the
image sequence enables models to generate engaging questions, which confirms
our assumption that people typically construct a picture of the event in their
minds before asking questions. These results open up an exciting challenge for
visual-and-language models to implicitly construct a story behind a series of
photos to allow for creativity and experience sharing and hence draw attention
to downstream applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Much Hate with #china? A Preliminary Analysis on China-related Hateful Tweets Two Years After the Covid Pandemic Began. (arXiv:2211.06116v1 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.06116">
<div class="article-summary-box-inner">
<span><p>Following the outbreak of a global pandemic, online content is filled with
hate speech. Donald Trump's ''Chinese Virus'' tweet shifted the blame for the
spread of the Covid-19 virus to China and the Chinese people, which triggered a
new round of anti-China hate both online and offline. This research intends to
examine China-related hate speech on Twitter during the two years following the
burst of the pandemic (2020 and 2021). Through Twitter's API, in total
2,172,333 tweets hashtagged #china posted during the time were collected. By
employing multiple state-of-the-art pretrained language models for hate speech
detection, we identify a wide range of hate of various types, resulting in an
automatically labeled anti-China hate speech dataset. We identify a hateful
rate in #china tweets of 2.5% in 2020 and 1.9% in 2021. This is well above the
average rate of online hate speech on Twitter at 0.6% identified in Gao et al.,
2017. We further analyzed the longitudinal development of #china tweets and
those identified as hateful in 2020 and 2021 through visualizing the daily
number and hate rate over the two years. Our keyword analysis of hate speech in
#china tweets reveals the most frequently mentioned terms in the hateful #china
tweets, which can be used for further social science studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">I Can't Believe There's No Images! Learning Visual Tasks Using only Language Data. (arXiv:2211.09778v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09778">
<div class="article-summary-box-inner">
<span><p>Many high-level skills that are required for computer vision tasks, such as
parsing questions, comparing and contrasting semantics, and writing
descriptions, are also required in other domains such as natural language
processing. In this paper, we ask whether this makes it possible to learn those
skills from text data and then use them to complete vision tasks without ever
training on visual training data. Key to our approach is exploiting the joint
embedding space of contrastively trained vision and language encoders. In
practice, there can be systematic differences between embedding spaces for
different modalities in contrastive models, and we analyze how these
differences affect our approach and study a variety of strategies to mitigate
this concern. We produce models using only text training data on three tasks:
image captioning, visual entailment and visual question answering, and evaluate
them on standard benchmarks using images. We find that this kind of transfer is
possible and results in only a small drop in performance relative to models
trained on images. We also showcase a variety of stylistic image captioning
models that were trained using no image data and no human-curated language
data, but instead text data from books, the web, or language models.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-11-21 23:15:34.814394316 UTC">2022-11-21 23:15:34 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>