<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-08-16T01:30:00Z">08-16</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">AI Text-to-Behavior: A Study In Steerability. (arXiv:2308.07326v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07326">
<div class="article-summary-box-inner">
<span><p>The research explores the steerability of Large Language Models (LLMs),
particularly OpenAI's ChatGPT iterations. By employing a behavioral psychology
framework called OCEAN (Openness, Conscientiousness, Extroversion,
Agreeableness, Neuroticism), we quantitatively gauged the model's
responsiveness to tailored prompts. When asked to generate text mimicking an
extroverted personality, OCEAN scored the language alignment to that behavioral
trait. In our analysis, while "openness" presented linguistic ambiguity,
"conscientiousness" and "neuroticism" were distinctly evoked in the OCEAN
framework, with "extroversion" and "agreeableness" showcasing a notable overlap
yet distinct separation from other traits. Our findings underscore GPT's
versatility and ability to discern and adapt to nuanced instructions.
Furthermore, historical figure simulations highlighted the LLM's capacity to
internalize and project instructible personas, precisely replicating their
philosophies and dialogic styles. However, the rapid advancements in LLM
capabilities and the opaque nature of some training techniques make metric
proposals degrade rapidly. Our research emphasizes a quantitative role to
describe steerability in LLMs, presenting both its promise and areas for
further refinement in aligning its progress to human intentions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic. (arXiv:2308.07336v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07336">
<div class="article-summary-box-inner">
<span><p>We study a synthetic corpus-based approach for language models (LMs) to
acquire logical deductive reasoning ability. The previous studies generated
deduction examples using specific sets of deduction rules. However, these rules
were limited or otherwise arbitrary. This can limit the generalizability of
acquired deductive reasoning ability. We rethink this and adopt a well-grounded
set of deduction rules based on formal logic theory, which can derive any other
deduction rules when combined in a multistep way. We empirically verify that
LMs trained on the proposed corpora, which we name $\textbf{FLD}$
($\textbf{F}$ormal $\textbf{L}$ogic $\textbf{D}$eduction), acquire more
generalizable deductive reasoning ability. Furthermore, we identify the aspects
of deductive reasoning ability on which deduction corpora can enhance LMs and
those on which they cannot. Finally, on the basis of these results, we discuss
the future directions for applying deduction corpora or other approaches for
each aspect. We release the code, data, and models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emergent communication for AR. (arXiv:2308.07342v1 [eess.SP])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07342">
<div class="article-summary-box-inner">
<span><p>Mobile augmented reality (MAR) is widely acknowledged as one of the
ubiquitous interfaces to the digital twin and Metaverse, demanding unparalleled
levels of latency, computational power, and energy efficiency. The existing
solutions for realizing MAR combine multiple technologies like edge, cloud
computing, and fifth-generation (5G) networks. However, the inherent
communication latency of visual data imposes apparent limitations on the
quality of experience (QoE). To address the challenge, we propose an emergent
semantic communication framework to learn the communication protocols in MAR.
Specifically, we train two agents through a modified Lewis signaling game to
emerge a discrete communication protocol spontaneously. Based on this protocol,
two agents can communicate about the abstract idea of visual data through
messages with extremely small data sizes in a noisy channel, which leads to
message errors. To better simulate real-world scenarios, we incorporate channel
uncertainty into our training process. Experiments have shown that the proposed
scheme has better generalization on unseen objects than traditional object
recognition used in MAR and can effectively enhance communication efficiency
through the utilization of small-size messages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Text Injection to Improve Recognition of Personal Identifiers in Speech. (arXiv:2308.07393v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07393">
<div class="article-summary-box-inner">
<span><p>Accurate recognition of specific categories, such as persons' names, dates or
other identifiers is critical in many Automatic Speech Recognition (ASR)
applications. As these categories represent personal information, ethical use
of this data including collection, transcription, training and evaluation
demands special care. One way of ensuring the security and privacy of
individuals is to redact or eliminate Personally Identifiable Information (PII)
from collection altogether. However, this results in ASR models that tend to
have lower recognition accuracy of these categories. We use text-injection to
improve the recognition of PII categories by including fake textual substitutes
of PII categories in the training data using a text injection method. We
demonstrate substantial improvement to Recall of Names and Dates in medical
notes while improving overall WER. For alphanumeric digit sequences we show
improvements to Character Error Rate and Sentence Accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text Injection for Capitalization and Turn-Taking Prediction in Speech Models. (arXiv:2308.07395v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07395">
<div class="article-summary-box-inner">
<span><p>Text injection for automatic speech recognition (ASR), wherein unpaired
text-only data is used to supplement paired audio-text data, has shown
promising improvements for word error rate. This study examines the use of text
injection for auxiliary tasks, which are the non-ASR tasks often performed by
an E2E model. In this work, we use joint end-to-end and internal language model
training (JEIT) as our text injection algorithm to train an ASR model which
performs two auxiliary tasks. The first is capitalization, which is a
de-normalization task. The second is turn-taking prediction, which attempts to
identify whether a user has completed their conversation turn in a digital
assistant interaction. We show results demonstrating that our text injection
method boosts capitalization performance for long-tail data, and improves
turn-taking detection recall.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Development and Evaluation of Three Chatbots for Postpartum Mood and Anxiety Disorders. (arXiv:2308.07407v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07407">
<div class="article-summary-box-inner">
<span><p>In collaboration with Postpartum Support International (PSI), a non-profit
organization dedicated to supporting caregivers with postpartum mood and
anxiety disorders, we developed three chatbots to provide context-specific
empathetic support to postpartum caregivers, leveraging both rule-based and
generative models. We present and evaluate the performance of our chatbots
using both machine-based metrics and human-based questionnaires. Overall, our
rule-based model achieves the best performance, with outputs that are close to
ground truth reference and contain the highest levels of empathy. Human users
prefer the rule-based chatbot over the generative chatbot for its
context-specific and human-like replies. Our generative chatbot also produced
empathetic responses and was described by human users as engaging. However,
limitations in the training dataset often result in confusing or nonsensical
responses. We conclude by discussing practical benefits of rule-based vs.
generative models for supporting individuals with mental health challenges. In
light of the recent surge of ChatGPT and BARD, we also discuss the
possibilities and pitfalls of large language models for digital mental
healthcare.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Playing with Words: Comparing the Vocabulary and Lexical Richness of ChatGPT and Humans. (arXiv:2308.07462v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07462">
<div class="article-summary-box-inner">
<span><p>The introduction of Artificial Intelligence (AI) generative language models
such as GPT (Generative Pre-trained Transformer) and tools such as ChatGPT has
triggered a revolution that can transform how text is generated. This has many
implications, for example, as AI-generated text becomes a significant fraction
of the text in many disciplines, would this have an effect on the language
capabilities of readers and also on the training of newer AI tools? Would it
affect the evolution of languages? Focusing on one specific aspect of the
language: words; will the use of tools such as ChatGPT increase or reduce the
vocabulary used or the lexical richness (understood as the number of different
words used in a written or oral production) when writing a given text? This has
implications for words, as those not included in AI-generated content will tend
to be less and less popular and may eventually be lost. In this work, we
perform an initial comparison of the vocabulary and lexical richness of ChatGPT
and humans when performing the same tasks. In more detail, two datasets
containing the answers to different types of questions answered by ChatGPT and
humans are used, and the analysis shows that ChatGPT tends to use fewer
distinct words and lower lexical richness than humans. These results are very
preliminary and additional datasets and ChatGPT configurations have to be
evaluated to extract more general conclusions. Therefore, further research is
needed to understand how the use of ChatGPT and more broadly generative AI
tools will affect the vocabulary and lexical richness in different types of
text and languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">O-1: Self-training with Oracle and 1-best Hypothesis. (arXiv:2308.07486v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07486">
<div class="article-summary-box-inner">
<span><p>We introduce O-1, a new self-training objective to reduce training bias and
unify training and evaluation metrics for speech recognition. O-1 is a faster
variant of Expected Minimum Bayes Risk (EMBR), that boosts the oracle
hypothesis and can accommodate both supervised and unsupervised data. We
demonstrate the effectiveness of our approach in terms of recognition on
publicly available SpeechStew datasets and a large-scale, in-house data set. On
Speechstew, the O-1 objective closes the gap between the actual and oracle
performance by 80\% relative compared to EMBR which bridges the gap by 43\%
relative. O-1 achieves 13\% to 25\% relative improvement over EMBR on the
various datasets that SpeechStew comprises of, and a 12\% relative gap
reduction with respect to the oracle WER over EMBR training on the in-house
dataset. Overall, O-1 results in a 9\% relative improvement in WER over EMBR,
thereby speaking to the scalability of the proposed objective for large-scale
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SOTASTREAM: A Streaming Approach to Machine Translation Training. (arXiv:2308.07489v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07489">
<div class="article-summary-box-inner">
<span><p>Many machine translation toolkits make use of a data preparation step wherein
raw data is transformed into a tensor format that can be used directly by the
trainer. This preparation step is increasingly at odds with modern research and
development practices because this process produces a static, unchangeable
version of the training data, making common training-time needs difficult
(e.g., subword sampling), time-consuming (preprocessing with large data can
take days), expensive (e.g., disk space), and cumbersome (managing experiment
combinatorics). We propose an alternative approach that separates the
generation of data from the consumption of that data. In this approach, there
is no separate pre-processing step; data generation produces an infinite stream
of permutations of the raw training data, which the trainer tensorizes and
batches as it is consumed. Additionally, this data stream can be manipulated by
a set of user-definable operators that provide on-the-fly modifications, such
as data normalization, augmentation or filtering. We release an open-source
toolkit, SOTASTREAM, that implements this approach:
https://github.com/marian-nmt/sotastream. We show that it cuts training time,
adds flexibility, reduces experiment management complexity, and reduces disk
space, all without affecting the accuracy of the trained models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Race Detection Using Large Language Models. (arXiv:2308.07505v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07505">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) are demonstrating significant promise as an
alternate strategy to facilitate analyses and optimizations of high-performance
computing programs, circumventing the need for resource-intensive manual tool
creation. In this paper, we explore a novel LLM-based data race detection
approach combining prompting engineering and fine-tuning techniques. We create
a dedicated dataset named DRB-ML, which is derived from DataRaceBench, with
fine-grain labels showing the presence of data race pairs and their associated
variables, line numbers, and read/write information. DRB-ML is then used to
evaluate representative LLMs and fine-tune open-source ones. Our experiment
shows that LLMs can be a viable approach to data race detection. However, they
still cannot compete with traditional data race detection tools when we need
detailed information about variable pairs causing data races.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Finding Stakeholder-Material Information from 10-K Reports using Fine-Tuned BERT and LSTM Models. (arXiv:2308.07522v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07522">
<div class="article-summary-box-inner">
<span><p>All public companies are required by federal securities law to disclose their
business and financial activities in their annual 10-K reports. Each report
typically spans hundreds of pages, making it difficult for human readers to
identify and extract the material information efficiently. To solve the
problem, I have fine-tuned BERT models and RNN models with LSTM layers to
identify stakeholder-material information, defined as statements that carry
information about a company's influence on its stakeholders, including
customers, employees, investors, and the community and natural environment. The
existing practice uses keyword search to identify such information, which is my
baseline model. Using business expert-labeled training data of nearly 6,000
sentences from 62 10-K reports published in 2022, the best model has achieved
an accuracy of 0.904 and an F1 score of 0.899 in test data, significantly above
the baseline model's 0.781 and 0.749 respectively. Furthermore, the same work
was replicated on more granular taxonomies, based on which four distinct groups
of stakeholders (i.e., customers, investors, employees, and the community and
natural environment) are tested separately. Similarly, fined-tuned BERT models
outperformed LSTM and the baseline. The implications for industry application
and ideas for future extensions are discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CALYPSO: LLMs as Dungeon Masters' Assistants. (arXiv:2308.07540v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07540">
<div class="article-summary-box-inner">
<span><p>The role of a Dungeon Master, or DM, in the game Dungeons &amp; Dragons is to
perform multiple tasks simultaneously. The DM must digest information about the
game setting and monsters, synthesize scenes to present to other players, and
respond to the players' interactions with the scene. Doing all of these tasks
while maintaining consistency within the narrative and story world is no small
feat of human cognition, making the task tiring and unapproachable to new
players. Large language models (LLMs) like GPT-3 and ChatGPT have shown
remarkable abilities to generate coherent natural language text. In this paper,
we conduct a formative evaluation with DMs to establish the use cases of LLMs
in D&amp;D and tabletop gaming generally. We introduce CALYPSO, a system of
LLM-powered interfaces that support DMs with information and inspiration
specific to their own scenario. CALYPSO distills game context into bite-sized
prose and helps brainstorm ideas without distracting the DM from the game. When
given access to CALYPSO, DMs reported that it generated high-fidelity text
suitable for direct presentation to players, and low-fidelity ideas that the DM
could develop further while maintaining their creative agency. We see CALYPSO
as exemplifying a paradigm of AI-augmented tools that provide synchronous
creative assistance within established game worlds, and tabletop gaming more
broadly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A User-Centered Evaluation of Spanish Text Simplification. (arXiv:2308.07556v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07556">
<div class="article-summary-box-inner">
<span><p>We present an evaluation of text simplification (TS) in Spanish for a
production system, by means of two corpora focused in both complex-sentence and
complex-word identification. We compare the most prevalent Spanish-specific
readability scores with neural networks, and show that the latter are
consistently better at predicting user preferences regarding TS. As part of our
analysis, we find that multilingual models underperform against equivalent
Spanish-only models on the same task, yet all models focus too often on
spurious statistical features, such as sentence length. We release the corpora
in our evaluation to the broader community with the hopes of pushing forward
the state-of-the-art in Spanish natural language processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VBD-MT Chinese-Vietnamese Translation Systems for VLSP 2022. (arXiv:2308.07601v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07601">
<div class="article-summary-box-inner">
<span><p>We present our systems participated in the VLSP 2022 machine translation
shared task. In the shared task this year, we participated in both translation
tasks, i.e., Chinese-Vietnamese and Vietnamese-Chinese translations. We build
our systems based on the neural-based Transformer model with the powerful
multilingual denoising pre-trained model mBART. The systems are enhanced by a
sampling method for backtranslation, which leverage large scale available
monolingual data. Additionally, several other methods are applied to improve
the translation quality including ensembling and postprocessing. We achieve
38.9 BLEU on ChineseVietnamese and 38.0 BLEU on VietnameseChinese on the public
test sets, which outperform several strong baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis. (arXiv:2308.07610v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07610">
<div class="article-summary-box-inner">
<span><p>Automated log analysis is crucial in modern software-intensive systems for
ensuring reliability and resilience throughout software maintenance and
engineering life cycles. Existing methods perform tasks such as log parsing and
log anomaly detection by providing a single prediction value without
interpretation. However, given the increasing volume of system events, the
limited interpretability of analysis results hinders analysts' trust and their
ability to take appropriate actions. Moreover, these methods require
substantial in-domain training data, and their performance declines sharply (by
up to 62.5%) in online scenarios involving unseen logs from new domains, a
common occurrence due to rapid software updates. In this paper, we propose
LogPrompt, a novel zero-shot and interpretable log analysis approach. LogPrompt
employs large language models (LLMs) to perform zero-shot log analysis tasks
via a suite of advanced prompt strategies tailored for log tasks, which
enhances LLMs' performance by up to 107.5% compared with simple prompts.
Experiments on nine publicly available evaluation datasets across two tasks
demonstrate that LogPrompt, despite using no training data, outperforms
existing approaches trained on thousands of logs by up to around 50%. We also
conduct a human evaluation of LogPrompt's interpretability, with six
practitioners possessing over 10 years of experience, who highly rated the
generated content in terms of usefulness and readability (averagely 4.42/5).
LogPrompt also exhibits remarkable compatibility with open-source and
smaller-scale LLMs, making it flexible for practical deployment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Model Compression for Large Language Models. (arXiv:2308.07633v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07633">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have revolutionized natural language processing
tasks with remarkable success. However, their formidable size and computational
demands present significant challenges for practical deployment, especially in
resource-constrained environments. As these challenges become increasingly
pertinent, the field of model compression has emerged as a pivotal research
area to alleviate these limitations. This paper presents a comprehensive survey
that navigates the landscape of model compression techniques tailored
specifically for LLMs. Addressing the imperative need for efficient deployment,
we delve into various methodologies, encompassing quantization, pruning,
knowledge distillation, and more. Within each of these techniques, we highlight
recent advancements and innovative approaches that contribute to the evolving
landscape of LLM research. Furthermore, we explore benchmarking strategies and
evaluation metrics that are essential for assessing the effectiveness of
compressed LLMs. By providing insights into the latest developments and
practical implications, this survey serves as an invaluable resource for both
researchers and practitioners. As LLMs continue to evolve, this survey aims to
facilitate enhanced efficiency and real-world applicability, establishing a
foundation for future advancements in the field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM-Mini-CEX: Automatic Evaluation of Large Language Model for Diagnostic Conversation. (arXiv:2308.07635v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07635">
<div class="article-summary-box-inner">
<span><p>There is an increasing interest in developing LLMs for medical diagnosis to
improve diagnosis efficiency. Despite their alluring technological potential,
there is no unified and comprehensive evaluation criterion, leading to the
inability to evaluate the quality and potential risks of medical LLMs, further
hindering the application of LLMs in medical treatment scenarios. Besides,
current evaluations heavily rely on labor-intensive interactions with LLMs to
obtain diagnostic dialogues and human evaluation on the quality of diagnosis
dialogue. To tackle the lack of unified and comprehensive evaluation criterion,
we first initially establish an evaluation criterion, termed LLM-specific
Mini-CEX to assess the diagnostic capabilities of LLMs effectively, based on
original Mini-CEX. To address the labor-intensive interaction problem, we
develop a patient simulator to engage in automatic conversations with LLMs, and
utilize ChatGPT for evaluating diagnosis dialogues automatically. Experimental
results show that the LLM-specific Mini-CEX is adequate and necessary to
evaluate medical diagnosis dialogue. Besides, ChatGPT can replace manual
evaluation on the metrics of humanistic qualities and provides reproducible and
automated comparisons between different LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Steering Language Generation: Harnessing Contrastive Expert Guidance and Negative Prompting for Coherent and Diverse Synthetic Data Generation. (arXiv:2308.07645v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07645">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) hold immense potential to generate synthetic
data of high quality and utility, which has numerous applications from
downstream model training to practical data utilisation. However, contemporary
models, despite their impressive capacities, consistently struggle to produce
both coherent and diverse data. To address the coherency issue, we introduce
contrastive expert guidance, where the difference between the logit
distributions of fine-tuned and base language models is emphasised to ensure
domain adherence. In order to ensure diversity, we utilise existing real and
synthetic examples as negative prompts to the model. We deem this dual-pronged
approach to logit reshaping as STEER: Semantic Text Enhancement via Embedding
Repositioning. STEER operates at inference-time and systematically guides the
LLMs to strike a balance between adherence to the data distribution (ensuring
semantic fidelity) and deviation from prior synthetic examples or existing real
datasets (ensuring diversity and authenticity). This delicate balancing act is
achieved by dynamically moving towards or away from chosen representations in
the latent space. STEER demonstrates improved performance over previous
synthetic data generation techniques, exhibiting better balance between data
diversity and coherency across three distinct tasks: hypothesis generation,
toxic and non-toxic comment generation, and commonsense reasoning task
generation. We demonstrate how STEER allows for fine-tuned control over the
diversity-coherency trade-off via its hyperparameters, highlighting its
versatility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SEER: Super-Optimization Explorer for HLS using E-graph Rewriting with MLIR. (arXiv:2308.07654v1 [cs.PL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07654">
<div class="article-summary-box-inner">
<span><p>High-level synthesis (HLS) is a process that automatically translates a
software program in a high-level language into a low-level hardware
description. However, the hardware designs produced by HLS tools still suffer
from a significant performance gap compared to manual implementations. This is
because the input HLS programs must still be written using hardware design
principles.
</p>
<p>Existing techniques either leave the program source unchanged or perform a
fixed sequence of source transformation passes, potentially missing
opportunities to find the optimal design. We propose a super-optimization
approach for HLS that automatically rewrites an arbitrary software program into
efficient HLS code that can be used to generate an optimized hardware design.
We developed a toolflow named SEER, based on the e-graph data structure, to
efficiently explore equivalent implementations of a program at scale. SEER
provides an extensible framework, orchestrating existing software compiler
passes and hardware synthesis optimizers.
</p>
<p>Our work is the first attempt to exploit e-graph rewriting for large software
compiler frameworks, such as MLIR. Across a set of open-source benchmarks, we
show that SEER achieves up to 38x the performance within 1.4x the area of the
original program. Via an Intel-provided case study, SEER demonstrates the
potential to outperform manually optimized designs produced by hardware
experts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention Is Not All You Need Anymore. (arXiv:2308.07661v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07661">
<div class="article-summary-box-inner">
<span><p>In recent years, the popular Transformer architecture has achieved great
success in many application areas, including natural language processing and
computer vision. Many existing works aim to reduce the computational and memory
complexity of the self-attention mechanism in the Transformer by trading off
performance. However, performance is key for the continuing success of the
Transformer. In this paper, a drop-in replacement for the self-attention
mechanism in the Transformer, called the Extractor, is proposed. Experimental
results show that replacing the self-attention mechanism with the Extractor
improves the performance of the Transformer. Furthermore, the proposed
Extractor has the potential to run faster than the self-attention since it has
a much shorter critical path of computation. Additionally, the sequence
prediction problem in the context of text generation is formulated using
variable-length discrete-time Markov chains, and the Transformer is reviewed
based on our understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Better Zero-Shot Reasoning with Role-Play Prompting. (arXiv:2308.07702v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07702">
<div class="article-summary-box-inner">
<span><p>Modern large language models (LLMs), such as ChatGPT, exhibit a remarkable
capacity for role-playing, enabling them to embody not only human characters
but also non-human entities like a Linux terminal. This versatility allows them
to simulate complex human-like interactions and behaviors within various
contexts, as well as to emulate specific objects or systems. While these
capabilities have enhanced user engagement and introduced novel modes of
interaction, the influence of role-playing on LLMs' reasoning abilities remains
underexplored. In this study, we introduce a strategically designed role-play
prompting methodology and assess its performance under the zero-shot setting
across twelve diverse reasoning benchmarks, encompassing arithmetic,
commonsense reasoning, symbolic reasoning, and more. Leveraging models such as
ChatGPT and Llama 2, our empirical results illustrate that role-play prompting
consistently surpasses the standard zero-shot approach across most datasets.
Notably, accuracy on AQuA rises from 53.5% to 63.8%, and on Last Letter from
23.8% to 84.2%. Beyond enhancing contextual understanding, we posit that
role-play prompting serves as an implicit Chain-of-Thought (CoT) trigger,
thereby improving the quality of reasoning. By comparing our approach with the
Zero-Shot-CoT technique, which prompts the model to "think step by step", we
further demonstrate that role-play prompting can generate a more effective CoT.
This highlights its potential to augment the reasoning capabilities of LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Transfer Learning in Medical Image Segmentation using Vision-Language Models. (arXiv:2308.07706v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07706">
<div class="article-summary-box-inner">
<span><p>Medical Image Segmentation is crucial in various clinical applications within
the medical domain. While state-of-the-art segmentation models have proven
effective, integrating textual guidance to enhance visual features for this
task remains an area with limited progress. Existing segmentation models that
utilize textual guidance are primarily trained on open-domain images, raising
concerns about their direct applicability in the medical domain without manual
intervention or fine-tuning.
</p>
<p>To address these challenges, we propose using multimodal vision-language
models for capturing semantic information from image descriptions and images,
enabling the segmentation of diverse medical images. This study comprehensively
evaluates existing vision language models across multiple datasets to assess
their transferability from the open domain to the medical field. Furthermore,
we introduce variations of image descriptions for previously unseen images in
the dataset, revealing notable variations in model performance based on the
generated prompts.
</p>
<p>Our findings highlight the distribution shift between the open-domain images
and the medical domain and show that the segmentation models trained on
open-domain images are not directly transferrable to the medical field. But
their performance can be increased by finetuning them in the medical datasets.
We report the zero-shot and finetuned segmentation performance of 4 Vision
Language Models (VLMs) on 11 medical datasets using 9 types of prompts derived
from 14 attributes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SPM: Structured Pretraining and Matching Architectures for Relevance Modeling in Meituan Search. (arXiv:2308.07711v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07711">
<div class="article-summary-box-inner">
<span><p>In e-commerce search, relevance between query and documents is an essential
requirement for satisfying user experience. Different from traditional
e-commerce platforms that offer products, users search on life service
platforms such as Meituan mainly for product providers, which usually have
abundant structured information, e.g. name, address, category, thousands of
products. Modeling search relevance with these rich structured contents is
challenging due to the following issues: (1) there is language distribution
discrepancy among different fields of structured document, making it difficult
to directly adopt off-the-shelf pretrained language model based methods like
BERT. (2) different fields usually have different importance and their length
vary greatly, making it difficult to extract document information helpful for
relevance matching.
</p>
<p>To tackle these issues, in this paper we propose a novel two-stage
pretraining and matching architecture for relevance matching with rich
structured documents. At pretraining stage, we propose an effective pretraining
method that employs both query and multiple fields of document as inputs,
including an effective information compression method for lengthy fields. At
relevance matching stage, a novel matching method is proposed by leveraging
domain knowledge in search query to generate more effective document
representations for relevance scoring. Extensive offline experiments and online
A/B tests on millions of users verify that the proposed architectures
effectively improve the performance of relevance modeling. The model has
already been deployed online, serving the search traffic of Meituan for over a
year.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Backward Reasoning in Large Language Models for Verification. (arXiv:2308.07758v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07758">
<div class="article-summary-box-inner">
<span><p>Chain-of-Though (CoT) prompting has shown promising performance in various
reasoning tasks. Recently, Self-Consistency \citep{wang2023selfconsistency}
proposes to sample a diverse set of reasoning chains which may lead to
different answers while the answer that receives the most votes is selected. In
this paper, we propose a novel method to use backward reasoning in verifying
candidate answers. We mask a token in the question by ${\bf x}$ and ask the LLM
to predict the masked token when a candidate answer is provided by \textit{a
simple template}, i.e., ``\textit{\textbf{If we know the answer of the above
question is \{a candidate answer\}, what is the value of unknown variable ${\bf
x}$?}}'' Intuitively, the LLM is expected to predict the masked token
successfully if the provided candidate answer is correct. We further propose
FOBAR to combine forward and backward reasoning for estimating the probability
of candidate answers. We conduct extensive experiments on six data sets and
three LLMs. Experimental results demonstrate that FOBAR achieves
state-of-the-art performance on various reasoning benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Visually-Rich Document Understanding via Layout Structure Modeling. (arXiv:2308.07777v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07777">
<div class="article-summary-box-inner">
<span><p>In recent years, the use of multi-modal pre-trained Transformers has led to
significant advancements in visually-rich document understanding. However,
existing models have mainly focused on features such as text and vision while
neglecting the importance of layout relationship between text nodes. In this
paper, we propose GraphLayoutLM, a novel document understanding model that
leverages the modeling of layout structure graph to inject document layout
knowledge into the model. GraphLayoutLM utilizes a graph reordering algorithm
to adjust the text sequence based on the graph structure. Additionally, our
model uses a layout-aware multi-head self-attention layer to learn document
layout knowledge. The proposed model enables the understanding of the spatial
arrangement of text elements, improving document comprehension. We evaluate our
model on various benchmarks, including FUNSD, XFUND and CORD, and achieve
state-of-the-art results among these datasets. Our experimental results
demonstrate that our proposed method provides a significant improvement over
existing approaches and showcases the importance of incorporating layout
information into document understanding models. We also conduct an ablation
study to investigate the contribution of each component of our model. The
results show that both the graph reordering algorithm and the layout-aware
multi-head self-attention layer play a crucial role in achieving the best
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Informed Named Entity Recognition Decoding for Generative Language Models. (arXiv:2308.07791v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07791">
<div class="article-summary-box-inner">
<span><p>Ever-larger language models with ever-increasing capabilities are by now
well-established text processing tools. Alas, information extraction tasks such
as named entity recognition are still largely unaffected by this progress as
they are primarily based on the previous generation of encoder-only transformer
models. Here, we propose a simple yet effective approach, Informed Named Entity
Recognition Decoding (iNERD), which treats named entity recognition as a
generative process. It leverages the language understanding capabilities of
recent generative models in a future-proof manner and employs an informed
decoding scheme incorporating the restricted nature of information extraction
into open-ended text generation, improving performance and eliminating any risk
of hallucinations. We coarse-tune our model on a merged named entity corpus to
strengthen its performance, evaluate five generative language models on eight
named entity recognition datasets, and achieve remarkable results, especially
in an environment with an unknown entity class set, demonstrating the
adaptability of the approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emotion Embeddings $\unicode{x2014}$ Learning Stable and Homogeneous Abstractions from Heterogeneous Affective Datasets. (arXiv:2308.07871v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07871">
<div class="article-summary-box-inner">
<span><p>Human emotion is expressed in many communication modalities and media formats
and so their computational study is equally diversified into natural language
processing, audio signal analysis, computer vision, etc. Similarly, the large
variety of representation formats used in previous research to describe
emotions (polarity scales, basic emotion categories, dimensional approaches,
appraisal theory, etc.) have led to an ever proliferating diversity of
datasets, predictive models, and software tools for emotion analysis. Because
of these two distinct types of heterogeneity, at the expressional and
representational level, there is a dire need to unify previous work on
increasingly diverging data and label types. This article presents such a
unifying computational model. We propose a training procedure that learns a
shared latent representation for emotions, so-called emotion embeddings,
independent of different natural languages, communication modalities, media or
representation label formats, and even disparate model architectures.
Experiments on a wide range of heterogeneous affective datasets indicate that
this approach yields the desired interoperability for the sake of reusability,
interpretability and flexibility, without penalizing prediction quality. Code
and data are archived under https://doi.org/10.5281/zenodo.7405327 .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Synthesizing Political Zero-Shot Relation Classification via Codebook Knowledge, NLI, and ChatGPT. (arXiv:2308.07876v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07876">
<div class="article-summary-box-inner">
<span><p>Recent supervised models for event coding vastly outperform pattern-matching
methods. However, their reliance solely on new annotations disregards the vast
knowledge within expert databases, hindering their applicability to
fine-grained classification. To address these limitations, we explore zero-shot
approaches for political event ontology relation classification, by leveraging
knowledge from established annotation codebooks. Our study encompasses both
ChatGPT and a novel natural language inference (NLI) based approach named ZSP.
ZSP adopts a tree-query framework that deconstructs the task into context,
modality, and class disambiguation levels. This framework improves
interpretability, efficiency, and adaptability to schema changes. By conducting
extensive experiments on our newly curated datasets, we pinpoint the
instability issues within ChatGPT and highlight the superior performance of
ZSP. ZSP achieves an impressive 40% improvement in F1 score for fine-grained
Rootcode classification. ZSP demonstrates competitive performance compared to
supervised BERT models, positioning it as a valuable tool for event record
validation and ontology development. Our work underscores the potential of
leveraging transfer learning and existing expertise to enhance the efficiency
and scalability of research in the field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Study on Knowledge Graph Embedding over Relational Patterns Based on Rule Learning. (arXiv:2308.07889v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07889">
<div class="article-summary-box-inner">
<span><p>Knowledge Graph Embedding (KGE) has proven to be an effective approach to
solving the Knowledge Graph Completion (KGC) task. Relational patterns which
refer to relations with specific semantics exhibiting graph patterns are an
important factor in the performance of KGE models. Though KGE models'
capabilities are analyzed over different relational patterns in theory and a
rough connection between better relational patterns modeling and better
performance of KGC has been built, a comprehensive quantitative analysis on KGE
models over relational patterns remains absent so it is uncertain how the
theoretical support of KGE to a relational pattern contributes to the
performance of triples associated to such a relational pattern. To address this
challenge, we evaluate the performance of 7 KGE models over 4 common relational
patterns on 2 benchmarks, then conduct an analysis in theory, entity frequency,
and part-to-whole three aspects and get some counterintuitive conclusions.
Finally, we introduce a training-free method Score-based Patterns Adaptation
(SPA) to enhance KGE models' performance over various relational patterns. This
approach is simple yet effective and can be applied to KGE models without
additional training. Our experimental results demonstrate that our method
generally enhances performance over specific relational patterns. Our source
code is available from GitHub at
https://github.com/zjukg/Comprehensive-Study-over-Relational-Patterns.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Link-Context Learning for Multimodal LLMs. (arXiv:2308.07891v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07891">
<div class="article-summary-box-inner">
<span><p>The ability to learn from context with novel concepts, and deliver
appropriate responses are essential in human conversations. Despite current
Multimodal Large Language Models (MLLMs) and Large Language Models (LLMs) being
trained on mega-scale datasets, recognizing unseen images or understanding
novel concepts in a training-free manner remains a challenge. In-Context
Learning (ICL) explores training-free few-shot learning, where models are
encouraged to ``learn to learn" from limited tasks and generalize to unseen
tasks. In this work, we propose link-context learning (LCL), which emphasizes
"reasoning from cause and effect" to augment the learning capabilities of
MLLMs. LCL goes beyond traditional ICL by explicitly strengthening the causal
relationship between the support set and the query set. By providing
demonstrations with causal links, LCL guides the model to discern not only the
analogy but also the underlying causal associations between data points, which
empowers MLLMs to recognize unseen images and understand novel concepts more
effectively. To facilitate the evaluation of this novel approach, we introduce
the ISEKAI dataset, comprising exclusively of unseen generated image-label
pairs designed for link-context learning. Extensive experiments show that our
LCL-MLLM exhibits strong link-context learning capabilities to novel concepts
over vanilla MLLMs. Code and data will be released at
https://github.com/isekai-portal/Link-Context-Learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Regular Expression Inference Challenge. (arXiv:2308.07899v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07899">
<div class="article-summary-box-inner">
<span><p>We propose \emph{regular expression inference (REI)} as a challenge for
code/language modelling, and the wider machine learning community. REI is a
supervised machine learning (ML) and program synthesis task, and poses the
problem of finding minimal regular expressions from examples: Given two finite
sets of strings $P$ and $N$ and a cost function $\text{cost}(\cdot)$, the task
is to generate an expression $r$ that accepts all strings in $P$ and rejects
all strings in $N$, while no other such expression $r'$ exists with
$\text{cost}(r')&lt;\text{cost}(r)$.
</p>
<p>REI has advantages as a challenge problem: (i) regular expressions are
well-known, widely used, and a natural idealisation of code; (ii) REI's
asymptotic worst-case complexity is well understood; (iii) REI has a small
number of easy to understand parameters (e.g.~$P$ or $N$ cardinality, string
lengths of examples, or the cost function); this lets us easily finetune
REI-hardness; (iv) REI is an unsolved problem for deep learning based ML.
</p>
<p>Recently, an REI solver was implemented on GPUs, using program synthesis
techniques. This enabled, for the first time, fast generation of minimal
expressions for complex REI instances. Building on this advance, we generate
and publish the first large-scale datasets for REI, and devise and evaluate
several initial heuristic and machine learning baselines.
</p>
<p>We invite the community to participate and explore ML methods that learn to
solve REI problems. We believe that progress in REI directly translates to
code/language modelling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Through the Lens of Core Competency: Survey on Evaluation of Large Language Models. (arXiv:2308.07902v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07902">
<div class="article-summary-box-inner">
<span><p>From pre-trained language model (PLM) to large language model (LLM), the
field of natural language processing (NLP) has witnessed steep performance
gains and wide practical uses. The evaluation of a research field guides its
direction of improvement. However, LLMs are extremely hard to thoroughly
evaluate for two reasons. First of all, traditional NLP tasks become inadequate
due to the excellent performance of LLM. Secondly, existing evaluation tasks
are difficult to keep up with the wide range of applications in real-world
scenarios. To tackle these problems, existing works proposed various benchmarks
to better evaluate LLMs. To clarify the numerous evaluation tasks in both
academia and industry, we investigate multiple papers concerning LLM
evaluations. We summarize 4 core competencies of LLM, including reasoning,
knowledge, reliability, and safety. For every competency, we introduce its
definition, corresponding benchmarks, and metrics. Under this competency
architecture, similar tasks are combined to reflect corresponding ability,
while new tasks can also be easily added into the system. Finally, we give our
suggestions on the future direction of LLM's evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification. (arXiv:2308.07921v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07921">
<div class="article-summary-box-inner">
<span><p>Recent progress in large language models (LLMs) like GPT-4 and PaLM-2 has
brought significant advancements in addressing math reasoning problems. In
particular, OpenAI's latest version of GPT-4, known as GPT-4 Code Interpreter,
shows remarkable performance on challenging math datasets. In this paper, we
explore the effect of code on enhancing LLMs' reasoning capability by
introducing different constraints on the \textit{Code Usage Frequency} of GPT-4
Code Interpreter. We found that its success can be largely attributed to its
powerful skills in generating and executing code, evaluating the output of code
execution, and rectifying its solution when receiving unreasonable outputs.
Based on this insight, we propose a novel and effective prompting method,
explicit \uline{c}ode-based \uline{s}elf-\uline{v}erification~(CSV), to further
boost the mathematical reasoning potential of GPT-4 Code Interpreter. This
method employs a zero-shot prompt on GPT-4 Code Interpreter to encourage it to
use code to self-verify its answers. In instances where the verification state
registers as ``False'', the model shall automatically amend its solution,
analogous to our approach of rectifying errors during a mathematics
examination. Furthermore, we recognize that the states of the verification
result indicate the confidence of a solution, which can improve the
effectiveness of majority voting. With GPT-4 Code Interpreter and CSV, we
achieve an impressive zero-shot accuracy on MATH dataset \textbf{(53.9\% $\to$
84.3\%)}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models. (arXiv:2308.07922v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07922">
<div class="article-summary-box-inner">
<span><p>In this paper, we investigate the in-context learning ability of
retrieval-augmented encoder-decoder language models. We first conduct a
comprehensive analysis of the state-of-the-art ATLAS model and identify its
limitations in in-context learning, primarily due to a mismatch between
pretraining and testing, as well as a restricted context length. To address
these issues, we propose RAVEN, a model that combines retrieval-augmented
masked language modeling and prefix language modeling. We further introduce
Fusion-in-Context Learning to enhance the few-shot performance by enabling the
model to leverage more in-context examples without requiring additional
training or model modifications. Through extensive experiments, we demonstrate
that RAVEN significantly outperforms ATLAS and achieves results comparable to
the most advanced language models in certain scenarios, despite having
substantially fewer parameters. Our work underscores the potential of
retrieval-augmented encoder-decoder language models for in-context learning and
encourages further research in this direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SuS-X: Training-Free Name-Only Transfer of Vision-Language Models. (arXiv:2211.16198v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.16198">
<div class="article-summary-box-inner">
<span><p>Contrastive Language-Image Pre-training (CLIP) has emerged as a simple yet
effective way to train large-scale vision-language models. CLIP demonstrates
impressive zero-shot classification and retrieval on diverse downstream tasks.
However, to leverage its full potential, fine-tuning still appears to be
necessary. Fine-tuning the entire CLIP model can be resource-intensive and
unstable. Moreover, recent methods that aim to circumvent this need for
fine-tuning still require access to images from the target distribution. In
this paper, we pursue a different approach and explore the regime of
training-free "name-only transfer" in which the only knowledge we possess about
the downstream task comprises the names of downstream target categories. We
propose a novel method, SuS-X, consisting of two key building blocks -- SuS and
TIP-X, that requires neither intensive fine-tuning nor costly labelled data.
SuS-X achieves state-of-the-art zero-shot classification results on 19
benchmark datasets. We further show the utility of TIP-X in the training-free
few-shot setting, where we again achieve state-of-the-art results over strong
training-free baselines. Code is available at
https://github.com/vishaal27/SuS-X.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SGL-PT: A Strong Graph Learner with Graph Prompt Tuning. (arXiv:2302.12449v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12449">
<div class="article-summary-box-inner">
<span><p>Recently, much exertion has been paid to design graph self-supervised methods
to obtain generalized pre-trained models, and adapt pre-trained models onto
downstream tasks through fine-tuning. However, there exists an inherent gap
between pretext and downstream graph tasks, which insufficiently exerts the
ability of pre-trained models and even leads to negative transfer. Meanwhile,
prompt tuning has seen emerging success in natural language processing by
aligning pre-training and fine-tuning with consistent training objectives. In
this paper, we identify the challenges for graph prompt tuning: The first is
the lack of a strong and universal pre-training task across sundry pre-training
methods in graph domain. The second challenge lies in the difficulty of
designing a consistent training objective for both pre-training and downstream
tasks. To overcome above obstacles, we propose a novel framework named SGL-PT
which follows the learning strategy ``Pre-train, Prompt, and Predict''.
Specifically, we raise a strong and universal pre-training task coined as SGL
that acquires the complementary merits of generative and contrastive
self-supervised graph learning. And aiming for graph classification task, we
unify pre-training and fine-tuning by designing a novel verbalizer-free
prompting function, which reformulates the downstream task in a similar format
as pretext task. Empirical results show that our method surpasses other
baselines under unsupervised setting, and our prompt tuning method can greatly
facilitate models on biological datasets over fine-tuning methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LeafAI: query generator for clinical cohort discovery rivaling a human programmer. (arXiv:2304.06203v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.06203">
<div class="article-summary-box-inner">
<span><p>Objective: Identifying study-eligible patients within clinical databases is a
critical step in clinical research. However, accurate query design typically
requires extensive technical and biomedical expertise. We sought to create a
system capable of generating data model-agnostic queries while also providing
novel logical reasoning capabilities for complex clinical trial eligibility
criteria.
</p>
<p>Materials and Methods: The task of query creation from eligibility criteria
requires solving several text-processing problems, including named entity
recognition and relation extraction, sequence-to-sequence transformation,
normalization, and reasoning. We incorporated hybrid deep learning and
rule-based modules for these, as well as a knowledge base of the Unified
Medical Language System (UMLS) and linked ontologies. To enable data-model
agnostic query creation, we introduce a novel method for tagging database
schema elements using UMLS concepts. To evaluate our system, called LeafAI, we
compared the capability of LeafAI to a human database programmer to identify
patients who had been enrolled in 8 clinical trials conducted at our
institution. We measured performance by the number of actual enrolled patients
matched by generated queries.
</p>
<p>Results: LeafAI matched a mean 43% of enrolled patients with 27,225 eligible
across 8 clinical trials, compared to 27% matched and 14,587 eligible in
queries by a human database programmer. The human programmer spent 26 total
hours crafting queries compared to several minutes by LeafAI.
</p>
<p>Conclusions: Our work contributes a state-of-the-art data model-agnostic
query generation system capable of conditional reasoning using a knowledge
base. We demonstrate that LeafAI can rival an experienced human programmer in
finding patients eligible for clinical trials.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for Verification. (arXiv:2305.04003v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04003">
<div class="article-summary-box-inner">
<span><p>Verification of machine learning models used in Natural Language Processing
(NLP) is known to be a hard problem. In particular, many known neural network
verification methods that work for computer vision and other numeric datasets
do not work for NLP. Here, we study technical reasons that underlie this
problem. Based on this analysis, we propose practical methods and heuristics
for preparing NLP datasets and models in a way that renders them amenable to
known verification methods based on abstract interpretation. We implement these
methods as a Python library called ANTONIO that links to the neural network
verifiers ERAN and Marabou. We perform evaluation of the tool using an NLP
dataset R-U-A-Robot suggested as a benchmark for verifying legally critical NLP
applications. We hope that, thanks to its general applicability, this work will
open novel possibilities for including NLP verification problems into neural
network verification competitions, and will popularise NLP problems within this
community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Framework For Refining Text Classification and Object Recognition from Academic Articles. (arXiv:2305.17401v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17401">
<div class="article-summary-box-inner">
<span><p>With the widespread use of the internet, it has become increasingly crucial
to extract specific information from vast amounts of academic articles
efficiently. Data mining techniques are generally employed to solve this issue.
However, data mining for academic articles is challenging since it requires
automatically extracting specific patterns in complex and unstructured layout
documents. Current data mining methods for academic articles employ
rule-based(RB) or machine learning(ML) approaches. However, using rule-based
methods incurs a high coding cost for complex typesetting articles. On the
other hand, simply using machine learning methods requires annotation work for
complex content types within the paper, which can be costly. Furthermore, only
using machine learning can lead to cases where patterns easily recognized by
rule-based methods are mistakenly extracted. To overcome these issues, from the
perspective of analyzing the standard layout and typesetting used in the
specified publication, we emphasize implementing specific methods for specific
characteristics in academic articles. We have developed a novel Text Block
Refinement Framework (TBRF), a machine learning and rule-based scheme hybrid.
We used the well-known ACL proceeding articles as experimental data for the
validation experiment. The experiment shows that our approach achieved over 95%
classification accuracy and 90% detection accuracy for tables and figures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GripRank: Bridging the Gap between Retrieval and Generation via the Generative Knowledge Improved Passage Ranking. (arXiv:2305.18144v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18144">
<div class="article-summary-box-inner">
<span><p>Retrieval-enhanced text generation has shown remarkable progress on
knowledge-intensive language tasks, such as open-domain question answering and
knowledge-enhanced dialogue generation, by leveraging passages retrieved from a
large passage corpus for delivering a proper answer given the input query.
However, the retrieved passages are not ideal for guiding answer generation
because of the discrepancy between retrieval and generation, i.e., the
candidate passages are all treated equally during the retrieval procedure
without considering their potential to generate a proper answer. This
discrepancy makes a passage retriever deliver a sub-optimal collection of
candidate passages to generate the answer. In this paper, we propose the
GeneRative Knowledge Improved Passage Ranking (GripRank) approach, addressing
the above challenge by distilling knowledge from a generative passage estimator
(GPE) to a passage ranker, where the GPE is a generative language model used to
measure how likely the candidate passages can generate the proper answer. We
realize the distillation procedure by teaching the passage ranker learning to
rank the passages ordered by the GPE. Furthermore, we improve the distillation
quality by devising a curriculum knowledge distillation mechanism, which allows
the knowledge provided by the GPE can be progressively distilled to the ranker
through an easy-to-hard curriculum, enabling the passage ranker to correctly
recognize the provenance of the answer from many plausible candidates. We
conduct extensive experiments on four datasets across three knowledge-intensive
language tasks. Experimental results show advantages over the state-of-the-art
methods for both passage ranking and answer generation on the KILT benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Contextual Biasing for Transducer Based Streaming Speech Recognition. (arXiv:2306.00804v3 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00804">
<div class="article-summary-box-inner">
<span><p>By incorporating additional contextual information, deep biasing methods have
emerged as a promising solution for speech recognition of personalized words.
However, for real-world voice assistants, always biasing on such personalized
words with high prediction scores can significantly degrade the performance of
recognizing common words. To address this issue, we propose an adaptive
contextual biasing method based on Context-Aware Transformer Transducer (CATT)
that utilizes the biased encoder and predictor embeddings to perform streaming
prediction of contextual phrase occurrences. Such prediction is then used to
dynamically switch the bias list on and off, enabling the model to adapt to
both personalized and common scenarios. Experiments on Librispeech and internal
voice assistant datasets show that our approach can achieve up to 6.7% and
20.7% relative reduction in WER and CER compared to the baseline respectively,
mitigating up to 96.7% and 84.9% of the relative WER and CER increase for
common cases. Furthermore, our approach has a minimal performance impact in
personalized scenarios while maintaining a streaming inference pipeline with
negligible RTF increase.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PoetryDiffusion: Towards Joint Semantic and Metrical Manipulation in Poetry Generation. (arXiv:2306.08456v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.08456">
<div class="article-summary-box-inner">
<span><p>Controllable text generation is a challenging and meaningful field in natural
language generation (NLG). Especially, poetry generation is a typical one with
well-defined and strict conditions for text generation which is an ideal
playground for the assessment of current methodologies. While prior works
succeeded in controlling either semantic or metrical aspects of poetry
generation, simultaneously addressing both remains a challenge. In this paper,
we pioneer the use of the Diffusion model for generating sonnets and Chinese
SongCi poetry to tackle such challenges. In terms of semantics, our
PoetryDiffusion model, built upon the Diffusion model, generates entire
sentences or poetry by comprehensively considering the entirety of sentence
information. This approach enhances semantic expression, distinguishing it from
autoregressive and large language models (LLMs). For metrical control, the
separation feature of diffusion generation and its constraint control module
enable us to flexibly incorporate a novel metrical controller to manipulate and
evaluate metrics (format and rhythm). The denoising process in PoetryDiffusion
allows for gradual enhancement of semantics and flexible integration of the
metrical controller which can calculate and impose penalties on states that
stray significantly from the target control distribution. Experimental results
on two datasets demonstrate that our model outperforms existing models in
automatic evaluation of semantic, metrical, and overall performance as well as
human evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BatGPT: A Bidirectional Autoregessive Talker from Generative Pre-trained Transformer. (arXiv:2307.00360v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.00360">
<div class="article-summary-box-inner">
<span><p>BatGPT is a large-scale language model designed and trained jointly by Wuhan
University and Shanghai Jiao Tong University. It is capable of generating
highly natural and fluent text in response to various types of input, including
text prompts, images, and audio. In the modeling level, we employ a
bidirectional autoregressive architecture that allows the model to efficiently
capture the complex dependencies of natural language, making it highly
effective in tasks such as language generation, dialog systems, and question
answering. Moreover, the bidirectional autoregressive modeling not only
operates from left to right but also from right to left, effectively reducing
fixed memory effects and alleviating model hallucinations.
</p>
<p>In the training aspect, we propose a novel parameter expansion method for
leveraging the pre-training of smaller models and employ reinforcement learning
from both AI and human feedback, aimed at improving the model's alignment
performance. Overall, these approaches significantly improve the effectiveness
of BatGPT, and the model can be utilized for a wide range of natural language
applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Style Over Substance: Evaluation Biases for Large Language Models. (arXiv:2307.03025v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03025">
<div class="article-summary-box-inner">
<span><p>As large language models (LLMs) continue to advance, accurately and
comprehensively evaluating their performance becomes increasingly challenging.
Human evaluations are conventionally considered the gold standard in natural
language generation, but recent advancements incorporate state-of-the-art LLMs
as proxies for human judges in evaluation processes. However, the extent to
which humans and LLMs are capable evaluators remains uncertain. This study
investigates the behavior of crowd-sourced and expert annotators, as well as
LLMs, when comparing outputs from different models. To achieve this, we curate
a dataset of intentionally flawed machine-generated answers. Our findings
reveal a concerning bias in the evaluation process, as answers with factual
errors are rated more favorably than answers that are too short or contained
grammatical errors. To address this issue, we propose independently evaluating
machine-generated text across multiple dimensions, rather than merging all the
evaluation aspects into a single score. We instantiate this idea with the Elo
rating system, resulting in the Multi-Elo Rating System. Empirical results from
our study reveal that this proposed approach significantly enhances the quality
of LLM-based evaluations, particularly in terms of factual accuracy. However,
there is no significant improvement in crowd-sourced-based evaluations,
indicating the need for further investigation and refinement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stack More Layers Differently: High-Rank Training Through Low-Rank Updates. (arXiv:2307.05695v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.05695">
<div class="article-summary-box-inner">
<span><p>Despite the dominance and effectiveness of scaling, resulting in large
networks with hundreds of billions of parameters, the necessity to train
overparametrized models remains poorly understood, and alternative approaches
do not necessarily make it cheaper to train high-performance models. In this
paper, we explore low-rank training techniques as an alternative approach to
training large neural networks. We introduce a novel method called ReLoRA,
which utilizes low-rank updates to train high-rank networks. We apply ReLoRA to
pre-training transformer language models with up to 350M parameters and
demonstrate comparable performance to regular neural network training.
Furthermore, we observe that the efficiency of ReLoRA increases with model
size, making it a promising approach for training multi-billion-parameter
networks efficiently. Our findings shed light on the potential of low-rank
training techniques and their implications for scaling laws.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization. (arXiv:2307.15199v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.15199">
<div class="article-summary-box-inner">
<span><p>In a joint vision-language space, a text feature (e.g., from "a photo of a
dog") could effectively represent its relevant image features (e.g., from dog
photos). Also, a recent study has demonstrated the cross-modal transferability
phenomenon of this joint space. From these observations, we propose
PromptStyler which simulates various distribution shifts in the joint space by
synthesizing diverse styles via prompts without using any images to deal with
source-free domain generalization. The proposed method learns to generate a
variety of style features (from "a S* style of a") via learnable style word
vectors for pseudo-words S*. To ensure that learned styles do not distort
content information, we force style-content features (from "a S* style of a
[class]") to be located nearby their corresponding content features (from
"[class]") in the joint vision-language space. After learning style word
vectors, we train a linear classifier using synthesized style-content features.
PromptStyler achieves the state of the art on PACS, VLCS, OfficeHome and
DomainNet, even though it does not require any images for training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LaFiCMIL: Rethinking Large File Classification from the Perspective of Correlated Multiple Instance Learning. (arXiv:2308.01413v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.01413">
<div class="article-summary-box-inner">
<span><p>Transformer-based models, such as BERT, have revolutionized various language
tasks, but still struggle with large file classification due to their input
limit (e.g., 512 tokens). Despite several attempts to alleviate this
limitation, no method consistently excels across all benchmark datasets,
primarily because they can only extract partial essential information from the
input file. Additionally, they fail to adapt to the varied properties of
different types of large files. In this work, we tackle this problem from the
perspective of correlated multiple instance learning. The proposed approach,
LaFiCMIL, serves as a versatile framework applicable to various large file
classification tasks covering binary, multi-class, and multi-label
classification tasks, spanning various domains including Natural Language
Processing, Programming Language Processing, and Android Analysis. To evaluate
its effectiveness, we employ eight benchmark datasets pertaining to Long
Document Classification, Code Defect Detection, and Android Malware Detection.
Leveraging BERT-family models as feature extractors, our experimental results
demonstrate that LaFiCMIL achieves new state-of-the-art performance across all
benchmark datasets. This is largely attributable to its capability of scaling
BERT up to nearly 20K tokens, running on a single Tesla V-100 GPU with 32G of
memory.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SynJax: Structured Probability Distributions for JAX. (arXiv:2308.03291v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.03291">
<div class="article-summary-box-inner">
<span><p>The development of deep learning software libraries enabled significant
progress in the field by allowing users to focus on modeling, while letting the
library to take care of the tedious and time-consuming task of optimizing
execution for modern hardware accelerators. However, this has benefited only
particular types of deep learning models, such as Transformers, whose
primitives map easily to the vectorized computation. The models that explicitly
account for structured objects, such as trees and segmentations, did not
benefit equally because they require custom algorithms that are difficult to
implement in a vectorized form.
</p>
<p>SynJax directly addresses this problem by providing an efficient vectorized
implementation of inference algorithms for structured distributions covering
alignment, tagging, segmentation, constituency trees and spanning trees. With
SynJax we can build large-scale differentiable models that explicitly model
structure in the data. The code is available at
https://github.com/deepmind/synjax.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning-Based Knowledge Injection for Metaphor Detection: A Comprehensive Review. (arXiv:2308.04306v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.04306">
<div class="article-summary-box-inner">
<span><p>The history of metaphor research also marks the evolution of knowledge
infusion research. With the continued advancement of deep learning techniques
in recent years, the natural language processing community has shown great
interest in applying knowledge to successful results in metaphor recognition
tasks. Although there has been a gradual increase in the number of approaches
involving knowledge injection in the field of metaphor recognition, there is a
lack of a complete review article on knowledge injection based approaches.
Therefore, the goal of this paper is to provide a comprehensive review of
research advances in the application of deep learning for knowledge injection
in metaphor recognition tasks. In this paper, we systematically summarize and
generalize the mainstream knowledge and knowledge injection principles, as well
as review the datasets, evaluation metrics, and benchmark models used in
metaphor recognition tasks. Finally, we explore the current issues facing
knowledge injection methods and provide an outlook on future research
directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MC-DRE: Multi-Aspect Cross Integration for Drug Event/Entity Extraction. (arXiv:2308.06546v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06546">
<div class="article-summary-box-inner">
<span><p>Extracting meaningful drug-related information chunks, such as adverse drug
events (ADE), is crucial for preventing morbidity and saving many lives. Most
ADEs are reported via an unstructured conversation with the medical context, so
applying a general entity recognition approach is not sufficient enough. In
this paper, we propose a new multi-aspect cross-integration framework for drug
entity/event detection by capturing and aligning different
context/language/knowledge properties from drug-related documents. We first
construct multi-aspect encoders to describe semantic, syntactic, and medical
document contextual information by conducting those slot tagging tasks, main
drug entity/event detection, part-of-speech tagging, and general medical named
entity recognition. Then, each encoder conducts cross-integration with other
contextual information in three ways: the key-value cross, attention cross, and
feedforward cross, so the multi-encoders are integrated in depth. Our model
outperforms all SOTA on two widely used tasks, flat entity detection and
discontinuous event extraction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Thresh: A Unified, Customizable and Deployable Platform for Fine-Grained Text Evaluation. (arXiv:2308.06953v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06953">
<div class="article-summary-box-inner">
<span><p>Fine-grained, span-level human evaluation has emerged as a reliable and
robust method for evaluating text generation tasks such as summarization,
simplification, machine translation and news generation, and the derived
annotations have been useful for training automatic metrics and improving
language models. However, existing annotation tools implemented for these
evaluation frameworks lack the adaptability to be extended to different domains
or languages, or modify annotation settings according to user needs. And the
absence of a unified annotated data format inhibits the research in multi-task
learning. In this paper, we introduce Thresh, a unified, customizable and
deployable platform for fine-grained evaluation. By simply creating a YAML
configuration file, users can build and test an annotation interface for any
framework within minutes -- all in one web browser window. To facilitate
collaboration and sharing, Thresh provides a community hub that hosts a
collection of fine-grained frameworks and corresponding annotations made and
collected by the community, covering a wide range of NLP tasks. For deployment,
Thresh offers multiple options for any scale of annotation projects from small
manual inspections to large crowdsourcing ones. Additionally, we introduce a
Python library to streamline the entire process from typology design and
deployment to annotation processing. Thresh is publicly accessible at
https://thresh.tools.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models. (arXiv:2308.07074v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07074">
<div class="article-summary-box-inner">
<span><p>Foundation language models obtain the instruction-following ability through
supervised fine-tuning (SFT). Diversity and complexity are considered critical
factors of a successful SFT dataset, while their definitions remain obscure and
lack quantitative analyses. In this work, we propose InsTag, an open-set
fine-grained tagger, to tag samples within SFT datasets based on semantics and
intentions and define instruction diversity and complexity regarding tags. We
obtain 6.6K tags to describe comprehensive user queries. Then we analyze
popular open-sourced SFT datasets and find that the model ability grows with
more diverse and complex data. Based on this observation, we propose a data
selector based on InsTag to select 6K diverse and complex samples from
open-source datasets and fine-tune models on InsTag-selected data. The
resulting models, TagLM, outperform open-source models based on considerably
larger SFT data evaluated by MT-Bench, echoing the importance of query
diversity and complexity. We open-source InsTag in
https://github.com/OFA-Sys/InsTag.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models for Information Retrieval: A Survey. (arXiv:2308.07107v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07107">
<div class="article-summary-box-inner">
<span><p>As a primary means of information acquisition, information retrieval (IR)
systems, such as search engines, have integrated themselves into our daily
lives. These systems also serve as components of dialogue, question-answering,
and recommender systems. The trajectory of IR has evolved dynamically from its
origins in term-based methods to its integration with advanced neural models.
While the neural models excel at capturing complex contextual signals and
semantic nuances, thereby reshaping the IR landscape, they still face
challenges such as data scarcity, interpretability, and the generation of
contextually plausible yet potentially inaccurate responses. This evolution
requires a combination of both traditional methods (such as term-based sparse
retrieval methods with rapid response) and modern neural architectures (such as
language models with powerful language understanding capacity). Meanwhile, the
emergence of large language models (LLMs), typified by ChatGPT and GPT-4, has
revolutionized natural language processing due to their remarkable language
understanding, generation, generalization, and reasoning abilities.
Consequently, recent research has sought to leverage LLMs to improve IR
systems. Given the rapid evolution of this research trajectory, it is necessary
to consolidate existing methodologies and provide nuanced insights through a
comprehensive overview. In this survey, we delve into the confluence of LLMs
and IR systems, including crucial aspects such as query rewriters, retrievers,
rerankers, and readers. Additionally, we explore promising directions within
this expanding field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked. (arXiv:2308.07308v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07308">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have skyrocketed in popularity in recent years
due to their ability to generate high-quality text in response to human
prompting. However, these models have been shown to have the potential to
generate harmful content in response to user prompting (e.g., giving users
instructions on how to commit crimes). There has been a focus in the literature
on mitigating these risks, through methods like aligning models with human
values through reinforcement learning. However, it has been shown that even
aligned language models are susceptible to adversarial attacks that bypass
their restrictions on generating harmful text. We propose a simple approach to
defending against these attacks by having a large language model filter its own
responses. Our current results show that even if a model is not fine-tuned to
be aligned with human values, it is possible to stop it from presenting harmful
content to users by validating the content using a language model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human-centered NLP Fact-checking: Co-Designing with Fact-checkers using Matchmaking for AI. (arXiv:2308.07213v1 [cs.HC] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07213">
<div class="article-summary-box-inner">
<span><p>A key challenge in professional fact-checking is its limited scalability in
relation to the magnitude of false information. While many Natural Language
Processing (NLP) tools have been proposed to enhance fact-checking efficiency
and scalability, both academic research and fact-checking organizations report
limited adoption of such tooling due to insufficient alignment with
fact-checker practices, values, and needs. To address this gap, we investigate
a co-design method, Matchmaking for AI, which facilitates fact-checkers,
designers, and NLP researchers to collaboratively discover what fact-checker
needs should be addressed by technology and how. Our co-design sessions with 22
professional fact-checkers yielded a set of 11 novel design ideas. They assist
in information searching, processing, and writing tasks for efficient and
personalized fact-checking; help fact-checkers proactively prepare for future
misinformation; monitor their potential biases; and support internal
organization collaboration. Our work offers implications for human-centered
fact-checking research and practice and AI co-design research.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-08-16 23:10:47.600380829 UTC">2023-08-16 23:10:47 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>