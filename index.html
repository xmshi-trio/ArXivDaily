<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-07-25T01:30:00Z">07-25</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus. (arXiv:2307.11760v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11760">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have achieved significant performance in many
fields such as reasoning, language understanding, and math problem-solving, and
are regarded as a crucial step to artificial general intelligence (AGI).
However, the sensitivity of LLMs to prompts remains a major bottleneck for
their daily adoption. In this paper, we take inspiration from psychology and
propose EmotionPrompt to explore emotional intelligence to enhance the
performance of LLMs. EmotionPrompt operates on a remarkably straightforward
principle: the incorporation of emotional stimulus into prompts. Experimental
results demonstrate that our \method, using the same single prompt templates,
significantly outperforms original zero-shot prompt and Zero-shot-CoT on 8
tasks with diverse models: ChatGPT, Vicuna-13b, Bloom, and T5. Further,
EmotionPrompt was observed to improve both truthfulness and informativeness. We
believe that EmotionPrompt heralds a novel avenue for exploring
interdisciplinary knowledge for humans-LLMs interaction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fairness of ChatGPT and the Role Of Explainable-Guided Prompts. (arXiv:2307.11761v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11761">
<div class="article-summary-box-inner">
<span><p>Our research investigates the potential of Large-scale Language Models
(LLMs), specifically OpenAI's GPT, in credit risk assessment-a binary
classification task. Our findings suggest that LLMs, when directed by
judiciously designed prompts and supplemented with domain-specific knowledge,
can parallel the performance of traditional Machine Learning (ML) models.
Intriguingly, they achieve this with significantly less data-40 times less,
utilizing merely 20 data points compared to the ML's 800. LLMs particularly
excel in minimizing false positives and enhancing fairness, both being vital
aspects of risk analysis. While our results did not surpass those of classical
ML models, they underscore the potential of LLMs in analogous tasks, laying a
groundwork for future explorations into harnessing the capabilities of LLMs in
diverse ML tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Similarity-based Memory Enhanced Joint Entity and Relation Extraction. (arXiv:2307.11762v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11762">
<div class="article-summary-box-inner">
<span><p>Document-level joint entity and relation extraction is a challenging
information extraction problem that requires a unified approach where a single
neural network performs four sub-tasks: mention detection, coreference
resolution, entity classification, and relation extraction. Existing methods
often utilize a sequential multi-task learning approach, in which the arbitral
decomposition causes the current task to depend only on the previous one,
missing the possible existence of the more complex relationships between them.
In this paper, we present a multi-task learning framework with bidirectional
memory-like dependency between tasks to address those drawbacks and perform the
joint problem more accurately. Our empirical studies show that the proposed
approach outperforms the existing methods and achieves state-of-the-art results
on the BioCreative V CDR corpus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sensi-BERT: Towards Sensitivity Driven Fine-Tuning for Parameter-Efficient BERT. (arXiv:2307.11764v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11764">
<div class="article-summary-box-inner">
<span><p>Large pre-trained language models have recently gained significant traction
due to their improved performance on various down-stream tasks like text
classification and question answering, requiring only few epochs of
fine-tuning. However, their large model sizes often prohibit their applications
on resource-constrained edge devices. Existing solutions of yielding
parameter-efficient BERT models largely rely on compute-exhaustive training and
fine-tuning. Moreover, they often rely on additional compute heavy models to
mitigate the performance gap. In this paper, we present Sensi-BERT, a
sensitivity driven efficient fine-tuning of BERT models that can take an
off-the-shelf pre-trained BERT model and yield highly parameter-efficient
models for downstream tasks. In particular, we perform sensitivity analysis to
rank each individual parameter tensor, that then is used to trim them
accordingly during fine-tuning for a given parameter or FLOPs budget. Our
experiments show the efficacy of Sensi-BERT across different downstream tasks
including MNLI, QQP, QNLI, and SST-2, demonstrating better performance at
similar or smaller parameter budget compared to various existing alternatives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Three-way Decisions with Evaluative Linguistic Expressions. (arXiv:2307.11766v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11766">
<div class="article-summary-box-inner">
<span><p>We propose a linguistic interpretation of three-way decisions, where the
regions of acceptance, rejection, and non-commitment are constructed by using
the so-called evaluative linguistic expressions, which are expressions of
natural language such as small, medium, very short, quite roughly strong,
extremely good, etc. Our results highlight new connections between two
different research areas: three-way decisions and the theory of evaluative
linguistic expressions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recognition of Mental Adjectives in An Efficient and Automatic Style. (arXiv:2307.11767v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11767">
<div class="article-summary-box-inner">
<span><p>In recent years, commonsense reasoning has received more and more attention
from academic community. We propose a new lexical inference task, Mental and
Physical Classification (MPC), to handle commonsense reasoning in a reasoning
graph. Mental words relate to mental activities, which fall into six
categories: Emotion, Need, Perceiving, Reasoning, Planning and Personality.
Physical words describe physical attributes of an object, like color, hardness,
speed and malleability. A BERT model is fine-tuned for this task and active
learning algorithm is adopted in the training framework to reduce the required
annotation resources. The model using ENTROPY strategy achieves satisfactory
accuracy and requires only about 300 labeled words. We also compare our result
with SentiWordNet to check the difference between MPC and subjectivity
classification task in sentiment analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Question Decomposition Improves the Faithfulness of Model-Generated Reasoning. (arXiv:2307.11768v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11768">
<div class="article-summary-box-inner">
<span><p>As large language models (LLMs) perform more difficult tasks, it becomes
harder to verify the correctness and safety of their behavior. One approach to
help with this issue is to prompt LLMs to externalize their reasoning, e.g., by
having them generate step-by-step reasoning as they answer a question
(Chain-of-Thought; CoT). The reasoning may enable us to check the process that
models use to perform tasks. However, this approach relies on the stated
reasoning faithfully reflecting the model's actual reasoning, which is not
always the case. To improve over the faithfulness of CoT reasoning, we have
models generate reasoning by decomposing questions into subquestions.
Decomposition-based methods achieve strong performance on question-answering
tasks, sometimes approaching that of CoT while improving the faithfulness of
the model's stated reasoning on several recently-proposed metrics. By forcing
the model to answer simpler subquestions in separate contexts, we greatly
increase the faithfulness of model-generated reasoning over CoT, while still
achieving some of the performance gains of CoT. Our results show it is possible
to improve the faithfulness of model-generated reasoning; continued
improvements may lead to reasoning that enables us to verify the correctness
and safety of LLM behavior.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain. (arXiv:2307.11769v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11769">
<div class="article-summary-box-inner">
<span><p>Engineering knowledge-based (or expert) systems require extensive manual
effort and domain knowledge. As Large Language Models (LLMs) are trained using
an enormous amount of cross-domain knowledge, it becomes possible to automate
such engineering processes. This paper presents an empirical automation and
semi-automation framework for domain knowledge distillation using prompt
engineering and the LLM ChatGPT. We assess the framework empirically in the
autonomous driving domain and present our key observations. In our
implementation, we construct the domain knowledge ontology by "chatting" with
ChatGPT. The key finding is that while fully automated domain ontology
construction is possible, human supervision and early intervention typically
improve efficiency and output quality as they lessen the effects of response
randomness and the butterfly effect. We, therefore, also develop a web-based
distillation assistant enabling supervision and flexible intervention at
runtime. We hope our findings and tools could inspire future research toward
revolutionizing the engineering of knowledge-based systems across application
domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large-Scale Evaluation of Topic Models and Dimensionality Reduction Methods for 2D Text Spatialization. (arXiv:2307.11770v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11770">
<div class="article-summary-box-inner">
<span><p>Topic models are a class of unsupervised learning algorithms for detecting
the semantic structure within a text corpus. Together with a subsequent
dimensionality reduction algorithm, topic models can be used for deriving
spatializations for text corpora as two-dimensional scatter plots, reflecting
semantic similarity between the documents and supporting corpus analysis.
Although the choice of the topic model, the dimensionality reduction, and their
underlying hyperparameters significantly impact the resulting layout, it is
unknown which particular combinations result in high-quality layouts with
respect to accuracy and perception metrics. To investigate the effectiveness of
topic models and dimensionality reduction methods for the spatialization of
corpora as two-dimensional scatter plots (or basis for landscape-type
visualizations), we present a large-scale, benchmark-based computational
evaluation. Our evaluation consists of (1) a set of corpora, (2) a set of
layout algorithms that are combinations of topic models and dimensionality
reductions, and (3) quality metrics for quantifying the resulting layout. The
corpora are given as document-term matrices, and each document is assigned to a
thematic class. The chosen metrics quantify the preservation of local and
global properties and the perceptual effectiveness of the two-dimensional
scatter plots. By evaluating the benchmark on a computing cluster, we derived a
multivariate dataset with over 45 000 individual layouts and corresponding
quality metrics. Based on the results, we propose guidelines for the effective
design of text spatializations that are based on topic models and
dimensionality reductions. As a main result, we show that interpretable topic
models are beneficial for capturing the structure of text corpora. We
furthermore recommend the use of t-SNE as a subsequent dimensionality
reduction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">an integrated npl approach to sentiment analysis in satisfaction surveys. (arXiv:2307.11771v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11771">
<div class="article-summary-box-inner">
<span><p>The research project aims to apply an integrated approach to natural language
processing NLP to satisfaction surveys. It will focus on understanding and
extracting relevant information from survey responses, analyzing feelings, and
identifying recurring word patterns. NLP techniques will be used to determine
emotional polarity, classify responses into positive, negative, or neutral
categories, and use opinion mining to highlight participants opinions. This
approach will help identify the most relevant aspects for participants and
understand their opinions in relation to those specific aspects. A key
component of the research project will be the analysis of word patterns in
satisfaction survey responses using NPL. This analysis will provide a deeper
understanding of feelings, opinions, and themes and trends present in
respondents responses. The results obtained from this approach can be used to
identify areas for improvement, understand respondents preferences, and make
strategic decisions based on analysis to improve respondent satisfaction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AutoAlign: Fully Automatic and Effective Knowledge Graph Alignment enabled by Large Language Models. (arXiv:2307.11772v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11772">
<div class="article-summary-box-inner">
<span><p>The task of entity alignment between knowledge graphs (KGs) aims to identify
every pair of entities from two different KGs that represent the same entity.
Many machine learning-based methods have been proposed for this task. However,
to our best knowledge, existing methods all require manually crafted seed
alignments, which are expensive to obtain. In this paper, we propose the first
fully automatic alignment method named AutoAlign, which does not require any
manually crafted seed alignments. Specifically, for predicate embeddings,
AutoAlign constructs a predicate-proximity-graph with the help of large
language models to automatically capture the similarity between predicates
across two KGs. For entity embeddings, AutoAlign first computes the entity
embeddings of each KG independently using TransE, and then shifts the two KGs'
entity embeddings into the same vector space by computing the similarity
between entities based on their attributes. Thus, both predicate alignment and
entity alignment can be done without manually crafted seed alignments.
AutoAlign is not only fully automatic, but also highly effective. Experiments
using real-world KGs show that AutoAlign improves the performance of entity
alignment significantly compared to state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Topical Approach to Capturing Customer Insight In Social Media. (arXiv:2307.11775v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11775">
<div class="article-summary-box-inner">
<span><p>The age of social media has opened new opportunities for businesses. This
flourishing wealth of information is outside traditional channels and
frameworks of classical marketing research, including that of Marketing Mix
Modeling (MMM). Textual data, in particular, poses many challenges that data
analysis practitioners must tackle. Social media constitute massive,
heterogeneous, and noisy document sources. Industrial data acquisition
processes include some amount of ETL. However, the variability of noise in the
data and the heterogeneity induced by different sources create the need for
ad-hoc tools. Put otherwise, customer insight extraction in fully unsupervised,
noisy contexts is an arduous task. This research addresses the challenge of
fully unsupervised topic extraction in noisy, Big Data contexts. We present
three approaches we built on the Variational Autoencoder framework: the
Embedded Dirichlet Process, the Embedded Hierarchical Dirichlet Process, and
the time-aware Dynamic Embedded Dirichlet Process. These nonparametric
approaches concerning topics present the particularity of determining word
embeddings and topic embeddings. These embeddings do not require transfer
learning, but knowledge transfer remains possible. We test these approaches on
benchmark and automotive industry-related datasets from a real-world use case.
We show that our models achieve equal to better performance than
state-of-the-art methods and that the field of topic modeling would benefit
from improved evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transsion TSUP's speech recognition system for ASRU 2023 MADASR Challenge. (arXiv:2307.11778v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11778">
<div class="article-summary-box-inner">
<span><p>This paper presents a speech recognition system developed by the Transsion
Speech Understanding Processing Team (TSUP) for the ASRU 2023 MADASR Challenge.
The system focuses on adapting ASR models for low-resource Indian languages and
covers all four tracks of the challenge. For tracks 1 and 2, the acoustic model
utilized a squeezeformer encoder and bidirectional transformer decoder with
joint CTC-Attention training loss. Additionally, an external KenLM language
model was used during TLG beam search decoding. For tracks 3 and 4, pretrained
IndicWhisper models were employed and finetuned on both the challenge dataset
and publicly available datasets. The whisper beam search decoding was also
modified to support an external KenLM language model, which enabled better
utilization of the additional text provided by the challenge. The proposed
method achieved word error rates (WER) of 24.17%, 24.43%, 15.97%, and 15.97%
for Bengali language in the four tracks, and WER of 19.61%, 19.54%, 15.48%, and
15.48% for Bhojpuri language in the four tracks. These results demonstrate the
effectiveness of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Extractive-Abstractive Axis: Measuring Content "Borrowing" in Generative Language Models. (arXiv:2307.11779v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11779">
<div class="article-summary-box-inner">
<span><p>Generative language models produce highly abstractive outputs by design, in
contrast to extractive responses in search engines. Given this characteristic
of LLMs and the resulting implications for content Licensing &amp; Attribution, we
propose the the so-called Extractive-Abstractive axis for benchmarking
generative models and highlight the need for developing corresponding metrics,
datasets and annotation guidelines. We limit our discussion to the text
modality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Conversational Shaping for Intelligent Agents. (arXiv:2307.11785v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11785">
<div class="article-summary-box-inner">
<span><p>The recent emergence of deep learning methods has enabled the research
community to achieve state-of-the art results in several domains including
natural language processing. However, the current robocall system remains
unstable and inaccurate: text generator and chat-bots can be tedious and
misunderstand human-like dialogue. In this work, we study the performance of
two models able to enhance an intelligent conversational agent through
adversarial conversational shaping: a generative adversarial network with
policy gradient (GANPG) and a generative adversarial network with reward for
every generation step (REGS) based on the REGS model presented in Li et al.
[18] . This model is able to assign rewards to both partially and fully
generated text sequences. We discuss performance with different training
details : seq2seq [ 36] and transformers [37 ] in a reinforcement learning
framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM Cognitive Judgements Differ From Human. (arXiv:2307.11787v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11787">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have lately been on the spotlight of
researchers, businesses, and consumers alike. While the linguistic capabilities
of such models have been studied extensively, there is growing interest in
investigating them as cognitive subjects. In the present work I examine GPT-3
and ChatGPT capabilities on an limited-data inductive reasoning task from the
cognitive science literature. The results suggest that these models' cognitive
judgements are not human-like.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Applying QNLP to sentiment analysis in finance. (arXiv:2307.11788v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11788">
<div class="article-summary-box-inner">
<span><p>As an application domain where the slightest qualitative improvements can
yield immense value, finance is a promising candidate for early quantum
advantage. Focusing on the rapidly advancing field of Quantum Natural Language
Processing (QNLP), we explore the practical applicability of the two central
approaches DisCoCat and Quantum-Enhanced Long Short-Term Memory (QLSTM) to the
problem of sentiment analysis in finance. Utilizing a novel ChatGPT-based data
generation approach, we conduct a case study with more than 1000 realistic
sentences and find that QLSTMs can be trained substantially faster than
DisCoCat while also achieving close to classical results for their available
software implementations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompting Large Language Models with Speech Recognition Abilities. (arXiv:2307.11795v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11795">
<div class="article-summary-box-inner">
<span><p>Large language models have proven themselves highly flexible, able to solve a
wide range of generative tasks, such as abstractive summarization and
open-ended question answering. In this paper we extend the capabilities of LLMs
by directly attaching a small audio encoder allowing it to perform speech
recognition. By directly prepending a sequence of audial embeddings to the text
token embeddings, the LLM can be converted to an automatic speech recognition
(ASR) system, and be used in the exact same manner as its textual counterpart.
Experiments on Multilingual LibriSpeech (MLS) show that incorporating a
conformer encoder into the open sourced LLaMA-7B allows it to outperform
monolingual baselines by 18% and perform multilingual speech recognition
despite LLaMA being trained overwhelmingly on English text. Furthermore, we
perform ablation studies to investigate whether the LLM can be completely
frozen during training to maintain its original capabilities, scaling up the
audio encoder, and increasing the audio encoder striding to generate fewer
embeddings. The results from these studies show that multilingual ASR is
possible even when the LLM is frozen or when strides of almost 1 second are
used in the audio encoder opening up the possibility for LLMs to operate on
long-form audio.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Document Analytics for Banking Process Automation. (arXiv:2307.11845v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11845">
<div class="article-summary-box-inner">
<span><p>In response to growing FinTech competition and the need for improved
operational efficiency, this research focuses on understanding the potential of
advanced document analytics, particularly using multimodal models, in banking
processes. We perform a comprehensive analysis of the diverse banking document
landscape, highlighting the opportunities for efficiency gains through
automation and advanced analytics techniques in the customer business. Building
on the rapidly evolving field of natural language processing (NLP), we
illustrate the potential of models such as LayoutXLM, a cross-lingual,
multimodal, pre-trained model, for analyzing diverse documents in the banking
sector. This model performs a text token classification on German company
register extracts with an overall F1 score performance of around 80\%. Our
empirical evidence confirms the critical role of layout information in
improving model performance and further underscores the benefits of integrating
image information. Interestingly, our study shows that over 75% F1 score can be
achieved with only 30% of the training data, demonstrating the efficiency of
LayoutXLM. Through addressing state-of-the-art document analysis frameworks,
our study aims to enhance process efficiency and demonstrate the real-world
applicability and benefits of multimodal models within banking.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MythQA: Query-Based Large-Scale Check-Worthy Claim Detection through Multi-Answer Open-Domain Question Answering. (arXiv:2307.11848v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11848">
<div class="article-summary-box-inner">
<span><p>Check-worthy claim detection aims at providing plausible misinformation to
downstream fact-checking systems or human experts to check. This is a crucial
step toward accelerating the fact-checking process. Many efforts have been put
into how to identify check-worthy claims from a small scale of pre-collected
claims, but how to efficiently detect check-worthy claims directly from a
large-scale information source, such as Twitter, remains underexplored. To fill
this gap, we introduce MythQA, a new multi-answer open-domain question
answering(QA) task that involves contradictory stance mining for query-based
large-scale check-worthy claim detection. The idea behind this is that
contradictory claims are a strong indicator of misinformation that merits
scrutiny by the appropriate authorities. To study this task, we construct
TweetMythQA, an evaluation dataset containing 522 factoid multi-answer
questions based on controversial topics. Each question is annotated with
multiple answers. Moreover, we collect relevant tweets for each distinct
answer, then classify them into three categories: "Supporting", "Refuting", and
"Neutral". In total, we annotated 5.3K tweets. Contradictory evidence is
collected for all answers in the dataset. Finally, we present a baseline system
for MythQA and evaluate existing NLP models for each system component using the
TweetMythQA dataset. We provide initial benchmarks and identify key challenges
for future models to improve upon. Code and data are available at:
https://github.com/TonyBY/Myth-QA
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Looming Threat of Fake and LLM-generated LinkedIn Profiles: Challenges and Opportunities for Detection and Prevention. (arXiv:2307.11864v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11864">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a novel method for detecting fake and Large
Language Model (LLM)-generated profiles in the LinkedIn Online Social Network
immediately upon registration and before establishing connections. Early fake
profile identification is crucial to maintaining the platform's integrity since
it prevents imposters from acquiring the private and sensitive information of
legitimate users and from gaining an opportunity to increase their credibility
for future phishing and scamming activities. This work uses textual information
provided in LinkedIn profiles and introduces the Section and Subsection Tag
Embedding (SSTE) method to enhance the discriminative characteristics of these
data for distinguishing between legitimate profiles and those created by
imposters manually or by using an LLM. Additionally, the dearth of a large
publicly available LinkedIn dataset motivated us to collect 3600 LinkedIn
profiles for our research. We will release our dataset publicly for research
purposes. This is, to the best of our knowledge, the first large publicly
available LinkedIn dataset for fake LinkedIn account detection. Within our
paradigm, we assess static and contextualized word embeddings, including GloVe,
Flair, BERT, and RoBERTa. We show that the suggested method can distinguish
between legitimate and fake profiles with an accuracy of about 95% across all
word embeddings. In addition, we show that SSTE has a promising accuracy for
identifying LLM-generated profiles, despite the fact that no LLM-generated
profiles were employed during the training phase, and can achieve an accuracy
of approximately 90% when only 20 LLM-generated profiles are added to the
training set. It is a significant finding since the proliferation of several
LLMs in the near future makes it extremely challenging to design a single
system that can identify profiles created with various LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction Execution for Robots. (arXiv:2307.11865v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11865">
<div class="article-summary-box-inner">
<span><p>This work explores the capacity of large language models (LLMs) to address
problems at the intersection of spatial planning and natural language
interfaces for navigation.Our focus is on following relatively complex
instructions that are more akin to natural conversation than traditional
explicit procedural directives seen in robotics. Unlike most prior work, where
navigation directives are provided as imperative commands (e.g., go to the
fridge), we examine implicit directives within conversational interactions. We
leverage the 3D simulator AI2Thor to create complex and repeatable scenarios at
scale, and augment it by adding complex language queries for 40 object types.
We demonstrate that a robot can better parse descriptive language queries than
existing methods by using an LLM to interpret the user interaction in the
context of a list of the objects in the scene.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Selective Perception: Optimizing State Descriptions with Reinforcement Learning for Language Model Actors. (arXiv:2307.11922v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11922">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) are being applied as actors for sequential
decision making tasks in domains such as robotics and games, utilizing their
general world knowledge and planning abilities. However, previous work does
little to explore what environment state information is provided to LLM actors
via language. Exhaustively describing high-dimensional states can impair
performance and raise inference costs for LLM actors. Previous LLM actors avoid
the issue by relying on hand-engineered, task-specific protocols to determine
which features to communicate about a state and which to leave out. In this
work, we propose Brief Language INputs for DEcision-making Responses (BLINDER),
a method for automatically selecting concise state descriptions by learning a
value function for task-conditioned state descriptions. We evaluate BLINDER on
the challenging video game NetHack and a robotic manipulation task. Our method
improves task success rate, reduces input size and compute costs, and
generalizes between LLM actors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Vision-and-Language Navigation from YouTube Videos. (arXiv:2307.11984v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11984">
<div class="article-summary-box-inner">
<span><p>Vision-and-language navigation (VLN) requires an embodied agent to navigate
in realistic 3D environments using natural language instructions. Existing VLN
methods suffer from training on small-scale environments or unreasonable
path-instruction datasets, limiting the generalization to unseen environments.
There are massive house tour videos on YouTube, providing abundant real
navigation experiences and layout information. However, these videos have not
been explored for VLN before. In this paper, we propose to learn an agent from
these videos by creating a large-scale dataset which comprises reasonable
path-instruction pairs from house tour videos and pre-training the agent on it.
To achieve this, we have to tackle the challenges of automatically constructing
path-instruction pairs and exploiting real layout knowledge from raw and
unlabeled videos. To address these, we first leverage an entropy-based method
to construct the nodes of a path trajectory. Then, we propose an action-aware
generator for generating instructions from unlabeled trajectories. Last, we
devise a trajectory judgment pretext task to encourage the agent to mine the
layout knowledge. Experimental results show that our method achieves
state-of-the-art performance on two popular benchmarks (R2R and REVERIE). Code
is available at https://github.com/JeremyLinky/YouTube-VLN
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Psy-LLM: Scaling up Global Mental Health Psychological Services with AI-based Large Language Models. (arXiv:2307.11991v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11991">
<div class="article-summary-box-inner">
<span><p>The demand for psychological counseling has grown significantly in recent
years, particularly with the global outbreak of COVID-19, which has heightened
the need for timely and professional mental health support. Online
psychological counseling has emerged as the predominant mode of providing
services in response to this demand. In this study, we propose the Psy-LLM
framework, an AI-based system leveraging Large Language Models (LLMs) for
question-answering in online psychological consultation. Our framework combines
pre-trained LLMs with real-world professional Q&amp;A from psychologists and
extensively crawled psychological articles. The Psy-LLM framework serves as a
front-end tool for healthcare professionals, allowing them to provide immediate
responses and mindfulness activities to alleviate patient stress. Additionally,
it functions as a screening tool to identify urgent cases requiring further
assistance. We evaluated the framework using intrinsic metrics, such as
perplexity, and extrinsic evaluation metrics, with human participant
assessments of response helpfulness, fluency, relevance, and logic. The results
demonstrate the effectiveness of the Psy-LLM framework in generating coherent
and relevant answers to psychological questions. This article concludes by
discussing the potential of large language models to enhance mental health
support through AI technologies in online psychological consultation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Distillation for Continual Learning on Visual Question Localized-Answering in Robotic Surgery. (arXiv:2307.12045v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.12045">
<div class="article-summary-box-inner">
<span><p>The visual-question localized-answering (VQLA) system can serve as a
knowledgeable assistant in surgical education. Except for providing text-based
answers, the VQLA system can highlight the interested region for better
surgical scene understanding. However, deep neural networks (DNNs) suffer from
catastrophic forgetting when learning new knowledge. Specifically, when DNNs
learn on incremental classes or tasks, their performance on old tasks drops
dramatically. Furthermore, due to medical data privacy and licensing issues, it
is often difficult to access old data when updating continual learning (CL)
models. Therefore, we develop a non-exemplar continual surgical VQLA framework,
to explore and balance the rigidity-plasticity trade-off of DNNs in a
sequential learning paradigm. We revisit the distillation loss in CL tasks, and
propose rigidity-plasticity-aware distillation (RP-Dist) and self-calibrated
heterogeneous distillation (SH-Dist) to preserve the old knowledge. The weight
aligning (WA) technique is also integrated to adjust the weight bias between
old and new tasks. We further establish a CL framework on three public surgical
datasets in the context of surgical settings that consist of overlapping
classes between old and new surgical VQLA tasks. With extensive experiments, we
demonstrate that our proposed method excellently reconciles learning and
forgetting on the continual surgical VQLA over conventional CL methods. Our
code is publicly accessible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">External Reasoning: Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback. (arXiv:2307.12057v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.12057">
<div class="article-summary-box-inner">
<span><p>Memory is identified as a crucial human faculty that allows for the retention
of visual and linguistic information within the hippocampus and neurons in the
brain, which can subsequently be retrieved to address real-world challenges
that arise through a lifetime of learning. The resolution of complex AI tasks
through the application of acquired knowledge represents a stride toward the
realization of artificial general intelligence. However, despite the prevalence
of Large Language Models (LLMs) like GPT-3.5 and GPT-4 , which have displayed
remarkable capabilities in language comprehension, generation, interaction, and
reasoning, they are inhibited by constraints on context length that preclude
the processing of extensive, continually evolving knowledge bases. This paper
proposes that LLMs could be augmented through the selective integration of
knowledge from external repositories, and in doing so, introduces a novel
methodology for External Reasoning, exemplified by ChatPDF. Central to this
approach is the establishment of a tiered policy for \textbf{External Reasoning
based on Multiple LLM Interchange Assistance}, where the level of support
rendered is modulated across entry, intermediate, and advanced tiers based on
the complexity of the query, with adjustments made in response to human
feedback. A comprehensive evaluation of this methodology is conducted using
multiple LLMs and the results indicate state-of-the-art performance, surpassing
existing solutions including ChatPDF.com. Moreover, the paper emphasizes that
this approach is more efficient compared to the direct processing of full text
by LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Zero-shot and Few-shot Study of Instruction-Finetuned Large Language Models Applied to Clinical and Biomedical Tasks. (arXiv:2307.12114v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.12114">
<div class="article-summary-box-inner">
<span><p>We evaluate four state-of-the-art instruction-tuned large language models
(LLMs) -- ChatGPT, Flan-T5 UL2, Tk-Instruct, and Alpaca -- on a set of 13
real-world clinical and biomedical natural language processing (NLP) tasks in
English, such as named-entity recognition (NER), question-answering (QA),
relation extraction (RE), etc. Our overall results demonstrate that the
evaluated LLMs begin to approach performance of state-of-the-art models in
zero- and few-shot scenarios for most tasks, and particularly well for the QA
task, even though they have never seen examples from these tasks before.
However, we observed that the classification and RE tasks perform below what
can be achieved with a specifically trained model for the medical field, such
as PubMedBERT. Finally, we noted that no LLM outperforms all the others on all
the studied tasks, with some models being better suited for certain tasks than
others.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explainable Topic-Enhanced Argument Mining from Heterogeneous Sources. (arXiv:2307.12131v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.12131">
<div class="article-summary-box-inner">
<span><p>Given a controversial target such as ``nuclear energy'', argument mining aims
to identify the argumentative text from heterogeneous sources. Current
approaches focus on exploring better ways of integrating the target-associated
semantic information with the argumentative text. Despite their empirical
successes, two issues remain unsolved: (i) a target is represented by a word or
a phrase, which is insufficient to cover a diverse set of target-related
subtopics; (ii) the sentence-level topic information within an argument, which
we believe is crucial for argument mining, is ignored. To tackle the above
issues, we propose a novel explainable topic-enhanced argument mining approach.
Specifically, with the use of the neural topic model and the language model,
the target information is augmented by explainable topic representations.
Moreover, the sentence-level topic information within the argument is captured
by minimizing the distance between its latent topic distribution and its
semantic representation through mutual learning. Experiments have been
conducted on the benchmark dataset in both the in-target setting and the
cross-target setting. Results demonstrate the superiority of the proposed model
against the state-of-the-art baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modality Confidence Aware Training for Robust End-to-End Spoken Language Understanding. (arXiv:2307.12134v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.12134">
<div class="article-summary-box-inner">
<span><p>End-to-end (E2E) spoken language understanding (SLU) systems that generate a
semantic parse from speech have become more promising recently. This approach
uses a single model that utilizes audio and text representations from
pre-trained speech recognition models (ASR), and outperforms traditional
pipeline SLU systems in on-device streaming scenarios. However, E2E SLU systems
still show weakness when text representation quality is low due to ASR
transcription errors. To overcome this issue, we propose a novel E2E SLU system
that enhances robustness to ASR errors by fusing audio and text representations
based on the estimated modality confidence of ASR hypotheses. We introduce two
novel techniques: 1) an effective method to encode the quality of ASR
hypotheses and 2) an effective approach to integrate them into E2E SLU models.
We show accuracy improvements on STOP dataset and share the analysis to
demonstrate the effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identifying Misinformation on YouTube through Transcript Contextual Analysis with Transformer Models. (arXiv:2307.12155v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.12155">
<div class="article-summary-box-inner">
<span><p>Misinformation on YouTube is a significant concern, necessitating robust
detection strategies. In this paper, we introduce a novel methodology for video
classification, focusing on the veracity of the content. We convert the
conventional video classification task into a text classification task by
leveraging the textual content derived from the video transcripts. We employ
advanced machine learning techniques like transfer learning to solve the
classification challenge. Our approach incorporates two forms of transfer
learning: (a) fine-tuning base transformer models such as BERT, RoBERTa, and
ELECTRA, and (b) few-shot learning using sentence-transformers MPNet and
RoBERTa-large. We apply the trained models to three datasets: (a) YouTube
Vaccine-misinformation related videos, (b) YouTube Pseudoscience videos, and
(c) Fake-News dataset (a collection of articles). Including the Fake-News
dataset extended the evaluation of our approach beyond YouTube videos. Using
these datasets, we evaluated the models distinguishing valid information from
misinformation. The fine-tuned models yielded Matthews Correlation
Coefficient&gt;0.81, accuracy&gt;0.90, and F1 score&gt;0.90 in two of three datasets.
Interestingly, the few-shot models outperformed the fine-tuned ones by 20% in
both Accuracy and F1 score for the YouTube Pseudoscience dataset, highlighting
the potential utility of this approach -- especially in the context of limited
training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Imitation Game: Detecting Human and AI-Generated Texts in the Era of Large Language Models. (arXiv:2307.12166v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.12166">
<div class="article-summary-box-inner">
<span><p>The potential of artificial intelligence (AI)-based large language models
(LLMs) holds considerable promise in revolutionizing education, research, and
practice. However, distinguishing between human-written and AI-generated text
has become a significant task. This paper presents a comparative study,
introducing a novel dataset of human-written and LLM-generated texts in
different genres: essays, stories, poetry, and Python code. We employ several
machine learning models to classify the texts. Results demonstrate the efficacy
of these models in discerning between human and AI-generated text, despite the
dataset's limited sample size. However, the task becomes more challenging when
classifying GPT-generated text, particularly in story writing. The results
indicate that the models exhibit superior performance in binary classification
tasks, such as distinguishing human-generated text from a specific LLM,
compared to the more complex multiclass tasks that involve discerning among
human-generated and multiple LLMs. Our findings provide insightful implications
for AI text detection while our dataset paves the way for future research in
this evolving area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FATRER: Full-Attention Topic Regularizer for Accurate and Robust Conversational Emotion Recognition. (arXiv:2307.12221v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.12221">
<div class="article-summary-box-inner">
<span><p>This paper concentrates on the understanding of interlocutors' emotions
evoked in conversational utterances. Previous studies in this literature mainly
focus on more accurate emotional predictions, while ignoring model robustness
when the local context is corrupted by adversarial attacks. To maintain
robustness while ensuring accuracy, we propose an emotion recognizer augmented
by a full-attention topic regularizer, which enables an emotion-related global
view when modeling the local context in a conversation. A joint topic modeling
strategy is introduced to implement regularization from both representation and
loss perspectives. To avoid over-regularization, we drop the constraints on
prior distributions that exist in traditional topic modeling and perform
probabilistic approximations based entirely on attention alignment. Experiments
show that our models obtain more favorable results than state-of-the-art
models, and gain convincing robustness under three types of adversarial
attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention Is All You Need. (arXiv:1706.03762v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1706.03762">
<div class="article-summary-box-inner">
<span><p>The dominant sequence transduction models are based on complex recurrent or
convolutional neural networks in an encoder-decoder configuration. The best
performing models also connect the encoder and decoder through an attention
mechanism. We propose a new simple network architecture, the Transformer, based
solely on attention mechanisms, dispensing with recurrence and convolutions
entirely. Experiments on two machine translation tasks show these models to be
superior in quality while being more parallelizable and requiring significantly
less time to train. Our model achieves 28.4 BLEU on the WMT 2014
English-to-German translation task, improving over the existing best results,
including ensembles by over 2 BLEU. On the WMT 2014 English-to-French
translation task, our model establishes a new single-model state-of-the-art
BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction
of the training costs of the best models from the literature. We show that the
Transformer generalizes well to other tasks by applying it successfully to
English constituency parsing both with large and limited training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Coreference Resolution by Leveraging Entity-Centric Features with Graph Neural Networks and Second-order Inference. (arXiv:2009.04639v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.04639">
<div class="article-summary-box-inner">
<span><p>One of the major challenges in coreference resolution is how to make use of
entity-level features defined over clusters of mentions rather than mention
pairs. However, coreferent mentions usually spread far apart in an entire text,
which makes it extremely difficult to incorporate entity-level features. We
propose a graph neural network-based coreference resolution method that can
capture the entity-centric information by encouraging the sharing of features
across all mentions that probably refer to the same real-world entity. Mentions
are linked to each other via the edges modeling how likely two linked mentions
point to the same entity. Modeling by such graphs, the features between
mentions can be shared by message passing operations in an entity-centric
manner. A global inference algorithm up to second-order features is also
presented to optimally cluster mentions into consistent groups. Experimental
results show our graph neural network-based method combing with the
second-order decoding algorithm (named GNNCR) achieved close to
state-of-the-art performance on the English CoNLL-2012 Shared Task dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Summarization by Jointly Extracting Sentences and Keywords. (arXiv:2009.07481v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07481">
<div class="article-summary-box-inner">
<span><p>We present RepRank, an unsupervised graph-based ranking model for extractive
multi-document summarization in which the similarity between words, sentences,
and word-to-sentence can be estimated by the distances between their vector
representations in a unified vector space. In order to obtain desirable
representations, we propose a self-attention based learning method that
represent a sentence by the weighted sum of its word embeddings, and the
weights are concentrated to those words hopefully better reflecting the content
of a document. We show that salient sentences and keywords can be extracted in
a joint and mutual reinforcement process using our learned representations, and
prove that this process always converges to a unique solution leading to
improvement in performance. A variant of absorbing random walk and the
corresponding sampling-based algorithm are also described to avoid redundancy
and increase diversity in the summaries. Experiment results with multiple
benchmark datasets show that RepRank achieved the best or comparable
performance in ROUGE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">XTQA: Span-Level Explanations of the Textbook Question Answering. (arXiv:2011.12662v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12662">
<div class="article-summary-box-inner">
<span><p>Textbook Question Answering (TQA) is a task that one should answer a
diagram/non-diagram question given a large multi-modal context consisting of
abundant essays and diagrams. We argue that the explainability of this task
should place students as a key aspect to be considered. To address this issue,
we devise a novel architecture towards span-level eXplanations of the TQA
(XTQA) based on our proposed coarse-to-fine grained algorithm, which can
provide not only the answers but also the span-level evidences to choose them
for students. This algorithm first coarsely chooses top $M$ paragraphs relevant
to questions using the TF-IDF method, and then chooses top $K$ evidence spans
finely from all candidate spans within these paragraphs by computing the
information gain of each span to questions. Experimental results shows that
XTQA significantly improves the state-of-the-art performance compared with
baselines. The source code is available at
https://github.com/keep-smile-001/opentqa
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SparseGAN: Sparse Generative Adversarial Network for Text Generation. (arXiv:2103.11578v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11578">
<div class="article-summary-box-inner">
<span><p>It is still a challenging task to learn a neural text generation model under
the framework of generative adversarial networks (GANs) since the entire
training process is not differentiable. The existing training strategies either
suffer from unreliable gradient estimations or imprecise sentence
representations. Inspired by the principle of sparse coding, we propose a
SparseGAN that generates semantic-interpretable, but sparse sentence
representations as inputs to the discriminator. The key idea is that we treat
an embedding matrix as an over-complete dictionary, and use a linear
combination of very few selected word embeddings to approximate the output
feature representation of the generator at each time step. With such
semantic-rich representations, we not only reduce unnecessary noises for
efficient adversarial training, but also make the entire training process fully
differentiable. Experiments on multiple text generation datasets yield
performance improvements, especially in sequence-level metrics, such as BLEU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model. (arXiv:2111.09564v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.09564">
<div class="article-summary-box-inner">
<span><p>The system log generated in a computer system refers to large-scale data that
are collected simultaneously and used as the basic data for determining errors,
intrusion and abnormal behaviors. The aim of system log anomaly detection is to
promptly identify anomalies while minimizing human intervention, which is a
critical problem in the industry. Previous studies performed anomaly detection
through algorithms after converting various forms of log data into a
standardized template using a parser. Particularly, a template corresponding to
a specific event should be defined in advance for all the log data using which
the information within the log key may get lost. In this study, we propose
LAnoBERT, a parser free system log anomaly detection method that uses the BERT
model, exhibiting excellent natural language processing performance. The
proposed method, LAnoBERT, learns the model through masked language modeling,
which is a BERT-based pre-training method, and proceeds with unsupervised
learning-based anomaly detection using the masked language modeling loss
function per log key during the test process. In addition, we also propose an
efficient inference process to establish a practically applicable pipeline to
the actual system. Experiments on three well-known log datasets, i.e., HDFS,
BGL, and Thunderbird, show that not only did LAnoBERT yield a higher anomaly
detection performance compared to unsupervised learning-based benchmark models,
but also it resulted in a comparable performance with supervised learning-based
benchmark models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DSTEA: Improving Dialogue State Tracking via Entity Adaptive Pre-training. (arXiv:2207.03858v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.03858">
<div class="article-summary-box-inner">
<span><p>Dialogue State Tracking (DST) is critical for comprehensively interpreting
user and system utterances, thereby forming the cornerstone of efficient
dialogue systems. Despite past research efforts focused on enhancing DST
performance through alterations to the model structure or integrating
additional features like graph relations, they often require additional
pre-training with external dialogue corpora. In this study, we propose DSTEA,
improving Dialogue State Tracking via Entity Adaptive pre-training, which can
enhance the encoder through by intensively training key entities in dialogue
utterances. DSTEA identifies these pivotal entities from input dialogues
utilizing four different methods: ontology information, named-entity
recognition, the spaCy, and the flair library. Subsequently, it employs
selective knowledge masking to train the model effectively. Remarkably, DSTEA
only requires pre-training without the direct infusion of extra knowledge into
the DST model. This approach resulted in substantial performance improvements
of four robust DST models on MultiWOZ 2.0, 2.1, and 2.2, with joint goal
accuracy witnessing an increase of up to 2.69% (from 52.41% to 55.10%). Further
validation of DSTEA's efficacy was provided through comparative experiments
considering various entity types and different entity adaptive pre-training
configurations such as masking strategy and masking rate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning "O" Helps for Learning More: Handling the Concealed Entity Problem for Class-incremental NER. (arXiv:2210.04676v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04676">
<div class="article-summary-box-inner">
<span><p>As the categories of named entities rapidly increase, the deployed NER models
are required to keep updating toward recognizing more entity types, creating a
demand for class-incremental learning for NER. Considering the privacy concerns
and storage constraints, the standard paradigm for class-incremental NER
updates the models with training data only annotated with the new classes, yet
the entities from other entity classes are unlabeled, regarded as "Non-entity"
(or "O"). In this work, we conduct an empirical study on the "Unlabeled Entity
Problem" and find that it leads to severe confusion between "O" and entities,
decreasing class discrimination of old classes and declining the model's
ability to learn new classes. To solve the Unlabeled Entity Problem, we propose
a novel representation learning method to learn discriminative representations
for the entity classes and "O". Specifically, we propose an entity-aware
contrastive learning method that adaptively detects entity clusters in "O".
Furthermore, we propose two effective distance-based relabeling strategies for
better learning the old classes. We introduce a more realistic and challenging
benchmark for class-incremental NER, and the proposed method achieves up to
10.62\% improvement over the baseline methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Log-linear Guardedness and its Implications. (arXiv:2210.10012v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10012">
<div class="article-summary-box-inner">
<span><p>Methods for erasing human-interpretable concepts from neural representations
that assume linearity have been found to be tractable and useful. However, the
impact of this removal on the behavior of downstream classifiers trained on the
modified representations is not fully understood. In this work, we formally
define the notion of log-linear guardedness as the inability of an adversary to
predict the concept directly from the representation, and study its
implications. We show that, in the binary case, under certain assumptions, a
downstream log-linear model cannot recover the erased concept. However, we
demonstrate that a multiclass log-linear model \emph{can} be constructed that
indirectly recovers the concept in some cases, pointing to the inherent
limitations of log-linear guardedness as a downstream bias mitigation
technique. These findings shed light on the theoretical limitations of linear
erasure methods and highlight the need for further research on the connections
between intrinsic and extrinsic bias in neural models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward expanding the scope of radiology report summarization to multiple anatomies and modalities. (arXiv:2211.08584v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.08584">
<div class="article-summary-box-inner">
<span><p>Radiology report summarization (RRS) is a growing area of research. Given the
Findings section of a radiology report, the goal is to generate a summary
(called an Impression section) that highlights the key observations and
conclusions of the radiology study. However, RRS currently faces essential
limitations.First, many prior studies conduct experiments on private datasets,
preventing reproduction of results and fair comparisons across different
systems and solutions. Second, most prior approaches are evaluated solely on
chest X-rays. To address these limitations, we propose a dataset (MIMIC-RRS)
involving three new modalities and seven new anatomies based on the MIMIC-III
and MIMIC-CXR datasets. We then conduct extensive experiments to evaluate the
performance of models both within and across modality-anatomy pairs in
MIMIC-RRS. In addition, we evaluate their clinical efficacy via RadGraph, a
factual correctness metric.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Style Classification of Rabbinic Literature for Detection of Lost Midrash Tanhuma Material. (arXiv:2211.09710v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09710">
<div class="article-summary-box-inner">
<span><p>Midrash collections are complex rabbinic works that consist of text in
multiple languages, which evolved through long processes of unstable oral and
written transmission. Determining the origin of a given passage in such a
compilation is not always straightforward and is often a matter of dispute
among scholars, yet it is essential for scholars' understanding of the passage
and its relationship to other texts in the rabbinic corpus. To help solve this
problem, we propose a system for classification of rabbinic literature based on
its style, leveraging recent advances in natural language processing for Hebrew
texts. Additionally, we demonstrate how this method can be applied to uncover
lost material from a specific midrash genre, Tan\d{h}uma-Yelammedenu, that has
been preserved in later anthologies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Knowledge Graph Reasoning on Graph Types: Static, Dynamic, and Multimodal. (arXiv:2212.05767v7 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.05767">
<div class="article-summary-box-inner">
<span><p>Knowledge graph reasoning (KGR), aiming to deduce new facts from existing
facts based on mined logic rules underlying knowledge graphs (KGs), has become
a fast-growing research direction. It has been proven to significantly benefit
the usage of KGs in many AI applications, such as question answering,
recommendation systems, and etc. According to the graph types, existing KGR
models can be roughly divided into three categories, i.e., static models,
temporal models, and multi-modal models. Early works in this domain mainly
focus on static KGR, and recent works try to leverage the temporal and
multi-modal information, which are more practical and closer to real-world.
However, no survey papers and open-source repositories comprehensively
summarize and discuss models in this important direction. To fill the gap, we
conduct a first survey for knowledge graph reasoning tracing from static to
temporal and then to multi-modal KGs. Concretely, the models are reviewed based
on bi-level taxonomy, i.e., top-level (graph types) and base-level (techniques
and scenarios). Besides, the performances, as well as datasets, are summarized
and presented. Moreover, we point out the challenges and potential
opportunities to enlighten the readers. The corresponding open-source
repository is shared on GitHub
https://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Next Chapter: A Study of Large Language Models in Storytelling. (arXiv:2301.09790v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09790">
<div class="article-summary-box-inner">
<span><p>To enhance the quality of generated stories, recent story generation models
have been investigating the utilization of higher-level attributes like plots
or commonsense knowledge. The application of prompt-based learning with large
language models (LLMs), exemplified by GPT-3, has exhibited remarkable
performance in diverse natural language processing (NLP) tasks. This paper
conducts a comprehensive investigation, utilizing both automatic and human
evaluation, to compare the story generation capacity of LLMs with recent models
across three datasets with variations in style, register, and length of
stories. The results demonstrate that LLMs generate stories of significantly
higher quality compared to other story generation models. Moreover, they
exhibit a level of performance that competes with human authors, albeit with
the preliminary observation that they tend to replicate real stories in
situations involving world knowledge, resembling a form of plagiarism.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature. (arXiv:2301.11305v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.11305">
<div class="article-summary-box-inner">
<span><p>The increasing fluency and widespread usage of large language models (LLMs)
highlight the desirability of corresponding tools aiding detection of
LLM-generated text. In this paper, we identify a property of the structure of
an LLM's probability function that is useful for such detection. Specifically,
we demonstrate that text sampled from an LLM tends to occupy negative curvature
regions of the model's log probability function. Leveraging this observation,
we then define a new curvature-based criterion for judging if a passage is
generated from a given LLM. This approach, which we call DetectGPT, does not
require training a separate classifier, collecting a dataset of real or
generated passages, or explicitly watermarking generated text. It uses only log
probabilities computed by the model of interest and random perturbations of the
passage from another generic pre-trained language model (e.g., T5). We find
DetectGPT is more discriminative than existing zero-shot methods for model
sample detection, notably improving detection of fake news articles generated
by 20B parameter GPT-NeoX from 0.81 AUROC for the strongest zero-shot baseline
to 0.95 AUROC for DetectGPT. See https://ericmitchell.ai/detectgpt for code,
data, and other project information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Harmful Agendas in News Articles. (arXiv:2302.00102v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00102">
<div class="article-summary-box-inner">
<span><p>Manipulated news online is a growing problem which necessitates the use of
automated systems to curtail its spread. We argue that while misinformation and
disinformation detection have been studied, there has been a lack of investment
in the important open challenge of detecting harmful agendas in news articles;
identifying harmful agendas is critical to flag news campaigns with the
greatest potential for real world harm. Moreover, due to real concerns around
censorship, harmful agenda detectors must be interpretable to be effective. In
this work, we propose this new task and release a dataset, NewsAgendas, of
annotated news articles for agenda identification. We show how interpretable
systems can be effective on this task and demonstrate that they can perform
comparably to black-box models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding. (arXiv:2303.04245v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04245">
<div class="article-summary-box-inner">
<span><p>While the successes of transformers across many domains are indisputable,
accurate understanding of the learning mechanics is still largely lacking.
Their capabilities have been probed on benchmarks which include a variety of
structured and reasoning tasks -- but mathematical understanding is lagging
substantially behind. Recent lines of work have begun studying representational
aspects of this question: that is, the size/depth/complexity of attention-based
networks to perform certain tasks. However, there is no guarantee the learning
dynamics will converge to the constructions proposed. In our paper, we provide
fine-grained mechanistic understanding of how transformers learn "semantic
structure", understood as capturing co-occurrence structure of words.
Precisely, we show, through a combination of mathematical analysis and
experiments on Wikipedia data and synthetic data modeled by Latent Dirichlet
Allocation (LDA), that the embedding layer and the self-attention layer encode
the topical structure. In the former case, this manifests as higher average
inner product of embeddings between same-topic words. In the latter, it
manifests as higher average pairwise attention between same-topic words. The
mathematical results involve several assumptions to make the analysis
tractable, which we verify on data, and might be of independent interest as
well.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MenuCraft: Interactive Menu System Design with Large Language Models. (arXiv:2303.04496v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04496">
<div class="article-summary-box-inner">
<span><p>Menu system design is a challenging task involving many design options and
various human factors. For example, one crucial factor that designers need to
consider is the semantic and systematic relation of menu commands. However,
capturing these relations can be challenging due to limited available
resources. With the advancement of neural language models, large language
models can utilize their vast pre-existing knowledge in designing and refining
menu systems. In this paper, we propose MenuCraft, an AI-assisted designer for
menu design that enables collaboration between the designer and a dialogue
system to design menus. MenuCraft offers an interactive language-based menu
design tool that simplifies the menu design process and enables easy
customization of design options. MenuCraft supports a variety of interactions
through dialog that allows performing zero/few-shot learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review. (arXiv:2303.13379v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.13379">
<div class="article-summary-box-inner">
<span><p>Educational technology innovations leveraging large language models (LLMs)
have shown the potential to automate the laborious process of generating and
analysing textual content. While various innovations have been developed to
automate a range of educational tasks (e.g., question generation, feedback
provision, and essay grading), there are concerns regarding the practicality
and ethicality of these innovations. Such concerns may hinder future research
and the adoption of LLMs-based innovations in authentic educational contexts.
To address this, we conducted a systematic scoping review of 118 peer-reviewed
papers published since 2017 to pinpoint the current state of research on using
LLMs to automate and support educational tasks. The findings revealed 53 use
cases for LLMs in automating education tasks, categorised into nine main
categories: profiling/labelling, detection, grading, teaching support,
prediction, knowledge representation, feedback, content generation, and
recommendation. Additionally, we also identified several practical and ethical
challenges, including low technological readiness, lack of replicability and
transparency, and insufficient privacy and beneficence considerations. The
findings were summarised into three recommendations for future studies,
including updating existing innovations with state-of-the-art models (e.g.,
GPT-3/4), embracing the initiative of open-sourcing models/systems, and
adopting a human-centred approach throughout the developmental process. As the
intersection of AI and education is continuously evolving, the findings of this
study can serve as an essential reference point for researchers, allowing them
to leverage the strengths, learn from the limitations, and uncover potential
research opportunities enabled by ChatGPT and other generative AI models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ELVIS: Empowering Locality of Vision Language Pre-training with Intra-modal Similarity. (arXiv:2304.05303v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.05303">
<div class="article-summary-box-inner">
<span><p>Deep learning has shown great potential in assisting radiologists in reading
chest X-ray (CXR) images, but its need for expensive annotations for improving
performance prevents widespread clinical application. Visual language
pre-training (VLP) can alleviate the burden and cost of annotation by
leveraging routinely generated reports for radiographs, which exist in large
quantities as well as in paired form (image-text pairs). Additionally,
extensions to localization-aware VLPs are being proposed to address the needs
for accurate localization of abnormalities for computer-aided diagnosis (CAD)
in CXR. However, we find that the formulation proposed by locality-aware VLP
literature actually leads to a loss in spatial relationships required for
downstream localization tasks. Therefore, we propose Empowering Locality of VLP
with Intra-modal Similarity, ELVIS, a VLP aware of intra-modal locality, to
better preserve the locality within radiographs or reports, which enhances the
ability to comprehend location references in text reports. Our locality-aware
VLP method significantly outperforms state-of-the art baselines in multiple
segmentation tasks and the MS-CXR phrase grounding task. Qualitatively, we show
that ELVIS focuses well on regions of interest described in the report text
compared to prior approaches, allowing for enhanced interpretability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classification of US Supreme Court Cases using BERT-Based Techniques. (arXiv:2304.08649v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.08649">
<div class="article-summary-box-inner">
<span><p>Models based on bidirectional encoder representations from transformers
(BERT) produce state of the art (SOTA) results on many natural language
processing (NLP) tasks such as named entity recognition (NER), part-of-speech
(POS) tagging etc. An interesting phenomenon occurs when classifying long
documents such as those from the US supreme court where BERT-based models can
be considered difficult to use on a first-pass or out-of-the-box basis. In this
paper, we experiment with several BERT-based classification techniques for US
supreme court decisions or supreme court database (SCDB) and compare them with
the previous SOTA results. We then compare our results specifically with SOTA
models for long documents. We compare our results for two classification tasks:
(1) a broad classification task with 15 categories and (2) a fine-grained
classification task with 279 categories. Our best result produces an accuracy
of 80\% on the 15 broad categories and 60\% on the fine-grained 279 categories
which marks an improvement of 8\% and 28\% respectively from previously
reported SOTA results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards autonomous system: flexible modular production system enhanced with large language model agents. (arXiv:2304.14721v4 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.14721">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a novel framework that combines large language
models (LLMs), digital twins and industrial automation system to enable
intelligent planning and control of production processes. We retrofit the
automation system for a modular production facility and create executable
control interfaces of fine-granular functionalities and coarse-granular skills.
Low-level functionalities are executed by automation components, and high-level
skills are performed by automation modules. Subsequently, a digital twin system
is developed, registering these interfaces and containing additional
descriptive information about the production system. Based on the retrofitted
automation system and the created digital twins, LLM-agents are designed to
interpret descriptive information in the digital twins and control the physical
system through service interfaces. These LLM-agents serve as intelligent agents
on different levels within an automation system, enabling autonomous planning
and control of flexible production. Given a task instruction as input, the
LLM-agents orchestrate a sequence of atomic functionalities and skills to
accomplish the task. We demonstrate how our implemented prototype can handle
un-predefined tasks, plan a production process, and execute the operations.
This research highlights the potential of integrating LLMs into industrial
automation systems in the context of smart factory for more agile, flexible,
and adaptive production processes, while it also underscores the critical
insights and limitations for future work. Demos at:
https://github.com/YuchenXia/GPT4IndustrialAutomation
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information. (arXiv:2305.01788v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01788">
<div class="article-summary-box-inner">
<span><p>Visual Word Sense Disambiguation (VWSD) is a task to find the image that most
accurately depicts the correct sense of the target word for the given context.
Previously, image-text matching models often suffered from recognizing
polysemous words. This paper introduces an unsupervised VWSD approach that uses
gloss information of an external lexical knowledge-base, especially the sense
definitions. Specifically, we suggest employing Bayesian inference to
incorporate the sense definitions when sense information of the answer is not
provided. In addition, to ameliorate the out-of-dictionary (OOD) issue, we
propose a context-aware definition generation with GPT-3. Experimental results
show that the VWSD performance significantly increased with our Bayesian
inference-based approach. In addition, our context-aware definition generation
achieved prominent performance improvement in OOD examples exhibiting better
performance than the existing definition generation method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MGR: Multi-generator Based Rationalization. (arXiv:2305.04492v8 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.04492">
<div class="article-summary-box-inner">
<span><p>Rationalization is to employ a generator and a predictor to construct a
self-explaining NLP model in which the generator selects a subset of
human-intelligible pieces of the input text to the following predictor.
However, rationalization suffers from two key challenges, i.e., spurious
correlation and degeneration, where the predictor overfits the spurious or
meaningless pieces solely selected by the not-yet well-trained generator and in
turn deteriorates the generator. Although many studies have been proposed to
address the two challenges, they are usually designed separately and do not
take both of them into account. In this paper, we propose a simple yet
effective method named MGR to simultaneously solve the two problems. The key
idea of MGR is to employ multiple generators such that the occurrence stability
of real pieces is improved and more meaningful pieces are delivered to the
predictor. Empirically, we show that MGR improves the F1 score by up to 20.9%
as compared to state-of-the-art methods. Codes are available at
https://github.com/jugechengzi/Rationalization-MGR .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Syllable Discovery and Cross-Lingual Generalization in a Visually Grounded, Self-Supervised Speech Model. (arXiv:2305.11435v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11435">
<div class="article-summary-box-inner">
<span><p>In this paper, we show that representations capturing syllabic units emerge
when training a self-supervised speech model with a visually-grounded training
objective. We demonstrate that a nearly identical model architecture (HuBERT)
trained with a masked language modeling loss does not exhibit this same
ability, suggesting that the visual grounding objective is responsible for the
emergence of this phenomenon. We propose the use of a minimum cut algorithm to
automatically predict syllable boundaries in speech, followed by a 2-stage
clustering method to group identical syllables together. We show that our model
not only outperforms a state-of-the-art syllabic segmentation method on the
language it was trained on (English), but also generalizes in a zero-shot
fashion to Estonian. Finally, we show that the same model is capable of
zero-shot generalization for a word segmentation task on 4 other languages from
the Zerospeech Challenge, in some cases beating the previous state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SpokenWOZ: A Large-Scale Speech-Text Benchmark for Spoken Task-Oriented Dialogue Agents. (arXiv:2305.13040v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.13040">
<div class="article-summary-box-inner">
<span><p>Task-oriented dialogue (TOD) models have made significant progress in recent
years. However, previous studies primarily focus on datasets written by
annotators, which has resulted in a gap between academic research and
real-world spoken conversation scenarios. While several small-scale spoken TOD
datasets are proposed to address robustness issues such as ASR errors, they
ignore the unique challenges in spoken conversation. To tackle the limitations,
we introduce SpokenWOZ, a large-scale speech-text dataset for spoken TOD,
containing 8 domains, 203k turns, 5.7k dialogues and 249 hours of audios from
human-to-human spoken conversations. SpokenWOZ further incorporates common
spoken characteristics such as word-by-word processing and reasoning in spoken
language. Based on these characteristics, we present cross-turn slot and
reasoning slot detection as new challenges. We conduct experiments on various
baselines, including text-modal models, newly proposed dual-modal models, and
LLMs, e.g., ChatGPT. The results show that the current models still have
substantial room for improvement in spoken conversation, where the most
advanced dialogue state tracker only achieves 25.65% in joint goal accuracy and
the SOTA end-to-end model only correctly completes the user request in 52.1% of
dialogues. The dataset, code, and leaderboard are available:
https://spokenwoz.github.io/SpokenWOZ-github.io/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Natural Language Processing for Long Texts: A Survey of the State-of-the-Art. (arXiv:2305.16259v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16259">
<div class="article-summary-box-inner">
<span><p>The adoption of Deep Neural Networks (DNNs) has greatly benefited Natural
Language Processing (NLP) during the past decade. However, the demands of long
document analysis are quite different from those of shorter texts, while the
ever increasing size of documents uploaded on-line renders automated
understanding of lengthy texts a critical issue. Relevant applications include
automated Web mining, legal document review, medical records analysis,
financial reports analysis, contract management, environmental impact
assessment, news aggregation, etc. Despite the relatively recent development of
efficient algorithms for analyzing long documents, practical tools in this
field are currently flourishing. This article serves as an entry point into
this dynamic domain and aims to achieve two objectives. Firstly, it provides an
overview of the relevant neural building blocks, serving as a concise tutorial
for the field. Secondly, it offers a brief examination of the current
state-of-the-art in long document NLP, with a primary focus on two key tasks:
document classification and document summarization. Sentiment analysis for long
texts is also covered, since it is typically treated as a particular case of
document classification. Consequently, this article presents an introductory
exploration of document-level analysis, addressing the primary challenges,
concerns, and existing solutions. Finally, the article presents publicly
available annotated datasets that can facilitate further research in this area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Emotion Experiencer Recognition. (arXiv:2305.16731v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16731">
<div class="article-summary-box-inner">
<span><p>The most prominent subtask in emotion analysis is emotion classification; to
assign a category to a textual unit, for instance a social media post. Many
research questions from the social sciences do, however, not only require the
detection of the emotion of an author of a post but to understand who is
ascribed an emotion in text. This task is tackled by emotion role labeling
which aims at extracting who is described in text to experience an emotion,
why, and towards whom. This could, however, be considered overly sophisticated
if the main question to answer is who feels which emotion. A targeted approach
for such setup is to classify emotion experiencer mentions (aka "emoters")
regarding the emotion they presumably perceive. This task is similar to named
entity recognition of person names with the difference that not every mentioned
entity name is an emoter. While, very recently, data with emoter annotations
has been made available, no experiments have yet been performed to detect such
mentions. With this paper, we provide baseline experiments to understand how
challenging the task is. We further evaluate the impact on experiencer-specific
emotion categorization and appraisal detection in a pipeline, when gold
mentions are not available. We show that experiencer detection in text is a
challenging task, with a precision of .82 and a recall of .56 (F1 =.66). These
results motivate future work of jointly modeling emoter spans and
emotion/appraisal predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inference-Time Intervention: Eliciting Truthful Answers from a Language Model. (arXiv:2306.03341v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.03341">
<div class="article-summary-box-inner">
<span><p>We introduce Inference-Time Intervention (ITI), a technique designed to
enhance the truthfulness of large language models (LLMs). ITI operates by
shifting model activations during inference, following a set of directions
across a limited number of attention heads. This intervention significantly
improves the performance of LLaMA models on the TruthfulQA benchmark. On an
instruction-finetuned LLaMA called Alpaca, ITI improves its truthfulness from
32.5% to 65.1%. We identify a tradeoff between truthfulness and helpfulness and
demonstrate how to balance it by tuning the intervention strength. ITI is
minimally invasive and computationally inexpensive. Moreover, the technique is
data efficient: while approaches like RLHF require extensive annotations, ITI
locates truthful directions using only few hundred examples. Our findings
suggest that LLMs may have an internal representation of the likelihood of
something being true, even as they produce falsehoods on the surface.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models. (arXiv:2306.14096v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14096">
<div class="article-summary-box-inner">
<span><p>Entity-level fine-grained sentiment analysis in the financial domain is a
crucial subtask of sentiment analysis and currently faces numerous challenges.
The primary challenge stems from the lack of high-quality and large-scale
annotated corpora specifically designed for financial text sentiment analysis,
which in turn limits the availability of data necessary for developing
effective text processing techniques. Recent advancements in large language
models (LLMs) have yielded remarkable performance in natural language
processing tasks, primarily centered around language pattern matching. In this
paper, we propose a novel and extensive Chinese fine-grained financial
sentiment analysis dataset, FinChina SA, for enterprise early warning. We
thoroughly evaluate and experiment with well-known existing open-source LLMs
using our dataset. We firmly believe that our dataset will serve as a valuable
resource to advance the exploration of real-world financial sentiment analysis
tasks, which should be the focus of future research. The FinChina SA dataset is
publicly available at https://github.com/YerayL/FinChina-SA
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is ChatGPT a Biomedical Expert? -- Exploring the Zero-Shot Performance of Current GPT Models in Biomedical Tasks. (arXiv:2306.16108v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.16108">
<div class="article-summary-box-inner">
<span><p>We assessed the performance of commercial Large Language Models (LLMs)
GPT-3.5-Turbo and GPT-4 on tasks from the 2023 BioASQ challenge. In Task 11b
Phase B, which is focused on answer generation, both models demonstrated
competitive abilities with leading systems. Remarkably, they achieved this with
simple zero-shot learning, grounded with relevant snippets. Even without
relevant snippets, their performance was decent, though not on par with the
best systems. Interestingly, the older and cheaper GPT-3.5-Turbo system was
able to compete with GPT-4 in the grounded Q&amp;A setting on factoid and list
answers. In Task 11b Phase A, focusing on retrieval, query expansion through
zero-shot learning improved performance, but the models fell short compared to
other systems. The code needed to rerun these experiments is available through
GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved NL2SQL based on Multi-layer Expert Network. (arXiv:2306.17727v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17727">
<div class="article-summary-box-inner">
<span><p>The Natural Language to SQL (NL2SQL) technique is used to convert natural
language queries into executable SQL statements. Typically, slot-filling is
employed as a classification method for multi-task cases to achieve this goal.
However, slot-filling can result in inaccurate SQL statement generation due to
negative migration issues arising from different classification tasks. To
overcome this limitation, this study introduces a new approach called
Multi-Layer Expert Generate SQL (MLEG-SQL), which utilizes a dedicated
multi-task hierarchical network. The lower layer of the network extracts
semantic features of natural language statements, while the upper layer builds
a specialized expert system for handling specific classification tasks. This
hierarchical approach mitigates performance degradation resulting from
different task conflicts. The proposed method was evaluated on the WiKSQL
dataset and was found to be effective in generating accurate SQL statements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ODD: A Benchmark Dataset for the NLP-based Opioid Related Aberrant Behavior Detection. (arXiv:2307.02591v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.02591">
<div class="article-summary-box-inner">
<span><p>Opioid related aberrant behaviors (ORAB) present novel risk factors for
opioid overdose. Previously, ORAB have been mainly assessed by survey results
and by monitoring drug administrations. Such methods however, cannot scale up
and do not cover the entire spectrum of aberrant behaviors. On the other hand,
ORAB are widely documented in electronic health record notes. This paper
introduces a novel biomedical natural language processing benchmark dataset
named ODD, for ORAB Detection Dataset. ODD is an expert-annotated dataset
comprising of more than 750 publicly available EHR notes. ODD has been designed
to identify ORAB from patients' EHR notes and classify them into nine
categories; 1) Confirmed Aberrant Behavior, 2) Suggested Aberrant Behavior, 3)
Opioids, 4) Indication, 5) Diagnosed opioid dependency, 6) Benzodiapines, 7)
Medication Changes, 8) Central Nervous System-related, and 9) Social
Determinants of Health. We explored two state-of-the-art natural language
processing (NLP) models (finetuning pretrained language models and
prompt-tuning approaches) to identify ORAB. Experimental results show that the
prompt-tuning models outperformed the finetuning models in most cateogories and
the gains were especially higher among uncommon categories (Suggested aberrant
behavior, Diagnosed opioid dependency and Medication change). Although the best
model achieved the highest 83.92% on area under precision recall curve,
uncommon classes (Suggested Aberrant Behavior, Diagnosed Opioid Dependence, and
Medication Change) still have a large room for performance improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Domain Adaptation of Sentence Embeddings using Adapters. (arXiv:2307.03104v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03104">
<div class="article-summary-box-inner">
<span><p>Sentence embeddings enable us to capture the semantic similarity of short
texts. Most sentence embedding models are trained for general semantic textual
similarity (STS) tasks. Therefore, to use sentence embeddings in a particular
domain, the model must be adapted to it in order to achieve good results.
Usually, this is done by fine-tuning the entire sentence embedding model for
the domain of interest. While this approach yields state-of-the-art results,
all of the model's weights are updated during fine-tuning, making this method
resource-intensive. Therefore, instead of fine-tuning entire sentence embedding
models for each target domain individually, we propose to train lightweight
adapters. These domain-specific adapters do not require fine-tuning all
underlying sentence embedding model parameters. Instead, we only train a small
number of additional parameters while keeping the weights of the underlying
sentence embedding model fixed. Training domain-specific adapters allows always
using the same base model and only exchanging the domain-specific adapters to
adapt sentence embeddings to a specific domain. We show that using adapters for
parameter-efficient domain adaptation of sentence embeddings yields competitive
performance within 1% of a domain-adapted, entirely fine-tuned sentence
embedding model while only training approximately 3.6% of the parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparing Apples to Apples: Generating Aspect-Aware Comparative Sentences from User Reviews. (arXiv:2307.03691v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03691">
<div class="article-summary-box-inner">
<span><p>It is time-consuming to find the best product among many similar
alternatives. Comparative sentences can help to contrast one item from others
in a way that highlights important features of an item that stand out. Given
reviews of one or multiple items and relevant item features, we generate
comparative review sentences to aid users to find the best fit. Specifically,
our model consists of three successive components in a transformer: (i) an item
encoding module to encode an item for comparison, (ii) a comparison generation
module that generates comparative sentences in an autoregressive manner, (iii)
a novel decoding method for user personalization. We show that our pipeline
generates fluent and diverse comparative sentences. We run experiments on the
relevance and fidelity of our generated sentences in a human evaluation study
and find that our algorithm creates comparative review sentences that are
relevant and truthful.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LaunchpadGPT: Language Model as Music Visualization Designer on Launchpad. (arXiv:2307.04827v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.04827">
<div class="article-summary-box-inner">
<span><p>Launchpad is a musical instrument that allows users to create and perform
music by pressing illuminated buttons. To assist and inspire the design of the
Launchpad light effect, and provide a more accessible approach for beginners to
create music visualization with this instrument, we proposed the LaunchpadGPT
model to generate music visualization designs on Launchpad automatically. Based
on the language model with excellent generation ability, our proposed
LaunchpadGPT takes an audio piece of music as input and outputs the lighting
effects of Launchpad-playing in the form of a video (Launchpad-playing video).
We collect Launchpad-playing videos and process them to obtain music and
corresponding video frame of Launchpad-playing as prompt-completion pairs, to
train the language model. The experiment result shows the proposed method can
create better music visualization than random generation methods and hold the
potential for a broader range of music visualization applications. Our code is
available at https://github.com/yunlong10/LaunchpadGPT/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge. (arXiv:2307.07851v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.07851">
<div class="article-summary-box-inner">
<span><p>Generic sentence embeddings provide a coarse-grained approximation of
semantic textual similarity but ignore specific aspects that make texts
similar. Conversely, aspect-based sentence embeddings provide similarities
between texts based on certain predefined aspects. Thus, similarity predictions
of texts are more targeted to specific requirements and more easily
explainable. In this paper, we present AspectCSE, an approach for aspect-based
contrastive learning of sentence embeddings. Results indicate that AspectCSE
achieves an average improvement of 3.97% on information retrieval tasks across
multiple aspects compared to the previous best results. We also propose using
Wikidata knowledge graph properties to train models of multi-aspect sentence
embeddings in which multiple specific aspects are simultaneously considered
during similarity predictions. We demonstrate that multi-aspect embeddings
outperform single-aspect embeddings on aspect-specific information retrieval
tasks. Finally, we examine the aspect-based sentence embedding space and
demonstrate that embeddings of semantically similar aspect labels are often
close, even without explicit similarity training between different aspect
labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disco-Bench: A Discourse-Aware Evaluation Benchmark for Language Modelling. (arXiv:2307.08074v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.08074">
<div class="article-summary-box-inner">
<span><p>Modeling discourse -- the linguistic phenomena that go beyond individual
sentences, is a fundamental yet challenging aspect of natural language
processing (NLP). However, existing evaluation benchmarks primarily focus on
the evaluation of inter-sentence properties and overlook critical discourse
phenomena that cross sentences. To bridge the gap, we propose Disco-Bench, a
benchmark that can evaluate intra-sentence discourse properties across a
diverse set of NLP tasks, covering understanding, translation, and generation.
Disco-Bench consists of 9 document-level testsets in the literature domain,
which contain rich discourse phenomena (e.g. cohesion and coherence) in Chinese
and/or English. For linguistic analysis, we also design a diagnostic test suite
that can examine whether the target models learn discourse knowledge. We
totally evaluate 20 general-, in-domain and commercial models based on
Transformer, advanced pretraining architectures and large language models
(LLMs). Our results show (1) the challenge and necessity of our evaluation
benchmark; (2) fine-grained pretraining based on literary document-level
training data consistently improves the modeling of discourse information. We
will release the datasets, pretrained models, and leaderboard, which we hope
can significantly facilitate research in this field:
https://github.com/longyuewangdcu/Disco-Bench.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Mathematical Derivations with Large Language Models. (arXiv:2307.09998v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.09998">
<div class="article-summary-box-inner">
<span><p>The derivation of mathematical results in specialised fields using Large
Language Models (LLMs) is an emerging research direction that can help identify
models' limitations, and potentially support mathematical discovery. In this
paper, we leverage a symbolic engine to generate derivations of equations at
scale, and investigate the capabilities of LLMs when deriving goal equations
from premises. Specifically, we employ in-context learning for GPT and
fine-tune a range of T5 models to compare the robustness and generalisation of
pre-training strategies to specialised models. Empirical results show that
fine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and
out-of-distribution test sets in terms of absolute performance. However, an
in-depth analysis reveals that the fine-tuned models are more sensitive to
perturbations involving unseen symbols and (to a lesser extent) changes to
equation structure. In addition, we analyse 1.7K equations and over 200
derivations to highlight common reasoning errors such as the inclusion of
incorrect, irrelevant, and redundant equations, along with the tendency to skip
derivation steps. Finally, we explore the suitability of existing metrics for
evaluating mathematical derivations finding evidence that, while they capture
general properties such as sensitivity to perturbations, they fail to highlight
fine-grained reasoning errors and essential differences between models.
Overall, this work demonstrates that training models on synthetic data can
improve their mathematical capabilities beyond larger architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Study on Fertility Proposals Using Multi-Grained Topic Analysis Methods. (arXiv:2307.10025v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.10025">
<div class="article-summary-box-inner">
<span><p>Fertility issues are closely related to population security, in 60 years
China's population for the first time in a negative growth trend, the change of
fertility policy is of great concern to the community. 2023 "two sessions"
proposal "suggests that the country in the form of legislation, the birth of
the registration of the cancellation of the marriage restriction" This topic
was once a hot topic on the Internet, and "unbundling" the relationship between
birth registration and marriage has become the focus of social debate. In this
paper, we adopt co-occurrence semantic analysis, topic analysis and sentiment
analysis to conduct multi-granularity semantic analysis of microblog comments.
It is found that the discussion on the proposal of "removing marriage
restrictions from birth registration" involves the individual, society and the
state at three dimensions, and is detailed into social issues such as personal
behaviour, social ethics and law, and national policy, with people's sentiment
inclined to be negative in most of the topics. Based on this, eight proposals
were made to provide a reference for governmental decision making and to form a
reference method for researching public opinion on political issues.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning. (arXiv:2307.10234v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.10234">
<div class="article-summary-box-inner">
<span><p>This study presents a thorough examination of various Generative Pretrained
Transformer (GPT) methodologies in sentiment analysis, specifically in the
context of Task 4 on the SemEval 2017 dataset. Three primary strategies are
employed: 1) prompt engineering using the advanced GPT-3.5 Turbo, 2)
fine-tuning GPT models, and 3) an inventive approach to embedding
classification. The research yields detailed comparative insights among these
strategies and individual GPT models, revealing their unique strengths and
potential limitations. Additionally, the study compares these GPT-based
methodologies with other current, high-performing models previously used with
the same dataset. The results illustrate the significant superiority of the GPT
approaches in terms of predictive performance, more than 22\% in F1-score
compared to the state-of-the-art. Further, the paper sheds light on common
challenges in sentiment analysis tasks, such as understanding context and
detecting sarcasm. It underscores the enhanced capabilities of the GPT models
to effectively handle these complexities. Taken together, these findings
highlight the promising potential of GPT models in sentiment analysis, setting
the stage for future research in this field. The code can be found at
https://github.com/DSAatUSU/SentimentGPT
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integrating a Heterogeneous Graph with Entity-aware Self-attention using Relative Position Labels for Reading Comprehension Model. (arXiv:2307.10443v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.10443">
<div class="article-summary-box-inner">
<span><p>Despite the significant progress made by transformer models in machine
reading comprehension tasks, they still fall short in handling complex
reasoning tasks due to the absence of explicit knowledge in the input sequence.
To address this limitation, many recent works have proposed injecting external
knowledge into the model. However, selecting relevant external knowledge,
ensuring its availability, and requiring additional processing steps remain
challenging. In this paper, we introduce a novel attention pattern that
integrates reasoning knowledge derived from a heterogeneous graph into the
transformer architecture without relying on external knowledge. The proposed
attention pattern comprises three key elements: global-local attention for word
tokens, graph attention for entity tokens that exhibit strong attention towards
tokens connected in the graph as opposed to those unconnected, and the
consideration of the type of relationship between each entity token and word
token. This results in optimized attention between the two if a relationship
exists. The pattern is coupled with special relative position labels, allowing
it to integrate with LUKE's entity-aware self-attention mechanism. The
experimental findings corroborate that our model outperforms both the
cutting-edge LUKE-Graph and the baseline LUKE model on the ReCoRD dataset that
focuses on commonsense reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">(Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs. (arXiv:2307.10490v3 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.10490">
<div class="article-summary-box-inner">
<span><p>We demonstrate how images and sounds can be used for indirect prompt and
instruction injection in multi-modal LLMs. An attacker generates an adversarial
perturbation corresponding to the prompt and blends it into an image or audio
recording. When the user asks the (unmodified, benign) model about the
perturbed image or audio, the perturbation steers the model to output the
attacker-chosen text and/or make the subsequent dialog follow the attacker's
instruction. We illustrate this attack with several proof-of-concept examples
targeting LLaVa and PandaGPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation. (arXiv:2307.11019v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11019">
<div class="article-summary-box-inner">
<span><p>Knowledge-intensive tasks (e.g., open-domain question answering (QA)) require
a substantial amount of factual knowledge and often rely on external
information for assistance. Recently, large language models (LLMs) (e.g.,
ChatGPT), have demonstrated impressive prowess in solving a wide range of tasks
with world knowledge, including knowledge-intensive tasks. However, it remains
unclear how well LLMs are able to perceive their factual knowledge boundaries,
particularly how they behave when incorporating retrieval augmentation. In this
study, we present an initial analysis of the factual knowledge boundaries of
LLMs and how retrieval augmentation affects LLMs on open-domain QA. Specially,
we focus on three primary research questions and analyze them by examining QA
performance, priori judgement and posteriori judgement of LLMs. We show
evidence that LLMs possess unwavering confidence in their capabilities to
respond to questions and the accuracy of their responses. Furthermore,
retrieval augmentation proves to be an effective approach in enhancing LLMs'
awareness of knowledge boundaries, thereby improving their judgemental
abilities. Additionally, we also find that LLMs have a propensity to rely on
the provided retrieval results when formulating answers, while the quality of
these results significantly impacts their reliance. The code to reproduce this
work is available at https://github.com/RUCAIBox/LLM-Knowledge-Boundary.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CausE: Towards Causal Knowledge Graph Embedding. (arXiv:2307.11610v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11610">
<div class="article-summary-box-inner">
<span><p>Knowledge graph embedding (KGE) focuses on representing the entities and
relations of a knowledge graph (KG) into the continuous vector spaces, which
can be employed to predict the missing triples to achieve knowledge graph
completion (KGC). However, KGE models often only briefly learn structural
correlations of triple data and embeddings would be misled by the trivial
patterns and noisy links in real-world KGs. To address this issue, we build the
new paradigm of KGE in the context of causality and embedding disentanglement.
We further propose a Causality-enhanced knowledge graph Embedding (CausE)
framework. CausE employs causal intervention to estimate the causal effect of
the confounder embeddings and design new training objectives to make stable
predictions. Experimental results demonstrate that CausE could outperform the
baseline models and achieve state-of-the-art KGC performance. We release our
code in https://github.com/zjukg/CausE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models. (arXiv:2307.08303v1 [cs.IR] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.08303">
<div class="article-summary-box-inner">
<span><p>Dense retrieval (DR) converts queries and documents into dense embeddings and
measures the similarity between queries and documents in vector space. One of
the challenges in DR is the lack of domain-specific training data. While DR
models can learn from large-scale public datasets like MS MARCO through
transfer learning, evidence shows that not all DR models and domains can
benefit from transfer learning equally. Recently, some researchers have
resorted to large language models (LLMs) to improve the zero-shot and few-shot
DR models. However, the hard prompts or human-written prompts utilized in these
works cannot guarantee the good quality of generated weak queries. To tackle
this, we propose soft prompt tuning for augmenting DR (SPTAR): For each task,
we leverage soft prompt-tuning to optimize a task-specific soft prompt on
limited ground truth data and then prompt the LLMs to tag unlabeled documents
with weak queries, yielding enough weak document-query pairs to train
task-specific dense retrievers. We design a filter to select high-quality
example document-query pairs in the prompt to further improve the quality of
weak tagged queries. To the best of our knowledge, there is no prior work
utilizing soft prompt tuning to augment DR models. The experiments demonstrate
that SPTAR outperforms the unsupervised baselines BM25 and the recently
proposed LLMs-based augmentation method for DR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?. (arXiv:2307.10719v1 [cs.AI] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.10719">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have exhibited impressive capabilities in
comprehending complex instructions. However, their blind adherence to provided
instructions has led to concerns regarding risks of malicious use. Existing
defence mechanisms, such as model fine-tuning or output censorship using LLMs,
have proven to be fallible, as LLMs can still generate problematic responses.
Commonly employed censorship approaches treat the issue as a machine learning
problem and rely on another LM to detect undesirable content in LLM outputs. In
this paper, we present the theoretical limitations of such semantic censorship
approaches. Specifically, we demonstrate that semantic censorship can be
perceived as an undecidable problem, highlighting the inherent challenges in
censorship that arise due to LLMs' programmatic and instruction-following
capabilities. Furthermore, we argue that the challenges extend beyond semantic
censorship, as knowledgeable attackers can reconstruct impermissible outputs
from a collection of permissible ones. As a result, we propose that the problem
of censorship needs to be reevaluated; it should be treated as a security
problem which warrants the adaptation of security-based approaches to mitigate
potential risks.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-07-25 23:09:38.254951569 UTC">2023-07-25 23:09:38 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>