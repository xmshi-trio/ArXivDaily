<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-12-06T01:30:00Z">12-06</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Continual Learning for On-Device Speech Recognition using Disentangled Conformers. (arXiv:2212.01393v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01393">
<div class="article-summary-box-inner">
<span><p>Automatic speech recognition research focuses on training and evaluating on
static datasets. Yet, as speech models are increasingly deployed on personal
devices, such models encounter user-specific distributional shifts. To simulate
this real-world scenario, we introduce LibriContinual, a continual learning
benchmark for speaker-specific domain adaptation derived from LibriVox
audiobooks, with data corresponding to 118 individual speakers and 6 train
splits per speaker of different sizes. Additionally, current speech recognition
models and continual learning algorithms are not optimized to be
compute-efficient. We adapt a general-purpose training algorithm NetAug for ASR
and create a novel Conformer variant called the DisConformer (Disentangled
Conformer). This algorithm produces ASR models consisting of a frozen 'core'
network for general-purpose use and several tunable 'augment' networks for
speaker-specific tuning. Using such models, we propose a novel
compute-efficient continual learning algorithm called DisentangledCL. Our
experiments show that the DisConformer models significantly outperform
baselines on general ASR i.e. LibriSpeech (15.58% rel. WER on test-other). On
speaker-specific LibriContinual they significantly outperform
trainable-parameter-matched baselines (by 20.65% rel. WER on test) and even
match fully finetuned baselines in some settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Thread With Caution: Proactively Helping Users Assess and Deescalate Tension in Their Online Discussions. (arXiv:2212.01401v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01401">
<div class="article-summary-box-inner">
<span><p>Incivility remains a major challenge for online discussion platforms, to such
an extent that even conversations between well-intentioned users can often
derail into uncivil behavior. Traditionally, platforms have relied on
moderators to -- with or without algorithmic assistance -- take corrective
actions such as removing comments or banning users. In this work we propose a
complementary paradigm that directly empowers users by proactively enhancing
their awareness about existing tension in the conversation they are engaging in
and actively guides them as they are drafting their replies to avoid further
escalation.
</p>
<p>As a proof of concept for this paradigm, we design an algorithmic tool that
provides such proactive information directly to users, and conduct a user study
in a popular discussion platform. Through a mixed methods approach combining
surveys with a randomized controlled experiment, we uncover qualitative and
quantitative insights regarding how the participants utilize and react to this
information. Most participants report finding this proactive paradigm valuable,
noting that it helps them to identify tension that they may have otherwise
missed and prompts them to further reflect on their own replies and to revise
them. These effects are corroborated by a comparison of how the participants
draft their reply when our tool warns them that their conversation is at risk
of derailing into uncivil behavior versus in a control condition where the tool
is disabled. These preliminary findings highlight the potential of this
user-centered paradigm and point to concrete directions for future
implementations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Avoiding spurious correlations via logit correction. (arXiv:2212.01433v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01433">
<div class="article-summary-box-inner">
<span><p>Empirical studies suggest that machine learning models trained with empirical
risk minimization (ERM) often rely on attributes that may be spuriously
correlated with the class labels. Such models typically lead to poor
performance during inference for data lacking such correlations. In this work,
we explicitly consider a situation where potential spurious correlations are
present in the majority of training data. In contrast with existing approaches,
which use the ERM model outputs to detect the samples without spurious
correlations, and either heuristically upweighting or upsampling those samples;
we propose the logit correction (LC) loss, a simple yet effective improvement
on the softmax cross-entropy loss, to correct the sample logit. We demonstrate
that minimizing the LC loss is equivalent to maximizing the group-balanced
accuracy, so the proposed LC could mitigate the negative impacts of spurious
correlations. Our extensive experimental results further reveal that the
proposed LC loss outperforms the SoTA solutions on multiple popular benchmarks
by a large margin, an average 5.5% absolute improvement, without access to
spurious attribute labels. LC is also competitive with oracle methods that make
use of the attribute labels. Code is available at
https://github.com/shengliu66/LC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Twitter Data Analysis: Izmir Earthquake Case. (arXiv:2212.01453v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01453">
<div class="article-summary-box-inner">
<span><p>T\"urkiye is located on a fault line; earthquakes often occur on a large and
small scale. There is a need for effective solutions for gathering current
information during disasters. We can use social media to get insight into
public opinion. This insight can be used in public relations and disaster
management. In this study, Twitter posts on Izmir Earthquake that took place on
October 2020 are analyzed. We question if this analysis can be used to make
social inferences on time. Data mining and natural language processing (NLP)
methods are used for this analysis. NLP is used for sentiment analysis and
topic modelling. The latent Dirichlet Allocation (LDA) algorithm is used for
topic modelling. We used the Bidirectional Encoder Representations from
Transformers (BERT) model working with Transformers architecture for sentiment
analysis. It is shown that the users shared their goodwill wishes and aimed to
contribute to the initiated aid activities after the earthquake. The users
desired to make their voices heard by competent institutions and organizations.
The proposed methods work effectively. Future studies are also discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topic Modeling on Clinical Social Work Notes for Exploring Social Determinants of Health Factors. (arXiv:2212.01462v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01462">
<div class="article-summary-box-inner">
<span><p>Most research studying social determinants of health (SDoH) has focused on
physician notes or structured elements of the electronic medical record (EMR).
We hypothesize that clinical notes from social workers, whose role is to
ameliorate social and economic factors, might provide a richer source of data
on SDoH. We sought to perform topic modeling to identify robust topics of
discussion within a large cohort of social work notes. We retrieved a diverse,
deidentified corpus of 0.95 million clinical social work notes from 181,644
patients at the University of California, San Francisco. We used word frequency
analysis and Latent Dirichlet Allocation (LDA) topic modeling analysis to
characterize this corpus and identify potential topics of discussion. Word
frequency analysis identified both medical and non-medical terms associated
with specific ICD10 chapters. The LDA topic modeling analysis extracted 11
topics related to social determinants of health risk factors including
financial status, abuse history, social support, risk of death, and mental
health. In addition, the topic modeling approach captured the variation between
different types of social work notes and across patients with different types
of diseases or conditions. We demonstrated that social work notes contain rich,
unique, and otherwise unobtainable information on an individual's SDoH.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NarraSum: A Large-Scale Dataset for Abstractive Narrative Summarization. (arXiv:2212.01476v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01476">
<div class="article-summary-box-inner">
<span><p>Narrative summarization aims to produce a distilled version of a narrative to
describe its most salient events and characters. Summarizing a narrative is
challenging as it requires an understanding of event causality and character
behaviors. To encourage research in this direction, we propose NarraSum, a
large-scale narrative summarization dataset. It contains 122K narrative
documents, which are collected from plot descriptions of movies and TV episodes
with diverse genres, and their corresponding abstractive summaries. Experiments
show that there is a large performance gap between humans and the
state-of-the-art summarization models on NarraSum. We hope that this dataset
will promote future research in summarization, as well as broader studies of
natural language understanding and generation. The dataset is available at
https://github.com/zhaochaocs/narrasum.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Event knowledge in large language models: the gap between the impossible and the unlikely. (arXiv:2212.01488v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01488">
<div class="article-summary-box-inner">
<span><p>People constantly use language to learn about the world. Computational
linguists have capitalized on this fact to build large language models (LLMs)
that acquire co-occurrence-based knowledge from language corpora. LLMs achieve
impressive performance on many tasks, but the robustness of their world
knowledge has been questioned. Here, we ask: do LLMs acquire generalized
knowledge about real-world events? Using curated sets of minimal sentence pairs
(n=1215), we tested whether LLMs are more likely to generate plausible event
descriptions compared to their implausible counterparts. We found that LLMs
systematically distinguish possible and impossible events (The teacher bought
the laptop vs. The laptop bought the teacher) but fall short of human
performance when distinguishing likely and unlikely events (The nanny tutored
the boy vs. The boy tutored the nanny). In follow-up analyses, we show that (i)
LLM scores are driven by both plausibility and surface-level sentence features,
(ii) LLMs generalize well across syntactic sentence variants (active vs
passive) but less well across semantic sentence variants (synonymous
sentences), (iii) some, but not all LLM deviations from ground-truth labels
align with crowdsourced human judgments, and (iv) explicit event plausibility
information emerges in middle LLM layers and remains high thereafter. Overall,
our analyses reveal a gap in LLMs' event knowledge, highlighting their
limitations as generalized knowledge bases. We conclude by speculating that the
differential performance on impossible vs. unlikely events is not a temporary
setback but an inherent property of LLMs, reflecting a fundamental difference
between linguistic knowledge and world knowledge in intelligent systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Orders Are Unwanted: Dynamic Deep Graph Convolutional Network for Personality Detection. (arXiv:2212.01515v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01515">
<div class="article-summary-box-inner">
<span><p>Predicting personality traits based on online posts has emerged as an
important task in many fields such as social network analysis. One of the
challenges of this task is assembling information from various posts into an
overall profile for each user. While many previous solutions simply concatenate
the posts into a long document and then encode the document by sequential or
hierarchical models, they introduce unwarranted orders for the posts, which may
mislead the models. In this paper, we propose a dynamic deep graph
convolutional network (D-DGCN) to overcome the above limitation. Specifically,
we design a learn-to-connect approach that adopts a dynamic multi-hop structure
instead of a deterministic structure, and combine it with a DGCN module to
automatically learn the connections between posts. The modules of post encoder,
learn-to-connect, and DGCN are jointly trained in an end-to-end manner.
Experimental results on the Kaggle and Pandora datasets show the superior
performance of D-DGCN to state-of-the-art baselines. Our code is available at
https://github.com/djz233/D-DGCN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The RoyalFlush System for the WMT 2022 Efficiency Task. (arXiv:2212.01543v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01543">
<div class="article-summary-box-inner">
<span><p>This paper describes the submission of the RoyalFlush neural machine
translation system for the WMT 2022 translation efficiency task. Unlike the
commonly used autoregressive translation system, we adopted a two-stage
translation paradigm called Hybrid Regression Translation (HRT) to combine the
advantages of autoregressive and non-autoregressive translation. Specifically,
HRT first autoregressively generates a discontinuous sequence (e.g., make a
prediction every $k$ tokens, $k&gt;1$) and then fills in all previously skipped
tokens at once in a non-autoregressive manner. Thus, we can easily trade off
the translation quality and speed by adjusting $k$. In addition, by integrating
other modeling techniques (e.g., sequence-level knowledge distillation and
deep-encoder-shallow-decoder layer allocation strategy) and a mass of
engineering efforts, HRT improves 80\% inference speed and achieves equivalent
translation performance with the same-capacity AT counterpart. Our fastest
system reaches 6k+ words/second on the GPU latency setting, estimated to be
about 3.1x faster than the last year's winner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta Learning for Few-Shot Medical Text Classification. (arXiv:2212.01552v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01552">
<div class="article-summary-box-inner">
<span><p>Medical professionals frequently work in a data constrained setting to
provide insights across a unique demographic. A few medical observations, for
instance, informs the diagnosis and treatment of a patient. This suggests a
unique setting for meta-learning, a method to learn models quickly on new
tasks, to provide insights unattainable by other methods. We investigate the
use of meta-learning and robustness techniques on a broad corpus of benchmark
text and medical data. To do this, we developed new data pipelines, combined
language models with meta-learning approaches, and extended existing
meta-learning algorithms to minimize worst case loss. We find that
meta-learning on text is a suitable framework for text-based data, providing
better data efficiency and comparable performance to few-shot language models
and can be successfully applied to medical note data. Furthermore,
meta-learning models coupled with DRO can improve worst case loss across
disease codes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling Label Correlations for Ultra-Fine Entity Typing with Neural Pairwise Conditional Random Field. (arXiv:2212.01581v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01581">
<div class="article-summary-box-inner">
<span><p>Ultra-fine entity typing (UFET) aims to predict a wide range of type phrases
that correctly describe the categories of a given entity mention in a sentence.
Most recent works infer each entity type independently, ignoring the
correlations between types, e.g., when an entity is inferred as a president, it
should also be a politician and a leader. To this end, we use an undirected
graphical model called pairwise conditional random field (PCRF) to formulate
the UFET problem, in which the type variables are not only unarily influenced
by the input but also pairwisely relate to all the other type variables. We use
various modern backbones for entity typing to compute unary potentials, and
derive pairwise potentials from type phrase representations that both capture
prior semantic information and facilitate accelerated inference. We use
mean-field variational inference for efficient type inference on very large
type sets and unfold it as a neural network module to enable end-to-end
training. Experiments on UFET show that the Neural-PCRF consistently
outperforms its backbones with little cost and results in a competitive
performance against cross-encoder based SOTA while being thousands of times
faster. We also find Neural- PCRF effective on a widely used fine-grained
entity typing dataset with a smaller type set. We pack Neural-PCRF as a network
module that can be plugged onto multi-label type classifiers with ease and
release it in https://github.com/modelscope/adaseq/tree/master/examples/NPCRF.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RHO ($\rho$): Reducing Hallucination in Open-domain Dialogues with Knowledge Grounding. (arXiv:2212.01588v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01588">
<div class="article-summary-box-inner">
<span><p>Dialogue systems can leverage large pre-trained language models and knowledge
to generate fluent and informative responses. However, these models are still
prone to produce hallucinated responses not supported by the input source,
which greatly hinders their application. The heterogeneity between external
knowledge and dialogue context challenges representation learning and source
integration, and further contributes to unfaithfulness. To handle this
challenge and generate more faithful responses, this paper presents RHO
($\rho$) utilizing the representations of linked entities and relation
predicates from a knowledge graph (KG). We propose (1) local knowledge
grounding to combine textual embeddings with the corresponding KG embeddings;
and (2) global knowledge grounding to equip RHO with multi-hop reasoning
abilities via the attention mechanism. In addition, we devise a response
re-ranking technique based on walks over KG sub-graphs for better
conversational reasoning. Experimental results on OpenDialKG show that our
approach significantly outperforms state-of-the-art methods on both automatic
and human evaluation by a large margin, especially in hallucination reduction
(17.54% in FeQA).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoP: Factual Inconsistency Detection by Controlling the Preference. (arXiv:2212.01611v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01611">
<div class="article-summary-box-inner">
<span><p>Abstractive summarization is the process of generating a summary given a
document as input. Although significant progress has been made, the factual
inconsistency between the document and the generated summary still limits its
practical applications. Previous work found that the probabilities assigned by
the generation model reflect its preferences for the generated summary,
including the preference for factual consistency, and the preference for the
language or knowledge prior as well. To separate the preference for factual
consistency, we propose an unsupervised framework named CoP by controlling the
preference of the generation model with the help of prompt. More specifically,
the framework performs an extra inference step in which a text prompt is
introduced as an additional input. In this way, another preference is described
by the generation probability of this extra inference process. The difference
between the above two preferences, i.e. the difference between the
probabilities, could be used as measurements for detecting factual
inconsistencies. Interestingly, we found that with the properly designed
prompt, our framework could evaluate specific preferences and serve as
measurements for fine-grained categories of inconsistency, such as
entity-related inconsistency, coreference-related inconsistency, etc. Moreover,
our framework could also be extended to the supervised setting to learn better
prompt from the labeled data as well. Experiments show that our framework
achieves new SOTA results on three factual inconsistency detection tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Named Entity and Relation Extraction with Multi-Modal Retrieval. (arXiv:2212.01612v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01612">
<div class="article-summary-box-inner">
<span><p>Multi-modal named entity recognition (NER) and relation extraction (RE) aim
to leverage relevant image information to improve the performance of NER and
RE. Most existing efforts largely focused on directly extracting potentially
useful information from images (such as pixel-level features, identified
objects, and associated captions). However, such extraction processes may not
be knowledge aware, resulting in information that may not be highly relevant.
In this paper, we propose a novel Multi-modal Retrieval based framework (MoRe).
MoRe contains a text retrieval module and an image-based retrieval module,
which retrieve related knowledge of the input text and image in the knowledge
corpus respectively. Next, the retrieval results are sent to the textual and
visual models respectively for predictions. Finally, a Mixture of Experts (MoE)
module combines the predictions from the two models to make the final decision.
Our experiments show that both our textual model and visual model can achieve
state-of-the-art performance on four multi-modal NER datasets and one
multi-modal RE dataset. With MoE, the model performance can be further improved
and our analysis demonstrates the benefits of integrating both textual and
visual cues for such tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Intermediate Entity-based Sparse Interpretable Representation Learning. (arXiv:2212.01641v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01641">
<div class="article-summary-box-inner">
<span><p>Interpretable entity representations (IERs) are sparse embeddings that are
"human-readable" in that dimensions correspond to fine-grained entity types and
values are predicted probabilities that a given entity is of the corresponding
type. These methods perform well in zero-shot and low supervision settings.
Compared to standard dense neural embeddings, such interpretable
representations may permit analysis and debugging. However, while fine-tuning
sparse, interpretable representations improves accuracy on downstream tasks, it
destroys the semantics of the dimensions which were enforced in pre-training.
Can we maintain the interpretable semantics afforded by IERs while improving
predictive performance on downstream tasks? Toward this end, we propose
Intermediate enTity-based Sparse Interpretable Representation Learning
(ItsIRL). ItsIRL realizes improved performance over prior IERs on biomedical
tasks, while maintaining "interpretability" generally and their ability to
support model debugging specifically. The latter is enabled in part by the
ability to perform "counterfactual" fine-grained entity type manipulation,
which we explore in this work. Finally, we propose a method to construct entity
type based class prototypes for revealing global semantic properties of classes
learned by our model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Global memory transformer for processing long documents. (arXiv:2212.01650v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01650">
<div class="article-summary-box-inner">
<span><p>Transformer variants dominate the state-of-the-art in different natural
language processing tasks such as translation, reading comprehension and
summarization. Our paper is more directed to use general memory slots added to
the inputs and studying the results of adding these slots. This paper is a go
on study of general memory slots rule that were added to the input of the
proposed model in previous work. We have two main tasks;1) pretraining task
using masked language modeling and b) fine tuning task using HotpotQA . This
study aims to verify the ability of the proposed model to handle chunks as if
they were one chunk comparing with the base model. As baseline we used T5
transformer. We studied the rule of memory slots augmented to each input chunk
and studied the model performance without selector. We found that adding memory
to input chunks helped the proposed model to overcome the baseline on Masked
language modeling task with specific training parameters. Ablation study
reveals the ability of using the compressed input chunks with a degradation in
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Fine-Tuning Data Selection for ASR Using Self-Supervised Speech Models. (arXiv:2212.01661v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01661">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) has been able to leverage unlabeled data to
boost the performance of automatic speech recognition (ASR) models when we have
access to only a small amount of transcribed speech data. However, this raises
the question of which subset of the available unlabeled data should be selected
for transcription. Our work investigates different unsupervised data selection
techniques for fine-tuning the HuBERT model under a limited transcription
budget. We investigate the impact of speaker diversity, gender bias, and topic
diversity on the downstream ASR performance. We also devise two novel
techniques for unsupervised data selection: pre-training loss based data
selection and the perplexity of byte pair encoded clustered units (PBPE) and we
show how these techniques compare to pure random data selection. Finally, we
analyze the correlations between the inherent characteristics of the selected
fine-tuning subsets as well as how these characteristics correlate with the
resultant word error rate. We demonstrate the importance of token diversity,
speaker diversity, and topic diversity in achieving the best performance in
terms of WER.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">T-STAR: Truthful Style Transfer using AMR Graph as Intermediate Representation. (arXiv:2212.01667v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01667">
<div class="article-summary-box-inner">
<span><p>Unavailability of parallel corpora for training text style transfer (TST)
models is a very challenging yet common scenario. Also, TST models implicitly
need to preserve the content while transforming a source sentence into the
target style. To tackle these problems, an intermediate representation is often
constructed that is devoid of style while still preserving the meaning of the
source sentence. In this work, we study the usefulness of Abstract Meaning
Representation (AMR) graph as the intermediate style agnostic representation.
We posit that semantic notations like AMR are a natural choice for an
intermediate representation. Hence, we propose T-STAR: a model comprising of
two components, text-to-AMR encoder and a AMR-to-text decoder. We propose
several modeling improvements to enhance the style agnosticity of the generated
AMR. To the best of our knowledge, T-STAR is the first work that uses AMR as an
intermediate representation for TST. With thorough experimental evaluation we
show T-STAR significantly outperforms state of the art techniques by achieving
on an average 15.2% higher content preservation with negligible loss (3%
approx.) in style accuracy. Through detailed human evaluation with 90,000
ratings, we also show that T-STAR has up to 50% lesser hallucinations compared
to state of the art TST models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Medical Document Summarization. (arXiv:2212.01669v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01669">
<div class="article-summary-box-inner">
<span><p>The internet has had a dramatic effect on the healthcare industry, allowing
documents to be saved, shared, and managed digitally. This has made it easier
to locate and share important data, improving patient care and providing more
opportunities for medical studies. As there is so much data accessible to
doctors and patients alike, summarizing it has become increasingly necessary -
this has been supported through the introduction of deep learning and
transformer-based networks, which have boosted the sector significantly in
recent years. This paper gives a comprehensive survey of the current techniques
and trends in medical summarization
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models as Agent Models. (arXiv:2212.01681v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01681">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) are trained on collections of documents, written by
individual human agents to achieve specific goals in an outside world. During
training, LMs have access only to text of these documents, with no direct
evidence of the internal states of the agents that produced them -- a fact
often used to argue that LMs are incapable of modeling goal-directed aspects of
human language production and comprehension. Can LMs trained on text learn
anything at all about the relationship between language and use? I argue that
LMs are models of intentional communication in a specific, narrow sense. When
performing next word prediction given a textual context, an LM can infer and
represent properties of an agent likely to have produced that context. These
representations can in turn influence subsequent LM generation in the same way
that agents' communicative intentions influence their language. I survey
findings from the recent literature showing that -- even in today's non-robust
and error-prone models -- LMs infer and use representations of fine-grained
communicative intentions and more abstract beliefs and goals. Despite the
limited nature of their training data, they can thus serve as building blocks
for systems that communicate and act intentionally.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What is Not in the Context? Evaluation of Few-shot Learners with Informative Demonstrations. (arXiv:2212.01692v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01692">
<div class="article-summary-box-inner">
<span><p>Large language models demonstrate an emergent ability to learn a new task
from a small number of input-output demonstrations, referred to as in-context
few-shot learning. However, recent work shows that in such settings, models
mainly learn to mimic the new task distribution, instead of the mechanics of
the new task. We argue that the commonly-used evaluation settings of few-shot
models utilizing a random selection of in-context demonstrations is not able to
disentangle models' ability to learn new skills from demonstrations, as most of
the such-selected demonstrations are not informative for prediction beyond
exposing the new task's input and output distribution.
</p>
<p>Therefore, we introduce an evaluation technique that disentangles few-shot
learners' gain from in-context learning by picking the demonstrations sharing a
specific, informative concept with the predicted sample, in addition to the
performance reached by mainly non-informative samples. We find that regardless
of the model size, existing few-shot learners are not able to benefit from
observing such informative concepts in demonstrations. We also find that such
ability may not be obtained trivially by exposing the informative
demonstrations in the training process, leaving the challenge of training true
in-context learners open.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Robust NLG Bias Evaluation with Syntactically-diverse Prompts. (arXiv:2212.01700v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01700">
<div class="article-summary-box-inner">
<span><p>We present a robust methodology for evaluating biases in natural language
generation(NLG) systems. Previous works use fixed hand-crafted prefix templates
with mentions of various demographic groups to prompt models to generate
continuations for bias analysis. These fixed prefix templates could themselves
be specific in terms of styles or linguistic structures, which may lead to
unreliable fairness conclusions that are not representative of the general
trends from tone varying prompts. To study this problem, we paraphrase the
prompts with different syntactic structures and use these to evaluate
demographic bias in NLG systems. Our results suggest similar overall bias
trends but some syntactic structures lead to contradictory conclusions compared
to past works. We show that our methodology is more robust and that some
syntactic structures prompt more toxic content while others could prompt less
biased generation. This suggests the importance of not relying on a fixed
syntactic structure and using tone-invariant prompts. Introducing
syntactically-diverse prompts can achieve more robust NLG (bias) evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Linguistic Constructs as the Representation of the Domain Model in an Intelligent Language Tutoring System. (arXiv:2212.01711v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01711">
<div class="article-summary-box-inner">
<span><p>This paper presents the development of an AI-based language learning platform
Revita. It is a freely available intelligent online tutor, developed to support
learners of multiple languages, from low-intermediate to advanced levels. It
has been in pilot use by hundreds of students at several universities, whose
feedback and needs are shaping the development. One of the main emerging
features of Revita is the introduction of a system of linguistic constructs as
the representation of domain knowledge. The system of constructs is developed
in close collaboration with experts in language teaching. Constructs define the
types of exercises, the content of the feedback, and enable the detailed
modeling and evaluation of learning progress.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KPT: Keyword-guided Pre-training for Grounded Dialog Generation. (arXiv:2212.01739v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01739">
<div class="article-summary-box-inner">
<span><p>Incorporating external knowledge into the response generation process is
essential to building more helpful and reliable dialog agents. However,
collecting knowledge-grounded conversations is often costly, calling for a
better pre-trained model for grounded dialog generation that generalizes well
w.r.t. different types of knowledge. In this work, we propose KPT
(Keyword-guided Pre-Training), a novel self-supervised pre-training method for
grounded dialog generation without relying on extra knowledge annotation.
Specifically, we use a pre-trained language model to extract the most uncertain
tokens in the dialog as keywords. With these keywords, we construct two kinds
of knowledge and pre-train a knowledge-grounded response generation model,
aiming at handling two different scenarios: (1) the knowledge should be
faithfully grounded; (2) it can be selectively used. For the former, the
grounding knowledge consists of keywords extracted from the response. For the
latter, the grounding knowledge is additionally augmented with keywords
extracted from other utterances in the same dialog. Since the knowledge is
extracted from the dialog itself, KPT can be easily performed on a large volume
and variety of dialogue data. We considered three data sources (open-domain,
task-oriented, conversational QA) with a total of 2.5M dialogues. We conduct
extensive experiments on various few-shot knowledge-grounded generation tasks,
including grounding on dialog acts, knowledge graphs, persona descriptions, and
Wikipedia passages. Our comprehensive experiments and analyses demonstrate that
KPT consistently outperforms state-of-the-art methods on these tasks with
diverse grounding knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Languages You Know Influence Those You Learn: Impact of Language Characteristics on Multi-Lingual Text-to-Text Transfer. (arXiv:2212.01757v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01757">
<div class="article-summary-box-inner">
<span><p>Multi-lingual language models (LM), such as mBERT, XLM-R, mT5, mBART, have
been remarkably successful in enabling natural language tasks in low-resource
languages through cross-lingual transfer from high-resource ones. In this work,
we try to better understand how such models, specifically mT5, transfer *any*
linguistic and semantic knowledge across languages, even though no explicit
cross-lingual signals are provided during pre-training. Rather, only
unannotated texts from each language are presented to the model separately and
independently of one another, and the model appears to implicitly learn
cross-lingual connections. This raises several questions that motivate our
study, such as: Are the cross-lingual connections between every language pair
equally strong? What properties of source and target language impact the
strength of cross-lingual transfer? Can we quantify the impact of those
properties on the cross-lingual transfer?
</p>
<p>In our investigation, we analyze a pre-trained mT5 to discover the attributes
of cross-lingual connections learned by the model. Through a statistical
interpretation framework over 90 language pairs across three tasks, we show
that transfer performance can be modeled by a few linguistic and data-derived
features. These observations enable us to interpret cross-lingual understanding
of the mT5 model. Through these observations, one can favorably choose the best
source language for a task, and can anticipate its training data demands. A key
finding of this work is that similarity of syntax, morphology and phonology are
good predictors of cross-lingual transfer, significantly more than just the
lexical similarity of languages. For a given language, we are able to predict
zero-shot performance, that increases on a logarithmic scale with the number of
few-shot target language data points.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving End-to-end Speech Translation by Leveraging Auxiliary Speech and Text Data. (arXiv:2212.01778v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01778">
<div class="article-summary-box-inner">
<span><p>We present a method for introducing a text encoder into pre-trained
end-to-end speech translation systems. It enhances the ability of adapting one
modality (i.e., source-language speech) to another (i.e., source-language
text). Thus, the speech translation model can learn from both unlabeled and
labeled data, especially when the source-language text data is abundant. Beyond
this, we present a denoising method to build a robust text encoder that can
deal with both normal and noisy text data. Our system sets new
state-of-the-arts on the MuST-C En-De, En-Fr, and LibriSpeech En-Fr tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MiLMo:Minority Multilingual Pre-trained Language Model. (arXiv:2212.01779v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01779">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models are trained on large-scale unsupervised data, and
they can be fine-tuned on small-scale labeled datasets and achieve good
results. Multilingual pre-trained language models can be trained on multiple
languages and understand multiple languages at the same time. At present, the
research on pre-trained models mainly focuses on rich-resource language, while
there is relatively little research on low-resource languages such as minority
languages, and the public multilingual pre-trained language model can not work
well for minority languages. Therefore, this paper constructs a multilingual
pre-trained language model named MiLMo that performs better on minority
language tasks, including Mongolian, Tibetan, Uyghur, Kazakh and Korean. To
solve the problem of scarcity of datasets on minority languages and verify the
effectiveness of the MiLMo model, this paper constructs a minority multilingual
text classification dataset named MiTC, and trains a word2vec model for each
language. By comparing the word2vec model and the pre-trained model in the text
classification task, this paper provides an optimal scheme for the downstream
task research of minority languages. The final experimental results show that
the performance of the pre-trained model is better than that of the word2vec
model, and it has achieved the best results in minority multilingual text
classification. The multilingual pre-trained language model MiLMo, multilingual
word2vec model and multilingual text classification dataset MiTC are published
on https://milmo.cmli-nlp.com.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An LSTM model for Twitter Sentiment Analysis. (arXiv:2212.01791v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01791">
<div class="article-summary-box-inner">
<span><p>Sentiment analysis on social media such as Twitter provides organizations and
individuals an effective way to monitor public emotions towards them and their
competitors. As a result, sentiment analysis has become an important and
challenging task. In this work, we have collected seven publicly available and
manually annotated twitter sentiment datasets. We create a new training and
testing dataset from the collected datasets. We develop an LSTM model to
classify sentiment of a tweet and evaluate the model with the new dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Constructing Highly Inductive Contexts for Dialogue Safety through Controllable Reverse Generation. (arXiv:2212.01810v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01810">
<div class="article-summary-box-inner">
<span><p>Large pretrained language models can easily produce toxic or biased content,
which is prohibitive for practical use. In order to detect such toxic
generations, existing methods rely on templates, real-world data extraction,
crowdsourcing workers, or automatic generation to construct adversarial
contexts that are likely to induce toxic generations. However, what type of
context is more likely to induce unsafe responses is still under-explored. In
this paper, we identify that context toxicity and context category (e.g.,
\textit{profanity}, \textit{insult}, \textit{drugs}, etc.) are two important
factors to cause safety issues in response generation. Hence, we propose a
method called \emph{reverse generation} to construct adversarial contexts
conditioned on a given response, with the flexibility to control category,
toxicity level, and inductivity of the generated contexts. Via reverse
generation, we augment the existing BAD dataset and construct a new dataset
BAD+ which contains more than 120K diverse and highly inductive contexts in 12
categories. We test three popular pretrained dialogue models (Blender,
DialoGPT, and Plato2) and find that BAD+ can largely expose their safety
problems. Furthermore, we show that BAD+ can greatly enhance the safety of
generation and reveal the key factors of safety improvement. Our code and
dataset is available at \url{https://github.com/thu-coai/Reverse_Generation}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pair-Based Joint Encoding with Relational Graph Convolutional Networks for Emotion-Cause Pair Extraction. (arXiv:2212.01844v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01844">
<div class="article-summary-box-inner">
<span><p>Emotion-cause pair extraction (ECPE) aims to extract emotion clauses and
corresponding cause clauses, which have recently received growing attention.
Previous methods sequentially encode features with a specified order. They
first encode the emotion and cause features for clause extraction and then
combine them for pair extraction. This lead to an imbalance in inter-task
feature interaction where features extracted later have no direct contact with
the former. To address this issue, we propose a novel Pair-Based Joint Encoding
(PBJE) network, which generates pairs and clauses features simultaneously in a
joint feature encoding manner to model the causal relationship in clauses. PBJE
can balance the information flow among emotion clauses, cause clauses and
pairs. From a multi-relational perspective, we construct a heterogeneous
undirected graph and apply the Relational Graph Convolutional Network (RGCN) to
capture the various relationship between clauses and the relationship between
pairs and clauses. Experimental results show that PBJE achieves
state-of-the-art performance on the Chinese benchmark corpus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward Efficient Language Model Pretraining and Downstream Adaptation via Self-Evolution: A Case Study on SuperGLUE. (arXiv:2212.01853v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01853">
<div class="article-summary-box-inner">
<span><p>This technical report briefly describes our JDExplore d-team's Vega v2
submission on the SuperGLUE leaderboard. SuperGLUE is more challenging than the
widely used general language understanding evaluation (GLUE) benchmark,
containing eight difficult language understanding tasks, including question
answering, natural language inference, word sense disambiguation, coreference
resolution, and reasoning. [Method] Instead of arbitrarily increasing the size
of a pretrained language model (PLM), our aim is to 1) fully extract knowledge
from the input pretraining data given a certain parameter budget, e.g., 6B, and
2) effectively transfer this knowledge to downstream tasks. To achieve goal 1),
we propose self-evolution learning for PLMs to wisely predict the informative
tokens that should be masked, and supervise the masked language modeling (MLM)
process with rectified smooth labels. For goal 2), we leverage the prompt
transfer technique to improve the low-resource tasks by transferring the
knowledge from the foundation model and related downstream tasks to the target
task. [Results] According to our submission record (Oct. 2022), with our
optimized pretraining and fine-tuning strategies, our 6B Vega method achieved
new state-of-the-art performance on 4/8 tasks, sitting atop the SuperGLUE
leaderboard on Oct. 8, 2022, with an average score of 91.3.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding How Model Size Affects Few-shot Instruction Prompting. (arXiv:2212.01907v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01907">
<div class="article-summary-box-inner">
<span><p>Large Language Models are affected by the phenomena of memorizing and
forgetting their training data. But how do these vary by model size? We work
towards this question by investigating how the model size affects the model's
ability to discriminate a word's meaning in a given context. We introduce a
dataset called DeltaWords, which evaluates a model's ability to follow
instructions to select a sentence which replaces the target word with its
antonym. We show a weak inverse scaling trend, where task accuracy degrades as
model size increase, under extremely few-shot prompting regimes. We show that
increasing the number of examples tend to disproportionately benefit larger
models than smaller models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-lingual Similarity of Multilingual Representations Revisited. (arXiv:2212.01924v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01924">
<div class="article-summary-box-inner">
<span><p>Related works used indexes like CKA and variants of CCA to measure the
similarity of cross-lingual representations in multilingual language models. In
this paper, we argue that assumptions of CKA/CCA align poorly with one of the
motivating goals of cross-lingual learning analysis, i.e., explaining zero-shot
cross-lingual transfer. We highlight what valuable aspects of cross-lingual
similarity these indexes fail to capture and provide a motivating case study
\textit{demonstrating the problem empirically}. Then, we introduce
\textit{Average Neuron-Wise Correlation (ANC)} as a straightforward alternative
that is exempt from the difficulties of CKA/CCA and is good specifically in a
cross-lingual context. Finally, we use ANC to construct evidence that the
previously introduced ``first align, then predict'' pattern takes place not
only in masked language models (MLMs) but also in multilingual models with
\textit{causal language modeling} objectives (CLMs). Moreover, we show that the
pattern extends to the \textit{scaled versions} of the MLMs and CLMs (up to 85x
original mBERT).\footnote{Our code is publicly available at
\url{https://github.com/TartuNLP/xsim}}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Layer-wise Analysis of a Self-supervised Speech Representation Model. (arXiv:2107.04734v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04734">
<div class="article-summary-box-inner">
<span><p>Recently proposed self-supervised learning approaches have been successful
for pre-training speech representation models. The utility of these learned
representations has been observed empirically, but not much has been studied
about the type or extent of information encoded in the pre-trained
representations themselves. Developing such insights can help understand the
capabilities and limits of these models and enable the research community to
more efficiently develop their usage for downstream applications. In this work,
we begin to fill this gap by examining one recent and successful pre-trained
model (wav2vec 2.0), via its intermediate representation vectors, using a suite
of analysis tools. We use the metrics of canonical correlation, mutual
information, and performance on simple downstream tasks with non-parametric
probes, in order to (i) query for acoustic and linguistic information content,
(ii) characterize the evolution of information across model layers, and (iii)
understand how fine-tuning the model for automatic speech recognition (ASR)
affects these observations. Our findings motivate modifying the fine-tuning
protocol for ASR, which produces improved word error rates in a low-resource
setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LOGEN: Few-shot Logical Knowledge-Conditioned Text Generation with Self-training. (arXiv:2112.01404v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.01404">
<div class="article-summary-box-inner">
<span><p>Natural language generation from structured data mainly focuses on
surface-level descriptions, suffering from uncontrollable content selection and
low fidelity. Previous works leverage logical forms to facilitate logical
knowledge-conditioned text generation. Though achieving remarkable progress,
they are data-hungry, which makes the adoption for real-world applications
challenging with limited data. To this end, this paper proposes a unified
framework for logical knowledge-conditioned text generation in the few-shot
setting. With only a few seeds logical forms (e.g., 20/100 shot), our approach
leverages self-training and samples pseudo logical forms based on content and
structure consistency. Experimental results demonstrate that our approach can
obtain better few-shot performance than baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantics-Preserved Distortion for Personal Privacy Protection in Information Management. (arXiv:2201.00965v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.00965">
<div class="article-summary-box-inner">
<span><p>Although machine learning and especially deep learning methods have played an
important role in the field of information management, privacy protection is an
important and concerning topic in current machine learning models. In
information management field, a large number of texts containing personal
information are produced by users every day. As the model training on
information from users is likely to invade personal privacy, many methods have
been proposed to block the learning and memorizing of the sensitive data in raw
texts. In this paper, we try to do this more linguistically via distorting the
text while preserving the semantics. In practice, we leverage a recently our
proposed metric, Neighboring Distribution Divergence, to evaluate the semantic
preservation during the distortion. Based on the metric, we propose two
frameworks for semantics-preserved distortion, a generative one and a
substitutive one. We conduct experiments on named entity recognition,
constituency parsing, and machine reading comprehension tasks. Results from our
experiments show the plausibility and efficiency of our distortion as a method
for personal privacy protection. Moreover, we also evaluate the attribute
attack on three privacy-related tasks in the current natural language
processing field, and the results show the simplicity and effectiveness of our
data-based improvement approach compared to the structural improvement
approach. Further, we also investigate the effects of privacy protection in
specific medical information management in this work and show that the medical
information pre-training model using our approach can effectively reduce the
memory of patients and symptoms, which fully demonstrates the practicality of
our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified Question Generation with Continual Lifelong Learning. (arXiv:2201.09696v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.09696">
<div class="article-summary-box-inner">
<span><p>Question Generation (QG), as a challenging Natural Language Processing task,
aims at generating questions based on given answers and context. Existing QG
methods mainly focus on building or training models for specific QG datasets.
These works are subject to two major limitations: (1) They are dedicated to
specific QG formats (e.g., answer-extraction or multi-choice QG), therefore, if
we want to address a new format of QG, a re-design of the QG model is required.
(2) Optimal performance is only achieved on the dataset they were just trained
on. As a result, we have to train and keep various QG models for different QG
datasets, which is resource-intensive and ungeneralizable.
</p>
<p>To solve the problems, we propose a model named Unified-QG based on lifelong
learning techniques, which can continually learn QG tasks across different
datasets and formats. Specifically, we first build a format-convert encoding to
transform different kinds of QG formats into a unified representation. Then, a
method named \emph{STRIDER} (\emph{S}imilari\emph{T}y \emph{R}egular\emph{I}zed
\emph{D}ifficult \emph{E}xample \emph{R}eplay) is built to alleviate
catastrophic forgetting in continual QG learning. Extensive experiments were
conducted on $8$ QG datasets across $4$ QG formats (answer-extraction,
answer-abstraction, multi-choice, and boolean QG) to demonstrate the
effectiveness of our approach. Experimental results demonstrate that our
Unified-QG can effectively and continually adapt to QG tasks when datasets and
formats vary. In addition, we verify the ability of a single trained Unified-QG
model in improving $8$ Question Answering (QA) systems' performance through
generating synthetic QA data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Kernelized Concept Erasure. (arXiv:2201.12191v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12191">
<div class="article-summary-box-inner">
<span><p>The representation space of neural models for textual data emerges in an
unsupervised manner during training. Understanding how those representations
encode human-interpretable concepts is a fundamental problem. One prominent
approach for the identification of concepts in neural representations is
searching for a linear subspace whose erasure prevents the prediction of the
concept from the representations. However, while many linear erasure algorithms
are tractable and interpretable, neural networks do not necessarily represent
concepts in a linear manner. To identify non-linearly encoded concepts, we
propose a kernelization of a linear minimax game for concept erasure. We
demonstrate that it is possible to prevent specific non-linear adversaries from
predicting the concept. However, the protection does not transfer to different
nonlinear adversaries. Therefore, exhaustively erasing a non-linearly encoded
concept remains an open problem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CL-XABSA: Contrastive Learning for Cross-lingual Aspect-based Sentiment Analysis. (arXiv:2204.00791v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.00791">
<div class="article-summary-box-inner">
<span><p>As an extensive research in the field of natural language processing (NLP),
aspect-based sentiment analysis (ABSA) is the task of predicting the sentiment
expressed in a text relative to the corresponding aspect. Unfortunately, most
languages lack sufficient annotation resources, thus more and more recent
researchers focus on cross-lingual aspect-based sentiment analysis (XABSA).
However, most recent researches only concentrate on cross-lingual data
alignment instead of model alignment. To this end, we propose a novel
framework, CL-XABSA: Contrastive Learning for Cross-lingual Aspect-Based
Sentiment Analysis. Based on contrastive learning, we close the distance
between samples with the same label in different semantic spaces, thus
achieving a convergence of semantic spaces of different languages.
Specifically, we design two contrastive strategies, token level contrastive
learning of token embeddings (TL-CTE) and sentiment level contrastive learning
of token embeddings (SL-CTE), to regularize the semantic space of source and
target language to be more uniform. Since our framework can receive datasets in
multiple languages during training, our framework can be adapted not only for
XABSA task but also for multilingual aspect-based sentiment analysis (MABSA).
To further improve the performance of our model, we perform knowledge
distillation technology leveraging data from unlabeled target language. In the
distillation XABSA task, we further explore the comparative effectiveness of
different data (source dataset, translated dataset, and code-switched dataset).
The results demonstrate that the proposed method has a certain improvement in
the three tasks of XABSA, distillation XABSA and MABSA. For reproducibility,
our code for this paper is available at https://github.com/GKLMIP/CL-XABSA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CTRLEval: An Unsupervised Reference-Free Metric for Evaluating Controlled Text Generation. (arXiv:2204.00862v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.00862">
<div class="article-summary-box-inner">
<span><p>Existing reference-free metrics have obvious limitations for evaluating
controlled text generation models. Unsupervised metrics can only provide a
task-agnostic evaluation result which correlates weakly with human judgments,
whereas supervised ones may overfit task-specific data with poor generalization
ability to other datasets. In this paper, we propose an unsupervised
reference-free metric called CTRLEval, which evaluates controlled text
generation from different aspects by formulating each aspect into multiple text
infilling tasks. On top of these tasks, the metric assembles the generation
probabilities from a pre-trained language model without any model training.
Experimental results show that our metric has higher correlations with human
judgments than other baselines, while obtaining better generalization of
evaluating generated texts from different models and with different qualities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PreQuEL: Quality Estimation of Machine Translation Outputs in Advance. (arXiv:2205.09178v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09178">
<div class="article-summary-box-inner">
<span><p>We present the task of PreQuEL, Pre-(Quality-Estimation) Learning. A PreQuEL
system predicts how well a given sentence will be translated, without recourse
to the actual translation, thus eschewing unnecessary resource allocation when
translation quality is bound to be low. PreQuEL can be defined relative to a
given MT system (e.g., some industry service) or generally relative to the
state-of-the-art. From a theoretical perspective, PreQuEL places the focus on
the source text, tracing properties, possibly linguistic features, that make a
sentence harder to machine translate.
</p>
<p>We develop a baseline model for the task and analyze its performance. We also
develop a data augmentation method (from parallel corpora), that improves
results substantially. We show that this augmentation method can improve the
performance of the Quality-Estimation task as well. We investigate the
properties of the input text that our model is sensitive to, by testing it on
challenge sets and different languages. We conclude that it is aware of
syntactic and semantic distinctions, and correlates and even over-emphasizes
the importance of standard NLP features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Machine Translation with Hyper-Adapters. (arXiv:2205.10835v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10835">
<div class="article-summary-box-inner">
<span><p>Multilingual machine translation suffers from negative interference across
languages. A common solution is to relax parameter sharing with
language-specific modules like adapters. However, adapters of related languages
are unable to transfer information, and their total number of parameters
becomes prohibitively expensive as the number of languages grows. In this work,
we overcome these drawbacks using hyper-adapters -- hyper-networks that
generate adapters from language and layer embeddings. While past work had poor
results when scaling hyper-networks, we propose a rescaling fix that
significantly improves convergence and enables training larger hyper-networks.
We find that hyper-adapters are more parameter efficient than regular adapters,
reaching the same performance with up to 12 times less parameters. When using
the same number of parameters and FLOPS, our approach consistently outperforms
regular adapters. Also, hyper-adapters converge faster than alternative
approaches and scale better than regular dense networks. Our analysis shows
that hyper-adapters learn to encode language relatedness, enabling positive
transfer across languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grammar Detection for Sentiment Analysis through Improved Viterbi Algorithm. (arXiv:2205.13148v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.13148">
<div class="article-summary-box-inner">
<span><p>Grammar Detection, also referred to as Parts of Speech Tagging of raw text,
is considered an underlying building block of the various Natural Language
Processing pipelines like named entity recognition, question answering, and
sentiment analysis. In short, forgiven a sentence, Parts of Speech tagging is
the task of specifying and tagging each word of a sentence with nouns, verbs,
adjectives, adverbs, and more. Sentiment Analysis may well be a procedure
accustomed to determining if a given sentence's emotional tone is neutral,
positive or negative. To assign polarity scores to the thesis or entities
within phrase, in-text analysis and analytics, machine learning and natural
language processing, approaches are incorporated. This Sentiment Analysis using
POS tagger helps us urge a summary of the broader public over a specific topic.
For this, we are using the Viterbi algorithm, Hidden Markov Model, Constraint
based Viterbi algorithm for POS tagging. By comparing the accuracies, we select
the foremost accurate result of the model for Sentiment Analysis for
determining the character of the sentence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoNT: Contrastive Neural Text Generation. (arXiv:2205.14690v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.14690">
<div class="article-summary-box-inner">
<span><p>Recently, contrastive learning attracts increasing interests in neural text
generation as a new solution to alleviate the exposure bias problem. It
introduces a sequence-level training signal which is crucial to generation
tasks that always rely on auto-regressive decoding. However, previous methods
using contrastive learning in neural text generation usually lead to inferior
performance. In this paper, we analyse the underlying reasons and propose a new
Contrastive Neural Text generation framework, CoNT. CoNT addresses bottlenecks
that prevent contrastive learning from being widely adopted in generation tasks
from three aspects -- the construction of contrastive examples, the choice of
the contrastive loss, and the strategy in decoding. We validate CoNT on five
generation tasks with ten benchmarks, including machine translation,
summarization, code comment generation, data-to-text generation and commonsense
generation. Experimental results show that CoNT clearly outperforms the
conventional training framework on all the ten benchmarks with a convincing
margin. Especially, CoNT surpasses previous the most competitive contrastive
learning method for text generation, by 1.50 BLEU on machine translation and
1.77 ROUGE-1 on summarization, respectively. It achieves new state-of-the-art
on summarization, code comment generation (without external data) and
data-to-text generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">E2S2: Encoding-Enhanced Sequence-to-Sequence Pretraining for Language Understanding and Generation. (arXiv:2205.14912v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.14912">
<div class="article-summary-box-inner">
<span><p>Sequence-to-sequence (seq2seq) learning is a popular fashion for large-scale
pretraining language models. However, the prior seq2seq pretraining models
generally focus on reconstructive objectives on the decoder side and neglect
the effect of encoder-side supervision, which we argue may lead to sub-optimal
performance. To verify our hypothesis, we first empirically study the
functionalities of the encoder and decoder in seq2seq pretrained language
models, and find that the encoder takes an important but under-exploitation
role than the decoder regarding the downstream performance and neuron
activation. Therefore, we propose an encoding-enhanced seq2seq pretraining
strategy, namely E2S2, which improves the seq2seq models via integrating more
efficient self-supervised information into the encoders. Specifically, E2S2
adopts two self-supervised objectives on the encoder side from two aspects: 1)
locally denoising the corrupted sentence (denoising objective); and 2) globally
learning better sentence representations (contrastive objective). With the help
of both objectives, the encoder can effectively distinguish the noise tokens
and capture high-level (i.e. syntactic and semantic) knowledge, thus
strengthening the ability of seq2seq model to accurately achieve the
conditional generation. On a large diversity of downstream natural language
understanding and generation tasks, E2S2 dominantly improves the performance of
its powerful backbone models, e.g. BART and T5. For example, upon BART
backbone, we achieve +1.1% averaged gain on the general language understanding
evaluation (GLUE) benchmark and +1.75% F_0.5 score improvement on CoNLL2014
dataset. We also provide in-depth analyses to show the improvement stems from
better linguistic representation. We hope that our work will foster future
self-supervision research on seq2seq language model pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Variable-rate hierarchical CPC leads to acoustic unit discovery in speech. (arXiv:2206.02211v3 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02211">
<div class="article-summary-box-inner">
<span><p>The success of deep learning comes from its ability to capture the
hierarchical structure of data by learning high-level representations defined
in terms of low-level ones. In this paper we explore self-supervised learning
of hierarchical representations of speech by applying multiple levels of
Contrastive Predictive Coding (CPC). We observe that simply stacking two CPC
models does not yield significant improvements over single-level architectures.
Inspired by the fact that speech is often described as a sequence of discrete
units unevenly distributed in time, we propose a model in which the output of a
low-level CPC module is non-uniformly downsampled to directly minimize the loss
of a high-level CPC module. The latter is designed to also enforce a prior of
separability and discreteness in its representations by enforcing dissimilarity
of successive high-level representations through focused negative sampling, and
by quantization of the prediction targets. Accounting for the structure of the
speech signal improves upon single-level CPC features and enhances the
disentanglement of the learned representations, as measured by downstream
speech recognition tasks, while resulting in a meaningful segmentation of the
signal that closely resembles phone boundaries.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FRAME: Evaluating Rationale-Label Consistency Metrics for Free-Text Rationales. (arXiv:2207.00779v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.00779">
<div class="article-summary-box-inner">
<span><p>Following how humans communicate, free-text rationales aim to use natural
language to explain neural language model (LM) behavior. However, free-text
rationales' unconstrained nature makes them prone to hallucination, so it is
important to have metrics for free-text rationale quality. Existing free-text
rationale metrics measure how consistent the rationale is with the LM's
predicted label, but there is no protocol for assessing such metrics'
reliability. Thus, we propose FRAME, a framework for evaluating rationale-label
consistency (RLC) metrics for free-text rationales. FRAME is based on three
axioms: (1) good metrics should yield highest scores for reference rationales,
which maximize RLC by construction; (2) good metrics should be appropriately
sensitive to semantic perturbation of rationales; and (3) good metrics should
be robust to variation in the LM's task performance. Across three text
classification datasets, we show that existing RLC metrics cannot satisfy all
three FRAME axioms, since they are implemented via model pretraining which
muddles the metric's signal. Then, we introduce a non-pretraining RLC metric
that greatly outperforms baselines on (1) and (3), while performing
competitively on (2). Finally, we discuss the limitations of using RLC to
evaluate free-text rationales.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Context Pattern Generation for Entity Set Expansion. (arXiv:2207.08087v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.08087">
<div class="article-summary-box-inner">
<span><p>Entity Set Expansion (ESE) is a valuable task that aims to find entities of
the target semantic class described by given seed entities. Various Natural
Language Processing (NLP) and Information Retrieval (IR) downstream
applications have benefited from ESE due to its ability to discover knowledge.
Although existing corpus-based ESE methods have achieved great progress, they
still rely on corpora with high-quality entity information annotated, because
most of them need to obtain the context patterns through the position of the
entity in a sentence. Therefore, the quality of the given corpora and their
entity annotation has become the bottleneck that limits the performance of such
methods. To overcome this dilemma and make the ESE models free from the
dependence on entity annotation, our work aims to explore a new ESE paradigm,
namely corpus-independent ESE. Specifically, we devise a context pattern
generation module that utilizes autoregressive language models (e.g., GPT-2) to
automatically generate high-quality context patterns for entities. In addition,
we propose the GAPA, a novel ESE framework that leverages the aforementioned
GenerAted PAtterns to expand target entities. Extensive experiments and
detailed analyses on three widely used datasets demonstrate the effectiveness
of our method. All the codes of our experiments are available at
https://github.com/geekjuruo/GAPA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Best Prompts for Text-to-Image Models and How to Find Them. (arXiv:2209.11711v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.11711">
<div class="article-summary-box-inner">
<span><p>Recent progress in generative models, especially in text-guided diffusion
models, has enabled the production of aesthetically-pleasing imagery resembling
the works of professional human artists. However, one has to carefully compose
the textual description, called the prompt, and augment it with a set of
clarifying keywords. Since aesthetics are challenging to evaluate
computationally, human feedback is needed to determine the optimal prompt
formulation and keyword combination. In this paper, we present a
human-in-the-loop approach to learning the most useful combination of prompt
keywords using a genetic algorithm. We also show how such an approach can
improve the aesthetic appeal of images depicting the same descriptions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unveiling the Black Box of PLMs with Semantic Anchors: Towards Interpretable Neural Semantic Parsing. (arXiv:2210.01425v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.01425">
<div class="article-summary-box-inner">
<span><p>The recent prevalence of pretrained language models (PLMs) has dramatically
shifted the paradigm of semantic parsing, where the mapping from natural
language utterances to structured logical forms is now formulated as a Seq2Seq
task. Despite the promising performance, previous PLM-based approaches often
suffer from hallucination problems due to their negligence of the structural
information contained in the sentence, which essentially constitutes the key
semantics of the logical forms. Furthermore, most works treat PLM as a black
box in which the generation process of the target logical form is hidden
beneath the decoder modules, which greatly hinders the model's intrinsic
interpretability. To address these two issues, we propose to incorporate the
current PLMs with a hierarchical decoder network. By taking the first-principle
structures as the semantic anchors, we propose two novel intermediate
supervision tasks, namely Semantic Anchor Extraction and Semantic Anchor
Alignment, for training the hierarchical decoders and probing the model
intermediate representations in a self-adaptive manner alongside the
fine-tuning process. We conduct intensive experiments on several semantic
parsing benchmarks and demonstrate that our approach can consistently
outperform the baselines. More importantly, by analyzing the intermediate
representations of the hierarchical decoders, our approach also makes a huge
step toward the intrinsic interpretability of PLMs in the domain of semantic
parsing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Sentiment Analysis By Emotion Lexicon Approach on Vietnamese Texts. (arXiv:2210.02063v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.02063">
<div class="article-summary-box-inner">
<span><p>The sentiment analysis task has various applications in practice. In the
sentiment analysis task, words and phrases that represent positive and negative
emotions are important. Finding out the words that represent the emotion from
the text can improve the performance of the classification models for the
sentiment analysis task. In this paper, we propose a methodology that combines
the emotion lexicon with the classification model to enhance the accuracy of
the models. Our experimental results show that the emotion lexicon combined
with the classification model improves the performance of models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners. (arXiv:2210.02969v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.02969">
<div class="article-summary-box-inner">
<span><p>Meta-training, which fine-tunes the language model (LM) on various downstream
tasks by maximizing the likelihood of the target label given the task
instruction and input instance, has improved the zero-shot task generalization
performance. However, meta-trained LMs still struggle to generalize to
challenging tasks containing novel labels unseen during meta-training. In this
paper, we propose Flipped Learning, an alternative method of meta-training
which trains the LM to generate the task instruction given the input instance
and label. During inference, the LM trained with Flipped Learning, referred to
as Flipped, selects the label option that is most likely to generate the task
instruction. On 14 tasks of the BIG-bench benchmark, the 11B-sized Flipped
outperforms zero-shot T0-11B and even a 16 times larger 3-shot GPT-3 (175B) on
average by 8.4% and 9.7% points, respectively. Flipped gives particularly large
improvements on tasks with unseen labels, outperforming T0-11B by up to +20%
average F1 score. This indicates that the strong task generalization of Flipped
comes from improved generalization to novel labels. We release our code at
https://github.com/seonghyeonye/Flipped-Learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RARR: Researching and Revising What Language Models Say, Using Language Models. (arXiv:2210.08726v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08726">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) now excel at many tasks such as few-shot learning,
question answering, reasoning, and dialog. However, they sometimes generate
unsupported or misleading content. A user cannot easily determine whether their
outputs are trustworthy or not, because most LMs do not have any built-in
mechanism for attribution to external evidence. To enable attribution while
still preserving all the powerful advantages of recent generation models, we
propose RARR (Retrofit Attribution using Research and Revision), a system that
1) automatically finds attribution for the output of any text generation model
and 2) post-edits the output to fix unsupported content while preserving the
original output as much as possible. When applied to the output of several
state-of-the-art LMs on a diverse set of generation tasks, we find that RARR
significantly improves attribution while otherwise preserving the original
input to a much greater degree than previously explored edit models.
Furthermore, the implementation of RARR requires only a handful of training
examples, a large language model, and standard web search.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topical Segmentation of Spoken Narratives: A Test Case on Holocaust Survivor Testimonies. (arXiv:2210.13783v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.13783">
<div class="article-summary-box-inner">
<span><p>The task of topical segmentation is well studied, but previous work has
mostly addressed it in the context of structured, well-defined segments, such
as segmentation into paragraphs, chapters, or segmenting text that originated
from multiple sources. We tackle the task of segmenting running (spoken)
narratives, which poses hitherto unaddressed challenges. As a test case, we
address Holocaust survivor testimonies, given in English. Other than the
importance of studying these testimonies for Holocaust research, we argue that
they provide an interesting test case for topical segmentation, due to their
unstructured surface level, relative abundance (tens of thousands of such
testimonies were collected), and the relatively confined domain that they
cover. We hypothesize that boundary points between segments correspond to low
mutual information between the sentences proceeding and following the boundary.
Based on this hypothesis, we explore a range of algorithmic approaches to the
task, building on previous work on segmentation that uses generative Bayesian
modeling and state-of-the-art neural machinery. Compared to manually annotated
references, we find that the developed approaches show considerable
improvements over previous work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning New Tasks from a Few Examples with Soft-Label Prototypes. (arXiv:2210.17437v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.17437">
<div class="article-summary-box-inner">
<span><p>It has been experimentally demonstrated that humans are able to learn in a
manner that allows them to make predictions on categories for which they have
not seen any examples (Malaviya et al., 2022). Sucholutsky and Schonlau (2020)
have recently presented a machine learning approach that aims to do the same.
They utilise synthetically generated data and demonstrate that it is possible
to achieve sub-linear scaling and develop models that can learn to recognise N
classes from M training samples where M is less than N - aka less-than-one shot
learning. Their method was, however, defined for univariate or simple
multivariate data (Sucholutsky et al., 2021). We extend it to work on large,
high-dimensional and real-world datasets and empirically validate it in this
new and challenging setting. We apply this method to learn previously unseen
NLP tasks from very few examples (4, 8 or 16). We first generate compact,
sophisticated less-than-one shot representations called soft-label prototypes
which are fitted on training data, capturing the distribution of different
classes across the input domain space. We then use a modified k-Nearest
Neighbours classifier to demonstrate that soft-label prototypes can classify
data competitively, even outperforming much more computationally complex
few-shot learning methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Why is Winoground Hard? Investigating Failures in Visuolinguistic Compositionality. (arXiv:2211.00768v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00768">
<div class="article-summary-box-inner">
<span><p>Recent visuolinguistic pre-trained models show promising progress on various
end tasks such as image retrieval and video captioning. Yet, they fail
miserably on the recently proposed Winoground dataset, which challenges models
to match paired images and English captions, with items constructed to overlap
lexically but differ in meaning (e.g., "there is a mug in some grass" vs.
"there is some grass in a mug"). By annotating the dataset using new
fine-grained tags, we show that solving the Winoground task requires not just
compositional language understanding, but a host of other abilities like
commonsense reasoning or locating small, out-of-focus objects in low-resolution
images. In this paper, we identify the dataset's main challenges through a
suite of experiments on related tasks (probing task, image retrieval task),
data augmentation, and manual inspection of the dataset. Our analysis suggests
that a main challenge in visuolinguistic models may lie in fusing visual and
textual representations, rather than in compositional language understanding.
We release our annotation and code at
https://github.com/ajd12342/why-winoground-hard .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluation of Automated Speech Recognition Systems for Conversational Speech: A Linguistic Perspective. (arXiv:2211.02812v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.02812">
<div class="article-summary-box-inner">
<span><p>Automatic speech recognition (ASR) meets more informal and free-form input
data as voice user interfaces and conversational agents such as the voice
assistants such as Alexa, Google Home, etc., gain popularity. Conversational
speech is both the most difficult and environmentally relevant sort of data for
speech recognition. In this paper, we take a linguistic perspective, and take
the French language as a case study toward disambiguation of the French
homophones. Our contribution aims to provide more insight into human speech
transcription accuracy in conditions to reproduce those of state-of-the-art ASR
systems, although in a much focused situation. We investigate a case study
involving the most common errors encountered in the automatic transcription of
French language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ERNIE-SAT: Speech and Text Joint Pretraining for Cross-Lingual Multi-Speaker Text-to-Speech. (arXiv:2211.03545v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.03545">
<div class="article-summary-box-inner">
<span><p>Speech representation learning has improved both speech understanding and
speech synthesis tasks for single language. However, its ability in
cross-lingual scenarios has not been explored. In this paper, we extend the
pretraining method for cross-lingual multi-speaker speech synthesis tasks,
including cross-lingual multi-speaker voice cloning and cross-lingual
multi-speaker speech editing. We propose a speech-text joint pretraining
framework, where we randomly mask the spectrogram and the phonemes given a
speech example and its transcription. By learning to reconstruct the masked
parts of the input in different languages, our model shows great improvements
over speaker-embedding-based multi-speaker TTS methods. Moreover, our framework
is end-to-end for both the training and the inference without any finetuning
effort. In cross-lingual multi-speaker voice cloning and cross-lingual
multi-speaker speech editing tasks, our experiments show that our model
outperforms speaker-embedding-based multi-speaker TTS methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparative layer-wise analysis of self-supervised speech models. (arXiv:2211.03929v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.03929">
<div class="article-summary-box-inner">
<span><p>Many self-supervised speech models, varying in their pre-training objective,
input modality, and pre-training data, have been proposed in the last few
years. Despite impressive empirical successes on downstream tasks, we still
have a limited understanding of the properties encoded by the models and the
differences across models. In this work, we examine the intermediate
representations for a variety of recent models. Specifically, we measure
acoustic, phonetic, and word-level properties encoded in individual layers,
using a lightweight analysis tool based on canonical correlation analysis
(CCA). We find that these properties evolve across layers differently depending
on the model, and the variations relate to the choice of pre-training
objective. We further investigate the utility of our analyses for downstream
tasks by comparing the property trends with performance on speech recognition
and spoken language understanding tasks. We discover that CCA trends provide
reliable guidance to choose layers of interest for downstream tasks and that
single-layer performance often matches or improves upon using all layers,
suggesting implications for more efficient use of pre-trained models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EVA: Exploring the Limits of Masked Visual Representation Learning at Scale. (arXiv:2211.07636v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.07636">
<div class="article-summary-box-inner">
<span><p>We launch EVA, a vision-centric foundation model to explore the limits of
visual representation at scale using only publicly accessible data. EVA is a
vanilla ViT pre-trained to reconstruct the masked out image-text aligned vision
features conditioned on visible image patches. Via this pretext task, we can
efficiently scale up EVA to one billion parameters, and sets new records on a
broad range of representative vision downstream tasks, such as image
recognition, video action recognition, object detection, instance segmentation
and semantic segmentation without heavy supervised training. Moreover, we
observe quantitative changes in scaling EVA result in qualitative changes in
transfer learning performance that are not present in other models. For
instance, EVA takes a great leap in the challenging large vocabulary instance
segmentation task: our model achieves almost the same state-of-the-art
performance on LVISv1.0 dataset with over a thousand categories and COCO
dataset with only eighty categories. Beyond a pure vision encoder, EVA can also
serve as a vision-centric, multi-modal pivot to connect images and text. We
find initializing the vision tower of a giant CLIP from EVA can greatly
stabilize the training and outperform the training from scratch counterpart
with much fewer samples and less compute, providing a new direction for scaling
up and accelerating the costly training of multi-modal foundation models. To
facilitate future research, we release all the code and models at
https://github.com/baaivision/EVA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discourse and conversation impairments in patients with dementia. (arXiv:2211.07971v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.07971">
<div class="article-summary-box-inner">
<span><p>Neurodegeneration characterizes individuals with different dementia subtypes
(e.g., individuals with Alzheimer's Disease, Primary Progressive Aphasia, and
Parkinson's Disease), leading to progressive decline in cognitive, linguistic,
and social functioning. Speech and language impairments are early symptoms in
individuals with focal forms of neurodegenerative conditions, coupled with
deficits in cognitive, social, and behavioral domains. This paper reviews the
findings on language and communication deficits and identifies the effects of
dementia on the production and perception of discourse. It discusses findings
concerning (i) language function, cognitive representation, and impairment,
(ii) communicative competence, emotions, empathy, and theory-of-mind, and (iii)
speech-in-interaction. It argues that clinical discourse analysis can provide a
comprehensive assessment of language and communication skills in individuals,
which complements the existing neurolinguistic evaluation for (differential)
diagnosis, prognosis, and treatment efficacy evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parameter-Efficient Tuning on Layer Normalization for Pre-trained Language Models. (arXiv:2211.08682v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.08682">
<div class="article-summary-box-inner">
<span><p>Conventional fine-tuning encounters increasing difficulties given the size of
current Pre-trained Language Models, which makes parameter-efficient tuning
become the focal point of frontier research. Previous methods in this field add
tunable adapters into MHA or/and FFN of Transformer blocks to enable PLMs
achieve transferability. However, as an important part of Transformer
architecture, the power of layer normalization for parameter-efficent tuning is
ignored. In this paper, we first propose LN-tuning, by tuning the gain and bias
term of Layer Normalization module with only 0.03\% parameters, which is of
high time-efficency and significantly superior to baselines which are less than
0.1\% tunable parameters. Further, we study the unified framework of combining
LN-tuning with previous ones and we find that: (1) the unified framework of
combining prefix-tuning, the adapter-based method working on MHA, and LN-tuning
achieves SOTA performance. (2) unified framework which tunes MHA and LayerNorm
simultaneously can get performance improvement but those which tune FFN and
LayerNorm simultaneous will cause performance decrease. Ablation study
validates LN-tuning is of no abundant parameters and gives a further
understanding of it.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multitask Vision-Language Prompt Tuning. (arXiv:2211.11720v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.11720">
<div class="article-summary-box-inner">
<span><p>Prompt Tuning, conditioning on task-specific learned prompt vectors, has
emerged as a data-efficient and parameter-efficient method for adapting large
pretrained vision-language models to multiple downstream tasks. However,
existing approaches usually consider learning prompt vectors for each task
independently from scratch, thereby failing to exploit the rich shareable
knowledge across different vision-language tasks. In this paper, we propose
multitask vision-language prompt tuning (MVLPT), which incorporates cross-task
knowledge into prompt tuning for vision-language models. Specifically, (i) we
demonstrate the effectiveness of learning a single transferable prompt from
multiple source tasks to initialize the prompt for each target task; (ii) we
show many target tasks can benefit each other from sharing prompt vectors and
thus can be jointly learned via multitask prompt tuning. We benchmark the
proposed MVLPT using three representative prompt tuning methods, namely text
prompt tuning, visual prompt tuning, and the unified vision-language prompt
tuning. Results in 20 vision tasks demonstrate that the proposed approach
outperforms all single-task baseline prompt tuning methods, setting the new
state-of-the-art on the few-shot ELEVATER benchmarks and cross-task
generalization benchmarks. To understand where the cross-task knowledge is most
effective, we also conduct a large-scale study on task transferability with 20
vision tasks in 400 combinations for each prompt tuning method. It shows that
the most performant MVLPT for each prompt tuning method prefers different task
combinations and many tasks can benefit each other, depending on their visual
similarity and label similarity. Code is available at
https://github.com/sIncerass/MVLPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Report on the Euphemisms Detection Shared Task. (arXiv:2211.13327v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.13327">
<div class="article-summary-box-inner">
<span><p>This paper presents The Shared Task on Euphemism Detection for the Third
Workshop on Figurative Language Processing (FigLang 2022) held in conjunction
with EMNLP 2022. Participants were invited to investigate the euphemism
detection task: given input text, identify whether it contains a euphemism. The
input data is a corpus of sentences containing potentially euphemistic terms
(PETs) collected from the GloWbE corpus (Davies and Fuchs, 2015), and are
human-annotated as containing either a euphemistic or literal usage of a PET.
In this paper, we present the results and analyze the common themes, methods
and findings of the participating teams
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Frustratingly Easy Label Projection for Cross-lingual Transfer. (arXiv:2211.15613v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.15613">
<div class="article-summary-box-inner">
<span><p>Translating training data into many languages has emerged as a practical
solution for improving cross-lingual transfer. For tasks that involve
span-level annotations, such as information extraction or question answering,
an additional label projection step is required to map annotated spans onto the
translated texts. Recently, a few efforts have utilized a simple
mark-then-translate method to jointly perform translation and projection by
inserting special markers around the labeled spans in the original sentence.
However, as far as we are aware, no empirical analysis has been conducted on
how this approach compares to traditional annotation projection based on word
alignment. In this paper, we present an extensive empirical study across 42
languages and three tasks (QA, NER, and Event Extraction) to evaluate the
effectiveness and limitations of both methods, filling an important gap in the
literature. Experimental results show that our optimized version of
mark-then-translate, which we call EasyProject, is easily applied to many
languages and works surprisingly well, outperforming the more complex word
alignment-based methods. We analyze several key factors that affect end-task
performance, and show EasyProject works well because it can accurately preserve
label span boundaries after translation. We will publicly release all our code
and data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Neural Discourse Deixis Resolution in Dialogue. (arXiv:2211.15980v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.15980">
<div class="article-summary-box-inner">
<span><p>We adapt Lee et al.'s (2018) span-based entity coreference model to the task
of end-to-end discourse deixis resolution in dialogue, specifically by
proposing extensions to their model that exploit task-specific characteristics.
The resulting model, dd-utt, achieves state-of-the-art results on the four
datasets in the CODI-CRAC 2021 shared task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Masked Contrastive Pre-Training for Efficient Video-Text Retrieval. (arXiv:2212.00986v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.00986">
<div class="article-summary-box-inner">
<span><p>We present a simple yet effective end-to-end Video-language Pre-training
(VidLP) framework, Masked Contrastive Video-language Pretraining (MAC), for
video-text retrieval tasks. Our MAC aims to reduce video representation's
spatial and temporal redundancy in the VidLP model by a mask sampling mechanism
to improve pre-training efficiency. Comparing conventional temporal sparse
sampling, we propose to randomly mask a high ratio of spatial regions and only
feed visible regions into the encoder as sparse spatial sampling. Similarly, we
adopt the mask sampling technique for text inputs for consistency. Instead of
blindly applying the mask-then-prediction paradigm from MAE, we propose a
masked-then-alignment paradigm for efficient video-text alignment. The
motivation is that video-text retrieval tasks rely on high-level alignment
rather than low-level reconstruction, and multimodal alignment with masked
modeling encourages the model to learn a robust and general multimodal
representation from incomplete and unstable inputs. Coupling these designs
enables efficient end-to-end pre-training: reduce FLOPs (60% off), accelerate
pre-training (by 3x), and improve performance. Our MAC achieves
state-of-the-art results on various video-text retrieval datasets, including
MSR-VTT, DiDeMo, and ActivityNet. Our approach is omnivorous to input
modalities. With minimal modifications, we achieve competitive results on
image-text retrieval tasks.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-12-06 23:13:15.386641786 UTC">2022-12-06 23:13:15 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>