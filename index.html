<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-12-22T01:30:00Z">12-22</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Ontologically Faithful Generation of Non-Player Character Dialogues. (arXiv:2212.10618v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10618">
<div class="article-summary-box-inner">
<span><p>We introduce a language generation task grounded in a popular video game
environment. KNUDGE (KNowledge Constrained User-NPC Dialogue GEneration)
involves generating dialogue trees conditioned on an ontology captured in
natural language passages providing quest and entity specifications. KNUDGE is
constructed from side quest dialogues drawn directly from game data of Obsidian
Entertainment's The Outer Worlds, leading to real-world complexities in
generation: (1) dialogues are branching trees as opposed to linear chains of
utterances; (2) utterances must remain faithful to the game lore--character
personas, backstories, and entity relationships; and (3) a dialogue must
accurately reveal new quest-related details to the human player. We report
results for supervised and in-context learning techniques, finding there is
significant room for future work on creating realistic game-quality dialogues.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">mFACE: Multilingual Summarization with Factual Consistency Evaluation. (arXiv:2212.10622v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10622">
<div class="article-summary-box-inner">
<span><p>Abstractive summarization has enjoyed renewed interest in recent years,
thanks to pre-trained language models and the availability of large-scale
datasets. Despite promising results, current models still suffer from
generating factually inconsistent summaries, reducing their utility for
real-world application. Several recent efforts attempt to address this by
devising models that automatically detect factual inconsistencies in machine
generated summaries. However, they focus exclusively on English, a language
with abundant resources. In this work, we leverage factual consistency
evaluation models to improve multilingual summarization. We explore two
intuitive approaches to mitigate hallucinations based on the signal provided by
a multilingual NLI model, namely data filtering and controlled generation.
Experimental results in the 45 languages from the XLSum dataset show gains over
strong baselines in both automatic and human evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KronA: Parameter Efficient Tuning with Kronecker Adapter. (arXiv:2212.10650v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10650">
<div class="article-summary-box-inner">
<span><p>Fine-tuning a Pre-trained Language Model (PLM) on a specific downstream task
has been a well-known paradigm in Natural Language Processing. However, with
the ever-growing size of PLMs, training the entire model on several downstream
tasks becomes very expensive and resource-hungry. Recently, different Parameter
Efficient Tuning (PET) techniques are proposed to improve the efficiency of
fine-tuning PLMs. One popular category of PET methods is the low-rank
adaptation methods which insert learnable truncated SVD modules into the
original model either sequentially or in parallel. However, low-rank
decomposition suffers from limited representation power. In this work, we
address this problem using the Kronecker product instead of the low-rank
representation. We introduce KronA, a Kronecker product-based adapter module
for efficient fine-tuning of Transformer-based PLMs. We apply the proposed
methods for fine-tuning T5 on the GLUE benchmark to show that incorporating the
Kronecker-based modules can outperform state-of-the-art PET methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">In-context Learning Distillation: Transferring Few-shot Learning Ability of Pre-trained Language Models. (arXiv:2212.10670v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10670">
<div class="article-summary-box-inner">
<span><p>Given the success with in-context learning of large pre-trained language
models, we introduce in-context learning distillation to transfer in-context
few-shot learning ability from large models to smaller models. We propose to
combine in-context learning objectives with language modeling objectives to
distill both the ability to read in-context examples and task knowledge to the
smaller models. We perform in-context learning distillation under two different
few-shot learning paradigms: Meta In-context Tuning (Meta-ICT) and Multitask
In-context Tuning (Multitask-ICT). Multitask-ICT performs better on multitask
few-shot learning but also requires more computation than Meta-ICT. Our method
shows consistent improvements for both Meta-ICT and Multitask-ICT on two
benchmarks: LAMA and CrossFit. Our extensive experiments and analysis reveal
that in-context learning objectives and language modeling objectives are
complementary under the Multitask-ICT paradigm. In-context learning objectives
achieve the best performance when combined with language modeling objectives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Stereotypes in Language Models: Towards Robust Measurement and Zero-Shot Debiasing. (arXiv:2212.10678v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10678">
<div class="article-summary-box-inner">
<span><p>Generated texts from large pretrained language models have been shown to
exhibit a variety of harmful, human-like biases about various demographics.
These findings prompted large efforts aiming to understand and measure such
effects, with the goal of providing benchmarks that can guide the development
of techniques mitigating these stereotypical associations. However, as recent
research has pointed out, the current benchmarks lack a robust experimental
setup, consequently hindering the inference of meaningful conclusions from
their evaluation metrics. In this paper, we extend these arguments and
demonstrate that existing techniques and benchmarks aiming to measure
stereotypes tend to be inaccurate and consist of a high degree of experimental
noise that severely limits the knowledge we can gain from benchmarking language
models based on them. Accordingly, we propose a new framework for robustly
measuring and quantifying biases exhibited by generative language models.
Finally, we use this framework to investigate GPT-3's occupational gender bias
and propose prompting techniques for mitigating these biases without the need
for fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">METEOR Guided Divergence for Video Captioning. (arXiv:2212.10690v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10690">
<div class="article-summary-box-inner">
<span><p>Automatic video captioning aims for a holistic visual scene understanding. It
requires a mechanism for capturing temporal context in video frames and the
ability to comprehend the actions and associations of objects in a given
timeframe. Such a system should additionally learn to abstract video sequences
into sensible representations as well as to generate natural written language.
While the majority of captioning models focus solely on the visual inputs,
little attention has been paid to the audiovisual modality. To tackle this
issue, we propose a novel two-fold approach. First, we implement a
reward-guided KL Divergence to train a video captioning model which is
resilient towards token permutations. Second, we utilise a Bi-Modal
Hierarchical Reinforcement Learning (BMHRL) Transformer architecture to capture
long-term temporal dependencies of the input data as a foundation for our
hierarchical captioning module. Using our BMHRL, we show the suitability of the
HRL agent in the generation of content-complete and grammatically sound
sentences by achieving $4.91$, $2.23$, and $10.80$ in BLEU3, BLEU4, and METEOR
scores, respectively on the ActivityNet Captions dataset. Finally, we make our
BMHRL framework and trained models publicly available for users and developers
at https://github.com/d-rothen/bmhrl.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generation-Augmented Query Expansion For Code Retrieval. (arXiv:2212.10692v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10692">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models have achieved promising success in code retrieval
tasks, where a natural language documentation query is given to find the most
relevant existing code snippet. However, existing models focus only on
optimizing the documentation code pairs by embedding them into latent space,
without the association of external knowledge. In this paper, we propose a
generation-augmented query expansion framework. Inspired by the human retrieval
process - sketching an answer before searching, in this work, we utilize the
powerful code generation model to benefit the code retrieval task.
Specifically, we demonstrate that rather than merely retrieving the target code
snippet according to the documentation query, it would be helpful to augment
the documentation query with its generation counterpart - generated code
snippets from the code generation model. To the best of our knowledge, this is
the first attempt that leverages the code generation model to enhance the code
retrieval task. We achieve new state-of-the-art results on the CodeSearchNet
benchmark and surpass the baselines significantly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analyzing Semantic Faithfulness of Language Models via Input Intervention on Conversational Question Answering. (arXiv:2212.10696v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10696">
<div class="article-summary-box-inner">
<span><p>Transformer-based language models have been shown to be highly effective for
several NLP tasks. In this paper, we consider three transformer models, BERT,
RoBERTa, and XLNet, in both small and large version, and investigate how
faithful their representations are with respect to the semantic content of
texts. We formalize a notion of semantic faithfulness, in which the semantic
content of a text should causally figure in a model's inferences in question
answering. We then test this notion by observing a model's behavior on
answering questions about a story after performing two novel semantic
interventions -- deletion intervention and negation intervention. While
transformer models achieve high performance on standard question answering
tasks, we show that they fail to be semantically faithful once we perform these
interventions for a significant number of cases (~50% for deletion
intervention, and ~20% drop in accuracy for negation intervention). We then
propose an intervention-based training regime that can mitigate the undesirable
effects for deletion intervention by a significant margin (from ~50% to ~6%).
We analyze the inner-workings of the models to better understand the
effectiveness of intervention-based training for deletion intervention. But we
show that this training does not attenuate other aspects of semantic
unfaithfulness such as the models' inability to deal with negation intervention
or to capture the predicate-argument structure of texts. We also test
InstructGPT, via prompting, for its ability to handle the two interventions and
to capture predicate-argument structure. While InstructGPT models do achieve
very high performance on predicate-argument structure task, they fail to
respond adequately to our deletion and negation interventions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extractive Text Summarization Using Generalized Additive Models with Interactions for Sentence Selection. (arXiv:2212.10707v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10707">
<div class="article-summary-box-inner">
<span><p>Automatic Text Summarization (ATS) is becoming relevant with the growth of
textual data; however, with the popularization of public large-scale datasets,
some recent machine learning approaches have focused on dense models and
architectures that, despite producing notable results, usually turn out in
models difficult to interpret. Given the challenge behind interpretable
learning-based text summarization and the importance it may have for evolving
the current state of the ATS field, this work studies the application of two
modern Generalized Additive Models with interactions, namely Explainable
Boosting Machine and GAMI-Net, to the extractive summarization problem based on
linguistic features and binary classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-shot Triplet Extraction by Template Infilling. (arXiv:2212.10708v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10708">
<div class="article-summary-box-inner">
<span><p>Triplet extraction aims to extract entities and their corresponding relations
in unstructured text. Most existing methods train an extraction model on
high-quality training data, and hence are incapable of extracting relations
that were not observed during training. Generalizing the model to unseen
relations typically requires fine-tuning on synthetic training data which is
often noisy and unreliable. In this paper, we argue that reducing triplet
extraction to a template filling task over a pre-trained language model can
equip the model with zero-shot learning capabilities and enable it to leverage
the implicit knowledge in the language model. Embodying these ideas, we propose
a novel framework, ZETT (ZEro-shot Triplet extraction by Template infilling),
that is based on end-to-end generative transformers. Our experiments show that
without any data augmentation or pipeline systems, ZETT can outperform previous
state-of-the-art models with 25% less parameters. We further show that ZETT is
more robust in detecting entities and can be incorporated with automatically
generated templates for relations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task Ambiguity in Humans and Language Models. (arXiv:2212.10711v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10711">
<div class="article-summary-box-inner">
<span><p>Language models have recently achieved strong performance across a wide range
of NLP benchmarks. However, unlike benchmarks, real world tasks are often
poorly specified, and agents must deduce the user's intended behavior from a
combination of context, instructions, and examples. We investigate how both
humans and models behave in the face of such task ambiguity by proposing
AmbiBench, a new benchmark of six ambiguously-specified classification tasks.
We evaluate humans and models on AmbiBench by seeing how well they identify the
intended task using 1) instructions with varying degrees of ambiguity, and 2)
different numbers of labeled examples. We find that the combination of model
scaling (to 175B parameters) and training with human feedback data enables
models to approach or exceed the accuracy of human participants across tasks,
but that either one alone is not sufficient. In addition, we show how to
dramatically improve the accuracy of language models trained without
large-scale human feedback training by finetuning on a small number of
ambiguous in-context examples, providing a promising direction for teaching
models to generalize well in the face of ambiguity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integrating Heterogeneous Domain Information into Relation Extraction: A Case Study on Drug-Drug Interaction Extraction. (arXiv:2212.10714v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10714">
<div class="article-summary-box-inner">
<span><p>The development of deep neural networks has improved representation learning
in various domains, including textual, graph structural, and relational triple
representations. This development opened the door to new relation extraction
beyond the traditional text-oriented relation extraction. However, research on
the effectiveness of considering multiple heterogeneous domain information
simultaneously is still under exploration, and if a model can take an advantage
of integrating heterogeneous information, it is expected to exhibit a
significant contribution to many problems in the world. This thesis works on
Drug-Drug Interactions (DDIs) from the literature as a case study and realizes
relation extraction utilizing heterogeneous domain information. First, a deep
neural relation extraction model is prepared and its attention mechanism is
analyzed. Next, a method to combine the drug molecular structure information
and drug description information to the input sentence information is proposed,
and the effectiveness of utilizing drug molecular structures and drug
descriptions for the relation extraction task is shown. Then, in order to
further exploit the heterogeneous information, drug-related items, such as
protein entries, medical terms and pathways are collected from multiple
existing databases and a new data set in the form of a knowledge graph (KG) is
constructed. A link prediction task on the constructed data set is conducted to
obtain embedding representations of drugs that contain the heterogeneous domain
information. Finally, a method that integrates the input sentence information
and the heterogeneous KG information is proposed. The proposed model is trained
and evaluated on a widely used data set, and as a result, it is shown that
utilizing heterogeneous domain information significantly improves the
performance of relation extraction from the literature.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MoralDial: A Framework to Train and Evaluate Moral Dialogue Systems via Constructing Moral Discussions. (arXiv:2212.10720v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10720">
<div class="article-summary-box-inner">
<span><p>Morality in dialogue systems has raised great attention in research recently.
A moral dialogue system could better connect users and enhance conversation
engagement by gaining users' trust. In this paper, we propose a framework,
MoralDial to train and evaluate moral dialogue systems. In our framework, we
first explore the communication mechanisms of morality and resolve expressed
morality into four sub-modules. The sub-modules indicate the roadmap for
building a moral dialogue system. Based on that, we design a simple yet
effective method: constructing moral discussions from Rules of Thumb (RoTs)
between simulated specific users and the dialogue system. The constructed
discussion consists of expressing, explaining, and revising the moral views in
dialogue exchanges, which makes conversational models learn morality well in a
natural manner. Furthermore, we propose a novel evaluation method in the
framework. We evaluate the multiple aspects of morality by judging the relation
between dialogue responses and RoTs in discussions, where the multifaceted
nature of morality is particularly considered. Automatic and manual experiments
demonstrate that our framework is promising to train and evaluate moral
dialogue systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tracing and Removing Data Errors in Natural Language Generation Datasets. (arXiv:2212.10722v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10722">
<div class="article-summary-box-inner">
<span><p>Recent work has identified noisy and misannotated data as a core cause of
hallucinations and unfaithful outputs in Natural Language Generation (NLG)
tasks. Consequently, identifying and removing these examples is a key open
challenge in creating reliable NLG systems. In this work, we introduce a
framework to identify and remove low-quality training instances that lead to
undesirable outputs, such as faithfulness errors in text summarization. We show
that existing approaches for error tracing, such as gradient-based influence
measures, do not perform reliably for detecting faithfulness errors in
summarization. We overcome the drawbacks of existing error tracing methods
through a new, contrast-based estimate that compares undesired generations to
human-corrected outputs. Our proposed method can achieve a mean average
precision of 0.91 across synthetic tasks with known ground truth and can
achieve a two-fold reduction in hallucinations on a real entity hallucination
evaluation on the NYT dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Contrastive Learning: A Variational Generative Model for Multilingual Retrieval. (arXiv:2212.10726v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10726">
<div class="article-summary-box-inner">
<span><p>Contrastive learning has been successfully used for retrieval of semantically
aligned sentences, but it often requires large batch sizes or careful
engineering to work well. In this paper, we instead propose a generative model
for learning multilingual text embeddings which can be used to retrieve or
score sentence pairs. Our model operates on parallel data in $N$ languages and,
through an approximation we introduce, efficiently encourages source separation
in this multilingual setting, separating semantic information that is shared
between translations from stylistic or language-specific variation. We show
careful large-scale comparisons between contrastive and generation-based
approaches for learning multilingual text embeddings, a comparison that has not
been done to the best of our knowledge despite the popularity of these
approaches. We evaluate this method on a suite of tasks including semantic
similarity, bitext mining, and cross-lingual question retrieval -- the last of
which we introduce in this paper. Overall, our Variational Multilingual
Source-Separation Transformer (VMSST) model outperforms both a strong
contrastive and generative baseline on these tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spoken Language Understanding for Conversational AI: Recent Advances and Future Direction. (arXiv:2212.10728v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10728">
<div class="article-summary-box-inner">
<span><p>When a human communicates with a machine using natural language on the web
and online, how can it understand the human's intention and semantic context of
their talk? This is an important AI task as it enables the machine to construct
a sensible answer or perform a useful action for the human. Meaning is
represented at the sentence level, identification of which is known as intent
detection, and at the word level, a labelling task called slot filling. This
dual-level joint task requires innovative thinking about natural language and
deep learning network design, and as a result, many approaches and models have
been proposed and applied.
</p>
<p>This tutorial will discuss how the joint task is set up and introduce Spoken
Language Understanding/Natural Language Understanding (SLU/NLU) with Deep
Learning techniques. We will cover the datasets, experiments and metrics used
in the field. We will describe how the machine uses the latest NLP and Deep
Learning techniques to address the joint task, including recurrent and
attention-based Transformer networks and pre-trained models (e.g. BERT). We
will then look in detail at a network that allows the two levels of the task,
intent classification and slot filling, to interact to boost performance
explicitly. We will do a code demonstration of a Python notebook for this model
and attendees will have an opportunity to watch coding demo tasks on this joint
NLU to further their understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ToL: A Tensor of List-Based Unified Computation Model. (arXiv:2212.10740v1 [cs.PL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10740">
<div class="article-summary-box-inner">
<span><p>Previous computation models either have equivalent abilities in representing
all computations but fail to provide primitive operators for programming
complex algorithms or lack generalized expression ability to represent
newly-added computations. This article presents a unified computation model
with generalized expression ability and a concise set of primitive operators
for programming high-level algorithms. We propose a unified data abstraction --
Tensor of List, and offer a unified computation model based on Tensor of List,
which we call the ToL model (in short, ToL). ToL introduces five atomic
computations that can represent any elementary computation by finite
composition, ensured with strict formal proof. Based on ToL, we design a
pure-functional language -- ToLang. ToLang provides a concise set of primitive
operators that can be used to program complex big data and AI algorithms. Our
evaluations show ToL has generalized expression ability and a built-in
performance indicator, born with a strictly defined computation metric --
elementary operation count (EOPs), consistent with FLOPs within a small error
range.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PropSegmEnt: A Large-Scale Corpus for Proposition-Level Segmentation and Entailment Recognition. (arXiv:2212.10750v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10750">
<div class="article-summary-box-inner">
<span><p>The widely studied task of Natural Language Inference (NLI) requires a system
to recognize whether one piece of text is textually entailed by another, i.e.
whether the entirety of its meaning can be inferred from the other. In current
NLI datasets and models, textual entailment relations are typically defined on
the sentence- or paragraph-level. However, even a simple sentence often
contains multiple propositions, i.e. distinct units of meaning conveyed by the
sentence. As these propositions can carry different truth values in the context
of a given premise, we argue for the need to recognize the textual entailment
relation of each proposition in a sentence individually.
</p>
<p>We propose PropSegmEnt, a corpus of over 35K propositions annotated by expert
human raters. Our dataset structure resembles the tasks of (1) segmenting
sentences within a document to the set of propositions, and (2) classifying the
entailment relation of each proposition with respect to a different yet
topically-aligned document, i.e. documents describing the same event or entity.
We establish strong baselines for the segmentation and entailment tasks.
Through case studies on summary hallucination detection and document-level NLI,
we demonstrate that our conceptual framework is potentially useful for
understanding and explaining the compositionality of NLI labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CORRPUS: Detecting Story Inconsistencies via Codex-Bootstrapped Neurosymbolic Reasoning. (arXiv:2212.10754v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10754">
<div class="article-summary-box-inner">
<span><p>Story generation and understanding -- as with all NLG/NLU tasks -- has seen a
surge in neurosymbolic work. Researchers have recognized that, while large
language models (LLMs) have tremendous utility, they can be augmented with
symbolic means to be even better and to make up for any flaws that the neural
networks might have. However, symbolic methods are extremely costly in terms of
the amount of time and expertise needed to create them. In this work, we
capitalize on state-of-the-art Code-LLMs, such as Codex, to bootstrap the use
of symbolic methods for tracking the state of stories and aiding in story
understanding. We show that our CoRRPUS system and abstracted prompting
procedures can beat current state-of-the-art structured LLM techniques on
pre-existing story understanding tasks (bAbI task 2 and Re^3) with minimal hand
engineering. We hope that this work can help highlight the importance of
symbolic representations and specialized prompting for LLMs as these models
require some guidance for performing reasoning tasks properly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">JASMINE: Arabic GPT Models for Few-Shot Learning. (arXiv:2212.10755v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10755">
<div class="article-summary-box-inner">
<span><p>Task agnostic generative pretraining (GPT) has recently proved promising for
zero- and few-shot learning, gradually diverting attention from the expensive
supervised learning paradigm. Although the community is accumulating knowledge
as to capabilities of English-language autoregressive models such as GPT-3
adopting this generative approach, scholarship about these models remains
acutely Anglocentric. Consequently, the community currently has serious gaps in
its understanding of this class of models, their potential, and their societal
impacts in diverse settings, linguistic traditions, and cultures. To alleviate
this issue for Arabic, a collection of diverse languages and language varieties
with more than $400$ million population, we introduce JASMINE, a suite of
powerful Arabic autoregressive Transformer language models ranging in size
between 300 million-13 billion parameters. We pretrain our new models with
large amounts of diverse data (400GB of text) from different Arabic varieties
and domains. We evaluate JASMINE extensively in both intrinsic and extrinsic
settings, using a comprehensive benchmark for zero- and few-shot learning
across a wide range of NLP tasks. We also carefully develop and release a novel
benchmark for both automated and human evaluation of Arabic autoregressive
models focused at investigating potential social biases, harms, and toxicity in
these models. We aim to responsibly release our models with interested
researchers, along with code for experimenting with them
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ORCA: A Challenging Benchmark for Arabic Language Understanding. (arXiv:2212.10758v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10758">
<div class="article-summary-box-inner">
<span><p>Due to their crucial role in all NLP, several benchmarks have been proposed
to evaluate pretrained language models. In spite of these efforts, no public
benchmark of diverse nature currently exists for evaluation of Arabic. This
makes it challenging to measure progress for both Arabic and multilingual
language models. This challenge is compounded by the fact that any benchmark
targeting Arabic needs to take into account the fact that Arabic is not a
single language but rather a collection of languages and varieties. In this
work, we introduce ORCA, a publicly available benchmark for Arabic language
understanding evaluation. ORCA is carefully constructed to cover diverse Arabic
varieties and a wide range of challenging Arabic understanding tasks exploiting
60 different datasets across seven NLU task clusters. To measure current
progress in Arabic NLU, we use ORCA to offer a comprehensive comparison between
18 multilingual and Arabic language models. We also provide a public
leaderboard with a unified single-number evaluation metric (ORCA score) to
facilitate future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning List-Level Domain-Invariant Representations for Ranking. (arXiv:2212.10764v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10764">
<div class="article-summary-box-inner">
<span><p>Domain adaptation aims to transfer the knowledge acquired by models trained
on (data-rich) source domains to (low-resource) target domains, for which a
popular method is invariant representation learning. While they have been
studied extensively for classification and regression problems, how they apply
to ranking problems, where the data and metrics have a list structure, is not
well understood. Theoretically, we establish a domain adaptation generalization
bound for ranking under listwise metrics such as MRR and NDCG. The bound
suggests an adaptation method via learning list-level domain-invariant feature
representations, whose benefits are empirically demonstrated by unsupervised
domain adaptation experiments on real-world ranking tasks, including passage
reranking. A key message is that for domain adaptation, the representations
should be analyzed at the same level at which the metric is computed, as we
show that learning invariant representations at the list level is most
effective for adaptation on ranking problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Does Beam Search improve Span-Level Confidence Estimation in Generative Sequence Labeling?. (arXiv:2212.10767v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10767">
<div class="article-summary-box-inner">
<span><p>Text-to-text generation models have increasingly become the go-to solution
for a wide variety of sequence labeling tasks (e.g., entity extraction and
dialog slot filling). While most research has focused on the labeling accuracy,
a key aspect -- of vital practical importance -- has slipped through the
cracks: understanding model confidence. More specifically, we lack a principled
understanding of how to reliably gauge the confidence of a model in its
predictions for each labeled span. This paper aims to provide some empirical
insights on estimating model confidence for generative sequence labeling. Most
notably, we find that simply using the decoder's output probabilities is not
the best in realizing well-calibrated confidence estimates. As verified over
six public datasets of different tasks, we show that our proposed approach --
which leverages statistics from top-$k$ predictions by a beam search --
significantly reduces calibration errors of the predictions of a generative
sequence labeling model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncontrolled Lexical Exposure Leads to Overestimation of Compositional Generalization in Pretrained Models. (arXiv:2212.10769v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10769">
<div class="article-summary-box-inner">
<span><p>Human linguistic capacity is often characterized by compositionality and the
generalization it enables -- human learners can produce and comprehend novel
complex expressions by composing known parts. Several benchmarks exploit
distributional control across training and test to gauge compositional
generalization, where certain lexical items only occur in limited contexts
during training. While recent work using these benchmarks suggests that
pretrained models achieve impressive generalization performance, we argue that
exposure to pretraining data may break the aforementioned distributional
control. Using the COGS benchmark of Kim and Linzen (2020), we test two
modified evaluation setups that control for this issue: (1) substituting
context-controlled lexical items with novel character sequences, and (2)
substituting them with special tokens represented by novel embeddings. We find
that both of these setups lead to lower generalization performance in T5
(Raffel et al., 2020), suggesting that previously reported results have been
overestimated due to uncontrolled lexical exposure during pretraining. The
performance degradation is more extreme with novel embeddings, and the
degradation increases with the amount of pretraining data, highlighting an
interesting case of inverse scaling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ImPaKT: A Dataset for Open-Schema Knowledge Base Construction. (arXiv:2212.10770v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10770">
<div class="article-summary-box-inner">
<span><p>Large language models have ushered in a golden age of semantic parsing. The
seq2seq paradigm allows for open-schema and abstractive attribute and relation
extraction given only small amounts of finetuning data. Language model
pretraining has simultaneously enabled great strides in natural language
inference, reasoning about entailment and implication in free text. These
advances motivate us to construct ImPaKT, a dataset for open-schema information
extraction, consisting of around 2500 text snippets from the C4 corpus, in the
shopping domain (product buying guides), professionally annotated with
extracted attributes, types, attribute summaries (attribute schema discovery
from idiosyncratic text), many-to-one relations between compound and atomic
attributes, and implication relations. We release this data in hope that it
will be useful in fine tuning semantic parsers for information extraction and
knowledge base construction across a variety of domains. We evaluate the power
of this approach by fine-tuning the open source UL2 language model on a subset
of the dataset, extracting a set of implication relations from a corpus of
product buying guides, and conducting human evaluations of the resulting
predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning. (arXiv:2212.10773v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10773">
<div class="article-summary-box-inner">
<span><p>Instruction tuning, a new learning paradigm that fine-tunes pre-trained
language models on tasks specified through instructions, has shown promising
zero-shot performance on various natural language processing tasks. However,
it's still not explored for vision and multimodal tasks. In this work, we
introduce MultiInstruct, the first multimodal instruction tuning benchmark
dataset that consists of 47 diverse multimodal tasks covering 11 broad
categories. Each task is designed at least with 5,000 instances (input-out
pairs) from existing open-source datasets and 5 expert-written instructions. We
take OFA as the base pre-trained model for multimodal instruction tuning, and
to improve its performance, we explore multiple transfer learning strategies to
leverage the large-scale Natural Instructions dataset. Experimental results
demonstrate its strong zero-shot performance on various unseen multimodal tasks
and the benefit of transfer learning from text-only instructions. We also
design a new evaluation metric: Sensitivity, to evaluate how sensitive the
model is to the variety of instructions. Our results indicate that the model is
less sensitive to the varying instructions after finetuning on a diverse set of
tasks and instructions for each task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can NLI Provide Proper Indirect Supervision for Low-resource Biomedical Relation Extraction?. (arXiv:2212.10784v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10784">
<div class="article-summary-box-inner">
<span><p>Two key obstacles in biomedical relation extraction (RE) are the scarcity of
annotations and the prevalence of instances without explicitly pre-defined
labels due to low annotation coverage. Existing approaches, which treat
biomedical RE as a multi-class classification task, often result in poor
generalization in low-resource settings and do not have the ability to make
selective prediction on unknown cases but give a guess from seen relations,
hindering the applicability of those approaches. We present NBR, which converts
biomedical RE as natural language inference formulation through indirect
supervision. By converting relations to natural language hypotheses, NBR is
capable of exploiting semantic cues to alleviate annotation scarcity. By
incorporating a ranking-based loss that implicitly calibrates abstinent
instances, NBR learns a clearer decision boundary and is instructed to abstain
on uncertain instances. Extensive experiments on three widely-used biomedical
RE benchmarks, namely ChemProt, DDI and GAD, verify the effectiveness of NBR in
both full-set and low-resource regimes. Our analysis demonstrates that indirect
supervision benefits biomedical RE even when a domain gap exists, and combining
NLI knowledge with biomedical knowledge leads to the best performance gains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SERENGETI: Massively Multilingual Language Models for Africa. (arXiv:2212.10785v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10785">
<div class="article-summary-box-inner">
<span><p>Multilingual language models (MLMs) acquire valuable, generalizable
linguistic information during pretraining and have advanced the state of the
art on task-specific finetuning. So far, only ~ 28 out of ~2,000 African
languages are covered in existing language models. We ameliorate this
limitation by developing SERENGETI, a set of massively multilingual language
model that covers 517 African languages and language varieties. We evaluate our
novel models on eight natural language understanding tasks across 20 datasets,
comparing to four MLMs that each cover any number of African languages.
SERENGETI outperforms other models on 11 datasets across the eights tasks and
achieves 82.27 average F-1. We also perform error analysis on our models'
performance and show the influence of mutual intelligibility when the models
are applied under zero-shot settings. We will publicly release our models for
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-hop Evidence Retrieval for Cross-document Relation Extraction. (arXiv:2212.10786v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10786">
<div class="article-summary-box-inner">
<span><p>Relation Extraction (RE) has been extended to cross-document scenarios
because many relations are not simply described in a single document. This
inevitably brings the challenge of efficient open-space evidence retrieval to
support the inference of cross-document relations, along with the challenge of
multi-hop reasoning on top of entities and evidence scattered in an open set of
documents. To combat these challenges, we propose Mr.CoD, a multi-hop evidence
retrieval method based on evidence path mining and ranking with adapted dense
retrievers. We explore multiple variants of retrievers to show evidence
retrieval is an essential part in cross-document RE. Experiments on CodRED show
that evidence retrieval with Mr.Cod effectively acquires cross-document
evidence that essentially supports open-setting cross-document RE.
Additionally, we show that Mr.CoD facilitates evidence retrieval and boosts
end-to-end RE performance with effective multi-hop reasoning in both closed and
open settings of RE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-modal Molecule Structure-text Model for Text-based Retrieval and Editing. (arXiv:2212.10789v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10789">
<div class="article-summary-box-inner">
<span><p>There is increasing adoption of artificial intelligence in drug discovery.
However, existing works use machine learning to mainly utilize the chemical
structures of molecules yet ignore the vast textual knowledge available in
chemistry. Incorporating textual knowledge enables us to realize new drug
design objectives, adapt to text-based instructions, and predict complex
biological activities. We present a multi-modal molecule structure-text model,
MoleculeSTM, by jointly learning molecule's chemical structures and textual
descriptions via a contrastive learning strategy. To train MoleculeSTM, we
construct the largest multi-modal dataset to date, namely PubChemSTM, with over
280K chemical structure-text pairs. To demonstrate the effectiveness and
utility of MoleculeSTM, we design two challenging zero-shot tasks based on text
instructions, including structure-text retrieval and molecule editing.
MoleculeSTM possesses two main properties: open vocabulary and compositionality
via natural language. In experiments, MoleculeSTM obtains the state-of-the-art
generalization ability to novel biochemical concepts across various benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OpineSum: Entailment-based self-training for abstractive opinion summarization. (arXiv:2212.10791v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10791">
<div class="article-summary-box-inner">
<span><p>A typical product or place often has hundreds of reviews, and summarization
of these texts is an important and challenging problem. Recent progress on
abstractive summarization in domains such as news has been driven by supervised
systems trained on hundreds of thousands of news articles paired with
human-written summaries. However for opinion texts, such large scale datasets
are rarely available. Unsupervised methods, self-training, and few-shot
learning approaches bridge that gap. In this work, we present a novel
self-training approach, OpineSum, for abstractive opinion summarization. The
summaries in this approach are built using a novel application of textual
entailment and capture the consensus of opinions across the various reviews for
an item. This method can be used to obtain silver-standard summaries on a large
scale and train both unsupervised and few-shot abstractive summarization
systems. OpineSum achieves state-of-the-art performance in both settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reconstruction Probing. (arXiv:2212.10792v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10792">
<div class="article-summary-box-inner">
<span><p>We propose reconstruction probing, a new analysis method for contextualized
representations based on reconstruction probabilities in masked language models
(MLMs). This method relies on comparing the reconstruction probabilities of
tokens in a given sequence when conditioned on the representation of a single
token that has been fully contextualized and when conditioned on only the
decontextualized lexical prior of the model. This comparison can be understood
as quantifying the contribution of contextualization towards reconstruction --
the difference in the reconstruction probabilities can only be attributed to
the representational change of the single token induced by contextualization.
We apply this analysis to three MLMs and find that contextualization boosts
reconstructability of tokens that are close to the token being reconstructed in
terms of linear and syntactic distance. Furthermore, we extend our analysis to
finer-grained decomposition of contextualized representations, and we find that
these boosts are largely attributable to static and positional embeddings at
the input layer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language Models. (arXiv:2212.10815v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10815">
<div class="article-summary-box-inner">
<span><p>We explore the use of large language models (LLMs) for zero-shot semantic
parsing. Semantic parsing involves mapping natural language utterances to
task-specific meaning representations. Language models are generally trained on
the publicly available text and code and cannot be expected to directly
generalize to domain-specific parsing tasks in a zero-shot setting. In this
work, we propose ZEROTOP, a zero-shot task-oriented parsing method that
decomposes a semantic parsing problem into a set of abstractive and extractive
question-answering (QA) problems, enabling us to leverage the ability of LLMs
to zero-shot answer reading comprehension questions. For each utterance, we
prompt the LLM with questions corresponding to its top-level intent and a set
of slots and use the LLM generations to construct the target meaning
representation. We observe that current LLMs fail to detect unanswerable
questions; and as a result, cannot handle questions corresponding to missing
slots. To address this problem, we fine-tune a language model on public QA
datasets using synthetic negative samples. Experimental results show that our
QA-based decomposition paired with the fine-tuned LLM can correctly parse ~16%
of utterances in the MTOP dataset without requiring any annotated data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">4D ASR: Joint modeling of CTC, Attention, Transducer, and Mask-Predict decoders. (arXiv:2212.10818v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10818">
<div class="article-summary-box-inner">
<span><p>The network architecture of end-to-end (E2E) automatic speech recognition
(ASR) can be classified into several models, including connectionist temporal
classification (CTC), recurrent neural network transducer (RNN-T), attention
mechanism, and non-autoregressive mask-predict models. Since each of these
network architectures has pros and cons, a typical use case is to switch these
separate models depending on the application requirement, resulting in the
increased overhead of maintaining all models. Several methods for integrating
two of these complementary models to mitigate the overhead issue have been
proposed; however, if we integrate more models, we will further benefit from
these complementary models and realize broader applications with a single
system. This paper proposes four-decoder joint modeling (4D) of CTC, attention,
RNN-T, and mask-predict, which has the following three advantages: 1) The four
decoders are jointly trained so that they can be easily switched depending on
the application scenarios. 2) Joint training may bring model regularization and
improve the model robustness thanks to their complementary properties. 3) Novel
one-pass joint decoding methods using CTC, attention, and RNN-T further
improves the performance. The experimental results showed that the proposed
model consistently reduced the WER.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attend to the Right Context: A Plug-and-Play Module for Content-Controllable Summarization. (arXiv:2212.10819v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10819">
<div class="article-summary-box-inner">
<span><p>Content-Controllable Summarization generates summaries focused on the given
controlling signals. Due to the lack of large-scale training corpora for the
task, we propose a plug-and-play module RelAttn to adapt any general
summarizers to the content-controllable summarization task. RelAttn first
identifies the relevant content in the source documents, and then makes the
model attend to the right context by directly steering the attention weight. We
further apply an unsupervised online adaptive parameter searching algorithm to
determine the degree of control in the zero-shot setting, while such parameters
are learned in the few-shot setting. By applying the module to three backbone
summarization models, experiments show that our method effectively improves all
the summarizers, and outperforms the prefix-based method and a widely used
plug-and-play model in both zero- and few-shot settings. Tellingly, more
benefit is observed in the scenarios when more control is needed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continual Contrastive Finetuning Improves Low-Resource Relation Extraction. (arXiv:2212.10823v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10823">
<div class="article-summary-box-inner">
<span><p>Relation extraction (RE), which has relied on structurally annotated corpora
for model training, has been particularly challenging in low-resource scenarios
and domains. Recent literature has tackled low-resource RE by self-supervised
learning, where the solution involves pretraining the relation embedding by
RE-based objective and finetuning on labeled data by classification-based
objective. However, a critical challenge to this approach is the gap in
objectives, which prevents the RE model from fully utilizing the knowledge in
pretrained representations. In this paper, we aim at bridging the gap and
propose to pretrain and finetune the RE model using consistent objectives of
contrastive learning. Since in this kind of representation learning paradigm,
one relation may easily form multiple clusters in the representation space, we
further propose a multi-center contrastive loss that allows one relation to
form multiple clusters to better align with pretraining. Experiments on two
document-level RE datasets, BioRED and Re-DocRED, demonstrate the effectiveness
of our method. Particularly, when using 1% end-task training data, our method
outperforms PLM-based RE classifier by 10.5% and 5.8% on the two datasets,
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Automatic Speech Recognition model for the Sudanese Dialect. (arXiv:2212.10826v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10826">
<div class="article-summary-box-inner">
<span><p>Designing a natural voice interface rely mostly on Speech recognition for
interaction between human and their modern digital life equipment. In addition,
speech recognition narrows the gap between monolingual individuals to better
exchange communication. However, the field lacks wide support for several
universal languages and their dialects, while most of the daily conversations
are carried out using them. This paper comes to inspect the viability of
designing an Automatic Speech Recognition model for the Sudanese dialect, which
is one of the Arabic Language dialects, and its complexity is a product of
historical and social conditions unique to its speakers. This condition is
reflected in both the form and content of the dialect, so this paper gives an
overview of the Sudanese dialect and the tasks of collecting represented
resources and pre-processing performed to construct a modest dataset to
overcome the lack of annotated data. Also proposed end- to-end speech
recognition model, the design of the model was formed using Convolution Neural
Networks. The Sudanese dialect dataset would be a stepping stone to enable
future Natural Language Processing research targeting the dialect. The designed
model provided some insights into the current recognition task and reached an
average Label Error Rate of 73.67%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Multiple-Length Summaries via Reinforcement Learning for Unsupervised Sentence Summarization. (arXiv:2212.10843v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10843">
<div class="article-summary-box-inner">
<span><p>Sentence summarization shortens given texts while maintaining core contents
of the texts. Unsupervised approaches have been studied to summarize texts
without human-written summaries. However, recent unsupervised models are
extractive, which remove words from texts and thus they are less flexible than
abstractive summarization. In this work, we devise an abstractive model based
on reinforcement learning without ground-truth summaries. We formulate the
unsupervised summarization based on the Markov decision process with rewards
representing the summary quality. To further enhance the summary quality, we
develop a multi-summary learning mechanism that generates multiple summaries
with varying lengths for a given text, while making the summaries mutually
enhance each other. Experimental results show that the proposed model
substantially outperforms both abstractive and extractive models, yet
frequently generating new words not contained in input texts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompt-Augmented Linear Probing: Scaling Beyond The Limit of Few-shot In-Context Learners. (arXiv:2212.10873v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10873">
<div class="article-summary-box-inner">
<span><p>Through in-context learning (ICL), large-scale language models are effective
few-shot learners without additional model fine-tuning. However, the ICL
performance does not scale well with the number of available training samples
as it is limited by the inherent input length constraint of the underlying
language model. Meanwhile, many studies have revealed that language models are
also powerful feature extractors, allowing them to be utilized in a black-box
manner and enabling the linear probing paradigm, where lightweight
discriminators are trained on top of the pre-extracted input representations.
This paper proposes prompt-augmented linear probing (PALP), a hybrid of linear
probing and ICL, which leverages the best of both worlds. PALP inherits the
scalability of linear probing and the capability of enforcing language models
to derive more meaningful representations via tailoring input into a more
conceivable form. Throughout in-depth investigations on various datasets, we
verified that PALP significantly enhances the input representations closing the
gap between ICL in the data-hungry scenario and fine-tuning in the
data-abundant scenario with little training overhead, potentially making PALP a
strong alternative in a black-box scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Linguistic Syntactic Difference in Multilingual BERT: How Good is It and How Does It Affect Transfer?. (arXiv:2212.10879v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10879">
<div class="article-summary-box-inner">
<span><p>Multilingual BERT (mBERT) has demonstrated considerable cross-lingual
syntactic ability, whereby it enables effective zero-shot cross-lingual
transfer of syntactic knowledge. The transfer is more successful between some
languages, but it is not well understood what leads to this variation and
whether it fairly reflects difference between languages. In this work, we
investigate the distributions of grammatical relations induced from mBERT in
the context of 24 typologically different languages. We demonstrate that the
distance between the distributions of different languages is highly consistent
with the syntactic difference in terms of linguistic formalisms. Such
difference learnt via self-supervision plays a crucial role in the zero-shot
transfer performance and can be predicted by variation in morphosyntactic
properties between languages. These results suggest that mBERT properly encodes
languages in a way consistent with linguistic diversity and provide insights
into the mechanism of cross-lingual transfer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Mix-based Data Augmentation: Taxonomy, Methods, Applications, and Explainability. (arXiv:2212.10888v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10888">
<div class="article-summary-box-inner">
<span><p>Data augmentation (DA) is indispensable in modern machine learning and deep
neural networks. The basic idea of DA is to construct new training data to
improve the model's generalization by adding slightly disturbed versions of
existing data or synthesizing new data. In this work, we review a small but
essential subset of DA -- Mix-based Data Augmentation (MixDA) that generates
novel samples by mixing multiple examples. Unlike conventional DA approaches
based on a single-sample operation or requiring domain knowledge, MixDA is more
general in creating a broad spectrum of new data and has received increasing
attention in the community. We begin with proposing a new taxonomy classifying
MixDA into, Mixup-based, Cutmix-based, and hybrid approaches according to a
hierarchical view of the data mix. Various MixDA techniques are then
comprehensively reviewed in a more fine-grained way. Owing to its
generalization, MixDA has penetrated a variety of applications which are also
completely reviewed in this work. We also examine why MixDA works from
different aspects of improving model performance, generalization, and
calibration while explaining the model behavior based on the properties of
MixDA. Finally, we recapitulate the critical findings and fundamental
challenges of current MixDA studies, and outline the potential directions for
future works. Different from previous related works that summarize the DA
approaches in a specific domain (e.g., images or natural language processing)
or only review a part of MixDA studies, we are the first to provide a
systematical survey of MixDA in terms of its taxonomy, methodology,
applications, and explainability. This work can serve as a roadmap to MixDA
techniques and application reviews while providing promising directions for
researchers interested in this exciting area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training language models for deeper understanding improves brain alignment. (arXiv:2212.10898v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10898">
<div class="article-summary-box-inner">
<span><p>Building systems that achieve a deeper understanding of language is one of
the central goals of natural language processing (NLP). Towards this goal,
recent works have begun to train language models on narrative datasets which
require extracting the most critical information by integrating across long
contexts. However, it is still an open question whether these models are
learning a deeper understanding of the text, or if the models are simply
learning a heuristic to complete the task. This work investigates this further
by turning to the one language processing system that truly understands complex
language: the human brain. We show that training language models for deeper
narrative understanding results in richer representations that have improved
alignment to human brain activity. We further find that the improvements in
brain alignment are larger for character names than for other discourse
features, which indicates that these models are learning important narrative
elements. Taken together, these results suggest that this type of training can
indeed lead to deeper language understanding. These findings have consequences
both for cognitive neuroscience by revealing some of the significant factors
behind brain-NLP alignment, and for NLP by highlighting that understanding of
long-range context can be improved beyond language modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RECAP: Retrieval Augmented Music Captioner. (arXiv:2212.10901v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10901">
<div class="article-summary-box-inner">
<span><p>With the prevalence of stream media platforms serving music search and
recommendation, interpreting music by understanding audio and lyrics
interactively has become an important and challenging task. However, many
previous works focus on refining individual components of encoder-decoder
architecture mapping music to caption tokens, ignoring the potential usage of
audio and lyrics correspondence. In this paper, we propose to explicitly learn
the multi-modal alignment with retrieval augmentation by contrastive learning.
By learning audio-lyrics correspondence, the model is guided to learn better
cross-modal attention weights, thus generating high-quality caption words. We
provide both theoretical and empirical results that demonstrate the advantage
of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models as Inductive Reasoners. (arXiv:2212.10923v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10923">
<div class="article-summary-box-inner">
<span><p>Inductive reasoning is a core component of human intelligence. In the past
research of inductive reasoning within computer science, logic language is used
as representations of knowledge (facts and rules, more specifically). However,
logic language can cause systematic problems for inductive reasoning such as
disability of handling raw input such as natural language, sensitiveness to
mislabeled data, and incapacity to handle ambiguous input. To this end, we
propose a new task, which is to induce natural language rules from natural
language facts, and create a dataset termed DEER containing 1.2k rule-fact
pairs for the task, where rules and facts are written in natural language. New
automatic metrics are also proposed and analysed for the evaluation of this
task. With DEER, we investigate a modern approach for inductive reasoning where
we use natural language as representation for knowledge instead of logic
language and use pretrained language models as ''reasoners''. Moreover, we
provide the first and comprehensive analysis of how well pretrained language
models can induce natural language rules from natural language facts. We also
propose a new framework drawing insights from philosophy literature for this
task, which we show in the experiment section that surpasses baselines in both
automatic and human evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SPT: Semi-Parametric Prompt Tuning for Multitask Prompted Learning. (arXiv:2212.10929v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10929">
<div class="article-summary-box-inner">
<span><p>Pre-trained large language models can efficiently interpolate human-written
prompts in a natural way. Multitask prompted learning can help generalization
through a diverse set of tasks at once, thus enhancing the potential for more
effective downstream fine-tuning. To perform efficient multitask-inference in
the same batch, parameter-efficient fine-tuning methods such as prompt tuning
have been proposed. However, the existing prompt tuning methods may lack
generalization. We propose SPT, a semi-parametric prompt tuning method for
multitask prompted learning. The novel component of SPT is a memory bank from
where memory prompts are retrieved based on discrete prompts. Extensive
experiments, such as (i) fine-tuning a full language model with SPT on 31
different tasks from 8 different domains and evaluating zero-shot
generalization on 9 heldout datasets under 5 NLP task categories and (ii)
pretraining SPT on the GLUE datasets and evaluating fine-tuning on the
SuperGLUE datasets, demonstrate effectiveness of SPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Resolving Indirect Referring Expressions for Entity Selection. (arXiv:2212.10933v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10933">
<div class="article-summary-box-inner">
<span><p>Recent advances in language modeling have enabled new conversational systems.
In particular, it is often desirable for people to make choices among specified
options when using such systems. We address the problem of reference
resolution, when people use natural expressions to choose between real world
entities. For example, given the choice `Should we make a Simnel cake or a
Pandan cake?' a natural response from a non-expert may be indirect: `let's make
the green one'. Reference resolution has been little studied with natural
expressions, thus robustly understanding such language has large potential for
improving naturalness in dialog, recommendation, and search systems. We create
AltEntities (Alternative Entities), a new public dataset of entity pairs and
utterances, and develop models for the disambiguation problem. Consisting of
42K indirect referring expressions across three domains, it enables for the
first time the study of how large language models can be adapted to this task.
We find they achieve 82%-87% accuracy in realistic settings, which while
reasonable also invites further advances.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Esports Data-to-commentary Generation on Large-scale Data-to-text Dataset. (arXiv:2212.10935v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10935">
<div class="article-summary-box-inner">
<span><p>Esports, a sports competition using video games, has become one of the most
important sporting events in recent years. Although the amount of esports data
is increasing than ever, only a small fraction of those data accompanies text
commentaries for the audience to retrieve and understand the plays. Therefore,
in this study, we introduce a task of generating game commentaries from
structured data records to address the problem. We first build a large-scale
esports data-to-text dataset using structured data and commentaries from a
popular esports game, League of Legends. On this dataset, we devise several
data preprocessing methods including linearization and data splitting to
augment its quality. We then introduce several baseline encoder-decoder models
and propose a hierarchical model to generate game commentaries. Considering the
characteristics of esports commentaries, we design evaluation metrics including
three aspects of the output: correctness, fluency, and strategic depth.
Experimental results on our large-scale esports dataset confirmed the advantage
of the hierarchical model, and the results revealed several challenges of this
novel task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Critic-Guided Decoding for Controlled Text Generation. (arXiv:2212.10938v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10938">
<div class="article-summary-box-inner">
<span><p>Steering language generation towards objectives or away from undesired
content has been a long-standing goal in utilizing language models (LM). Recent
work has demonstrated reinforcement learning and weighted decoding as effective
approaches to achieve a higher level of language control and quality with pros
and cons. In this work, we propose a novel critic decoding method for
controlled language generation (CriticControl) that combines the strengths of
reinforcement learning and weighted decoding. Specifically, we adopt the
actor-critic framework to train an LM-steering critic from non-differentiable
reward models. And similar to weighted decoding, our method freezes the
language model and manipulates the output token distribution using called
critic, improving training efficiency and stability. Evaluation of our method
on three controlled generation tasks, namely topic control, sentiment control,
and detoxification, shows that our approach generates more coherent and
well-controlled texts than previous methods. In addition, CriticControl
demonstrates superior generalization ability in zero-shot settings. Human
evaluation studies also corroborate our findings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parallel Context Windows Improve In-Context Learning of Large Language Models. (arXiv:2212.10947v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10947">
<div class="article-summary-box-inner">
<span><p>For applications that require processing large amounts of text at inference
time, Large Language Models (LLMs) are handicapped by their limited context
windows, which are typically 2048 tokens. In-context learning, an emergent
phenomenon in LLMs in sizes above a certain parameter threshold, constitutes
one significant example because it can only leverage training examples that fit
into the context window. Existing efforts to address the context window
limitation involve training specialized architectures, which tend to be smaller
than the sizes in which in-context learning manifests due to the memory
footprint of processing long texts. We present Parallel Context Windows (PCW),
a method that alleviates the context window restriction for any off-the-shelf
LLM without further training. The key to the approach is to carve a long
context into chunks (``windows'') that fit within the architecture, restrict
the attention mechanism to apply only within each window, and re-use the
positional embeddings among the windows. We test the PCW approach on in-context
learning with models that range in size between 750 million and 178 billion
parameters, and show substantial improvements for tasks with diverse input and
output spaces. Our results motivate further investigation of Parallel Context
Windows as a method for applying off-the-shelf LLMs in other settings that
require long text sequences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Computer says "No": The Case Against Empathetic Conversational AI. (arXiv:2212.10983v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10983">
<div class="article-summary-box-inner">
<span><p>Emotions are an integral part of human cognition and they guide not only our
understanding of the world but also our actions within it. As such, whether we
soothe or flame an emotion is not inconsequential. Recent work in
conversational AI has focused on responding empathetically to users, validating
and soothing their emotions without a real basis. This AI-aided emotional
regulation can have negative consequences for users and society, tending
towards a one-noted happiness defined as only the absence of "negative"
emotions. We argue that we must carefully consider whether and how to respond
to users' emotions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MAViC: Multimodal Active Learning for Video Captioning. (arXiv:2212.11109v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.11109">
<div class="article-summary-box-inner">
<span><p>A large number of annotated video-caption pairs are required for training
video captioning models, resulting in high annotation costs. Active learning
can be instrumental in reducing these annotation requirements. However, active
learning for video captioning is challenging because multiple semantically
similar captions are valid for a video, resulting in high entropy outputs even
for less-informative samples. Moreover, video captioning algorithms are
multimodal in nature with a visual encoder and language decoder. Further, the
sequential and combinatorial nature of the output makes the problem even more
challenging. In this paper, we introduce MAViC which leverages our proposed
Multimodal Semantics Aware Sequential Entropy (M-SASE) based acquisition
function to address the challenges of active learning approaches for video
captioning. Our approach integrates semantic similarity and uncertainty of both
visual and language dimensions in the acquisition function. Our detailed
experiments empirically demonstrate the efficacy of M-SASE for active learning
for video captioning and improve on the baselines by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A survey on text generation using generative adversarial networks. (arXiv:2212.11119v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.11119">
<div class="article-summary-box-inner">
<span><p>This work presents a thorough review concerning recent studies and text
generation advancements using Generative Adversarial Networks. The usage of
adversarial learning for text generation is promising as it provides
alternatives to generate the so-called "natural" language. Nevertheless,
adversarial text generation is not a simple task as its foremost architecture,
the Generative Adversarial Networks, were designed to cope with continuous
information (image) instead of discrete data (text). Thus, most works are based
on three possible options, i.e., Gumbel-Softmax differentiation, Reinforcement
Learning, and modified training objectives. All alternatives are reviewed in
this survey as they present the most recent approaches for generating text
using adversarial-based techniques. The selected works were taken from renowned
databases, such as Science Direct, IEEEXplore, Springer, Association for
Computing Machinery, and arXiv, whereas each selected work has been critically
analyzed and assessed to present its objective, methodology, and experimental
results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Religion and Spirituality on Social Media in the Aftermath of the Global Pandemic. (arXiv:2212.11121v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.11121">
<div class="article-summary-box-inner">
<span><p>During the COVID-19 pandemic, the Church closed its physical doors for the
first time in about 800 years, which is, arguably, a cataclysmic event. Other
religions have found themselves in a similar situation, and they were
practically forced to move online, which is an unprecedented occasion. In this
paper, we analyse this sudden change in religious activities twofold: we create
and deliver a questionnaire, as well as analyse Twitter data, to understand
people's perceptions and activities related to religious activities online.
Importantly, we also analyse the temporal variations in this process by
analysing a period of 3 months: July-September 2020. Additionally to the
separate analysis of the two data sources, we also discuss the implications
from triangulating the results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chatbots in a Botnet World. (arXiv:2212.11126v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.11126">
<div class="article-summary-box-inner">
<span><p>Question-and-answer formats provide a novel experimental platform for
investigating cybersecurity questions. Unlike previous chatbots, the latest
ChatGPT model from OpenAI supports an advanced understanding of complex coding
questions. The research demonstrates thirteen coding tasks that generally
qualify as stages in the MITRE ATT&amp;CK framework, ranging from credential access
to defense evasion. With varying success, the experimental prompts generate
examples of keyloggers, logic bombs, obfuscated worms, and payment-fulfilled
ransomware. The empirical results illustrate cases that support the broad gain
of functionality, including self-replication and self-modification, evasion,
and strategic understanding of complex cybersecurity goals. One surprising
feature of ChatGPT as a language-only model centers on its ability to spawn
coding approaches that yield images that obfuscate or embed executable
programming steps or links.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Universal versus system-specific features of punctuation usage patterns in~major Western~languages. (arXiv:2212.11182v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.11182">
<div class="article-summary-box-inner">
<span><p>The celebrated proverb that "speech is silver, silence is golden" has a long
multinational history and multiple specific meanings. In written texts
punctuation can in fact be considered one of its manifestations. Indeed, the
virtue of effectively speaking and writing involves - often decisively - the
capacity to apply the properly placed breaks. In the present study, based on a
large corpus of world-famous and representative literary texts in seven major
Western languages, it is shown that the distribution of intervals between
consecutive punctuation marks in almost all texts can universally be
characterised by only two parameters of the discrete Weibull distribution which
can be given an intuitive interpretation in terms of the so-called hazard
function. The values of these two parameters tend to be language-specific,
however, and even appear to navigate translations. The properties of the
computed hazard functions indicate that among the studied languages, English
turns out to be the least constrained by the necessity to place a consecutive
punctuation mark to partition a sequence of words. This may suggest that when
compared to other studied languages, English is more flexible, in the sense of
allowing longer uninterrupted sequences of words. Spanish reveals similar
tendency to only a bit lesser extent.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Entropy- and Distance-Based Predictors From GPT-2 Attention Patterns Predict Reading Times Over and Above GPT-2 Surprisal. (arXiv:2212.11185v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.11185">
<div class="article-summary-box-inner">
<span><p>Transformer-based large language models are trained to make predictions about
the next word by aggregating representations of previous tokens through their
self-attention mechanism. In the field of cognitive modeling, such attention
patterns have recently been interpreted as embodying the process of cue-based
retrieval, in which attention over multiple targets is taken to generate
interference and latency during retrieval. Under this framework, this work
first defines an entropy-based predictor that quantifies the diffuseness of
self-attention, as well as distance-based predictors that capture the
incremental change in attention patterns across timesteps. Moreover, following
recent studies that question the informativeness of attention weights, we also
experiment with alternative methods for incorporating vector norms into
attention weights. Regression experiments using predictors calculated from the
GPT-2 language model show that these predictors deliver a substantially better
fit to held-out self-paced reading and eye-tracking data over a rigorous
baseline including GPT-2 surprisal. Additionally, the distance-based predictors
generally demonstrated higher predictive power, with effect sizes of up to 6.59
ms per standard deviation on self-paced reading times (compared to 2.82 ms for
surprisal) and 1.05 ms per standard deviation on eye-gaze durations (compared
to 3.81 ms for surprisal).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Safe and Usable Chatbots for Promoting Voter Participation. (arXiv:2212.11219v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.11219">
<div class="article-summary-box-inner">
<span><p>Chatbots, or bots for short, are multi-modal collaborative assistants that
can help people complete useful tasks. Usually, when chatbots are referenced in
connection with elections, they often draw negative reactions due to the fear
of mis-information and hacking. Instead, in this paper, we explore how chatbots
may be used to promote voter participation in vulnerable segments of society
like senior citizens and first-time voters. In particular, we build a system
that amplifies official information while personalizing it to users' unique
needs transparently. We discuss its design, build prototypes with frequently
asked questions (FAQ) election information for two US states that are low on an
ease-of-voting scale, and report on its initial evaluation in a focus group.
Our approach can be a win-win for voters, election agencies trying to fulfill
their mandate and democracy at large.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Narrative Relationship Embeddings by Training with Additional Inverse-Relationship Constraints. (arXiv:2212.11234v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.11234">
<div class="article-summary-box-inner">
<span><p>We consider the problem of embedding character-entity relationships from the
reduced semantic space of narratives, proposing and evaluating the assumption
that these relationships hold under a reflection operation. We analyze this
assumption and compare the approach to a baseline state-of-the-art model with a
unique evaluation that simulates efficacy on a downstream clustering task with
human-created labels. Although our model creates clusters that achieve
Silhouette scores of -.084, outperforming the baseline -.227, our analysis
reveals that the models approach the task much differently and perform well on
very different examples. We conclude that our assumption might be useful for
specific types of data and should be evaluated on a wider range of tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Language-Vision AI Models Pretrained on Web-Scraped Multimodal Data Exhibit Sexual Objectification Bias. (arXiv:2212.11261v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.11261">
<div class="article-summary-box-inner">
<span><p>Nine language-vision AI models trained on web scrapes with the Contrastive
Language-Image Pretraining (CLIP) objective are evaluated for evidence of a
bias studied by psychologists: the sexual objectification of girls and women,
which occurs when a person's human characteristics are disregarded and the
person is treated as a body or a collection of body parts. A first experiment
uses standardized images of women from the Sexual OBjectification and EMotion
Database, and finds that, commensurate with prior research in psychology, human
characteristics are disassociated from images of objectified women: the model's
recognition of emotional state is mediated by whether the subject is fully or
partially clothed. Embedding association tests (EATs) return significant effect
sizes for both anger (d &gt;.8) and sadness (d &gt;.5). A second experiment measures
the effect in a representative application: an automatic image captioner
(Antarctic Captions) includes words denoting emotion less than 50% as often for
images of partially clothed women than for images of fully clothed women. A
third experiment finds that images of female professionals (scientists,
doctors, executives) are likely to be associated with sexual descriptions
relative to images of male professionals. A fourth experiment shows that a
prompt of "a [age] year old girl" generates sexualized images (as determined by
an NSFW classifier) up to 73% of the time for VQGAN-CLIP (age 17), and up to
40% of the time for Stable Diffusion (ages 14 and 18); the corresponding rate
for boys never surpasses 9%. The evidence indicates that language-vision AI
models trained on automatically collected web scrapes learn biases of sexual
objectification, which propagate to downstream applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalized Decoding for Pixel, Image, and Language. (arXiv:2212.11270v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.11270">
<div class="article-summary-box-inner">
<span><p>We present X-Decoder, a generalized decoding model that can predict
pixel-level segmentation and language tokens seamlessly. X-Decodert takes as
input two types of queries: (i) generic non-semantic queries and (ii) semantic
queries induced from text inputs, to decode different pixel-level and
token-level outputs in the same semantic space. With such a novel design,
X-Decoder is the first work that provides a unified way to support all types of
image segmentation and a variety of vision-language (VL) tasks. Further, our
design enables seamless interactions across tasks at different granularities
and brings mutual benefits by learning a common and rich pixel-level
visual-semantic understanding space, without any pseudo-labeling. After
pretraining on a mixed set of a limited amount of segmentation data and
millions of image-text pairs, X-Decoder exhibits strong transferability to a
wide range of downstream tasks in both zero-shot and finetuning settings.
Notably, it achieves (1) state-of-the-art results on open-vocabulary
segmentation and referring segmentation on eight datasets; (2) better or
competitive finetuned performance to other generalist and specialist models on
segmentation and VL tasks; and (3) flexibility for efficient finetuning and
novel task composition (e.g., referring captioning and image editing). Code,
demo, video, and visualization are available at https://x-decoder-vl.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Named Tensor Notation. (arXiv:2102.13196v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13196">
<div class="article-summary-box-inner">
<span><p>We propose a notation for tensors with named axes, which relieves the author,
reader, and future implementers of machine learning models from the burden of
keeping track of the order of axes and the purpose of each. The notation makes
it easy to lift operations on low-order tensors to higher order ones, for
example, from images to minibatches of images, or from an attention mechanism
to multiple attention heads.
</p>
<p>After a brief overview and formal definition of the notation, we illustrate
it through several examples from modern machine learning, from building blocks
like attention and convolution to full models like Transformers and LeNet. We
then discuss differential calculus in our notation and compare with some
alternative notations. Our proposals build on ideas from many previous papers
and software libraries. We hope that our notation will encourage more authors
to use named tensors, resulting in clearer papers and more precise
implementations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextual-Lexicon Approach for Abusive Language Detection. (arXiv:2104.12265v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12265">
<div class="article-summary-box-inner">
<span><p>Since a lexicon-based approach is more elegant scientifically, explaining the
solution components and being easier to generalize to other applications, this
paper provides a new approach for offensive language and hate speech detection
on social media. Our approach embodies a lexicon of implicit and explicit
offensive and swearing expressions annotated with contextual information. Due
to the severity of the social media abusive comments in Brazil, and the lack of
research in Portuguese, Brazilian Portuguese is the language used to validate
the models. Nevertheless, our method may be applied to any other language. The
conducted experiments show the effectiveness of the proposed approach,
outperforming the current baseline methods for the Portuguese language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-View Active Learning for Short Text Classification in User-Generated Data. (arXiv:2112.02611v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.02611">
<div class="article-summary-box-inner">
<span><p>Mining user-generated data often suffers from the lack of enough labeled
data, short document lengths, and the informal user language. In this paper, we
propose a novel active learning model to overcome these obstacles in the tasks
tailored for query phrases--e.g., detecting positive reports of natural
disasters. Our model has three novelties: 1) It is the first approach to employ
multi-view active learning in this domain. 2) It uses the Parzen-Rosenblatt
window method to integrate the representativeness measure into multi-view
active learning. 3) It employs a query-by-committee strategy, based on the
agreement between predictors, to address the usually noisy language of the
documents in this domain. We evaluate our model in four publicly available
Twitter datasets with distinctly different applications. We also compare our
model with a wide range of baselines including those with multiple classifiers.
The experiments testify that our model is highly consistent and outperforms
existing models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Two-view Graph Neural Networks for Knowledge Graph Completion. (arXiv:2112.09231v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.09231">
<div class="article-summary-box-inner">
<span><p>We present an effective graph neural network (GNN)-based knowledge graph
embedding model, which we name WGE, to capture entity- and relation-focused
graph structures. Given a knowledge graph, WGE builds a single undirected
entity-focused graph that views entities as nodes. WGE also constructs another
single undirected graph from relation-focused constraints, which views entities
and relations as nodes. WGE then proposes a GNN-based architecture to better
learn vector representations of entities and relations from these two single
entity- and relation-focused graphs. WGE feeds the learned entity and relation
representations into a weighted score function to return the triple scores for
knowledge graph completion. Experimental results show that WGE outperforms
competitive baselines, obtaining state-of-the-art performances on seven
benchmark datasets for knowledge graph completion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does human speech follow Benford's Law?. (arXiv:2203.13352v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.13352">
<div class="article-summary-box-inner">
<span><p>Researchers have observed that the frequencies of leading digits in many
man-made and naturally occurring datasets follow a logarithmic curve, with
digits that start with the number 1 accounting for $\sim 30\%$ of all numbers
in the dataset and digits that start with the number 9 accounting for $\sim
5\%$ of all numbers in the dataset. This phenomenon, known as Benford's Law, is
highly repeatable and appears in lists of numbers from electricity bills, stock
prices, tax returns, house prices, death rates, lengths of rivers, and
naturally occurring images. In this paper we demonstrate that human speech
spectra also follow Benford's Law on average. That is, when averaged over many
speakers, the frequencies of leading digits in speech magnitude spectra follow
this distribution, although with some variability at the individual sample
level. We use this observation to motivate a new set of features that can be
efficiently extracted from speech and demonstrate that these features can be
used to classify between human speech and synthetic speech.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Hate Speech Detection from Bengali Memes and Texts. (arXiv:2204.10196v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.10196">
<div class="article-summary-box-inner">
<span><p>Numerous machine learning (ML) and deep learning (DL)-based approaches have
been proposed to utilize textual data from social media for anti-social
behavior analysis like cyberbullying, fake news detection, and identification
of hate speech mainly for highly-resourced languages such as English. However,
despite having a lot of diversity and millions of native speakers, some
languages like Bengali are under-resourced, which is due to a lack of
computational resources for natural language processing (NLP). Similar to other
languages, Bengali social media contents also include images along with texts
(e.g., multimodal memes are posted by embedding short texts into images on
Facebook). Therefore, only the textual data is not enough to judge them since
images might give extra context to make a proper judgement. This paper is about
hate speech detection from multimodal Bengali memes and texts. We prepared the
only multimodal hate speech dataset for-a-kind of problem for Bengali, which we
use to train state-of-the-art neural architectures (e.g., Bi-LSTM/Conv-LSTM
with word embeddings, ConvNets + pre-trained language models, e.g., monolingual
Bangla BERT, multilingual BERT-cased/uncased, and XLM-RoBERTa) to jointly
analyze textual and visual information for hate speech detection. Conv-LSTM and
XLM-RoBERTa models performed best for texts, yielding F1 scores of 0.78 and
0.82, respectively. As of memes, ResNet-152 and DenseNet-161 models yield F1
scores of 0.78 and 0.79, respectively. As for multimodal fusion, XLM-RoBERTa +
DenseNet-161 performed the best, yielding an F1 score of 0.83. Our study
suggests that text modality is most useful for hate speech detection, while
memes are moderately useful.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimizing Test-Time Query Representations for Dense Retrieval. (arXiv:2205.12680v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12680">
<div class="article-summary-box-inner">
<span><p>Recent developments of dense retrieval rely on quality representations of
queries and contexts coming from pre-trained query and context encoders. In
this paper, we introduce TouR (test-time optimization of query
representations), which further optimizes instance-level query representations
guided by signals from test-time retrieval results. We leverage a cross-encoder
re-ranker to provide fine-grained pseudo labels over retrieval results and
iteratively optimize query representations with the gradient descent method.
Our theoretical analysis reveals that TouR can be viewed as a generalization of
the classical Rocchio's algorithm for pseudo relevance feedback, and we present
two variants leveraging psuedo labels as either hard binary or soft continuous
labels. We first apply TouR on phrase retrieval with our proposed phrase
re-ranker. On passage retrieval, we demonstrate its effectiveness with an
off-the-shelf re-ranker. TouR improves the end-to-end open-domain QA accuracy
significantly, as well as passage retrieval performance. Compared to re-ranker,
TouR requires a smaller number of candidates, and achieves consistently better
performance and runs up to 4x faster with our efficient implementation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can large language models reason about medical questions?. (arXiv:2207.08143v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.08143">
<div class="article-summary-box-inner">
<span><p>Although large language models (LLMs) often produce impressive outputs, it
remains unclear how they perform in real-world scenarios requiring strong
reasoning skills and expert domain knowledge. We set out to investigate whether
GPT-3.5 (Codex and InstructGPT) can be applied to answer and reason about
difficult real-world-based questions. We utilize two multiple-choice medical
exam questions (USMLE and MedMCQA) and a medical reading comprehension dataset
(PubMedQA). We investigate multiple prompting scenarios: Chain-of-Thought (CoT,
think step-by-step), zero- and few-shot (prepending the question with
question-answer exemplars) and retrieval augmentation (injecting Wikipedia
passages into the prompt). For a subset of the USMLE questions, a medical
expert reviewed and annotated the model's CoT. We found that InstructGPT can
often read, reason and recall expert knowledge. Failure are primarily due to
lack of knowledge and reasoning errors and trivial guessing heuristics are
observed, e.g.\ too often predicting labels A and D on USMLE. Sampling and
combining many completions overcome some of these limitations. Using 100
samples, Codex 5-shot CoT not only gives close to well-calibrated predictive
probability but also achieves human-level performances on the three datasets.
USMLE: 60.2%, MedMCQA: 57.5% and PubMedQA: 78.2%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is Your Model Sensitive? SPeDaC: A New Benchmark for Detecting and Classifying Sensitive Personal Data. (arXiv:2208.06216v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.06216">
<div class="article-summary-box-inner">
<span><p>In recent years, there has been an exponential growth of applications,
including dialogue systems, that handle sensitive personal information. This
has brought to light the extremely important issue of personal data protection
in virtual environments. Sensitive Information Detection (SID) approaches
different domains and languages in literature. However, if we refer to the
personal data domain, a shared benchmark or the absence of an available labeled
resource makes comparison with the state-of-the-art difficult. We introduce and
release SPeDaC , a new annotated resource for the identification of sensitive
personal data categories in the English language. SPeDaC enables the evaluation
of computational models for three different SID subtasks with increasing levels
of complexity. SPeDaC 1 regards binary classification, a model has to detect if
a sentence contains sensitive information or not; whereas, in SPeDaC 2 we
collected labeled sentences using 5 categories that relate to macro-domains of
personal information; in SPeDaC 3, the labeling is fine-grained (61 personal
data categories). We conduct an extensive evaluation of the resource using
different state-of-the-art-classifiers. The results show that SPeDaC is
challenging, particularly with regard to fine-grained classification. The
transformer models achieve the best results (acc. RoBERTa on SPeDaC 1 = 98.20%,
DeBERTa on SPeDaC 2 = 95.81% and SPeDaC 3 = 77.63%).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">In conversation with Artificial Intelligence: aligning language models with human values. (arXiv:2209.00731v2 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.00731">
<div class="article-summary-box-inner">
<span><p>Large-scale language technologies are increasingly used in various forms of
communication with humans across different contexts. One particular use case
for these technologies is conversational agents, which output natural language
text in response to prompts and queries. This mode of engagement raises a
number of social and ethical questions. For example, what does it mean to align
conversational agents with human norms or values? Which norms or values should
they be aligned with? And how can this be accomplished? In this paper, we
propose a number of steps that help answer these questions. We start by
developing a philosophical analysis of the building blocks of linguistic
communication between conversational agents and human interlocutors. We then
use this analysis to identify and formulate ideal norms of conversation that
can govern successful linguistic communication between humans and
conversational agents. Furthermore, we explore how these norms can be used to
align conversational agents with human values across a range of different
discursive domains. We conclude by discussing the practical implications of our
proposal for the design of conversational agents that are aligned with these
norms and values.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GROOT: Corrective Reward Optimization for Generative Sequential Labeling. (arXiv:2209.14694v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.14694">
<div class="article-summary-box-inner">
<span><p>Sequential labeling is a fundamental NLP task, forming the backbone of many
applications. Supervised learning of Seq2Seq models has shown great success on
these problems. However, the training objectives are still significantly
disconnected with the metrics and desiderata we care about in practice. For
example, a practical sequence tagging application may want to optimize for a
certain precision-recall trade-off (of the top-k predictions) which is quite
different from the standard objective of maximizing the likelihood of the gold
labeled sequence. Thus to bridge this gap, we propose GROOT -- a simple yet
effective framework for Generative Reward Optimization Of Text sequences. GROOT
works by training a generative sequential labeling model to match the decoder
output distribution with that of the (black-box) reward function. Using an
iterative training regime, we first generate prediction candidates, then
correct errors in them, and finally contrast those candidates (based on their
reward values). As demonstrated via extensive experiments on four public
benchmarks, GROOT significantly improves all reward metrics. Furthermore, GROOT
leads to improvements of the overall decoder distribution as evidenced by the
quality gains of the top-$k$ candidates.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal Open-domain Conversation. (arXiv:2211.05719v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.05719">
<div class="article-summary-box-inner">
<span><p>Responding with multi-modal content has been recognized as an essential
capability for an intelligent conversational agent. In this paper, we introduce
the MMDialog dataset to better facilitate multi-modal conversation. MMDialog is
composed of a curated set of 1.08 million real-world dialogues with 1.53
million unique images across 4,184 topics. MMDialog has two main and unique
advantages. First, it is the largest multi-modal conversation dataset by the
number of dialogues by 88x. Second, it contains massive topics to generalize
the open-domain. To build engaging dialogue system with this dataset, we
propose and normalize two response producing tasks based on retrieval and
generative scenarios. In addition, we build two baselines for above tasks with
state-of-the-art techniques and report their experimental performance. We also
propose a novel evaluation metric MM-Relevance to measure the multi-modal
responses. Our dataset and scripts are available in
https://github.com/victorsungo/MMDialog.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reasoning over Different Types of Knowledge Graphs: Static, Temporal and Multi-Modal. (arXiv:2212.05767v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.05767">
<div class="article-summary-box-inner">
<span><p>Knowledge graph reasoning (KGR), aiming to deduce new facts from existing
facts based on mined logic rules underlying knowledge graphs (KGs), has become
a fast-growing research direction. It has been proven to significantly benefit
the usage of KGs in many AI applications, such as question answering and
recommendation systems, etc. According to the graph types, the existing KGR
models can be roughly divided into three categories, i.e., static models,
temporal models, and multi-modal models. The early works in this domain mainly
focus on static KGR and tend to directly apply general knowledge graph
embedding models to the reasoning task. However, these models are not suitable
for more complex but practical tasks, such as inductive static KGR, temporal
KGR, and multi-modal KGR. To this end, multiple works have been developed
recently, but no survey papers and open-source repositories comprehensively
summarize and discuss models in this important direction. To fill the gap, we
conduct a survey for knowledge graph reasoning tracing from static to temporal
and then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR
models, and typical datasets are introduced and discussed consequently.
Moreover, we discuss the challenges and potential opportunities. The
corresponding open-source repository is shared on GitHub:
https://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SMSMix: Sense-Maintained Sentence Mixup for Word Sense Disambiguation. (arXiv:2212.07072v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.07072">
<div class="article-summary-box-inner">
<span><p>Word Sense Disambiguation (WSD) is an NLP task aimed at determining the
correct sense of a word in a sentence from discrete sense choices. Although
current systems have attained unprecedented performances for such tasks, the
nonuniform distribution of word senses during training generally results in
systems performing poorly on rare senses. To this end, we consider data
augmentation to increase the frequency of these least frequent senses (LFS) to
reduce the distributional bias of senses during training. We propose
Sense-Maintained Sentence Mixup (SMSMix), a novel word-level mixup method that
maintains the sense of a target word. SMSMix smoothly blends two sentences
using mask prediction while preserving the relevant span determined by saliency
scores to maintain a specific word's sense. To the best of our knowledge, this
is the first attempt to apply mixup in NLP while preserving the meaning of a
specific word. With extensive experiments, we validate that our augmentation
method can effectively give more information about rare senses during training
with maintained target sense label.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Linguistically Informed Multi-Objective Pre-Training for Natural Language Inference. (arXiv:2212.07428v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.07428">
<div class="article-summary-box-inner">
<span><p>We introduce a linguistically enhanced combination of pre-training methods
for transformers. The pre-training objectives include POS-tagging, synset
prediction based on semantic knowledge graphs, and parent prediction based on
dependency parse trees. Our approach achieves competitive results on the
Natural Language Inference task, compared to the state of the art. Specifically
for smaller models, the method results in a significant performance boost,
emphasizing the fact that intelligent pre-training can make up for fewer
parameters and help building more efficient models. Combining POS-tagging and
synset prediction yields the overall best results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Scales Data Augmentation Approach In Natural Language Inference For Artifacts Mitigation And Pre-Trained Model Optimization. (arXiv:2212.08756v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.08756">
<div class="article-summary-box-inner">
<span><p>Machine learning models can reach high performance on benchmark natural
language processing (NLP) datasets but fail in more challenging settings. We
study this issue when a pre-trained model learns dataset artifacts in natural
language inference (NLI), the topic of studying the logical relationship
between a pair of text sequences. We provide a variety of techniques for
analyzing and locating dataset artifacts inside the crowdsourced Stanford
Natural Language Inference (SNLI) corpus. We study the stylistic pattern of
dataset artifacts in the SNLI. To mitigate dataset artifacts, we employ a
unique multi-scale data augmentation technique with two distinct frameworks: a
behavioral testing checklist at the sentence level and lexical synonym criteria
at the word level. Specifically, our combination method enhances our model's
resistance to perturbation testing, enabling it to continuously outperform the
pre-trained baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers. (arXiv:2212.10559v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10559">
<div class="article-summary-box-inner">
<span><p>Large pretrained language models have shown surprising In-Context Learning
(ICL) ability. With a few demonstration input-label pairs, they can predict the
label for an unseen input without additional parameter updates. Despite the
great success in performance, the working mechanism of ICL still remains an
open problem. In order to better understand how ICL works, this paper explains
language models as meta-optimizers and understands ICL as a kind of implicit
finetuning. Theoretically, we figure out that the Transformer attention has a
dual form of gradient descent based optimization. On top of it, we understand
ICL as follows: GPT first produces meta-gradients according to the
demonstration examples, and then these meta-gradients are applied to the
original GPT to build an ICL model. Experimentally, we comprehensively compare
the behavior of ICL and explicit finetuning based on real tasks to provide
empirical evidence that supports our understanding. The results prove that ICL
behaves similarly to explicit finetuning at the prediction level, the
representation level, and the attention behavior level. Further, inspired by
our understanding of meta-optimization, we design a momentum-based attention by
analogy with the momentum-based gradient descent algorithm. Its consistently
better performance over vanilla attention supports our understanding again from
another aspect, and more importantly, it shows the potential to utilize our
understanding for future model designing.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-12-22 23:13:56.629763433 UTC">2022-12-22 23:13:56 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>