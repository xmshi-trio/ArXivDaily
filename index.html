<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-10-26T01:30:00Z">10-26</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">CR-COPEC: Causal Rationale of Corporate Performance Changes to Learn from Financial Reports. (arXiv:2310.16095v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16095">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce CR-COPEC called Causal Rationale of Corporate
Performance Changes from financial reports. This is a comprehensive large-scale
domain-adaptation causal sentence dataset to detect financial performance
changes of corporate. CR-COPEC contributes to two major achievements. First, it
detects causal rationale from 10-K annual reports of the U.S. companies, which
contain experts' causal analysis following accounting standards in a formal
manner. This dataset can be widely used by both individual investors and
analysts as material information resources for investing and decision making
without tremendous effort to read through all the documents. Second, it
carefully considers different characteristics which affect the financial
performance of companies in twelve industries. As a result, CR-COPEC can
distinguish causal sentences in various industries by taking unique narratives
in each industry into consideration. We also provide an extensive analysis of
how well CR-COPEC dataset is constructed and suited for classifying target
sentences as causal ones with respect to industry characteristics. Our dataset
and experimental codes are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Locally Differentially Private Document Generation Using Zero Shot Prompting. (arXiv:2310.16111v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16111">
<div class="article-summary-box-inner">
<span><p>Numerous studies have highlighted the privacy risks associated with
pretrained large language models. In contrast, our research offers a unique
perspective by demonstrating that pretrained large language models can
effectively contribute to privacy preservation. We propose a locally
differentially private mechanism called DP-Prompt, which leverages the power of
pretrained large language models and zero-shot prompting to counter author
de-anonymization attacks while minimizing the impact on downstream utility.
When DP-Prompt is used with a powerful language model like ChatGPT (gpt-3.5),
we observe a notable reduction in the success rate of de-anonymization attacks,
showing that it surpasses existing approaches by a considerable margin despite
its simpler design. For instance, in the case of the IMDB dataset, DP-Prompt
(with ChatGPT) perfectly recovers the clean sentiment F1 score while achieving
a 46\% reduction in author identification F1 score against static attackers and
a 26\% reduction against adaptive attackers. We conduct extensive experiments
across six open-source large language models, ranging up to 7 billion
parameters, to analyze various effects of the privacy-utility tradeoff.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NADI 2023: The Fourth Nuanced Arabic Dialect Identification Shared Task. (arXiv:2310.16117v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16117">
<div class="article-summary-box-inner">
<span><p>We describe the findings of the fourth Nuanced Arabic Dialect Identification
Shared Task (NADI 2023). The objective of NADI is to help advance
state-of-the-art Arabic NLP by creating opportunities for teams of researchers
to collaboratively compete under standardized conditions. It does so with a
focus on Arabic dialects, offering novel datasets and defining subtasks that
allow for meaningful comparisons between different approaches. NADI 2023
targeted both dialect identification (Subtask 1) and dialect-to-MSA machine
translation (Subtask 2 and Subtask 3). A total of 58 unique teams registered
for the shared task, of whom 18 teams have participated (with 76 valid
submissions during test phase). Among these, 16 teams participated in Subtask
1, 5 participated in Subtask 2, and 3 participated in Subtask 3. The winning
teams achieved 87.27
</p>
<p>F1 on Subtask 1, 14.76 Bleu in Subtask 2, and 21.10 Bleu in Subtask 3,
respectively. Results show that all three subtasks remain challenging, thereby
motivating future work in this area. We describe the methods employed by the
participating teams and briefly offer an outlook for NADI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Octopus: A Multitask Model and Toolkit for Arabic Natural Language Generation. (arXiv:2310.16127v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16127">
<div class="article-summary-box-inner">
<span><p>Understanding Arabic text and generating human-like responses is a
challenging endeavor. While many researchers have proposed models and solutions
for individual problems, there is an acute shortage of a comprehensive Arabic
natural language generation toolkit that is capable of handling a wide range of
tasks. In this work, we present a novel Arabic text-to-text Transformer model,
namely AraT5v2. Our new model is methodically trained on extensive and diverse
data, utilizing an extended sequence length of 2,048 tokens. We explore various
pretraining strategies including unsupervised, supervised, and joint
pertaining, under both single and multitask settings. Our models outperform
competitive baselines with large margins. We take our work one step further by
developing and publicly releasing Octopus, a Python-based package and
command-line toolkit tailored for eight Arabic generation tasks all exploiting
a single model. We release the models and the toolkit on our public repository.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GenKIE: Robust Generative Multimodal Document Key Information Extraction. (arXiv:2310.16131v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16131">
<div class="article-summary-box-inner">
<span><p>Key information extraction (KIE) from scanned documents has gained increasing
attention because of its applications in various domains. Although promising
results have been achieved by some recent KIE approaches, they are usually
built based on discriminative models, which lack the ability to handle optical
character recognition (OCR) errors and require laborious token-level labelling.
In this paper, we propose a novel generative end-to-end model, named GenKIE, to
address the KIE task. GenKIE is a sequence-to-sequence multimodal generative
model that utilizes multimodal encoders to embed visual, layout and textual
features and a decoder to generate the desired output. Well-designed prompts
are leveraged to incorporate the label semantics as the weakly supervised
signals and entice the generation of the key information. One notable advantage
of the generative model is that it enables automatic correction of OCR errors.
Besides, token-level granular annotation is not required. Extensive experiments
on multiple public real-world datasets show that GenKIE effectively generalizes
over different types of documents and achieves state-of-the-art results. Our
experiments also validate the model's robustness against OCR errors, making
GenKIE highly applicable in real-world scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can You Follow Me? Testing Situational Understanding in ChatGPT. (arXiv:2310.16135v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16135">
<div class="article-summary-box-inner">
<span><p>Understanding sentence meanings and updating information states appropriately
across time -- what we call "situational understanding" (SU) -- is a critical
ability for human-like AI agents. SU is essential in particular for chat
models, such as ChatGPT, to enable consistent, coherent, and effective dialogue
between humans and AI. Previous works have identified certain SU limitations in
non-chatbot Large Language models (LLMs), but the extent and causes of these
limitations are not well understood, and capabilities of current chat-based
models in this domain have not been explored. In this work we tackle these
questions, proposing a novel synthetic environment for SU testing which allows
us to do controlled and systematic testing of SU in chat-oriented models,
through assessment of models' ability to track and enumerate environment
states. Our environment also allows for close analysis of dynamics of model
performance, to better understand underlying causes for performance patterns.
We apply our test to ChatGPT, the state-of-the-art chatbot, and find that
despite the fundamental simplicity of the task, the model's performance
reflects an inability to retain correct environment states across time. Our
follow-up analyses suggest that performance degradation is largely because
ChatGPT has non-persistent in-context memory (although it can access the full
dialogue history) and it is susceptible to hallucinated updates -- including
updates that artificially inflate accuracies. Our findings suggest overall that
ChatGPT is not currently equipped for robust tracking of situation states, and
that trust in the impressive dialogue performance of ChatGPT comes with risks.
We release the codebase for reproducing our test environment, as well as all
prompts and API responses from ChatGPT, at
https://github.com/yangalan123/SituationalTesting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Language Model with Limited Memory Capacity Captures Interference in Human Sentence Processing. (arXiv:2310.16142v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16142">
<div class="article-summary-box-inner">
<span><p>Two of the central factors believed to underpin human sentence processing
difficulty are expectations and retrieval from working memory. A recent attempt
to create a unified cognitive model integrating these two factors relied on the
parallels between the self-attention mechanism of transformer language models
and cue-based retrieval theories of working memory in human sentence processing
(Ryu and Lewis 2021). While Ryu and Lewis show that attention patterns in
specialized attention heads of GPT-2 are consistent with similarity-based
interference, a key prediction of cue-based retrieval models, their method
requires identifying syntactically specialized attention heads, and makes the
cognitively implausible assumption that hundreds of memory retrieval operations
take place in parallel. In the present work, we develop a recurrent neural
language model with a single self-attention head, which more closely parallels
the memory system assumed by cognitive theories. We show that our model's
single attention head captures semantic and syntactic interference effects
observed in human experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Clinfo.ai: An Open-Source Retrieval-Augmented Large Language Model System for Answering Medical Questions using Scientific Literature. (arXiv:2310.16146v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16146">
<div class="article-summary-box-inner">
<span><p>The quickly-expanding nature of published medical literature makes it
challenging for clinicians and researchers to keep up with and summarize
recent, relevant findings in a timely manner. While several closed-source
summarization tools based on large language models (LLMs) now exist, rigorous
and systematic evaluations of their outputs are lacking. Furthermore, there is
a paucity of high-quality datasets and appropriate benchmark tasks with which
to evaluate these tools. We address these issues with four contributions: we
release Clinfo.ai, an open-source WebApp that answers clinical questions based
on dynamically retrieved scientific literature; we specify an information
retrieval and abstractive summarization task to evaluate the performance of
such retrieval-augmented LLM systems; we release a dataset of 200 questions and
corresponding answers derived from published systematic reviews, which we name
PubMed Retrieval and Synthesis (PubMedRS-200); and report benchmark results for
Clinfo.ai and other publicly available OpenQA systems on PubMedRS-200.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PreWoMe: Exploiting Presuppositions as Working Memory for Long Form Question Answering. (arXiv:2310.16147v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16147">
<div class="article-summary-box-inner">
<span><p>Information-seeking questions in long-form question answering (LFQA) often
prove misleading due to ambiguity or false presupposition in the question.
While many existing approaches handle misleading questions, they are tailored
to limited questions, which are insufficient in a real-world setting with
unpredictable input characteristics. In this work, we propose PreWoMe, a
unified approach capable of handling any type of information-seeking question.
The key idea of PreWoMe involves extracting presuppositions in the question and
exploiting them as working memory to generate feedback and action about the
question. Our experiment shows that PreWoMe is effective not only in tackling
misleading questions but also in handling normal ones, thereby demonstrating
the effectiveness of leveraging presuppositions, feedback, and action for
real-world QA settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WojoodNER 2023: The First Arabic Named Entity Recognition Shared Task. (arXiv:2310.16153v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16153">
<div class="article-summary-box-inner">
<span><p>We present WojoodNER-2023, the first Arabic Named Entity Recognition (NER)
Shared Task. The primary focus of WojoodNER-2023 is on Arabic NER, offering
novel NER datasets (i.e., Wojood) and the definition of subtasks designed to
facilitate meaningful comparisons between different NER approaches.
WojoodNER-2023 encompassed two Subtasks: FlatNER and NestedNER. A total of 45
unique teams registered for this shared task, with 11 of them actively
participating in the test phase. Specifically, 11 teams participated in
FlatNER, while $8$ teams tackled NestedNER. The winning teams achieved F1
scores of 91.96 and 93.73 in FlatNER and NestedNER, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Correction with Backtracking Reduces Hallucination in Summarization. (arXiv:2310.16176v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16176">
<div class="article-summary-box-inner">
<span><p>Abstractive summarization aims at generating natural language summaries of a
source document that are succinct while preserving the important elements.
Despite recent advances, neural text summarization models are known to be
susceptible to hallucinating (or more correctly confabulating), that is to
produce summaries with details that are not grounded in the source document. In
this paper, we introduce a simple yet efficient technique, CoBa, to reduce
hallucination in abstractive summarization. The approach is based on two steps:
hallucination detection and mitigation. We show that the former can be achieved
through measuring simple statistics about conditional word probabilities and
distance to context words. Further, we demonstrate that straight-forward
backtracking is surprisingly effective at mitigation. We thoroughly evaluate
the proposed method with prior art on three benchmark datasets for text
summarization. The results show that CoBa is effective and efficient in
reducing hallucination, and offers great adaptability and flexibility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hidden Citations Obscure True Impact in Science. (arXiv:2310.16181v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16181">
<div class="article-summary-box-inner">
<span><p>References, the mechanism scientists rely on to signal previous knowledge,
lately have turned into widely used and misused measures of scientific impact.
Yet, when a discovery becomes common knowledge, citations suffer from
obliteration by incorporation. This leads to the concept of hidden citation,
representing a clear textual credit to a discovery without a reference to the
publication embodying it. Here, we rely on unsupervised interpretable machine
learning applied to the full text of each paper to systematically identify
hidden citations. We find that for influential discoveries hidden citations
outnumber citation counts, emerging regardless of publishing venue and
discipline. We show that the prevalence of hidden citations is not driven by
citation counts, but rather by the degree of the discourse on the topic within
the text of the manuscripts, indicating that the more discussed is a discovery,
the less visible it is to standard bibliometric analysis. Hidden citations
indicate that bibliometric measures offer a limited perspective on quantifying
the true impact of a discovery, raising the need to extract knowledge from the
full text of the scientific corpus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BLP 2023 Task 2: Sentiment Analysis. (arXiv:2310.16183v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16183">
<div class="article-summary-box-inner">
<span><p>We present an overview of the BLP Sentiment Shared Task, organized as part of
the inaugural BLP 2023 workshop, co-located with EMNLP 2023. The task is
defined as the detection of sentiment in a given piece of social media text.
This task attracted interest from 71 participants, among whom 29 and 30 teams
submitted systems during the development and evaluation phases, respectively.
In total, participants submitted 597 runs. However, a total of 15 teams
submitted system description papers. The range of approaches in the submitted
systems spans from classical machine learning models, fine-tuning pre-trained
models, to leveraging Large Language Model (LLMs) in zero- and few-shot
settings. In this paper, we provide a detailed account of the task setup,
including dataset development and evaluation setup. Additionally, we provide a
brief overview of the systems submitted by the participants. All datasets and
evaluation scripts from the shared task have been made publicly available for
the research community, to foster further research in this domain
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Length is a Curse and a Blessing for Document-level Semantics. (arXiv:2310.16193v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16193">
<div class="article-summary-box-inner">
<span><p>In recent years, contrastive learning (CL) has been extensively utilized to
recover sentence and document-level encoding capability from pre-trained
language models. In this work, we question the length generalizability of
CL-based models, i.e., their vulnerability towards length-induced semantic
shift. We verify not only that length vulnerability is a significant yet
overlooked research gap, but we can devise unsupervised CL methods solely
depending on the semantic signal provided by document length. We first derive
the theoretical foundations underlying length attacks, showing that elongating
a document would intensify the high intra-document similarity that is already
brought by CL. Moreover, we found that isotropy promised by CL is highly
dependent on the length range of text exposed in training. Inspired by these
findings, we introduce a simple yet universal document representation learning
framework, LA(SER)$^{3}$: length-agnostic self-reference for semantically
robust sentence representation learning, achieving state-of-the-art
unsupervised performance on the standard information retrieval benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Background Summarization of Event Timelines. (arXiv:2310.16197v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16197">
<div class="article-summary-box-inner">
<span><p>Generating concise summaries of news events is a challenging natural language
processing task. While journalists often curate timelines to highlight key
sub-events, newcomers to a news event face challenges in catching up on its
historical context. In this paper, we address this need by introducing the task
of background news summarization, which complements each timeline update with a
background summary of relevant preceding events. We construct a dataset by
merging existing timeline datasets and asking human annotators to write a
background summary for each timestep of each news event. We establish strong
baseline performance using state-of-the-art summarization systems and propose a
query-focused variant to generate background summaries. To evaluate background
summary quality, we present a question-answering-based evaluation metric,
Background Utility Score (BUS), which measures the percentage of questions
about a current event timestep that a background summary answers. Our
experiments show the effectiveness of instruction fine-tuned systems such as
Flan-T5, in addition to strong zero-shot performance using GPT-3.5.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Editing for Large Language Models: A Survey. (arXiv:2310.16218v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16218">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have recently transformed both the academic and
industrial landscapes due to their remarkable capacity to understand, analyze,
and generate texts based on their vast knowledge and reasoning ability.
Nevertheless, one major drawback of LLMs is their substantial computational
cost for pre-training due to their unprecedented amounts of parameters. The
disadvantage is exacerbated when new knowledge frequently needs to be
introduced into the pre-trained model. Therefore, it is imperative to develop
effective and efficient techniques to update pre-trained LLMs. Traditional
methods encode new knowledge in pre-trained LLMs through direct fine-tuning.
However, naively re-training LLMs can be computationally intensive and risks
degenerating valuable pre-trained knowledge irrelevant to the update in the
model. Recently, Knowledge-based Model Editing (KME) has attracted increasing
attention, which aims to precisely modify the LLMs to incorporate specific
knowledge, without negatively influencing other irrelevant knowledge. In this
survey, we aim to provide a comprehensive and in-depth overview of recent
advances in the field of KME. We first introduce a general formulation of KME
to encompass different KME strategies. Afterward, we provide an innovative
taxonomy of KME techniques based on how the new knowledge is introduced into
pre-trained LLMs, and investigate existing KME strategies while analyzing key
insights, advantages, and limitations of methods from each category. Moreover,
representative metrics, datasets, and applications of KME are introduced
accordingly. Finally, we provide an in-depth analysis regarding the
practicality and remaining challenges of KME and suggest promising research
directions for further advancement in this field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset. (arXiv:2310.16225v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16225">
<div class="article-summary-box-inner">
<span><p>The CoNLL-03 corpus is arguably the most well-known and utilized benchmark
dataset for named entity recognition (NER). However, prior works found
significant numbers of annotation errors, incompleteness, and inconsistencies
in the data. This poses challenges to objectively comparing NER approaches and
analyzing their errors, as current state-of-the-art models achieve F1-scores
that are comparable to or even exceed the estimated noise level in CoNLL-03. To
address this issue, we present a comprehensive relabeling effort assisted by
automatic consistency checking that corrects 7.0% of all labels in the English
CoNLL-03. Our effort adds a layer of entity linking annotation both for better
explainability of NER labels and as additional safeguard of annotation quality.
Our experimental evaluation finds not only that state-of-the-art approaches
reach significantly higher F1-scores (97.1%) on our data, but crucially that
the share of correct predictions falsely counted as errors due to annotation
noise drops from 47% to 6%. This indicates that our resource is well suited to
analyze the remaining errors made by state-of-the-art models, and that the
theoretical upper bound even on high resource, coarse-grained NER is not yet
reached. To facilitate such analysis, we make CleanCoNLL publicly available to
the research community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TiC-CLIP: Continual Training of CLIP Models. (arXiv:2310.16226v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16226">
<div class="article-summary-box-inner">
<span><p>Keeping large foundation models up to date on latest data is inherently
expensive. To avoid the prohibitive costs of constantly retraining, it is
imperative to continually train these models. This problem is exacerbated by
the lack of any large scale continual learning benchmarks or baselines. We
introduce the first set of web-scale Time-Continual (TiC) benchmarks for
training vision-language models: TiC-DataCompt, TiC-YFCC, and TiC-RedCaps with
over 12.7B timestamped image-text pairs spanning 9 years (2014--2022). We first
use our benchmarks to curate various dynamic evaluations to measure temporal
robustness of existing models. We show OpenAI's CLIP (trained on data up to
2020) loses $\approx 8\%$ zero-shot accuracy on our curated retrieval task from
2021--2022 compared with more recently trained models in OpenCLIP repository.
We then study how to efficiently train models on time-continuous data. We
demonstrate that a simple rehearsal-based approach that continues training from
the last checkpoint and replays old data reduces compute by $2.5\times$ when
compared to the standard practice of retraining from scratch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mixture-of-Linguistic-Experts Adapters for Improving and Interpreting Pre-trained Language Models. (arXiv:2310.16240v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16240">
<div class="article-summary-box-inner">
<span><p>In this work, we propose a method that combines two popular research areas by
injecting linguistic structures into pre-trained language models in the
parameter-efficient fine-tuning (PEFT) setting. In our approach, parallel
adapter modules encoding different linguistic structures are combined using a
novel Mixture-of-Linguistic-Experts architecture, where Gumbel-Softmax gates
are used to determine the importance of these modules at each layer of the
model. To reduce the number of parameters, we first train the model for a fixed
small number of steps before pruning the experts based on their importance
scores. Our experiment results with three different pre-trained models show
that our approach can outperform state-of-the-art PEFT methods with a
comparable number of parameters. In addition, we provide additional analysis to
examine the experts selected by each model at each layer to provide insights
for future studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ZzzGPT: An Interactive GPT Approach to Enhance Sleep Quality. (arXiv:2310.16242v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16242">
<div class="article-summary-box-inner">
<span><p>In today's world, sleep quality is pivotal for overall well-being. While
wearable sensors offer real-time monitoring, they often lack actionable
insights, leading to user abandonment. This paper delves into the role of
technology in understanding sleep patterns. We introduce a two-stage framework,
utilizing Large Language Models (LLMs), aiming to provide accurate sleep
predictions with actionable feedback. Leveraging the GLOBEM dataset and
synthetic data from LLMs, we highlight enhanced results with models like
XGBoost. Our approach merges advanced machine learning with user-centric
design, blending scientific accuracy with practicality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GlotLID: Language Identification for Low-Resource Languages. (arXiv:2310.16248v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16248">
<div class="article-summary-box-inner">
<span><p>Several recent papers have published good solutions for language
identification (LID) for about 300 high-resource and medium-resource languages.
However, there is no LID available that (i) covers a wide range of low-resource
languages, (ii) is rigorously evaluated and reliable and (iii) efficient and
easy to use. Here, we publish GlotLID-M, an LID model that satisfies the
desiderata of wide coverage, reliability and efficiency. It identifies 1665
languages, a large increase in coverage compared to prior work. In our
experiments, GlotLID-M outperforms four baselines (CLD3, FT176, OpenLID and
NLLB) when balancing F1 and false positive rate (FPR). We analyze the unique
challenges that low-resource LID poses: incorrect corpus metadata, leakage from
high-resource languages, difficulty separating closely related languages,
handling of macrolanguage vs varieties and in general noisy data. We hope that
integrating GlotLID-M into dataset creation pipelines will improve quality and
enhance accessibility of NLP technology for low-resource languages and
cultures. GlotLID-M model, code, and list of data sources are available:
https://github.com/cisnlp/GlotLID.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speakerly: A Voice-based Writing Assistant for Text Composition. (arXiv:2310.16251v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16251">
<div class="article-summary-box-inner">
<span><p>We present Speakerly, a new real-time voice-based writing assistance system
that helps users with text composition across various use cases such as emails,
instant messages, and notes. The user can interact with the system through
instructions or dictation, and the system generates a well-formatted and
coherent document. We describe the system architecture and detail how we
address the various challenges while building and deploying such a system at
scale. More specifically, our system uses a combination of small, task-specific
models as well as pre-trained language models for fast and effective text
composition while supporting a variety of input modes for better usability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Distributional Hypothesis Does Not Fully Explain the Benefits of Masked Language Model Pretraining. (arXiv:2310.16261v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16261">
<div class="article-summary-box-inner">
<span><p>We analyze the masked language modeling pretraining objective function from
the perspective of the distributional hypothesis. We investigate whether better
sample efficiency and the better generalization capability of models pretrained
with masked language modeling can be attributed to the semantic similarity
encoded in the pretraining data's distributional property. Via a synthetic
dataset, our analysis suggests that distributional property indeed leads to the
better sample efficiency of pretrained masked language models, but does not
fully explain the generalization capability. We also conduct analyses over two
real-world datasets and demonstrate that the distributional property does not
explain the generalization ability of pretrained natural language models
either. Our results illustrate our limited understanding of model pretraining
and provide future research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Large Language Models for Secure Code Generation: A Dataset-driven Study on Vulnerability Mitigation. (arXiv:2310.16263v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16263">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have brought significant advancements to code
generation, benefiting both novice and experienced developers. However, their
training using unsanitized data from open-source repositories, like GitHub,
introduces the risk of inadvertently propagating security vulnerabilities. To
effectively mitigate this concern, this paper presents a comprehensive study
focused on evaluating and enhancing code LLMs from a software security
perspective. We introduce SecuCoGen\footnote{SecuCoGen has been uploaded as
supplemental material and will be made publicly available after publication.},
a meticulously curated dataset targeting 21 critical vulnerability types.
SecuCoGen comprises 180 samples and serves as the foundation for conducting
experiments on three crucial code-related tasks: code generation, code repair
and vulnerability classification, with a strong emphasis on security. Our
experimental results reveal that existing models often overlook security
concerns during code generation, leading to the generation of vulnerable code.
To address this, we propose effective approaches to mitigate the security
vulnerabilities and enhance the overall robustness of code generated by LLMs.
Moreover, our study identifies weaknesses in existing models' ability to repair
vulnerable code, even when provided with vulnerability information.
Additionally, certain vulnerability types pose challenges for the models,
hindering their performance in vulnerability classification. Based on these
findings, we believe our study will have a positive impact on the software
engineering community, inspiring the development of improved methods for
training and utilizing LLMs, thereby leading to safer and more trustworthy
model deployment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Coarse Political Stance Classification of Media. The Editorial Line of a ChatGPT and Bard Newspaper. (arXiv:2310.16269v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16269">
<div class="article-summary-box-inner">
<span><p>Neutrality is difficult to achieve and, in politics, subjective. Traditional
media typically adopt an editorial line that can be used by their potential
readers as an indicator of the media bias. Several platforms currently rate
news outlets according to their political bias. The editorial line and the
ratings help readers in gathering a balanced view of news. But in the advent of
instruction-following language models, tasks such as writing a newspaper
article can be delegated to computers. Without imposing a biased persona, where
would an AI-based news outlet lie within the bias ratings? In this work, we use
the ratings of authentic news outlets to create a multilingual corpus of news
with coarse stance annotations (Left and Right) along with automatically
extracted topic annotations. We show that classifiers trained on this data are
able to identify the editorial line of most unseen newspapers in English,
German, Spanish and Catalan. We then apply the classifiers to 101
newspaper-like articles written by ChatGPT and Bard in the 4 languages at
different time periods. We observe that, similarly to traditional newspapers,
ChatGPT editorial line evolves with time and, being a data-driven system, the
stance of the generated articles differs among languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention Lens: A Tool for Mechanistically Interpreting the Attention Head Information Retrieval Mechanism. (arXiv:2310.16270v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16270">
<div class="article-summary-box-inner">
<span><p>Transformer-based Large Language Models (LLMs) are the state-of-the-art for
natural language tasks. Recent work has attempted to decode, by reverse
engineering the role of linear layers, the internal mechanisms by which LLMs
arrive at their final predictions for text completion tasks. Yet little is
known about the specific role of attention heads in producing the final token
prediction. We propose Attention Lens, a tool that enables researchers to
translate the outputs of attention heads into vocabulary tokens via learned
attention-head-specific transformations called lenses. Preliminary findings
from our trained lenses indicate that attention heads play highly specialized
roles in language models. The code for Attention Lens is available at
github.com/msakarvadia/AttentionLens.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CycleAlign: Iterative Distillation from Black-box LLM to White-box Models for Better Human Alignment. (arXiv:2310.16271v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16271">
<div class="article-summary-box-inner">
<span><p>Language models trained on large-scale corpus often generate content that is
harmful, toxic, or contrary to human preferences, making their alignment with
human values a critical concern. Reinforcement learning from human feedback
(RLHF) with algorithms like PPO is a prevalent approach for alignment but is
often complex, unstable, and resource-intensive. Recently, ranking-based
alignment methods have emerged, offering stability and effectiveness by
replacing the RL framework with supervised fine-tuning, but they are costly due
to the need for annotated data. Considering that existing large language models
(LLMs) like ChatGPT are already relatively well-aligned and cost-friendly,
researchers have begun to align the language model with human preference from
AI feedback. The common practices, which unidirectionally distill the
instruction-following responses from LLMs, are constrained by their bottleneck.
Thus we introduce CycleAlign to distill alignment capabilities from
parameter-invisible LLMs (black-box) to a parameter-visible model (white-box)
in an iterative manner. With in-context learning (ICL) as the core of the
cycle, the black-box models are able to rank the model-generated responses
guided by human-craft instruction and demonstrations about their preferences.
During iterative interaction, the white-box models also have a judgment about
responses generated by them. Consequently, the agreement ranking could be
viewed as a pseudo label to dynamically update the in-context demonstrations
and improve the preference ranking ability of black-box models. Through
multiple interactions, the CycleAlign framework could align the white-box model
with the black-box model effectively in a low-resource way. Empirical results
illustrate that the model fine-tuned by CycleAlign remarkably exceeds existing
methods, and achieves the state-of-the-art performance in alignment with human
value.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">XFEVER: Exploring Fact Verification across Languages. (arXiv:2310.16278v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16278">
<div class="article-summary-box-inner">
<span><p>This paper introduces the Cross-lingual Fact Extraction and VERification
(XFEVER) dataset designed for benchmarking the fact verification models across
different languages. We constructed it by translating the claim and evidence
texts of the Fact Extraction and VERification (FEVER) dataset into six
languages. The training and development sets were translated using machine
translation, whereas the test set includes texts translated by professional
translators and machine-translated texts. Using the XFEVER dataset, two
cross-lingual fact verification scenarios, zero-shot learning and
translate-train learning, are defined, and baseline models for each scenario
are also proposed in this paper. Experimental results show that the
multilingual language model can be used to build fact verification models in
different languages efficiently. However, the performance varies by language
and is somewhat inferior to the English case. We also found that we can
effectively mitigate model miscalibration by considering the prediction
similarity between the English and target languages. The XFEVER dataset, code,
and model checkpoints are available at
https://github.com/nii-yamagishilab/xfever.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is ChatGPT a Good Multi-Party Conversation Solver?. (arXiv:2310.16301v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16301">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have emerged as influential instruments within
the realm of natural language processing; nevertheless, their capacity to
handle multi-party conversations (MPCs) -- a scenario marked by the presence of
multiple interlocutors involved in intricate information exchanges -- remains
uncharted. In this paper, we delve into the potential of generative LLMs such
as ChatGPT and GPT-4 within the context of MPCs. An empirical analysis is
conducted to assess the zero-shot learning capabilities of ChatGPT and GPT-4 by
subjecting them to evaluation across three MPC datasets that encompass five
representative tasks. The findings reveal that ChatGPT's performance on a
number of evaluated MPC tasks leaves much to be desired, whilst GPT-4's results
portend a promising future. Additionally, we endeavor to bolster performance
through the incorporation of MPC structures, encompassing both speaker and
addressee architecture. This study provides an exhaustive evaluation and
analysis of applying generative LLMs to MPCs, casting a light upon the
conception and creation of increasingly effective and robust MPC agents.
Concurrently, this work underscores the challenges implicit in the utilization
of LLMs for MPCs, such as deciphering graphical information flows and
generating stylistically consistent responses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">URL-BERT: Training Webpage Representations via Social Media Engagements. (arXiv:2310.16303v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16303">
<div class="article-summary-box-inner">
<span><p>Understanding and representing webpages is crucial to online social networks
where users may share and engage with URLs. Common language model (LM) encoders
such as BERT can be used to understand and represent the textual content of
webpages. However, these representations may not model thematic information of
web domains and URLs or accurately capture their appeal to social media users.
In this work, we introduce a new pre-training objective that can be used to
adapt LMs to understand URLs and webpages. Our proposed framework consists of
two steps: (1) scalable graph embeddings to learn shallow representations of
URLs based on user engagement on social media and (2) a contrastive objective
that aligns LM representations with the aforementioned graph-based
representation. We apply our framework to the multilingual version of BERT to
obtain the model URL-BERT. We experimentally demonstrate that our continued
pre-training approach improves webpage understanding on a variety of tasks and
Twitter internal and external benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiQAD: A Benchmark Dataset for End-to-End Open-domain Dialogue Assessment. (arXiv:2310.16319v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16319">
<div class="article-summary-box-inner">
<span><p>Dialogue assessment plays a critical role in the development of open-domain
dialogue systems. Existing work are uncapable of providing an end-to-end and
human-epistemic assessment dataset, while they only provide sub-metrics like
coherence or the dialogues are conversed between annotators far from real user
settings. In this paper, we release a large-scale dialogue quality assessment
dataset (DiQAD), for automatically assessing open-domain dialogue quality.
Specifically, we (1) establish the assessment criteria based on the dimensions
conforming to human judgements on dialogue qualities, and (2) annotate
large-scale dialogues that conversed between real users based on these
annotation criteria, which contains around 100,000 dialogues. We conduct
several experiments and report the performances of the baselines as the
benchmark on DiQAD. The dataset is openly accessible at
https://github.com/yukunZhao/Dataset_Dialogue_quality_evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Samsung R&D Institute Philippines at WMT 2023. (arXiv:2310.16322v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16322">
<div class="article-summary-box-inner">
<span><p>In this paper, we describe the constrained MT systems submitted by Samsung
R&amp;D Institute Philippines to the WMT 2023 General Translation Task for two
directions: en$\rightarrow$he and he$\rightarrow$en. Our systems comprise of
Transformer-based sequence-to-sequence models that are trained with a mix of
best practices: comprehensive data preprocessing pipelines, synthetic
backtranslated data, and the use of noisy channel reranking during online
decoding. Our models perform comparably to, and sometimes outperform, strong
baseline unconstrained systems such as mBART50 M2M and NLLB 200 MoE despite
having significantly fewer parameters on two public benchmarks: FLORES-200 and
NTREX-128.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoheSentia: A Novel Benchmark of Incremental versus Holistic Assessment of Coherence in Generated Texts. (arXiv:2310.16329v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16329">
<div class="article-summary-box-inner">
<span><p>Coherence is a linguistic term that refers to the relations between small
textual units (sentences, propositions), which make the text logically
consistent and meaningful to the reader. With the advances of generative
foundational models in NLP, there is a pressing need to automatically assess
the human-perceived coherence of automatically generated texts. Up until now,
little work has been done on explicitly assessing the coherence of generated
texts and analyzing the factors contributing to (in)coherence. Previous work on
the topic used other tasks, e.g., sentence reordering, as proxies of coherence,
rather than approaching coherence detection heads on. In this paper, we
introduce {\sc CoheSentia}, a novel benchmark of human-perceived coherence of
automatically generated texts. Our annotation protocol reflects two
perspectives; one is global, assigning a single coherence score, and the other
is incremental, scoring sentence by sentence. The incremental method produces
an (in)coherence score for each text fragment and also pinpoints reasons for
incoherence at that point. Our benchmark contains 500 automatically-generated
and human-annotated paragraphs, each annotated in both methods, by multiple
raters. Our analysis shows that the inter-annotator agreement in the
incremental mode is higher than in the holistic alternative, and our
experiments show that standard LMs fine-tuned for coherence detection show
varied performance on the different factors contributing to (in)coherence. All
in all, these models yield unsatisfactory performance, emphasizing the need for
developing more reliable methods for coherence assessment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Pre-training for Speech with Flow Matching. (arXiv:2310.16338v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16338">
<div class="article-summary-box-inner">
<span><p>Generative models have gained more and more attention in recent years for
their remarkable success in tasks that required estimating and sampling data
distribution to generate high-fidelity synthetic data. In speech,
text-to-speech synthesis and neural vocoder are good examples where generative
models have shined. While generative models have been applied to different
applications in speech, there exists no general-purpose generative model that
models speech directly. In this work, we take a step toward this direction by
showing a single pre-trained generative model can be adapted to different
downstream tasks with strong performance. Specifically, we pre-trained a
generative model, named SpeechFlow, on 60k hours of untranscribed speech with
Flow Matching and masked conditions. Experiment results show the pre-trained
generative model can be fine-tuned with task-specific data to match or surpass
existing expert models on speech enhancement, separation, and synthesis. Our
work suggested a foundational model for generation tasks in speech can be built
with generative pre-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models. (arXiv:2310.16340v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16340">
<div class="article-summary-box-inner">
<span><p>Large language model (LLM) applications in cloud root cause analysis (RCA)
have been actively explored recently. However, current methods are still
reliant on manual workflow settings and do not unleash LLMs' decision-making
and environment interaction capabilities. We present RCAgent, a tool-augmented
LLM autonomous agent framework for practical and privacy-aware industrial RCA
usage. Running on an internally deployed model rather than GPT families,
RCAgent is capable of free-form data collection and comprehensive analysis with
tools. Our framework combines a variety of enhancements, including a unique
Self-Consistency for action trajectories, and a suite of methods for context
management, stabilization, and importing domain knowledge. Our experiments show
RCAgent's evident and consistent superiority over ReAct across all aspects of
RCA -- predicting root causes, solutions, evidence, and responsibilities -- and
tasks covered or uncovered by current rules, as validated by both automated
metrics and human evaluations. Furthermore, RCAgent has already been integrated
into the diagnosis and issue discovery workflow of the Real-time Compute
Platform for Apache Flink of Alibaba Cloud.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Evaluation of Constrained Text Generation for Large Language Models. (arXiv:2310.16343v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16343">
<div class="article-summary-box-inner">
<span><p>Advancements in natural language generation (NLG) and large language models
(LLMs) have led to proficient text generation in various tasks. However,
integrating intricate constraints into neural text generation, due to LLMs'
opacity, remains challenging. This study investigates constrained text
generation for LLMs, where predefined constraints are applied during LLM's
generation process. Our research examines multiple LLMs, including ChatGPT and
GPT-4, categorizing constraints into lexical, structural, and relation-based
types. We also present various benchmarks to facilitate fair evaluation. The
study addresses some key research questions, including the extent of LLMs'
compliance with constraints. Results illuminate LLMs' capacity and deficiency
to incorporate constraints and provide insights for future developments in
constrained text generation. Codes and datasets will be released upon
acceptance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unraveling Feature Extraction Mechanisms in Neural Networks. (arXiv:2310.16350v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16350">
<div class="article-summary-box-inner">
<span><p>The underlying mechanism of neural networks in capturing precise knowledge
has been the subject of consistent research efforts. In this work, we propose a
theoretical approach based on Neural Tangent Kernels (NTKs) to investigate such
mechanisms. Specifically, considering the infinite network width, we
hypothesize the learning dynamics of target models may intuitively unravel the
features they acquire from training data, deepening our insights into their
internal mechanisms. We apply our approach to several fundamental models and
reveal how these models leverage statistical features during gradient descent
and how they are integrated into final decisions. We also discovered that the
choice of activation function can affect feature extraction. For instance, the
use of the \textit{ReLU} activation function could potentially introduce a bias
in features, providing a plausible explanation for its replacement with
alternative functions in recent pre-trained language models. Additionally, we
find that while self-attention and CNN models may exhibit limitations in
learning n-grams, multiplication-based models seem to excel in this area. We
verify these theoretical findings through experiments and find that they can be
applied to analyze language modeling tasks, which can be regarded as a special
variant of classification. Our contributions offer insights into the roles and
capacities of fundamental components within large language models, thereby
aiding the broader understanding of these complex systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multi-Modal Multilingual Benchmark for Document Image Classification. (arXiv:2310.16356v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16356">
<div class="article-summary-box-inner">
<span><p>Document image classification is different from plain-text document
classification and consists of classifying a document by understanding the
content and structure of documents such as forms, emails, and other such
documents. We show that the only existing dataset for this task (Lewis et al.,
2006) has several limitations and we introduce two newly curated multilingual
datasets WIKI-DOC and MULTIEURLEX-DOC that overcome these limitations. We
further undertake a comprehensive study of popular visually-rich document
understanding or Document AI models in previously untested setting in document
image classification such as 1) multi-label classification, and 2) zero-shot
cross-lingual transfer setup. Experimental results show limitations of
multilingual Document AI models on cross-lingual transfer across typologically
distant languages. Our datasets and findings open the door for future research
into improving Document AI models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Simple to Complex: A Progressive Framework for Document-level Informative Argument Extraction. (arXiv:2310.16358v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16358">
<div class="article-summary-box-inner">
<span><p>Document-level Event Argument Extraction (EAE) requires the model to extract
arguments of multiple events from a single document. Considering the underlying
dependencies between these events, recent efforts leverage the idea of
"memory", where the results of already predicted events are cached and can be
retrieved to help the prediction of upcoming events. These methods extract
events according to their appearance order in the document, however, the event
that appears in the first sentence does not mean that it is the easiest to
extract. Existing methods might introduce noise to the extraction of upcoming
events if they rely on an incorrect prediction of previous events. In order to
provide more reliable memory, we propose a simple-to-complex progressive
framework for document-level EAE. Specifically, we first calculate the
difficulty of each event and then, we conduct the extraction following a
simple-to-complex order. In this way, the memory will store the most certain
results, and the model could use these reliable sources to help the prediction
of more difficult events. Experiments on WikiEvents show that our model
outperforms SOTA by 1.4% in F1, indicating the proposed simple-to-complex
framework is useful in the EAE task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InstructPTS: Instruction-Tuning LLMs for Product Title Summarization. (arXiv:2310.16361v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16361">
<div class="article-summary-box-inner">
<span><p>E-commerce product catalogs contain billions of items. Most products have
lengthy titles, as sellers pack them with product attributes to improve
retrieval, and highlight key product aspects. This results in a gap between
such unnatural products titles, and how customers refer to them. It also limits
how e-commerce stores can use these seller-provided titles for recommendation,
QA, or review summarization.
</p>
<p>Inspired by recent work on instruction-tuned LLMs, we present InstructPTS, a
controllable approach for the task of Product Title Summarization (PTS).
Trained using a novel instruction fine-tuning strategy, our approach is able to
summarize product titles according to various criteria (e.g. number of words in
a summary, inclusion of specific phrases, etc.). Extensive evaluation on a
real-world e-commerce catalog shows that compared to simple fine-tuning of
LLMs, our proposed approach can generate more accurate product name summaries,
with an improvement of over 14 and 8 BLEU and ROUGE points, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer-based Live Update Generation for Soccer Matches from Microblog Posts. (arXiv:2310.16368v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16368">
<div class="article-summary-box-inner">
<span><p>It has been known to be difficult to generate adequate sports updates from a
sequence of vast amounts of diverse live tweets, although the live sports
viewing experience with tweets is gaining the popularity. In this paper, we
focus on soccer matches and work on building a system to generate live updates
for soccer matches from tweets so that users can instantly grasp a match's
progress and enjoy the excitement of the match from raw tweets. Our proposed
system is based on a large pre-trained language model and incorporates a
mechanism to control the number of updates and a mechanism to reduce the
redundancy of duplicate and similar updates.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ZGUL: Zero-shot Generalization to Unseen Languages using Multi-source Ensembling of Language Adapters. (arXiv:2310.16393v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16393">
<div class="article-summary-box-inner">
<span><p>We tackle the problem of zero-shot cross-lingual transfer in NLP tasks via
the use of language adapters (LAs). Most of the earlier works have explored
training with adapter of a single source (often English), and testing either
using the target LA or LA of another related language. Training target LA
requires unlabeled data, which may not be readily available for low resource
unseen languages: those that are neither seen by the underlying multilingual
language model (e.g., mBERT), nor do we have any (labeled or unlabeled) data
for them. We posit that for more effective cross-lingual transfer, instead of
just one source LA, we need to leverage LAs of multiple (linguistically or
geographically related) source languages, both at train and test-time - which
we investigate via our novel neural architecture, ZGUL. Extensive
experimentation across four language groups, covering 15 unseen target
languages, demonstrates improvements of up to 3.2 average F1 points over
standard fine-tuning and other strong baselines on POS tagging and NER tasks.
We also extend ZGUL to settings where either (1) some unlabeled data or (2)
few-shot training examples are available for the target language. We find that
ZGUL continues to outperform baselines in these settings too.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video Referring Expression Comprehension via Transformer with Content-conditioned Query. (arXiv:2310.16402v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16402">
<div class="article-summary-box-inner">
<span><p>Video Referring Expression Comprehension (REC) aims to localize a target
object in videos based on the queried natural language. Recent improvements in
video REC have been made using Transformer-based methods with learnable
queries. However, we contend that this naive query design is not ideal given
the open-world nature of video REC brought by text supervision. With numerous
potential semantic categories, relying on only a few slow-updated queries is
insufficient to characterize them. Our solution to this problem is to create
dynamic queries that are conditioned on both the input video and language to
model the diverse objects referred to. Specifically, we place a fixed number of
learnable bounding boxes throughout the frame and use corresponding region
features to provide prior information. Also, we noticed that current query
features overlook the importance of cross-modal alignment. To address this, we
align specific phrases in the sentence with semantically relevant visual areas,
annotating them in existing video datasets (VID-Sentence and VidSTG). By
incorporating these two designs, our proposed model (called ConFormer)
outperforms other models on widely benchmarked datasets. For example, in the
testing split of VID-Sentence dataset, ConFormer achieves 8.75% absolute
improvement on Accu.@0.6 compared to the previous state-of-the-art model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decoding Stumpers: Large Language Models vs. Human Problem-Solvers. (arXiv:2310.16411v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16411">
<div class="article-summary-box-inner">
<span><p>This paper investigates the problem-solving capabilities of Large Language
Models (LLMs) by evaluating their performance on stumpers, unique single-step
intuition problems that pose challenges for human solvers but are easily
verifiable. We compare the performance of four state-of-the-art LLMs
(Davinci-2, Davinci-3, GPT-3.5-Turbo, GPT-4) to human participants. Our
findings reveal that the new-generation LLMs excel in solving stumpers and
surpass human performance. However, humans exhibit superior skills in verifying
solutions to the same problems. This research enhances our understanding of
LLMs' cognitive abilities and provides insights for enhancing their
problem-solving potential across various domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhanced Simultaneous Machine Translation with Word-level Policies. (arXiv:2310.16417v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16417">
<div class="article-summary-box-inner">
<span><p>Recent years have seen remarkable advances in the field of Simultaneous
Machine Translation (SiMT) due to the introduction of innovative policies that
dictate whether to READ or WRITE at each step of the translation process.
However, a common assumption in many existing studies is that operations are
carried out at the subword level, even though the standard unit for input and
output in most practical scenarios is typically at the word level. This paper
demonstrates that policies devised and validated at the subword level are
surpassed by those operating at the word level, which process multiple subwords
to form a complete word in a single step. Additionally, we suggest a method to
boost SiMT models using language models (LMs), wherein the proposed word-level
policy plays a vital role in addressing the subword disparity between LMs and
SiMT models. Code is available at https://github.com/xl8-ai/WordSiMT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization. (arXiv:2310.16427v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16427">
<div class="article-summary-box-inner">
<span><p>Highly effective, task-specific prompts are often heavily engineered by
experts to integrate detailed instructions and domain insights based on a deep
understanding of both instincts of large language models (LLMs) and the
intricacies of the target task. However, automating the generation of such
expert-level prompts remains elusive. Existing prompt optimization methods tend
to overlook the depth of domain knowledge and struggle to efficiently explore
the vast space of expert-level prompts. Addressing this, we present
PromptAgent, an optimization method that autonomously crafts prompts equivalent
in quality to those handcrafted by experts. At its core, PromptAgent views
prompt optimization as a strategic planning problem and employs a principled
planning algorithm, rooted in Monte Carlo tree search, to strategically
navigate the expert-level prompt space. Inspired by human-like trial-and-error
exploration, PromptAgent induces precise expert-level insights and in-depth
instructions by reflecting on model errors and generating constructive error
feedback. Such a novel framework allows the agent to iteratively examine
intermediate prompts (states), refine them based on error feedbacks (actions),
simulate future rewards, and search for high-reward paths leading to expert
prompts. We apply PromptAgent to 12 tasks spanning three practical domains:
BIG-Bench Hard (BBH), as well as domain-specific and general NLP tasks, showing
it significantly outperforms strong Chain-of-Thought and recent prompt
optimization baselines. Extensive analyses emphasize its capability to craft
expert-level, detailed, and domain-insightful prompts with great efficiency and
generalizability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models. (arXiv:2310.16436v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16436">
<div class="article-summary-box-inner">
<span><p>A long-standing goal of AI systems is to perform complex multimodal reasoning
like humans. Recently, large language models (LLMs) have made remarkable
strides in such multi-step reasoning on the language modality solely by
leveraging the chain of thought (CoT) to mimic human thinking. However, the
transfer of these advancements to multimodal contexts introduces heightened
challenges, including but not limited to the impractical need for
labor-intensive annotation and the limitations in terms of flexibility,
generalizability, and explainability. To evoke CoT reasoning in multimodality,
this work first conducts an in-depth analysis of these challenges posed by
multimodality and presents two key insights: "keeping critical thinking" and
"letting everyone do their jobs" in multimodal CoT reasoning. Furthermore, this
study proposes a novel DDCoT prompting that maintains a critical attitude
through negative-space prompting and incorporates multimodality into reasoning
by first dividing the reasoning responsibility of LLMs into reasoning and
recognition and then integrating the visual recognition capability of visual
models into the joint reasoning process. The rationales generated by DDCoT not
only improve the reasoning abilities of both large and small language models in
zero-shot prompting and fine-tuning learning, significantly outperforming
state-of-the-art methods but also exhibit impressive generalizability and
explainability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diversity Enhanced Narrative Question Generation for Storybooks. (arXiv:2310.16446v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16446">
<div class="article-summary-box-inner">
<span><p>Question generation (QG) from a given context can enhance comprehension,
engagement, assessment, and overall efficacy in learning or conversational
environments. Despite recent advancements in QG, the challenge of enhancing or
measuring the diversity of generated questions often remains unaddressed. In
this paper, we introduce a multi-question generation model (mQG), which is
capable of generating multiple, diverse, and answerable questions by focusing
on context and questions. To validate the answerability of the generated
questions, we employ a SQuAD2.0 fine-tuned question answering model,
classifying the questions as answerable or not. We train and evaluate mQG on
the FairytaleQA dataset, a well-structured QA dataset based on storybooks, with
narrative questions. We further apply a zero-shot adaptation on the TellMeWhy
and SQuAD1.1 datasets. mQG shows promising results across various evaluation
metrics, among strong baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLEX: Continuous Length Extrapolation for Large Language Models. (arXiv:2310.16450v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16450">
<div class="article-summary-box-inner">
<span><p>Transformer-based Large Language Models (LLMs) are pioneering advances in
many natural language processing tasks, however, their exceptional capabilities
are restricted within the preset context window of Transformer. Position
Embedding (PE) scaling methods, while effective in extending the context window
to a specific length, demonstrate either notable limitations in their
extrapolation abilities or sacrificing partial performance within the context
window. Length extrapolation methods, although theoretically capable of
extending the context window beyond the training sequence length, often
underperform in practical long-context applications. To address these
challenges, we propose Continuous Length EXtrapolation (CLEX) for LLMs. We
generalise the PE scaling approaches to model the continuous dynamics by
ordinary differential equations over the length scaling factor, thereby
overcoming the constraints of current PE scaling methods designed for specific
lengths. Moreover, by extending the dynamics to desired context lengths beyond
the training sequence length, CLEX facilitates the length extrapolation with
impressive performance in practical tasks. We demonstrate that CLEX can be
seamlessly incorporated into LLMs equipped with Rotary Position Embedding, such
as LLaMA and GPT-NeoX, with negligible impact on training and inference
latency. Experimental results reveal that CLEX can effectively extend the
context window to over 4x or almost 8x training length, with no deterioration
in performance. Furthermore, when evaluated on the practical LongBench
benchmark, our model trained on a 4k length exhibits competitive performance
against state-of-the-art open-source models trained on context lengths up to
32k.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Subspace Chronicles: How Linguistic Information Emerges, Shifts and Interacts during Language Model Training. (arXiv:2310.16484v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16484">
<div class="article-summary-box-inner">
<span><p>Representational spaces learned via language modeling are fundamental to
Natural Language Processing (NLP), however there has been limited understanding
regarding how and when during training various types of linguistic information
emerge and interact. Leveraging a novel information theoretic probing suite,
which enables direct comparisons of not just task performance, but their
representational subspaces, we analyze nine tasks covering syntax, semantics
and reasoning, across 2M pre-training steps and five seeds. We identify
critical learning phases across tasks and time, during which subspaces emerge,
share information, and later disentangle to specialize. Across these phases,
syntactic knowledge is acquired rapidly after 0.5% of full training. Continued
performance improvements primarily stem from the acquisition of open-domain
knowledge, while semantics and reasoning tasks benefit from later boosts to
long-range contextualization and higher specialization. Measuring cross-task
similarity further reveals that linguistically related tasks share information
throughout training, and do so more during the critical phase of learning than
before or after. Our findings have implications for model interpretability,
multi-task learning, and learning from limited data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OccuQuest: Mitigating Occupational Bias for Inclusive Large Language Models. (arXiv:2310.16517v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16517">
<div class="article-summary-box-inner">
<span><p>The emergence of large language models (LLMs) has revolutionized natural
language processing tasks. However, existing instruction-tuning datasets suffer
from occupational bias: the majority of data relates to only a few occupations,
which hampers the instruction-tuned LLMs to generate helpful responses to
professional queries from practitioners in specific fields. To mitigate this
issue and promote occupation-inclusive LLMs, we create an instruction-tuning
dataset named \emph{OccuQuest}, which contains 110,000+ prompt-completion pairs
and 30,000+ dialogues covering over 1,000 occupations in 26 occupational
categories. We systematically request ChatGPT, organizing queries
hierarchically based on Occupation, Responsibility, Topic, and Question, to
ensure a comprehensive coverage of occupational specialty inquiries. By
comparing with three commonly used datasets (Dolly, ShareGPT, and WizardLM), we
observe that OccuQuest exhibits a more balanced distribution across
occupations. Furthermore, we assemble three test sets for comprehensive
evaluation, an occu-test set covering 25 occupational categories, an estate set
focusing on real estate, and an occu-quora set containing real-world questions
from Quora. We then fine-tune LLaMA on OccuQuest to obtain OccuLLaMA, which
significantly outperforms state-of-the-art LLaMA variants (Vicuna, Tulu, and
WizardLM) on professional questions in GPT-4 and human evaluations. Notably, on
the occu-quora set, OccuLLaMA reaches a high win rate of 86.4\% against
WizardLM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting. (arXiv:2310.16523v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16523">
<div class="article-summary-box-inner">
<span><p>A crucial challenge for generative large language models (LLMs) is diversity:
when a user's prompt is under-specified, models may follow implicit assumptions
while generating a response, which may result in homogenization of the
responses, as well as certain demographic groups being under-represented or
even erased from the generated responses. In this paper, we formalize diversity
of representation in generative LLMs. We present evaluation datasets and
propose metrics to measure diversity in generated responses along people and
culture axes. We find that LLMs understand the notion of diversity, and that
they can reason and critique their own responses for that goal. This finding
motivated a new prompting technique called collective-critique and self-voting
(CCSV) to self-improve people diversity of LLMs by tapping into its diversity
reasoning capabilities, without relying on handcrafted examples or prompt
tuning. Extensive empirical experiments with both human and automated
evaluations show that our proposed approach is effective at improving people
and culture diversity, and outperforms all baseline methods by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CUNI Submission to MRL 2023 Shared Task on Multi-lingual Multi-task Information Retrieval. (arXiv:2310.16528v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16528">
<div class="article-summary-box-inner">
<span><p>We present the Charles University system for the MRL~2023 Shared Task on
Multi-lingual Multi-task Information Retrieval. The goal of the shared task was
to develop systems for named entity recognition and question answering in
several under-represented languages. Our solutions to both subtasks rely on the
translate-test approach. We first translate the unlabeled examples into English
using a multilingual machine translation model. Then, we run inference on the
translated data using a strong task-specific model. Finally, we project the
labeled data back into the original language. To keep the inferred tags on the
correct positions in the original language, we propose a method based on
scoring the candidate positions using a label-sensitive translation model. In
both settings, we experiment with finetuning the classification models on the
translated data. However, due to a domain mismatch between the development data
and the shared task validation and test sets, the finetuned models could not
outperform our baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Early Evaluation of GPT-4V(ision). (arXiv:2310.16534v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16534">
<div class="article-summary-box-inner">
<span><p>In this paper, we evaluate different abilities of GPT-4V including visual
understanding, language understanding, visual puzzle solving, and understanding
of other modalities such as depth, thermal, video, and audio. To estimate
GPT-4V's performance, we manually construct 656 test instances and carefully
evaluate the results of GPT-4V. The highlights of our findings are as follows:
(1) GPT-4V exhibits impressive performance on English visual-centric benchmarks
but fails to recognize simple Chinese texts in the images; (2) GPT-4V shows
inconsistent refusal behavior when answering questions related to sensitive
traits such as gender, race, and age; (3) GPT-4V obtains worse results than
GPT-4 (API) on language understanding tasks including general language
understanding benchmarks and visual commonsense knowledge evaluation
benchmarks; (4) Few-shot prompting can improve GPT-4V's performance on both
visual understanding and language understanding; (5) GPT-4V struggles to find
the nuances between two similar images and solve the easy math picture puzzles;
(6) GPT-4V shows non-trivial performance on the tasks of similar modalities to
image, such as video and thermal. Our experimental results reveal the ability
and limitations of GPT-4V and we hope our paper can provide some insights into
the application and research of GPT-4V.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">R$^3$ Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context. (arXiv:2310.16535v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16535">
<div class="article-summary-box-inner">
<span><p>With the help of Chain-of-Thought (CoT) prompting, Large Language Models
(LLMs) have achieved remarkable performance on various reasoning tasks.
However, most of them have been evaluated under noise-free context and the
dilemma for LLMs to produce inaccurate results under the noisy context has not
been fully investigated. Existing studies utilize trigger sentences to
encourage LLMs to concentrate on the relevant information but the trigger has
limited effect on final answer prediction. Inspired by interactive CoT method,
where intermediate reasoning steps are promoted by multiple rounds of
interaction between users and LLMs, we propose a novel prompting method, namely
R$^3$ prompting, for CoT reasoning under noisy context. Specifically, R$^3$
prompting interacts with LLMs to perform key sentence extraction, variable
declaration and answer prediction, which corresponds to a thought process of
reviewing, rephrasing and resolving. The responses generated at the last
interaction will perform as hints to guide toward the responses of the next
interaction. Our experiments show that R$^3$ prompting significantly
outperforms existing CoT prompting methods on five reasoning tasks under noisy
context. With GPT-3.5-turbo, we observe 3.7% accuracy improvement on average on
the reasoning tasks under noisy context compared to the most competitive
prompting baseline. More analyses and ablation studies show the robustness and
generalization of R$^3$ prompting method in solving reasoning tasks in LLMs
under noisy context.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FedTherapist: Mental Health Monitoring with User-Generated Linguistic Expressions on Smartphones via Federated Learning. (arXiv:2310.16538v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16538">
<div class="article-summary-box-inner">
<span><p>Psychiatrists diagnose mental disorders via the linguistic use of patients.
Still, due to data privacy, existing passive mental health monitoring systems
use alternative features such as activity, app usage, and location via mobile
devices. We propose FedTherapist, a mobile mental health monitoring system that
utilizes continuous speech and keyboard input in a privacy-preserving way via
federated learning. We explore multiple model designs by comparing their
performance and overhead for FedTherapist to overcome the complex nature of
on-device language model training on smartphones. We further propose a
Context-Aware Language Learning (CALL) methodology to effectively utilize
smartphones' large and noisy text for mental health signal sensing. Our
IRB-approved evaluation of the prediction of self-reported depression, stress,
anxiety, and mood from 46 participants shows higher accuracy of FedTherapist
compared with the performance with non-language features, achieving 0.15 AUROC
improvement and 8.21% MAE reduction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">1-PAGER: One Pass Answer Generation and Evidence Retrieval. (arXiv:2310.16568v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16568">
<div class="article-summary-box-inner">
<span><p>We present 1-Pager the first system that answers a question and retrieves
evidence using a single Transformer-based model and decoding process. 1-Pager
incrementally partitions the retrieval corpus using constrained decoding to
select a document and answer string, and we show that this is competitive with
comparable retrieve-and-read alternatives according to both retrieval and
answer accuracy metrics. 1-Pager also outperforms the equivalent closed-book
question answering model, by grounding predictions in an evidence corpus. While
1-Pager is not yet on-par with more expensive systems that read many more
documents before generating an answer, we argue that it provides an important
step toward attributed generation by folding retrieval into the
sequence-to-sequence paradigm that is currently dominant in NLP. We also show
that the search paths used to partition the corpus are easy to read and
understand, paving a way forward for interpretable neural retrieval.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained Language Models. (arXiv:2310.16570v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16570">
<div class="article-summary-box-inner">
<span><p>Pre-trained Language Models (PLMs) are trained on vast unlabeled data, rich
in world knowledge. This fact has sparked the interest of the community in
quantifying the amount of factual knowledge present in PLMs, as this explains
their performance on downstream tasks, and potentially justifies their use as
knowledge bases. In this work, we survey methods and datasets that are used to
probe PLMs for factual knowledge. Our contributions are: (1) We propose a
categorization scheme for factual probing methods that is based on how their
inputs, outputs and the probed PLMs are adapted; (2) We provide an overview of
the datasets used for factual probing; (3) We synthesize insights about
knowledge retention and prompt optimization in PLMs, analyze obstacles to
adopting PLMs as knowledge bases and outline directions for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WSDMS: Debunk Fake News via Weakly Supervised Detection of Misinforming Sentences with Contextualized Social Wisdom. (arXiv:2310.16579v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16579">
<div class="article-summary-box-inner">
<span><p>In recent years, we witness the explosion of false and unconfirmed
information (i.e., rumors) that went viral on social media and shocked the
public. Rumors can trigger versatile, mostly controversial stance expressions
among social media users. Rumor verification and stance detection are different
yet relevant tasks. Fake news debunking primarily focuses on determining the
truthfulness of news articles, which oversimplifies the issue as fake news
often combines elements of both truth and falsehood. Thus, it becomes crucial
to identify specific instances of misinformation within the articles. In this
research, we investigate a novel task in the field of fake news debunking,
which involves detecting sentence-level misinformation. One of the major
challenges in this task is the absence of a training dataset with
sentence-level annotations regarding veracity. Inspired by the Multiple
Instance Learning (MIL) approach, we propose a model called Weakly Supervised
Detection of Misinforming Sentences (WSDMS). This model only requires bag-level
labels for training but is capable of inferring both sentence-level
misinformation and article-level veracity, aided by relevant social media
conversations that are attentively contextualized with news sentences. We
evaluate WSDMS on three real-world benchmarks and demonstrate that it
outperforms existing state-of-the-art baselines in debunking fake news at both
the sentence and article levels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tailoring Personality Traits in Large Language Models via Unsupervisedly-Built Personalized Lexicons. (arXiv:2310.16582v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16582">
<div class="article-summary-box-inner">
<span><p>Personality plays a pivotal role in shaping human expression patterns, and
empowering and manipulating large language models (LLMs) with personality
traits holds significant promise in enhancing the user experience of LLMs.
However, prior approaches either rely on fine-tuning LLMs on a corpus enriched
with personalized expressions or necessitate the manual crafting of prompts to
induce LLMs to produce personalized responses. The former approaches demand
substantial time and resources for collecting sufficient training examples
while the latter might fail in enabling the precise manipulation of the
personality traits at a fine-grained level (e.g., achieving high agreeableness
while reducing openness). In this study, we introduce a novel approach for
tailoring personality traits within LLMs, allowing for the incorporation of any
combination of the Big Five factors (i.e., openness, conscientiousness,
extraversion, agreeableness, and neuroticism) in a pluggable manner. This is
achieved by employing a set of Unsupervisedly-Built Personalized Lexicons
(UBPL) that are utilized to adjust the probability of the next token predicted
by the original LLMs during the decoding phase. This adjustment encourages the
models to generate words present in the personalized lexicons while preserving
the naturalness of the generated texts. Extensive experimentation demonstrates
the effectiveness of our approach in finely manipulating LLMs' personality
traits. Furthermore, our method can be seamlessly integrated into other LLMs
without necessitating updates to their parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Interplay between Fairness and Explainability. (arXiv:2310.16607v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16607">
<div class="article-summary-box-inner">
<span><p>In order to build reliable and trustworthy NLP applications, models need to
be both fair across different demographics and explainable. Usually these two
objectives, fairness and explainability, are optimized and/or examined
independently of each other. Instead, we argue that forthcoming, trustworthy
NLP systems should consider both. In this work, we perform a first study to
understand how they influence each other: do fair(er) models rely on more
plausible rationales? and vice versa. To this end, we conduct experiments on
two English multi-class text classification datasets, BIOS and ECtHR, that
provide information on gender and nationality, respectively, as well as
human-annotated rationales. We fine-tune pre-trained language models with
several methods for (i) bias mitigation, which aims to improve fairness; (ii)
rationale extraction, which aims to produce plausible explanations. We find
that bias mitigation algorithms do not always lead to fairer models. Moreover,
we discover that empirical fairness and explainability are orthogonal.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Back Transcription as a Method for Evaluating Robustness of Natural Language Understanding Models to Speech Recognition Errors. (arXiv:2310.16609v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16609">
<div class="article-summary-box-inner">
<span><p>In a spoken dialogue system, an NLU model is preceded by a speech recognition
system that can deteriorate the performance of natural language understanding.
This paper proposes a method for investigating the impact of speech recognition
errors on the performance of natural language understanding models. The
proposed method combines the back transcription procedure with a fine-grained
technique for categorizing the errors that affect the performance of NLU
models. The method relies on the usage of synthesized speech for NLU
evaluation. We show that the use of synthesized speech in place of audio
recording does not change the outcomes of the presented technique in a
significant way.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Context Does Matter: End-to-end Panoptic Narrative Grounding with Deformable Attention Refined Matching Network. (arXiv:2310.16616v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16616">
<div class="article-summary-box-inner">
<span><p>Panoramic Narrative Grounding (PNG) is an emerging visual grounding task that
aims to segment visual objects in images based on dense narrative captions. The
current state-of-the-art methods first refine the representation of phrase by
aggregating the most similar $k$ image pixels, and then match the refined text
representations with the pixels of the image feature map to generate
segmentation results. However, simply aggregating sampled image features
ignores the contextual information, which can lead to phrase-to-pixel
mis-match. In this paper, we propose a novel learning framework called
Deformable Attention Refined Matching Network (DRMN), whose main idea is to
bring deformable attention in the iterative process of feature learning to
incorporate essential context information of different scales of pixels. DRMN
iteratively re-encodes pixels with the deformable attention network after
updating the feature representation of the top-$k$ most similar pixels. As
such, DRMN can lead to accurate yet discriminative pixel representations,
purify the top-$k$ most similar pixels, and consequently alleviate the
phrase-to-pixel mis-match substantially.Experimental results show that our
novel design significantly improves the matching results between text phrases
and image pixels. Concretely, DRMN achieves new state-of-the-art performance on
the PNG benchmark with an average recall improvement 3.5%. The codes are
available in: https://github.com/JaMesLiMers/DRMN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ArTST: Arabic Text and Speech Transformer. (arXiv:2310.16621v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16621">
<div class="article-summary-box-inner">
<span><p>We present ArTST, a pre-trained Arabic text and speech transformer for
supporting open-source speech technologies for the Arabic language. The model
architecture follows the unified-modal framework, SpeechT5, that was recently
released for English, and is focused on Modern Standard Arabic (MSA), with
plans to extend the model for dialectal and code-switched Arabic in future
editions. We pre-trained the model from scratch on MSA speech and text data,
and fine-tuned it for the following tasks: Automatic Speech Recognition (ASR),
Text-To-Speech synthesis (TTS), and spoken dialect identification. In our
experiments comparing ArTST with SpeechT5, as well as with previously reported
results in these tasks, ArTST performs on a par with or exceeding the current
state-of-the-art in all three tasks. Moreover, we find that our pre-training is
conducive for generalization, which is particularly evident in the low-resource
TTS task. The pre-trained model as well as the fine-tuned ASR and TTS models
are released for research use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT is a Potential Zero-Shot Dependency Parser. (arXiv:2310.16654v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16654">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models have been widely used in dependency parsing task
and have achieved significant improvements in parser performance. However, it
remains an understudied question whether pre-trained language models can
spontaneously exhibit the ability of dependency parsing without introducing
additional parser structure in the zero-shot scenario. In this paper, we
propose to explore the dependency parsing ability of large language models such
as ChatGPT and conduct linguistic analysis. The experimental results
demonstrate that ChatGPT is a potential zero-shot dependency parser, and the
linguistic analysis also shows some unique preferences in parsing outputs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SSLCL: An Efficient Model-Agnostic Supervised Contrastive Learning Framework for Emotion Recognition in Conversations. (arXiv:2310.16676v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16676">
<div class="article-summary-box-inner">
<span><p>Emotion recognition in conversations (ERC) is a rapidly evolving task within
the natural language processing community, which aims to detect the emotions
expressed by speakers during a conversation. Recently, a growing number of ERC
methods have focused on leveraging supervised contrastive learning (SCL) to
enhance the robustness and generalizability of learned features. However,
current SCL-based approaches in ERC are impeded by the constraint of large
batch sizes and the lack of compatibility with most existing ERC models. To
address these challenges, we propose an efficient and model-agnostic SCL
framework named Supervised Sample-Label Contrastive Learning with Soft-HGR
Maximal Correlation (SSLCL), which eliminates the need for a large batch size
and can be seamlessly integrated with existing ERC models without introducing
any model-specific assumptions. Specifically, we introduce a novel perspective
on utilizing label representations by projecting discrete labels into dense
embeddings through a shallow multilayer perceptron, and formulate the training
objective to maximize the similarity between sample features and their
corresponding ground-truth label embeddings, while minimizing the similarity
between sample features and label embeddings of disparate classes. Moreover, we
innovatively adopt the Soft-HGR maximal correlation as a measure of similarity
between sample features and label embeddings, leading to significant
performance improvements over conventional similarity measures. Additionally,
multimodal cues of utterances are effectively leveraged by SSLCL as data
augmentations to boost model performances. Extensive experiments on two ERC
benchmark datasets, IEMOCAP and MELD, demonstrate the compatibility and
superiority of our proposed SSLCL framework compared to existing
state-of-the-art SCL methods. Our code is available at
\url{https://github.com/TaoShi1998/SSLCL}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPT Understands, Too. (arXiv:2103.10385v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10385">
<div class="article-summary-box-inner">
<span><p>Prompting a pretrained language model with natural language patterns has been
proved effective for natural language understanding (NLU). However, our
preliminary study reveals that manual discrete prompts often lead to unstable
performance -- e.g., changing a single word in the prompt might result in
substantial performance drop. We propose a novel method P-Tuning that employs
trainable continuous prompt embeddings in concatenation with discrete prompts.
Empirically, P-Tuning not only stabilizes training by minimizing the gap
between various discrete prompts, but also improves performance by a sizeable
margin on a wide range of NLU tasks including LAMA and SuperGLUE. P-Tuning is
generally effective for both frozen and tuned language models, under both the
fully-supervised and few-shot settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Targeted Assessment of Incremental Processing in Neural LanguageModels and Humans. (arXiv:2106.03232v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03232">
<div class="article-summary-box-inner">
<span><p>We present a targeted, scaled-up comparison of incremental processing in
humans and neural language models by collecting by-word reaction time data for
sixteen different syntactic test suites across a range of structural phenomena.
Human reaction time data comes from a novel online experimental paradigm called
the Interpolated Maze task. We compare human reaction times to by-word
probabilities for four contemporary language models, with different
architectures and trained on a range of data set sizes. We find that across
many phenomena, both humans and language models show increased processing
difficulty in ungrammatical sentence regions with human and model `accuracy'
scores (a la Marvin and Linzen(2018)) about equal. However, although language
model outputs match humans in direction, we show that models systematically
under-predict the difference in magnitude of incremental processing difficulty
between grammatical and ungrammatical sentences. Specifically, when models
encounter syntactic violations they fail to accurately predict the longer
reaction times observed in the human data. These results call into question
whether contemporary language models are approaching human-like performance for
sensitivity to syntactic violations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is Attention always needed? A Case Study on Language Identification from Speech. (arXiv:2110.03427v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03427">
<div class="article-summary-box-inner">
<span><p>Language Identification (LID) is a crucial preliminary process in the field
of Automatic Speech Recognition (ASR) that involves the identification of a
spoken language from audio samples. Contemporary systems that can process
speech in multiple languages require users to expressly designate one or more
languages prior to utilization. The LID task assumes a significant role in
scenarios where ASR systems are unable to comprehend the spoken language in
multilingual settings, leading to unsuccessful speech recognition outcomes. The
present study introduces convolutional recurrent neural network (CRNN) based
LID, designed to operate on the Mel-frequency Cepstral Coefficient (MFCC)
characteristics of audio samples. Furthermore, we replicate certain
state-of-the-art methodologies, specifically the Convolutional Neural Network
(CNN) and Attention-based Convolutional Recurrent Neural Network (CRNN with
attention), and conduct a comparative analysis with our CRNN-based approach. We
conducted comprehensive evaluations on thirteen distinct Indian languages and
our model resulted in over 98\% classification accuracy. The LID model exhibits
high-performance levels ranging from 97% to 100% for languages that are
linguistically similar. The proposed LID model exhibits a high degree of
extensibility to additional languages and demonstrates a strong resistance to
noise, achieving 91.2% accuracy in a noisy setting when applied to a European
Language (EU) dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GLM-130B: An Open Bilingual Pre-trained Model. (arXiv:2210.02414v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.02414">
<div class="article-summary-box-inner">
<span><p>We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language
model with 130 billion parameters. It is an attempt to open-source a 100B-scale
model at least as good as GPT-3 (davinci) and unveil how models of such a scale
can be successfully pre-trained. Over the course of this effort, we face
numerous unexpected technical and engineering challenges, particularly on loss
spikes and divergence. In this paper, we introduce the training process of
GLM-130B including its design choices, training strategies for both efficiency
and stability, and engineering efforts. The resultant GLM-130B model offers
significant outperformance over GPT-3 175B (davinci) on a wide range of popular
English benchmarks while the performance advantage is not observed in OPT-175B
and BLOOM-176B. It also consistently and significantly outperforms ERNIE TITAN
3.0 260B -- the largest Chinese language model -- across related benchmarks.
Finally, we leverage a unique scaling property of GLM-130B to reach INT4
quantization without post training, with almost no performance loss, making it
the first among 100B-scale models and more importantly, allowing its effective
inference on 4$\times$RTX 3090 (24G) or 8$\times$RTX 2080 Ti (11G) GPUs, the
most affordable GPUs required for using 100B-scale models. The GLM-130B model
weights are publicly accessible and its code, training logs, related toolkit,
and lessons learned are open-sourced at
\url{https://github.com/THUDM/GLM-130B/}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What to Read in a Contract? Party-Specific Summarization of Legal Obligations, Entitlements, and Prohibitions. (arXiv:2212.09825v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09825">
<div class="article-summary-box-inner">
<span><p>Reviewing and comprehending key obligations, entitlements, and prohibitions
in legal contracts can be a tedious task due to their length and
domain-specificity. Furthermore, the key rights and duties requiring review
vary for each contracting party. In this work, we propose a new task of
party-specific extractive summarization for legal contracts to facilitate
faster reviewing and improved comprehension of rights and duties. To facilitate
this, we curate a dataset comprising of party-specific pairwise importance
comparisons annotated by legal experts, covering ~293K sentence pairs that
include obligations, entitlements, and prohibitions extracted from lease
agreements. Using this dataset, we train a pairwise importance ranker and
propose a pipeline-based extractive summarization system that generates a
party-specific contract summary. We establish the need for incorporating
domain-specific notion of importance during summarization by comparing our
system against various baselines using both automatic and human evaluation
methods
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tokenization Consistency Matters for Generative Models on Extractive NLP Tasks. (arXiv:2212.09912v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09912">
<div class="article-summary-box-inner">
<span><p>Generative models have been widely applied to solve extractive tasks, where
parts of the input is extracted to form the desired output, and achieved
significant success. For example, in extractive question answering (QA),
generative models have constantly yielded state-of-the-art results. In this
work, we identify the issue of tokenization inconsistency that is commonly
neglected in training these models. This issue damages the extractive nature of
these tasks after the input and output are tokenized inconsistently by the
tokenizer, and thus leads to performance drop as well as hallucination. We
propose a simple yet effective fix to this issue and conduct a case study on
extractive QA. We show that, with consistent tokenization, the model performs
better in both in-domain and out-of-domain datasets, with a notable average of
+1.7 F2 gain when a BART model is trained on SQuAD and evaluated on 8 QA
datasets. Further, the model converges faster, and becomes less likely to
generate out-of-context answers. With these findings, we would like to call for
more attention on how tokenization should be done when solving extractive tasks
and recommend applying consistent tokenization during training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open Domain Multi-document Summarization: A Comprehensive Study of Model Brittleness under Retrieval. (arXiv:2212.10526v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10526">
<div class="article-summary-box-inner">
<span><p>Multi-document summarization (MDS) assumes a set of topic-related documents
are provided as input. In practice, this document set is not always available;
it would need to be retrieved given an information need, i.e. a question or
topic statement, a setting we dub "open-domain" MDS. We study this more
challenging setting by formalizing the task and bootstrapping it using existing
datasets, retrievers and summarizers. Via extensive automatic and human
evaluation, we determine: (1) state-of-the-art summarizers suffer large
reductions in performance when applied to open-domain MDS, (2) additional
training in the open-domain setting can reduce this sensitivity to imperfect
retrieval, and (3) summarizers are insensitive to the retrieval of duplicate
documents and the order of retrieved documents, but highly sensitive to other
errors, like the retrieval of irrelevant documents. Based on our results, we
provide practical guidelines to enable future work on open-domain MDS, e.g. how
to choose the number of retrieved documents to summarize. Our results suggest
that new retrieval and summarization methods and annotated resources for
training and evaluation are necessary for further progress in the open-domain
setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">JASMINE: Arabic GPT Models for Few-Shot Learning. (arXiv:2212.10755v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10755">
<div class="article-summary-box-inner">
<span><p>Scholarship on generative pretraining (GPT) remains acutely Anglocentric,
leaving serious gaps in our understanding of the whole class of autoregressive
models. For example, we have little knowledge about the potential of these
models and their societal impacts in diverse linguistic and cultural settings.
We alleviate this issue for Arabic, a wide collection of languages and
dialectal varieties with more than 400 million population, by introducing
JASMINE. JASMINE is a suite of powerful Arabic autoregressive Transformer
language models ranging in size between 300 million-6.7 billion parameters
pretrained on a large and diverse dataset (~ 235 GB of text). We also carefully
design and release a comprehensive benchmark for both automated and human
evaluation of Arabic autoregressive models, with coverage of potential social
biases, harms, and toxicity. Using our novel benchmark, we evaluate JASMINE
extensively showing powerful performance intrinsically as well as in few-shot
learning on a wide range of NLP tasks. We aim to responsibly release our models
and evaluation benchmark with interested researchers, along with code for
experimenting with them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Distillation $\approx$ Label Smoothing: Fact or Fallacy?. (arXiv:2301.12609v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.12609">
<div class="article-summary-box-inner">
<span><p>Originally proposed as a method for knowledge transfer from one model to
another, some recent studies have suggested that knowledge distillation (KD) is
in fact a form of regularization. Perhaps the strongest argument of all for
this new perspective comes from its apparent similarities with label smoothing
(LS). Here we re-examine this stated equivalence between the two methods by
comparing the predictive confidences of the models they train. Experiments on
four text classification tasks involving models of different sizes show that:
(a) In most settings, KD and LS drive model confidence in completely opposite
directions, and (b) In KD, the student inherits not only its knowledge but also
its confidence from the teacher, reinforcing the classical knowledge transfer
view.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Goal Driven Discovery of Distributional Differences via Language Descriptions. (arXiv:2302.14233v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.14233">
<div class="article-summary-box-inner">
<span><p>Mining large corpora can generate useful discoveries but is time-consuming
for humans. We formulate a new task, D5, that automatically discovers
differences between two large corpora in a goal-driven way. The task input is a
problem comprising a research goal "$\textit{comparing the side effects of drug
A and drug B}$" and a corpus pair (two large collections of patients'
self-reported reactions after taking each drug). The output is a language
description (discovery) of how these corpora differ (patients taking drug A
"$\textit{mention feelings of paranoia}$" more often). We build a D5 system,
and to quantitatively measure its performance, we 1) contribute a meta-dataset,
OpenD5, aggregating 675 open-ended problems ranging across business, social
sciences, humanities, machine learning, and health, and 2) propose a set of
unified evaluation metrics: validity, relevance, novelty, and significance.
With the dataset and the unified metrics, we confirm that language models can
use the goals to propose more relevant, novel, and significant candidate
discoveries. Finally, our system produces discoveries previously unknown to the
authors on a wide range of applications in OpenD5, including temporal and
demographic differences in discussion topics, political stances and stereotypes
in speech, insights in commercial reviews, and error patterns in NLP models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs. (arXiv:2304.08244v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.08244">
<div class="article-summary-box-inner">
<span><p>Recent research has demonstrated that Large Language Models (LLMs) can
enhance their capabilities by utilizing external tools. However, three pivotal
questions remain unanswered: (1) How effective are current LLMs in utilizing
tools? (2) How can we enhance LLMs' ability to utilize tools? (3) What
obstacles need to be overcome to leverage tools? To address these questions, we
introduce API-Bank, a groundbreaking benchmark, specifically designed for
tool-augmented LLMs. For the first question, we develop a runnable evaluation
system consisting of 73 API tools. We annotate 314 tool-use dialogues with 753
API calls to assess the existing LLMs' capabilities in planning, retrieving,
and calling APIs. For the second question, we construct a comprehensive
training set containing 1,888 tool-use dialogues from 2,138 APIs spanning 1,000
distinct domains. Using this dataset, we train Lynx, a tool-augmented LLM
initialized from Alpaca. Experimental results demonstrate that GPT-3.5 exhibits
improved tool utilization compared to GPT-3, while GPT-4 excels in planning.
However, there is still significant potential for further improvement.
Moreover, Lynx surpasses Alpaca's tool utilization performance by more than 26
pts and approaches the effectiveness of GPT-3.5. Through error analysis, we
highlight the key challenges for future research in this field to answer the
third question.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StrAE: Autoencoding for Pre-Trained Embeddings using Explicit Structure. (arXiv:2305.05588v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05588">
<div class="article-summary-box-inner">
<span><p>This work presents StrAE: a Structured Autoencoder framework that through
strict adherence to explicit structure, and use of a novel contrastive
objective over tree-structured representations, enables effective learning of
multi-level representations. Through comparison over different forms of
structure, we verify that our results are directly attributable to the
informativeness of the structure provided as input, and show that this is not
the case for existing tree models. We then further extend StrAE to allow the
model to define its own compositions using a simple localised-merge algorithm.
This variant, called Self-StrAE, outperforms baselines that don't involve
explicit hierarchical compositions, and is comparable to models given
informative structure (e.g. constituency parses). Our experiments are conducted
in a data-constrained (circa 10M tokens) setting to help tease apart the
contribution of the inductive bias to effective learning. However, we find that
this framework can be robust to scale, and when extended to a much larger
dataset (circa 100M tokens), our 430 parameter model performs comparably to a
6-layer RoBERTa many orders of magnitude larger in size. Our findings support
the utility of incorporating explicit composition as an inductive bias for
effective representation learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FACE: Evaluating Natural Language Generation with Fourier Analysis of Cross-Entropy. (arXiv:2305.10307v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10307">
<div class="article-summary-box-inner">
<span><p>Measuring the distance between machine-produced and human language is a
critical open problem. Inspired by empirical findings from psycholinguistics on
the periodicity of entropy in language, we propose FACE, a set of metrics based
on Fourier Analysis of the estimated Cross-Entropy of language, for measuring
the similarity between model-generated and human-written languages. Based on an
open-ended generation task and the experimental data from previous studies, we
find that FACE can effectively identify the human-model gap, scales with model
size, reflects the outcomes of different sampling methods for decoding,
correlates well with other evaluation metrics and with human judgment scores.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining. (arXiv:2305.10429v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10429">
<div class="article-summary-box-inner">
<span><p>The mixture proportions of pretraining data domains (e.g., Wikipedia, books,
web text) greatly affect language model (LM) performance. In this paper, we
propose Domain Reweighting with Minimax Optimization (DoReMi), which first
trains a small proxy model using group distributionally robust optimization
(Group DRO) over domains to produce domain weights (mixture proportions)
without knowledge of downstream tasks. We then resample a dataset with these
domain weights and train a larger, full-sized model. In our experiments, we use
DoReMi on a 280M-parameter proxy model to find domain weights for training an
8B-parameter model (30x larger) more efficiently. On The Pile, DoReMi improves
perplexity across all domains, even when it downweights a domain. DoReMi
improves average few-shot downstream accuracy by 6.5% points over a baseline
model trained using The Pile's default domain weights and reaches the baseline
accuracy with 2.6x fewer training steps. On the GLaM dataset, DoReMi, which has
no knowledge of downstream tasks, even matches the performance of using domain
weights tuned on downstream tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks. (arXiv:2305.11430v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11430">
<div class="article-summary-box-inner">
<span><p>While LLMs have shown great success in understanding and generating text in
traditional conversational settings, their potential for performing ill-defined
complex tasks is largely under-studied. Indeed, we are yet to conduct
comprehensive benchmarking studies with multiple LLMs that are exclusively
focused on a complex task. However, conducting such benchmarking studies is
challenging because of the large variations in LLMs' performance when different
prompt types/styles are used and different degrees of detail are provided in
the prompts. To address this issue, the paper proposes a general taxonomy that
can be used to design prompts with specific properties in order to perform a
wide range of complex tasks. This taxonomy will allow future benchmarking
studies to report the specific categories of prompts used as part of the study,
enabling meaningful comparisons across different studies. Also, by establishing
a common standard through this taxonomy, researchers will be able to draw more
accurate conclusions about LLMs' performance on a specific complex task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mitigating Data Imbalance and Representation Degeneration in Multilingual Machine Translation. (arXiv:2305.12786v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.12786">
<div class="article-summary-box-inner">
<span><p>Despite advances in multilingual neural machine translation (MNMT), we argue
that there are still two major challenges in this area: data imbalance and
representation degeneration. The data imbalance problem refers to the imbalance
in the amount of parallel corpora for all language pairs, especially for
long-tail languages (i.e., very low-resource languages). The representation
degeneration problem refers to the problem of encoded tokens tending to appear
only in a small subspace of the full space available to the MNMT model. To
solve these two issues, we propose Bi-ACL, a framework that uses only
target-side monolingual data and a bilingual dictionary to improve the
performance of the MNMT model. We define two modules, named bidirectional
autoencoder and bidirectional contrastive learning, which we combine with an
online constrained beam search and a curriculum learning sampling strategy.
Extensive experiments show that our proposed method is more effective both in
long-tail languages and in high-resource languages. We also demonstrate that
our approach is capable of transferring knowledge between domains and languages
in zero-shot scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Diachronic Analysis of Paradigm Shifts in NLP Research: When, How, and Why?. (arXiv:2305.12920v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.12920">
<div class="article-summary-box-inner">
<span><p>Understanding the fundamental concepts and trends in a scientific field is
crucial for keeping abreast of its continuous advancement. In this study, we
propose a systematic framework for analyzing the evolution of research topics
in a scientific field using causal discovery and inference techniques. We
define three variables to encompass diverse facets of the evolution of research
topics within NLP and utilize a causal discovery algorithm to unveil the causal
connections among these variables using observational data. Subsequently, we
leverage this structure to measure the intensity of these relationships. By
conducting extensive experiments on the ACL Anthology corpus, we demonstrate
that our framework effectively uncovers evolutionary trends and the underlying
causes for a wide range of NLP research topics. Specifically, we show that
tasks and methods are primary drivers of research in NLP, with datasets
following, while metrics have minimal impact.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Asking Clarification Questions to Handle Ambiguity in Open-Domain QA. (arXiv:2305.13808v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.13808">
<div class="article-summary-box-inner">
<span><p>Ambiguous questions persist in open-domain question answering, because
formulating a precise question with a unique answer is often challenging.
Previously, Min et al. (2020) have tackled this issue by generating
disambiguated questions for all possible interpretations of the ambiguous
question. This can be effective, but not ideal for providing an answer to the
user. Instead, we propose to ask a clarification question, where the user's
response will help identify the interpretation that best aligns with the user's
intention. We first present CAMBIGNQ, a dataset consisting of 5,654 ambiguous
questions, each with relevant passages, possible answers, and a clarification
question. The clarification questions were efficiently created by generating
them using InstructGPT and manually revising them as necessary. We then define
a pipeline of tasks and design appropriate evaluation metrics. Lastly, we
achieve 61.3 F1 on ambiguity detection and 40.5 F1 on clarification-based QA,
providing strong baselines for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality. (arXiv:2305.13812v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.13812">
<div class="article-summary-box-inner">
<span><p>Contrastively trained vision-language models have achieved remarkable
progress in vision and language representation learning, leading to
state-of-the-art models for various downstream multimodal tasks. However,
recent research has highlighted severe limitations of these models in their
ability to perform compositional reasoning over objects, attributes, and
relations. Scene graphs have emerged as an effective way to understand images
compositionally. These are graph-structured semantic representations of images
that contain objects, their attributes, and relations with other objects in a
scene. In this work, we consider the scene graph parsed from text as a proxy
for the image scene graph and propose a graph decomposition and augmentation
framework along with a coarse-to-fine contrastive learning objective between
images and text that aligns sentences of various complexities to the same
image. Along with this, we propose novel negative mining techniques in the
scene graph space for improving attribute binding and relation understanding.
Through extensive experiments, we demonstrate the effectiveness of our approach
that significantly improves attribute binding, relation understanding,
systematic generalization, and productivity on multiple recently proposed
benchmarks (For example, improvements upto $18\%$ for systematic
generalization, $16.5\%$ for relation understanding over a strong baseline),
while achieving similar or better performance than CLIP on various general
multimodal tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Manipulation via Multi-Hop Instructions -- A New Dataset and Weakly-Supervised Neuro-Symbolic Approach. (arXiv:2305.14410v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14410">
<div class="article-summary-box-inner">
<span><p>We are interested in image manipulation via natural language text -- a task
that is useful for multiple AI applications but requires complex reasoning over
multi-modal spaces. We extend recently proposed Neuro Symbolic Concept Learning
(NSCL), which has been quite effective for the task of Visual Question
Answering (VQA), for the task of image manipulation. Our system referred to as
NeuroSIM can perform complex multi-hop reasoning over multi-object scenes and
only requires weak supervision in the form of annotated data for VQA. NeuroSIM
parses an instruction into a symbolic program, based on a Domain Specific
Language (DSL) comprising of object attributes and manipulation operations,
that guides its execution. We create a new dataset for the task, and extensive
experiments demonstrate that NeuroSIM is highly competitive with or beats SOTA
baselines that make use of supervised data for manipulation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is a Prestigious Job the same as a Prestigious Country? A Case Study on Multilingual Sentence Embeddings and European Countries. (arXiv:2305.14482v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14482">
<div class="article-summary-box-inner">
<span><p>We study how multilingual sentence representations capture European countries
and occupations and how this differs across European languages. We prompt the
models with templated sentences that we machine-translate into 12 European
languages and analyze the most prominent dimensions in the embeddings.Our
analysis reveals that the most prominent feature in the embedding is the
geopolitical distinction between Eastern and Western Europe and the country's
economic strength in terms of GDP. When prompted specifically for job prestige,
the embedding space clearly distinguishes high and low-prestige jobs. The
occupational dimension is uncorrelated with the most dominant country
dimensions in three out of four studied models. The exception is a small
distilled model that exhibits a connection between occupational prestige and
country of origin, which is a potential source of nationality-based
discrimination. Our findings are consistent across languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Natural Language Decompositions of Implicit Content Enable Better Text Representations. (arXiv:2305.14583v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14583">
<div class="article-summary-box-inner">
<span><p>When people interpret text, they rely on inferences that go beyond the
observed language itself. Inspired by this observation, we introduce a method
for the analysis of text that takes implicitly communicated content explicitly
into account. We use a large language model to produce sets of propositions
that are inferentially related to the text that has been observed, then
validate the plausibility of the generated content via human judgments.
Incorporating these explicit representations of implicit content proves useful
in multiple problem settings that involve the human interpretation of
utterances: assessing the similarity of arguments, making sense of a body of
opinion data, and modeling legislative behavior. Our results suggest that
modeling the meanings behind observed language, rather than the literal text
alone, is a valuable direction for NLP and particularly its applications to
social science.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpretable and Explainable Logical Policies via Neurally Guided Symbolic Abstraction. (arXiv:2306.01439v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01439">
<div class="article-summary-box-inner">
<span><p>The limited priors required by neural networks make them the dominating
choice to encode and learn policies using reinforcement learning (RL). However,
they are also black-boxes, making it hard to understand the agent's behaviour,
especially when working on the image level. Therefore, neuro-symbolic RL aims
at creating policies that are interpretable in the first place. Unfortunately,
interpretability is not explainability. To achieve both, we introduce Neurally
gUided Differentiable loGic policiEs (NUDGE). NUDGE exploits trained neural
network-based agents to guide the search of candidate-weighted logic rules,
then uses differentiable logic to train the logic agents. Our experimental
evaluation demonstrates that NUDGE agents can induce interpretable and
explainable policies while outperforming purely neural ones and showing good
flexibility to environments of different initial states and problem sizes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training Priors Predict Text-To-Image Model Performance. (arXiv:2306.01755v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01755">
<div class="article-summary-box-inner">
<span><p>Text-to-image models can often generate some relations, i.e., "astronaut
riding horse", but fail to generate other relations composed of the same basic
parts, i.e., "horse riding astronaut". These failures are often taken as
evidence that models rely on training priors rather than constructing novel
images compositionally. This paper tests this intuition on the stablediffusion
2.1 text-to-image model. By looking at the subject-verb-object (SVO) triads
that underlie these prompts (e.g., "astronaut", "ride", "horse"), we find that
the more often an SVO triad appears in the training data, the better the model
can generate an image aligned with that triad. Here, by aligned we mean that
each of the terms appears in the generated image in the proper relation to each
other. Surprisingly, this increased frequency also diminishes how well the
model can generate an image aligned with the flipped triad. For example, if
"astronaut riding horse" appears frequently in the training data, the image for
"horse riding astronaut" will tend to be poorly aligned. Our results thus show
that current models are biased to generate images with relations seen in
training, and provide new data to the ongoing debate on whether these
text-to-image models employ abstract compositional structure in a traditional
sense, or rather, interpolate between relations explicitly seen in the training
data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding. (arXiv:2306.02858v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.02858">
<div class="article-summary-box-inner">
<span><p>We present Video-LLaMA a multi-modal framework that empowers Large Language
Models (LLMs) with the capability of understanding both visual and auditory
content in the video. Video-LLaMA bootstraps cross-modal training from the
frozen pre-trained visual and audio encoders and the frozen LLMs. Unlike
previous works that complement LLMs to process the visual or audio signals
only, Video-LLaMA enables video comprehension by tackling two challenges: (1)
capturing the temporal changes in visual scenes, (2) integrating audio-visual
signals. To counter the first challenge, we propose a Video Q-former to
assemble a pre-trained image encoder into our video encoder and introduce a
video-to-text generation task to learn video-language correspondence. For the
second challenge, we leverage ImageBind, a universal embedding model aligning
multiple modalities, as the pre-trained audio encoder and introduce an Audio
Q-former on top of ImageBind to learn reasonable auditory query embeddings for
the LLM module. To align the output of both visual and audio encoders with
LLM's embedding space, we first train Video-LLaMA on massive
video/image-caption pairs and then tune our model with visual-instruction
datasets of moderate amount but higher quality. We found Video-LLaMA shows the
ability to perceive and comprehend video content and generate meaningful
responses grounded in the visual and auditory information presented in the
videos.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WebArena: A Realistic Web Environment for Building Autonomous Agents. (arXiv:2307.13854v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.13854">
<div class="article-summary-box-inner">
<span><p>With advances in generative AI, there is now potential for autonomous agents
to manage daily tasks via natural language commands. However, current agents
are primarily created and tested in simplified synthetic environments, leading
to a disconnect with real-world scenarios. In this paper, we build an
environment for language-guided agents that is highly realistic and
reproducible. Specifically, we focus on agents that perform tasks on the web,
and create an environment with fully functional websites from four common
domains: e-commerce, social forum discussions, collaborative software
development, and content management. Our environment is enriched with tools
(e.g., a map) and external knowledge bases (e.g., user manuals) to encourage
human-like task-solving. Building upon our environment, we release a set of
benchmark tasks focusing on evaluating the functional correctness of task
completions. The tasks in our benchmark are diverse, long-horizon, and designed
to emulate tasks that humans routinely perform on the internet. We experiment
with several baseline agents, integrating recent techniques such as reasoning
before acting. The results demonstrate that solving complex tasks is
challenging: our best GPT-4-based agent only achieves an end-to-end task
success rate of 14.41%, significantly lower than the human performance of
78.24%. These results highlight the need for further development of robust
agents, that current state-of-the-art large language models are far from
perfect performance in these real-life tasks, and that WebArena can be used to
measure such progress.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Select and Augment: Enhanced Dense Retrieval Knowledge Graph Augmentation. (arXiv:2307.15776v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.15776">
<div class="article-summary-box-inner">
<span><p>Injecting textual information into knowledge graph (KG) entity
representations has been a worthwhile expedition in terms of improving
performance in KG oriented tasks within the NLP community. External knowledge
often adopted to enhance KG embeddings ranges from semantically rich lexical
dependency parsed features to a set of relevant key words to entire text
descriptions supplied from an external corpus such as wikipedia and many more.
Despite the gains this innovation (Text-enhanced KG embeddings) has made, the
proposal in this work suggests that it can be improved even further. Instead of
using a single text description (which would not sufficiently represent an
entity because of the inherent lexical ambiguity of text), we propose a
multi-task framework that jointly selects a set of text descriptions relevant
to KG entities as well as align or augment KG embeddings with text
descriptions. Different from prior work that plugs formal entity descriptions
declared in knowledge bases, this framework leverages a retriever model to
selectively identify richer or highly relevant text descriptions to use in
augmenting entities. Furthermore, the framework treats the number of
descriptions to use in augmentation process as a parameter, which allows the
flexibility of enumerating across several numbers before identifying an
appropriate number. Experiment results for Link Prediction demonstrate a 5.5%
and 3.5% percentage increase in the Mean Reciprocal Rank (MRR) and Hits@10
scores respectively, in comparison to text-enhanced knowledge graph
augmentation methods using traditional CNNs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Knowledge-enhanced Two-stage Generative Framework for Medical Dialogue Information Extraction. (arXiv:2307.16200v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.16200">
<div class="article-summary-box-inner">
<span><p>This paper focuses on term-status pair extraction from medical dialogues
(MD-TSPE), which is essential in diagnosis dialogue systems and the automatic
scribe of electronic medical records (EMRs). In the past few years, works on
MD-TSPE have attracted increasing research attention, especially after the
remarkable progress made by generative methods. However, these generative
methods output a whole sequence consisting of term-status pairs in one stage
and ignore integrating prior knowledge, which demands a deeper understanding to
model the relationship between terms and infer the status of each term. This
paper presents a knowledge-enhanced two-stage generative framework (KTGF) to
address the above challenges. Using task-specific prompts, we employ a single
model to complete the MD-TSPE through two phases in a unified generative form:
we generate all terms the first and then generate the status of each generated
term. In this way, the relationship between terms can be learned more
effectively from the sequence containing only terms in the first phase, and our
designed knowledge-enhanced prompt in the second phase can leverage the
category and status candidates of the generated term for status generation.
Furthermore, our proposed special status "not mentioned" makes more terms
available and enriches the training data in the second phase, which is critical
in the low-resource setting. The experiments on the Chunyu and CMDD datasets
show that the proposed method achieves superior results compared to the
state-of-the-art models in the full training and low-resource settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AgentBench: Evaluating LLMs as Agents. (arXiv:2308.03688v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.03688">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) are becoming increasingly smart and autonomous,
targeting real-world pragmatic missions beyond traditional NLP tasks. As a
result, there has been an urgent need to evaluate LLMs as agents on challenging
tasks in interactive environments. We present AgentBench, a multi-dimensional
evolving benchmark that currently consists of 8 distinct environments to assess
LLM-as-Agent's reasoning and decision-making abilities in a multi-turn
open-ended generation setting. Our extensive test over 27 API-based and
open-sourced (OSS) LLMs shows that, while top commercial LLMs present a strong
ability of acting as agents in complex environments, there is a significant
disparity in performance between them and OSS competitors. We identify the
typical reasons of failures in environments and LLMs, showing that poor
long-term reasoning, decision-making, and instruction following abilities are
the main obstacles for developing usable LLM agents. Training on code and high
quality multi-turn alignment data could improve agent performance. Datasets,
environments, and an integrated evaluation package for AgentBench are released
at \url{https://github.com/THUDM/AgentBench}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Knowledge Graphs Simplify Text?. (arXiv:2308.06975v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06975">
<div class="article-summary-box-inner">
<span><p>Knowledge Graph (KG)-to-Text Generation has seen recent improvements in
generating fluent and informative sentences which describe a given KG. As KGs
are widespread across multiple domains and contain important entity-relation
information, and as text simplification aims to reduce the complexity of a text
while preserving the meaning of the original text, we propose KGSimple, a novel
approach to unsupervised text simplification which infuses KG-established
techniques in order to construct a simplified KG path and generate a concise
text which preserves the original input's meaning. Through an iterative and
sampling KG-first approach, our model is capable of simplifying text when
starting from a KG by learning to keep important information while harnessing
KG-to-text generation to output fluent and descriptive sentences. We evaluate
various settings of the KGSimple model on currently-available KG-to-text
datasets, demonstrating its effectiveness compared to unsupervised text
simplification models which start with a given complex text. Our code is
available on GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SeamlessM4T: Massively Multilingual & Multimodal Machine Translation. (arXiv:2308.11596v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.11596">
<div class="article-summary-box-inner">
<span><p>What does it take to create the Babel Fish, a tool that can help individuals
translate speech between any two languages? While recent breakthroughs in
text-based models have pushed machine translation coverage beyond 200
languages, unified speech-to-speech translation models have yet to achieve
similar strides. More specifically, conventional speech-to-speech translation
systems rely on cascaded systems that perform translation progressively,
putting high-performing unified systems out of reach. To address these gaps, we
introduce SeamlessM4T, a single model that supports speech-to-speech
translation, speech-to-text translation, text-to-speech translation,
text-to-text translation, and automatic speech recognition for up to 100
languages. To build this, we used 1 million hours of open speech audio data to
learn self-supervised speech representations with w2v-BERT 2.0. Subsequently,
we created a multimodal corpus of automatically aligned speech translations.
Filtered and combined with human-labeled and pseudo-labeled data, we developed
the first multilingual system capable of translating from and into English for
both speech and text. On FLEURS, SeamlessM4T sets a new standard for
translations into multiple target languages, achieving an improvement of 20%
BLEU over the previous SOTA in direct speech-to-text translation. Compared to
strong cascaded models, SeamlessM4T improves the quality of into-English
translation by 1.3 BLEU points in speech-to-text and by 2.6 ASR-BLEU points in
speech-to-speech. Tested for robustness, our system performs better against
background noises and speaker variations in speech-to-text tasks compared to
the current SOTA model. Critically, we evaluated SeamlessM4T on gender bias and
added toxicity to assess translation safety. Finally, all contributions in this
work are open-sourced and accessible at
https://github.com/facebookresearch/seamless_communication
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task-Based MoE for Multitask Multilingual Machine Translation. (arXiv:2308.15772v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.15772">
<div class="article-summary-box-inner">
<span><p>Mixture-of-experts (MoE) architecture has been proven a powerful method for
diverse tasks in training deep models in many applications. However, current
MoE implementations are task agnostic, treating all tokens from different tasks
in the same manner. In this work, we instead design a novel method that
incorporates task information into MoE models at different granular levels with
shared dynamic task-based adapters. Our experiments and analysis show the
advantages of our approaches over the dense and canonical MoE models on
multi-task multilingual machine translations. With task-specific adapters, our
models can additionally generalize to new tasks efficiently.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Large Language Models Discern Evidence for Scientific Hypotheses? Case Studies in the Social Sciences. (arXiv:2309.06578v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.06578">
<div class="article-summary-box-inner">
<span><p>Hypothesis formulation and testing are central to empirical research. A
strong hypothesis is a best guess based on existing evidence and informed by a
comprehensive view of relevant literature. However, with exponential increase
in the number of scientific articles published annually, manual aggregation and
synthesis of evidence related to a given hypothesis is a challenge. Our work
explores the ability of current large language models (LLMs) to discern
evidence in support or refute of specific hypotheses based on the text of
scientific abstracts. We share a novel dataset for the task of scientific
hypothesis evidencing using community-driven annotations of studies in the
social sciences. We compare the performance of LLMs to several state-of-the-art
benchmarks and highlight opportunities for future research in this area. The
dataset is available at
https://github.com/Sai90000/ScientificHypothesisEvidencing.git
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Talk2Care: Facilitating Asynchronous Patient-Provider Communication with Large-Language-Model. (arXiv:2309.09357v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.09357">
<div class="article-summary-box-inner">
<span><p>Despite the plethora of telehealth applications to assist home-based older
adults and healthcare providers, basic messaging and phone calls are still the
most common communication methods, which suffer from limited availability,
information loss, and process inefficiencies. One promising solution to
facilitate patient-provider communication is to leverage large language models
(LLMs) with their powerful natural conversation and summarization capability.
However, there is a limited understanding of LLMs' role during the
communication. We first conducted two interview studies with both older adults
(N=10) and healthcare providers (N=9) to understand their needs and
opportunities for LLMs in patient-provider asynchronous communication. Based on
the insights, we built an LLM-powered communication system, Talk2Care, and
designed interactive components for both groups: (1) For older adults, we
leveraged the convenience and accessibility of voice assistants (VAs) and built
an LLM-powered VA interface for effective information collection. (2) For
health providers, we built an LLM-based dashboard to summarize and present
important health information based on older adults' conversations with the VA.
We further conducted two user studies with older adults and providers to
evaluate the usability of the system. The results showed that Talk2Care could
facilitate the communication process, enrich the health information collected
from older adults, and considerably save providers' efforts and time. We
envision our work as an initial exploration of LLMs' capability in the
intersection of healthcare and interpersonal communication.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unify word-level and span-level tasks: NJUNLP's Participation for the WMT2023 Quality Estimation Shared Task. (arXiv:2309.13230v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13230">
<div class="article-summary-box-inner">
<span><p>We introduce the submissions of the NJUNLP team to the WMT 2023 Quality
Estimation (QE) shared task. Our team submitted predictions for the
English-German language pair on all two sub-tasks: (i) sentence- and word-level
quality prediction; and (ii) fine-grained error span detection. This year, we
further explore pseudo data methods for QE based on NJUQE framework
(https://github.com/NJUNLP/njuqe). We generate pseudo MQM data using parallel
data from the WMT translation task. We pre-train the XLMR large model on pseudo
QE data, then fine-tune it on real QE data. At both stages, we jointly learn
sentence-level scores and word-level tags. Empirically, we conduct experiments
to find the key hyper-parameters that improve the performance. Technically, we
propose a simple method that covert the word-level outputs to fine-grained
error span results. Overall, our models achieved the best results in
English-German for both word-level and fine-grained error span detection
sub-tasks by a considerable margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reproducing Whisper-Style Training Using an Open-Source Toolkit and Publicly Available Data. (arXiv:2309.13876v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13876">
<div class="article-summary-box-inner">
<span><p>Pre-training speech models on large volumes of data has achieved remarkable
success. OpenAI Whisper is a multilingual multitask model trained on 680k hours
of supervised speech data. It generalizes well to various speech recognition
and translation benchmarks even in a zero-shot setup. However, the full
pipeline for developing such models (from data collection to training) is not
publicly accessible, which makes it difficult for researchers to further
improve its performance and address training-related issues such as efficiency,
robustness, fairness, and bias. This work presents an Open Whisper-style Speech
Model (OWSM), which reproduces Whisper-style training using an open-source
toolkit and publicly available data. OWSM even supports more translation
directions and can be more efficient to train. We will publicly release all
scripts used for data preparation, training, inference, and scoring as well as
pre-trained models and training logs to promote open science.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Overview of the BioLaySumm 2023 Shared Task on Lay Summarization of Biomedical Research Articles. (arXiv:2309.17332v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.17332">
<div class="article-summary-box-inner">
<span><p>This paper presents the results of the shared task on Lay Summarisation of
Biomedical Research Articles (BioLaySumm), hosted at the BioNLP Workshop at ACL
2023. The goal of this shared task is to develop abstractive summarisation
models capable of generating "lay summaries" (i.e., summaries that are
comprehensible to non-technical audiences) in both a controllable and
non-controllable setting. There are two subtasks: 1) Lay Summarisation, where
the goal is for participants to build models for lay summary generation only,
given the full article text and the corresponding abstract as input; and 2)
Readability-controlled Summarisation, where the goal is for participants to
train models to generate both the technical abstract and the lay summary, given
an article's main text as input. In addition to overall results, we report on
the setup and insights from the BioLaySumm shared task, which attracted a total
of 20 participating teams across both subtasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OceanGPT: A Large Language Model for Ocean Science Tasks. (arXiv:2310.02031v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.02031">
<div class="article-summary-box-inner">
<span><p>Ocean science, which delves into the oceans that are reservoirs of life and
biodiversity, is of great significance given that oceans cover over 70% of our
planet's surface. Recently, advances in Large Language Models (LLMs) have
transformed the paradigm in science. Despite the success in other domains,
current LLMs often fall short in catering to the needs of domain experts like
oceanographers, and the potential of LLMs for ocean science is under-explored.
The intrinsic reason may be the immense and intricate nature of ocean data as
well as the necessity for higher granularity and richness in knowledge. To
alleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean
domain, which is expert in various ocean science tasks. We propose DoInstruct,
a novel framework to automatically obtain a large volume of ocean domain
instruction data, which generates instructions based on multi-agent
collaboration. Additionally, we construct the first oceanography benchmark,
OceanBench, to evaluate the capabilities of LLMs in the ocean domain. Though
comprehensive experiments, OceanGPT not only shows a higher level of knowledge
expertise for oceans science tasks but also gains preliminary embodied
intelligence capabilities in ocean technology. Codes, data and checkpoints will
soon be available at https://github.com/zjunlp/KnowLM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Hallucinations in Chinese Large Language Models. (arXiv:2310.03368v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03368">
<div class="article-summary-box-inner">
<span><p>In this paper, we establish a benchmark named HalluQA (Chinese Hallucination
Question-Answering) to measure the hallucination phenomenon in Chinese large
language models. HalluQA contains 450 meticulously designed adversarial
questions, spanning multiple domains, and takes into account Chinese historical
culture, customs, and social phenomena. During the construction of HalluQA, we
consider two types of hallucinations: imitative falsehoods and factual errors,
and we construct adversarial samples based on GLM-130B and ChatGPT. For
evaluation, we design an automated evaluation method using GPT-4 to judge
whether a model output is hallucinated. We conduct extensive experiments on 24
large language models, including ERNIE-Bot, Baichuan2, ChatGLM, Qwen, SparkDesk
and etc. Out of the 24 models, 18 achieved non-hallucination rates lower than
50%. This indicates that HalluQA is highly challenging. We analyze the primary
types of hallucinations in different types of models and their causes.
Additionally, we discuss which types of hallucinations should be prioritized
for different types of models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Investigation of LLMs' Inefficacy in Understanding Converse Relations. (arXiv:2310.05163v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.05163">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have achieved remarkable success in many formal
language oriented tasks, such as structural data-to-text and semantic parsing.
However current benchmarks mostly follow the data distribution of the
pre-training data of LLMs. Therefore, a natural question rises that do LLMs
really understand the structured semantics of formal languages. In this paper,
we investigate this problem on a special case, converse binary relation. We
introduce a new benchmark ConvRe focusing on converse relations, which contains
17 relations and 1240 triples extracted from popular knowledge graph completion
datasets. Our ConvRE features two tasks, Re2Text and Text2Re, which are
formulated as multi-choice question answering to evaluate LLMs' ability to
determine the matching between relations and associated text. For the
evaluation protocol, apart from different prompting methods, we further
introduce variants to the test text and few-shot example text. We conduct
experiments on three popular LLM families and have observed various scaling
trends. The results suggest that LLMs often resort to shortcut learning and
still face challenges on our proposed benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Summarization with Human Edits. (arXiv:2310.05857v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.05857">
<div class="article-summary-box-inner">
<span><p>Recent work has shown the promise of learning with human feedback paradigms
to produce human-determined high-quality text. Existing works use human
feedback to train large language models (LLMs) in general domain abstractive
summarization and have obtained summary quality exceeding traditional
likelihood training. In this paper, we focus on a less explored form of human
feedback -- Human Edits. We propose Sequence Alignment (un)Likelihood Training
(SALT), a novel technique to use both the human-edited and model-generated data
together in the training loop. In addition, we demonstrate simulating Human
Edits with ground truth summaries coming from existing training data --
Imitation edits, along with the model-generated summaries obtained after the
training, to reduce the need for expensive human-edit data. In our experiments,
we extend human feedback exploration from general domain summarization to
medical domain summarization. Our results demonstrate the effectiveness of SALT
in improving the summary quality with Human and Imitation Edits. Through
additional experiments, we show that SALT outperforms the conventional RLHF
method (designed for human preferences) -- DPO, when applied to human-edit
data. We hope the evidence in our paper prompts researchers to explore,
collect, and better use different human feedback approaches scalably.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KGQuiz: Evaluating the Generalization of Encoded Knowledge in Large Language Models. (arXiv:2310.09725v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09725">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) demonstrate remarkable performance on
knowledge-intensive tasks, suggesting that real-world knowledge is encoded in
their model parameters. However, besides explorations on a few probing tasks in
limited knowledge domains, it is not well understood how to evaluate LLMs'
knowledge systematically and how well their knowledge abilities generalize,
across a spectrum of knowledge domains and progressively complex task formats.
To this end, we propose KGQuiz, a knowledge-intensive benchmark to
comprehensively investigate the knowledge generalization abilities of LLMs.
KGQuiz is a scalable framework constructed from triplet-based knowledge, which
covers three knowledge domains and consists of five tasks with increasing
complexity: true-or-false, multiple-choice QA, blank filling, factual editing,
and open-ended knowledge generation. To gain a better understanding of LLMs'
knowledge abilities and their generalization, we evaluate 10 open-source and
black-box LLMs on the KGQuiz benchmark across the five knowledge-intensive
tasks and knowledge domains. Extensive experiments demonstrate that LLMs
achieve impressive performance in straightforward knowledge QA tasks, while
settings and contexts requiring more complex reasoning or employing
domain-specific facts still present significant challenges. We envision KGQuiz
as a testbed to analyze such nuanced variations in performance across domains
and task formats, and ultimately to understand, evaluate, and improve LLMs'
knowledge abilities across a wide spectrum of knowledge domains and tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Legal NLP Meets MiCAR: Advancing the Analysis of Crypto White Papers. (arXiv:2310.10333v3 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.10333">
<div class="article-summary-box-inner">
<span><p>In the rapidly evolving field of crypto assets, white papers are essential
documents for investor guidance, and are now subject to unprecedented content
requirements under the European Union's Markets in Crypto-Assets Regulation
(MiCAR). Natural Language Processing (NLP) can serve as a powerful tool for
both analyzing these documents and assisting in regulatory compliance. This
paper delivers two contributions to the topic. First, we survey existing
applications of textual analysis to unregulated crypto asset white papers,
uncovering a research gap that could be bridged with interdisciplinary
collaboration. We then conduct an analysis of the changes introduced by MiCAR,
highlighting the opportunities and challenges of integrating NLP within the new
regulatory framework. The findings set the stage for further research, with the
potential to benefit regulators, crypto asset issuers, and investors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VoxArabica: A Robust Dialect-Aware Arabic Speech Recognition System. (arXiv:2310.11069v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.11069">
<div class="article-summary-box-inner">
<span><p>Arabic is a complex language with many varieties and dialects spoken by over
450 millions all around the world. Due to the linguistic diversity and
variations, it is challenging to build a robust and generalized ASR system for
Arabic. In this work, we address this gap by developing and demoing a system,
dubbed VoxArabica, for dialect identification (DID) as well as automatic speech
recognition (ASR) of Arabic. We train a wide range of models such as HuBERT
(DID), Whisper, and XLS-R (ASR) in a supervised setting for Arabic DID and ASR
tasks. Our DID models are trained to identify 17 different dialects in addition
to MSA. We finetune our ASR models on MSA, Egyptian, Moroccan, and mixed data.
Additionally, for the remaining dialects in ASR, we provide the option to
choose various models such as Whisper and MMS in a zero-shot setting. We
integrate these models into a single web interface with diverse features such
as audio recording, file upload, model selection, and the option to raise flags
for incorrect outputs. Overall, we believe VoxArabica will be useful for a wide
range of audiences concerned with Arabic research. Our system is currently
running at https://cdce-206-12-100-168.ngrok.io/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models. (arXiv:2310.11954v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.11954">
<div class="article-summary-box-inner">
<span><p>AI-empowered music processing is a diverse field that encompasses dozens of
tasks, ranging from generation tasks (e.g., timbre synthesis) to comprehension
tasks (e.g., music classification). For developers and amateurs, it is very
difficult to grasp all of these task to satisfy their requirements in music
processing, especially considering the huge differences in the representations
of music data and the model applicability across platforms among various tasks.
Consequently, it is necessary to build a system to organize and integrate these
tasks, and thus help practitioners to automatically analyze their demand and
call suitable tools as solutions to fulfill their requirements. Inspired by the
recent success of large language models (LLMs) in task automation, we develop a
system, named MusicAgent, which integrates numerous music-related tools and an
autonomous workflow to address user requirements. More specifically, we build
1) toolset that collects tools from diverse sources, including Hugging Face,
GitHub, and Web API, etc. 2) an autonomous workflow empowered by LLMs (e.g.,
ChatGPT) to organize these tools and automatically decompose user requests into
multiple sub-tasks and invoke corresponding music tools. The primary goal of
this system is to free users from the intricacies of AI-music tools, enabling
them to concentrate on the creative aspect. By granting users the freedom to
effortlessly combine tools, the system offers a seamless and enriching music
experience.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Tale of Pronouns: Interpretability Informs Gender Bias Mitigation for Fairer Instruction-Tuned Machine Translation. (arXiv:2310.12127v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.12127">
<div class="article-summary-box-inner">
<span><p>Recent instruction fine-tuned models can solve multiple NLP tasks when
prompted to do so, with machine translation (MT) being a prominent use case.
However, current research often focuses on standard performance benchmarks,
leaving compelling fairness and ethical considerations behind. In MT, this
might lead to misgendered translations, resulting, among other harms, in the
perpetuation of stereotypes and prejudices. In this work, we address this gap
by investigating whether and to what extent such models exhibit gender bias in
machine translation and how we can mitigate it. Concretely, we compute
established gender bias metrics on the WinoMT corpus from English to German and
Spanish. We discover that IFT models default to male-inflected translations,
even disregarding female occupational stereotypes. Next, using interpretability
methods, we unveil that models systematically overlook the pronoun indicating
the gender of a target occupation in misgendered translations. Finally, based
on this finding, we propose an easy-to-implement and effective bias mitigation
solution based on few-shot learning that leads to significantly fairer
translations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Model for Multi-objective Evolutionary Optimization. (arXiv:2310.12541v2 [cs.NE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.12541">
<div class="article-summary-box-inner">
<span><p>Multiobjective evolutionary algorithms (MOEAs) are major methods for solving
multiobjective optimization problems (MOPs). Many MOEAs have been proposed in
the past decades, of which the search operators need a carefully handcrafted
design with domain knowledge. Recently, some attempts have been made to replace
the manually designed operators in MOEAs with learning-based operators (e.g.,
neural network models). However, much effort is still required for designing
and training such models, and the learned operators might not generalize well
on new problems. To tackle the above challenges, this work investigates a novel
approach that leverages the powerful large language model (LLM) to design MOEA
operators. With proper prompt engineering, we successfully let a general LLM
serve as a black-box search operator for decomposition-based MOEA (MOEA/D) in a
zero-shot manner. In addition, by learning from the LLM behavior, we further
design an explicit white-box operator with randomness and propose a new version
of decomposition-based MOEA, termed MOEA/D-LO. Experimental studies on
different test benchmarks show that our proposed method can achieve competitive
performance with widely used MOEAs. It is also promising to see the operator
only learned from a few instances can have robust generalization performance on
unseen problems with quite different patterns and settings. The results reveal
the potential benefits of using pre-trained LLMs in the design of MOEAs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InvGC: Robust Cross-Modal Retrieval by Inverse Graph Convolution. (arXiv:2310.13276v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.13276">
<div class="article-summary-box-inner">
<span><p>Over recent decades, significant advancements in cross-modal retrieval are
mainly driven by breakthroughs in visual and linguistic modeling. However, a
recent study shows that multi-modal data representations tend to cluster within
a limited convex cone (as representation degeneration problem), which hinders
retrieval performance due to the inseparability of these representations. In
our study, we first empirically validate the presence of the representation
degeneration problem across multiple cross-modal benchmarks and methods. Next,
to address it, we introduce a novel method, called InvGC, a post-processing
technique inspired by graph convolution and average pooling. Specifically,
InvGC defines the graph topology within the datasets and then applies graph
convolution in a subtractive manner. This method effectively separates
representations by increasing the distances between data points. To improve the
efficiency and effectiveness of InvGC, we propose an advanced graph topology,
LocalAdj, which only aims to increase the distances between each data point and
its nearest neighbors. To understand why InvGC works, we present a detailed
theoretical analysis, proving that the lower bound of recall will be improved
after deploying InvGC. Extensive empirical results show that InvGC and InvGC
w/LocalAdj significantly mitigate the representation degeneration problem,
thereby enhancing retrieval performance.
</p>
<p>Our code is available at
https://github.com/yimuwangcs/Better_Cross_Modal_Retrieval
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multiscale Superpixel Structured Difference Graph Convolutional Network for VL Representation. (arXiv:2310.13447v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.13447">
<div class="article-summary-box-inner">
<span><p>Within the multimodal field, the key to integrating vision and language lies
in establishing a good alignment strategy. Recently, benefiting from the
success of self-supervised learning, significant progress has been made in
multimodal semantic representation based on pre-trained models for vision and
language. However, there is still room for improvement in visual semantic
representation. The lack of spatial semantic coherence and vulnerability to
noise makes it challenging for current pixel or patch-based methods to
accurately extract complex scene boundaries. To this end, this paper develops
superpixel as a comprehensive compact representation of learnable image data,
which effectively reduces the number of visual primitives for subsequent
processing by clustering perceptually similar pixels. To mine more precise
topological relations, we propose a Multiscale Difference Graph Convolutional
Network (MDGCN). It parses the entire image as a fine-to-coarse hierarchical
structure of constituent visual patterns, and captures multiscale features by
progressively merging adjacent superpixels as graph nodes. Moreover, we predict
the differences between adjacent nodes through the graph structure,
facilitating key information aggregation of graph nodes to reason actual
semantic relations. Afterward, we design a multi-level fusion rule in a
bottom-up manner to avoid understanding deviation by learning complementary
spatial information at different regional scales. Our proposed method can be
well applied to multiple downstream task learning. Extensive experiments
demonstrate that our method is competitive with other state-of-the-art methods
in visual reasoning. Our code will be released upon publication.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hunayn: Elevating Translation Beyond the Literal. (arXiv:2310.13613v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.13613">
<div class="article-summary-box-inner">
<span><p>This project introduces an advanced English-to-Arabic translator surpassing
conventional tools. Leveraging the Helsinki transformer (MarianMT), our
approach involves fine-tuning on a self-scraped, purely literary Arabic
dataset. Evaluations against Google Translate show consistent outperformance in
qualitative assessments. Notably, it excels in cultural sensitivity and context
accuracy. This research underscores the Helsinki transformer's superiority for
English-to-Arabic translation using a Fusha dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NormDial: A Comparable Bilingual Synthetic Dialog Dataset for Modeling Social Norm Adherence and Violation. (arXiv:2310.14563v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.14563">
<div class="article-summary-box-inner">
<span><p>Social norms fundamentally shape interpersonal communication. We present
NormDial, a high-quality dyadic dialogue dataset with turn-by-turn annotations
of social norm adherences and violations for Chinese and American cultures.
Introducing the task of social norm observance detection, our dataset is
synthetically generated in both Chinese and English using a human-in-the-loop
pipeline by prompting large language models with a small collection of
expert-annotated social norms. We show that our generated dialogues are of high
quality through human evaluation and further evaluate the performance of
existing large language models on this task. Our findings point towards new
directions for understanding the nuances of social norms as they manifest in
conversational contexts that span across languages and cultures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DISC-FinLLM: A Chinese Financial Large Language Model based on Multiple Experts Fine-tuning. (arXiv:2310.15205v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.15205">
<div class="article-summary-box-inner">
<span><p>We propose Multiple Experts Fine-tuning Framework to build a financial large
language model (LLM), DISC-FinLLM. Our methodology improves general LLMs by
endowing them with multi-turn question answering abilities, domain text
processing capabilities, mathematical computation skills, and
retrieval-enhanced generation capabilities. We build a financial
instruction-tuning dataset named DISC-FIN-SFT, including instruction samples of
four categories (consulting, NLP tasks, computing and retrieval-augmented
generation). Evaluations conducted on multiple benchmarks demonstrate that our
model performs better than baseline models in various financial scenarios.
Further resources can be found at https://github.com/FudanDISC/DISC-FinLLM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TaskDiff: A Similarity Metric for Task-Oriented Conversations. (arXiv:2310.15298v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.15298">
<div class="article-summary-box-inner">
<span><p>The popularity of conversational digital assistants has resulted in the
availability of large amounts of conversational data which can be utilized for
improved user experience and personalized response generation. Building these
assistants using popular large language models like ChatGPT also require
additional emphasis on prompt engineering and evaluation methods. Textual
similarity metrics are a key ingredient for such analysis and evaluations.
While many similarity metrics have been proposed in the literature, they have
not proven effective for task-oriented conversations as they do not take
advantage of unique conversational features. To address this gap, we present
TaskDiff, a novel conversational similarity metric that utilizes different
dialogue components (utterances, intents, and slots) and their distributions to
compute similarity. Extensive experimental evaluation of TaskDiff on a
benchmark dataset demonstrates its superior performance and improved robustness
over other related approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions. (arXiv:2310.15421v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.15421">
<div class="article-summary-box-inner">
<span><p>Theory of mind (ToM) evaluations currently focus on testing models using
passive narratives that inherently lack interactivity. We introduce FANToM, a
new benchmark designed to stress-test ToM within information-asymmetric
conversational contexts via question answering. Our benchmark draws upon
important theoretical requisites from psychology and necessary empirical
considerations when evaluating large language models (LLMs). In particular, we
formulate multiple types of questions that demand the same underlying reasoning
to identify illusory or false sense of ToM capabilities in LLMs. We show that
FANToM is challenging for state-of-the-art LLMs, which perform significantly
worse than humans even with chain-of-thought reasoning or fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction. (arXiv:2310.15556v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.15556">
<div class="article-summary-box-inner">
<span><p>Since ChatGPT released its API for public use, the number of applications
built on top of commercial large language models (LLMs) increase exponentially.
One popular usage of such models is leveraging its in-context learning ability
and generating responses given user queries leveraging knowledge obtained by
retrieval augmentation. One problem of deploying commercial retrieval-augmented
LLMs is the cost due to the additionally retrieved context that largely
increases the input token size of the LLMs. To mitigate this, we propose a
token compression scheme that includes two methods: summarization compression
and semantic compression. The first method applies a T5-based model that is
fine-tuned by datasets generated using self-instruct containing samples with
varying lengths and reduce token size by doing summarization. The second method
further compresses the token size by removing words with lower impact on the
semantic. In order to adequately evaluate the effectiveness of the proposed
methods, we propose and utilize a dataset called Food-Recommendation DB (FRDB)
focusing on food recommendation for women around pregnancy period or infants.
Our summarization compression can reduce 65% of the retrieval token size with
further 0.3% improvement on the accuracy; semantic compression provides a more
flexible way to trade-off the token size with performance, for which we can
reduce the token size by 20% with only 1.6% of accuracy drop.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COPF: Continual Learning Human Preference through Optimal Policy Fitting. (arXiv:2310.15694v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.15694">
<div class="article-summary-box-inner">
<span><p>The technique of Reinforcement Learning from Human Feedback (RLHF) is a
commonly employed method to improve pre-trained Language Models (LM), enhancing
their ability to conform to human preferences. Nevertheless, the current
RLHF-based LMs necessitate full retraining each time novel queries or feedback
are introduced, which becomes a challenging task because human preferences can
vary between different domains or tasks. Retraining LMs poses practical
difficulties in many real-world situations due to the significant time and
computational resources required, along with concerns related to data privacy.
To address this limitation, we propose a new method called Continual Optimal
Policy Fitting (COPF), in which we estimate a series of optimal policies using
the Monte Carlo method, and then continually fit the policy sequence with the
function regularization. COPF involves a single learning phase and doesn't
necessitate complex reinforcement learning. Importantly, it shares the
capability with RLHF to learn from unlabeled data, making it flexible for
continual preference learning. Our experimental results show that COPF
outperforms strong Continuous learning (CL) baselines when it comes to
consistently aligning with human preferences on different tasks and domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accented Speech Recognition With Accent-specific Codebooks. (arXiv:2310.15970v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.15970">
<div class="article-summary-box-inner">
<span><p>Speech accents pose a significant challenge to state-of-the-art automatic
speech recognition (ASR) systems. Degradation in performance across
underrepresented accents is a severe deterrent to the inclusive adoption of
ASR. In this work, we propose a novel accent adaptation approach for end-to-end
ASR systems using cross-attention with a trainable set of codebooks. These
learnable codebooks capture accent-specific information and are integrated
within the ASR encoder layers. The model is trained on accented English speech,
while the test data also contained accents which were not seen during training.
On the Mozilla Common Voice multi-accented dataset, we show that our proposed
approach yields significant performance gains not only on the seen English
accents (up to $37\%$ relative improvement in word error rate) but also on the
unseen accents (up to $5\%$ relative improvement in WER). Further, we
illustrate benefits for a zero-shot transfer setup on the L2Artic dataset. We
also compare the performance with other approaches based on accent adversarial
training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WebWISE: Web Interface Control and Sequential Exploration with Large Language Models. (arXiv:2310.16042v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.16042">
<div class="article-summary-box-inner">
<span><p>The paper investigates using a Large Language Model (LLM) to automatically
perform web software tasks using click, scroll, and text input operations.
Previous approaches, such as reinforcement learning (RL) or imitation learning,
are inefficient to train and task-specific. Our method uses filtered Document
Object Model (DOM) elements as observations and performs tasks step-by-step,
sequentially generating small programs based on the current observations. We
use in-context learning, either benefiting from a single manually provided
example, or an automatically generated example based on a successful zero-shot
trial. We evaluate the proposed method on the MiniWob++ benchmark. With only
one in-context example, our WebWISE method achieves similar or better
performance than other methods that require many demonstrations or trials.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLAIR: Evaluating Image Captions with Large Language Models. (arXiv:2310.12971v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.12971">
<div class="article-summary-box-inner">
<span><p>The evaluation of machine-generated image captions poses an interesting yet
persistent challenge. Effective evaluation measures must consider numerous
dimensions of similarity, including semantic relevance, visual structure,
object interactions, caption diversity, and specificity. Existing
highly-engineered measures attempt to capture specific aspects, but fall short
in providing a holistic score that aligns closely with human judgments. Here,
we propose CLAIR, a novel method that leverages the zero-shot language modeling
capabilities of large language models (LLMs) to evaluate candidate captions. In
our evaluations, CLAIR demonstrates a stronger correlation with human judgments
of caption quality compared to existing measures. Notably, on Flickr8K-Expert,
CLAIR achieves relative correlation improvements over SPICE of 39.6% and over
image-augmented methods such as RefCLIP-S of 18.3%. Moreover, CLAIR provides
noisily interpretable results by allowing the language model to identify the
underlying reasoning behind its assigned score. Code is available at
https://davidmchan.github.io/clair/
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-10-26 23:11:19.525998531 UTC">2023-10-26 23:11:19 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>