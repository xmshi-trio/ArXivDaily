<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-08-29T01:30:00Z">08-29</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Building Trust in Conversational AI: A Comprehensive Review and Solution Architecture for Explainable, Privacy-Aware Systems using LLMs and Knowledge Graph. (arXiv:2308.13534v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13534">
<div class="article-summary-box-inner">
<span><p>Conversational AI systems have emerged as key enablers of human-like
interactions across diverse sectors. Nevertheless, the balance between
linguistic nuance and factual accuracy has proven elusive. In this paper, we
first introduce LLMXplorer, a comprehensive tool that provides an in-depth
review of over 150 Large Language Models (LLMs), elucidating their myriad
implications ranging from social and ethical to regulatory, as well as their
applicability across industries. Building on this foundation, we propose a
novel functional architecture that seamlessly integrates the structured
dynamics of Knowledge Graphs with the linguistic capabilities of LLMs.
Validated using real-world AI news data, our architecture adeptly blends
linguistic sophistication with factual rigour and further strengthens data
security through Role-Based Access Control. This research provides insights
into the evolving landscape of conversational AI, emphasizing the imperative
for systems that are efficient, transparent, and trustworthy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Preliminary Study on a Conceptual Game Feature Generation and Recommendation System. (arXiv:2308.13538v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13538">
<div class="article-summary-box-inner">
<span><p>This paper introduces a system used to generate game feature suggestions
based on a text prompt. Trained on the game descriptions of almost 60k games,
it uses the word embeddings of a small GLoVe model to extract features and
entities found in thematically similar games which are then passed through a
generator model to generate new features for a user's prompt. We perform a
short user study comparing the features generated from a fine-tuned GPT-2
model, a model using the ConceptNet, and human-authored game features. Although
human suggestions won the overall majority of votes, the GPT-2 model
outperformed the human suggestions in certain games. This system is part of a
larger game design assistant tool that is able to collaborate with users at a
conceptual level.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feature Extraction Using Deep Generative Models for Bangla Text Classification on a New Comprehensive Dataset. (arXiv:2308.13545v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13545">
<div class="article-summary-box-inner">
<span><p>The selection of features for text classification is a fundamental task in
text mining and information retrieval. Despite being the sixth most widely
spoken language in the world, Bangla has received little attention due to the
scarcity of text datasets. In this research, we collected, annotated, and
prepared a comprehensive dataset of 212,184 Bangla documents in seven different
categories and made it publicly accessible. We implemented three deep learning
generative models: LSTM variational autoencoder (LSTM VAE), auxiliary
classifier generative adversarial network (AC-GAN), and adversarial autoencoder
(AAE) to extract text features, although their applications are initially found
in the field of computer vision. We utilized our dataset to train these three
models and used the feature space obtained in the document classification task.
We evaluated the performance of the classifiers and found that the adversarial
autoencoder model produced the best feature space.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models in Analyzing Crash Narratives -- A Comparative Study of ChatGPT, BARD and GPT-4. (arXiv:2308.13563v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13563">
<div class="article-summary-box-inner">
<span><p>In traffic safety research, extracting information from crash narratives
using text analysis is a common practice. With recent advancements of large
language models (LLM), it would be useful to know how the popular LLM
interfaces perform in classifying or extracting information from crash
narratives. To explore this, our study has used the three most popular publicly
available LLM interfaces- ChatGPT, BARD and GPT4. This study investigated their
usefulness and boundaries in extracting information and answering queries
related to accidents from 100 crash narratives from Iowa and Kansas. During the
investigation, their capabilities and limitations were assessed and their
responses to the queries were compared. Five questions were asked related to
the narratives: 1) Who is at-fault? 2) What is the manner of collision? 3) Has
the crash occurred in a work-zone? 4) Did the crash involve pedestrians? and 5)
What are the sequence of harmful events in the crash? For questions 1 through
4, the overall similarity among the LLMs were 70%, 35%, 96% and 89%,
respectively. The similarities were higher while answering direct questions
requiring binary responses and significantly lower for complex questions. To
compare the responses to question 5, network diagram and centrality measures
were analyzed. The network diagram from the three LLMs were not always similar
although they sometimes have the same influencing events with high in-degree,
out-degree and betweenness centrality. This study suggests using multiple
models to extract viable information from narratives. Also, caution must be
practiced while using these interfaces to obtain crucial safety related
information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DARWIN Series: Domain Specific Large Language Models for Natural Science. (arXiv:2308.13565v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13565">
<div class="article-summary-box-inner">
<span><p>Emerging tools bring forth fresh approaches to work, and the field of natural
science is no different. In natural science, traditional manual, serial, and
labour-intensive work is being augmented by automated, parallel, and iterative
processes driven by artificial intelligence-based experimental automation and
more. To add new capabilities in natural science, enabling the acceleration and
enrichment of automation of the discovery process, we present DARWIN, a series
of tailored LLMs for natural science, mainly in physics, chemistry, and
material science. This series relies on open-source LLM, incorporating
structured and unstructured scientific knowledge from public datasets and
literature. We fine-tuned the models using over 60,000 instruction data points,
emphasizing factual correctness. During the fine-tuning, we introduce the
Scientific Instruction Generation (SIG) model, automating instruction
generation from scientific texts. This eliminates the need for manual
extraction or domain-specific knowledge graphs and efficiently injects
scientific knowledge into the model. We also explore multi-task training
strategies, revealing interconnections between scientific tasks. DARWIN series
not only achieves state-of-the-art results on various scientific tasks but also
diminishes reliance on closed-source AI models. Our research showcases the
ability of LLM in the scientific domain, with the overarching goal of fostering
prosperity within the broader AI for science community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MLLM-DataEngine: An Iterative Refinement Approach for MLLM. (arXiv:2308.13566v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13566">
<div class="article-summary-box-inner">
<span><p>Despite the great advance of Multimodal Large Language Models (MLLMs) in both
instruction dataset building and benchmarking, the independence of training and
evaluation makes current MLLMs hard to further improve their capability under
the guidance of evaluation results with a relatively low human cost. In this
paper, we propose MLLM-DataEngine, a novel closed-loop system that bridges data
generation, model training, and evaluation. Within each loop iteration, the
MLLM-DataEngine first analyze the weakness of the model based on the evaluation
results, then generate a proper incremental dataset for the next training
iteration and enhance the model capability iteratively. Compared with previous
data collection methods which are separate from the benchmarking, the data
generated by MLLM-DataEngine shows better targeting, quality, and correctness.
For targeting, we propose an Adaptive Bad-case Sampling module, which adjusts
the ratio of different types of data within each incremental dataset based on
the benchmarking results. For quality, we resort to GPT-4 to generate
high-quality data with each given data type. For correctness, prompt design is
critical for the data generation results. Rather than previous hand-crafted
prompt, we propose an Interactive Prompt Optimization strategy, which optimizes
the prompt with the multi-round interaction between human and GPT, and improve
the correctness of generated data greatly. Through extensive experiments, we
find our MLLM-DataEngine could boost the MLLM capability in a targeted and
automatic manner, with only a few human participation. The MLLM-DataEngine will
be released and we hope it could be a general solution for the following MLLMs
building.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discovering Mental Health Research Topics with Topic Modeling. (arXiv:2308.13569v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13569">
<div class="article-summary-box-inner">
<span><p>Mental health significantly influences various aspects of our daily lives,
and its importance has been increasingly recognized by the research community
and the general public, particularly in the wake of the COVID-19 pandemic. This
heightened interest is evident in the growing number of publications dedicated
to mental health in the past decade. In this study, our goal is to identify
general trends in the field and pinpoint high-impact research topics by
analyzing a large dataset of mental health research papers. To accomplish this,
we collected abstracts from various databases and trained a customized
Sentence-BERT based embedding model leveraging the BERTopic framework. Our
dataset comprises 96,676 research papers pertaining to mental health, enabling
us to examine the relationships between different topics using their abstracts.
To evaluate the effectiveness of the model, we compared it against two other
state-of-the-art methods: Top2Vec model and LDA-BERT model. The model
demonstrated superior performance in metrics that measure topic diversity and
coherence. To enhance our analysis, we also generated word clouds to provide a
comprehensive overview of the machine learning models applied in mental health
research, shedding light on commonly utilized techniques and emerging trends.
Furthermore, we provide a GitHub link* to the dataset used in this paper,
ensuring its accessibility for further research endeavors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Ensemble Approach to Personalized Real Time Predictive Writing for Experts. (arXiv:2308.13576v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13576">
<div class="article-summary-box-inner">
<span><p>Completing a sentence, phrase or word after typing few words / characters is
very helpful for Intuit financial experts, while taking notes or having a live
chat with users, since they need to write complex financial concepts more
efficiently and accurately many times in a day. In this paper, we tie together
different approaches like large language models, traditional Markov Models and
char level models to create an end-to-end system to provide personalised
sentence/word auto-complete suggestions to experts, under strict latency
constraints. Proposed system can auto-complete sentences, phrases or words
while writing with personalisation and can be trained with very less data and
resources with good efficiency. Our proposed system is not only efficient and
personalized but also robust as it leverages multiple machine learning
techniques along with transfer learning approach to fine tune large language
model with Intuit specific data. This ensures that even in cases of rare or
unusual phrases, the system can provide relevant auto-complete suggestions in
near real time. Survey has showed that this system saves expert note-taking
time and boosts expert confidence in their communication with teammates and
clients. Since enabling this predictive writing feature for QBLive experts,
more than a million keystrokes have been saved based on these suggestions. We
have done comparative study for our ensemble choice. Moreover this feature can
be integrated with any product which has writing facility within a very short
period of time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text Style Transfer Evaluation Using Large Language Models. (arXiv:2308.13577v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13577">
<div class="article-summary-box-inner">
<span><p>Text Style Transfer (TST) is challenging to evaluate because the quality of
the generated text manifests itself in multiple aspects, each of which is hard
to measure individually: style transfer accuracy, content preservation, and
overall fluency of the text. Human evaluation is the gold standard in TST
evaluation; however, it is expensive, and the results are difficult to
reproduce. Numerous automated metrics are employed to assess performance in
these aspects, serving as substitutes for human evaluation. However, the
correlation between many of these automated metrics and human evaluations
remains unclear, raising doubts about their effectiveness as reliable
benchmarks. Recent advancements in Large Language Models (LLMs) have
demonstrated their ability to not only match but also surpass the average human
performance across a wide range of unseen tasks. This suggests that LLMs have
the potential to serve as a viable alternative to human evaluation and other
automated metrics. We assess the performance of different LLMs on TST
evaluation by employing multiple input prompts and comparing their results. Our
findings indicate that (even zero-shot) prompting correlates strongly with
human evaluation and often surpasses the performance of (other) automated
metrics. Additionally, we propose the ensembling of prompts and show it
increases the robustness of TST evaluation.This work contributes to the ongoing
efforts in evaluating LLMs on diverse tasks, which includes a discussion of
failure cases and limitations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LSTM-based QoE Evaluation for Web Microservices' Reputation Scoring. (arXiv:2308.13590v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13590">
<div class="article-summary-box-inner">
<span><p>Sentiment analysis is the task of mining the authors' opinions about specific
entities. It allows organizations to monitor different services in real time
and act accordingly. Reputation is what is generally said or believed about
people or things. Informally, reputation combines the measure of reliability
derived from feedback, reviews, and ratings gathered from users, which reflect
their quality of experience (QoE) and can either increase or harm the
reputation of the provided services. In this study, we propose to perform
sentiment analysis on web microservices reviews to exploit the provided
information to assess and score the microservices' reputation. Our proposed
approach uses the Long Short-Term Memory (LSTM) model to perform sentiment
analysis and the Net Brand Reputation (NBR) algorithm to assess reputation
scores for microservices. This approach is tested on a set of more than 10,000
reviews related to 15 Amazon Web microservices, and the experimental results
have shown that our approach is more accurate than existing approaches, with an
accuracy and precision of 93% obtained after applying an oversampling strategy
and a resulting reputation score of the considered microservices community of
89%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GRASP: A Rehearsal Policy for Efficient Online Continual Learning. (arXiv:2308.13646v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13646">
<div class="article-summary-box-inner">
<span><p>Continual learning (CL) in deep neural networks (DNNs) involves incrementally
accumulating knowledge in a DNN from a growing data stream. A major challenge
in CL is that non-stationary data streams cause catastrophic forgetting of
previously learned abilities. Rehearsal is a popular and effective way to
mitigate this problem, which is storing past observations in a buffer and
mixing them with new observations during learning. This leads to a question:
Which stored samples should be selected for rehearsal? Choosing samples that
are best for learning, rather than simply selecting them at random, could lead
to significantly faster learning. For class incremental learning, prior work
has shown that a simple class balanced random selection policy outperforms more
sophisticated methods. Here, we revisit this question by exploring a new sample
selection policy called GRASP. GRASP selects the most prototypical (class
representative) samples first and then gradually selects less prototypical
(harder) examples to update the DNN. GRASP has little additional compute or
memory overhead compared to uniform selection, enabling it to scale to large
datasets. We evaluate GRASP and other policies by conducting CL experiments on
the large-scale ImageNet-1K and Places-LT image classification datasets. GRASP
outperforms all other rehearsal policies. Beyond vision, we also demonstrate
that GRASP is effective for CL on five text classification datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Language Models as Symbolic Knowledge Graphs. (arXiv:2308.13676v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13676">
<div class="article-summary-box-inner">
<span><p>Symbolic knowledge graphs (KGs) play a pivotal role in knowledge-centric
applications such as search, question answering and recommendation. As
contemporary language models (LMs) trained on extensive textual data have
gained prominence, researchers have extensively explored whether the parametric
knowledge within these models can match up to that present in knowledge graphs.
Various methodologies have indicated that enhancing the size of the model or
the volume of training data enhances its capacity to retrieve symbolic
knowledge, often with minimal or no human supervision. Despite these
advancements, there is a void in comprehensively evaluating whether LMs can
encompass the intricate topological and semantic attributes of KGs, attributes
crucial for reasoning processes. In this work, we provide an exhaustive
evaluation of language models of varying sizes and capabilities. We construct
nine qualitative benchmarks that encompass a spectrum of attributes including
symmetry, asymmetry, hierarchy, bidirectionality, compositionality, paths,
entity-centricity, bias and ambiguity. Additionally, we propose novel
evaluation metrics tailored for each of these attributes. Our extensive
evaluation of various LMs shows that while these models exhibit considerable
potential in recalling factual information, their ability to capture intricate
topological and semantic traits of KGs remains significantly constrained. We
note that our proposed evaluation metrics are more reliable in evaluating these
abilities than the existing metrics. Lastly, some of our benchmarks challenge
the common notion that larger LMs (e.g., GPT-4) universally outshine their
smaller counterparts (e.g., BERT).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">1.5 million materials narratives generated by chatbots. (arXiv:2308.13687v1 [cond-mat.mtrl-sci])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13687">
<div class="article-summary-box-inner">
<span><p>The advent of artificial intelligence (AI) has enabled a comprehensive
exploration of materials for various applications. However, AI models often
prioritize frequently encountered materials in the scientific literature,
limiting the selection of suitable candidates based on inherent physical and
chemical properties. To address this imbalance, we have generated a dataset of
1,494,017 natural language-material paragraphs based on combined OQMD,
Materials Project, JARVIS, COD and AFLOW2 databases, which are dominated by ab
initio calculations and tend to be much more evenly distributed on the periodic
table. The generated text narratives were then polled and scored by both human
experts and ChatGPT-4, based on three rubrics: technical accuracy, language and
structure, and relevance and depth of content, showing similar scores but with
human-scored depth of content being the most lagging. The merger of
multi-modality data sources and large language model (LLM) holds immense
potential for AI frameworks to help the exploration and discovery of
solid-state materials for specific applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Depth between Beam Search and Exhaustive Search for Text Generation. (arXiv:2308.13696v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13696">
<div class="article-summary-box-inner">
<span><p>Beam search and exhaustive search are two extreme ends of text decoding
algorithms with respect to the search depth. Beam search is limited in both
search width and depth, whereas exhaustive search is a global search that has
no such limitations. Surprisingly, beam search is not only computationally
cheaper but also performs better than exhaustive search despite its higher
search error. Plenty of research has investigated a range of beam widths, from
small to large, and reported that a beam width that is neither too large nor
too small is desirable. However, in terms of search depth, only the two extreme
ends, beam search and exhaustive search are studied intensively. In this paper,
we examine a range of search depths between the two extremes to discover the
desirable search depth. To this end, we introduce Lookahead Beam Search (LBS),
a multi-step lookahead search that optimizes the objective considering a fixed
number of future steps. Beam search and exhaustive search are special cases of
LBS where the lookahead depth is set to $0$ and $\infty$, respectively. We
empirically evaluate the performance of LBS and find that it outperforms beam
search overall on machine translation tasks. The result suggests there is room
for improvement in beam search by searching deeper. Inspired by the analysis,
we propose Lookbehind Heuristic Beam Search, a computationally feasible search
algorithm that heuristically simulates LBS with 1-step lookahead. The empirical
results show that the proposed method outperforms vanilla beam search on
machine translation and text summarization tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WellXplain: Wellness Concept Extraction and Classification in Reddit Posts for Mental Health Analysis. (arXiv:2308.13710v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13710">
<div class="article-summary-box-inner">
<span><p>During the current mental health crisis, the importance of identifying
potential indicators of mental issues from social media content has surged.
Overlooking the multifaceted nature of mental and social well-being can have
detrimental effects on one's mental state. In traditional therapy sessions,
professionals manually pinpoint the origins and outcomes of underlying mental
challenges, a process both detailed and time-intensive. We introduce an
approach to this intricate mental health analysis by framing the identification
of wellness dimensions in Reddit content as a wellness concept extraction and
categorization challenge. We've curated a unique dataset named WELLXPLAIN,
comprising 3,092 entries and totaling 72,813 words. Drawing from Halbert L.
Dunn's well-regarded wellness theory, our team formulated an annotation
framework along with guidelines. This dataset also includes human-marked
textual segments, offering clear reasoning for decisions made in the wellness
concept categorization process. Our aim in publishing this dataset and
analyzing initial benchmarks is to spearhead the creation of advanced language
models tailored for healthcare-focused concept extraction and categorization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Computational Evaluation Framework for Singable Lyric Translation. (arXiv:2308.13715v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13715">
<div class="article-summary-box-inner">
<span><p>Lyric translation plays a pivotal role in amplifying the global resonance of
music, bridging cultural divides, and fostering universal connections.
Translating lyrics, unlike conventional translation tasks, requires a delicate
balance between singability and semantics. In this paper, we present a
computational framework for the quantitative evaluation of singable lyric
translation, which seamlessly integrates musical, linguistic, and cultural
dimensions of lyrics. Our comprehensive framework consists of four metrics that
measure syllable count distance, phoneme repetition similarity, musical
structure distance, and semantic similarity. To substantiate the efficacy of
our framework, we collected a singable lyrics dataset, which precisely aligns
English, Japanese, and Korean lyrics on a line-by-line and section-by-section
basis, and conducted a comparative analysis between singable and non-singable
lyrics. Our multidisciplinary approach provides insights into the key
components that underlie the art of lyric translation and establishes a solid
groundwork for the future of computational lyric translation assessment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Philomatics and Psychomatics for Combining Philosophy and Psychology with Mathematics. (arXiv:2308.13738v1 [math.HO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13738">
<div class="article-summary-box-inner">
<span><p>We propose the concepts of philomatics and psychomatics as hybrid
combinations of philosophy and psychology with mathematics. We explain four
motivations for this combination which are fulfilling the desire of analytical
philosophy, proposing science of philosophy, justifying mathematical algorithms
by philosophy, and abstraction in both philosophy and mathematics. We enumerate
various examples for philomatics and psychomatics, some of which are explained
in more depth. The first example is the analysis of relation between the
context principle, semantic holism, and the usage theory of meaning with the
attention mechanism in mathematics. The other example is on the relations of
Plato's theory of forms in philosophy with the holographic principle in string
theory, object-oriented programming, and machine learning. Finally, the
relation between Wittgenstein's family resemblance and clustering in
mathematics is explained. This paper opens the door of research for combining
philosophy and psychology with mathematics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ZC3: Zero-Shot Cross-Language Code Clone Detection. (arXiv:2308.13754v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13754">
<div class="article-summary-box-inner">
<span><p>Developers introduce code clones to improve programming productivity. Many
existing studies have achieved impressive performance in monolingual code clone
detection. However, during software development, more and more developers write
semantically equivalent programs with different languages to support different
platforms and help developers translate projects from one language to another.
Considering that collecting cross-language parallel data, especially for
low-resource languages, is expensive and time-consuming, how designing an
effective cross-language model that does not rely on any parallel data is a
significant problem. In this paper, we propose a novel method named ZC3 for
Zero-shot Cross-language Code Clone detection. ZC3 designs the contrastive
snippet prediction to form an isomorphic representation space among different
programming languages. Based on this, ZC3 exploits domain-aware learning and
cycle consistency learning to further constrain the model to generate
representations that are aligned among different languages meanwhile are
diacritical for different types of clones. To evaluate our approach, we conduct
extensive experiments on four representative cross-language clone detection
datasets. Experimental results show that ZC3 outperforms the state-of-the-art
baselines by 67.12%, 51.39%, 14.85%, and 53.01% on the MAP score, respectively.
We further investigate the representational distribution of different languages
and discuss the effectiveness of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Can Context Help? Exploring Joint Retrieval of Passage and Personalized Context. (arXiv:2308.13760v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13760">
<div class="article-summary-box-inner">
<span><p>The integration of external personalized context information into
document-grounded conversational systems has significant potential business
value, but has not been well-studied. Motivated by the concept of personalized
context-aware document-grounded conversational systems, we introduce the task
of context-aware passage retrieval. We also construct a dataset specifically
curated for this purpose. We describe multiple baseline systems to address this
task, and propose a novel approach, Personalized Context-Aware Search (PCAS),
that effectively harnesses contextual information during passage retrieval.
Experimental evaluations conducted on multiple popular dense retrieval systems
demonstrate that our proposed approach not only outperforms the baselines in
retrieving the most relevant passage but also excels at identifying the
pertinent context among all the available contexts. We envision that our
contributions will serve as a catalyst for inspiring future research endeavors
in this promising direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Fine-Tuning of Language Models: An Iterative Optimisation Approach for the Generation and Detection of Problematic Content. (arXiv:2308.13768v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13768">
<div class="article-summary-box-inner">
<span><p>In this paper, we tackle the emerging challenge of unintended harmful content
generation in Large Language Models (LLMs) with a novel dual-stage optimisation
technique using adversarial fine-tuning. Our two-pronged approach employs an
adversarial model, fine-tuned to generate potentially harmful prompts, and a
judge model, iteratively optimised to discern these prompts. In this
adversarial cycle, the two models seek to outperform each other in the
prompting phase, generating a dataset of rich examples which are then used for
fine-tuning. This iterative application of prompting and fine-tuning allows
continuous refinement and improved performance. The performance of our approach
is evaluated through classification accuracy on a dataset consisting of
problematic prompts not detected by GPT-4, as well as a selection of
contentious but unproblematic prompts. We show considerable increase in
classification accuracy of the judge model on this challenging dataset as it
undergoes the optimisation process. Furthermore, we show that a rudimentary
model \texttt{ada} can achieve 13\% higher accuracy on the hold-out test set
than GPT-4 after only a few rounds of this process, and that this fine-tuning
improves performance in parallel tasks such as toxic comment identification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EditSum: A Retrieve-and-Edit Framework for Source Code Summarization. (arXiv:2308.13775v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13775">
<div class="article-summary-box-inner">
<span><p>Existing studies show that code summaries help developers understand and
maintain source code. Unfortunately, these summaries are often missing or
outdated in software projects. Code summarization aims to generate natural
language descriptions automatically for source code. Code summaries are highly
structured and have repetitive patterns. Besides the patternized words, a code
summary also contains important keywords, which are the key to reflecting the
functionality of the code. However, the state-of-the-art approaches perform
poorly on predicting the keywords, which leads to the generated summaries
suffering a loss in informativeness. To alleviate this problem, this paper
proposes a novel retrieve-and-edit approach named EditSum for code
summarization. Specifically, EditSum first retrieves a similar code snippet
from a pre-defined corpus and treats its summary as a prototype summary to
learn the pattern. Then, EditSum edits the prototype automatically to combine
the pattern in the prototype with the semantic information of input code. Our
motivation is that the retrieved prototype provides a good start-point for
post-generation because the summaries of similar code snippets often have the
same pattern. The post-editing process further reuses the patternized words in
the prototype and generates keywords based on the semantic information of input
code. We conduct experiments on a large-scale Java corpus and experimental
results demonstrate that EditSum outperforms the state-of-the-art approaches by
a substantial margin. The human evaluation also proves the summaries generated
by EditSum are more informative and useful. We also verify that EditSum
performs well on predicting the patternized words and keywords.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Planning with Logical Graph-based Language Model for Instruction Generation. (arXiv:2308.13782v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13782">
<div class="article-summary-box-inner">
<span><p>Despite the superior performance of large language models to generate natural
language texts, it is hard to generate texts with correct logic according to a
given task, due to the difficulties for neural models to capture implied rules
from free-form texts. In this paper, we propose a novel graph-based language
model, Logical-GLM, to infuse logic into language models for more valid text
generation and interpretability. Specifically, we first capture information
from natural language instructions and construct logical bayes graphs that
generally describe domains. Next, we generate logical skeletons to guide
language model training, infusing domain knowledge into language models.
Finally, we alternately optimize the searching policy of graphs and language
models until convergence. The experimental results show that Logical-GLM is
both effective and efficient compared with traditional language models, despite
using smaller-scale training data and fewer parameters. Our approach can
generate instructional texts with more correct logic owing to the internalized
domain knowledge. Moreover, the usage of logical graphs reflects the inner
mechanism of the language models, which improves the interpretability of
black-box models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Solving Math Word Problem with Problem Type Classification. (arXiv:2308.13844v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13844">
<div class="article-summary-box-inner">
<span><p>Math word problems (MWPs) require analyzing text descriptions and generating
mathematical equations to derive solutions. Existing works focus on solving
MWPs with two types of solvers: tree-based solver and large language model
(LLM) solver. However, these approaches always solve MWPs by a single solver,
which will bring the following problems: (1) Single type of solver is hard to
solve all types of MWPs well. (2) A single solver will result in poor
performance due to over-fitting. To address these challenges, this paper
utilizes multiple ensemble approaches to improve MWP-solving ability. Firstly,
We propose a problem type classifier that combines the strengths of the
tree-based solver and the LLM solver. This ensemble approach leverages their
respective advantages and broadens the range of MWPs that can be solved.
Furthermore, we also apply ensemble techniques to both tree-based solver and
LLM solver to improve their performance. For the tree-based solver, we propose
an ensemble learning framework based on ten-fold cross-validation and voting
mechanism. In the LLM solver, we adopt self-consistency (SC) method to improve
answer selection. Experimental results demonstrate the effectiveness of these
ensemble approaches in enhancing MWP-solving ability. The comprehensive
evaluation showcases improved performance, validating the advantages of our
proposed approach. Our code is available at this url:
https://github.com/zhouzihao501/NLPCC2023-Shared-Task3-ChineseMWP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors. (arXiv:2308.13904v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13904">
<div class="article-summary-box-inner">
<span><p>Prompt-tuning has emerged as an attractive paradigm for deploying large-scale
language models due to its strong downstream task performance and efficient
multitask serving ability. Despite its wide adoption, we empirically show that
prompt-tuning is vulnerable to downstream task-agnostic backdoors, which reside
in the pretrained models and can affect arbitrary downstream tasks. The
state-of-the-art backdoor detection approaches cannot defend against
task-agnostic backdoors since they hardly converge in reversing the backdoor
triggers. To address this issue, we propose LMSanitator, a novel approach for
detecting and removing task-agnostic backdoors on Transformer models. Instead
of directly inversing the triggers, LMSanitator aims to inverse the predefined
attack vectors (pretrained models' output when the input is embedded with
triggers) of the task-agnostic backdoors, which achieves much better
convergence performance and backdoor detection accuracy. LMSanitator further
leverages prompt-tuning's property of freezing the pretrained model to perform
accurate and fast output monitoring and input purging during the inference
phase. Extensive experiments on multiple language models and NLP tasks
illustrate the effectiveness of LMSanitator. For instance, LMSanitator achieves
92.8% backdoor detection accuracy on 960 models and decreases the attack
success rate to less than 1% in most scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Wide Evaluation of ChatGPT on Affective Computing Tasks. (arXiv:2308.13911v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13911">
<div class="article-summary-box-inner">
<span><p>With the rise of foundation models, a new artificial intelligence paradigm
has emerged, by simply using general purpose foundation models with prompting
to solve problems instead of training a separate machine learning model for
each problem. Such models have been shown to have emergent properties of
solving problems that they were not initially trained on. The studies for the
effectiveness of such models are still quite limited. In this work, we widely
study the capabilities of the ChatGPT models, namely GPT-4 and GPT-3.5, on 13
affective computing problems, namely aspect extraction, aspect polarity
classification, opinion extraction, sentiment analysis, sentiment intensity
ranking, emotions intensity ranking, suicide tendency detection, toxicity
detection, well-being assessment, engagement measurement, personality
assessment, sarcasm detection, and subjectivity detection. We introduce a
framework to evaluate the ChatGPT models on regression-based problems, such as
intensity ranking problems, by modelling them as pairwise ranking
classification. We compare ChatGPT against more traditional NLP methods, such
as end-to-end recurrent neural networks and transformers. The results
demonstrate the emergent abilities of the ChatGPT models on a wide range of
affective computing problems, where GPT-3.5 and especially GPT-4 have shown
strong performance on many problems, particularly the ones related to
sentiment, emotions, or toxicity. The ChatGPT models fell short for problems
with implicit signals, such as engagement measurement and subjectivity
detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Large Language Models for Knowledge Graph Completion. (arXiv:2308.13916v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13916">
<div class="article-summary-box-inner">
<span><p>Knowledge graphs play a vital role in numerous artificial intelligence tasks,
yet they frequently face the issue of incompleteness. In this study, we explore
utilizing Large Language Models (LLM) for knowledge graph completion. We
consider triples in knowledge graphs as text sequences and introduce an
innovative framework called Knowledge Graph LLM (KG-LLM) to model these
triples. Our technique employs entity and relation descriptions of a triple as
prompts and utilizes the response for predictions. Experiments on various
benchmark knowledge graphs demonstrate that our method attains state-of-the-art
performance in tasks such as triple classification and relation prediction. We
also find that fine-tuning relatively smaller models (e.g., LLaMA-7B,
ChatGLM-6B) outperforms recent ChatGPT and GPT-4.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Knowledge Distillation for BERT Models: Loss Functions, Mapping Methods, and Weight Tuning. (arXiv:2308.13958v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13958">
<div class="article-summary-box-inner">
<span><p>The use of large transformer-based models such as BERT, GPT, and T5 has led
to significant advancements in natural language processing. However, these
models are computationally expensive, necessitating model compression
techniques that reduce their size and complexity while maintaining accuracy.
This project investigates and applies knowledge distillation for BERT model
compression, specifically focusing on the TinyBERT student model. We explore
various techniques to improve knowledge distillation, including experimentation
with loss functions, transformer layer mapping methods, and tuning the weights
of attention and representation loss and evaluate our proposed techniques on a
selection of downstream tasks from the GLUE benchmark. The goal of this work is
to improve the efficiency and effectiveness of knowledge distillation, enabling
the development of more efficient and accurate models for a range of natural
language processing tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Translate Meanings, Not Just Words: IdiomKB's Role in Optimizing Idiomatic Translation with Language Models. (arXiv:2308.13961v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13961">
<div class="article-summary-box-inner">
<span><p>To translate well, machine translation (MT) systems and general-purposed
language models (LMs) need a deep understanding of both source and target
languages and cultures. Therefore, idioms, with their non-compositional nature,
pose particular challenges for Transformer-based systems, as literal
translations often miss the intended meaning. Traditional methods, which
replace idioms using existing knowledge bases (KBs), often lack scale and
context awareness. Addressing these challenges, our approach prioritizes
context awareness and scalability, allowing for offline storage of idioms in a
manageable KB size. This ensures efficient serving with smaller models and
provides a more comprehensive understanding of idiomatic expressions. We
introduce a multilingual idiom KB (IdiomKB) developed using large LMs to
address this. This KB facilitates better translation by smaller models, such as
BLOOMZ (7.1B), Alpaca (7B), and InstructGPT (6.7B), by retrieving idioms'
figurative meanings. We present a novel, GPT-4-powered metric for human-aligned
evaluation, demonstrating that IdiomKB considerably boosts model performance.
Human evaluations further validate our KB's quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoPaSul Manual -- Contour-based parametric and superpositional intonation stylization. (arXiv:1612.04765v11 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1612.04765">
<div class="article-summary-box-inner">
<span><p>The purposes of the CoPaSul toolkit are (1) automatic prosodic annotation and
(2) prosodic feature extraction from syllable to utterance level. CoPaSul
stands for contour-based, parametric, superpositional intonation stylization.
In this framework intonation is represented as a superposition of global and
local contours that are described parametrically in terms of polynomial
coefficients. On the global level (usually associated but not necessarily
restricted to intonation phrases) the stylization serves to represent register
in terms of time-varying F0 level and range. On the local level (e.g. accent
groups), local contour shapes are described. From this parameterization several
features related to prosodic boundaries and prominence can be derived.
Furthermore, by coefficient clustering prosodic contour classes can be obtained
in a bottom-up way. Next to the stylization-based feature extraction also
standard F0 and energy measures (e.g. mean and variance) as well as rhythmic
aspects can be calculated. At the current state automatic annotation comprises:
segmentation into interpausal chunks, syllable nucleus extraction, and
unsupervised localization of prosodic phrase boundaries and prominent
syllables. F0 and partly also energy feature sets can be derived for: standard
measurements (as median and IQR), register in terms of F0 level and range,
prosodic boundaries, local contour shapes, bottom-up derived contour classes,
Gestalt of accent groups in terms of their deviation from higher level prosodic
units, as well as for rhythmic aspects quantifying the relation between F0 and
energy contours and prosodic event rates.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Self-Disclosure In Neural Dialog Models By Candidate Re-ranking. (arXiv:2109.05090v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05090">
<div class="article-summary-box-inner">
<span><p>Neural language modelling has progressed the state-of-the-art in different
downstream Natural Language Processing (NLP) tasks. One such area is of
open-domain dialog modelling, neural dialog models based on GPT-2 such as
DialoGPT have shown promising performance in single-turn conversation. However,
such (neural) dialog models have been criticized for generating responses which
although may have relevance to the previous human response, tend to quickly
dissipate human interest and descend into trivial conversation. One reason for
such performance is the lack of explicit conversation strategy being employed
in human-machine conversation. Humans employ a range of conversation strategies
while engaging in a conversation, one such key social strategies is
Self-disclosure(SD). A phenomenon of revealing information about one-self to
others. Social penetration theory (SPT) proposes that communication between two
people moves from shallow to deeper levels as the relationship progresses
primarily through self-disclosure. Disclosure helps in creating rapport among
the participants engaged in a conversation. In this paper, Self-disclosure
enhancement architecture (SDEA) is introduced utilizing Self-disclosure Topic
Model (SDTM) during inference stage of a neural dialog model to re-rank
response candidates to enhance self-disclosure in single-turn responses from
from the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Making first order linear logic a generating grammar. (arXiv:2206.08955v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08955">
<div class="article-summary-box-inner">
<span><p>It is known that different categorial grammars have surface representation in
a fragment of first order multiplicative linear logic (MLL1). We show that the
fragment of interest is equivalent to the recently introduced extended tensor
type calculus (ETTC). ETTC is a calculus of specific typed terms, which
represent tuples of strings, more precisely bipartite graphs decorated with
strings. Types are derived from linear logic formulas, and rules correspond to
concrete operations on these string-labeled graphs, so that they can be
conveniently visualized. This provides the above mentioned fragment of MLL1
that is relevant for language modeling not only with some alternative syntax
and intuitive geometric representation, but also with an intrinsic deductive
system, which has been absent.
</p>
<p>In this work we consider a non-trivial notationally enriched variation of the
previously introduced {\bf ETTC}, which allows more concise and transparent
computations. We present both a cut-free sequent calculus and a natural
deduction formalism.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantum Circuit Compiler for a Shuttling-Based Trapped-Ion Quantum Computer. (arXiv:2207.01964v3 [quant-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.01964">
<div class="article-summary-box-inner">
<span><p>The increasing capabilities of quantum computing hardware and the challenge
of realizing deep quantum circuits require fully automated and efficient tools
for compiling quantum circuits. To express arbitrary circuits in a sequence of
native gates specific to the quantum computer architecture, it is necessary to
make algorithms portable across the landscape of quantum hardware providers. In
this work, we present a compiler capable of transforming and optimizing a
quantum circuit targeting a shuttling-based trapped-ion quantum processor. It
consists of custom algorithms set on top of the quantum circuit framework
Pytket. The performance was evaluated for a wide range of quantum circuits and
the results show that the gate counts can be reduced by factors up to 5.1
compared to standard Pytket and up to 2.2 compared to standard Qiskit
compilation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explaining Machine Learning Models in Natural Conversations: Towards a Conversational XAI Agent. (arXiv:2209.02552v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.02552">
<div class="article-summary-box-inner">
<span><p>The goal of Explainable AI (XAI) is to design methods to provide insights
into the reasoning process of black-box models, such as deep neural networks,
in order to explain them to humans. Social science research states that such
explanations should be conversational, similar to human-to-human explanations.
In this work, we show how to incorporate XAI in a conversational agent, using a
standard design for the agent comprising natural language understanding and
generation components. We build upon an XAI question bank which we extend by
quality-controlled paraphrases to understand the user's information needs. We
further systematically survey the literature for suitable explanation methods
that provide the information to answer those questions, and present a
comprehensive list of suggestions. Our work is the first step towards truly
natural conversations about machine learning models with an explanation agent.
The comprehensive list of XAI questions and the corresponding explanation
methods may support other researchers in providing the necessary information to
address users' demands.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parameter-Efficient Finetuning for Robust Continual Multilingual Learning. (arXiv:2209.06767v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.06767">
<div class="article-summary-box-inner">
<span><p>We introduce and study the problem of Continual Multilingual Learning (CML)
where a previously trained multilingual model is periodically updated using new
data arriving in stages. If the new data is present only in a subset of
languages, we find that the resulting model shows improved performance only on
the languages included in the latest update (and a few closely related
languages) while its performance on all the remaining languages degrade
significantly. We address this challenge by proposing LAFT-URIEL, a
parameter-efficient finetuning strategy which aims to increase the number of
languages on which the model improves after an update, while reducing the
magnitude of loss in performance for the remaining languages. LAFT-URIEL uses
linguistic knowledge to balance overfitting and knowledge sharing across
languages, allowing for an additional 25% of task languages to see an
improvement in performance after an update, while also reducing the average
magnitude of losses on the remaining languages by 78% relative.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations at Twitter. (arXiv:2209.07562v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.07562">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PLMs) are fundamental for natural language
processing applications. Most existing PLMs are not tailored to the noisy
user-generated text on social media, and the pre-training does not factor in
the valuable social engagement logs available in a social network. We present
TwHIN-BERT, a multilingual language model productionized at Twitter, trained on
in-domain data from the popular social network. TwHIN-BERT differs from prior
pre-trained language models as it is trained with not only text-based
self-supervision, but also with a social objective based on the rich social
engagements within a Twitter heterogeneous information network (TwHIN). Our
model is trained on 7 billion tweets covering over 100 distinct languages,
providing a valuable representation to model short, noisy, user-generated text.
We evaluate our model on various multilingual social recommendation and
semantic understanding tasks and demonstrate significant metric improvement
over established pre-trained language models. We open-source TwHIN-BERT and our
curated hashtag prediction and social engagement benchmark datasets to the
research community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-View Reasoning: Consistent Contrastive Learning for Math Word Problem. (arXiv:2210.11694v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11694">
<div class="article-summary-box-inner">
<span><p>Math word problem solver requires both precise relation reasoning about
quantities in the text and reliable generation for the diverse equation.
Current sequence-to-tree or relation extraction methods regard this only from a
fixed view, struggling to simultaneously handle complex semantics and diverse
equations. However, human solving naturally involves two consistent reasoning
views: top-down and bottom-up, just as math equations also can be expressed in
multiple equivalent forms: pre-order and post-order. We propose a multi-view
consistent contrastive learning for a more complete semantics-to-equation
mapping. The entire process is decoupled into two independent but consistent
views: top-down decomposition and bottom-up construction, and the two reasoning
views are aligned in multi-granularity for consistency, enhancing global
generation and precise reasoning. Experiments on multiple datasets across two
languages show our approach significantly outperforms the existing baselines,
especially on complex problems. We also show after consistent alignment,
multi-view can absorb the merits of both views and generate more diverse
results consistent with the mathematical laws.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Event knowledge in large language models: the gap between the impossible and the unlikely. (arXiv:2212.01488v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01488">
<div class="article-summary-box-inner">
<span><p>Word co-occurrence patterns in language corpora contain a surprising amount
of conceptual knowledge. Large language models (LLMs), trained to predict words
in context, leverage these patterns to achieve impressive performance on
diverse semantic tasks requiring world knowledge. An important but understudied
question about LLMs' semantic abilities is whether they acquire generalized
knowledge of common events. Here, we test whether five pre-trained LLMs (from
2018's BERT to 2023's MPT) assign higher likelihood to plausible descriptions
of agent-patient interactions than to minimally different implausible versions
of the same event. Using three curated sets of minimal sentence pairs (total
n=1,215), we found that pre-trained LLMs possess substantial event knowledge,
outperforming other distributional language models. In particular, they almost
always assign higher likelihood to possible vs. impossible events (The teacher
bought the laptop vs. The laptop bought the teacher). However, LLMs show less
consistent preferences for likely vs. unlikely events (The nanny tutored the
boy vs. The boy tutored the nanny). In follow-up analyses, we show that (i) LLM
scores are driven by both plausibility and surface-level sentence features,
(ii) LLM scores generalize well across syntactic variants (active vs. passive
constructions) but less well across semantic variants (synonymous sentences),
(iii) some LLM errors mirror human judgment ambiguity, and (iv) sentence
plausibility serves as an organizing dimension in internal LLM representations.
Overall, our results show that important aspects of event knowledge naturally
emerge from distributional linguistic patterns, but also highlight a gap
between representations of possible/impossible and likely/unlikely events.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Protecting Language Generation Models via Invisible Watermarking. (arXiv:2302.03162v3 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03162">
<div class="article-summary-box-inner">
<span><p>Language generation models have been an increasingly powerful enabler for
many applications. Many such models offer free or affordable API access, which
makes them potentially vulnerable to model extraction attacks through
distillation. To protect intellectual property (IP) and ensure fair use of
these models, various techniques such as lexical watermarking and synonym
replacement have been proposed. However, these methods can be nullified by
obvious countermeasures such as "synonym randomization". To address this issue,
we propose GINSEW, a novel method to protect text generation models from being
stolen through distillation. The key idea of our method is to inject secret
signals into the probability vector of the decoding steps for each target
token. We can then detect the secret message by probing a suspect model to tell
if it is distilled from the protected one. Experimental results show that
GINSEW can effectively identify instances of IP infringement with minimal
impact on the generation quality of protected APIs. Our method demonstrates an
absolute improvement of 19 to 29 points on mean average precision (mAP) in
detecting suspects compared to previous methods against watermark removal
attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Re-Label Method For Data-Centric Machine Learning. (arXiv:2302.04391v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04391">
<div class="article-summary-box-inner">
<span><p>In industry deep learning application, our manually labeled data has a
certain number of noisy data. To solve this problem and achieve more than 90
score in dev dataset, we present a simple method to find the noisy data and
re-label the noisy data by human, given the model predictions as references in
human labeling. In this paper, we illustrate our idea for a broad set of deep
learning tasks, includes classification, sequence tagging, object detection,
sequence generation, click-through rate prediction. The experimental results
and human evaluation results verify our idea.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EmotionIC: Emotional Inertia and Contagion-Driven Dependency Modeling for Emotion Recognition in Conversation. (arXiv:2303.11117v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11117">
<div class="article-summary-box-inner">
<span><p>Emotion Recognition in Conversation (ERC) has attracted growing attention in
recent years as a result of the advancement and implementation of
human-computer interface technologies. In this paper, we propose a novel
approach to dependency modeling driven by Emotional Inertia and Contagion
(EmotionIC) for ERC task. Our EmotionIC consists of three main components,
i.e., Identity Masked Multi-Head Attention (IMMHA), Dialogue-based Gated
Recurrent Unit (DiaGRU), and Skip-chain Conditional Random Field (SkipCRF).
Compared to previous ERC models, EmotionIC can model a conversation more
thoroughly at both the feature-extraction and classification levels. The
proposed model attempts to integrate the advantages of attention- and
recurrence-based methods at the feature-extraction level. Specifically, IMMHA
is applied to capture identity-based global contextual dependencies, while
DiaGRU is utilized to extract speaker- and temporal-aware local contextual
information. At the classification level, SkipCRF can explicitly mine complex
emotional flows from higher-order neighboring utterances in the conversation.
Experimental results show that our method can significantly outperform the
state-of-the-art models on four benchmark datasets. The ablation studies
confirm that our modules can effectively model emotional inertia and contagion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Model Behavior: A Comprehensive Survey. (arXiv:2303.11504v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.11504">
<div class="article-summary-box-inner">
<span><p>Transformer language models have received widespread public attention, yet
their generated text is often surprising even to NLP researchers. In this
survey, we discuss over 250 recent studies of English language model behavior
before task-specific fine-tuning. Language models possess basic capabilities in
syntax, semantics, pragmatics, world knowledge, and reasoning, but these
capabilities are sensitive to specific inputs and surface features. Despite
dramatic increases in generated text quality as models scale to hundreds of
billions of parameters, the models are still prone to unfactual responses,
commonsense errors, memorized text, and social biases. Many of these weaknesses
can be framed as over-generalizations or under-generalizations of learned
patterns in text. We synthesize recent results to highlight what is currently
known about large language model capabilities, thus providing a resource for
applied work and for research in adjacent fields that use language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparing Abstractive Summaries Generated by ChatGPT to Real Summaries Through Blinded Reviewers and Text Classification Algorithms. (arXiv:2303.17650v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17650">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have gathered significant attention due to their
impressive performance on a variety of tasks. ChatGPT, developed by OpenAI, is
a recent addition to the family of language models and is being called a
disruptive technology by a few, owing to its human-like text-generation
capabilities. Although, many anecdotal examples across the internet have
evaluated ChatGPT's strength and weakness, only a few systematic research
studies exist. To contribute to the body of literature of systematic research
on ChatGPT, we evaluate the performance of ChatGPT on Abstractive Summarization
by the means of automated metrics and blinded human reviewers. We also build
automatic text classifiers to detect ChatGPT generated summaries. We found that
while text classification algorithms can distinguish between real and generated
summaries, humans are unable to distinguish between real summaries and those
produced by ChatGPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does Human Collaboration Enhance the Accuracy of Identifying LLM-Generated Deepfake Texts?. (arXiv:2304.01002v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.01002">
<div class="article-summary-box-inner">
<span><p>Advances in Large Language Models (e.g., GPT-4, LLaMA) have improved the
generation of coherent sentences resembling human writing on a large scale,
resulting in the creation of so-called deepfake texts. However, this progress
poses security and privacy concerns, necessitating effective solutions for
distinguishing deepfake texts from human-written ones. Although prior works
studied humans' ability to detect deepfake texts, none has examined whether
"collaboration" among humans improves the detection of deepfake texts. In this
study, to address this gap of understanding on deepfake texts, we conducted
experiments with two groups: (1) nonexpert individuals from the AMT platform
and (2) writing experts from the Upwork platform. The results demonstrate that
collaboration among humans can potentially improve the detection of deepfake
texts for both groups, increasing detection accuracies by 6.36% for non-experts
and 12.76% for experts, respectively, compared to individuals' detection
accuracies. We further analyze the explanations that humans used for detecting
a piece of text as deepfake text, and find that the strongest indicator of
deepfake texts is their lack of coherence and consistency. Our study provides
useful insights for future tools and framework designs to facilitate the
collaborative human detection of deepfake texts. The experiment datasets and
AMT implementations are available at:
https://github.com/huashen218/llm-deepfake-human-study.git
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PGTask: Introducing the Task of Profile Generation from Dialogues. (arXiv:2304.06634v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.06634">
<div class="article-summary-box-inner">
<span><p>Recent approaches have attempted to personalize dialogue systems by
leveraging profile information into models. However, this knowledge is scarce
and difficult to obtain, which makes the extraction/generation of profile
information from dialogues a fundamental asset. To surpass this limitation, we
introduce the Profile Generation Task (PGTask). We contribute with a new
dataset for this problem, comprising profile sentences aligned with related
utterances, extracted from a corpus of dialogues. Furthermore, using
state-of-the-art methods, we provide a benchmark for profile generation on this
novel dataset. Our experiments disclose the challenges of profile generation,
and we hope that this introduces a new research direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers. (arXiv:2305.07011v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07011">
<div class="article-summary-box-inner">
<span><p>We present Region-aware Open-vocabulary Vision Transformers (RO-ViT) - a
contrastive image-text pretraining recipe to bridge the gap between image-level
pretraining and open-vocabulary object detection. At the pretraining phase, we
propose to randomly crop and resize regions of positional embeddings instead of
using the whole image positional embeddings. This better matches the use of
positional embeddings at region-level in the detection finetuning phase. In
addition, we replace the common softmax cross entropy loss in contrastive
learning with focal loss to better learn the informative yet difficult
examples. Finally, we leverage recent advances in novel object proposals to
improve open-vocabulary detection finetuning. We evaluate our full model on the
LVIS and COCO open-vocabulary detection benchmarks and zero-shot transfer.
RO-ViT achieves a state-of-the-art 34.1 $AP_r$ on LVIS, surpassing the best
existing approach by +7.8 points in addition to competitive zero-shot transfer
detection. Surprisingly, RO-ViT improves the image-level representation as well
and achieves the state of the art on 9 out of 12 metrics on COCO and Flickr
image-text retrieval benchmarks, outperforming competitive approaches with
larger models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Versatile and Efficient Visual Knowledge Integration into Pre-trained Language Models with Cross-Modal Adapters. (arXiv:2305.07358v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07358">
<div class="article-summary-box-inner">
<span><p>Humans learn language via multi-modal knowledge. However, due to the
text-only pre-training scheme, most existing pre-trained language models (PLMs)
are hindered from the multi-modal information.
</p>
<p>To inject visual knowledge into PLMs, existing methods incorporate either the
text or image encoder of vision-language models (VLMs) to encode the visual
information and update all the original parameters of PLMs for knowledge
fusion.
</p>
<p>In this paper, we propose a new plug-and-play module, X-adapter, to flexibly
leverage the aligned visual and textual knowledge learned in pre-trained VLMs
and efficiently inject them into PLMs.
</p>
<p>Specifically, we insert X-adapters into PLMs, and only the added parameters
are updated during adaptation.
</p>
<p>To fully exploit the potential in VLMs, X-adapters consist of two
sub-modules, V-expert and T-expert, to fuse VLMs' image and text
representations, respectively.
</p>
<p>We can opt for activating different sub-modules depending on the downstream
tasks.
</p>
<p>Experimental results show that our method can significantly improve the
performance on object-color reasoning and natural language understanding (NLU)
tasks compared with PLM baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Open-QA Evaluation. (arXiv:2305.12421v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.12421">
<div class="article-summary-box-inner">
<span><p>This study focuses on the evaluation of the Open Question Answering (Open-QA)
task, which can directly estimate the factuality of large language models
(LLMs). Current automatic evaluation methods have shown limitations, indicating
that human evaluation still remains the most reliable approach. We introduce a
new task, Evaluating QA Evaluation (QA-Eval) and the corresponding dataset
EVOUNA, designed to assess the accuracy of AI-generated answers in relation to
standard answers within Open-QA. Our evaluation of these methods utilizes
human-annotated results to measure their performance. Specifically, the work
investigates methods that show high correlation with human evaluations, deeming
them more reliable. We also discuss the pitfalls of current methods and methods
to improve LLM-based evaluators. We believe this new QA-Eval task and
corresponding dataset EVOUNA will facilitate the development of more effective
automatic evaluation tools and prove valuable for future research in this area.
All resources are available at \url{https://github.com/wangcunxiang/QA-Eval}
and it is under the Apache-2.0 License.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Effects of Political Martyrdom on Election Results: The Assassination of Abe. (arXiv:2305.18004v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18004">
<div class="article-summary-box-inner">
<span><p>In developed nations assassinations are rare and thus the impact of such acts
on the electoral and political landscape is understudied. In this paper, we
focus on Twitter data to examine the effects of Japan's former Primer Minister
Abe's assassination on the Japanese House of Councillors elections in 2022. We
utilize sentiment analysis and emotion detection together with topic modeling
on over 2 million tweets and compare them against tweets during previous
election cycles. Our findings indicate that Twitter sentiments were negatively
impacted by the event in the short term and that social media attention span
has shortened. We also discuss how "necropolitics" affected the outcome of the
elections in favor of the deceased's party meaning that there seems to have
been an effect of Abe's death on the election outcome though the findings
warrant further investigation for conclusive results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Specialization as the Key to Make Large Language Models Disruptive: A Comprehensive Survey. (arXiv:2305.18703v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18703">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have significantly advanced the field of natural
language processing (NLP), providing a highly useful, task-agnostic foundation
for a wide range of applications. However, directly applying LLMs to solve
sophisticated problems in specific domains meets many hurdles, caused by the
heterogeneity of domain data, the sophistication of domain knowledge, the
uniqueness of domain objectives, and the diversity of the constraints (e.g.,
various social norms, cultural conformity, religious beliefs, and ethical
standards in the domain applications). Domain specification techniques are key
to make large language models disruptive in many applications. Specifically, to
solve these hurdles, there has been a notable increase in research and
practices conducted in recent years on the domain specialization of LLMs. This
emerging field of study, with its substantial potential for impact,
necessitates a comprehensive and systematic review to better summarize and
guide ongoing work in this area. In this article, we present a comprehensive
survey on domain specification techniques for large language models, an
emerging direction critical for large language model applications. First, we
propose a systematic taxonomy that categorizes the LLM domain-specialization
techniques based on the accessibility to LLMs and summarizes the framework for
all the subcategories as well as their relations and differences to each other.
Second, we present an extensive taxonomy of critical application domains that
can benefit dramatically from specialized LLMs, discussing their practical
significance and open challenges. Last, we offer our insights into the current
research status and future trends in this area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises. (arXiv:2306.04802v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.04802">
<div class="article-summary-box-inner">
<span><p>Healthcare knowledge graphs (HKGs) have emerged as a promising tool for
organizing medical knowledge in a structured and interpretable way, which
provides a comprehensive view of medical concepts and their relationships.
However, challenges such as data heterogeneity and limited coverage remain,
emphasizing the need for further research in the field of HKGs. This survey
paper serves as the first comprehensive overview of HKGs. We summarize the
pipeline and key techniques for HKG construction (i.e., from scratch and
through integration), as well as the common utilization approaches (i.e.,
model-free and model-based). To provide researchers with valuable resources, we
organize existing HKGs (The resource is available at
https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase) based on the
data types they capture and application domains, supplemented with pertinent
statistical information. In the application section, we delve into the
transformative impact of HKGs across various healthcare domains, spanning from
fine-grained basic science research to high-level clinical decision support.
Lastly, we shed light on the opportunities for creating comprehensive and
accurate HKGs in the era of large language models, presenting the potential to
revolutionize healthcare delivery and enhance the interpretability and
reliability of clinical prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RestGPT: Connecting Large Language Models with Real-World RESTful APIs. (arXiv:2306.06624v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.06624">
<div class="article-summary-box-inner">
<span><p>Tool-augmented large language models (LLMs) have achieved remarkable progress
in tackling a broad range of tasks. However, existing methods are mainly
restricted to specifically designed tools and fail to fulfill complex
instructions, having great limitations when confronted with real-world
scenarios. In this paper, we explore a more realistic scenario by connecting
LLMs with RESTful APIs, which adhere to the widely adopted REST software
architectural style for web service development. To address the practical
challenges of tackling complex instructions, we propose RestGPT, which exploits
the power of LLMs and conducts a coarse-to-fine online planning mechanism to
enhance the abilities of task decomposition and API selection. RestGPT also
contains an API executor tailored for calling RESTful APIs, which can
meticulously formulate parameters and parse API responses. To fully evaluate
the performance of RestGPT, we propose RestBench, a high-quality benchmark
which consists of two real-world scenarios and human-annotated instructions
with gold solution paths. Experiments show that RestGPT is able to achieve
impressive results in complex tasks and has strong robustness, which paves a
new way towards AGI. RestGPT and RestBench is publicly available at
https://restgpt.github.io/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models are Fixated by Red Herrings: Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset. (arXiv:2306.11167v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.11167">
<div class="article-summary-box-inner">
<span><p>The quest for human imitative AI has been an enduring topic in AI research
since its inception. The technical evolution and emerging capabilities of the
latest cohort of large language models (LLMs) have reinvigorated the subject
beyond academia to the cultural zeitgeist. While recent NLP evaluation
benchmark tasks test some aspects of human-imitative behaviour (e.g.,
BIG-bench's 'human-like behavior' tasks), few, if not none, examine creative
problem solving abilities. Creative problem solving in humans is a well-studied
topic in cognitive neuroscience with standardized tests that predominantly use
the ability to associate (heterogeneous) connections among clue words as a
metric for creativity. Exposure to misleading stimuli - distractors dubbed red
herrings - impede human performance in such tasks via the fixation effect and
Einstellung paradigm. In cognitive neuroscience studies, such fixations are
experimentally induced by pre-exposing participants to orthographically similar
incorrect words to subsequent word-fragments or clues. The popular British quiz
show Only Connect's Connecting Wall segment essentially mimics Mednick's Remote
Associates Test (RAT) formulation with built-in, deliberate red herrings, which
makes it an ideal proxy dataset to explore and study fixation effect and
Einstellung paradigm from cognitive neuroscience in LLMs. In this paper we
present the novel Only Connect Wall (OCW) dataset and report results from our
evaluation of selected pre-trained language models and LLMs on creative problem
solving tasks like grouping clue words by heterogeneous connections, and
identifying correct open knowledge domain connections in respective groups. We
synthetically generate two additional datasets: OCW-Randomized, OCW-WordNet to
further analyze our red-herrings hypothesis in language models. The code and
link to the dataset are available at https://github.com/TaatiTeam/OCW.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emoji Prediction in Tweets using BERT. (arXiv:2307.02054v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.02054">
<div class="article-summary-box-inner">
<span><p>In recent years, the use of emojis in social media has increased
dramatically, making them an important element in understanding online
communication. However, predicting the meaning of emojis in a given text is a
challenging task due to their ambiguous nature. In this study, we propose a
transformer-based approach for emoji prediction using BERT, a widely-used
pre-trained language model. We fine-tuned BERT on a large corpus of text
(tweets) containing both text and emojis to predict the most appropriate emoji
for a given text. Our experimental results demonstrate that our approach
outperforms several state-of-the-art models in predicting emojis with an
accuracy of over 75 percent. This work has potential applications in natural
language processing, sentiment analysis, and social media marketing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Linguistic Style Matching in Online Communities: The Role of Social Context and Conversation Dynamics. (arXiv:2307.02758v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.02758">
<div class="article-summary-box-inner">
<span><p>Linguistic style matching (LSM) in conversations can be reflective of several
aspects of social influence such as power or persuasion. However, how LSM
relates to the outcomes of online communication on platforms such as Reddit is
an unknown question. In this study, we analyze a large corpus of two-party
conversation threads in Reddit where we identify all occurrences of LSM using
two types of style: the use of function words and formality. Using this
framework, we examine how levels of LSM differ in conversations depending on
several social factors within Reddit: post and subreddit features, conversation
depth, user tenure, and the controversiality of a comment. Finally, we measure
the change of LSM following loss of status after community banning. Our
findings reveal the interplay of LSM in Reddit conversations with several
community metrics, suggesting the importance of understanding conversation
engagement when understanding community dynamics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Domain Adaptation of Sentence Embeddings Using Adapters. (arXiv:2307.03104v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03104">
<div class="article-summary-box-inner">
<span><p>Sentence embeddings enable us to capture the semantic similarity of short
texts. Most sentence embedding models are trained for general semantic textual
similarity tasks. Therefore, to use sentence embeddings in a particular domain,
the model must be adapted to it in order to achieve good results. Usually, this
is done by fine-tuning the entire sentence embedding model for the domain of
interest. While this approach yields state-of-the-art results, all of the
model's weights are updated during fine-tuning, making this method
resource-intensive. Therefore, instead of fine-tuning entire sentence embedding
models for each target domain individually, we propose to train lightweight
adapters. These domain-specific adapters do not require fine-tuning all
underlying sentence embedding model parameters. Instead, we only train a small
number of additional parameters while keeping the weights of the underlying
sentence embedding model fixed. Training domain-specific adapters allows always
using the same base model and only exchanging the domain-specific adapters to
adapt sentence embeddings to a specific domain. We show that using adapters for
parameter-efficient domain adaptation of sentence embeddings yields competitive
performance within 1% of a domain-adapted, entirely fine-tuned sentence
embedding model while only training approximately 3.6% of the parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v7 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03109">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) are gaining increasing popularity in both
academia and industry, owing to their unprecedented performance in various
applications. As LLMs continue to play a vital role in both research and daily
use, their evaluation becomes increasingly critical, not only at the task
level, but also at the society level for better understanding of their
potential risks. Over the past years, significant efforts have been made to
examine LLMs from various perspectives. This paper presents a comprehensive
review of these evaluation methods for LLMs, focusing on three key dimensions:
what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide
an overview from the perspective of evaluation tasks, encompassing general
natural language processing tasks, reasoning, medical usage, ethics,
educations, natural and social sciences, agent applications, and other areas.
Secondly, we answer the `where' and `how' questions by diving into the
evaluation methods and benchmarks, which serve as crucial components in
assessing performance of LLMs. Then, we summarize the success and failure cases
of LLMs in different tasks. Finally, we shed light on several future challenges
that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to
researchers in the realm of LLMs evaluation, thereby aiding the development of
more proficient LLMs. Our key point is that evaluation should be treated as an
essential discipline to better assist the development of LLMs. We consistently
maintain the related open-source materials at:
https://github.com/MLGroupJLU/LLM-eval-survey.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity Using Contrastive Learning and Structured Knowledge. (arXiv:2307.07851v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.07851">
<div class="article-summary-box-inner">
<span><p>Generic sentence embeddings provide a coarse-grained approximation of
semantic textual similarity but ignore specific aspects that make texts
similar. Conversely, aspect-based sentence embeddings provide similarities
between texts based on certain predefined aspects. Thus, similarity predictions
of texts are more targeted to specific requirements and more easily
explainable. In this paper, we present AspectCSE, an approach for aspect-based
contrastive learning of sentence embeddings. Results indicate that AspectCSE
achieves an average improvement of 3.97% on information retrieval tasks across
multiple aspects compared to the previous best results. We also propose using
Wikidata knowledge graph properties to train models of multi-aspect sentence
embeddings in which multiple specific aspects are simultaneously considered
during similarity predictions. We demonstrate that multi-aspect embeddings
outperform single-aspect embeddings on aspect-specific information retrieval
tasks. Finally, we examine the aspect-based sentence embedding space and
demonstrate that embeddings of semantically similar aspect labels are often
close, even without explicit similarity training between different aspect
labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Communicative Agents for Software Development. (arXiv:2307.07924v3 [cs.SE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.07924">
<div class="article-summary-box-inner">
<span><p>Software engineering is a domain characterized by intricate decision-making
processes, often relying on nuanced intuition and consultation. Recent
advancements in deep learning have started to revolutionize software
engineering practices through elaborate designs implemented at various stages
of software development. In this paper, we present an innovative paradigm that
leverages large language models (LLMs) throughout the entire software
development process, streamlining and unifying key processes through natural
language communication, thereby eliminating the need for specialized models at
each phase. At the core of this paradigm lies ChatDev, a virtual chat-powered
software development company that mirrors the established waterfall model,
meticulously dividing the development process into four distinct chronological
stages: designing, coding, testing, and documenting. Each stage engages a team
of agents, such as programmers, code reviewers, and test engineers, fostering
collaborative dialogue and facilitating a seamless workflow. The chat chain
acts as a facilitator, breaking down each stage into atomic subtasks. This
enables dual roles, allowing for proposing and validating solutions through
context-aware communication, leading to efficient resolution of specific
subtasks. The instrumental analysis of ChatDev highlights its remarkable
efficacy in software generation, enabling the completion of the entire software
development process in under seven minutes at a cost of less than one dollar.
It not only identifies and alleviates potential vulnerabilities but also
rectifies potential hallucinations while maintaining commendable efficiency and
cost-effectiveness. The potential of ChatDev unveils fresh possibilities for
integrating LLMs into the realm of software development.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output Robustness of Large Language Models. (arXiv:2307.08487v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.08487">
<div class="article-summary-box-inner">
<span><p>Considerable research efforts have been devoted to ensuring that large
language models (LLMs) align with human values and generate safe text. However,
an excessive focus on sensitivity to certain topics can compromise the model's
robustness in following instructions, thereby impacting its overall performance
in completing tasks. Previous benchmarks for jailbreaking LLMs have primarily
focused on evaluating the safety of the models without considering their
robustness. In this paper, we propose a benchmark that assesses both the safety
and robustness of LLMs, emphasizing the need for a balanced approach. To
comprehensively study text safety and output robustness, we introduce a latent
jailbreak prompt dataset, each involving malicious instruction embedding.
Specifically, we instruct the model to complete a regular task, such as
translation, with the text to be translated containing malicious instructions.
To further analyze safety and robustness, we design a hierarchical annotation
framework. We present a systematic analysis of the safety and robustness of
LLMs regarding the position of explicit normal instructions, word replacements
(verbs in explicit normal instructions, target groups in malicious
instructions, cue words for explicit normal instructions), and instruction
replacements (different explicit normal instructions). Our results demonstrate
that current LLMs not only prioritize certain instruction verbs but also
exhibit varying jailbreak rates for different instruction verbs in explicit
normal instructions. Code and data are available at
https://github.com/qiuhuachuan/latent-jailbreak.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">External Reasoning: Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback. (arXiv:2307.12057v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.12057">
<div class="article-summary-box-inner">
<span><p>Memory is identified as a crucial human faculty that allows for the retention
of visual and linguistic information within the hippocampus and neurons in the
brain, which can subsequently be retrieved to address real-world challenges
that arise through a lifetime of learning. The resolution of complex AI tasks
through the application of acquired knowledge represents a stride toward the
realization of artificial general intelligence. However, despite the prevalence
of Large Language Models (LLMs) like GPT-3.5 and GPT-4 \cite{brown2020language,
leiter2023chatgpt, zaitsu2023distinguishing, OpenAI2023GPT4TR} , which have
displayed remarkable capabilities in language comprehension, generation,
interaction, and reasoning, they are inhibited by constraints on context length
that preclude the processing of extensive, continually evolving knowledge
bases. This paper proposes that LLMs could be augmented through the selective
integration of knowledge from external repositories, and in doing so,
introduces a novel methodology for External Reasoning, exemplified by ChatPDF.
Central to this approach is the establishment of a tiered policy for
\textbf{External Reasoning based on Multiple LLM Interchange Assistance} in
\cref{fig:overall}, where the level of support rendered is modulated across
entry, intermediate, and advanced tiers based on the complexity of the query,
with adjustments made in response to human feedback. A comprehensive evaluation
of this methodology is conducted using multiple LLMs and the results indicate
state-of-the-art performance in \cref{comparison} , surpassing existing
solutions including ChatPDF.com. Moreover, the paper emphasizes that this
approach is more efficient compared to the direct processing of full text by
LLMs. The source code is publicly available at:
\url{https://github.com/AkideLiu/ANLP}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Ensemble Approach to Question Classification: Integrating Electra Transformer, GloVe, and LSTM. (arXiv:2308.06828v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06828">
<div class="article-summary-box-inner">
<span><p>Natural Language Processing (NLP) has emerged as a crucial technology for
understanding and generating human language, playing an essential role in tasks
such as machine translation, sentiment analysis, and more pertinently, question
classification. As a subfield within NLP, question classification focuses on
determining the type of information being sought, a fundamental step for
downstream applications like question answering systems. This study presents an
innovative ensemble approach for question classification, combining the
strengths of Electra, GloVe, and LSTM models. Rigorously tested on the
well-regarded TREC dataset, the model demonstrates how the integration of these
disparate technologies can lead to superior results. Electra brings in its
transformer-based capabilities for complex language understanding, GloVe offers
global vector representations for capturing word-level semantics, and LSTM
contributes its sequence learning abilities to model long-term dependencies. By
fusing these elements strategically, our ensemble model delivers a robust and
efficient solution for the complex task of question classification. Through
rigorous comparisons with well-known models like BERT, RoBERTa, and DistilBERT,
the ensemble approach verifies its effectiveness by attaining an 80% accuracy
score on the test dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EcomGPT: Instruction-tuning Large Language Models with Chain-of-Task Tasks for E-commerce. (arXiv:2308.06966v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06966">
<div class="article-summary-box-inner">
<span><p>Recently, instruction-following Large Language Models (LLMs) , represented by
ChatGPT, have exhibited exceptional performance in general Natural Language
Processing (NLP) tasks. However, the unique characteristics of E-commerce data
pose significant challenges to general LLMs. An LLM tailored specifically for
E-commerce scenarios, possessing robust cross-dataset/task generalization
capabilities, is a pressing necessity. To solve this issue, in this work, we
proposed the first e-commerce instruction dataset EcomInstruct, with a total of
2.5 million instruction data. EcomInstruct scales up the data size and task
diversity by constructing atomic tasks with E-commerce basic data types, such
as product information, user reviews. Atomic tasks are defined as intermediate
tasks implicitly involved in solving a final task, which we also call
Chain-of-Task tasks. We developed EcomGPT with different parameter scales by
training the backbone model BLOOMZ with the EcomInstruct. Benefiting from the
fundamental semantic understanding capabilities acquired from the Chain-of-Task
tasks, EcomGPT exhibits excellent zero-shot generalization capabilities.
Extensive experiments and human evaluations demonstrate that EcomGPT
outperforms ChatGPT in term of cross-dataset/task generalization on E-commerce
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SPM: Structured Pretraining and Matching Architectures for Relevance Modeling in Meituan Search. (arXiv:2308.07711v3 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.07711">
<div class="article-summary-box-inner">
<span><p>In e-commerce search, relevance between query and documents is an essential
requirement for satisfying user experience. Different from traditional
e-commerce platforms that offer products, users search on life service
platforms such as Meituan mainly for product providers, which usually have
abundant structured information, e.g. name, address, category, thousands of
products. Modeling search relevance with these rich structured contents is
challenging due to the following issues: (1) there is language distribution
discrepancy among different fields of structured document, making it difficult
to directly adopt off-the-shelf pretrained language model based methods like
BERT. (2) different fields usually have different importance and their length
vary greatly, making it difficult to extract document information helpful for
relevance matching.
</p>
<p>To tackle these issues, in this paper we propose a novel two-stage
pretraining and matching architecture for relevance matching with rich
structured documents. At pretraining stage, we propose an effective pretraining
method that employs both query and multiple fields of document as inputs,
including an effective information compression method for lengthy fields. At
relevance matching stage, a novel matching method is proposed by leveraging
domain knowledge in search query to generate more effective document
representations for relevance scoring. Extensive offline experiments and online
A/B tests on millions of users verify that the proposed architectures
effectively improve the performance of relevance modeling. The model has
already been deployed online, serving the search traffic of Meituan for over a
year.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models. (arXiv:2308.09729v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.09729">
<div class="article-summary-box-inner">
<span><p>LLMs usually exhibit limitations in their ability to incorporate new
knowledge, the generation of hallucinations, and the transparency of their
decision-making process. In this paper, we explore how to prompt LLMs with
knowledge graphs (KG), working as a remedy to engage LLMs with up-to-date
knowledge and elicit the reasoning pathways from LLMs. Specifically, we build a
prompting pipeline that endows LLMs with the capability of comprehending KG
inputs and inferring with a combined implicit knowledge and the retrieved
external knowledge. In addition, we investigate eliciting the mind map on which
LLMs perform the reasoning and generate the answers. It is identified that the
produced mind map exhibits the reasoning pathways of LLMs grounded on the
ontology of knowledge, hence bringing the prospects of probing and gauging LLM
inference in production. The experiments on three question &amp; answering datasets
also show that MindMap prompting leads to a striking empirical gain. For
instance, prompting a GPT-3.5 with MindMap yields an overwhelming performance
over GPT-4 consistently. We also demonstrate that with structured facts
retrieved from KG, MindMap can outperform a series of
prompting-with-document-retrieval methods, benefiting from more accurate,
concise, and comprehensive knowledge from KGs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Study on Robustness and Reliability of Large Language Model Code Generation. (arXiv:2308.10335v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.10335">
<div class="article-summary-box-inner">
<span><p>Recently, the large language models (LLMs) have shown extraordinary ability
in understanding natural language and generating programming code. It has been
a common practice of software engineers to consult LLMs when encountering
coding questions. Although efforts have been made to avoid syntax errors and
align the code with the intended semantics, the reliability and robustness of
the code generationfrom LLMs have not yet been thoroughly studied. The
executable code is not equivalent to the reliable and robust code, especially
in the context of real-world software development. The misuse of APIs in the
generated code could lead to severe problem, such as resource leaks, program
crashes. To make things worse, the users of LLM code generation services are
actually the developers that are most vulnerable to these code that seems right
-- They are always novice developers that are not familiar with the APIs that
LLMs generate code for them. Therefore, they could hardly tell the misuse in
the code generated by LLMs, which further facilitates the incorrect code
applied in real-world software. Existing code evaluation benchmark and datasets
focus on crafting small tasks such as programming questions in coding
interviews, which however deviates from the problem that developers would ask
LLM for real-world coding help. To fill the missing piece, in this work, we
propose a dataset RobustAPI for evaluating the reliability and robustness of
code generated by LLMs. We collect 1208 coding questions from StackOverflow on
24 representative Java APIs. We summarize thecommon misuse patterns of these
APIs and evaluate them oncurrent popular LLMs. The evaluation results show that
evenfor GPT-4, 62% of the generated code contains API misuses,which would cause
unexpected consequences if the code isintroduced into real-world software.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bridging the Gap: Deciphering Tabular Data Using Large Language Model. (arXiv:2308.11891v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.11891">
<div class="article-summary-box-inner">
<span><p>In the realm of natural language processing, the understanding of tabular
data has perpetually stood as a focal point of scholarly inquiry. The emergence
of expansive language models, exemplified by the likes of ChatGPT, has ushered
in a wave of endeavors wherein researchers aim to harness these models for
tasks related to table-based question answering. Central to our investigative
pursuits is the elucidation of methodologies that amplify the aptitude of such
large language models in discerning both the structural intricacies and
inherent content of tables, ultimately facilitating their capacity to provide
informed responses to pertinent queries. To this end, we have architected a
distinctive module dedicated to the serialization of tables for seamless
integration with expansive language models. Additionally, we've instituted a
corrective mechanism within the model to rectify potential inaccuracies.
Experimental results indicate that, although our proposed method trails the
SOTA by approximately 11.7% in overall metrics, it surpasses the SOTA by about
1.2% in tests on specific datasets. This research marks the first application
of large language models to table-based question answering tasks, enhancing the
model's comprehension of both table structures and content.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments. (arXiv:2308.12086v2 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.12086">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have gained widespread popularity across diverse
domains involving text generation, summarization, and various natural language
processing tasks. Despite their inherent limitations, LLM-based designs have
shown promising capabilities in planning and navigating open-world scenarios.
This paper introduces a novel application of pre-trained LLMs as agents within
cybersecurity network environments, focusing on their utility for sequential
decision-making processes.
</p>
<p>We present an approach wherein pre-trained LLMs are leveraged as attacking
agents in two reinforcement learning environments. Our proposed agents
demonstrate similar or better performance against state-of-the-art agents
trained for thousands of episodes in most scenarios and configurations. In
addition, the best LLM agents perform similarly to human testers of the
environment without any additional training process. This design highlights the
potential of LLMs to efficiently address complex decision-making tasks within
cybersecurity.
</p>
<p>Furthermore, we introduce a new network security environment named
NetSecGame. The environment is designed to eventually support complex
multi-agent scenarios within the network security domain. The proposed
environment mimics real network attacks and is designed to be highly modular
and adaptable for various scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Vote: Prompting for Rare Disease Identification. (arXiv:2308.12890v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.12890">
<div class="article-summary-box-inner">
<span><p>The emergence of generative Large Language Models (LLMs) emphasizes the need
for accurate and efficient prompting approaches. LLMs are often applied in
Few-Shot Learning (FSL) contexts, where tasks are executed with minimal
training data. FSL has become popular in many Artificial Intelligence (AI)
subdomains, including AI for health. Rare diseases affect a small fraction of
the population. Rare disease identification from clinical notes inherently
requires FSL techniques due to limited data availability. Manual data
collection and annotation is both expensive and time-consuming. In this paper,
we propose Models-Vote Prompting (MVP), a flexible prompting approach for
improving the performance of LLM queries in FSL settings. MVP works by
prompting numerous LLMs to perform the same tasks and then conducting a
majority vote on the resulting outputs. This method achieves improved results
to any one model in the ensemble on one-shot rare disease identification and
classification tasks. We also release a novel rare disease dataset for FSL,
available to those who signed the MIMIC-IV Data Use Agreement (DUA).
Furthermore, in using MVP, each model is prompted multiple times, substantially
increasing the time needed for manual annotation, and to address this, we
assess the feasibility of using JSON for automating generative LLM evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training and Meta-Evaluating Machine Translation Evaluation Metrics at the Paragraph Level. (arXiv:2308.13506v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13506">
<div class="article-summary-box-inner">
<span><p>As research on machine translation moves to translating text beyond the
sentence level, it remains unclear how effective automatic evaluation metrics
are at scoring longer translations. In this work, we first propose a method for
creating paragraph-level data for training and meta-evaluating metrics from
existing sentence-level data. Then, we use these new datasets to benchmark
existing sentence-level metrics as well as train learned metrics at the
paragraph level. Interestingly, our experimental results demonstrate that using
sentence-level metrics to score entire paragraphs is equally as effective as
using a metric designed to work at the paragraph level. We speculate this
result can be attributed to properties of the task of reference-based
evaluation as well as limitations of our datasets with respect to capturing all
types of phenomena that occur in paragraph-level translations.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-08-29 23:10:05.004266634 UTC">2023-08-29 23:10:05 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>