<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-02-06T01:30:00Z">02-06</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Creating a Large Language Model of a Philosopher. (arXiv:2302.01339v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01339">
<div class="article-summary-box-inner">
<span><p>Can large language models be trained to produce philosophical texts that are
difficult to distinguish from texts produced by human philosophers? To address
this question, we fine-tuned OpenAI's GPT-3 with the works of philosopher
Daniel C. Dennett as additional training data. To explore the Dennett model, we
asked the real Dennett ten philosophical questions and then posed the same
questions to the language model, collecting four responses for each question
without cherry-picking. We recruited 425 participants to distinguish Dennett's
answer from the four machine-generated answers. Experts on Dennett's work (N =
25) succeeded 51% of the time, above the chance rate of 20% but short of our
hypothesized rate of 80% correct. For two of the ten questions, the language
model produced at least one answer that experts selected more frequently than
Dennett's own answer. Philosophy blog readers (N = 302) performed similarly to
the experts, while ordinary research participants (N = 98) were near chance
distinguishing GPT-3's responses from those of an "actual human philosopher".
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Curriculum-Guided Abstractive Summarization. (arXiv:2302.01342v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01342">
<div class="article-summary-box-inner">
<span><p>Recent Transformer-based summarization models have provided a promising
approach to abstractive summarization. They go beyond sentence selection and
extractive strategies to deal with more complicated tasks such as novel word
generation and sentence paraphrasing. Nonetheless, these models have two
shortcomings: (1) they often perform poorly in content selection, and (2) their
training strategy is not quite efficient, which restricts model performance. In
this paper, we explore two orthogonal ways to compensate for these pitfalls.
First, we augment the Transformer network with a sentence cross-attention
module in the decoder, encouraging more abstraction of salient content. Second,
we include a curriculum learning approach to reweight the training samples,
bringing about an efficient learning procedure. Our second approach to enhance
the training strategy of Transformers networks makes stronger gains as compared
to the first approach. We apply our model on extreme summarization dataset of
Reddit TIFU posts. We further look into three cross-domain summarization
datasets (Webis-TLDR-17, CNN/DM, and XSum), measuring the efficacy of
curriculum learning when applied in summarization. Moreover, a human evaluation
is conducted to show the efficacy of the proposed method in terms of
qualitative criteria, namely, fluency, informativeness, and overall quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The unreasonable effectiveness of few-shot learning for machine translation. (arXiv:2302.01398v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01398">
<div class="article-summary-box-inner">
<span><p>We demonstrate the potential of few-shot translation systems, trained with
unpaired language data, for both high and low-resource language pairs. We show
that with only 5 examples of high-quality translation data shown at inference,
a transformer decoder-only model trained solely with self-supervised learning,
is able to match specialized supervised state-of-the-art models as well as more
general commercial translation systems. In particular, we outperform the best
performing system on the WMT'21 English - Chinese news translation task by only
using five examples of English - Chinese parallel data at inference. Moreover,
our approach in building these models does not necessitate joint multilingual
training or back-translation, is conceptually simple and shows the potential to
extend to the multilingual setting. Furthermore, the resulting models are two
orders of magnitude smaller than state-of-the-art language models. We then
analyze the factors which impact the performance of few-shot translation
systems, and highlight that the quality of the few-shot demonstrations heavily
determines the quality of the translations generated by our models. Finally, we
show that the few-shot paradigm also provides a way to control certain
attributes of the translation -- we show that we are able to control for
regional varieties and formality using only a five examples at inference,
paving the way towards controllable machine translation systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation. (arXiv:2302.01441v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01441">
<div class="article-summary-box-inner">
<span><p>Improving the emotional awareness of pre-trained language models is an
emerging important problem for dialogue generation tasks. Although prior
studies have introduced methods to improve empathetic dialogue generation, few
have discussed how to incorporate commonsense knowledge into pre-trained
language models for controllable dialogue generation. In this study, we propose
a novel framework that improves empathetic dialogue generation using
pre-trained language models by 1) incorporating commonsense knowledge through
prompt verbalization, and 2) controlling dialogue generation using a
strategy-driven future discriminator. We conducted experiments to reveal that
both the incorporation of social commonsense knowledge and enforcement of
control over generation help to improve generation performance. Finally, we
discuss the implications of our study for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CTE: A Dataset for Contextualized Table Extraction. (arXiv:2302.01451v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01451">
<div class="article-summary-box-inner">
<span><p>Relevant information in documents is often summarized in tables, helping the
reader to identify useful facts. Most benchmark datasets support either
document layout analysis or table understanding, but lack in providing data to
apply both tasks in a unified way. We define the task of Contextualized Table
Extraction (CTE), which aims to extract and define the structure of tables
considering the textual context of the document. The dataset comprises 75k
fully annotated pages of scientific papers, including more than 35k tables.
Data are gathered from PubMed Central, merging the information provided by
annotations in the PubTables-1M and PubLayNet datasets. The dataset can support
CTE and adds new classes to the original ones. The generated annotations can be
used to develop end-to-end pipelines for various tasks, including document
layout analysis, table detection, structure recognition, and functional
analysis. We formally define CTE and evaluation metrics, showing which subtasks
can be tackled, describing advantages, limitations, and future works of this
collection of data. Annotations and code will be accessible a
https://github.com/AILab-UniFI/cte-dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Domain Adaptation for Speech Foundation Models. (arXiv:2302.01496v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01496">
<div class="article-summary-box-inner">
<span><p>Foundation models (FMs), that are trained on broad data at scale and are
adaptable to a wide range of downstream tasks, have brought large interest in
the research community. Benefiting from the diverse data sources such as
different modalities, languages and application domains, foundation models have
demonstrated strong generalization and knowledge transfer capabilities. In this
paper, we present a pioneering study towards building an efficient solution for
FM-based speech recognition systems. We adopt the recently developed
self-supervised BEST-RQ for pretraining, and propose the joint finetuning with
both source and unsupervised target domain data using JUST Hydra. The FM
encoder adapter and decoder are then finetuned to the target domain with a
small amount of supervised in-domain data. On a large-scale YouTube and Voice
Search task, our method is shown to be both data and model parameter efficient.
It achieves the same quality with only 21.6M supervised in-domain data and
130.8M finetuned parameters, compared to the 731.1M model trained from scratch
on additional 300M supervised in-domain data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Intermediate Layer Distillation for Compressing Language Models: An Overfitting Perspective. (arXiv:2302.01530v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01530">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation (KD) is a highly promising method for mitigating the
computational problems of pre-trained language models (PLMs). Among various KD
approaches, Intermediate Layer Distillation (ILD) has been a de facto standard
KD method with its performance efficacy in the NLP field. In this paper, we
find that existing ILD methods are prone to overfitting to training datasets,
although these methods transfer more information than the original KD. Next, we
present the simple observations to mitigate the overfitting of ILD: distilling
only the last Transformer layer and conducting ILD on supplementary tasks.
Based on our two findings, we propose a simple yet effective
consistency-regularized ILD (CR-ILD), which prevents the student model from
overfitting the training dataset. Substantial experiments on distilling BERT on
the GLUE benchmark and several synthetic datasets demonstrate that our proposed
ILD method outperforms other KD techniques. Our code is available at
https://github.com/jongwooko/CR-ILD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using natural language processing and structured medical data to phenotype patients hospitalized due to COVID-19. (arXiv:2302.01536v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01536">
<div class="article-summary-box-inner">
<span><p>To identify patients who are hospitalized because of COVID-19 as opposed to
those who were admitted for other indications, we compared the performance of
different computable phenotype definitions for COVID-19 hospitalizations that
use different types of data from the electronic health records (EHR), including
structured EHR data elements, provider notes, or a combination of both data
types. And conduct a retrospective data analysis utilizing chart review-based
validation. Participants are 586 hospitalized individuals who tested positive
for SARS-CoV-2 during January 2022. We used natural language processing to
incorporate data from provider notes and LASSO regression and Random Forests to
fit classification algorithms that incorporated structured EHR data elements,
provider notes, or a combination of structured data and provider notes.
Results: Based on a chart review, 38% of 586 patients were determined to be
hospitalized for reasons other than COVID-19 despite having tested positive for
SARS-CoV-2. A classification algorithm that used provider notes had
significantly better discrimination than one that used structured EHR data
elements (AUROC: 0.894 vs 0.841, p &lt; 0.001), and performed similarly to a model
that combined provider notes with structured data elements (AUROC: 0.894 vs
0.893). Assessments of hospital outcome metrics significantly differed based on
whether the population included all hospitalized patients who tested positive
for SARS-CoV-2 versus those who were determined to have been hospitalized due
to COVID-19. This work demonstrates the utility of natural language processing
approaches to derive information related to patient hospitalizations in cases
where there may be multiple conditions that could serve as the primary
indication for hospitalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Witgenstein's influence on artificial intelligence. (arXiv:2302.01570v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01570">
<div class="article-summary-box-inner">
<span><p>We examine how much of the contemporary progress in artificial intelligence
(and, specifically, in natural language processing), can be, more or less
directly, traced back to the seminal work and ideas of the Austrian-British
philosopher Ludwig Wittgenstein, with particular focus on his late views.
Discussing Wittgenstein's original theses will give us the chance to survey the
state of artificial intelligence, and comment on both its strengths and
weaknesses. A similar text appeared first in Spanish as a chapter of CENTENARIO
DEL SILENCIO (2021), a book celebrating 100 years since the publication of the
Tractatus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controlling for Stereotypes in Multimodal Language Model Evaluation. (arXiv:2302.01582v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01582">
<div class="article-summary-box-inner">
<span><p>We propose a methodology and design two benchmark sets for measuring to what
extent language-and-vision language models use the visual signal in the
presence or absence of stereotypes. The first benchmark is designed to test for
stereotypical colors of common objects, while the second benchmark considers
gender stereotypes. The key idea is to compare predictions when the image
conforms to the stereotype to predictions when it does not.
</p>
<p>Our results show that there is significant variation among multimodal models:
the recent Transformer-based FLAVA seems to be more sensitive to the choice of
image and less affected by stereotypes than older CNN-based models such as
VisualBERT and LXMERT. This effect is more discernible in this type of
controlled setting than in traditional evaluations where we do not know whether
the model relied on the stereotype or the visual signal.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bioformer: an efficient transformer language model for biomedical text mining. (arXiv:2302.01588v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01588">
<div class="article-summary-box-inner">
<span><p>Pretrained language models such as Bidirectional Encoder Representations from
Transformers (BERT) have achieved state-of-the-art performance in natural
language processing (NLP) tasks. Recently, BERT has been adapted to the
biomedical domain. Despite the effectiveness, these models have hundreds of
millions of parameters and are computationally expensive when applied to
large-scale NLP applications. We hypothesized that the number of parameters of
the original BERT can be dramatically reduced with minor impact on performance.
In this study, we present Bioformer, a compact BERT model for biomedical text
mining. We pretrained two Bioformer models (named Bioformer8L and Bioformer16L)
which reduced the model size by 60% compared to BERTBase. Bioformer uses a
biomedical vocabulary and was pre-trained from scratch on PubMed abstracts and
PubMed Central full-text articles. We thoroughly evaluated the performance of
Bioformer as well as existing biomedical BERT models including BioBERT and
PubMedBERT on 15 benchmark datasets of four different biomedical NLP tasks:
named entity recognition, relation extraction, question answering and document
classification. The results show that with 60% fewer parameters, Bioformer16L
is only 0.1% less accurate than PubMedBERT while Bioformer8L is 0.9% less
accurate than PubMedBERT. Both Bioformer16L and Bioformer8L outperformed
BioBERTBase-v1.1. In addition, Bioformer16L and Bioformer8L are 2-3 fold as
fast as PubMedBERT/BioBERTBase-v1.1. Bioformer has been successfully deployed
to PubTator Central providing gene annotations over 35 million PubMed abstracts
and 5 million PubMed Central full-text articles. We make Bioformer publicly
available via https://github.com/WGLab/bioformer, including pre-trained models,
datasets, and instructions for downstream use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Around the world in 60 words: A generative vocabulary test for online research. (arXiv:2302.01614v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01614">
<div class="article-summary-box-inner">
<span><p>Conducting experiments with diverse participants in their native languages
can uncover insights into culture, cognition, and language that may not be
revealed otherwise. However, conducting these experiments online makes it
difficult to validate self-reported language proficiency. Furthermore, existing
proficiency tests are small and cover only a few languages. We present an
automated pipeline to generate vocabulary tests using text from Wikipedia. Our
pipeline samples rare nouns and creates pseudowords with the same low-level
statistics. Six behavioral experiments (N=236) in six countries and eight
languages show that (a) our test can distinguish between native speakers of
closely related languages, (b) the test is reliable ($r=0.82$), and (c)
performance strongly correlates with existing tests (LexTale) and self-reports.
We further show that test accuracy is negatively correlated with the linguistic
distance between the tested and the native language. Our test, available in
eight languages, can easily be extended to other languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling Sequential Sentence Relation to Improve Cross-lingual Dense Retrieval. (arXiv:2302.01626v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01626">
<div class="article-summary-box-inner">
<span><p>Recently multi-lingual pre-trained language models (PLM) such as mBERT and
XLM-R have achieved impressive strides in cross-lingual dense retrieval.
Despite its successes, they are general-purpose PLM while the multilingual PLM
tailored for cross-lingual retrieval is still unexplored. Motivated by an
observation that the sentences in parallel documents are approximately in the
same order, which is universal across languages, we propose to model this
sequential sentence relation to facilitate cross-lingual representation
learning. Specifically, we propose a multilingual PLM called masked sentence
model (MSM), which consists of a sentence encoder to generate the sentence
representations, and a document encoder applied to a sequence of sentence
vectors from a document. The document encoder is shared for all languages to
model the universal sequential sentence relation across languages. To train the
model, we propose a masked sentence prediction task, which masks and predicts
the sentence vector via a hierarchical contrastive loss with sampled negatives.
Comprehensive experiments on four cross-lingual retrieval tasks show MSM
significantly outperforms existing advanced pre-training models, demonstrating
the effectiveness and stronger cross-lingual retrieval capabilities of our
approach. Code and model will be available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Show me your NFT and I tell you how it will perform: Multimodal representation learning for NFT selling price prediction. (arXiv:2302.01676v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01676">
<div class="article-summary-box-inner">
<span><p>Non-Fungible Tokens (NFTs) represent deeds of ownership, based on blockchain
technologies and smart contracts, of unique crypto assets on digital art forms
(e.g., artworks or collectibles). In the spotlight after skyrocketing in 2021,
NFTs have attracted the attention of crypto enthusiasts and investors intent on
placing promising investments in this profitable market. However, the NFT
financial performance prediction has not been widely explored to date.
</p>
<p>In this work, we address the above problem based on the hypothesis that NFT
images and their textual descriptions are essential proxies to predict the NFT
selling prices. To this purpose, we propose MERLIN, a novel multimodal deep
learning framework designed to train Transformer-based language and visual
models, along with graph neural network models, on collections of NFTs' images
and texts. A key aspect in MERLIN is its independence on financial features, as
it exploits only the primary data a user interested in NFT trading would like
to deal with, i.e., NFT images and textual descriptions. By learning dense
representations of such data, a price-category classification task is performed
by MERLIN models, which can also be tuned according to user preferences in the
inference phase to mimic different risk-return investment profiles.
Experimental evaluation on a publicly available dataset has shown that MERLIN
models achieve significant performances according to several financial
assessment criteria, fostering profitable investments, and also beating
baseline machine-learning classifiers based on financial features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LIQUID: A Framework for List Question Answering Dataset Generation. (arXiv:2302.01691v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01691">
<div class="article-summary-box-inner">
<span><p>Question answering (QA) models often rely on large-scale training datasets,
which necessitates the development of a data generation framework to reduce the
cost of manual annotations. Although several recent studies have aimed to
generate synthetic questions with single-span answers, no study has been
conducted on the creation of list questions with multiple, non-contiguous spans
as answers. To address this gap, we propose \ours, an automated framework for
generating list QA datasets from unlabeled corpora. We first convert a passage
from Wikipedia or PubMed into a summary and extract named entities from the
summarized text as candidate answers. This allows us to select answers that are
semantically correlated in context and is, therefore, suitable for constructing
list questions. We then create questions using an off-the-shelf question
generator with the extracted entities and original passage. Finally, iterative
filtering and answer expansion are performed to ensure the accuracy and
completeness of the answers. Using our synthetic data, we significantly improve
the performance of the previous best list QA models by exact-match F1 scores of
5.0 on MultiSpanQA, 1.9 on Quoref, and 2.8 averaged across three BioASQ
benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Command Line Interface Risk Modeling. (arXiv:2302.01749v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01749">
<div class="article-summary-box-inner">
<span><p>Protecting sensitive data is an essential part of security in cloud
computing. However, only specific privileged individuals have access to view or
interact with this data; therefore, it is unscalable to depend on these
individuals also to maintain the software. A solution to this is to allow
non-privileged individuals access to maintain these systems but mask sensitive
information from egressing. To this end, we have created a machine-learning
model to predict and redact fields with sensitive data. This work concentrates
on Azure PowerShell, showing how it applies to other command-line interfaces
and APIs. Using the F5-score as a weighted metric, we demonstrate different
transformation techniques to map this problem from an unknown field to the
well-researched area of natural language processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DANES: Deep Neural Network Ensemble Architecture for Social and Textual Context-aware Fake News Detection. (arXiv:2302.01756v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01756">
<div class="article-summary-box-inner">
<span><p>The growing popularity of social media platforms has simplified the creation
and distribution of news articles but also creates a conduit for spreading fake
news. In consequence, the need arises for effective context-aware fake news
detection mechanisms, where the contextual information can be built either from
the textual content of posts or from available social data (e.g., information
about the users, reactions to posts, or the social network). In this paper, we
propose DANES, a Deep Neural Network Ensemble Architecture for Social and
Textual Context-aware Fake News Detection. DANES comprises a Text Branch for a
textual content-based context and a Social Branch for the social context. These
two branches are used to create a novel Network Embedding. Preliminary ablation
results on 3 real-world datasets, i.e., BuzzFace, Twitter15, and Twitter16, are
promising, with an accuracy that outperforms state-of-the-art solutions when
employing both social and textual content features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mitigating Data Scarcity for Large Language Models. (arXiv:2302.01806v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01806">
<div class="article-summary-box-inner">
<span><p>In recent years, pretrained neural language models (PNLMs) have taken the
field of natural language processing by storm, achieving new benchmarks and
state-of-the-art performances. These models often rely heavily on annotated
data, which may not always be available. Data scarcity are commonly found in
specialized domains, such as medical, or in low-resource languages that are
underexplored by AI research. In this dissertation, we focus on mitigating data
scarcity using data augmentation and neural ensemble learning techniques for
neural language models. In both research directions, we implement neural
network algorithms and evaluate their impact on assisting neural language
models in downstream NLP tasks. Specifically, for data augmentation, we explore
two techniques: 1) creating positive training data by moving an answer span
around its original context and 2) using text simplification techniques to
introduce a variety of writing styles to the original training data. Our
results indicate that these simple and effective solutions improve the
performance of neural language models considerably in low-resource NLP domains
and tasks. For neural ensemble learning, we use a multilabel neural classifier
to select the best prediction outcome from a variety of individual pretrained
neural language models trained for a low-resource medical text simplification
task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lexical Simplification using multi level and modular approach. (arXiv:2302.01823v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01823">
<div class="article-summary-box-inner">
<span><p>Text Simplification is an ongoing problem in Natural Language Processing,
solution to which has varied implications. In conjunction with the TSAR-2022
Workshop @EMNLP2022 Lexical Simplification is the process of reducing the
lexical complexity of a text by replacing difficult words with easier to read
(or understand) expressions while preserving the original information and
meaning. This paper explains the work done by our team "teamPN" for English sub
task. We created a modular pipeline which combines modern day transformers
based models with traditional NLP methods like paraphrasing and verb sense
disambiguation. We created a multi level and modular pipeline where the target
text is treated according to its semantics(Part of Speech Tag). Pipeline is
multi level as we utilize multiple source models to find potential candidates
for replacement, It is modular as we can switch the source models and their
weight-age in the final re-ranking.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Stylistic Profiles for the Task of Empathy Classification in Medical Narrative Essays. (arXiv:2302.01839v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01839">
<div class="article-summary-box-inner">
<span><p>One important aspect of language is how speakers generate utterances and
texts to convey their intended meanings. In this paper, we bring various
aspects of the Construction Grammar (CxG) and the Systemic Functional Grammar
(SFG) theories in a deep learning computational framework to model empathic
language. Our corpus consists of 440 essays written by premed students as
narrated simulated patient-doctor interactions. We start with baseline
classifiers (state-of-the-art recurrent neural networks and transformer
models). Then, we enrich these models with a set of linguistic constructions
proving the importance of this novel approach to the task of empathy
classification for this dataset. Our results indicate the potential of such
constructions to contribute to the overall empathy profile of first-person
narrative essays.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Case Study for Compliance as Code with Graphs and Language Models: Public release of the Regulatory Knowledge Graph. (arXiv:2302.01842v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01842">
<div class="article-summary-box-inner">
<span><p>The paper presents a study on using language models to automate the
construction of executable Knowledge Graph (KG) for compliance. The paper
focuses on Abu Dhabi Global Market regulations and taxonomy, involves manual
tagging a portion of the regulations, training BERT-based models, which are
then applied to the rest of the corpus. Coreference resolution and syntax
analysis were used to parse the relationships between the tagged entities and
to form KG stored in a Neo4j database. The paper states that the use of machine
learning models released by regulators to automate the interpretation of rules
is a vital step towards compliance automation, demonstrates the concept
querying with Cypher, and states that the produced sub-graphs combined with
Graph Neural Networks (GNN) will achieve expandability in judgment automation
systems. The graph is open sourced on GitHub to provide structured data for
future advancements in the field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Entity-Agnostic Representation Learning for Parameter-Efficient Knowledge Graph Embedding. (arXiv:2302.01849v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01849">
<div class="article-summary-box-inner">
<span><p>We propose an entity-agnostic representation learning method for handling the
problem of inefficient parameter storage costs brought by embedding knowledge
graphs. Conventional knowledge graph embedding methods map elements in a
knowledge graph, including entities and relations, into continuous vector
spaces by assigning them one or multiple specific embeddings (i.e., vector
representations). Thus the number of embedding parameters increases linearly as
the growth of knowledge graphs. In our proposed model, Entity-Agnostic
Representation Learning (EARL), we only learn the embeddings for a small set of
entities and refer to them as reserved entities. To obtain the embeddings for
the full set of entities, we encode their distinguishable information from
their connected relations, k-nearest reserved entities, and multi-hop
neighbors. We learn universal and entity-agnostic encoders for transforming
distinguishable information into entity embeddings. This approach allows our
proposed EARL to have a static, efficient, and lower parameter count than
conventional knowledge graph embedding methods. Experimental results show that
EARL uses fewer parameters and performs better on link prediction tasks than
baselines, reflecting its parameter efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalizing to Unseen Elements: A Survey on Knowledge Extrapolation for Knowledge Graphs. (arXiv:2302.01859v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01859">
<div class="article-summary-box-inner">
<span><p>Knowledge graphs (KGs) have become effective knowledge resources in diverse
applications, and knowledge graph embedding (KGE) methods have attracted
increasing attention in recent years. However, it's still challenging for
conventional KGE methods to handle unseen entities or relations during the
model test. Much effort has been made in various fields of KGs to address this
problem. In this paper, we use a set of general terminologies to unify these
methods and refer to them as Knowledge Extrapolation. We comprehensively
summarize these methods classified by our proposed taxonomy and describe their
correlations. Next, we introduce the benchmarks and provide comparisons of
these methods from aspects that are not reflected by the taxonomy. Finally, we
suggest some potential directions for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GLADIS: A General and Large Acronym Disambiguation Benchmark. (arXiv:2302.01860v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01860">
<div class="article-summary-box-inner">
<span><p>Acronym Disambiguation (AD) is crucial for natural language understanding on
various sources, including biomedical reports, scientific papers, and search
engine queries. However, existing acronym disambiguation benchmarks and tools
are limited to specific domains, and the size of prior benchmarks is rather
small. To accelerate the research on acronym disambiguation, we construct a new
benchmark named GLADIS with three components: (1) a much larger acronym
dictionary with 1.5M acronyms and 6.4M long forms; (2) a pre-training corpus
with 160 million sentences; (3) three datasets that cover the general,
scientific, and biomedical domains. We then pre-train a language model,
\emph{AcroBERT}, on our constructed corpus for general acronym disambiguation,
and show the challenges and values of our new benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Keyword Assisted Topic Models. (arXiv:2004.05964v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.05964">
<div class="article-summary-box-inner">
<span><p>In recent years, fully automated content analysis based on probabilistic
topic models has become popular among social scientists because of their
scalability. The unsupervised nature of the models makes them suitable for
exploring topics in a corpus without prior knowledge. However, researchers find
that these models often fail to measure specific concepts of substantive
interest by inadvertently creating multiple topics with similar content and
combining distinct themes into a single topic. In this paper, we empirically
demonstrate that providing a small number of keywords can substantially enhance
the measurement performance of topic models. An important advantage of the
proposed keyword assisted topic model (keyATM) is that the specification of
keywords requires researchers to label topics prior to fitting a model to the
data. This contrasts with a widespread practice of post-hoc topic
interpretation and adjustments that compromises the objectivity of empirical
findings. In our application, we find that keyATM provides more interpretable
results, has better document classification performance, and is less sensitive
to the number of topics than the standard topic models. Finally, we show that
keyATM can also incorporate covariates and model time trends. An open-source
software package is available for implementing the proposed methodology.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Solvability of Interpretability Evaluation Metrics. (arXiv:2205.08696v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08696">
<div class="article-summary-box-inner">
<span><p>Feature attribution methods are popular for explaining neural network
predictions, and they are often evaluated on metrics such as comprehensiveness
and sufficiency. In this paper, we highlight an intriguing property of these
metrics: their solvability. Concretely, we can define the problem of optimizing
an explanation for a metric, which can be solved by beam search. This
observation leads to the obvious yet unaddressed question: why do we use
explainers (e.g., LIME) not based on solving the target metric, if the metric
value represents explanation quality? We present a series of investigations
showing strong performance of this beam search explainer and discuss its
broader implication: a definition-evaluation duality of interpretability
concepts. We implement the explainer and release the Python solvex package for
models of text, image and tabular domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoNT: Contrastive Neural Text Generation. (arXiv:2205.14690v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.14690">
<div class="article-summary-box-inner">
<span><p>Recently, contrastive learning attracts increasing interests in neural text
generation as a new solution to alleviate the exposure bias problem. It
introduces a sequence-level training signal which is crucial to generation
tasks that always rely on auto-regressive decoding. However, previous methods
using contrastive learning in neural text generation usually lead to inferior
performance. In this paper, we analyse the underlying reasons and propose a new
Contrastive Neural Text generation framework, CoNT. CoNT addresses bottlenecks
that prevent contrastive learning from being widely adopted in generation tasks
from three aspects -- the construction of contrastive examples, the choice of
the contrastive loss, and the strategy in decoding. We validate CoNT on five
generation tasks with ten benchmarks, including machine translation,
summarization, code comment generation, data-to-text generation and commonsense
generation. Experimental results show that CoNT clearly outperforms the
conventional training framework on all the ten benchmarks with a convincing
margin. Especially, CoNT surpasses previous the most competitive contrastive
learning method for text generation, by 1.50 BLEU on machine translation and
1.77 ROUGE-1 on summarization, respectively. It achieves new state-of-the-art
on summarization, code comment generation (without external data) and
data-to-text generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MetaPrompting: Learning to Learn Better Prompts. (arXiv:2209.11486v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.11486">
<div class="article-summary-box-inner">
<span><p>Prompting method is regarded as one of the crucial progress for few-shot
nature language processing. Recent research on prompting moves from discrete
tokens based ``hard prompts'' to continuous ``soft prompts'', which employ
learnable vectors as pseudo prompt tokens and achieve better performance.
Though showing promising prospects, these soft-prompting methods are observed
to rely heavily on good initialization to take effect. Unfortunately, obtaining
a perfect initialization for soft prompts requires understanding of inner
language models working and elaborate design, which is no easy task and has to
restart from scratch for each new task. To remedy this, we propose a
generalized soft prompting method called MetaPrompting, which adopts the
well-recognized model-agnostic meta-learning algorithm to automatically find
better prompt initialization that facilitates fast adaptation to new prompting
tasks.Extensive experiments show MetaPrompting tackles soft prompt
initialization problem and brings significant improvement on four different
datasets (over 6 points improvement in accuracy for 1-shot setting), achieving
new state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis. (arXiv:2210.01108v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.01108">
<div class="article-summary-box-inner">
<span><p>We propose MINT, a new Multilingual INTimacy analysis dataset covering 13,372
tweets in 10 languages including English, French, Spanish, Italian, Portuguese,
Korean, Dutch, Chinese, Hindi, and Arabic. We benchmarked a list of popular
multilingual pre-trained language models. The dataset is released along with
the SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis
(https://sites.google.com/umich.edu/semeval-2023-tweet-intimacy).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visualize Before You Write: Imagination-Guided Open-Ended Text Generation. (arXiv:2210.03765v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.03765">
<div class="article-summary-box-inner">
<span><p>Recent advances in text-to-image synthesis make it possible to visualize
machine imaginations for a given context. On the other hand, when generating
text, human writers are gifted at creative visualization, which enhances their
writings by forming imaginations as blueprints before putting down the stories
in words. Inspired by such a cognitive process, we ask the natural question of
whether we can endow machines with the same ability to utilize visual
information and construct a general picture of the context to guide text
generation. In this work, we propose iNLG that uses machine-generated images to
guide language models in open-ended text generation. The experiments and
analyses demonstrate the effectiveness of iNLG on open-ended text generation
tasks, including text completion, story generation, and concept-to-text
generation in both few-shot and full-data scenarios. Both automatic metrics and
human evaluations verify that the text snippets generated by our iNLG are
coherent and informative while displaying minor degeneration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"John is 50 years old, can his son be 65?" Evaluating NLP Models' Understanding of Feasibility. (arXiv:2210.07471v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07471">
<div class="article-summary-box-inner">
<span><p>In current NLP research, large-scale language models and their abilities are
widely being discussed. Some recent works have also found notable failures of
these models. Often these failure examples involve complex reasoning abilities.
This work focuses on a simple commonsense ability, reasoning about when an
action (or its effect) is feasible. To this end, we introduce FeasibilityQA, a
question-answering dataset involving binary classification (BCQ) and
multi-choice multi-correct questions (MCQ) that test understanding of
feasibility. We show that even state-of-the-art models such as GPT-3, GPT-2,
and T5 struggle to answer the feasibility questions correctly. Specifically, on
MCQ and BCQ questions, GPT-3 achieves an accuracy of just (19%, 62%) and (25%,
64%) in zero-shot and few-shot settings, respectively. We also evaluate models
by providing relevant knowledge statements required to answer the question. We
find that the additional knowledge leads to a 7% gain in performance, but the
overall performance still remains low. These results make one wonder how much
commonsense knowledge about action feasibility is encoded in state-of-the-art
models and how well they can reason about it.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Active Learning for Natural Language Processing. (arXiv:2210.10109v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10109">
<div class="article-summary-box-inner">
<span><p>In this work, we provide a survey of active learning (AL) for its
applications in natural language processing (NLP). In addition to a
fine-grained categorization of query strategies, we also investigate several
other important aspects of applying AL to NLP problems. These include AL for
structured prediction tasks, annotation cost, model learning (especially with
deep neural models), and starting and stopping AL. Finally, we conclude with a
discussion of related topics and future directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Resolving Open-textured Rules with Templated Interpretive Arguments. (arXiv:2212.09700v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09700">
<div class="article-summary-box-inner">
<span><p>Open-textured terms in written rules are typically settled through
interpretive argumentation. Ongoing work has attempted to catalogue the schemes
used in such interpretive argumentation. But how can the use of these schemes
affect the way in which people actually use and reason over the proper
interpretations of open-textured terms? Using the interpretive
argument-eliciting game Aporia as our framework, we carried out an empirical
study to answer this question. Differing from previous work, we did not allow
participants to argue for interpretations arbitrarily, but to only use
arguments that fit with a given set of interpretive argument templates.
Finally, we analyze the results captured by this new dataset, specifically
focusing on practical implications for the development of
interpretation-capable artificial reasoners.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VaxxHesitancy: A Dataset for Studying Hesitancy Towards COVID-19 Vaccination on Twitter. (arXiv:2301.06660v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.06660">
<div class="article-summary-box-inner">
<span><p>Vaccine hesitancy has been a common concern, probably since vaccines were
created and, with the popularisation of social media, people started to express
their concerns about vaccines online alongside those posting pro- and
anti-vaccine content. Predictably, since the first mentions of a COVID-19
vaccine, social media users posted about their fears and concerns or about
their support and belief into the effectiveness of these rapidly developing
vaccines. Identifying and understanding the reasons behind public hesitancy
towards COVID-19 vaccines is important for policy markers that need to develop
actions to better inform the population with the aim of increasing vaccine
take-up. In the case of COVID-19, where the fast development of the vaccines
was mirrored closely by growth in anti-vaxx disinformation, automatic means of
detecting citizen attitudes towards vaccination became necessary. This is an
important computational social sciences task that requires data analysis in
order to gain in-depth understanding of the phenomena at hand. Annotated data
is also necessary for training data-driven models for more nuanced analysis of
attitudes towards vaccination. To this end, we created a new collection of over
3,101 tweets annotated with users' attitudes towards COVID-19 vaccination
(stance). Besides, we also develop a domain-specific language model (VaxxBERT)
that achieves the best predictive performance (73.0 accuracy and 69.3 F1-score)
as compared to a robust set of baselines. To the best of our knowledge, these
are the first dataset and model that model vaccine hesitancy as a category
distinct from pro- and anti-vaccine stance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning the Effects of Physical Actions in a Multi-modal Environment. (arXiv:2301.11845v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.11845">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) handle physical commonsense information
inadequately. As a result of being trained in a disembodied setting, LLMs often
fail to predict an action's outcome in a given environment. However, predicting
the effects of an action before it is executed is crucial in planning, where
coherent sequences of actions are often needed to achieve a goal. Therefore, we
introduce the multi-modal task of predicting the outcomes of actions solely
from realistic sensory inputs (images and text). Next, we extend an LLM to
model latent representations of objects to better predict action outcomes in an
environment. We show that multi-modal models can capture physical commonsense
when augmented with visual information. Finally, we evaluate our model's
performance on novel actions and objects and find that combining modalities
help models to generalize and learn physical commonsense reasoning better.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vicarious Offense and Noise Audit of Offensive Speech Classifiers. (arXiv:2301.12534v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.12534">
<div class="article-summary-box-inner">
<span><p>This paper examines social web content moderation from two key perspectives:
automated methods (machine moderators) and human evaluators (human moderators).
We conduct a noise audit at an unprecedented scale using nine machine
moderators trained on well-known offensive speech data sets evaluated on a
corpus sampled from 92 million YouTube comments discussing a multitude of
issues relevant to US politics. We introduce a first-of-its-kind data set of
vicarious offense. We ask annotators: (1) if they find a given social media
post offensive; and (2) how offensive annotators sharing different political
beliefs would find the same content. Our experiments with machine moderators
reveal that moderation outcomes wildly vary across different machine
moderators. Our experiments with human moderators suggest that (1) political
leanings considerably affect first-person offense perspective; (2) Republicans
are the worst predictors of vicarious offense; (3) predicting vicarious offense
for the Republicans is most challenging than predicting vicarious offense for
the Independents and the Democrats; and (4) disagreement across political
identity groups considerably increases when sensitive issues such as
reproductive rights or gun control/rights are discussed. Both experiments
suggest that offense, is indeed, highly subjective and raise important
questions concerning content moderation practices.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TopoBERT: Plug and Play Toponym Recognition Module Harnessing Fine-tuned BERT. (arXiv:2301.13631v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.13631">
<div class="article-summary-box-inner">
<span><p>Extracting precise geographical information from textual contents is crucial
in a plethora of applications. For example, during hazardous events, a robust
and unbiased toponym extraction framework can provide an avenue to tie the
location concerned to the topic discussed by news media posts and pinpoint
humanitarian help requests or damage reports from social media. Early studies
have leveraged rule-based, gazetteer-based, deep learning, and hybrid
approaches to address this problem. However, the performance of existing tools
is deficient in supporting operations like emergency rescue, which relies on
fine-grained, accurate geographic information. The emerging pretrained language
models can better capture the underlying characteristics of text information,
including place names, offering a promising pathway to optimize toponym
recognition to underpin practical applications. In this paper, TopoBERT, a
toponym recognition module based on a one dimensional Convolutional Neural
Network (CNN1D) and Bidirectional Encoder Representation from Transformers
(BERT), is proposed and fine-tuned. Three datasets (CoNLL2003-Train,
Wikipedia3000, WNUT2017) are leveraged to tune the hyperparameters, discover
the best training strategy, and train the model. Another two datasets
(CoNLL2003-Test and Harvey2017) are used to evaluate the performance. Three
distinguished classifiers, linear, multi-layer perceptron, and CNN1D, are
benchmarked to determine the optimal model architecture. TopoBERT achieves
state-of-the-art performance (f1-score=0.865) compared to the other five
baseline models and can be applied to diverse toponym recognition tasks without
additional training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero Shot Transfer of Legal Judgement Prediction as Article-aware Entailment for the European Court of Human Rights. (arXiv:2302.00609v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00609">
<div class="article-summary-box-inner">
<span><p>In this paper, we cast Legal Judgment Prediction (LJP) from text on European
Court of Human Rights cases as an entailment task, where the case outcome is
classified from a combined input of case facts and convention articles. This
configuration facilitates the model learning legal reasoning ability in mapping
article text to specific fact text. It also provides the opportunity to
evaluate the model's ability to generalize to zero-shot settings when asked to
classify the case outcome with respect to articles not seen during training. We
devise zero-shot LJP experiments and apply domain adaptation methods based on
domain discriminator and Wasserstein distance. Our results demonstrate that the
entailment architecture outperforms straightforward fact classification. We
also find that domain adaptation methods improve zero-shot transfer
performance, with article relatedness and encoder pre-training influencing the
effect.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AmbiCoref: Evaluating Human and Model Sensitivity to Ambiguous Coreference. (arXiv:2302.00762v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00762">
<div class="article-summary-box-inner">
<span><p>Given a sentence "Abby told Brittney that she upset Courtney", one would
struggle to understand who "she" refers to, and ask for clarification. However,
if the word "upset" were replaced with "hugged", "she" unambiguously refers to
Abby. We study if modern coreference resolution models are sensitive to such
pronominal ambiguity. To this end, we construct AmbiCoref, a diagnostic corpus
of minimal sentence pairs with ambiguous and unambiguous referents. Our
examples generalize psycholinguistic studies of human perception of ambiguity
around particular arrangements of verbs and their arguments. Analysis shows
that (1) humans are less sure of referents in ambiguous AmbiCoref examples than
unambiguous ones, and (2) most coreference models show little difference in
output between ambiguous and unambiguous pairs. We release AmbiCoref as a
diagnostic corpus for testing whether models treat ambiguity similarly to
humans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging task dependency and contrastive learning for Legal Judgement Prediction on the European Court of Human Rights. (arXiv:2302.00768v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00768">
<div class="article-summary-box-inner">
<span><p>We report on an experiment in legal judgement prediction on European Court of
Human Rights cases where our model first learns to predict the convention
articles allegedly violated by the state from case facts descriptions, and
subsequently utilizes that information to predict a finding of a violation by
the court. We assess the dependency between these two tasks at the feature and
outcome level. Furthermore, we leverage a hierarchical contrastive loss to pull
together article specific representations of cases at the higher level level,
leading to distinctive article clusters, and further pulls the cases in each
article cluster based on their outcome leading to sub-clusters of cases with
similar outcomes. Our experiment results demonstrate that, given a static
pre-trained encoder, our models produce a small but consistent improvement in
prediction performance over single-task and joint models without contrastive
loss.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Quantized AutoEncoders: Towards Unsupervised Text-Image Alignment. (arXiv:2302.00902v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00902">
<div class="article-summary-box-inner">
<span><p>Recent progress in scaling up large language models has shown impressive
capabilities in performing few-shot learning across a wide range of text-based
tasks. However, a key limitation is that these language models fundamentally
lack visual perception - a crucial attribute needed to extend these models to
be able to interact with the real world and solve vision tasks, such as in
visual-question answering and robotics. Prior works have largely connected
image to text through pretraining and/or fine-tuning on curated image-text
datasets, which can be a costly and expensive process. In order to resolve this
limitation, we propose a simple yet effective approach called
Language-Quantized AutoEncoder (LQAE), a modification of VQ-VAE that learns to
align text-image data in an unsupervised manner by leveraging pretrained
language models (e.g., BERT, RoBERTa). Our main idea is to encode image as
sequences of text tokens by directly quantizing image embeddings using a
pretrained language codebook. We then apply random masking followed by a BERT
model, and have the decoder reconstruct the original image from BERT predicted
text token embeddings. By doing so, LQAE learns to represent similar images
with similar clusters of text tokens, thereby aligning these two modalities
without the use of aligned text-image pairs. This enables few-shot image
classification with large language models (e.g., GPT-3) as well as linear
classification of images based on BERT text features. To the best of our
knowledge, our work is the first work that uses unaligned images for multimodal
tasks by leveraging the power of pretrained language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Extraction in Low-Resource Scenarios: Survey and Perspective. (arXiv:2202.08063v3 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.08063">
<div class="article-summary-box-inner">
<span><p>Knowledge Extraction (KE), aiming to extract structural information from
unstructured texts, often suffers from data scarcity and emerging unseen types,
i.e., low-resource scenarios. Many neural approaches to low-resource KE have
been widely investigated and achieved impressive performance. In this paper, we
present a literature review towards KE in low-resource scenarios, and
systematically categorize existing works into three paradigms: (1) exploiting
higher-resource data, (2) exploiting stronger models, and (3) exploiting data
and models together. In addition, we highlight promising applications and
outline some potential directions for future research. We hope that our survey
can help both the academic and industrial communities to better understand this
field, inspire more ideas, and boost broader applications.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-02-06 23:12:16.869498040 UTC">2023-02-06 23:12:16 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>