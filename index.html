<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-06-02T01:30:00Z">06-02</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">A Two-Stage Decoder for Efficient ICD Coding. (arXiv:2306.00005v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00005">
<div class="article-summary-box-inner">
<span><p>Clinical notes in healthcare facilities are tagged with the International
Classification of Diseases (ICD) code; a list of classification codes for
medical diagnoses and procedures. ICD coding is a challenging multilabel text
classification problem due to noisy clinical document inputs and long-tailed
label distribution. Recent automated ICD coding efforts improve performance by
encoding medical notes and codes with additional data and knowledge bases.
However, most of them do not reflect how human coders generate the code: first,
the coders select general code categories and then look for specific
subcategories that are relevant to a patient's condition. Inspired by this, we
propose a two-stage decoding mechanism to predict ICD codes. Our model uses the
hierarchical properties of the codes to split the prediction into two steps: At
first, we predict the parent code and then predict the child code based on the
previous prediction. Experiments on the public MIMIC-III data set show that our
model performs well in single-model settings without external data or
knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Datasets for Portuguese Legal Semantic Textual Similarity: Comparing weak supervision and an annotation process approaches. (arXiv:2306.00007v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00007">
<div class="article-summary-box-inner">
<span><p>The Brazilian judiciary has a large workload, resulting in a long time to
finish legal proceedings. Brazilian National Council of Justice has established
in Resolution 469/2022 formal guidance for document and process digitalization
opening up the possibility of using automatic techniques to help with everyday
tasks in the legal field, particularly in a large number of texts yielded on
the routine of law procedures. Notably, Artificial Intelligence (AI) techniques
allow for processing and extracting useful information from textual data,
potentially speeding up the process. However, datasets from the legal domain
required by several AI techniques are scarce and difficult to obtain as they
need labels from experts. To address this challenge, this article contributes
with four datasets from the legal domain, two with documents and metadata but
unlabeled, and another two labeled with a heuristic aiming at its use in
textual semantic similarity tasks. Also, to evaluate the effectiveness of the
proposed heuristic label process, this article presents a small ground truth
dataset generated from domain expert annotations. The analysis of ground truth
labels highlights that semantic analysis of domain text can be challenging even
for domain experts. Also, the comparison between ground truth and heuristic
labels shows that heuristic labels are useful.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Brainformers: Trading Simplicity for Efficiency. (arXiv:2306.00008v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00008">
<div class="article-summary-box-inner">
<span><p>Transformers are central to recent successes in natural language processing
and computer vision. Transformers have a mostly uniform backbone where layers
alternate between feed-forward and self-attention in order to build a deep
network. Here we investigate this design choice and find that more complex
blocks that have different permutations of layer primitives can be more
efficient. Using this insight, we develop a complex block, named Brainformer,
that consists of a diverse sets of layers such as sparsely gated feed-forward
layers, dense feed-forward layers, attention layers, and various forms of layer
normalization and activation functions. Brainformer consistently outperforms
the state-of-the-art dense and sparse Transformers, in terms of both quality
and efficiency. A Brainformer model with 8 billion activated parameters per
token demonstrates 2x faster training convergence and 5x faster step time
compared to its GLaM counterpart. In downstream task evaluation, Brainformer
also demonstrates a 3% higher SuperGLUE score with fine-tuning compared to GLaM
with a similar number of activated parameters. Finally, Brainformer largely
outperforms a Primer dense model derived with NAS with similar computation per
token on fewshot evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Learning Approach for Cancer Entities Association and Classification. (arXiv:2306.00013v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00013">
<div class="article-summary-box-inner">
<span><p>According to the World Health Organization (WHO), cancer is the second
leading cause of death globally. Scientific research on different types of
cancers grows at an ever-increasing rate, publishing large volumes of research
articles every year. The insight information and the knowledge of the drug,
diagnostics, risk, symptoms, treatments, etc., related to genes are significant
factors that help explore and advance the cancer research progression. Manual
screening of such a large volume of articles is very laborious and
time-consuming to formulate any hypothesis. The study uses the two most
non-trivial NLP, Natural Language Processing functions, Entity Recognition, and
text classification to discover knowledge from biomedical literature. Named
Entity Recognition (NER) recognizes and extracts the predefined entities
related to cancer from unstructured text with the support of a user-friendly
interface and built-in dictionaries. Text classification helps to explore the
insights into the text and simplifies data categorization, querying, and
article screening. Machine learning classifiers are also used to build the
classification model and Structured Query Languages (SQL) is used to identify
the hidden relations that may lead to significant predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PreQuant: A Task-agnostic Quantization Approach for Pre-trained Language Models. (arXiv:2306.00014v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00014">
<div class="article-summary-box-inner">
<span><p>While transformer-based pre-trained language models (PLMs) have dominated a
number of NLP applications, these models are heavy to deploy and expensive to
use. Therefore, effectively compressing large-scale PLMs becomes an
increasingly important problem. Quantization, which represents high-precision
tensors with low-bit fix-point format, is a viable solution. However, most
existing quantization methods are task-specific, requiring customized training
and quantization with a large number of trainable parameters on each individual
task. Inspired by the observation that the over-parameterization nature of PLMs
makes it possible to freeze most of the parameters during the fine-tuning
stage, in this work, we propose a novel ``quantize before fine-tuning''
framework, PreQuant, that differs from both quantization-aware training and
post-training quantization. PreQuant is compatible with various quantization
strategies, with outlier-aware parameter-efficient fine-tuning incorporated to
correct the induced quantization error. We demonstrate the effectiveness of
PreQuant on the GLUE benchmark using BERT, RoBERTa, and T5. We also provide an
empirical investigation into the workflow of PreQuant, which sheds light on its
efficacy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale. (arXiv:2306.00017v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00017">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have achieved a milestone that undenia-bly
changed many held beliefs in artificial intelligence (AI). However, there
remains many limitations of these LLMs when it comes to true language
understanding, limitations that are a byproduct of the under-lying architecture
of deep neural networks. Moreover, and due to their subsymbolic nature,
whatever knowledge these models acquire about how language works will always be
buried in billions of microfeatures (weights), none of which is meaningful on
its own, making such models hopelessly unexplainable. To address these
limitations, we suggest com-bining the strength of symbolic representations
with what we believe to be the key to the success of LLMs, namely a successful
bottom-up re-verse engineering of language at scale. As such we argue for a
bottom-up reverse engineering of language in a symbolic setting. Hints on what
this project amounts to have been suggested by several authors, and we discuss
in some detail here how this project could be accomplished.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Utilization of Multinomial Naive Bayes Algorithm and Term Frequency Inverse Document Frequency (TF-IDF Vectorizer) in Checking the Credibility of News Tweet in the Philippines. (arXiv:2306.00018v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00018">
<div class="article-summary-box-inner">
<span><p>The digitalization of news media become a good indicator of progress and
signal to more threats. Media disinformation or fake news is one of these
threats, and it is necessary to take any action in fighting disinformation.
This paper utilizes ground truth-based annotations and TF-IDF as feature
extraction for the news articles which is then used as a training data set for
Multinomial Naive Bayes. The model has an accuracy of 99.46% in training and
88.98% in predicting unseen data. Tagging fake news as real news is a
concerning point on the prediction that is indicated in the F1 score of 89.68%.
This could lead to a negative impact. To prevent this to happen it is suggested
to further improve the corpus collection, and use an ensemble machine learning
to reinforce the prediction
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPT4GEO: How a Language Model Sees the World's Geography. (arXiv:2306.00020v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00020">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have shown remarkable capabilities across a
broad range of tasks involving question answering and the generation of
coherent text and code. Comprehensively understanding the strengths and
weaknesses of LLMs is beneficial for safety, downstream applications and
improving performance. In this work, we investigate the degree to which GPT-4
has acquired factual geographic knowledge and is capable of using this
knowledge for interpretative reasoning, which is especially important for
applications that involve geographic data, such as geospatial analysis, supply
chain management, and disaster response. To this end, we design and conduct a
series of diverse experiments, starting from factual tasks such as location,
distance and elevation estimation to more complex questions such as generating
country outlines and travel networks, route finding under constraints and
supply chain analysis. We provide a broad characterisation of what GPT-4
(without plugins or Internet access) knows about the world, highlighting both
potentially surprising capabilities but also limitations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explaining Hate Speech Classification with Model Agnostic Methods. (arXiv:2306.00021v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00021">
<div class="article-summary-box-inner">
<span><p>There have been remarkable breakthroughs in Machine Learning and Artificial
Intelligence, notably in the areas of Natural Language Processing and Deep
Learning. Additionally, hate speech detection in dialogues has been gaining
popularity among Natural Language Processing researchers with the increased use
of social media. However, as evidenced by the recent trends, the need for the
dimensions of explainability and interpretability in AI models has been deeply
realised. Taking note of the factors above, the research goal of this paper is
to bridge the gap between hate speech prediction and the explanations generated
by the system to support its decision. This has been achieved by first
predicting the classification of a text and then providing a posthoc, model
agnostic and surrogate interpretability approach for explainability and to
prevent model bias. The bidirectional transformer model BERT has been used for
prediction because of its state of the art efficiency over other Machine
Learning models. The model agnostic algorithm LIME generates explanations for
the output of a trained classifier and predicts the features that influence the
model decision. The predictions generated from the model were evaluated
manually, and after thorough evaluation, we observed that the model performs
efficiently in predicting and explaining its prediction. Lastly, we suggest
further directions for the expansion of the provided research work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Verification Improves Few-Shot Clinical Information Extraction. (arXiv:2306.00024v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00024">
<div class="article-summary-box-inner">
<span><p>Extracting patient information from unstructured text is a critical task in
health decision-support and clinical research. Large language models (LLMs)
have shown the potential to accelerate clinical curation via few-shot
in-context learning, in contrast to supervised learning which requires much
more costly human annotations. However, despite drastic advances in modern LLMs
such as GPT-4, they still struggle with issues regarding accuracy and
interpretability, especially in mission-critical domains such as health. Here,
we explore a general mitigation framework using self-verification, which
leverages the LLM to provide provenance for its own extraction and check its
own outputs. This is made possible by the asymmetry between verification and
generation, where the latter is often much easier than the former. Experimental
results show that our method consistently improves accuracy for various LLMs in
standard clinical information extraction tasks. Additionally, self-verification
yields interpretations in the form of a short text span corresponding to each
output, which makes it very efficient for human experts to audit the results,
paving the way towards trustworthy extraction of clinical information in
resource-constrained scenarios. To facilitate future research in this
direction, we release our code and prompts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MetaXLR -- Mixed Language Meta Representation Transformation for Low-resource Cross-lingual Learning based on Multi-Armed Bandit. (arXiv:2306.00100v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00100">
<div class="article-summary-box-inner">
<span><p>Transfer learning for extremely low resource languages is a challenging task
as there is no large scale monolingual corpora for pre training or sufficient
annotated data for fine tuning. We follow the work of MetaXL which suggests
using meta learning for transfer learning from a single source language to an
extremely low resource one. We propose an enhanced approach which uses multiple
source languages chosen in a data driven manner. In addition, we introduce a
sample selection strategy for utilizing the languages in training by using a
multi armed bandit algorithm. Using both of these improvements we managed to
achieve state of the art results on the NER task for the extremely low resource
languages while using the same amount of data, making the representations
better generalized. Also, due to the method ability to use multiple languages
it allows the framework to use much larger amounts of data, while still having
superior results over the former MetaXL method even with the same amounts of
data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ManagerTower: Aggregating the Insights of Uni-Modal Experts for Vision-Language Representation Learning. (arXiv:2306.00103v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00103">
<div class="article-summary-box-inner">
<span><p>Two-Tower Vision-Language (VL) models have shown promising improvements on
various downstream VL tasks. Although the most advanced work improves
performance by building bridges between encoders, it suffers from ineffective
layer-by-layer utilization of uni-modal representations and cannot flexibly
exploit different levels of uni-modal semantic knowledge. In this work, we
propose ManagerTower, a novel VL model architecture that gathers and combines
the insights of pre-trained uni-modal experts at different levels. The managers
introduced in each cross-modal layer can adaptively aggregate uni-modal
semantic knowledge to facilitate more comprehensive cross-modal alignment and
fusion. ManagerTower outperforms previous strong baselines both with and
without Vision-Language Pre-training (VLP). With only 4M VLP data, ManagerTower
achieves superior performances on various downstream VL tasks, especially
79.15% accuracy on VQAv2 Test-Std, 86.56% IR@1 and 95.64% TR@1 on Flickr30K.
Code and checkpoints are available at https://github.com/LooperXX/ManagerTower.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training. (arXiv:2306.00107v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00107">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) has recently emerged as a promising paradigm
for training generalisable models on large-scale data in the fields of vision,
text, and speech. Although SSL has been proven effective in speech and audio,
its application to music audio has yet to be thoroughly explored. This is
primarily due to the distinctive challenges associated with modelling musical
knowledge, particularly its tonal and pitched characteristics of music. To
address this research gap, we propose an acoustic Music undERstanding model
with large-scale self-supervised Training (MERT), which incorporates teacher
models to provide pseudo labels in the masked language modelling (MLM) style
acoustic pre-training. In our exploration, we identified a superior combination
of teacher models, which outperforms conventional speech and audio approaches
in terms of performance. This combination includes an acoustic teacher based on
Residual Vector Quantization - Variational AutoEncoder (RVQ-VAE) and a musical
teacher based on the Constant-Q Transform (CQT). These teachers effectively
guide our student model, a BERT-style transformer encoder, to better model
music audio. In addition, we introduce an in-batch noise mixture augmentation
to enhance the representation robustness. Furthermore, we explore a wide range
of settings to overcome the instability in acoustic language model
pre-training, which allows our designed paradigm to scale from 95M to 330M
parameters. Experimental results indicate that our model can generalise and
perform well on 14 music understanding tasks and attains state-of-the-art
(SOTA) overall scores. The code and models are online:
https://github.com/yizhilll/MERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MuseCoco: Generating Symbolic Music from Text. (arXiv:2306.00110v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00110">
<div class="article-summary-box-inner">
<span><p>Generating music from text descriptions is a user-friendly mode since the
text is a relatively easy interface for user engagement. While some approaches
utilize texts to control music audio generation, editing musical elements in
generated audio is challenging for users. In contrast, symbolic music offers
ease of editing, making it more accessible for users to manipulate specific
musical elements. In this paper, we propose MuseCoco, which generates symbolic
music from text descriptions with musical attributes as the bridge to break
down the task into text-to-attribute understanding and attribute-to-music
generation stages. MuseCoCo stands for Music Composition Copilot that empowers
musicians to generate music directly from given text descriptions, offering a
significant improvement in efficiency compared to creating music entirely from
scratch. The system has two main advantages: Firstly, it is data efficient. In
the attribute-to-music generation stage, the attributes can be directly
extracted from music sequences, making the model training self-supervised. In
the text-to-attribute understanding stage, the text is synthesized and refined
by ChatGPT based on the defined attribute templates. Secondly, the system can
achieve precise control with specific attributes in text descriptions and
offers multiple control options through attribute-conditioned or
text-conditioned approaches. MuseCoco outperforms baseline systems in terms of
musicality, controllability, and overall score by at least 1.27, 1.08, and 1.32
respectively. Besides, there is a notable enhancement of about 20% in objective
control accuracy. In addition, we have developed a robust large-scale model
with 1.2 billion parameters, showcasing exceptional controllability and
musicality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Multi-Figurative Language Detection. (arXiv:2306.00121v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00121">
<div class="article-summary-box-inner">
<span><p>Figures of speech help people express abstract concepts and evoke stronger
emotions than literal expressions, thereby making texts more creative and
engaging. Due to its pervasive and fundamental character, figurative language
understanding has been addressed in Natural Language Processing, but it's
highly understudied in a multilingual setting and when considering more than
one figure of speech at the same time. To bridge this gap, we introduce
multilingual multi-figurative language modelling, and provide a benchmark for
sentence-level figurative language detection, covering three common figures of
speech and seven languages. Specifically, we develop a framework for figurative
language detection based on template-based prompt learning. In so doing, we
unify multiple detection tasks that are interrelated across multiple figures of
speech and languages, without requiring task- or language-specific modules.
Experimental results show that our framework outperforms several strong
baselines and may serve as a blueprint for the joint modelling of other
interrelated tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-Trained Language-Meaning Models for Multilingual Parsing and Generation. (arXiv:2306.00124v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00124">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PLMs) have achieved great success in NLP and
have recently been used for tasks in computational semantics. However, these
tasks do not fully benefit from PLMs since meaning representations are not
explicitly included in the pre-training stage. We introduce multilingual
pre-trained language-meaning models based on Discourse Representation
Structures (DRSs), including meaning representations besides natural language
texts in the same model, and design a new strategy to reduce the gap between
the pre-training and fine-tuning objectives. Since DRSs are language neutral,
cross-lingual transfer learning is adopted to further improve the performance
of non-English tasks. Automatic evaluation results show that our approach
achieves the best performance on both the multilingual DRS parsing and
DRS-to-text generation tasks. Correlation analysis between automatic metrics
and human judgements on the generation task further validates the effectiveness
of our model. Human inspection reveals that out-of-vocabulary tokens are the
main cause of erroneous results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Sequence-to-Sequence&Set Model for Text-to-Table Generation. (arXiv:2306.00137v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00137">
<div class="article-summary-box-inner">
<span><p>Recently, the text-to-table generation task has attracted increasing
attention due to its wide applications. In this aspect, the dominant model
formalizes this task as a sequence-to-sequence generation task and serializes
each table into a token sequence during training by concatenating all rows in a
top-down order. However, it suffers from two serious defects: 1) the predefined
order introduces a wrong bias during training, which highly penalizes shifts in
the order between rows; 2) the error propagation problem becomes serious when
the model outputs a long token sequence. In this paper, we first conduct a
preliminary study to demonstrate the generation of most rows is
order-insensitive. Furthermore, we propose a novel sequence-to-sequence&amp;set
text-to-table generation model. Specifically, in addition to a text encoder
encoding the input text, our model is equipped with a table header generator to
first output a table header, i.e., the first row of the table, in the manner of
sequence generation. Then we use a table body generator with learnable row
embeddings and column embeddings to generate a set of table body rows in
parallel. Particularly, to deal with the issue that there is no correspondence
between each generated table body row and target during training, we propose a
target assignment strategy based on the bipartite matching between the first
cells of generated table body rows and targets. Experiment results show that
our model significantly surpasses the baselines, achieving state-of-the-art
performance on commonly-used datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Measuring the Robustness of Natural Language Processing Models to Domain Shifts. (arXiv:2306.00168v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00168">
<div class="article-summary-box-inner">
<span><p>Large Language Models have shown promising performance on various tasks,
including fine-tuning, few-shot learning, and zero-shot learning. However,
their performance on domains without labeled data still lags behind those with
labeled data, which we refer as the Domain Robustness (DR) challenge. Existing
research on DR suffers from disparate setups, lack of evaluation task variety,
and reliance on challenge sets. In this paper, we explore the DR challenge of
both fine-tuned and few-shot learning models in natural domain shift settings.
We introduce a DR benchmark comprising diverse NLP tasks, including sentence
and token-level classification, QA, and generation, each task consists of
several domains. We propose two views of the DR challenge: Source Drop (SD) and
Target Drop (TD), which alternate between the source and target in-domain
performance as reference points. We find that in significant proportions of
domain shifts, either SD or TD is positive, but not both, emphasizing the
importance of considering both measures as diagnostic tools. Our experimental
results demonstrate the persistent existence of the DR challenge in both
fine-tuning and few-shot learning models, though it is less pronounced in the
latter. We also find that increasing the fine-tuned model size improves
performance, particularly in classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Annotation with Generative AI Requires Validation. (arXiv:2306.00176v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00176">
<div class="article-summary-box-inner">
<span><p>Generative large language models (LLMs) can be a powerful tool for augmenting
text annotation procedures, but their performance varies across annotation
tasks due to prompt quality, text data idiosyncrasies, and conceptual
difficulty. Because these challenges will persist even as LLM technology
improves, we argue that any automated annotation process using an LLM must
validate the LLM's performance against labels generated by humans. To this end,
we outline a workflow to harness the annotation potential of LLMs in a
principled, efficient way. Using GPT-4, we validate this approach by
replicating 27 annotation tasks across 11 datasets from recent social science
articles in high-impact journals. We find that LLM performance for text
annotation is promising but highly contingent on both the dataset and the type
of annotation task, which reinforces the necessity to validate on a
task-by-task basis. We make available easy-to-use software designed to
implement our workflow and streamline the deployment of LLMs for automated
annotation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Hierarchical Discourse Graph for Scientific Document Summarization. (arXiv:2306.00177v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00177">
<div class="article-summary-box-inner">
<span><p>The extended structural context has made scientific paper summarization a
challenging task. This paper proposes CHANGES, a contrastive hierarchical graph
neural network for extractive scientific paper summarization. CHANGES
represents a scientific paper with a hierarchical discourse graph and learns
effective sentence representations with dedicated designed hierarchical graph
information aggregation. We also propose a graph contrastive learning module to
learn global theme-aware sentence representations. Extensive experiments on the
PubMed and arXiv benchmark datasets prove the effectiveness of CHANGES and the
importance of capturing hierarchical structure information in modeling
scientific papers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Factually Consistent Summarization via Reinforcement Learning with Textual Entailment Feedback. (arXiv:2306.00186v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00186">
<div class="article-summary-box-inner">
<span><p>Despite the seeming success of contemporary grounded text generation systems,
they often tend to generate factually inconsistent text with respect to their
input. This phenomenon is emphasized in tasks like summarization, in which the
generated summaries should be corroborated by their source article. In this
work, we leverage recent progress on textual entailment models to directly
address this problem for abstractive summarization systems. We use
reinforcement learning with reference-free, textual entailment rewards to
optimize for factual consistency and explore the ensuing trade-offs, as
improved consistency may come at the cost of less informative or more
extractive summaries. Our results, according to both automatic metrics and
human evaluation, show that our method considerably improves the faithfulness,
salience, and conciseness of the generated summaries.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Invariant Learning Characterization of Controlled Text Generation. (arXiv:2306.00198v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00198">
<div class="article-summary-box-inner">
<span><p>Controlled generation refers to the problem of creating text that contains
stylistic or semantic attributes of interest. Many approaches reduce this
problem to training a predictor of the desired attribute. For example,
researchers hoping to deploy a large language model to produce non-toxic
content may use a toxicity classifier to filter generated text. In practice,
the generated text to classify, which is determined by user prompts, may come
from a wide range of distributions. In this paper, we show that the performance
of controlled generation may be poor if the distributions of text in response
to user prompts differ from the distribution the predictor was trained on. To
address this problem, we cast controlled generation under distribution shift as
an invariant learning problem: the most effective predictor should be invariant
across multiple text environments. We then discuss a natural solution that
arises from this characterization and propose heuristics for selecting natural
environments. We study this characterization and the proposed method
empirically using both synthetic and real data. Experiments demonstrate both
the challenge of distribution shift in controlled generation and the potential
of invariance methods in this setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Strategies for improving low resource speech to text translation relying on pre-trained ASR models. (arXiv:2306.00208v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00208">
<div class="article-summary-box-inner">
<span><p>This paper presents techniques and findings for improving the performance of
low-resource speech to text translation (ST). We conducted experiments on both
simulated and real-low resource setups, on language pairs English - Portuguese,
and Tamasheq - French respectively. Using the encoder-decoder framework for ST,
our results show that a multilingual automatic speech recognition system acts
as a good initialization under low-resource scenarios. Furthermore, using the
CTC as an additional objective for translation during training and decoding
helps to reorder the internal representations and improves the final
translation. Through our experiments, we try to identify various factors
(initializations, objectives, and hyper-parameters) that contribute the most
for improvements in low-resource setups. With only 300 hours of pre-training
data, our model achieved 7.3 BLEU score on Tamasheq - French data,
outperforming prior published works from IWSLT 2022 by 1.6 points.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FEED PETs: Further Experimentation and Expansion on the Disambiguation of Potentially Euphemistic Terms. (arXiv:2306.00217v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00217">
<div class="article-summary-box-inner">
<span><p>Transformers have been shown to work well for the task of English euphemism
disambiguation, in which a potentially euphemistic term (PET) is classified as
euphemistic or non-euphemistic in a particular context. In this study, we
expand on the task in two ways. First, we annotate PETs for vagueness, a
linguistic property associated with euphemisms, and find that transformers are
generally better at classifying vague PETs, suggesting linguistic differences
in the data that impact performance. Second, we present novel euphemism corpora
in three different languages: Yoruba, Spanish, and Mandarin Chinese. We perform
euphemism disambiguation experiments in each language using multilingual
transformer models mBERT and XLM-RoBERTa, establishing preliminary results from
which to launch future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diffusion Brush: A Latent Diffusion Model-based Editing Tool for AI-generated Images. (arXiv:2306.00219v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00219">
<div class="article-summary-box-inner">
<span><p>Text-to-image generative models have made remarkable advancements in
generating high-quality images. However, generated images often contain
undesirable artifacts or other errors due to model limitations. Existing
techniques to fine-tune generated images are time-consuming (manual editing),
produce poorly-integrated results (inpainting), or result in unexpected changes
across the entire image (variation selection and prompt fine-tuning). In this
work, we present Diffusion Brush, a Latent Diffusion Model-based (LDM) tool to
efficiently fine-tune desired regions within an AI-synthesized image. Our
method introduces new random noise patterns at targeted regions during the
reverse diffusion process, enabling the model to efficiently make changes to
the specified regions while preserving the original context for the rest of the
image. We evaluate our method's usability and effectiveness through a user
study with artists, comparing our technique against other state-of-the-art
image inpainting techniques and editing software for fine-tuning AI-generated
imagery.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Visual Cropping to Enhance Fine-Detail Question Answering of BLIP-Family Models. (arXiv:2306.00228v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00228">
<div class="article-summary-box-inner">
<span><p>Visual Question Answering is a challenging task, as it requires seamless
interaction between perceptual, linguistic, and background knowledge systems.
While the recent progress of visual and natural language models like BLIP has
led to improved performance on this task, we lack understanding of the ability
of such models to perform on different kinds of questions and reasoning types.
As our initial analysis of BLIP-family models revealed difficulty with
answering fine-detail questions, we investigate the following question: Can
visual cropping be employed to improve the performance of state-of-the-art
visual question answering models on fine-detail questions? Given the recent
success of the BLIP-family models, we study a zero-shot and a fine-tuned BLIP
model. We define three controlled subsets of the popular VQA-v2 benchmark to
measure whether cropping can help model performance. Besides human cropping, we
devise two automatic cropping strategies based on multi-modal embedding by CLIP
and BLIP visual QA model gradients. Our experiments demonstrate that the
performance of BLIP model variants can be significantly improved through human
cropping, and automatic cropping methods can produce comparable benefits. A
deeper dive into our findings indicates that the performance enhancement is
more pronounced in zero-shot models than in fine-tuned models and more salient
with smaller bounding boxes than larger ones. We perform case studies to
connect quantitative differences with qualitative observations across question
types and datasets. Finally, we see that the cropping enhancement is robust, as
we gain an improvement of 4.59% (absolute) in the general VQA-random task by
simply inputting a concatenation of the original and gradient-based cropped
images. We make our code available to facilitate further innovation on visual
cropping methods for question answering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Pixels to UI Actions: Learning to Follow Instructions via Graphical User Interfaces. (arXiv:2306.00245v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00245">
<div class="article-summary-box-inner">
<span><p>Much of the previous work towards digital agents for graphical user
interfaces (GUIs) has relied on text-based representations (derived from HTML
or other structured data sources), which are not always readily available.
These input representations have been often coupled with custom, task-specific
action spaces. This paper focuses on creating agents that interact with the
digital world using the same conceptual interface that humans commonly use --
via pixel-based screenshots and a generic action space corresponding to
keyboard and mouse actions. Building upon recent progress in pixel-based
pretraining, we show, for the first time, that it is possible for such agents
to outperform human crowdworkers on the MiniWob++ benchmark of GUI-based
instruction following tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AfriNames: Most ASR models "butcher" African Names. (arXiv:2306.00253v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00253">
<div class="article-summary-box-inner">
<span><p>Useful conversational agents must accurately capture named entities to
minimize error for downstream tasks, for example, asking a voice assistant to
play a track from a certain artist, initiating navigation to a specific
location, or documenting a laboratory result for a patient. However, where
named entities such as ``Ukachukwu`` (Igbo), ``Lakicia`` (Swahili), or
``Ingabire`` (Rwandan) are spoken, automatic speech recognition (ASR) models'
performance degrades significantly, propagating errors to downstream systems.
We model this problem as a distribution shift and demonstrate that such model
bias can be mitigated through multilingual pre-training, intelligent data
augmentation strategies to increase the representation of African-named
entities, and fine-tuning multilingual ASR models on multiple African accents.
The resulting fine-tuned models show an 81.5\% relative WER improvement
compared with the baseline on samples with African-named entities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training-free Neural Architecture Search for RNNs and Transformers. (arXiv:2306.00288v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00288">
<div class="article-summary-box-inner">
<span><p>Neural architecture search (NAS) has allowed for the automatic creation of
new and effective neural network architectures, offering an alternative to the
laborious process of manually designing complex architectures. However,
traditional NAS algorithms are slow and require immense amounts of computing
power. Recent research has investigated training-free NAS metrics for image
classification architectures, drastically speeding up search algorithms. In
this paper, we investigate training-free NAS metrics for recurrent neural
network (RNN) and BERT-based transformer architectures, targeted towards
language modeling tasks. First, we develop a new training-free metric, named
hidden covariance, that predicts the trained performance of an RNN architecture
and significantly outperforms existing training-free metrics. We experimentally
evaluate the effectiveness of the hidden covariance metric on the NAS-Bench-NLP
benchmark. Second, we find that the current search space paradigm for
transformer architectures is not optimized for training-free neural
architecture search. Instead, a simple qualitative analysis can effectively
shrink the search space to the best performing architectures. This conclusion
is based on our investigation of existing training-free metrics and new metrics
developed from recent transformer pruning literature, evaluated on our own
benchmark of trained BERT architectures. Ultimately, our analysis shows that
the architecture search space and the training-free metric must be developed
together in order to achieve effective results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CapText: Large Language Model-based Caption Generation From Image Context and Description. (arXiv:2306.00301v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00301">
<div class="article-summary-box-inner">
<span><p>While deep-learning models have been shown to perform well on image-to-text
datasets, it is difficult to use them in practice for captioning images. This
is because \textit{captions} traditionally tend to be context-dependent and
offer complementary information about an image, while models tend to produce
\textit{descriptions} that describe the visual features of the image. Prior
research in caption generation has explored the use of models that generate
captions when provided with the images alongside their respective descriptions
or contexts. We propose and evaluate a new approach, which leverages existing
large language models to generate captions from textual descriptions and
context alone, without ever processing the image directly. We demonstrate that
after fine-tuning, our approach outperforms current state-of-the-art image-text
alignment models like OSCAR-VinVL on this task on the CIDEr metric.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CAISA at SemEval-2023 Task 8: Counterfactual Data Augmentation for Mitigating Class Imbalance in Causal Claim Identification. (arXiv:2306.00346v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00346">
<div class="article-summary-box-inner">
<span><p>The class imbalance problem can cause machine learning models to produce an
undesirable performance on the minority class as well as the whole dataset.
Using data augmentation techniques to increase the number of samples is one way
to tackle this problem. We introduce a novel counterfactual data augmentation
by verb replacement for the identification of medical claims. In addition, we
investigate the impact of this method and compare it with 3 other data
augmentation techniques, showing that the proposed method can result in a
significant (relative) improvement in the minority class.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Focused Prefix Tuning for Controllable Text Generation. (arXiv:2306.00369v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00369">
<div class="article-summary-box-inner">
<span><p>In a controllable text generation dataset, there exist unannotated attributes
that could provide irrelevant learning signals to models that use it for
training and thus degrade their performance. We propose focused prefix
tuning(FPT) to mitigate the problem and to enable the control to focus on the
desired attribute. Experimental results show that FPT can achieve better
control accuracy and text fluency than baseline models in single-attribute
control tasks. In multi-attribute control tasks, FPT achieves comparable
control accuracy with the state-of-the-art approach while keeping the
flexibility to control new attributes without retraining existing models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CFL: Causally Fair Language Models Through Token-level Attribute Controlled Generation. (arXiv:2306.00374v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00374">
<div class="article-summary-box-inner">
<span><p>We propose a method to control the attributes of Language Models (LMs) for
the text generation task using Causal Average Treatment Effect (ATE) scores and
counterfactual augmentation. We explore this method, in the context of LM
detoxification, and propose the Causally Fair Language (CFL) architecture for
detoxifying pre-trained LMs in a plug-and-play manner. Our architecture is
based on a Structural Causal Model (SCM) that is mathematically transparent and
computationally efficient as compared with many existing detoxification
techniques. We also propose several new metrics that aim to better understand
the behaviour of LMs in the context of toxic text generation. Further, we
achieve state of the art performance for toxic degeneration, which are computed
using \RTP (RTP) benchmark. Our experiments show that CFL achieves such a
detoxification without much impact on the model perplexity. We also show that
CFL mitigates the unintended bias problem through experiments on the BOLD
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Developing and Building Ontologies in Cyber Security. (arXiv:2306.00377v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00377">
<div class="article-summary-box-inner">
<span><p>Cyber Security is one of the most arising disciplines in our modern society.
We work on Cybersecurity domain and in this the topic we chose is Cyber
Security Ontologies. In this we gather all latest and previous ontologies and
compare them on the basis of different analyzing factors to get best of them.
Reason to select this topic is to assemble different ontologies from different
era of time. Because, researches that included in this SLR is mostly studied
single ontology. If any researcher wants to study ontologies, he has to study
every single ontology and select which one is best for his research. So, we
assemble different types of ontology and compare them against each other to get
best of them. A total 24 papers between years 2010-2020 are carefully selected
through systematic process and classified accordingly. Lastly, this SLR have
been presented to provide the researchers promising future directions in the
domain of cybersecurity ontologies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Preference-grounded Token-level Guidance for Language Model Fine-tuning. (arXiv:2306.00398v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00398">
<div class="article-summary-box-inner">
<span><p>Aligning language models (LMs) with preferences is an important problem in
natural language generation. A key challenge is that preferences are typically
provided at the sequence level while LM training and generation both occur at
the token level. There is, therefore, a granularity mismatch between the
preference and the LM training losses, which may complicate the learning
problem. In this paper, we address this issue by developing an alternate
training process, where we iterate between grounding the sequence-level
preference into token-level training guidance, and improving the LM with the
learned guidance. For guidance learning, we design a framework that extends the
pairwise-preference learning in imitation learning to both variable-length LM
generation and utilizing the preference among multiple generations. For LM
training, based on the amount of supervised data, we present two minimalist
learning objectives that utilize the learned guidance. In experiments, our
method performs competitively on two distinct representative LM tasks --
discrete-prompt generation and text summarization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BiSync: A Bilingual Editor for Synchronized Monolingual Texts. (arXiv:2306.00400v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00400">
<div class="article-summary-box-inner">
<span><p>In our globalized world, a growing number of situations arise where people
are required to communicate in one or several foreign languages. In the case of
written communication, users with a good command of a foreign language may find
assistance from computer-aided translation (CAT) technologies. These
technologies often allow users to access external resources, such as
dictionaries, terminologies or bilingual concordancers, thereby interrupting
and considerably hindering the writing process. In addition, CAT systems assume
that the source sentence is fixed and also restrict the possible changes on the
target side. In order to make the writing process smoother, we present BiSync,
a bilingual writing assistant that allows users to freely compose text in two
languages, while maintaining the two monolingual texts synchronized. We also
include additional functionalities, such as the display of alternative prefix
translations and paraphrases, which are intended to facilitate the authoring of
texts. We detail the model architecture used for synchronization and evaluate
the resulting tool, showing that high accuracy can be attained with limited
computational resources. The interface and models are publicly available at
https://github.com/jmcrego/BiSync and a demonstration video can be watched on
YouTube at https://youtu.be/_l-ugDHfNgU .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards hate speech detection in low-resource languages: Comparing ASR to acoustic word embeddings on Wolof and Swahili. (arXiv:2306.00410v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00410">
<div class="article-summary-box-inner">
<span><p>We consider hate speech detection through keyword spotting on radio
broadcasts. One approach is to build an automatic speech recognition (ASR)
system for the target low-resource language. We compare this to using acoustic
word embedding (AWE) models that map speech segments to a space where matching
words have similar vectors. We specifically use a multilingual AWE model
trained on labelled data from well-resourced languages to spot keywords in data
in the unseen target language. In contrast to ASR, the AWE approach only
requires a few keyword exemplars. In controlled experiments on Wolof and
Swahili where training and test data are from the same domain, an ASR model
trained on just five minutes of data outperforms the AWE approach. But in an
in-the-wild test on Swahili radio broadcasts with actual hate speech keywords,
the AWE model (using one minute of template data) is more robust, giving
similar performance to an ASR system trained on 30 hours of labelled data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty-Aware Unlikelihood Learning Improves Generative Aspect Sentiment Quad Prediction. (arXiv:2306.00418v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00418">
<div class="article-summary-box-inner">
<span><p>Recently, aspect sentiment quad prediction has received widespread attention
in the field of aspect-based sentiment analysis. Existing studies extract
quadruplets via pre-trained generative language models to paraphrase the
original sentence into a templated target sequence. However, previous works
only focus on what to generate but ignore what not to generate. We argue that
considering the negative samples also leads to potential benefits. In this
work, we propose a template-agnostic method to control the token-level
generation, which boosts original learning and reduces mistakes simultaneously.
Specifically, we introduce Monte Carlo dropout to understand the built-in
uncertainty of pre-trained language models, acquiring the noises and errors. We
further propose marginalized unlikelihood learning to suppress the
uncertainty-aware mistake tokens. Finally, we introduce minimization entropy to
balance the effects of marginalized unlikelihood learning. Extensive
experiments on four public datasets demonstrate the effectiveness of our
approach on various generation templates1.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-end Knowledge Retrieval with Multi-modal Queries. (arXiv:2306.00424v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00424">
<div class="article-summary-box-inner">
<span><p>We investigate knowledge retrieval with multi-modal queries, i.e. queries
containing information split across image and text inputs, a challenging task
that differs from previous work on cross-modal retrieval. We curate a new
dataset called ReMuQ for benchmarking progress on this task. ReMuQ requires a
system to retrieve knowledge from a large corpus by integrating contents from
both text and image queries. We introduce a retriever model ``ReViz'' that can
directly process input text and images to retrieve relevant knowledge in an
end-to-end fashion without being dependent on intermediate modules such as
object detectors or caption generators. We introduce a new pretraining task
that is effective for learning knowledge retrieval with multimodal queries and
also improves performance on downstream tasks. We demonstrate superior
performance in retrieval on two datasets (ReMuQ and OK-VQA) under zero-shot
settings as well as further improvements when finetuned on these datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Divide, Conquer, and Combine: Mixture of Semantic-Independent Experts for Zero-Shot Dialogue State Tracking. (arXiv:2306.00434v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00434">
<div class="article-summary-box-inner">
<span><p>Zero-shot transfer learning for Dialogue State Tracking (DST) helps to handle
a variety of task-oriented dialogue domains without the cost of collecting
in-domain data. Existing works mainly study common data- or model-level
augmentation methods to enhance the generalization but fail to effectively
decouple the semantics of samples, limiting the zero-shot performance of DST.
In this paper, we present a simple and effective "divide, conquer and combine"
solution, which explicitly disentangles the semantics of seen data, and
leverages the performance and robustness with the mixture-of-experts mechanism.
Specifically, we divide the seen data into semantically independent subsets and
train corresponding experts, the newly unseen samples are mapped and inferred
with mixture-of-experts with our designed ensemble inference. Extensive
experiments on MultiWOZ2.1 upon the T5-Adapter show our schema significantly
and consistently improves the zero-shot performance, achieving the SOTA on
settings without external knowledge, with only 10M trainable parameters1.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Many Answers Should I Give? An Empirical Study of Multi-Answer Reading Comprehension. (arXiv:2306.00435v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00435">
<div class="article-summary-box-inner">
<span><p>The multi-answer phenomenon, where a question may have multiple answers
scattered in the document, can be well handled by humans but is challenging
enough for machine reading comprehension (MRC) systems. Despite recent progress
in multi-answer MRC, there lacks a systematic analysis of how this phenomenon
arises and how to better address it. In this work, we design a taxonomy to
categorize commonly-seen multi-answer MRC instances, with which we inspect
three multi-answer datasets and analyze where the multi-answer challenge comes
from. We further analyze how well different paradigms of current multi-answer
MRC models deal with different types of multi-answer instances. We find that
some paradigms capture well the key information in the questions while others
better model the relationship between questions and contexts. We thus explore
strategies to make the best of the strengths of different paradigms.
Experiments show that generation models can be a promising platform to
incorporate different paradigms. Our annotations and code are released for
further research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Responsibility Perspective Transfer for Italian Femicide News. (arXiv:2306.00437v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00437">
<div class="article-summary-box-inner">
<span><p>Different ways of linguistically expressing the same real-world event can
lead to different perceptions of what happened. Previous work has shown that
different descriptions of gender-based violence (GBV) influence the reader's
perception of who is to blame for the violence, possibly reinforcing
stereotypes which see the victim as partly responsible, too. As a contribution
to raise awareness on perspective-based writing, and to facilitate access to
alternative perspectives, we introduce the novel task of automatically
rewriting GBV descriptions as a means to alter the perceived level of
responsibility on the perpetrator. We present a quasi-parallel dataset of
sentences with low and high perceived responsibility levels for the
perpetrator, and experiment with unsupervised (mBART-based), zero-shot and
few-shot (GPT3-based) methods for rewriting sentences. We evaluate our models
using a questionnaire study and a suite of automatic metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A big data approach towards sarcasm detection in Russian. (arXiv:2306.00445v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00445">
<div class="article-summary-box-inner">
<span><p>We present a set of deterministic algorithms for Russian inflection and
automated text synthesis. These algorithms are implemented in a publicly
available web-service www.passare.ru. This service provides functions for
inflection of single words, word matching and synthesis of grammatically
correct Russian text. Selected code and datasets are available at
https://github.com/passare-ru/PassareFunctions/ Performance of the inflectional
functions has been tested against the annotated corpus of Russian language
OpenCorpora, compared with that of other solutions, and used for estimating the
morphological variability and complexity of different parts of speech in
Russian.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Anisotropy and Outliers in Multilingual Language Models for Cross-Lingual Semantic Sentence Similarity. (arXiv:2306.00458v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00458">
<div class="article-summary-box-inner">
<span><p>Previous work has shown that the representations output by contextual
language models are more anisotropic than static type embeddings, and typically
display outlier dimensions. This seems to be true for both monolingual and
multilingual models, although much less work has been done on the multilingual
context. Why these outliers occur and how they affect the representations is
still an active area of research. We investigate outlier dimensions and their
relationship to anisotropy in multiple pre-trained multilingual language
models. We focus on cross-lingual semantic similarity tasks, as these are
natural tasks for evaluating multilingual representations. Specifically, we
examine sentence representations. Sentence transformers which are fine-tuned on
parallel resources (that are not always available) perform better on this task,
and we show that their representations are more isotropic. However, we aim to
improve multilingual representations in general. We investigate how much of the
performance difference can be made up by only transforming the embedding space
without fine-tuning, and visualise the resulting spaces. We test different
operations: Removing individual outlier dimensions, cluster-based isotropy
enhancement, and ZCA whitening. We publish our code for reproducibility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Make Your Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning. (arXiv:2306.00477v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00477">
<div class="article-summary-box-inner">
<span><p>Parameter-efficient fine-tuning (PEFT) of pre-trained language models (PLMs)
has emerged as a highly successful approach, with training only a small number
of parameters without sacrificing performance and becoming the de-facto
learning paradigm with the increasing size of PLMs. However, existing PEFT
methods are not memory-efficient, because they still require caching most of
the intermediate activations for the gradient calculation, akin to fine-tuning.
One effective way to reduce the activation memory is to apply a reversible
model, so the intermediate activations are not necessary to be cached and can
be recomputed. Nevertheless, modifying a PLM to its reversible variant with
PEFT is not straightforward, since the reversible model has a distinct
architecture from the currently released PLMs. In this paper, we first
investigate what is a key factor for the success of existing PEFT methods, and
realize that it's essential to preserve the PLM's starting point when
initializing a PEFT method. With this finding, we propose memory-efficient
fine-tuning (MEFT) that inserts adapters into a PLM, preserving the PLM's
starting point and making it reversible without additional pre-training. We
evaluate MEFT on the GLUE benchmark and five question-answering tasks with
various backbones, BERT, RoBERTa, BART and OPT. MEFT significantly reduces the
activation memory up to 84% of full fine-tuning with a negligible amount of
trainable parameters. Moreover, MEFT achieves the same score on GLUE and a
comparable score on the question-answering tasks as full fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parallel Neurosymbolic Integration with Concordia. (arXiv:2306.00480v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00480">
<div class="article-summary-box-inner">
<span><p>Parallel neurosymbolic architectures have been applied effectively in NLP by
distilling knowledge from a logic theory into a deep model.However, prior art
faces several limitations including supporting restricted forms of logic
theories and relying on the assumption of independence between the logic and
the deep network. We present Concordia, a framework overcoming the limitations
of prior art. Concordia is agnostic both to the deep network and the logic
theory offering support for a wide range of probabilistic theories. Our
framework can support supervised training of both components and unsupervised
training of the neural component. Concordia has been successfully applied to
tasks beyond NLP and data classification, improving the accuracy of
state-of-the-art on collective activity detection, entity linking and
recommendation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inspecting Spoken Language Understanding from Kids for Basic Math Learning at Home. (arXiv:2306.00482v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00482">
<div class="article-summary-box-inner">
<span><p>Enriching the quality of early childhood education with interactive math
learning at home systems, empowered by recent advances in conversational AI
technologies, is slowly becoming a reality. With this motivation, we implement
a multimodal dialogue system to support play-based learning experiences at
home, guiding kids to master basic math concepts. This work explores Spoken
Language Understanding (SLU) pipeline within a task-oriented dialogue system
developed for Kid Space, with cascading Automatic Speech Recognition (ASR) and
Natural Language Understanding (NLU) components evaluated on our home
deployment data with kids going through gamified math learning activities. We
validate the advantages of a multi-task architecture for NLU and experiment
with a diverse set of pretrained language representations for Intent
Recognition and Entity Extraction tasks in the math learning domain. To
recognize kids' speech in realistic home environments, we investigate several
ASR systems, including the commercial Google Cloud and the latest open-source
Whisper solutions with varying model sizes. We evaluate the SLU pipeline by
testing our best-performing NLU models on noisy ASR output to inspect the
challenges of understanding children for math learning in authentic homes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SMARAGD: Learning SMatch for Accurate and Rapid Approximate Graph Distance. (arXiv:2203.13226v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.13226">
<div class="article-summary-box-inner">
<span><p>The similarity of graph structures, such as Meaning Representations (MRs), is
often assessed via structural matching algorithms, such as Smatch (Cai and
Knight, 2013). However, Smatch involves a combinatorial problem that suffers
from NP-completeness, making large-scale applications, e.g., graph clustering
or search, infeasible. To alleviate this issue, we learn SMARAGD: Semantic
Match for Accurate and Rapid Approximate Graph Distance. We show the potential
of neural networks to approximate Smatch scores, i) in linear time using a
machine translation framework to predict alignments, or ii) in constant time
using a Siamese CNN to directly predict Smatch scores. We show that the
approximation error can be substantially reduced through data augmentation and
graph anonymization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Aerial Vision-and-Dialog Navigation. (arXiv:2205.12219v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12219">
<div class="article-summary-box-inner">
<span><p>The ability to converse with humans and follow natural language commands is
crucial for intelligent unmanned aerial vehicles (a.k.a. drones). It can
relieve people's burden of holding a controller all the time, allow
multitasking, and make drone control more accessible for people with
disabilities or with their hands occupied. To this end, we introduce Aerial
Vision-and-Dialog Navigation (AVDN), to navigate a drone via natural language
conversation. We build a drone simulator with a continuous photorealistic
environment and collect a new AVDN dataset of over 3k recorded navigation
trajectories with asynchronous human-human dialogs between commanders and
followers. The commander provides initial navigation instruction and further
guidance by request, while the follower navigates the drone in the simulator
and asks questions when needed. During data collection, followers' attention on
the drone's visual observation is also recorded. Based on the AVDN dataset, we
study the tasks of aerial navigation from (full) dialog history and propose an
effective Human Attention Aided Transformer model (HAA-Transformer), which
learns to predict both navigation waypoints and human attention.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GENEVA: Benchmarking Generalizability for Event Argument Extraction with Hundreds of Event Types and Argument Roles. (arXiv:2205.12505v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12505">
<div class="article-summary-box-inner">
<span><p>Recent works in Event Argument Extraction (EAE) have focused on improving
model generalizability to cater to new events and domains. However, standard
benchmarking datasets like ACE and ERE cover less than 40 event types and 25
entity-centric argument roles. Limited diversity and coverage hinder these
datasets from adequately evaluating the generalizability of EAE models. In this
paper, we first contribute by creating a large and diverse EAE ontology. This
ontology is created by transforming FrameNet, a comprehensive semantic role
labeling (SRL) dataset for EAE, by exploiting the similarity between these two
tasks. Then, exhaustive human expert annotations are collected to build the
ontology, concluding with 115 events and 220 argument roles, with a significant
portion of roles not being entities. We utilize this ontology to further
introduce GENEVA, a diverse generalizability benchmarking dataset comprising
four test suites, aimed at evaluating models' ability to handle limited data
and unseen event type generalization. We benchmark six EAE models from various
families. The results show that owing to non-entity argument roles, even the
best-performing model can only achieve 39% F1 score, indicating how GENEVA
provides new challenges for generalization in EAE. Overall, our large and
diverse EAE ontology can aid in creating more comprehensive future resources,
while GENEVA is a challenging benchmarking dataset encouraging further research
for improving generalizability in EAE. The code and data can be found at
https://github.com/PlusLabNLP/GENEVA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Claim-Dissector: An Interpretable Fact-Checking System with Joint Re-ranking and Veracity Prediction. (arXiv:2207.14116v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.14116">
<div class="article-summary-box-inner">
<span><p>We present Claim-Dissector: a novel latent variable model for fact-checking
and analysis, which given a claim and a set of retrieved evidences jointly
learns to identify: (i) the relevant evidences to the given claim, (ii) the
veracity of the claim. We propose to disentangle the per-evidence relevance
probability and its contribution to the final veracity probability in an
interpretable way -- the final veracity probability is proportional to a linear
ensemble of per-evidence relevance probabilities. In this way, the individual
contributions of evidences towards the final predicted probability can be
identified. In per-evidence relevance probability, our model can further
distinguish whether each relevant evidence is supporting (S) or refuting (R)
the claim. This allows to quantify how much the S/R probability contributes to
the final verdict or to detect disagreeing evidence.
</p>
<p>Despite its interpretable nature, our system achieves results competitive
with state-of-the-art on the FEVER dataset, as compared to typical two-stage
system pipelines, while using significantly fewer parameters. It also sets new
state-of-the-art on FAVIQ and RealFC datasets. Furthermore, our analysis shows
that our model can learn fine-grained relevance cues while using coarse-grained
supervision, and we demonstrate it in 2 ways. (i) We show that our model can
achieve competitive sentence recall while using only paragraph-level relevance
supervision. (ii) Traversing towards the finest granularity of relevance, we
show that our model is capable of identifying relevance at the token level. To
do this, we present a new benchmark TLR-FEVER focusing on token-level
interpretability -- humans annotate tokens in relevant evidences they
considered essential when making their judgment. Then we measure how similar
are these annotations to the tokens our model is focusing on.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Large Language Models know what humans know?. (arXiv:2209.01515v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.01515">
<div class="article-summary-box-inner">
<span><p>Humans can attribute beliefs to others. However, it is unknown to what extent
this ability results from an innate biological endowment or from experience
accrued through child development, particularly exposure to language describing
others' mental states. We test the viability of the language exposure
hypothesis by assessing whether models exposed to large quantities of human
language display sensitivity to the implied knowledge states of characters in
written passages. In pre-registered analyses, we present a linguistic version
of the False Belief Task to both human participants and a Large Language Model,
GPT-3. Both are sensitive to others' beliefs, but while the language model
significantly exceeds chance behavior, it does not perform as well as the
humans, nor does it explain the full extent of their behavior -- despite being
exposed to more language than a human would in a lifetime. This suggests that
while statistical learning from language exposure may in part explain how
humans develop the ability to reason about the mental states of others, other
mechanisms are also responsible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Best Prompts for Text-to-Image Models and How to Find Them. (arXiv:2209.11711v3 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.11711">
<div class="article-summary-box-inner">
<span><p>Recent progress in generative models, especially in text-guided diffusion
models, has enabled the production of aesthetically-pleasing imagery resembling
the works of professional human artists. However, one has to carefully compose
the textual description, called the prompt, and augment it with a set of
clarifying keywords. Since aesthetics are challenging to evaluate
computationally, human feedback is needed to determine the optimal prompt
formulation and keyword combination. In this paper, we present a
human-in-the-loop approach to learning the most useful combination of prompt
keywords using a genetic algorithm. We also show how such an approach can
improve the aesthetic appeal of images depicting the same descriptions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SQuId: Measuring Speech Naturalness in Many Languages. (arXiv:2210.06324v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06324">
<div class="article-summary-box-inner">
<span><p>Much of text-to-speech research relies on human evaluation, which incurs
heavy costs and slows down the development process. The problem is particularly
acute in heavily multilingual applications, where recruiting and polling judges
can take weeks. We introduce SQuId (Speech Quality Identification), a
multilingual naturalness prediction model trained on over a million ratings and
tested in 65 locales-the largest effort of this type to date. The main insight
is that training one model on many locales consistently outperforms mono-locale
baselines. We present our task, the model, and show that it outperforms a
competitive baseline based on w2v-BERT and VoiceMOS by 50.0%. We then
demonstrate the effectiveness of cross-locale transfer during fine-tuning and
highlight its effect on zero-shot locales, i.e., locales for which there is no
fine-tuning data. Through a series of analyses, we highlight the role of
non-linguistic effects such as sound artifacts in cross-locale transfer.
Finally, we present the effect of our design decision, e.g., model size,
pre-training diversity, and language rebalancing with several ablation
experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Creation of Named Entity Recognition Datasets by Querying Phrase Representations. (arXiv:2210.07586v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07586">
<div class="article-summary-box-inner">
<span><p>Most weakly supervised named entity recognition (NER) models rely on
domain-specific dictionaries provided by experts. This approach is infeasible
in many domains where dictionaries do not exist. While a phrase retrieval model
was used to construct pseudo-dictionaries with entities retrieved from
Wikipedia automatically in a recent study, these dictionaries often have
limited coverage because the retriever is likely to retrieve popular entities
rather than rare ones. In this study, we present a novel framework, HighGEN,
that generates NER datasets with high-coverage pseudo-dictionaries.
Specifically, we create entity-rich dictionaries with a novel search method,
called phrase embedding search, which encourages the retriever to search a
space densely populated with various entities. In addition, we use a new
verification process based on the embedding distance between candidate entity
mentions and entity types to reduce the false-positive noise in weak labels
generated by high-coverage dictionaries. We demonstrate that HighGEN
outperforms the previous best model by an average F1 score of 4.7 across five
NER benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Arithmetic Sampling: Parallel Diverse Decoding for Large Language Models. (arXiv:2210.15458v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.15458">
<div class="article-summary-box-inner">
<span><p>Decoding methods for large language models often trade-off between diversity
of outputs and parallelism of computation. Methods such as beam search and
Gumbel top-k sampling can guarantee a different output for each element of the
beam, but are not easy to parallelize. Alternatively, methods such as
temperature sampling and its modifications (top-k sampling, nucleus sampling,
typical decoding, and others), are embarrassingly parallel, but have no
guarantees about duplicate samples. We present a framework for sampling
according to an arithmetic code book implicitly defined by a large language
model, compatible with common sampling variations, with provable beam diversity
under certain conditions, as well as being embarrassingly parallel and
providing unbiased and consistent expectations from the original model. We
demonstrate the effectiveness of our approach on WMT machine translation, more
than halving the standard deviation when estimating expected BLEU score reward,
and closing the BLEU score gap between independent sampling and beam search by
up to 63%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emergent Linguistic Structures in Neural Networks are Fragile. (arXiv:2210.17406v8 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.17406">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have been reported to have strong performance on
natural language processing tasks. However, performance metrics such as
accuracy do not measure the quality of the model in terms of its ability to
robustly represent complex linguistic structures. In this paper, focusing on
the ability of language models to represent syntax, we propose a framework to
assess the consistency and robustness of linguistic representations. To this
end, we introduce measures of robustness of neural network models that leverage
recent advances in extracting linguistic constructs from LLMs via probing
tasks, i.e., simple tasks used to extract meaningful information about a single
facet of a language model, such as syntax reconstruction and root
identification. Empirically, we study the performance of four LLMs across six
different corpora on the proposed robustness measures by analysing their
performance and robustness with respect to syntax-preserving perturbations. We
provide evidence that context-free representation (e.g., GloVe) are in some
cases competitive with context-dependent representations from modern LLMs
(e.g., BERT), yet equally brittle to syntax-preserving perturbations. Our key
observation is that emergent syntactic representations in neural networks are
brittle. We make the code, trained models and logs available to the community
as a contribution to the debate about the capabilities of LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speaking Multiple Languages Affects the Moral Bias of Language Models. (arXiv:2211.07733v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.07733">
<div class="article-summary-box-inner">
<span><p>Pre-trained multilingual language models (PMLMs) are commonly used when
dealing with data from multiple languages and cross-lingual transfer. However,
PMLMs are trained on varying amounts of data for each language. In practice
this means their performance is often much better on English than many other
languages. We explore to what extent this also applies to moral norms. Do the
models capture moral norms from English and impose them on other languages? Do
the models exhibit random and thus potentially harmful beliefs in certain
languages? Both these issues could negatively impact cross-lingual transfer and
potentially lead to harmful outcomes. In this paper, we (1) apply the
MoralDirection framework to multilingual models, comparing results in German,
Czech, Arabic, Chinese, and English, (2) analyse model behaviour on filtered
parallel subtitles corpora, and (3) apply the models to a Moral Foundations
Questionnaire, comparing with human responses from different countries. Our
experiments demonstrate that, indeed, PMLMs encode differing moral biases, but
these do not necessarily correspond to cultural differences or commonalities in
human opinions. We release our code and models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MT Metrics Correlate with Human Ratings of Simultaneous Speech Translation. (arXiv:2211.08633v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.08633">
<div class="article-summary-box-inner">
<span><p>There have been several meta-evaluation studies on the correlation between
human ratings and offline machine translation (MT) evaluation metrics such as
BLEU, chrF2, BertScore and COMET. These metrics have been used to evaluate
simultaneous speech translation (SST) but their correlations with human ratings
of SST, which has been recently collected as Continuous Ratings (CR), are
unclear. In this paper, we leverage the evaluations of candidate systems
submitted to the English-German SST task at IWSLT 2022 and conduct an extensive
correlation analysis of CR and the aforementioned metrics. Our study reveals
that the offline metrics are well correlated with CR and can be reliably used
for evaluating machine translation in simultaneous mode, with some limitations
on the test set size. We conclude that given the current quality levels of SST,
these metrics can be used as proxies for CR, alleviating the need for large
scale human evaluation. Additionally, we observe that correlations of the
metrics with translation as a reference is significantly higher than with
simultaneous interpreting, and thus we recommend the former for reliable
evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reward Gaming in Conditional Text Generation. (arXiv:2211.08714v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.08714">
<div class="article-summary-box-inner">
<span><p>To align conditional text generation model outputs with desired behaviors,
there has been an increasing focus on training the model using reinforcement
learning (RL) with reward functions learned from human annotations. Under this
framework, we identify three common cases where high rewards are incorrectly
assigned to undesirable patterns: noise-induced spurious correlation, naturally
occurring spurious correlation, and covariate shift. We show that even though
learned metrics achieve high performance on the distribution of the data used
to train the reward function, the undesirable patterns may be amplified during
RL training of the text generation model. While there has been discussion about
reward gaming in the RL or safety community, in this discussion piece, we would
like to highlight reward gaming in the natural language generation (NLG)
community using concrete conditional text generation examples and discuss
potential fixes and areas for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Super-CLEVR: A Virtual Benchmark to Diagnose Domain Robustness in Visual Reasoning. (arXiv:2212.00259v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.00259">
<div class="article-summary-box-inner">
<span><p>Visual Question Answering (VQA) models often perform poorly on
out-of-distribution data and struggle on domain generalization. Due to the
multi-modal nature of this task, multiple factors of variation are intertwined,
making generalization difficult to analyze. This motivates us to introduce a
virtual benchmark, Super-CLEVR, where different factors in VQA domain shifts
can be isolated in order that their effects can be studied independently. Four
factors are considered: visual complexity, question redundancy, concept
distribution and concept compositionality. With controllably generated data,
Super-CLEVR enables us to test VQA methods in situations where the test data
differs from the training data along each of these axes. We study four existing
methods, including two neural symbolic methods NSCL and NSVQA, and two
non-symbolic methods FiLM and mDETR; and our proposed method, probabilistic
NSVQA (P-NSVQA), which extends NSVQA with uncertainty reasoning. P-NSVQA
outperforms other methods on three of the four domain shift factors. Our
results suggest that disentangling reasoning and perception, combined with
probabilistic uncertainty, form a strong VQA model that is more robust to
domain shifts. The dataset and code are released at
https://github.com/Lizw14/Super-CLEVR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teaching Small Language Models to Reason. (arXiv:2212.08410v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.08410">
<div class="article-summary-box-inner">
<span><p>Chain of thought prompting successfully improves the reasoning capabilities
of large language models, achieving state of the art results on a range of
datasets. However, these reasoning capabilities only appear to emerge in models
with a size of over 100 billion parameters. In this paper, we explore the
transfer of such reasoning capabilities to models with less than 100 billion
parameters via knowledge distillation. Specifically, we finetune a student
model on the chain of thought outputs generated by a larger teacher model. Our
experiments show that the proposed method improves task performance across
arithmetic, commonsense and symbolic reasoning datasets. For example, the
accuracy of T5 XXL on GSM8K improves from 8.11% to 21.99% when finetuned on
PaLM-540B generated chains of thought.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09597">
<div class="article-summary-box-inner">
<span><p>Reasoning, as an essential ability for complex problem-solving, can provide
back-end support for various real-world applications, such as medical
diagnosis, negotiation, etc. This paper provides a comprehensive survey of
cutting-edge research on reasoning with language model prompting. We introduce
research works with comparisons and summaries and provide systematic resources
to help beginners. We also discuss the potential reasons for emerging such
reasoning abilities and highlight future research directions. Resources are
available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated
periodically).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters. (arXiv:2212.10001v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10001">
<div class="article-summary-box-inner">
<span><p>Chain-of-Thought (CoT) prompting can dramatically improve the multi-step
reasoning abilities of large language models (LLMs). CoT explicitly encourages
the LLM to generate intermediate rationales for solving a problem, by providing
a series of reasoning steps in the demonstrations. Despite its success, there
is still little understanding of what makes CoT prompting effective and which
aspects of the demonstrated reasoning steps contribute to its performance. In
this paper, we show that CoT reasoning is possible even with invalid
demonstrations - prompting with invalid reasoning steps can achieve over 80-90%
of the performance obtained using CoT under various metrics, while still
generating coherent lines of reasoning during inference. Further experiments
show that other aspects of the rationales, such as being relevant to the query
and correctly ordering the reasoning steps, are much more important for
effective CoT reasoning. Overall, these findings both deepen our understanding
of CoT prompting, and open up new questions regarding LLMs' capability to learn
to reason in context.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DISCO: Distilling Phrasal Counterfactuals with Large Language Models. (arXiv:2212.10534v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10534">
<div class="article-summary-box-inner">
<span><p>Models trained with counterfactually augmented data learn representations of
the causal structure of tasks, enabling robust generalization. However,
high-quality counterfactual data is scarce for most tasks and not easily
generated at scale. When crowdsourced, such data is typically limited in scale
and diversity; when generated using supervised methods, it is computationally
expensive to extend to new counterfactual dimensions. In this work, we
introduce DISCO (DIStilled COunterfactual Data), a new method for automatically
generating high quality counterfactual data at scale. DISCO engineers prompts
to generate phrasal perturbations with a large general language model. Then, a
task-specific teacher model filters these generations to distill high-quality
counterfactual data. While task-agnostic, we apply our pipeline to the task of
natural language inference (NLI) and find that on challenging evaluations such
as the NLI stress test, comparatively smaller student models trained with DISCO
generated counterfactuals are more robust (6% absolute) and generalize better
across distributions (2%) compared to models trained without data augmentation.
Furthermore, DISCO augmented models are 10% more consistent between
counterfactual pairs on three evaluation sets, demonstrating that DISCO
augmentation enables models to more reliably learn causal representations. Our
repository is available at: https://github.com/eric11eca/disco
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on In-context Learning. (arXiv:2301.00234v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.00234">
<div class="article-summary-box-inner">
<span><p>With the increasing ability of large language models (LLMs), in-context
learning (ICL) has become a new paradigm for natural language processing (NLP),
where LLMs make predictions only based on contexts augmented with a few
examples. It has been a new trend to explore ICL to evaluate and extrapolate
the ability of LLMs. In this paper, we aim to survey and summarize the progress
and challenges of ICL. We first present a formal definition of ICL and clarify
its correlation to related studies. Then, we organize and discuss advanced
techniques, including training strategies, demonstration designing strategies,
as well as related analysis. Finally, we discuss the challenges of ICL and
provide potential directions for further research. We hope that our work can
encourage more research on uncovering how ICL works and improving ICL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Communication Drives the Emergence of Language Universals in Neural Agents: Evidence from the Word-order/Case-marking Trade-off. (arXiv:2301.13083v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.13083">
<div class="article-summary-box-inner">
<span><p>Artificial learners often behave differently from human learners in the
context of neural agent-based simulations of language emergence and change. A
common explanation is the lack of appropriate cognitive biases in these
learners. However, it has also been proposed that more naturalistic settings of
language learning and use could lead to more human-like results. We investigate
this latter account focusing on the word-order/case-marking trade-off, a widely
attested language universal that has proven particularly hard to simulate. We
propose a new Neural-agent Language Learning and Communication framework
(NeLLCom) where pairs of speaking and listening agents first learn a miniature
language via supervised learning, and then optimize it for communication via
reinforcement learning. Following closely the setup of earlier human
experiments, we succeed in replicating the trade-off with the new framework
without hard-coding specific biases in the agents. We see this as an essential
step towards the investigation of language universals with neural learners.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grounding Language Models to Images for Multimodal Inputs and Outputs. (arXiv:2301.13823v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.13823">
<div class="article-summary-box-inner">
<span><p>We propose an efficient method to ground pretrained text-only language models
to the visual domain, enabling them to process arbitrarily interleaved
image-and-text data, and generate text interleaved with retrieved images. Our
method leverages the abilities of language models learnt from large scale
text-only pretraining, such as in-context learning and free-form text
generation. We keep the language model frozen, and finetune input and output
linear layers to enable cross-modality interactions. This allows our model to
process arbitrarily interleaved image-and-text inputs, and generate free-form
text interleaved with retrieved images. We achieve strong zero-shot performance
on grounded tasks such as contextual image retrieval and multimodal dialogue,
and showcase compelling interactive abilities. Our approach works with any
off-the-shelf language model and paves the way towards an effective, general
solution for leveraging pretrained language models in visually grounded
settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery. (arXiv:2302.03668v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03668">
<div class="article-summary-box-inner">
<span><p>The strength of modern generative models lies in their ability to be
controlled through text-based prompts. Typical "hard" prompts are made from
interpretable words and tokens, and must be hand-crafted by humans. There are
also "soft" prompts, which consist of continuous feature vectors. These can be
discovered using powerful optimization methods, but they cannot be easily
interpreted, re-used across models, or plugged into a text-based interface.
</p>
<p>We describe an approach to robustly optimize hard text prompts through
efficient gradient-based optimization. Our approach automatically generates
hard text-based prompts for both text-to-image and text-to-text applications.
In the text-to-image setting, the method creates hard prompts for diffusion
models, allowing API users to easily generate, discover, and mix and match
image concepts without prior knowledge on how to prompt the model. In the
text-to-text setting, we show that hard prompts can be automatically discovered
that are effective in tuning LMs for classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bag of Tricks for Training Data Extraction from Language Models. (arXiv:2302.04460v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04460">
<div class="article-summary-box-inner">
<span><p>With the advance of language models, privacy protection is receiving more
attention. Training data extraction is therefore of great importance, as it can
serve as a potential tool to assess privacy leakage. However, due to the
difficulty of this task, most of the existing methods are proof-of-concept and
still not effective enough. In this paper, we investigate and benchmark tricks
for improving training data extraction using a publicly available dataset.
Because most existing extraction methods use a pipeline of
generating-then-ranking, i.e., generating text candidates as potential training
data and then ranking them based on specific criteria, our research focuses on
the tricks for both text generation (e.g., sampling strategy) and text ranking
(e.g., token-level criteria). The experimental results show that several
previously overlooked tricks can be crucial to the success of training data
extraction. Based on the GPT-Neo 1.3B evaluation results, our proposed tricks
outperform the baseline by a large margin in most cases, providing a much
stronger baseline for future research. The code is available at
https://github.com/weichen-yu/LM-Extraction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Level Generation Through Large Language Models. (arXiv:2302.05817v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05817">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) are powerful tools, capable of leveraging their
training on natural language to write stories, generate code, and answer
questions. But can they generate functional video game levels? Game levels,
with their complex functional constraints and spatial relationships in more
than one dimension, are very different from the kinds of data an LLM typically
sees during training. Datasets of game levels are also hard to come by,
potentially taxing the abilities of these data-hungry models. We investigate
the use of LLMs to generate levels for the game Sokoban, finding that LLMs are
indeed capable of doing so, and that their performance scales dramatically with
dataset size. We also perform preliminary experiments on controlling LLM level
generators and discuss promising areas for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ProsAudit, a prosodic benchmark for self-supervised speech models. (arXiv:2302.12057v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.12057">
<div class="article-summary-box-inner">
<span><p>We present ProsAudit, a benchmark in English to assess structural prosodic
knowledge in self-supervised learning (SSL) speech models. It consists of two
subtasks, their corresponding metrics, and an evaluation dataset. In the
protosyntax task, the model must correctly identify strong versus weak prosodic
boundaries. In the lexical task, the model needs to correctly distinguish
between pauses inserted between words and within words. We also provide human
evaluation scores on this benchmark. We evaluated a series of SSL models and
found that they were all able to perform above chance on both tasks, even when
evaluated on an unseen language. However, non-native models performed
significantly worse than native ones on the lexical task, highlighting the
importance of lexical knowledge in this task. We also found a clear effect of
size with models trained on more data performing better in the two subtasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Let's have a chat! A Conversation with ChatGPT: Technology, Applications, and Limitations. (arXiv:2302.13817v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.13817">
<div class="article-summary-box-inner">
<span><p>The emergence of an AI-powered chatbot that can generate human-like sentences
and write coherent essays has caught the world's attention. This paper
discusses the historical overview of chatbots and the technology behind Chat
Generative Pre-trained Transformer, better known as ChatGPT. Moreover,
potential applications of ChatGPT in various domains, including healthcare,
education, and research, are highlighted. Despite promising results, there are
several privacy and ethical concerns surrounding ChatGPT. In addition, we
highlight some of the important limitations of the current version of ChatGPT.
We also ask ChatGPT to provide its point of view and present its responses to
several questions we attempt to answer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Speech Recognition for Language-Guided Embodied Agents. (arXiv:2302.14030v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.14030">
<div class="article-summary-box-inner">
<span><p>Benchmarks for language-guided embodied agents typically assume text-based
instructions, but deployed agents will encounter spoken instructions. While
Automatic Speech Recognition (ASR) models can bridge the input gap, erroneous
ASR transcripts can hurt the agents' ability to complete tasks. In this work,
we propose training a multimodal ASR model to reduce errors in transcribing
spoken instructions by considering the accompanying visual context. We train
our model on a dataset of spoken instructions, synthesized from the ALFRED task
completion dataset, where we simulate acoustic noise by systematically masking
spoken words. We find that utilizing visual observations facilitates masked
word recovery, with multimodal ASR models recovering up to 30% more masked
words than unimodal baselines. We also find that a text-trained embodied agent
successfully completes tasks more often by following transcribed instructions
from multimodal ASR models. github.com/Cylumn/embodied-multimodal-asr
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Are State-of-the-Art Evaluators of Translation Quality. (arXiv:2302.14520v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.14520">
<div class="article-summary-box-inner">
<span><p>We describe GEMBA, a GPT-based metric for assessment of translation quality,
which works both with a reference translation and without. In our evaluation,
we focus on zero-shot prompting, comparing four prompt variants in two modes,
based on the availability of the reference. We investigate nine versions of GPT
models, including ChatGPT and GPT-4. We show that our method for translation
quality assessment only works with GPT~3.5 and larger models. Comparing to
results from WMT22's Metrics shared task, our method achieves state-of-the-art
accuracy in both modes when compared to MQM-based human labels. Our results are
valid on the system level for all three WMT22 Metrics shared task language
pairs, namely English into German, English into Russian, and Chinese into
English. This provides a first glimpse into the usefulness of pre-trained,
generative large language models for quality assessment of translations. We
publicly release all our code and prompt templates used for the experiments
described in this work, as well as all corresponding scoring results, to allow
for external validation and reproducibility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Almanac: Retrieval-Augmented Language Models for Clinical Medicine. (arXiv:2303.01229v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01229">
<div class="article-summary-box-inner">
<span><p>Large-language models have recently demonstrated impressive zero-shot
capabilities in a variety of natural language tasks such as summarization,
dialogue generation, and question-answering. Despite many promising
applications in clinical medicine, adoption of these models in real-world
settings has been largely limited by their tendency to generate incorrect and
sometimes even toxic statements. In this study, we develop Almanac, a large
language model framework augmented with retrieval capabilities for medical
guideline and treatment recommendations. Performance on a novel dataset of
clinical scenarios (n = 130) evaluated by a panel of 5 board-certified and
resident physicians demonstrates significant increases in factuality (mean of
18% at p-value &lt; 0.05) across all specialties, with improvements in
completeness and safety. Our results demonstrate the potential for large
language models to be effective tools in the clinical decision-making process,
while also emphasizing the importance of careful testing and deployment to
mitigate their shortcomings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Query-Utterance Attention with Joint modeling for Query-Focused Meeting Summarization. (arXiv:2303.04487v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04487">
<div class="article-summary-box-inner">
<span><p>Query-focused meeting summarization (QFMS) aims to generate summaries from
meeting transcripts in response to a given query. Previous works typically
concatenate the query with meeting transcripts and implicitly model the query
relevance only at the token level with attention mechanism. However, due to the
dilution of key query-relevant information caused by long meeting transcripts,
the original transformer-based model is insufficient to highlight the key parts
related to the query. In this paper, we propose a query-aware framework with
joint modeling token and utterance based on Query-Utterance Attention. It
calculates the utterance-level relevance to the query with a dense retrieval
module. Then both token-level query relevance and utterance-level query
relevance are combined and incorporated into the generation process with
attention mechanism explicitly. We show that the query relevance of different
granularities contributes to generating a summary more related to the query.
Experimental results on the QMSum dataset show that the proposed model achieves
new state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emergent and Predictable Memorization in Large Language Models. (arXiv:2304.11158v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11158">
<div class="article-summary-box-inner">
<span><p>Memorization, or the tendency of large language models (LLMs) to output
entire sequences from their training data verbatim, is a key concern for safely
deploying language models. In particular, it is vital to minimize a model's
memorization of sensitive datapoints such as those containing personal
identifiable information (PII). The prevalence of such undesirable memorization
can pose issues for model trainers, and may even require discarding an
otherwise functional model. We therefore seek to predict which sequences will
be memorized before a large model's full train-time by extrapolating the
memorization behavior of lower-compute trial runs. We measure memorization of
the Pythia model suite and plot scaling laws for forecasting memorization,
allowing us to provide equi-compute recommendations to maximize the reliability
(recall) of such predictions. We additionally provide further novel discoveries
on the distribution of memorization scores across models and data. We release
all code and data necessary to reproduce the results in this paper at
https://github.com/EleutherAI/pythia
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Challenges of Deploying BERT-based NLP Models in Resource-Constrained Embedded Devices. (arXiv:2304.11520v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11520">
<div class="article-summary-box-inner">
<span><p>BERT-based neural architectures have established themselves as popular
state-of-the-art baselines for many downstream NLP tasks. However, these
architectures are data-hungry and consume a lot of memory and energy, often
hindering their deployment in many real-time, resource-constrained
applications. Existing lighter versions of BERT (eg. DistilBERT and TinyBERT)
often cannot perform well on complex NLP tasks. More importantly, from a
designer's perspective, it is unclear what is the "right" BERT-based
architecture to use for a given NLP task that can strike the optimal trade-off
between the resources available and the minimum accuracy desired by the end
user. System engineers have to spend a lot of time conducting trial-and-error
experiments to find a suitable answer to this question. This paper presents an
exploratory study of BERT-based models under different resource constraints and
accuracy budgets to derive empirical observations about this resource/accuracy
trade-offs. Our findings can help designers to make informed choices among
alternative BERT-based architectures for embedded systems, thus saving
significant development time and effort.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation. (arXiv:2305.00955v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.00955">
<div class="article-summary-box-inner">
<span><p>Many recent advances in natural language generation have been fueled by
training large language models on internet-scale data. However, this paradigm
can lead to models that generate toxic, inaccurate, and unhelpful content, and
automatic evaluation metrics often fail to identify these behaviors. As models
become more capable, human feedback is an invaluable signal for evaluating and
improving models. This survey aims to provide an overview of the recent
research that has leveraged human feedback to improve natural language
generation. First, we introduce an encompassing formalization of feedback, and
identify and organize existing research into a taxonomy following this
formalization. Next, we discuss how feedback can be described by its format and
objective, and cover the two approaches proposed to use feedback (either for
training or decoding): directly using the feedback or training feedback models.
We also discuss existing datasets for human-feedback data collection, and
concerns surrounding feedback collection. Finally, we provide an overview of
the nascent field of AI feedback, which exploits large language models to make
judgments based on a set of principles and minimize the need for human
intervention.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?. (arXiv:2305.01555v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01555">
<div class="article-summary-box-inner">
<span><p>Scaling language models have revolutionized widespread NLP tasks, yet little
comprehensively explored few-shot relation extraction with large language
models. In this paper, we investigate principal methodologies, in-context
learning and data generation, for few-shot relation extraction via GPT-3.5
through exhaustive experiments. To enhance few-shot performance, we further
propose task-related instructions and schema-constrained data generation. We
observe that in-context learning can achieve performance on par with previous
prompt learning approaches, and data generation with the large language model
can boost previous solutions to obtain new state-of-the-art few-shot results on
four widely-studied relation extraction datasets. We hope our work can inspire
future research for the capabilities of large language models in few-shot
relation extraction. Code is available in
https://github.com/zjunlp/DeepKE/tree/main/example/llm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT as a Text Simplification Tool to Remove Bias. (arXiv:2305.06166v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.06166">
<div class="article-summary-box-inner">
<span><p>The presence of specific linguistic signals particular to a certain sub-group
of people can be picked up by language models during training. If the model
begins to associate specific language with a distinct group, any decisions made
based upon this language would hold a strong correlation to a decision based
upon their protected characteristic, leading to possible discrimination. We
explore a potential technique for bias mitigation in the form of simplification
of text. The driving force of this idea is that simplifying text should
standardise language between different sub-groups to one way of speaking while
keeping the same meaning. The experiment shows promising results as the
classifier accuracy for predicting the sensitive attribute drops by up to 17%
for the simplified data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning Methods for Extracting Metaphorical Names of Flowers and Plants. (arXiv:2305.10833v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10833">
<div class="article-summary-box-inner">
<span><p>The domain of Botany is rich with metaphorical terms. Those terms play an
important role in the description and identification of flowers and plants.
However, the identification of such terms in discourse is an arduous task. This
leads in some cases to committing errors during translation processes and
lexicographic tasks. The process is even more challenging when it comes to
machine translation, both in the cases of single-word terms and multi-word
terms. One of the recent concerns of Natural Language Processing (NLP)
applications and Machine Translation (MT) technologies is the automatic
identification of metaphor-based words in discourse through Deep Learning (DL).
In this study, we seek to fill this gap through the use of thirteen popular
transformer based models, as well as ChatGPT, and we show that discriminative
models perform better than GPT-3.5 model with our best performer reporting
92.2349% F1 score in metaphoric flower and plant names identification task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Off-Target Problem of Zero-Shot Multilingual Neural Machine Translation. (arXiv:2305.10930v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10930">
<div class="article-summary-box-inner">
<span><p>While multilingual neural machine translation has achieved great success, it
suffers from the off-target issue, where the translation is in the wrong
language. This problem is more pronounced on zero-shot translation tasks. In
this work, we find that failing in encoding discriminative target language
signal will lead to off-target and a closer lexical distance (i.e.,
KL-divergence) between two languages' vocabularies is related with a higher
off-target rate. We also find that solely isolating the vocab of different
languages in the decoder can alleviate the problem. Motivated by the findings,
we propose Language Aware Vocabulary Sharing (LAVS), a simple and effective
algorithm to construct the multilingual vocabulary, that greatly alleviates the
off-target problem of the translation model by increasing the KL-divergence
between languages. We conduct experiments on a multilingual machine translation
benchmark in 11 languages. Experiments show that the off-target rate for 90
translation tasks is reduced from 29\% to 8\%, while the overall BLEU score is
improved by an average of 1.9 points without extra training cost or sacrificing
the supervised directions' performance. We release the code at
\href{https://github.com/chenllliang/Off-Target-MNMT}{https://github.com/chenllliang/Off-Target-MNMT}
for reproduction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Pilot Study on Dialogue-Level Dependency Parsing for Chinese. (arXiv:2305.12441v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.12441">
<div class="article-summary-box-inner">
<span><p>Dialogue-level dependency parsing has received insufficient attention,
especially for Chinese. To this end, we draw on ideas from syntactic dependency
and rhetorical structure theory (RST), developing a high-quality
human-annotated corpus, which contains 850 dialogues and 199,803 dependencies.
Considering that such tasks suffer from high annotation costs, we investigate
zero-shot and few-shot scenarios. Based on an existing syntactic treebank, we
adopt a signal-based method to transform seen syntactic dependencies into
unseen ones between elementary discourse units (EDUs), where the signals are
detected by masked language modeling. Besides, we apply single-view and
multi-view data selection to access reliable pseudo-labeled instances.
Experimental results show the effectiveness of these baselines. Moreover, we
discuss several crucial points about our dataset and approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models are Frame-level Directors for Zero-shot Text-to-Video Generation. (arXiv:2305.14330v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14330">
<div class="article-summary-box-inner">
<span><p>In the paradigm of AI-generated content (AIGC), there has been increasing
attention in extending pre-trained text-to-image (T2I) models to text-to-video
(T2V) generation. Despite their effectiveness, these frameworks face challenges
in maintaining consistent narratives and handling rapid shifts in scene
composition or object placement from a single user prompt. This paper
introduces a new framework, dubbed DirecT2V, which leverages instruction-tuned
large language models (LLMs) to generate frame-by-frame descriptions from a
single abstract user prompt. DirecT2V utilizes LLM directors to divide user
inputs into separate prompts for each frame, enabling the inclusion of
time-varying content and facilitating consistent video generation. To maintain
temporal consistency and prevent object collapse, we propose a novel value
mapping method and dual-softmax filtering. Extensive experimental results
validate the effectiveness of the DirecT2V framework in producing visually
coherent and consistent videos from abstract user prompts, addressing the
challenges of zero-shot video generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BeamSearchQA: Large Language Models are Strong Zero-Shot QA Solver. (arXiv:2305.14766v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14766">
<div class="article-summary-box-inner">
<span><p>Open-domain question answering is a crucial task that often requires
accessing external information. Existing methods typically adopt a single-turn
retrieve-then-read approach, where relevant documents are first retrieved, and
questions are then answered based on the retrieved information. However, there
are cases where answering a question requires implicit knowledge that is not
directly retrievable from the question itself. In this work, we propose a novel
question-answering pipeline called BeamSearchQA. Our approach leverages large
language models to iteratively generate new questions about the original
question, enabling an iterative reasoning process. By iteratively refining and
expanding the scope of the question, our method aims to capture and utilize
hidden knowledge that may not be directly obtainable through retrieval. We
evaluate our approach on the widely-used open-domain NQ and WebQ datasets. The
experimental results demonstrate that BeamSearchQA significantly outperforms
other zero-shot baselines, indicating its effectiveness in tackling the
challenges of open-domain question answering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LMs with a Voice: Spoken Language Modeling beyond Speech Tokens. (arXiv:2305.15255v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15255">
<div class="article-summary-box-inner">
<span><p>We present SPECTRON, a novel approach to adapting pre-trained language models
(LMs) to perform speech continuation. By leveraging pre-trained speech
encoders, our model generates both text and speech outputs with the entire
system being trained end-to-end operating directly on spectrograms. Training
the entire model in the spectrogram domain simplifies our speech continuation
system versus existing cascade methods which use discrete speech
representations. We further show our method surpasses existing spoken language
models both in semantic content and speaker preservation while also benefiting
from the knowledge transferred from pre-existing models. Audio samples can be
found in our website https://michelleramanovich.github.io/spectron/spectron
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective. (arXiv:2305.15408v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15408">
<div class="article-summary-box-inner">
<span><p>Recent studies have discovered that Chain-of-Thought prompting (CoT) can
dramatically improve the performance of Large Language Models (LLMs),
particularly when dealing with complex tasks involving mathematics or
reasoning. Despite the enormous empirical success, the underlying mechanisms
behind CoT and how it unlocks the potential of LLMs remain elusive. In this
paper, we take a first step towards theoretically answering these questions.
Specifically, we examine the expressivity of LLMs with CoT in solving
fundamental mathematical and decision-making problems. We start by giving an
impossibility result showing that bounded-depth Transformers are unable to
directly produce correct answers for basic arithmetic/equation tasks unless the
model size grows super-polynomially with respect to the input length. In
contrast, we then prove by construction that autoregressive Transformers of
constant size suffice to solve both tasks by generating CoT derivations using a
commonly-used math language format. Moreover, we show LLMs with CoT are capable
of solving a general class of decision-making problems known as Dynamic
Programming, thus justifying its power in tackling complex real-world tasks.
Finally, extensive experiments on four tasks show that, while Transformers
always fail to predict the answers directly, they can consistently learn to
generate correct solutions step-by-step given sufficient CoT demonstrations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LFTK: Handcrafted Features in Computational Linguistics. (arXiv:2305.15878v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15878">
<div class="article-summary-box-inner">
<span><p>Past research has identified a rich set of handcrafted linguistic features
that can potentially assist various tasks. However, their extensive number
makes it difficult to effectively select and utilize existing handcrafted
features. Coupled with the problem of inconsistent implementation across
research works, there has been no categorization scheme or generally-accepted
feature names. This creates unwanted confusion. Also, most existing handcrafted
feature extraction libraries are not open-source or not actively maintained. As
a result, a researcher often has to build such an extraction system from the
ground up.
</p>
<p>We collect and categorize more than 220 popular handcrafted features grounded
on past literature. Then, we conduct a correlation analysis study on several
task-specific datasets and report the potential use cases of each feature.
Lastly, we devise a multilingual handcrafted linguistic feature extraction
system in a systematically expandable manner. We open-source our system for
public access to a rich set of pre-implemented handcrafted features. Our system
is coined LFTK and is the largest of its kind. Find it at
github.com/brucewlee/lftk.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Natural Language Processing for Long Texts: A Survey of the State-of-the-Art. (arXiv:2305.16259v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16259">
<div class="article-summary-box-inner">
<span><p>The adoption of Deep Neural Networks (DNNs) has greatly benefited Natural
Language Processing (NLP) during the past decade. However, the demands of long
document analysis are quite different from those of shorter texts, while the
ever increasing size of documents uploaded on-line renders automated
understanding of long texts a critical area of research. This article has two
goals: a) it overviews the relevant neural building blocks, thus serving as a
short tutorial, and b) it surveys the state-of-the-art in long document NLP,
mainly focusing on two central tasks: document classification and document
summarization. Sentiment analysis for long texts is also covered, since it is
typically treated as a particular case of document classification.
Additionally, this article discusses the main challenges, issues and current
solutions related to long document NLP. Finally, the relevant, publicly
available, annotated datasets are presented, in order to facilitate further
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NLP Reproducibility For All: Understanding Experiences of Beginners. (arXiv:2305.16579v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16579">
<div class="article-summary-box-inner">
<span><p>As natural language processing (NLP) has recently seen an unprecedented level
of excitement, and more people are eager to enter the field, it is unclear
whether current research reproducibility efforts are sufficient for this group
of beginners to apply the latest developments. To understand their needs, we
conducted a study with 93 students in an introductory NLP course, where
students reproduced the results of recent NLP papers. Surprisingly, we find
that their programming skill and comprehension of research papers have a
limited impact on their effort spent completing the exercise. Instead, we find
accessibility efforts by research authors to be the key to success, including
complete documentation, better coding practice, and easier access to data
files. Going forward, we recommend that NLP researchers pay close attention to
these simple aspects of open-sourcing their work, and use insights from
beginners' feedback to provide actionable ideas on how to better support them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Emotion Experiencer Recognition. (arXiv:2305.16731v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16731">
<div class="article-summary-box-inner">
<span><p>The most prominent subtask in emotion analysis is emotion classification; to
assign a category to a textual unit, for instance a social media post. Many
research questions from the social sciences do, however, not only require the
detection of the emotion of an author of a post but to understand who is
ascribed an emotion in text. This task is tackled by emotion role labeling
which aims at extracting who is described in text to experience an emotion,
why, and towards whom. This could, however, be considered overly sophisticated
if the main question to answer is who feels which emotion. A targeted approach
for such setup is to classify emotion experiencer mentions (aka "emoters")
regarding the emotion they presumably perceive. This task is similar to named
entity recognition of person names with the difference that not every mentioned
entity name is an emoter. While, very recently, data with emoter annotations
has been made available, no experiments have yet been performed to detect such
mentions. With this paper, we provide baseline experiments to understand how
challenging the task is. We further evaluate the impact on experiencer-specific
emotion categorization and appraisal detection in a pipeline, when gold
mentions are not available. We show that experiencer detection in text is a
challenging task, with a precision of .82 and a recall of .56 (F1 =.66). These
results motivate future work of jointly modeling emoter spans and
emotion/appraisal predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory. (arXiv:2305.17144v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17144">
<div class="article-summary-box-inner">
<span><p>The captivating realm of Minecraft has attracted substantial research
interest in recent years, serving as a rich platform for developing intelligent
agents capable of functioning in open-world environments. However, the current
research landscape predominantly focuses on specific objectives, such as the
popular "ObtainDiamond" task, and has not yet shown effective generalization to
a broader spectrum of tasks. Furthermore, the current leading success rate for
the "ObtainDiamond" task stands at around 20%, highlighting the limitations of
Reinforcement Learning (RL) based controllers used in existing methods. To
tackle these challenges, we introduce Ghost in the Minecraft (GITM), a novel
framework integrates Large Language Models (LLMs) with text-based knowledge and
memory, aiming to create Generally Capable Agents (GCAs) in Minecraft. These
agents, equipped with the logic and common sense capabilities of LLMs, can
skillfully navigate complex, sparse-reward environments with text-based
interactions. We develop a set of structured actions and leverage LLMs to
generate action plans for the agents to execute. The resulting LLM-based agent
markedly surpasses previous methods, achieving a remarkable improvement of
+47.5% in success rate on the "ObtainDiamond" task, demonstrating superior
robustness compared to traditional RL-based controllers. Notably, our agent is
the first to procure all items in the Minecraft Overworld technology tree,
demonstrating its extensive capabilities. GITM does not need any GPU for
training, but a single CPU node with 32 CPU cores is enough. This research
shows the potential of LLMs in developing capable agents for handling
long-horizon, complex tasks and adapting to uncertainties in open-world
environments. See the project website at https://github.com/OpenGVLab/GITM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Heterogeneous Value Evaluation for Large Language Models. (arXiv:2305.17147v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17147">
<div class="article-summary-box-inner">
<span><p>The emergent capabilities of Large Language Models (LLMs) have made it
crucial to align their values with those of humans. Current methodologies
typically attempt alignment with a homogeneous human value and requires human
verification, yet lack consensus on the desired aspect and depth of alignment
and resulting human biases. In this paper, we propose A2EHV, an Automated
Alignment Evaluation with a Heterogeneous Value system that (1) is automated to
minimize individual human biases, and (2) allows assessments against various
target values to foster heterogeneous agents. Our approach pivots on the
concept of value rationality, which represents the ability for agents to
execute behaviors that satisfy a target value the most. The quantification of
value rationality is facilitated by the Social Value Orientation framework from
social psychology, which partitions the value space into four categories to
assess social preferences from agents' behaviors. We evaluate the value
rationality of eight mainstream LLMs and observe that large models are more
inclined to align neutral values compared to those with strong personal values.
By examining the behavior of these LLMs, we contribute to a deeper
understanding of value alignment within a heterogeneous value system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FACTUAL: A Benchmark for Faithful and Consistent Textual Scene Graph Parsing. (arXiv:2305.17497v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17497">
<div class="article-summary-box-inner">
<span><p>Textual scene graph parsing has become increasingly important in various
vision-language applications, including image caption evaluation and image
retrieval. However, existing scene graph parsers that convert image captions
into scene graphs often suffer from two types of errors. First, the generated
scene graphs fail to capture the true semantics of the captions or the
corresponding images, resulting in a lack of faithfulness. Second, the
generated scene graphs have high inconsistency, with the same semantics
represented by different annotations.
</p>
<p>To address these challenges, we propose a novel dataset, which involves
re-annotating the captions in Visual Genome (VG) using a new intermediate
representation called FACTUAL-MR. FACTUAL-MR can be directly converted into
faithful and consistent scene graph annotations. Our experimental results
clearly demonstrate that the parser trained on our dataset outperforms existing
approaches in terms of faithfulness and consistency. This improvement leads to
a significant performance boost in both image caption evaluation and zero-shot
image retrieval tasks. Furthermore, we introduce a novel metric for measuring
scene graph similarity, which, when combined with the improved scene graph
parser, achieves state-of-the-art (SOTA) results on multiple benchmark datasets
for the aforementioned tasks. The code and dataset are available at
https://github.com/zhuang-li/FACTUAL .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Translatotron 3: Speech to Speech Translation with Monolingual Data. (arXiv:2305.17547v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17547">
<div class="article-summary-box-inner">
<span><p>This paper presents Translatotron 3, a novel approach to train a direct
speech-to-speech translation model from monolingual speech-text datasets only
in a fully unsupervised manner. Translatotron 3 combines masked autoencoder,
unsupervised embedding mapping, and back-translation to achieve this goal.
Experimental results in speech-to-speech translation tasks between Spanish and
English show that Translatotron 3 outperforms a baseline cascade system,
reporting 18.14 BLEU points improvement on the synthesized
Unpaired-Conversational dataset. In contrast to supervised approaches that
necessitate real paired data, which is unavailable, or specialized modeling to
replicate para-/non-linguistic information, Translatotron 3 showcases its
capability to retain para-/non-linguistic such as pauses, speaking rates, and
speaker identity. Audio samples can be found in our website
<a href="http://google-research.github.io/lingvo-lab/translatotron3">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Task Synthesis for Visual Programming. (arXiv:2305.18342v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18342">
<div class="article-summary-box-inner">
<span><p>Generative neural models hold great promise in enhancing programming
education by synthesizing new content for students. We seek to design neural
models that can automatically generate programming tasks for a given
specification in the context of visual programming domains. Despite the recent
successes of large generative models like GPT-4, our initial results show that
these models are ineffective in synthesizing visual programming tasks and
struggle with logical and spatial reasoning. We propose a novel neuro-symbolic
technique, NeurTaskSyn, that can synthesize programming tasks for a
specification given in the form of desired programming concepts exercised by
its solution code and constraints on the visual task. NeurTaskSyn has two
components: the first component is trained via imitation learning procedure to
generate possible solution codes, and the second component is trained via
reinforcement learning procedure to guide an underlying symbolic execution
engine that generates visual tasks for these codes. We demonstrate the
effectiveness of NeurTaskSyn through an extensive empirical evaluation and a
qualitative study on reference tasks taken from the Hour of Code: Classic Maze
challenge by Code-dot-org and the Intro to Programming with Karel course by
CodeHS-dot-com.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conformal Prediction with Large Language Models for Multi-Choice Question Answering. (arXiv:2305.18404v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18404">
<div class="article-summary-box-inner">
<span><p>As large language models continue to be widely developed, robust uncertainty
quantification techniques will become crucial for their safe deployment in
high-stakes scenarios. In this work, we explore how conformal prediction can be
used to provide uncertainty quantification in language models for the specific
task of multiple-choice question-answering. We find that the uncertainty
estimates from conformal prediction are tightly correlated with prediction
accuracy. This observation can be useful for downstream applications such as
selective classification and filtering out low-quality predictions. We also
investigate the exchangeability assumption required by conformal prediction to
out-of-subject questions, which may be a more realistic scenario for many
practical applications. Our work contributes towards more trustworthy and
reliable usage of large language models in safety-critical situations, where
robust guarantees of error rate are required.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Representation Of Lexical Stylistic Features In Language Models' Embedding Space. (arXiv:2305.18657v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18657">
<div class="article-summary-box-inner">
<span><p>The representation space of pretrained Language Models (LMs) encodes rich
information about words and their relationships (e.g., similarity, hypernymy,
polysemy) as well as abstract semantic notions (e.g., intensity). In this
paper, we demonstrate that lexical stylistic notions such as complexity,
formality, and figurativeness, can also be identified in this space. We show
that it is possible to derive a vector representation for each of these
stylistic notions from only a small number of seed pairs. Using these vectors,
we can characterize new texts in terms of these dimensions by performing simple
calculations in the corresponding embedding space. We conduct experiments on
five datasets and find that static embeddings encode these features more
accurately at the level of words and phrases, whereas contextualized LMs
perform better on sentences. The lower performance of contextualized
representations at the word level is partially attributable to the anisotropy
of their vector space, which can be corrected to some extent using techniques
like standardization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DC CoMix TTS: An End-to-End Expressive TTS with Discrete Code Collaborated with Mixer. (arXiv:2305.19567v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19567">
<div class="article-summary-box-inner">
<span><p>Despite the huge successes made in neutral TTS, content-leakage remains a
challenge. In this paper, we propose a new input representation and simple
architecture to achieve improved prosody modeling. Inspired by the recent
success in the use of discrete code in TTS, we introduce discrete code to the
input of the reference encoder. Specifically, we leverage the vector quantizer
from the audio compression model to exploit the diverse acoustic information it
has already been trained on. In addition, we apply the modified MLP-Mixer to
the reference encoder, making the architecture lighter. As a result, we train
the prosody transfer TTS in an end-to-end manner. We prove the effectiveness of
our method through both subjective and objective evaluations. We demonstrate
that the reference encoder learns better speaker-independent prosody when
discrete code is utilized as input in the experiments. In addition, we obtain
comparable results even when fewer parameters are inputted.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Global Context Mechanism for Sequence Labeling. (arXiv:2305.19928v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19928">
<div class="article-summary-box-inner">
<span><p>Sequential labeling tasks necessitate the computation of sentence
representations for each word within a given sentence. With the advent of
advanced pretrained language models; one common approach involves incorporating
a BiLSTM layer to bolster the sequence structure information at the output
level. Nevertheless, it has been empirically demonstrated (P.-H. Li et al.,
2020) that the potential of BiLSTM for generating sentence representations for
sequence labeling tasks is constrained, primarily due to the amalgamation of
fragments form past and future sentence representations to form a complete
sentence representation. In this study, we discovered that strategically
integrating the whole sentence representation, which existing in the first cell
and last cell of BiLSTM, into sentence representation of ecah cell, could
markedly enhance the F1 score and accuracy. Using BERT embedded within BiLSTM
as illustration, we conducted exhaustive experiments on nine datasets for
sequence labeling tasks, encompassing named entity recognition (NER), part of
speech (POS) tagging and End-to-End Aspect-Based sentiment analysis (E2E-ABSA).
We noted significant improvements in F1 scores and accuracy across all examined
datasets .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beam Tree Recursive Cells. (arXiv:2305.19999v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19999">
<div class="article-summary-box-inner">
<span><p>We propose Beam Tree Recursive Cell (BT-Cell) - a backpropagation-friendly
framework to extend Recursive Neural Networks (RvNNs) with beam search for
latent structure induction. We further extend this framework by proposing a
relaxation of the hard top-k operators in beam search for better propagation of
gradient signals. We evaluate our proposed models in different
out-of-distribution splits in both synthetic and realistic data. Our
experiments show that BTCell achieves near-perfect performance on several
challenging structure-sensitive synthetic tasks like ListOps and logical
inference while maintaining comparable performance in realistic data against
other RvNN-based models. Additionally, we identify a previously unknown failure
case for neural models in generalization to unseen number of arguments in
ListOps. The code is available at:
https://github.com/JRC1995/BeamTreeRecursiveCells.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decision-Oriented Dialogue for Human-AI Collaboration. (arXiv:2305.20076v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.20076">
<div class="article-summary-box-inner">
<span><p>We describe a class of tasks called decision-oriented dialogues, in which AI
assistants must collaborate with one or more humans via natural language to
help them make complex decisions. We formalize three domains in which users
face everyday decisions: (1) choosing an assignment of reviewers to conference
papers, (2) planning a multi-step itinerary in a city, and (3) negotiating
travel plans for a group of friends. In each of these settings, AI assistants
and users have disparate abilities that they must combine to arrive at the best
decision: assistants can access and process large amounts of information, while
users have preferences and constraints external to the system. For each task,
we build a dialogue environment where agents receive a reward based on the
quality of the final decision they reach. Using these environments, we collect
human-human dialogues with humans playing the role of assistant. To compare how
current AI assistants communicate in these settings, we present baselines using
large language models in self-play. Finally, we highlight a number of
challenges models face in decision-oriented dialogues, ranging from efficient
communication to reasoning and optimization, and release our environments as a
testbed for future modeling work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards an Understanding and Explanation for Mixed-Initiative Artificial Scientific Text Detection. (arXiv:2304.05011v1 [cs.HC] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.05011">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have gained popularity in various fields for
their exceptional capability of generating human-like text. Their potential
misuse has raised social concerns about plagiarism in academic contexts.
However, effective artificial scientific text detection is a non-trivial task
due to several challenges, including 1) the lack of a clear understanding of
the differences between machine-generated and human-written scientific text, 2)
the poor generalization performance of existing methods caused by
out-of-distribution issues, and 3) the limited support for human-machine
collaboration with sufficient interpretability during the detection process. In
this paper, we first identify the critical distinctions between
machine-generated and human-written scientific text through a quantitative
experiment. Then, we propose a mixed-initiative workflow that combines human
experts' prior knowledge with machine intelligence, along with a visual
analytics prototype to facilitate efficient and trustworthy scientific text
detection. Finally, we demonstrate the effectiveness of our approach through
two case studies and a controlled user study with proficient researchers. We
also provide design implications for interactive artificial text detection
tools in high-stakes decision-making scenarios.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-06-02 23:12:20.310909813 UTC">2023-06-02 23:12:20 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>