<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-04-18T01:30:00Z">04-18</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Instructed Reinforcement Learning for Human-AI Coordination. (arXiv:2304.07297v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07297">
<div class="article-summary-box-inner">
<span><p>One of the fundamental quests of AI is to produce agents that coordinate well
with humans. This problem is challenging, especially in domains that lack high
quality human behavioral data, because multi-agent reinforcement learning (RL)
often converges to different equilibria from the ones that humans prefer. We
propose a novel framework, instructRL, that enables humans to specify what kind
of strategies they expect from their AI partners through natural language
instructions. We use pretrained large language models to generate a prior
policy conditioned on the human instruction and use the prior to regularize the
RL objective. This leads to the RL agent converging to equilibria that are
aligned with human preferences. We show that instructRL converges to human-like
policies that satisfy the given instructions in a proof-of-concept environment
as well as the challenging Hanabi benchmark. Finally, we show that knowing the
language instruction significantly boosts human-AI coordination performance in
human evaluations in Hanabi.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OpenAssistant Conversations -- Democratizing Large Language Model Alignment. (arXiv:2304.07327v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07327">
<div class="article-summary-box-inner">
<span><p>Aligning large language models (LLMs) with human preferences has proven to
drastically improve usability and has driven rapid adoption as demonstrated by
ChatGPT. Alignment techniques such as supervised fine-tuning (SFT) and
reinforcement learning from human feedback (RLHF) greatly reduce the required
skill and domain knowledge to effectively harness the capabilities of LLMs,
increasing their accessibility and utility across various domains. However,
state-of-the-art alignment techniques like RLHF rely on high-quality human
feedback data, which is expensive to create and often remains proprietary. In
an effort to democratize research on large-scale alignment, we release
OpenAssistant Conversations, a human-generated, human-annotated assistant-style
conversation corpus consisting of 161,443 messages distributed across 66,497
conversation trees, in 35 different languages, annotated with 461,292 quality
ratings. The corpus is a product of a worldwide crowd-sourcing effort involving
over 13,500 volunteers. To demonstrate the OpenAssistant Conversations
dataset's effectiveness, we present OpenAssistant, the first fully open-source
large-scale instruction-tuned model to be trained on human data. A preference
study revealed that OpenAssistant replies are comparably preferred to
GPT-3.5-turbo (ChatGPT) with a relative winrate of 48.3% vs. 51.7%
respectively. We release our code and data under fully permissive licenses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Self-Perception and Political Biases of ChatGPT. (arXiv:2304.07333v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07333">
<div class="article-summary-box-inner">
<span><p>This contribution analyzes the self-perception and political biases of
OpenAI's Large Language Model ChatGPT. Taking into account the first
small-scale reports and studies that have emerged, claiming that ChatGPT is
politically biased towards progressive and libertarian points of view, this
contribution aims to provide further clarity on this subject. For this purpose,
ChatGPT was asked to answer the questions posed by the political compass test
as well as similar questionnaires that are specific to the respective politics
of the G7 member states. These eight tests were repeated ten times each and
revealed that ChatGPT seems to hold a bias towards progressive views. The
political compass test revealed a bias towards progressive and libertarian
views, with the average coordinates on the political compass being (-6.48,
-5.99) (with (0, 0) the center of the compass, i.e., centrism and the axes
ranging from -10 to 10), supporting the claims of prior research. The political
questionnaires for the G7 member states indicated a bias towards progressive
views but no significant bias between authoritarian and libertarian views,
contradicting the findings of prior reports, with the average coordinates being
(-3.27, 0.58). In addition, ChatGPT's Big Five personality traits were tested
using the OCEAN test and its personality type was queried using the
Myers-Briggs Type Indicator (MBTI) test. Finally, the maliciousness of ChatGPT
was evaluated using the Dark Factor test. These three tests were also repeated
ten times each, revealing that ChatGPT perceives itself as highly open and
agreeable, has the Myers-Briggs personality type ENFJ, and is among the 15% of
test-takers with the least pronounced dark traits.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-Shot Multi-Label Topic Inference with Sentence Encoders. (arXiv:2304.07382v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07382">
<div class="article-summary-box-inner">
<span><p>Sentence encoders have indeed been shown to achieve superior performances for
many downstream text-mining tasks and, thus, claimed to be fairly general.
Inspired by this, we performed a detailed study on how to leverage these
sentence encoders for the "zero-shot topic inference" task, where the topics
are defined/provided by the users in real-time. Extensive experiments on seven
different datasets demonstrate that Sentence-BERT demonstrates superior
generality compared to other encoders, while Universal Sentence Encoder can be
preferred when efficiency is a top priority.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Patient Pre-screening for Clinical Trials: Assisting Physicians with Large Language Models. (arXiv:2304.07396v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07396">
<div class="article-summary-box-inner">
<span><p>Physicians considering clinical trials for their patients are met with the
laborious process of checking many text based eligibility criteria. Large
Language Models (LLMs) have shown to perform well for clinical information
extraction and clinical reasoning, including medical tests, but not yet in
real-world scenarios. This paper investigates the use of InstructGPT to assist
physicians in determining eligibility for clinical trials based on a patient's
summarised medical profile. Using a prompting strategy combining one-shot,
selection-inference and chain-of-thought techniques, we investigate the
performance of LLMs on 10 synthetically created patient profiles. Performance
is evaluated at four levels: ability to identify screenable eligibility
criteria from a trial given a medical profile; ability to classify for each
individual criterion whether the patient qualifies; the overall classification
whether a patient is eligible for a clinical trial and the percentage of
criteria to be screened by physician. We evaluated against 146 clinical trials
and a total of 4,135 eligibility criteria. The LLM was able to correctly
identify the screenability of 72% (2,994/4,135) of the criteria. Additionally,
72% (341/471) of the screenable criteria were evaluated correctly. The
resulting trial level classification as eligible or ineligible resulted in a
recall of 0.5. By leveraging LLMs with a physician-in-the-loop, a recall of 1.0
and precision of 0.71 on clinical trial level can be achieved while reducing
the amount of criteria to be checked by an estimated 90%. LLMs can be used to
assist physicians with pre-screening of patients for clinical trials. By
forcing instruction-tuned LLMs to produce chain-of-thought responses, the
reasoning can be made transparent to and the decision process becomes amenable
by physicians, thereby making such a system feasible for use in real-world
scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Medical Question Summarization with Entity-driven Contrastive Learning. (arXiv:2304.07437v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07437">
<div class="article-summary-box-inner">
<span><p>By summarizing longer consumer health questions into shorter and essential
ones, medical question answering (MQA) systems can more accurately understand
consumer intentions and retrieve suitable answers. However, medical question
summarization is very challenging due to obvious distinctions in health trouble
descriptions from patients and doctors. Although existing works have attempted
to utilize Seq2Seq, reinforcement learning, or contrastive learning to solve
the problem, two challenges remain: how to correctly capture question focus to
model its semantic intention, and how to obtain reliable datasets to fairly
evaluate performance. To address these challenges, this paper proposes a novel
medical question summarization framework using entity-driven contrastive
learning (ECL). ECL employs medical entities in frequently asked questions
(FAQs) as focuses and devises an effective mechanism to generate hard negative
samples. This approach forces models to pay attention to the crucial focus
information and generate more ideal question summarization. Additionally, we
find that some MQA datasets suffer from serious data leakage problems, such as
the iCliniq dataset's 33% duplicate rate. To evaluate the related methods
fairly, this paper carefully checks leaked samples to reorganize more
reasonable datasets. Extensive experiments demonstrate that our ECL method
outperforms state-of-the-art methods by accurately capturing question focus and
generating medical question summaries. The code and datasets are available at
https://github.com/yrbobo/MQS-ECL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tractable Control for Autoregressive Language Generation. (arXiv:2304.07438v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07438">
<div class="article-summary-box-inner">
<span><p>Despite the success of autoregressive large language models in text
generation, it remains a major challenge to generate text that satisfies
complex constraints: sampling from the conditional distribution
$\Pr(\text{text} | \alpha)$ is intractable for even the simplest lexical
constraints $\alpha$. To overcome this challenge, we propose to use tractable
probabilistic models to impose lexical constraints in autoregressive text
generation, which we refer to as GeLaTo. To demonstrate the effectiveness of
this framework, we use distilled hidden Markov models to control autoregressive
generation from GPT2. GeLaTo achieves state-of-the-art performance on
CommonGen, a challenging benchmark for constrained text generation, beating a
wide range of strong baselines by a large margin. Our work not only opens up
new avenues for controlling large language models but also motivates the
development of more expressive tractable probabilistic models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Educational Dialogue Act Classifiers with Low-Resource and Imbalanced Datasets. (arXiv:2304.07499v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07499">
<div class="article-summary-box-inner">
<span><p>Dialogue acts (DAs) can represent conversational actions of tutors or
students that take place during tutoring dialogues. Automating the
identification of DAs in tutoring dialogues is significant to the design of
dialogue-based intelligent tutoring systems. Many prior studies employ machine
learning models to classify DAs in tutoring dialogues and invest much effort to
optimize the classification accuracy by using limited amounts of training data
(i.e., low-resource data scenario). However, beyond the classification
accuracy, the robustness of the classifier is also important, which can reflect
the capability of the classifier on learning the patterns from different class
distributions. We note that many prior studies on classifying educational DAs
employ cross entropy (CE) loss to optimize DA classifiers on low-resource data
with imbalanced DA distribution. The DA classifiers in these studies tend to
prioritize accuracy on the majority class at the expense of the minority class
which might not be robust to the data with imbalanced ratios of different DA
classes. To optimize the robustness of classifiers on imbalanced class
distributions, we propose to optimize the performance of the DA classifier by
maximizing the area under the ROC curve (AUC) score (i.e., AUC maximization).
Through extensive experiments, our study provides evidence that (i) by
maximizing AUC in the training process, the DA classifier achieves significant
performance improvement compared to the CE approach under low-resource data,
and (ii) AUC maximization approaches can improve the robustness of the DA
classifier under different class imbalance ratios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A CTC Alignment-based Non-autoregressive Transformer for End-to-end Automatic Speech Recognition. (arXiv:2304.07611v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07611">
<div class="article-summary-box-inner">
<span><p>Recently, end-to-end models have been widely used in automatic speech
recognition (ASR) systems. Two of the most representative approaches are
connectionist temporal classification (CTC) and attention-based encoder-decoder
(AED) models. Autoregressive transformers, variants of AED, adopt an
autoregressive mechanism for token generation and thus are relatively slow
during inference. In this paper, we present a comprehensive study of a CTC
Alignment-based Single-Step Non-Autoregressive Transformer (CASS-NAT) for
end-to-end ASR. In CASS-NAT, word embeddings in the autoregressive transformer
(AT) are substituted with token-level acoustic embeddings (TAE) that are
extracted from encoder outputs with the acoustical boundary information offered
by the CTC alignment. TAE can be obtained in parallel, resulting in a parallel
generation of output tokens. During training, Viterbi-alignment is used for TAE
generation, and multiple training strategies are further explored to improve
the word error rate (WER) performance. During inference, an error-based
alignment sampling method is investigated in depth to reduce the alignment
mismatch in the training and testing processes. Experimental results show that
the CASS-NAT has a WER that is close to AT on various ASR tasks, while
providing a ~24x inference speedup. With and without self-supervised learning,
we achieve new state-of-the-art results for non-autoregressive models on
several datasets. We also analyze the behavior of the CASS-NAT decoder to
explain why it can perform similarly to AT. We find that TAEs have similar
functionality to word embeddings for grammatical structures, which might
indicate the possibility of learning some semantic information from TAEs
without a language model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models. (arXiv:2304.07619v1 [q-fin.ST])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07619">
<div class="article-summary-box-inner">
<span><p>We examine the potential of ChatGPT, and other large language models, in
predicting stock market returns using sentiment analysis of news headlines. We
use ChatGPT to indicate whether a given headline is good, bad, or irrelevant
news for firms' stock prices. We then compute a numerical score and document a
positive correlation between these ``ChatGPT scores'' and subsequent daily
stock market returns. Further, ChatGPT outperforms traditional sentiment
analysis methods. We find that more basic models such as GPT-1, GPT-2, and BERT
cannot accurately forecast returns, indicating return predictability is an
emerging capacity of complex models. Our results suggest that incorporating
advanced language models into the investment decision-making process can yield
more accurate predictions and enhance the performance of quantitative trading
strategies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Approaches to Entity-Centric Information Extraction. (arXiv:2304.07625v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07625">
<div class="article-summary-box-inner">
<span><p>Artificial Intelligence (AI) has huge impact on our daily lives with
applications such as voice assistants, facial recognition, chatbots,
autonomously driving cars, etc. Natural Language Processing (NLP) is a
cross-discipline of AI and Linguistics, dedicated to study the understanding of
the text. This is a very challenging area due to unstructured nature of the
language, with many ambiguous and corner cases. In this thesis we address a
very specific area of NLP that involves the understanding of entities (e.g.,
names of people, organizations, locations) in text. First, we introduce a
radically different, entity-centric view of the information in text. We argue
that instead of using individual mentions in text to understand their meaning,
we should build applications that would work in terms of entity concepts. Next,
we present a more detailed model on how the entity-centric approach can be used
for the entity linking task. In our work, we show that this task can be
improved by considering performing entity linking at the coreference cluster
level rather than each of the mentions individually. In our next work, we
further study how information from Knowledge Base entities can be integrated
into text. Finally, we analyze the evolution of the entities from the evolving
temporal perspective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Out-of-Context Multimodal Misinformation with interpretable neural-symbolic model. (arXiv:2304.07633v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07633">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed the sustained evolution of misinformation that
aims at manipulating public opinions. Unlike traditional rumors or fake news
editors who mainly rely on generated and/or counterfeited images, text and
videos, current misinformation creators now more tend to use out-of-context
multimedia contents (e.g. mismatched images and captions) to deceive the public
and fake news detection systems. This new type of misinformation increases the
difficulty of not only detection but also clarification, because every
individual modality is close enough to true information. To address this
challenge, in this paper we explore how to achieve interpretable cross-modal
de-contextualization detection that simultaneously identifies the mismatched
pairs and the cross-modal contradictions, which is helpful for fact-check
websites to document clarifications. The proposed model first symbolically
disassembles the text-modality information to a set of fact queries based on
the Abstract Meaning Representation of the caption and then forwards the
query-image pairs into a pre-trained large vision-language model select the
``evidences" that are helpful for us to detect misinformation. Extensive
experiments indicate that the proposed methodology can provide us with much
more interpretable predictions while maintaining the accuracy same as the
state-of-the-art model on this task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TransDocs: Optical Character Recognition with word to word translation. (arXiv:2304.07637v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07637">
<div class="article-summary-box-inner">
<span><p>While OCR has been used in various applications, its output is not always
accurate, leading to misfit words. This research work focuses on improving the
optical character recognition (OCR) with ML techniques with integration of OCR
with long short-term memory (LSTM) based sequence to sequence deep learning
models to perform document translation. This work is based on ANKI dataset for
English to Spanish translation. In this work, I have shown comparative study
for pre-trained OCR while using deep learning model using LSTM-based seq2seq
architecture with attention for machine translation. End-to-end performance of
the model has been expressed in BLEU-4 score. This research paper is aimed at
researchers and practitioners interested in OCR and its applications in
document translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ArguGPT: evaluating, understanding and identifying argumentative essays generated by GPT models. (arXiv:2304.07666v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07666">
<div class="article-summary-box-inner">
<span><p>AI generated content (AIGC) presents considerable challenge to educators
around the world. Instructors need to be able to detect such text generated by
large language models, either with the naked eye or with the help of some
tools. There is also growing need to understand the lexical, syntactic and
stylistic features of AIGC. To address these challenges in English language
teaching, we first present ArguGPT, a balanced corpus of 4,038 argumentative
essays generated by 7 GPT models in response to essay prompts from three
sources: (1) in-class or homework exercises, (2) TOEFL and (3) GRE writing
tasks. Machine-generated texts are paired with roughly equal number of
human-written essays with three score levels matched in essay prompts. We then
hire English instructors to distinguish machine essays from human ones. Results
show that when first exposed to machine-generated essays, the instructors only
have an accuracy of 61% in detecting them. But the number rises to 67% after
one round of minimal self-training. Next, we perform linguistic analyses of
these essays, which show that machines produce sentences with more complex
syntactic structures while human essays tend to be lexically more complex.
Finally, we test existing AIGC detectors and build our own detectors using SVMs
and RoBERTa. Results suggest that a RoBERTa fine-tuned with the training set of
ArguGPT achieves above 90% accuracy in both essay- and sentence-level
classification. To the best of our knowledge, this is the first comprehensive
analysis of argumentative essays produced by generative large language models.
Machine-authored essays in ArguGPT and our models will be made publicly
available at https://github.com/huhailinguist/ArguGPT
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MLRegTest: A Benchmark for the Machine Learning of Regular Languages. (arXiv:2304.07687v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07687">
<div class="article-summary-box-inner">
<span><p>Evaluating machine learning (ML) systems on their ability to learn known
classifiers allows fine-grained examination of the patterns they can learn,
which builds confidence when they are applied to the learning of unknown
classifiers. This article presents a new benchmark for ML systems on sequence
classification called MLRegTest, which contains training, development, and test
sets from 1,800 regular languages.
</p>
<p>Different kinds of formal languages represent different kinds of
long-distance dependencies, and correctly identifying long-distance
dependencies in sequences is a known challenge for ML systems to generalize
successfully. MLRegTest organizes its languages according to their logical
complexity (monadic second order, first order, propositional, or monomial
expressions) and the kind of logical literals (string, tier-string,
subsequence, or combinations thereof). The logical complexity and choice of
literal provides a systematic way to understand different kinds of
long-distance dependencies in regular languages, and therefore to understand
the capacities of different ML systems to learn such long-distance
dependencies.
</p>
<p>Finally, the performance of different neural networks (simple RNN, LSTM, GRU,
transformer) on MLRegTest is examined. The main conclusion is that their
performance depends significantly on the kind of test set, the class of
language, and the neural network architecture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">USNID: A Framework for Unsupervised and Semi-supervised New Intent Discovery. (arXiv:2304.07699v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07699">
<div class="article-summary-box-inner">
<span><p>New intent discovery is of great value to natural language processing,
allowing for a better understanding of user needs and providing friendly
services. However, most existing methods struggle to capture the complicated
semantics of discrete text representations when limited or no prior knowledge
of labeled data is available. To tackle this problem, we propose a novel
framework called USNID for unsupervised and semi-supervised new intent
discovery, which has three key technologies. First, it takes full use of
unsupervised or semi-supervised data to mine shallow semantic similarity
relations and provide well-initialized representations for clustering. Second,
it designs a centroid-guided clustering mechanism to address the issue of
cluster allocation inconsistency and provide high-quality self-supervised
targets for representation learning. Third, it captures high-level semantics in
unsupervised or semi-supervised data to discover fine-grained intent-wise
clusters by optimizing both cluster-level and instance-level objectives. We
also propose an effective method for estimating the cluster number in
open-world scenarios without knowing the number of new intents beforehand.
USNID performs exceptionally well on several intent benchmark datasets,
achieving new state-of-the-art results in unsupervised and semi-supervised new
intent discovery and demonstrating robust performance with different cluster
numbers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Canvas: End-to-End Kernel Architecture Search in Neural Networks. (arXiv:2304.07741v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07741">
<div class="article-summary-box-inner">
<span><p>The demands for higher performance and accuracy in neural networks (NNs)
never end. Existing tensor compilation and Neural Architecture Search (NAS)
techniques orthogonally optimize the two goals but actually share many
similarities in their concrete strategies. We exploit such opportunities by
combining the two into one and make a case for Kernel Architecture Search
(KAS). KAS reviews NAS from a system perspective and zooms into a more
fine-grained level to generate neural kernels with both high performance and
good accuracy. To demonstrate the potential of KAS, we build an end-to-end
framework, Canvas, to find high-quality kernels as convolution replacements.
Canvas samples from a rich set of fine-grained primitives to stochastically and
iteratively construct new kernels and evaluate them according to user-specified
constraints. Canvas supports freely adjustable tensor dimension sizes inside
the kernel and uses two levels of solvers to satisfy structural legality and
fully utilize model budgets. The evaluation shows that by replacing standard
convolutions with generated new kernels in common NNs, Canvas achieves average
1.5x speedups compared to the previous state-of-the-art with acceptable
accuracy loss and search efficiency. Canvas verifies the practicability of KAS
by rediscovering many manually designed kernels in the past and producing new
structures that may inspire future machine learning innovations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MisRoB{\AE}RTa: Transformers versus Misinformation. (arXiv:2304.07759v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07759">
<div class="article-summary-box-inner">
<span><p>Misinformation is considered a threat to our democratic values and
principles. The spread of such content on social media polarizes society and
undermines public discourse by distorting public perceptions and generating
social unrest while lacking the rigor of traditional journalism. Transformers
and transfer learning proved to be state-of-the-art methods for multiple
well-known natural language processing tasks. In this paper, we propose
MisRoB{\AE}RTa, a novel transformer-based deep neural ensemble architecture for
misinformation detection. MisRoB{\AE}RTa takes advantage of two transformers
(BART \&amp; RoBERTa) to improve the classification performance. We also
benchmarked and evaluated the performances of multiple transformers on the task
of misinformation detection. For training and testing, we used a large
real-world news articles dataset labeled with 10 classes, addressing two
shortcomings in the current research: increasing the size of the dataset from
small to large, and moving the focus of fake news detection from binary
classification to multi-class classification. For this dataset, we manually
verified the content of the news articles to ensure that they were correctly
labeled. The experimental results show that the accuracy of transformers on the
misinformation detection problem was significantly influenced by the method
employed to learn the context, dataset size, and vocabulary dimension. We
observe empirically that the best accuracy performance among the classification
models that use only one transformer is obtained by BART, while DistilRoBERTa
obtains the best accuracy in the least amount of time required for fine-tuning
and training. The proposed MisRoB{\AE}RTa outperforms the other transformer
models in the task of misinformation detection. To arrive at this conclusion,
we performed ample ablation and sensitivity testing with MisRoB{\AE}RTa on two
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Evaluation of the Copy Mechanism for Natural Language to SPARQL Query Generation. (arXiv:2304.07772v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07772">
<div class="article-summary-box-inner">
<span><p>In recent years, the field of neural machine translation (NMT) for SPARQL
query generation has witnessed a significant growth. Recently, the
incorporation of the copy mechanism with traditional encoder-decoder
architectures and the use of pre-trained encoder-decoders have set new
performance benchmarks. This paper presents a large variety of experiments that
replicate and expand upon recent NMT-based SPARQL generation studies, comparing
pre-trained and non-pre-trained models, question annotation formats, and the
use of a copy mechanism for non-pre-trained and pre-trained models. Our results
show that either adding the copy mechanism or using a question annotation
improves performances for nonpre-trained models and for pre-trained models,
setting new baselines for three popular datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Syntactic Complexity Identification, Measurement, and Reduction Through Controlled Syntactic Simplification. (arXiv:2304.07774v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07774">
<div class="article-summary-box-inner">
<span><p>Text simplification is one of the domains in Natural Language Processing
(NLP) that offers an opportunity to understand the text in a simplified manner
for exploration. However, it is always hard to understand and retrieve
knowledge from unstructured text, which is usually in the form of compound and
complex sentences. There are state-of-the-art neural network-based methods to
simplify the sentences for improved readability while replacing words with
plain English substitutes and summarising the sentences and paragraphs. In the
Knowledge Graph (KG) creation process from unstructured text, summarising long
sentences and substituting words is undesirable since this may lead to
information loss. However, KG creation from text requires the extraction of all
possible facts (triples) with the same mentions as in the text. In this work,
we propose a controlled simplification based on the factual information in a
sentence, i.e., triple. We present a classical syntactic dependency-based
approach to split and rephrase a compound and complex sentence into a set of
simplified sentences. This simplification process will retain the original
wording with a simple structure of possible domain facts in each sentence,
i.e., triples. The paper also introduces an algorithm to identify and measure a
sentence's syntactic complexity (SC), followed by reduction through a
controlled syntactic simplification process. Last, an experiment for a dataset
re-annotation is also conducted through GPT3; we aim to publish this refined
corpus as a resource. This work is accepted and presented in International
workshop on Learning with Knowledge Graphs (IWLKG) at WSDM-2023 Conference. The
code and data is available at www.github.com/sallmanm/SynSim.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SikuGPT: A Generative Pre-trained Model for Intelligent Information Processing of Ancient Texts from the Perspective of Digital Humanities. (arXiv:2304.07778v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07778">
<div class="article-summary-box-inner">
<span><p>The rapid advance in artificial intelligence technology has facilitated the
prosperity of digital humanities research. Against such backdrop, research
methods need to be transformed in the intelligent processing of ancient texts,
which is a crucial component of digital humanities research, so as to adapt to
new development trends in the wave of AIGC. In this study, we propose a GPT
model called SikuGPT based on the corpus of Siku Quanshu. The model's
performance in tasks such as intralingual translation and text classification
exceeds that of other GPT-type models aimed at processing ancient texts.
SikuGPT's ability to process traditional Chinese ancient texts can help promote
the organization of ancient information and knowledge services, as well as the
international dissemination of Chinese ancient culture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">It's All in the Embedding! Fake News Detection Using Document Embeddings. (arXiv:2304.07781v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07781">
<div class="article-summary-box-inner">
<span><p>With the current shift in the mass media landscape from journalistic rigor to
social media, personalized social media is becoming the new norm. Although the
digitalization progress of the media brings many advantages, it also increases
the risk of spreading disinformation, misinformation, and malformation through
the use of fake news. The emergence of this harmful phenomenon has managed to
polarize society and manipulate public opinion on particular topics, e.g.,
elections, vaccinations, etc. Such information propagated on social media can
distort public perceptions and generate social unrest while lacking the rigor
of traditional journalism. Natural Language Processing and Machine Learning
techniques are essential for developing efficient tools that can detect fake
news. Models that use the context of textual data are essential for resolving
the fake news detection problem, as they manage to encode linguistic features
within the vector representation of words. In this paper, we propose a new
approach that uses document embeddings to build multiple models that accurately
label news articles as reliable or fake. We also present a benchmark on
different architectures that detect fake news using binary or multi-labeled
classification. We evaluated the models on five large news corpora using
accuracy, precision, and recall. We obtained better results than more complex
state-of-the-art Deep Neural Network models. We observe that the most important
factor for obtaining high accuracy is the document encoding, not the
classification model's complexity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EasyNER: A Customizable Easy-to-Use Pipeline for Deep Learning- and Dictionary-based Named Entity Recognition from Medical Text. (arXiv:2304.07805v1 [q-bio.QM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07805">
<div class="article-summary-box-inner">
<span><p>Medical research generates a large number of publications with the PubMed
database already containing &gt;35 million research articles. Integration of the
knowledge scattered across this large body of literature could provide key
insights into physiological mechanisms and disease processes leading to novel
medical interventions. However, it is a great challenge for researchers to
utilize this information in full since the scale and complexity of the data
greatly surpasses human processing abilities. This becomes especially
problematic in cases of extreme urgency like the COVID-19 pandemic. Automated
text mining can help extract and connect information from the large body of
medical research articles. The first step in text mining is typically the
identification of specific classes of keywords (e.g., all protein or disease
names), so called Named Entity Recognition (NER). Here we present an end-to-end
pipeline for NER of typical entities found in medical research articles,
including diseases, cells, chemicals, genes/proteins, and species. The pipeline
can access and process large medical research article collections (PubMed,
CORD-19) or raw text and incorporates a series of deep learning models
fine-tuned on the HUNER corpora collection. In addition, the pipeline can
perform dictionary-based NER related to COVID-19 and other medical topics.
Users can also load their own NER models and dictionaries to include additional
entities. The output consists of publication-ready ranked lists and graphs of
detected entities and files containing the annotated texts. An associated
script allows rapid inspection of the results for specific entities of
interest. As model use cases, the pipeline was deployed on two collections of
autophagy-related abstracts from PubMed and on the CORD19 dataset, a collection
of 764 398 research article abstracts related to COVID-19.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping. (arXiv:2304.07810v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07810">
<div class="article-summary-box-inner">
<span><p>In argumentative writing, writers must brainstorm hierarchical writing goals,
ensure the persuasiveness of their arguments, and revise and organize their
plans through drafting. Recent advances in large language models (LLMs) have
made interactive text generation through a chat interface (e.g., ChatGPT)
possible. However, this approach often neglects implicit writing context and
user intent, lacks support for user control and autonomy, and provides limited
assistance for sensemaking and revising writing plans. To address these
challenges, we introduce VISAR, an AI-enabled writing assistant system designed
to help writers brainstorm and revise hierarchical goals within their writing
context, organize argument structures through synchronized text editing and
visual programming, and enhance persuasiveness with argumentation spark
recommendations. VISAR allows users to explore, experiment with, and validate
their writing plans using automatic draft prototyping. A controlled lab study
confirmed the usability and effectiveness of VISAR in facilitating the
argumentative writing planning process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How does ChatGPT rate sound semantics?. (arXiv:2304.07830v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07830">
<div class="article-summary-box-inner">
<span><p>Semantic dimensions of sound have been playing a central role in
understanding the nature of auditory sensory experience as well as the broader
relation between perception, language, and meaning. Accordingly, and given the
recent proliferation of large language models (LLMs), here we asked whether
such models exhibit an organisation of perceptual semantics similar to those
observed in humans. Specifically, we prompted ChatGPT, a chatbot based on a
state-of-the-art LLM, to rate musical instrument sounds on a set of 20 semantic
scales. We elicited multiple responses in separate chats, analogous to having
multiple human raters. ChatGPT generated semantic profiles that only partially
correlated with human ratings, yet showed robust agreement along well-known
psychophysical dimensions of musical sounds such as brightness (bright-dark)
and pitch height (deep-high). Exploratory factor analysis suggested the same
dimensionality but different spatial configuration of a latent factor space
between the chatbot and human ratings. Unexpectedly, the chatbot showed degrees
of internal variability that were comparable in magnitude to that of human
ratings. Our work highlights the potential of LLMs to capture salient
dimensions of human sensory experience.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatPLUG: Open-Domain Generative Dialogue System with Internet-Augmented Instruction Tuning for Digital Human. (arXiv:2304.07849v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07849">
<div class="article-summary-box-inner">
<span><p>In this paper, we present ChatPLUG, a Chinese open-domain dialogue system for
digital human applications that instruction finetunes on a wide range of
dialogue tasks in a unified internet-augmented format. Different from other
open-domain dialogue models that focus on large-scale pre-training and scaling
up model size or dialogue corpus, we aim to build a powerful and practical
dialogue system for digital human with diverse skills and good multi-task
generalization by internet-augmented instruction tuning. To this end, we first
conduct large-scale pre-training on both common document corpus and dialogue
data with curriculum learning, so as to inject various world knowledge and
dialogue abilities into ChatPLUG. Then, we collect a wide range of dialogue
tasks spanning diverse features of knowledge, personality, multi-turn memory,
and empathy, on which we further instruction tune \modelname via unified
natural language instruction templates. External knowledge from an internet
search is also used during instruction finetuning for alleviating the problem
of knowledge hallucinations. We show that \modelname outperforms
state-of-the-art Chinese dialogue systems on both automatic and human
evaluation, and demonstrates strong multi-task generalization on a variety of
text understanding and generation tasks. In addition, we deploy \modelname to
real-world applications such as Smart Speaker and Instant Message applications
with fast inference. Our models and code will be made publicly available on
ModelScope~\footnote{\small{https://modelscope.cn/models/damo/ChatPLUG-3.7B}}
and Github~\footnote{\small{https://github.com/X-PLUG/ChatPLUG}}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Better Instruction Following Language Models for Chinese: Investigating the Impact of Training Data and Evaluation. (arXiv:2304.07854v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07854">
<div class="article-summary-box-inner">
<span><p>Recently, significant public efforts have been directed towards developing
low-cost models with capabilities akin to ChatGPT, thereby fostering the growth
of open-source conversational models. However, there remains a scarcity of
comprehensive and in-depth evaluations of these models' performance. In this
study, we examine the influence of training data factors, including quantity,
quality, and linguistic distribution, on model performance. Our analysis is
grounded in several publicly accessible, high-quality instruction datasets, as
well as our own Chinese multi-turn conversations. We assess various models
using a evaluation set of 1,000 samples, encompassing nine real-world
scenarios. Our goal is to supplement manual evaluations with quantitative
analyses, offering valuable insights for the continued advancement of
open-source chat models. Furthermore, to enhance the performance and training
and inference efficiency of models in the Chinese domain, we extend the
vocabulary of LLaMA - the model with the closest open-source performance to
proprietary language models like GPT-3 - and conduct secondary pre-training on
3.4B Chinese words. We make our model, data, as well as code publicly
available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Machine Translation For Low Resource Languages. (arXiv:2304.07869v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07869">
<div class="article-summary-box-inner">
<span><p>Neural Machine translation is a challenging task due to the inherent complex
nature and the fluidity that natural languages bring. Nonetheless, in recent
years, it has achieved state-of-the-art performance in several language pairs.
Although, a lot of traction can be seen in the areas of multilingual neural
machine translation (MNMT) in the recent years, there are no comprehensive
survey done to identify what approaches work well. The goal of this project is
to investigate the realm of low resource languages and build a Neural Machine
Translation model to achieve state-of-the-art results. The project looks to
build upon the \texttt{mBART.CC25} \cite{liu2020multilingual} language model
and explore strategies to augment it with various NLP and Deep Learning
techniques like back translation and transfer learning. This implementation
tries to unpack the architecture of the NMT application and determine the
different components which offers us opportunities to amend the said
application within the purview of the low resource languages problem space.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey on Publicly Available Sinhala Natural Language Processing Tools and Research. (arXiv:1906.02358v18 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.02358">
<div class="article-summary-box-inner">
<span><p>Sinhala is the native language of the Sinhalese people who make up the
largest ethnic group of Sri Lanka. The language belongs to the globe-spanning
language tree, Indo-European. However, due to poverty in both linguistic and
economic capital, Sinhala, in the perspective of Natural Language Processing
tools and research, remains a resource-poor language which has neither the
economic drive its cousin English has nor the sheer push of the law of numbers
a language such as Chinese has. A number of research groups from Sri Lanka have
noticed this dearth and the resultant dire need for proper tools and research
for Sinhala natural language processing. However, due to various reasons, these
attempts seem to lack coordination and awareness of each other. The objective
of this paper is to fill that gap of a comprehensive literature survey of the
publicly available Sinhala natural language tools and research so that the
researchers working in this field can better utilize contributions of their
peers. As such, we shall be uploading this paper to arXiv and perpetually
update it periodically to reflect the advances made in the field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeliData: A dataset for deliberation in multi-party problem solving. (arXiv:2108.05271v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05271">
<div class="article-summary-box-inner">
<span><p>Group deliberation enables people to collaborate and solve problems, however,
it is understudied due to a lack of resources. To this end, we introduce the
first publicly available dataset containing collaborative conversations on
solving a well-established cognitive task, consisting of 500 group dialogues
and 14k utterances. In 64% of these conversations, the group members are able
to find a better solution than they had identified individually, and in 43.8%
of the groups who had a correct answer as their final solution, none of the
participants had solved the task correctly by themselves. Furthermore, we
propose a novel annotation schema that captures deliberation cues and release
all 14k utterances annotated with it. Finally, we use the proposed dataset to
develop and evaluate two methods for generating deliberation utterances. The
data collection platform, dataset and annotated corpus are publicly available
at https://delibot.xyz.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified Instance and Knowledge Alignment Pretraining for Aspect-based Sentiment Analysis. (arXiv:2110.13398v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13398">
<div class="article-summary-box-inner">
<span><p>Aspect-based Sentiment Analysis (ABSA) aims to determine the sentiment
polarity towards an aspect. Because of the expensive and limited labelled data,
the pretraining strategy has become the de-facto standard for ABSA. However,
there always exists severe domain shift between the pretraining and downstream
ABSA datasets, hindering the effective knowledge transfer when directly
finetuning and making the downstream task performs sub-optimal. To mitigate
such domain shift, we introduce a unified alignment pretraining framework into
the vanilla pretrain-finetune pipeline with both instance- and knowledge-level
alignments. Specifically, we first devise a novel coarse-to-fine retrieval
sampling approach to select target domain-related instances from the
large-scale pretraining dataset, thus aligning the instances between
pretraining and target domains (First Stage). Then, we introduce a knowledge
guidance-based strategy to further bridge the domain gap at the knowledge
level. In practice, we formulate the model pretrained on the sampled instances
into a knowledge guidance model and a learner model, respectively. On the
target dataset, we design an on-the-fly teacher-student joint fine-tuning
approach to progressively transfer the knowledge from the knowledge guidance
model to the learner model (Second Stage). Thereby, the learner model can
maintain more domain-invariant knowledge when learning new knowledge from the
target dataset. In the Third Stage, the learner model is finetuned to better
adapt its learned knowledge to the target dataset. Extensive experiments and
analyses on several ABSA benchmarks demonstrate the effectiveness and
universality of our proposed pretraining framework. Our source code and models
are publicly available at https://github.com/WHU-ZQH/UIKA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TraVLR: Now You See It, Now You Don't! A Bimodal Dataset for Evaluating Visio-Linguistic Reasoning. (arXiv:2111.10756v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.10756">
<div class="article-summary-box-inner">
<span><p>Numerous visio-linguistic (V+L) representation learning methods have been
developed, yet existing datasets do not adequately evaluate the extent to which
they represent visual and linguistic concepts in a unified space. We propose
several novel evaluation settings for V+L models, including cross-modal
transfer. Furthermore, existing V+L benchmarks often report global accuracy
scores on the entire dataset, making it difficult to pinpoint the specific
reasoning tasks that models fail and succeed at. We present TraVLR, a synthetic
dataset comprising four V+L reasoning tasks. TraVLR's synthetic nature allows
us to constrain its training and testing distributions along task-relevant
dimensions, enabling the evaluation of out-of-distribution generalisation. Each
example in TraVLR redundantly encodes the scene in two modalities, allowing
either to be dropped or added during training or testing without losing
relevant information. We compare the performance of four state-of-the-art V+L
models, finding that while they perform well on test examples from the same
modality, they all fail at cross-modal transfer and have limited success
accommodating the addition or deletion of one modality. We release TraVLR as an
open challenge for the research community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Least-to-Most Prompting Enables Complex Reasoning in Large Language Models. (arXiv:2205.10625v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10625">
<div class="article-summary-box-inner">
<span><p>Chain-of-thought prompting has demonstrated remarkable performance on various
natural language reasoning tasks. However, it tends to perform poorly on tasks
which requires solving problems harder than the exemplars shown in the prompts.
To overcome this challenge of easy-to-hard generalization, we propose a novel
prompting strategy, least-to-most prompting. The key idea in this strategy is
to break down a complex problem into a series of simpler subproblems and then
solve them in sequence. Solving each subproblem is facilitated by the answers
to previously solved subproblems. Our experimental results on tasks related to
symbolic manipulation, compositional generalization, and math reasoning reveal
that least-to-most prompting is capable of generalizing to more difficult
problems than those seen in the prompts. A notable finding is that when the
GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve
the compositional generalization benchmark SCAN in any split (including length
split) with an accuracy of at least 99% using just 14 exemplars, compared to
only 16% accuracy with chain-of-thought prompting. This is particularly
noteworthy because neural-symbolic models in the literature that specialize in
solving SCAN are trained on the entire training set containing over 15,000
examples. We have included prompts for all the tasks in the Appendix.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models. (arXiv:2206.09557v3 [cs.DC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09557">
<div class="article-summary-box-inner">
<span><p>The recent advancements in self-supervised learning, combined with the
Transformer architecture, have enabled natural language processing (NLP) to
achieve remarkably low perplexity. However, powerful NLP models necessitate
increasing model size, leading to substantial computational and memory
requirements. In this paper, we introduce an efficient inference framework
tailored for large-scale generative language models. To reduce the model size,
we employ a weight-only quantization strategy while preserving full precision
for activations. As a result, we attain sub-4-bit quantization for each weight
through non-uniform or uniform quantization techniques. Our proposed kernel,
called LUT-GEMM, then accelerates quantized matrix multiplications, offering a
flexible balance between compression ratio and accuracy. Unlike earlier matrix
multiplication kernels that accommodated weight-only quantization, LUT-GEMM
efficiently eliminates the resource-demanding dequantization process for both
uniform and non-uniform quantization methods. By reducing the latency of
individual GPUs and the overall inference process for large-scale language
models, LUT-GEMM provides significant performance improvements in inference.
The impact of LUT-GEMM is facilitated by implementing high compression ratios
through low-bit quantization and efficient LUT-based operations, which
decreases the number of required GPUs. For the OPT-175B model with 3-bit
quantization, we show that LUT-GEMM accelerates the latency for generating each
token by 2.1x compared to OPTQ, which requires costly dequantization.
Consequently, LUT-GEMM enables inference of the OPT-175B model on a single GPU
without noticeable degradation in accuracy or performance, while the
non-quantized OPT-175B model requires a minimum of 8 GPUs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Two-Tailed Averaging: Anytime, Adaptive, Once-in-a-While Optimal Weight Averaging for Better Generalization. (arXiv:2209.12581v3 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.12581">
<div class="article-summary-box-inner">
<span><p>Tail Averaging improves on Polyak averaging's non-asymptotic behaviour by
excluding a number of leading iterates of stochastic optimization from its
calculations. In practice, with a finite number of optimization steps and a
learning rate that cannot be annealed to zero, Tail Averaging can get much
closer to a local minimum point of the training loss than either the individual
iterates or the Polyak average. However, the number of leading iterates to
ignore is an important hyperparameter, and starting averaging too early or too
late leads to inefficient use of resources or suboptimal solutions. Our work
focusses on improving generalization, which makes setting this hyperparameter
even more difficult, especially in the presence of other hyperparameters and
overfitting. Furthermore, before averaging starts, the loss is only weakly
informative of the final performance, which makes early stopping unreliable. To
alleviate these problems, we propose an anytime variant of Tail Averaging
intended for improving generalization not pure optimization, that has no
hyperparameters and approximates the optimal tail at all optimization steps.
Our algorithm is based on two running averages with adaptive lengths bounded in
terms of the optimal tail length, one of which achieves approximate optimality
with some regularity. Requiring only the additional storage for two sets of
weights and periodic evaluation of the loss, the proposed Two-Tailed Averaging
algorithm is a practical and widely applicable method for improving
generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DecAF: Joint Decoding of Answers and Logical Forms for Question Answering over Knowledge Bases. (arXiv:2210.00063v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.00063">
<div class="article-summary-box-inner">
<span><p>Question answering over knowledge bases (KBs) aims to answer natural language
questions with factual information such as entities and relations in KBs.
Previous methods either generate logical forms that can be executed over KBs to
obtain final answers or predict answers directly. Empirical results show that
the former often produces more accurate answers, but it suffers from
non-execution issues due to potential syntactic and semantic errors in the
generated logical forms. In this work, we propose a novel framework DecAF that
jointly generates both logical forms and direct answers, and then combines the
merits of them to get the final answers. Moreover, different from most of the
previous methods, DecAF is based on simple free-text retrieval without relying
on any entity linking tools -- this simplification eases its adaptation to
different datasets. DecAF achieves new state-of-the-art accuracy on WebQSP,
FreebaseQA, and GrailQA benchmarks, while getting competitive results on the
ComplexWebQuestions benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Path: Scaling Vision-and-Language Navigation with Synthetic Instructions and Imitation Learning. (arXiv:2210.03112v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.03112">
<div class="article-summary-box-inner">
<span><p>Recent studies in Vision-and-Language Navigation (VLN) train RL agents to
execute natural-language navigation instructions in photorealistic
environments, as a step towards robots that can follow human instructions.
However, given the scarcity of human instruction data and limited diversity in
the training environments, these agents still struggle with complex language
grounding and spatial language understanding. Pretraining on large text and
image-text datasets from the web has been extensively explored but the
improvements are limited. We investigate large-scale augmentation with
synthetic instructions. We take 500+ indoor environments captured in
densely-sampled 360 degree panoramas, construct navigation trajectories through
these panoramas, and generate a visually-grounded instruction for each
trajectory using Marky, a high-quality multilingual navigation instruction
generator. We also synthesize image observations from novel viewpoints using an
image-to-image GAN. The resulting dataset of 4.2M instruction-trajectory pairs
is two orders of magnitude larger than existing human-annotated datasets, and
contains a wider variety of environments and viewpoints. To efficiently
leverage data at this scale, we train a simple transformer agent with imitation
learning. On the challenging RxR dataset, our approach outperforms all existing
RL agents, improving the state-of-the-art NDTW from 71.1 to 79.1 in seen
environments, and from 64.6 to 66.8 in unseen test environments. Our work
points to a new path to improving instruction-following agents, emphasizing
large-scale imitation learning and the development of synthetic instruction
generation capabilities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Schema-aware Reference as Prompt Improves Data-Efficient Knowledge Graph Construction. (arXiv:2210.10709v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10709">
<div class="article-summary-box-inner">
<span><p>With the development of pre-trained language models, many prompt-based
approaches to data-efficient knowledge graph construction have been proposed
and achieved impressive performance. However, existing prompt-based learning
methods for knowledge graph construction are still susceptible to several
potential limitations: (i) semantic gap between natural language and output
structured knowledge with pre-defined schema, which means model cannot fully
exploit semantic knowledge with the constrained templates; (ii) representation
learning with locally individual instances limits the performance given the
insufficient features, which are unable to unleash the potential analogical
capability of pre-trained language models. Motivated by these observations, we
propose a retrieval-augmented approach, which retrieves schema-aware Reference
As Prompt (RAP), for data-efficient knowledge graph construction. It can
dynamically leverage schema and knowledge inherited from human-annotated and
weak-supervised data as a prompt for each sample, which is model-agnostic and
can be plugged into widespread existing approaches. Experimental results
demonstrate that previous methods integrated with RAP can achieve impressive
performance gains in low-resource settings on five datasets of relational
triple extraction and event extraction for knowledge graph construction. Code
is available in https://github.com/zjunlp/RAP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling structure-building in the brain with CCG parsing and large language models. (arXiv:2210.16147v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.16147">
<div class="article-summary-box-inner">
<span><p>To model behavioral and neural correlates of language comprehension in
naturalistic environments researchers have turned to broad-coverage tools from
natural-language processing and machine learning. Where syntactic structure is
explicitly modeled, prior work has relied predominantly on context-free
grammars (CFG), yet such formalisms are not sufficiently expressive for human
languages. Combinatory Categorial Grammars (CCGs) are sufficiently expressive
directly compositional models of grammar with flexible constituency that
affords incremental interpretation. In this work we evaluate whether a more
expressive CCG provides a better model than a CFG for human neural signals
collected with fMRI while participants listen to an audiobook story. We further
test between variants of CCG that differ in how they handle optional adjuncts.
These evaluations are carried out against a baseline that includes estimates of
next-word predictability from a Transformer neural network language model. Such
a comparison reveals unique contributions of CCG structure-building
predominantly in the left posterior temporal lobe: CCG-derived measures offer a
superior fit to neural signals compared to those derived from a CFG. These
effects are spatially distinct from bilateral superior temporal effects that
are unique to predictability. Neural effects for structure-building are thus
separable from predictability during naturalistic listening, and those effects
are best characterized by a grammar whose expressive power is motivated on
independent linguistic grounds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficiently Trained Low-Resource Mongolian Text-to-Speech System Based On FullConv-TTS. (arXiv:2211.01948v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.01948">
<div class="article-summary-box-inner">
<span><p>Recurrent Neural Networks (RNNs) have become the standard modeling technique
for sequence data, and are used in a number of novel text-to-speech models.
However, training a TTS model including RNN components has certain requirements
for GPU performance and takes a long time. In contrast, studies have shown that
CNN-based sequence synthesis technology can greatly reduce training time in
text-to-speech models while ensuring a certain performance due to its high
parallelism. We propose a new text-to-speech system based on deep convolutional
neural networks that does not employ any RNN components (recurrent units). At
the same time, we improve the generality and robustness of our model through a
series of data augmentation methods such as Time Warping, Frequency Mask, and
Time Mask. The final experimental results show that the TTS model using only
the CNN component can reduce the training time compared to the classic TTS
models such as Tacotron while ensuring the quality of the synthesized speech.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VaxxHesitancy: A Dataset for Studying Hesitancy towards COVID-19 Vaccination on Twitter. (arXiv:2301.06660v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.06660">
<div class="article-summary-box-inner">
<span><p>Vaccine hesitancy has been a common concern, probably since vaccines were
created and, with the popularisation of social media, people started to express
their concerns about vaccines online alongside those posting pro- and
anti-vaccine content. Predictably, since the first mentions of a COVID-19
vaccine, social media users posted about their fears and concerns or about
their support and belief into the effectiveness of these rapidly developing
vaccines. Identifying and understanding the reasons behind public hesitancy
towards COVID-19 vaccines is important for policy markers that need to develop
actions to better inform the population with the aim of increasing vaccine
take-up. In the case of COVID-19, where the fast development of the vaccines
was mirrored closely by growth in anti-vaxx disinformation, automatic means of
detecting citizen attitudes towards vaccination became necessary. This is an
important computational social sciences task that requires data analysis in
order to gain in-depth understanding of the phenomena at hand. Annotated data
is also necessary for training data-driven models for more nuanced analysis of
attitudes towards vaccination. To this end, we created a new collection of over
3,101 tweets annotated with users' attitudes towards COVID-19 vaccination
(stance). Besides, we also develop a domain-specific language model (VaxxBERT)
that achieves the best predictive performance (73.0 accuracy and 69.3 F1-score)
as compared to a robust set of baselines. To the best of our knowledge, these
are the first dataset and model that model vaccine hesitancy as a category
distinct from pro- and anti-vaccine stance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GLIGEN: Open-Set Grounded Text-to-Image Generation. (arXiv:2301.07093v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07093">
<div class="article-summary-box-inner">
<span><p>Large-scale text-to-image diffusion models have made amazing advances.
However, the status quo is to use text input alone, which can impede
controllability. In this work, we propose GLIGEN, Grounded-Language-to-Image
Generation, a novel approach that builds upon and extends the functionality of
existing pre-trained text-to-image diffusion models by enabling them to also be
conditioned on grounding inputs. To preserve the vast concept knowledge of the
pre-trained model, we freeze all of its weights and inject the grounding
information into new trainable layers via a gated mechanism. Our model achieves
open-world grounded text2img generation with caption and bounding box condition
inputs, and the grounding ability generalizes well to novel spatial
configurations and concepts. GLIGEN's zero-shot performance on COCO and LVIS
outperforms that of existing supervised layout-to-image baselines by a large
margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is Multimodal Vision Supervision Beneficial to Language?. (arXiv:2302.05016v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05016">
<div class="article-summary-box-inner">
<span><p>Vision (image and video) - Language (VL) pre-training is the recent popular
paradigm that achieved state-of-the-art results on multi-modal tasks like
image-retrieval, video-retrieval, visual question answering etc. These models
are trained in an unsupervised way and greatly benefit from the complementary
modality supervision. In this paper, we explore if the language representations
trained using vision supervision perform better than vanilla language
representations on Natural Language Understanding and commonsense reasoning
benchmarks. We experiment with a diverse set of image-text models such as
ALBEF, BLIP, METER and video-text models like ALPRO, Frozen-in-Time (FiT),
VIOLET. We compare the performance of language representations of stand-alone
text encoders of these models to the language representations of text encoders
learnt through vision supervision. Our experiments suggest that vanilla
language representations show superior performance on most of the tasks. These
results shed light on the current drawbacks of the vision-language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Enhanced Semantic Communication Receiver. (arXiv:2302.07727v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07727">
<div class="article-summary-box-inner">
<span><p>In recent years, with the rapid development of deep learning and natural
language processing technologies, semantic communication has become a topic of
great interest in the field of communication. Although existing deep
learning-based semantic communication approaches have shown many advantages,
they still do not make sufficient use of prior knowledge. Moreover, most
existing semantic communication methods focus on the semantic encoding at the
transmitter side, while we believe that the semantic decoding capability of the
receiver should also be concerned. In this paper, we propose a knowledge
enhanced semantic communication framework in which the receiver can more
actively utilize the facts in the knowledge base for semantic reasoning and
decoding, on the basis of only affecting the parameters rather than the
structure of the neural networks at the transmitter side. Specifically, we
design a transformer-based knowledge extractor to find relevant factual triples
for the received noisy signal. Extensive simulation results on the WebNLG
dataset demonstrate that the proposed receiver yields superior performance on
top of the knowledge graph enhanced decoding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation. (arXiv:2302.09664v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.09664">
<div class="article-summary-box-inner">
<span><p>We introduce a method to measure uncertainty in large language models. For
tasks like question answering, it is essential to know when we can trust the
natural language outputs of foundation models. We show that measuring
uncertainty in natural language is challenging because of "semantic
equivalence" -- different sentences can mean the same thing. To overcome these
challenges we introduce semantic entropy -- an entropy which incorporates
linguistic invariances created by shared meanings. Our method is unsupervised,
uses only a single model, and requires no modifications to off-the-shelf
language models. In comprehensive ablation studies we show that the semantic
entropy is more predictive of model accuracy on question answering data sets
than comparable baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">E2E Spoken Entity Extraction for Virtual Agents. (arXiv:2302.10186v5 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10186">
<div class="article-summary-box-inner">
<span><p>This paper rethink some aspects of speech processing using speech encoders,
specifically about extracting entities directly from speech, without
intermediate textual representation. In human-computer conversations,
extracting entities such as names, street addresses and email addresses from
speech is a challenging task. In this paper, we study the impact of fine-tuning
pre-trained speech encoders on extracting spoken entities in human-readable
form directly from speech without the need for text transcription. We
illustrate that such a direct approach optimizes the encoder to transcribe only
the entity relevant portions of speech ignoring the superfluous portions such
as carrier phrases, or spell name entities. In the context of dialog from an
enterprise virtual agent, we demonstrate that the 1-step approach outperforms
the typical 2-step approach which first generates lexical transcriptions
followed by text-based entity extraction for identifying spoken entities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval. (arXiv:2303.03004v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.03004">
<div class="article-summary-box-inner">
<span><p>The ability to solve problems is a hallmark of intelligence and has been an
enduring goal in AI. AI systems that can create programs as solutions to
problems or assist developers in writing programs can increase productivity and
make programming more accessible. Recently, pre-trained large language models
have shown impressive abilities in generating new codes from natural language
descriptions, repairing buggy codes, translating codes between languages, and
retrieving relevant code segments. However, the evaluation of these models has
often been performed in a scattered way on only one or two specific tasks, in a
few languages, at a partial granularity (e.g., function) level and in many
cases without proper training data. Even more concerning is that in most cases
the evaluation of generated codes has been done in terms of mere lexical
overlap rather than actual execution whereas semantic similarity (or
equivalence) of two code segments depends only on their ``execution
similarity'', i.e., being able to get the same output for a given input.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disambiguation of Company names via Deep Recurrent Networks. (arXiv:2303.05391v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.05391">
<div class="article-summary-box-inner">
<span><p>Name Entity Disambiguation is the Natural Language Processing task of
identifying textual records corresponding to the same Named Entity, i.e.
real-world entities represented as a list of attributes (names, places,
organisations, etc.). In this work, we face the task of disambiguating
companies on the basis of their written names. We propose a Siamese LSTM
Network approach to extract -- via supervised learning -- an embedding of
company name strings in a (relatively) low dimensional vector space and use
this representation to identify pairs of company names that actually represent
the same company (i.e. the same Entity).
</p>
<p>Given that the manual labelling of string pairs is a rather onerous task, we
analyse how an Active Learning approach to prioritise the samples to be
labelled leads to a more efficient overall learning pipeline.
</p>
<p>With empirical investigations, we show that our proposed Siamese Network
outperforms several benchmark approaches based on standard string matching
algorithms when enough labelled data are available. Moreover, we show that
Active Learning prioritisation is indeed helpful when labelling resources are
limited, and let the learning models reach the out-of-sample performance
saturation with less labelled data with respect to standard (random) data
labelling approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Can Be Used to Scale the Ideologies of Politicians in a Zero-Shot Learning Setting. (arXiv:2303.12057v3 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.12057">
<div class="article-summary-box-inner">
<span><p>The aggregation of knowledge embedded in large language models (LLMs) holds
the promise of new solutions to problems of observability and measurement in
the social sciences. We examine this potential in a challenging setting:
measuring latent ideology -- crucial for better understanding core political
functions such as democratic representation. We scale pairwise
liberal-conservative comparisons between members of the 116th U.S. Senate using
prompts made to ChatGPT. Our measure strongly correlates with widely used
liberal-conservative scales such as DW-NOMINATE. Our scale also has
interpretative advantages, such as not placing senators who vote against their
party for ideologically extreme reasons towards the middle. Our measure is more
strongly associated with political activists' perceptions of senators than
other measures, consistent with LLMs synthesizing vast amounts of politically
relevant data from internet/book corpora rather than memorizing existing
measures. LLMs will likely open new avenues for measuring latent constructs
utilizing modeled information from massive text corpora.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Large Language Models. (arXiv:2303.18223v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18223">
<div class="article-summary-box-inner">
<span><p>Language is essentially a complex, intricate system of human expressions
governed by grammatical rules. It poses a significant challenge to develop
capable AI algorithms for comprehending and grasping a language. As a major
approach, language modeling has been widely studied for language understanding
and generation in the past two decades, evolving from statistical language
models to neural language models. Recently, pre-trained language models (PLMs)
have been proposed by pre-training Transformer models over large-scale corpora,
showing strong capabilities in solving various NLP tasks. Since researchers
have found that model scaling can lead to performance improvement, they further
study the scaling effect by increasing the model size to an even larger size.
Interestingly, when the parameter scale exceeds a certain level, these enlarged
language models not only achieve a significant performance improvement but also
show some special abilities that are not present in small-scale language
models. To discriminate the difference in parameter scale, the research
community has coined the term large language models (LLM) for the PLMs of
significant size. Recently, the research on LLMs has been largely advanced by
both academia and industry, and a remarkable progress is the launch of ChatGPT,
which has attracted widespread attention from society. The technical evolution
of LLMs has been making an important impact on the entire AI community, which
would revolutionize the way how we develop and use AI algorithms. In this
survey, we review the recent advances of LLMs by introducing the background,
key findings, and mainstream techniques. In particular, we focus on four major
aspects of LLMs, namely pre-training, adaptation tuning, utilization, and
capacity evaluation. Besides, we also summarize the available resources for
developing LLMs and discuss the remaining issues for future directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task. (arXiv:2304.01097v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.01097">
<div class="article-summary-box-inner">
<span><p>The recent progress of large language models (LLMs), including ChatGPT and
GPT-4, in comprehending and responding to human instructions has been
remarkable. Nevertheless, these models typically perform better in English and
have not been explicitly trained for the medical domain, resulting in
suboptimal precision in diagnoses, drug recommendations, and other medical
advice. Additionally, training and deploying a dialogue model is still believed
to be impossible for hospitals, hindering the promotion of LLMs. To tackle
these challenges, we have collected databases of medical dialogues in Chinese
with ChatGPT's help and adopted several techniques to train an easy-deploy LLM.
Remarkably, we were able to fine-tune the ChatGLM-6B on a single A100 80G in 13
hours, which means having a healthcare-purpose LLM can be very affordable.
DoctorGLM is currently an early-stage engineering attempt and contain various
mistakes. We are sharing it with the broader community to invite feedback and
suggestions to improve its healthcare-focused capabilities:
https://github.com/xionghonglin/DoctorGLM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SpectFormer: Frequency and Attention is what you need in a Vision Transformer. (arXiv:2304.06446v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.06446">
<div class="article-summary-box-inner">
<span><p>Vision transformers have been applied successfully for image recognition
tasks. There have been either multi-headed self-attention based (ViT
\cite{dosovitskiy2020image}, DeIT, \cite{touvron2021training}) similar to the
original work in textual models or more recently based on spectral layers
(Fnet\cite{lee2021fnet}, GFNet\cite{rao2021global},
AFNO\cite{guibas2021efficient}). We hypothesize that both spectral and
multi-headed attention plays a major role. We investigate this hypothesis
through this work and observe that indeed combining spectral and multi-headed
attention layers provides a better transformer architecture. We thus propose
the novel Spectformer architecture for transformers that combines spectral and
multi-headed attention layers. We believe that the resulting representation
allows the transformer to capture the feature representation appropriately and
it yields improved performance over other transformer representations. For
instance, it improves the top-1 accuracy by 2\% on ImageNet compared to both
GFNet-H and LiT. SpectFormer-S reaches 84.25\% top-1 accuracy on ImageNet-1K
(state of the art for small version). Further, Spectformer-L achieves 85.7\%
that is the state of the art for the comparable base version of the
transformers. We further ensure that we obtain reasonable results in other
scenarios such as transfer learning on standard datasets such as CIFAR-10,
CIFAR-100, Oxford-IIIT-flower, and Standford Car datasets. We then investigate
its use in downstream tasks such of object detection and instance segmentation
on the MS-COCO dataset and observe that Spectformer shows consistent
performance that is comparable to the best backbones and can be further
optimized and improved. Hence, we believe that combined spectral and attention
layers are what are needed for vision transformers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vax-Culture: A Dataset for Studying Vaccine Discourse on Twitter. (arXiv:2304.06858v2 [cs.SI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.06858">
<div class="article-summary-box-inner">
<span><p>Vaccine hesitancy continues to be a main challenge for public health
officials during the COVID-19 pandemic. As this hesitancy undermines vaccine
campaigns, many researchers have sought to identify its root causes, finding
that the increasing volume of anti-vaccine misinformation on social media
platforms is a key element of this problem. We explored Twitter as a source of
misleading content with the goal of extracting overlapping cultural and
political beliefs that motivate the spread of vaccine misinformation. To do
this, we have collected a data set of vaccine-related Tweets and annotated them
with the help of a team of annotators with a background in communications and
journalism. Ultimately we hope this can lead to effective and targeted public
health communication strategies for reaching individuals with anti-vaccine
beliefs. Moreover, this information helps with developing Machine Learning
models to automatically detect vaccine misinformation posts and combat their
negative impacts. In this paper, we present Vax-Culture, a novel Twitter
COVID-19 dataset consisting of 6373 vaccine-related tweets accompanied by an
extensive set of human-provided annotations including vaccine-hesitancy stance,
indication of any misinformation in tweets, the entities criticized and
supported in each tweet and the communicated message of each tweet. Moreover,
we define five baseline tasks including four classification and one sequence
generation tasks, and report the results of a set of recent transformer-based
models for them. The dataset and code are publicly available at
https://github.com/mrzarei5/Vax-Culture.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-04-18 23:11:42.457491101 UTC">2023-04-18 23:11:42 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>