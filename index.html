<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-04-24T01:30:00Z">04-24</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Supporting Qualitative Analysis with Large Language Models: Combining Codebook with GPT-3 for Deductive Coding. (arXiv:2304.10548v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10548">
<div class="article-summary-box-inner">
<span><p>Qualitative analysis of textual contents unpacks rich and valuable
information by assigning labels to the data. However, this process is often
labor-intensive, particularly when working with large datasets. While recent
AI-based tools demonstrate utility, researchers may not have readily available
AI resources and expertise, let alone be challenged by the limited
generalizability of those task-specific models. In this study, we explored the
use of large language models (LLMs) in supporting deductive coding, a major
category of qualitative analysis where researchers use pre-determined codebooks
to label the data into a fixed set of codes. Instead of training task-specific
models, a pre-trained LLM could be used directly for various tasks without
fine-tuning through prompt learning. Using a curiosity-driven questions coding
task as a case study, we found, by combining GPT-3 with expert-drafted
codebooks, our proposed approach achieved fair to substantial agreements with
expert-coded results. We lay out challenges and opportunities in using LLMs to
support qualitative coding and beyond.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-aspect Repetition Suppression and Content Moderation of Large Language Models. (arXiv:2304.10611v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10611">
<div class="article-summary-box-inner">
<span><p>Natural language generation is one of the most impactful fields in NLP, and
recent years have witnessed its evolution brought about by large language
models (LLMs). As the key instrument for writing assistance applications, they
are generally prone to replicating or extending offensive content provided in
the input. In low-resource data regime, they can also lead to repetitive
outputs (Holtzman et al., 2019) [1]. Usually, offensive content and repetitions
are mitigated with post-hoc methods, including n-gram level blocklists, top-k
and nucleus sampling. In this paper, we introduce a combination of exact and
non-exact repetition suppression using token and sequence level unlikelihood
loss, repetition penalty during training, inference, and post-processing
respectively. We further explore multi-level unlikelihood loss to the extent
that it endows the model with abilities to avoid generating offensive words and
phrases from the beginning. Finally, with comprehensive experiments, we
demonstrate that our proposed methods work exceptionally in controlling the
repetition and content quality of LLM outputs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"HOT" ChatGPT: The promise of ChatGPT in detecting and discriminating hateful, offensive, and toxic comments on social media. (arXiv:2304.10619v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10619">
<div class="article-summary-box-inner">
<span><p>Harmful content is pervasive on social media, poisoning online communities
and negatively impacting participation. A common approach to address this issue
is to develop detection models that rely on human annotations. However, the
tasks required to build such models expose annotators to harmful and offensive
content and may require significant time and cost to complete. Generative AI
models have the potential to understand and detect harmful content. To
investigate this potential, we used ChatGPT and compared its performance with
MTurker annotations for three frequently discussed concepts related to harmful
content: Hateful, Offensive, and Toxic (HOT). We designed five prompts to
interact with ChatGPT and conducted four experiments eliciting HOT
classifications. Our results show that ChatGPT can achieve an accuracy of
approximately 80% when compared to MTurker annotations. Specifically, the model
displays a more consistent classification for non-HOT comments than HOT
comments compared to human annotations. Our findings also suggest that ChatGPT
classifications align with provided HOT definitions, but ChatGPT classifies
"hateful" and "offensive" as subsets of "toxic." Moreover, the choice of
prompts used to interact with ChatGPT impacts its performance. Based on these
in-sights, our study provides several meaningful implications for employing
ChatGPT to detect HOT content, particularly regarding the reliability and
consistency of its performance, its understand-ing and reasoning of the HOT
concept, and the impact of prompts on its performance. Overall, our study
provides guidance about the potential of using generative AI models to moderate
large volumes of user-generated content on social media.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IXA/Cogcomp at SemEval-2023 Task 2: Context-enriched Multilingual Named Entity Recognition using Knowledge Bases. (arXiv:2304.10637v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10637">
<div class="article-summary-box-inner">
<span><p>Named Entity Recognition (NER) is a core natural language processing task in
which pre-trained language models have shown remarkable performance. However,
standard benchmarks like CoNLL 2003 \cite{conll03} do not address many of the
challenges that deployed NER systems face, such as having to classify emerging
or complex entities in a fine-grained way. In this paper we present a novel NER
cascade approach comprising three steps: first, identifying candidate entities
in the input sentence; second, linking the each candidate to an existing
knowledge base; third, predicting the fine-grained category for each entity
candidate. We empirically demonstrate the significance of external knowledge
bases in accurately classifying fine-grained and emerging entities. Our system
exhibits robust performance in the MultiCoNER2 \cite{multiconer2-data} shared
task, even in the low-resource language setting where we leverage knowledge
bases of high-resource languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Word Sense Induction with Knowledge Distillation from BERT. (arXiv:2304.10642v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10642">
<div class="article-summary-box-inner">
<span><p>Pre-trained contextual language models are ubiquitously employed for language
understanding tasks, but are unsuitable for resource-constrained systems.
Noncontextual word embeddings are an efficient alternative in these settings.
Such methods typically use one vector to encode multiple different meanings of
a word, and incur errors due to polysemy. This paper proposes a two-stage
method to distill multiple word senses from a pre-trained language model (BERT)
by using attention over the senses of a word in a context and transferring this
sense information to fit multi-sense embeddings in a skip-gram-like framework.
We demonstrate an effective approach to training the sense disambiguation
mechanism in our model with a distribution over word senses extracted from the
output layer embeddings of BERT. Experiments on the contextual word similarity
and sense induction tasks show that this method is superior to or competitive
with state-of-the-art multi-sense embeddings on multiple benchmark data sets,
and experiments with an embedding-based topic model (ETM) demonstrates the
benefits of using this multi-sense embedding in a downstream application.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta Semantics: Towards better natural language understanding and reasoning. (arXiv:2304.10663v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10663">
<div class="article-summary-box-inner">
<span><p>Natural language understanding is one of the most challenging topics in
artificial intelligence. Deep neural network methods, particularly large
language module (LLM) methods such as ChatGPT and GPT-3, have powerful
flexibility to adopt informal text but are weak on logical deduction and suffer
from the out-of-vocabulary (OOV) problem. On the other hand, rule-based methods
such as Mathematica, Semantic web, and Lean, are excellent in reasoning but
cannot handle the complex and changeable informal text. Inspired by pragmatics
and structuralism, we propose two strategies to solve the OOV problem and a
semantic model for better natural language understanding and reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness. (arXiv:2304.10703v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10703">
<div class="article-summary-box-inner">
<span><p>Multi-step reasoning ability is fundamental to many natural language tasks,
yet it is unclear what constitutes a good reasoning chain and how to evaluate
them. Most existing methods focus solely on whether the reasoning chain leads
to the correct conclusion, but this answer-oriented view may confound the
quality of reasoning with other spurious shortcuts to predict the answer. To
bridge this gap, we evaluate reasoning chains by viewing them as informal
proofs that derive the final answer. Specifically, we propose ReCEval
(Reasoning Chain Evaluation), a framework that evaluates reasoning chains
through two key properties: (1) correctness, i.e., each step makes a valid
inference based on the information contained within the step, preceding steps,
and input context, and (2) informativeness, i.e., each step provides new
information that is helpful towards deriving the generated answer. We implement
ReCEval using natural language inference models and information-theoretic
measures. On multiple datasets, ReCEval is highly effective in identifying
different types of errors, resulting in notable improvements compared to prior
methods. We demonstrate that our informativeness metric captures the expected
flow of information in high-quality reasoning chains and we also analyze the
impact of previous steps on evaluating correctness and informativeness.
Finally, we show that scoring reasoning chains based on ReCEval can improve
downstream performance of reasoning tasks. Our code is publicly available at:
https://github.com/archiki/ReCEval
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TC-GAT: Graph Attention Network for Temporal Causality Discovery. (arXiv:2304.10706v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10706">
<div class="article-summary-box-inner">
<span><p>The present study explores the intricacies of causal relationship extraction,
a vital component in the pursuit of causality knowledge. Causality is
frequently intertwined with temporal elements, as the progression from cause to
effect is not instantaneous but rather ensconced in a temporal dimension. Thus,
the extraction of temporal causality holds paramount significance in the field.
In light of this, we propose a method for extracting causality from the text
that integrates both temporal and causal relations, with a particular focus on
the time aspect. To this end, we first compile a dataset that encompasses
temporal relationships. Subsequently, we present a novel model, TC-GAT, which
employs a graph attention mechanism to assign weights to the temporal
relationships and leverages a causal knowledge graph to determine the adjacency
matrix. Additionally, we implement an equilibrium mechanism to regulate the
interplay between temporal and causal relations. Our experiments demonstrate
that our proposed method significantly surpasses baseline models in the task of
causality extraction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KitchenScale: Learning to predict ingredient quantities from recipe contexts. (arXiv:2304.10739v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10739">
<div class="article-summary-box-inner">
<span><p>Determining proper quantities for ingredients is an essential part of cooking
practice from the perspective of enriching tastiness and promoting healthiness.
We introduce KitchenScale, a fine-tuned Pre-trained Language Model (PLM) that
predicts a target ingredient's quantity and measurement unit given its recipe
context. To effectively train our KitchenScale model, we formulate an
ingredient quantity prediction task that consists of three sub-tasks which are
ingredient measurement type classification, unit classification, and quantity
regression task. Furthermore, we utilized transfer learning of cooking
knowledge from recipe texts to PLMs. We adopted the Discrete Latent Exponent
(DExp) method to cope with high variance of numerical scales in recipe corpora.
Experiments with our newly constructed dataset and recommendation examples
demonstrate KitchenScale's understanding of various recipe contexts and
generalizability in predicting ingredient quantities. We implemented a web
application for KitchenScale to demonstrate its functionality in recommending
ingredient quantities expressed in numerals (e.g., 2) with units (e.g., ounce).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Grounded Language Understanding in a Collaborative Environment by Interacting with Agents Through Help Feedback. (arXiv:2304.10750v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10750">
<div class="article-summary-box-inner">
<span><p>Many approaches to Natural Language Processing (NLP) tasks often treat them
as single-step problems, where an agent receives an instruction, executes it,
and is evaluated based on the final outcome. However, human language is
inherently interactive, as evidenced by the back-and-forth nature of human
conversations. In light of this, we posit that human-AI collaboration should
also be interactive, with humans monitoring the work of AI agents and providing
feedback that the agent can understand and utilize. Further, the AI agent
should be able to detect when it needs additional information and proactively
ask for help. Enabling this scenario would lead to more natural, efficient, and
engaging human-AI collaborations.
</p>
<p>In this work, we explore these directions using the challenging task defined
by the IGLU competition, an interactive grounded language understanding task in
a MineCraft-like world. We explore multiple types of help players can give to
the AI to guide it and analyze the impact of this help in AI behavior,
resulting in performance improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GeoLayoutLM: Geometric Pre-training for Visual Information Extraction. (arXiv:2304.10759v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10759">
<div class="article-summary-box-inner">
<span><p>Visual information extraction (VIE) plays an important role in Document
Intelligence. Generally, it is divided into two tasks: semantic entity
recognition (SER) and relation extraction (RE). Recently, pre-trained models
for documents have achieved substantial progress in VIE, particularly in SER.
However, most of the existing models learn the geometric representation in an
implicit way, which has been found insufficient for the RE task since geometric
information is especially crucial for RE. Moreover, we reveal another factor
that limits the performance of RE lies in the objective gap between the
pre-training phase and the fine-tuning phase for RE. To tackle these issues, we
propose in this paper a multi-modal framework, named GeoLayoutLM, for VIE.
GeoLayoutLM explicitly models the geometric relations in pre-training, which we
call geometric pre-training. Geometric pre-training is achieved by three
specially designed geometry-related pre-training tasks. Additionally, novel
relation heads, which are pre-trained by the geometric pre-training tasks and
fine-tuned for RE, are elaborately designed to enrich and enhance the feature
representation. According to extensive experiments on standard VIE benchmarks,
GeoLayoutLM achieves highly competitive scores in the SER task and
significantly outperforms the previous state-of-the-arts for RE (\eg, the F1
score of RE on FUNSD is boosted from 80.35\% to 89.45\%). The code and models
are publicly available at
https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/GeoLayoutLM
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Eyettention: An Attention-based Dual-Sequence Model for Predicting Human Scanpaths during Reading. (arXiv:2304.10784v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10784">
<div class="article-summary-box-inner">
<span><p>Eye movements during reading offer insights into both the reader's cognitive
processes and the characteristics of the text that is being read. Hence, the
analysis of scanpaths in reading have attracted increasing attention across
fields, ranging from cognitive science over linguistics to computer science. In
particular, eye-tracking-while-reading data has been argued to bear the
potential to make machine-learning-based language models exhibit a more
human-like linguistic behavior. However, one of the main challenges in modeling
human scanpaths in reading is their dual-sequence nature: the words are ordered
following the grammatical rules of the language, whereas the fixations are
chronologically ordered. As humans do not strictly read from left-to-right, but
rather skip or refixate words and regress to previous words, the alignment of
the linguistic and the temporal sequence is non-trivial. In this paper, we
develop Eyettention, the first dual-sequence model that simultaneously
processes the sequence of words and the chronological sequence of fixations.
The alignment of the two sequences is achieved by a cross-sequence attention
mechanism. We show that Eyettention outperforms state-of-the-art models in
predicting scanpaths. We provide an extensive within- and across-data set
evaluation on different languages. An ablation study and qualitative analysis
support an in-depth understanding of the model's behavior.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Which Factors Predict the Chat Experience of a Natural Language Generation Dialogue Service?. (arXiv:2304.10785v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10785">
<div class="article-summary-box-inner">
<span><p>In this paper, we proposed a conceptual model to predict the chat experience
in a natural language generation dialog system. We evaluated the model with 120
participants with Partial Least Squares Structural Equation Modeling (PLS-SEM)
and obtained an R-square (R2) with 0.541. The model considers various factors,
including the prompts used for generation; coherence, sentiment, and similarity
in the conversation; and users' perceived dialog agents' favorability. We then
further explore the effectiveness of the subset of our proposed model. The
results showed that users' favorability and coherence, sentiment, and
similarity in the dialogue are positive predictors of users' chat experience.
Moreover, we found users may prefer dialog agents with characteristics of
Extroversion, Openness, Conscientiousness, Agreeableness, and Non-Neuroticism.
Through our research, an adaptive dialog system might use collected data to
infer factors in our model, predict the chat experience for users through these
factors, and optimize it by adjusting prompts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Downstream Task-Oriented Neural Tokenizer Optimization with Vocabulary Restriction as Post Processing. (arXiv:2304.10808v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10808">
<div class="article-summary-box-inner">
<span><p>This paper proposes a method to optimize tokenization for the performance
improvement of already trained downstream models. Our method generates
tokenization results attaining lower loss values of a given downstream model on
the training data for restricting vocabularies and trains a tokenizer
reproducing the tokenization results. Therefore, our method can be applied to
variety of tokenization methods, while existing work cannot due to the
simultaneous learning of the tokenizer and the downstream model. This paper
proposes an example of the BiLSTM-based tokenizer with vocabulary restriction,
which can capture wider contextual information for the tokenization process
than non-neural-based tokenization methods used in existing work. Experimental
results on text classification in Japanese, Chinese, and English text
classification tasks show that the proposed method improves performance
compared to the existing methods for tokenization optimization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tokenization Tractability for Human and Machine Learning Model: An Annotation Study. (arXiv:2304.10813v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10813">
<div class="article-summary-box-inner">
<span><p>Is tractable tokenization for humans also tractable for machine learning
models? This study investigates relations between tractable tokenization for
humans (e.g., appropriateness and readability) and one for models of machine
learning (e.g., performance on an NLP task). We compared six tokenization
methods on the Japanese commonsense question-answering dataset (JCommmonsenseQA
in JGLUE). We tokenized question texts of the QA dataset with different
tokenizers and compared the performance of human annotators and
machine-learning models. Besides,we analyze relationships among the
performance, appropriateness of tokenization, and response time to questions.
This paper provides a quantitative investigation result that shows the
tractable tokenizations for humans and machine learning models are not
necessarily the same as each other.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Better Sign Language Translation with Monolingual Data. (arXiv:2304.10844v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10844">
<div class="article-summary-box-inner">
<span><p>Sign language translation (SLT) systems, which are often decomposed into
video-to-gloss (V2G) recognition and gloss-to-text (G2T) translation through
the pivot gloss, heavily relies on the availability of large-scale parallel G2T
pairs. However, the manual annotation of pivot gloss, which is a sequence of
transcribed written-language words in the order in which they are signed,
further exacerbates the scarcity of data for SLT. To address this issue, this
paper proposes a simple and efficient rule transformation method to transcribe
the large-scale target monolingual data into its pseudo glosses automatically
for enhancing the SLT translation. Empirical results show that the proposed
approach can significantly improve the performance of SLT, especially achieving
state-of-the-art results on two SLT benchmark datasets PHEONIX-WEATHER 2014T
and ASLG-PC12. Our code has been released at:
https://github.com/pengr/Mono\_SLT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text2Time: Transformer-based article time period predictor. (arXiv:2304.10859v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10859">
<div class="article-summary-box-inner">
<span><p>We explore the problem of predicting the publication period of text document,
such as a news article, using the text from that document. In order to do so,
we created our own extensive labeled dataset of over 350,000 news articles
published by The New York Times over six decades. We then provide an
implementation of a simple Naive Bayes baseline model, which surprisingly
achieves decent performance in terms of accuracy.Finally, for our approach, we
use a pretrained BERT model fine-tuned for the task of text classification.
This model exceeds our expectations and provides some very impressive results
in terms of accurately classifying news articles into their respective
publication decades. The results beat the performance of the few previously
tried models for this relatively unexplored task of time prediction from text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CancerGPT: Few-shot Drug Pair Synergy Prediction using Large Pre-trained Language Models. (arXiv:2304.10946v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10946">
<div class="article-summary-box-inner">
<span><p>Large pre-trained language models (LLMs) have been shown to have significant
potential in few-shot learning across various fields, even with minimal
training data. However, their ability to generalize to unseen tasks in more
complex fields, such as biology, has yet to be fully evaluated. LLMs can offer
a promising alternative approach for biological inference, particularly in
cases where structured data and sample size are limited, by extracting prior
knowledge from text corpora. Our proposed few-shot learning approach uses LLMs
to predict the synergy of drug pairs in rare tissues that lack structured data
and features. Our experiments, which involved seven rare tissues from different
cancer types, demonstrated that the LLM-based prediction model achieved
significant accuracy with very few or zero samples. Our proposed model, the
CancerGPT (with $\sim$ 124M parameters), was even comparable to the larger
fine-tuned GPT-3 model (with $\sim$ 175B parameters). Our research is the first
to tackle drug pair synergy prediction in rare tissues with limited data. We
are also the first to utilize an LLM-based prediction model for biological
reaction prediction tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEIA: Linguistic Embeddings for the Identification of Affect. (arXiv:2304.10973v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10973">
<div class="article-summary-box-inner">
<span><p>The wealth of text data generated by social media has enabled new kinds of
analysis of emotions with language models. These models are often trained on
small and costly datasets of text annotations produced by readers who guess the
emotions expressed by others in social media posts. This affects the quality of
emotion identification methods due to training data size limitations and noise
in the production of labels used in model development. We present LEIA, a model
for emotion identification in text that has been trained on a dataset of more
than 6 million posts with self-annotated emotion labels for happiness,
affection, sadness, anger, and fear. LEIA is based on a word masking method
that enhances the learning of emotion words during model pre-training. LEIA
achieves macro-F1 values of approximately 73 on three in-domain test datasets,
outperforming other supervised and unsupervised methods in a strong benchmark
that shows that LEIA generalizes across posts, users, and time periods. We
further perform an out-of-domain evaluation on five different datasets of
social media and other sources, showing LEIA's robust performance across media,
data collection methods, and annotation schemes. Our results show that LEIA
generalizes its classification of anger, happiness, and sadness beyond the
domain it was trained on. LEIA can be applied in future research to provide
better identification of emotions in text from the perspective of the writer.
The models produced for this article are publicly available at
https://huggingface.co/LEIA
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Transformer Language Models on Arithmetic Operations Using Number Decomposition. (arXiv:2304.10977v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10977">
<div class="article-summary-box-inner">
<span><p>In recent years, Large Language Models such as GPT-3 showed remarkable
capabilities in performing NLP tasks in the zero and few shot settings. On the
other hand, the experiments highlighted the difficulty of GPT-3 in carrying out
tasks that require a certain degree of reasoning, such as arithmetic
operations. In this paper we evaluate the ability of Transformer Language
Models to perform arithmetic operations following a pipeline that, before
performing computations, decomposes numbers in units, tens, and so on. We
denote the models fine-tuned with this pipeline with the name Calculon and we
test them in the task of performing additions, subtractions and multiplications
on the same test sets of GPT-3. Results show an increase of accuracy of 63% in
the five-digit addition task. Moreover, we demonstrate the importance of the
decomposition pipeline introduced, since fine-tuning the same Language Model
without decomposing numbers results in 0% accuracy in the five-digit addition
task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Information Extraction from Documents: Question Answering vs Token Classification in real-world setups. (arXiv:2304.10994v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10994">
<div class="article-summary-box-inner">
<span><p>Research in Document Intelligence and especially in Document Key Information
Extraction (DocKIE) has been mainly solved as Token Classification problem.
Recent breakthroughs in both natural language processing (NLP) and computer
vision helped building document-focused pre-training methods, leveraging a
multimodal understanding of the document text, layout and image modalities.
However, these breakthroughs also led to the emergence of a new DocKIE subtask
of extractive document Question Answering (DocQA), as part of the Machine
Reading Comprehension (MRC) research field. In this work, we compare the
Question Answering approach with the classical token classification approach
for document key information extraction. We designed experiments to benchmark
five different experimental setups : raw performances, robustness to noisy
environment, capacity to extract long entities, fine-tuning speed on Few-Shot
Learning and finally Zero-Shot Learning. Our research showed that when dealing
with clean and relatively short entities, it is still best to use token
classification-based approach, while the QA approach could be a good
alternative for noisy environment or long entities use-cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERT Based Clinical Knowledge Extraction for Biomedical Knowledge Graph Construction and Analysis. (arXiv:2304.10996v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10996">
<div class="article-summary-box-inner">
<span><p>Background : Knowledge is evolving over time, often as a result of new
discoveries or changes in the adopted methods of reasoning. Also, new facts or
evidence may become available, leading to new understandings of complex
phenomena. This is particularly true in the biomedical field, where scientists
and physicians are constantly striving to find new methods of diagnosis,
treatment and eventually cure. Knowledge Graphs (KGs) offer a real way of
organizing and retrieving the massive and growing amount of biomedical
knowledge.
</p>
<p>Objective : We propose an end-to-end approach for knowledge extraction and
analysis from biomedical clinical notes using the Bidirectional Encoder
Representations from Transformers (BERT) model and Conditional Random Field
(CRF) layer.
</p>
<p>Methods : The approach is based on knowledge graphs, which can effectively
process abstract biomedical concepts such as relationships and interactions
between medical entities. Besides offering an intuitive way to visualize these
concepts, KGs can solve more complex knowledge retrieval problems by
simplifying them into simpler representations or by transforming the problems
into representations from different perspectives. We created a biomedical
Knowledge Graph using using Natural Language Processing models for named entity
recognition and relation extraction. The generated biomedical knowledge graphs
(KGs) are then used for question answering.
</p>
<p>Results : The proposed framework can successfully extract relevant structured
information with high accuracy (90.7% for Named-entity recognition (NER), 88%
for relation extraction (RE)), according to experimental findings based on
real-world 505 patient biomedical unstructured clinical notes.
</p>
<p>Conclusions : In this paper, we propose a novel end-to-end system for the
construction of a biomedical knowledge graph from clinical textual using a
variation of BERT models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction. (arXiv:2304.11015v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11015">
<div class="article-summary-box-inner">
<span><p>We study the problem of decomposing a complex text-to-sql task into smaller
sub-tasks and how such a decomposition can significantly improve the
performance of Large Language Models (LLMs) in the reasoning process. There is
currently a significant gap between the performance of fine-tuned models and
prompting approaches using LLMs on challenging text-to-sql datasets such as
Spider. We show that SQL queries, despite their declarative structure, can be
broken down into sub-problems and the solutions of those sub-problems can be
fed into LLMs to significantly improve their performance. Our experiments with
three LLMs show that this approach consistently improves their performance by
roughly 10%, pushing the accuracy of LLMs towards state-of-the-art, and even
beating large fine-tuned models on the holdout Spider dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emotional Expression Detection in Spoken Language Employing Machine Learning Algorithms. (arXiv:2304.11040v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11040">
<div class="article-summary-box-inner">
<span><p>There are a variety of features of the human voice that can be classified as
pitch, timbre, loudness, and vocal tone. It is observed in numerous incidents
that human expresses their feelings using different vocal qualities when they
are speaking. The primary objective of this research is to recognize different
emotions of human beings such as anger, sadness, fear, neutrality, disgust,
pleasant surprise, and happiness by using several MATLAB functions namely,
spectral descriptors, periodicity, and harmonicity. To accomplish the work, we
analyze the CREMA-D (Crowd-sourced Emotional Multimodal Actors Data) &amp; TESS
(Toronto Emotional Speech Set) datasets of human speech. The audio file
contains data that have various characteristics (e.g., noisy, speedy, slow)
thereby the efficiency of the ML (Machine Learning) models increases
significantly. The EMD (Empirical Mode Decomposition) is utilized for the
process of signal decomposition. Then, the features are extracted through the
use of several techniques such as the MFCC, GTCC, spectral centroid, roll-off
point, entropy, spread, flux, harmonic ratio, energy, skewness, flatness, and
audio delta. The data is trained using some renowned ML models namely, Support
Vector Machine, Neural Network, Ensemble, and KNN. The algorithms show an
accuracy of 67.7%, 63.3%, 61.6%, and 59.0% respectively for the test data and
77.7%, 76.1%, 99.1%, and 61.2% for the training data. We have conducted
experiments using Matlab and the result shows that our model is very prominent
and flexible than existing similar works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Affective social anthropomorphic intelligent system. (arXiv:2304.11046v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11046">
<div class="article-summary-box-inner">
<span><p>Human conversational styles are measured by the sense of humor, personality,
and tone of voice. These characteristics have become essential for
conversational intelligent virtual assistants. However, most of the
state-of-the-art intelligent virtual assistants (IVAs) are failed to interpret
the affective semantics of human voices. This research proposes an
anthropomorphic intelligent system that can hold a proper human-like
conversation with emotion and personality. A voice style transfer method is
also proposed to map the attributes of a specific emotion. Initially, the
frequency domain data (Mel-Spectrogram) is created by converting the temporal
audio wave data, which comprises discrete patterns for audio features such as
notes, pitch, rhythm, and melody. A collateral CNN-Transformer-Encoder is used
to predict seven different affective states from voice. The voice is also fed
parallelly to the deep-speech, an RNN model that generates the text
transcription from the spectrogram. Then the transcripted text is transferred
to the multi-domain conversation agent using blended skill talk,
transformer-based retrieve-and-generate generation strategy, and beam-search
decoding, and an appropriate textual response is generated. The system learns
an invertible mapping of data to a latent space that can be manipulated and
generates a Mel-spectrogram frame based on previous Mel-spectrogram frames to
voice synthesize and style transfer. Finally, the waveform is generated using
WaveGlow from the spectrogram. The outcomes of the studies we conducted on
individual models were auspicious. Furthermore, users who interacted with the
system provided positive feedback, demonstrating the system's effectiveness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comparison of Semi-Supervised Learning Techniques for Streaming ASR at Scale. (arXiv:2304.11053v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11053">
<div class="article-summary-box-inner">
<span><p>Unpaired text and audio injection have emerged as dominant methods for
improving ASR performance in the absence of a large labeled corpus. However,
little guidance exists on deploying these methods to improve production ASR
systems that are trained on very large supervised corpora and with realistic
requirements like a constrained model size and CPU budget, streaming
capability, and a rich lattice for rescoring and for downstream NLU tasks. In
this work, we compare three state-of-the-art semi-supervised methods
encompassing both unpaired text and audio as well as several of their
combinations in a controlled setting using joint training. We find that in our
setting these methods offer many improvements beyond raw WER, including
substantial gains in tail-word WER, decoder computation during inference, and
lattice density.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Novel Intent Detection and Active Learning Based Classification (Student Abstract). (arXiv:2304.11058v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11058">
<div class="article-summary-box-inner">
<span><p>Novel intent class detection is an important problem in real world scenario
for conversational agents for continuous interaction. Several research works
have been done to detect novel intents in a mono-lingual (primarily English)
texts and images. But, current systems lack an end-to-end universal framework
to detect novel intents across various different languages with less human
annotation effort for mis-classified and system rejected samples. This paper
proposes NIDAL (Novel Intent Detection and Active Learning based
classification), a semi-supervised framework to detect novel intents while
reducing human annotation cost. Empirical results on various benchmark datasets
demonstrate that this system outperforms the baseline methods by more than 10%
margin for accuracy and macro-F1. The system achieves this while maintaining
overall annotation cost to be just ~6-10% of the unlabeled data available to
the system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SkillGPT: a RESTful API service for skill extraction and standardization using a Large Language Model. (arXiv:2304.11060v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11060">
<div class="article-summary-box-inner">
<span><p>We present SkillGPT, a tool for skill extraction and standardization (SES)
from free-style job descriptions and user profiles with an open-source Large
Language Model (LLM) as backbone. Most previous methods for similar tasks
either need supervision or rely on heavy data-preprocessing and feature
engineering. Directly prompting the latest conversational LLM for standard
skills, however, is slow, costly and inaccurate. In contrast, SkillGPT utilizes
a LLM to perform its tasks in steps via summarization and vector similarity
search, to balance speed with precision. The backbone LLM of SkillGPT is based
on Llama, free for academic use and thus useful for exploratory research and
prototype development. Hence, our cost-free SkillGPT gives users the
convenience of conversational SES, efficiently and reliably.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CEIL: A General Classification-Enhanced Iterative Learning Framework for Text Clustering. (arXiv:2304.11061v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11061">
<div class="article-summary-box-inner">
<span><p>Text clustering, as one of the most fundamental challenges in unsupervised
learning, aims at grouping semantically similar text segments without relying
on human annotations. With the rapid development of deep learning, deep
clustering has achieved significant advantages over traditional clustering
methods. Despite the effectiveness, most existing deep text clustering methods
rely heavily on representations pre-trained in general domains, which may not
be the most suitable solution for clustering in specific target domains. To
address this issue, we propose CEIL, a novel Classification-Enhanced Iterative
Learning framework for short text clustering, which aims at generally promoting
the clustering performance by introducing a classification objective to
iteratively improve feature representations. In each iteration, we first adopt
a language model to retrieve the initial text representations, from which the
clustering results are collected using our proposed Category Disentangled
Contrastive Clustering (CDCC) algorithm. After strict data filtering and
aggregation processes, samples with clean category labels are retrieved, which
serve as supervision information to update the language model with the
classification objective via a prompt learning approach. Finally, the updated
language model with improved representation ability is used to enhance
clustering in the next iteration. Extensive experiments demonstrate that the
CEIL framework significantly improves the clustering performance over
iterations, and is generally effective on various clustering algorithms.
Moreover, by incorporating CEIL on CDCC, we achieve the state-of-the-art
clustering performance on a wide range of short text clustering benchmarks
outperforming other strong baseline methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scaling Transformer to 1M tokens and beyond with RMT. (arXiv:2304.11062v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11062">
<div class="article-summary-box-inner">
<span><p>This technical report presents the application of a recurrent memory to
extend the context length of BERT, one of the most effective Transformer-based
models in natural language processing. By leveraging the Recurrent Memory
Transformer architecture, we have successfully increased the model's effective
context length to an unprecedented two million tokens, while maintaining high
memory retrieval accuracy. Our method allows for the storage and processing of
both local and global information and enables information flow between segments
of the input sequence through the use of recurrence. Our experiments
demonstrate the effectiveness of our approach, which holds significant
potential to enhance long-term dependency handling in natural language
understanding and generation tasks as well as enable large-scale context
processing for memory-intensive applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Think Before You Act: Unified Policy for Interleaving Language Reasoning with Actions. (arXiv:2304.11063v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11063">
<div class="article-summary-box-inner">
<span><p>The success of transformer models trained with a language modeling objective
brings a promising opportunity to the reinforcement learning framework.
Decision Transformer is a step towards this direction, showing how to train
transformers with a similar next-step prediction objective on offline data.
Another important development in this area is the recent emergence of
large-scale datasets collected from the internet, such as the ones composed of
tutorial videos with captions where people talk about what they are doing. To
take advantage of this language component, we propose a novel method for
unifying language reasoning with actions in a single policy. Specifically, we
augment a transformer policy with word outputs, so it can generate textual
captions interleaved with actions. When tested on the most challenging task in
BabyAI, with captions describing next subgoals, our reasoning policy
consistently outperforms the caption-free baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conversational Process Modelling: State of the Art, Applications, and Implications in Practice. (arXiv:2304.11065v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11065">
<div class="article-summary-box-inner">
<span><p>Chatbots such as ChatGPT have caused a tremendous hype lately. For BPM
applications, it is often not clear how to apply chatbots to generate business
value. Hence, this work aims at the systematic analysis of existing chatbots
for their support of conversational process modelling as process-oriented
capability. Application scenarios are identified along the process life cycle.
Then a systematic literature review on conversational process modelling is
performed. The resulting taxonomy serves as input for the identification of
application scenarios for conversational process modelling, including
paraphrasing and improvement of process descriptions. The application scenarios
are evaluated for existing chatbots based on a real-world test set from the
higher education domain. It contains process descriptions as well as
corresponding process models, together with an assessment of the model quality.
Based on the literature and application scenario analyses, recommendations for
the usage (practical implications) and further development (research
directions) of conversational process modelling are derived.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OLISIA: a Cascade System for Spoken Dialogue State Tracking. (arXiv:2304.11073v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11073">
<div class="article-summary-box-inner">
<span><p>Though Dialogue State Tracking (DST) is a core component of spoken dialogue
systems, recent work on this task mostly deals with chat corpora, disregarding
the discrepancies between spoken and written language.In this paper, we propose
OLISIA, a cascade system which integrates an Automatic Speech Recognition (ASR)
model and a DST model. We introduce several adaptations in the ASR and DST
modules to improve integration and robustness to spoken conversations.With
these adaptations, our system ranked first in DSTC11 Track 3, a benchmark to
evaluate spoken DST. We conduct an in-depth analysis of the results and find
that normalizing the ASR outputs and adapting the DST inputs through data
augmentation, along with increasing the pre-trained models size all play an
important role in reducing the performance discrepancy between written and
spoken conversations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spaiche: Extending State-of-the-Art ASR Models to Swiss German Dialects. (arXiv:2304.11075v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11075">
<div class="article-summary-box-inner">
<span><p>Recent breakthroughs in NLP largely increased the presence of ASR systems in
our daily lives. However, for many low-resource languages, ASR models still
need to be improved due in part to the difficulty of acquiring pertinent data.
This project aims to help advance research in ASR models for Swiss German
dialects, by providing insights about the performance of state-of-the-art ASR
models on recently published Swiss German speech datasets. We propose a novel
loss that takes into account the semantic distance between the predicted and
the ground-truth labels. We outperform current state-of-the-art results by
fine-tuning OpenAI's Whisper model on Swiss-German datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can ChatGPT-like Generative Models Guarantee Factual Accuracy? On the Mistakes of New Generation Search Engines. (arXiv:2304.11076v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11076">
<div class="article-summary-box-inner">
<span><p>Although large conversational AI models such as OpenAI's ChatGPT have
demonstrated great potential, we question whether such models can guarantee
factual accuracy. Recently, technology companies such as Microsoft and Google
have announced new services which aim to combine search engines with
conversational AI. However, we have found numerous mistakes in the public
demonstrations that suggest we should not easily trust the factual claims of
the AI models. Rather than criticizing specific models or companies, we hope to
call on researchers and developers to improve AI models' transparency and
factual correctness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HeRo: RoBERTa and Longformer Hebrew Language Models. (arXiv:2304.11077v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11077">
<div class="article-summary-box-inner">
<span><p>In this paper, we fill in an existing gap in resources available to the
Hebrew NLP community by providing it with the largest so far pre-train dataset
HeDC4, a state-of-the-art pre-trained language model HeRo for standard length
inputs and an efficient transformer LongHeRo for long input sequences. The HeRo
model was evaluated on the sentiment analysis, the named entity recognition,
and the question answering tasks while the LongHeRo model was evaluated on the
document classification task with a dataset composed of long documents. Both
HeRo and LongHeRo presented state-of-the-art performance. The dataset and model
checkpoints used in this work are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Academic Writing with GPT-3.5: Reflections on Practices, Efficacy and Transparency. (arXiv:2304.11079v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11079">
<div class="article-summary-box-inner">
<span><p>The debate around the use of GPT 3.5 has been a popular topic among academics
since the release of ChatGPT. Whilst some have argued for the advantages of GPT
3.5 in enhancing academic writing, others have raised concerns such as
plagiarism, the spread of false information, and ecological issues. The need
for finding ways to use GPT 3.5 models transparently has been voiced, and
suggestions have been made on social media as to how to use GPT 3.5 models in a
smart way. Nevertheless, to date, there is a lack of literature which clearly
outlines how to use GPT 3.5 models in academic writing, how effective they are,
and how to use them transparently. To address this, I conducted a personal
experience experiment with GPT 3.5, specifically by using OpenAI text davinci
003 model, for writing this article. I identified five ways of using GPT 3.5:
Chunk Stylist, Bullet to Paragraph, Talk Textualizer, Research Buddy, and
Polisher. I reflected on their efficacy, and commented on their potential
impact on writing ethics. Additionally, I provided a comprehensive document
which shows the prompts I used, results I got from GPT 3.5, the final edits and
visually compares those by showing the differences in percentages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fundamental Limitations of Alignment in Large Language Models. (arXiv:2304.11082v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11082">
<div class="article-summary-box-inner">
<span><p>An important aspect in developing language models that interact with humans
is aligning their behavior to be useful and unharmful for their human users.
This is usually achieved by tuning the model in a way that enhances desired
behaviors and inhibits undesired ones, a process referred to as alignment. In
this paper, we propose a theoretical approach called Behavior Expectation
Bounds (BEB) which allows us to formally investigate several inherent
characteristics and limitations of alignment in large language models.
Importantly, we prove that for any behavior that has a finite probability of
being exhibited by the model, there exist prompts that can trigger the model
into outputting this behavior, with probability that increases with the length
of the prompt. This implies that any alignment process that attenuates
undesired behavior but does not remove it altogether, is not safe against
adversarial prompting attacks. Furthermore, our framework hints at the
mechanism by which leading alignment approaches such as reinforcement learning
from human feedback increase the LLM's proneness to being prompted into the
undesired behaviors. Moreover, we include the notion of personas in our BEB
framework, and find that behaviors which are generally very unlikely to be
exhibited by the model can be brought to the front by prompting the model to
behave as specific persona. This theoretical result is being experimentally
demonstrated in large scale by the so called contemporary "chatGPT jailbreaks",
where adversarial users trick the LLM into breaking its alignment guardrails by
triggering it into acting as a malicious persona. Our results expose
fundamental limitations in alignment of LLMs and bring to the forefront the
need to devise reliable mechanisms for ensuring AI safety.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Testing the Reliability of ChatGPT for Text Annotation and Classification: A Cautionary Remark. (arXiv:2304.11085v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11085">
<div class="article-summary-box-inner">
<span><p>Recent studies have demonstrated promising potential of ChatGPT for various
text annotation and classification tasks. However, ChatGPT is non-deterministic
which means that, as with human coders, identical input can lead to different
outputs. Given this, it seems appropriate to test the reliability of ChatGPT.
Therefore, this study investigates the consistency of ChatGPT's zero-shot
capabilities for text annotation and classification, focusing on different
model parameters, prompt variations, and repetitions of identical inputs. Based
on the real-world classification task of differentiating website texts into
news and not news, results show that consistency in ChatGPT's classification
output can fall short of scientific thresholds for reliability. For example,
even minor wording alterations in prompts or repeating the identical input can
lead to varying outputs. Although pooling outputs from multiple repetitions can
improve reliability, this study advises caution when using ChatGPT for
zero-shot text annotation and underscores the need for thorough validation,
such as comparison against human-annotated data. The unsupervised application
of ChatGPT for text annotation and classification is not recommended.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Profiling the news spreading barriers using news headlines. (arXiv:2304.11088v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11088">
<div class="article-summary-box-inner">
<span><p>News headlines can be a good data source for detecting the news spreading
barriers in news media, which may be useful in many real-world applications. In
this paper, we utilize semantic knowledge through the inference-based model
COMET and sentiments of news headlines for barrier classification. We consider
five barriers including cultural, economic, political, linguistic, and
geographical, and different types of news headlines including health, sports,
science, recreation, games, homes, society, shopping, computers, and business.
To that end, we collect and label the news headlines automatically for the
barriers using the metadata of news publishers. Then, we utilize the extracted
commonsense inferences and sentiments as features to detect the news spreading
barriers. We compare our approach to the classical text classification methods,
deep learning, and transformer-based methods. The results show that the
proposed approach using inferences-based semantic knowledge and sentiment
offers better performance than the usual (the average F1-score of the ten
categories improves from 0.41, 0.39, 0.59, and 0.59 to 0.47, 0.55, 0.70, and
0.76 for the cultural, economic, political, and geographical respectively) for
classifying the news-spreading barriers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Responsible AI in the Era of ChatGPT: A Reference Architecture for Designing Foundation Model-based AI Systems. (arXiv:2304.11090v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11090">
<div class="article-summary-box-inner">
<span><p>The release of ChatGPT, Bard, and other large language model (LLM)-based
chatbots has drawn huge attention on foundations models worldwide. There is a
growing trend that foundation models will serve as the fundamental building
blocks for most of the future AI systems. However, incorporating foundation
models in AI systems raises significant concerns about responsible AI due to
their black box nature and rapidly advancing super-intelligence. Additionally,
the foundation model's growing capabilities can eventually absorb the other
components of AI systems, introducing the moving boundary and interface
evolution challenges in architecture design. To address these challenges, this
paper proposes a pattern-oriented responsible-AI-by-design reference
architecture for designing foundation model-based AI systems. Specially, the
paper first presents an architecture evolution of AI systems in the era of
foundation models, from "foundation-model-as-a-connector" to
"foundation-model-as-a-monolithic architecture". The paper then identifies the
key design decision points and proposes a pattern-oriented reference
architecture to provide reusable responsible-AI-by-design architectural
solutions to address the new architecture evolution and responsible AI
challenges. The patterns can be embedded as product features of foundation
model-based AI systems and can enable organisations to capitalise on the
potential of foundation models while minimising associated risks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hi Sheldon! Creating Deep Personalized Characters from TV Shows. (arXiv:2304.11093v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11093">
<div class="article-summary-box-inner">
<span><p>Imagine an interesting multimodal interactive scenario that you can see,
hear, and chat with an AI-generated digital character, who is capable of
behaving like Sheldon from The Big Bang Theory, as a DEEP copy from appearance
to personality. Towards this fantastic multimodal chatting scenario, we propose
a novel task, named Deep Personalized Character Creation (DPCC): creating
multimodal chat personalized characters from multimodal data such as TV shows.
Specifically, given a single- or multi-modality input (text, audio, video), the
goal of DPCC is to generate a multi-modality (text, audio, video) response,
which should be well-matched the personality of a specific character such as
Sheldon, and of high quality as well. To support this novel task, we further
collect a character centric multimodal dialogue dataset, named Deep
Personalized Character Dataset (DPCD), from TV shows. DPCD contains
character-specific multimodal dialogue data of ~10k utterances and ~6 hours of
audio/video per character, which is around 10 times larger compared to existing
related datasets.On DPCD, we present a baseline method for the DPCC task and
create 5 Deep personalized digital Characters (DeepCharacters) from Big Bang TV
Shows. We conduct both subjective and objective experiments to evaluate the
multimodal response from DeepCharacters in terms of characterization and
quality. The results demonstrates that, on our collected DPCD dataset, the
proposed baseline can create personalized digital characters for generating
multimodal response.Our collected DPCD dataset, the code of data collection and
our baseline will be published soon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effectiveness of Debiasing Techniques: An Indigenous Qualitative Analysis. (arXiv:2304.11094v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11094">
<div class="article-summary-box-inner">
<span><p>An indigenous perspective on the effectiveness of debiasing techniques for
pre-trained language models (PLMs) is presented in this paper. The current
techniques used to measure and debias PLMs are skewed towards the US racial
biases and rely on pre-defined bias attributes (e.g. "black" vs "white"). Some
require large datasets and further pre-training. Such techniques are not
designed to capture the underrepresented indigenous populations in other
countries, such as M\=aori in New Zealand. Local knowledge and understanding
must be incorporated to ensure unbiased algorithms, especially when addressing
a resource-restricted society.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is Cross-modal Information Retrieval Possible without Training?. (arXiv:2304.11095v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11095">
<div class="article-summary-box-inner">
<span><p>Encoded representations from a pretrained deep learning model (e.g., BERT
text embeddings, penultimate CNN layer activations of an image) convey a rich
set of features beneficial for information retrieval. Embeddings for a
particular modality of data occupy a high-dimensional space of its own, but it
can be semantically aligned to another by a simple mapping without training a
deep neural net. In this paper, we take a simple mapping computed from the
least squares and singular value decomposition (SVD) for a solution to the
Procrustes problem to serve a means to cross-modal information retrieval. That
is, given information in one modality such as text, the mapping helps us locate
a semantically equivalent data item in another modality such as image. Using
off-the-shelf pretrained deep learning models, we have experimented the
aforementioned simple cross-modal mappings in tasks of text-to-image and
image-to-text retrieval. Despite simplicity, our mappings perform reasonably
well reaching the highest accuracy of 77% on recall@10, which is comparable to
those requiring costly neural net training and fine-tuning. We have improved
the simple mappings by contrastive learning on the pretrained models.
Contrastive learning can be thought as properly biasing the pretrained encoders
to enhance the cross-modal mapping quality. We have further improved the
performance by multilayer perceptron with gating (gMLP), a simple neural
architecture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatABL: Abductive Learning via Natural Language Interaction with ChatGPT. (arXiv:2304.11107v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11107">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) such as ChatGPT have recently demonstrated
significant potential in mathematical abilities, providing valuable reasoning
paradigm consistent with human natural language. However, LLMs currently have
difficulty in bridging perception, language understanding and reasoning
capabilities due to incompatibility of the underlying information flow among
them, making it challenging to accomplish tasks autonomously. On the other
hand, abductive learning (ABL) frameworks for integrating the two abilities of
perception and reasoning has seen significant success in inverse decipherment
of incomplete facts, but it is limited by the lack of semantic understanding of
logical reasoning rules and the dependence on complicated domain knowledge
representation. This paper presents a novel method (ChatABL) for integrating
LLMs into the ABL framework, aiming at unifying the three abilities in a more
user-friendly and understandable manner. The proposed method uses the strengths
of LLMs' understanding and logical reasoning to correct the incomplete logical
facts for optimizing the performance of perceptual module, by summarizing and
reorganizing reasoning rules represented in natural language format. Similarly,
perceptual module provides necessary reasoning examples for LLMs in natural
language format. The variable-length handwritten equation deciphering task, an
abstract expression of the Mayan calendar decoding, is used as a testbed to
demonstrate that ChatABL has reasoning ability beyond most existing
state-of-the-art methods, which has been well supported by comparative studies.
To our best knowledge, the proposed ChatABL is the first attempt to explore a
new pattern for further approaching human-level cognitive ability via natural
language interaction with ChatGPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inducing anxiety in large language models increases exploration and bias. (arXiv:2304.11111v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11111">
<div class="article-summary-box-inner">
<span><p>Large language models are transforming research on machine learning while
galvanizing public debates. Understanding not only when these models work well
and succeed but also why they fail and misbehave is of great societal
relevance. We propose to turn the lens of computational psychiatry, a framework
used to computationally describe and modify aberrant behavior, to the outputs
produced by these models. We focus on the Generative Pre-Trained Transformer
3.5 and subject it to tasks commonly studied in psychiatry. Our results show
that GPT-3.5 responds robustly to a common anxiety questionnaire, producing
higher anxiety scores than human subjects. Moreover, GPT-3.5's responses can be
predictably changed by using emotion-inducing prompts. Emotion-induction not
only influences GPT-3.5's behavior in a cognitive task measuring exploratory
decision-making but also influences its behavior in a previously-established
task measuring biases such as racism and ableism. Crucially, GPT-3.5 shows a
strong increase in biases when prompted with anxiety-inducing text. Thus, it is
likely that how prompts are communicated to large language models has a strong
influence on their behavior in applied settings. These results progress our
understanding of prompt engineering and demonstrate the usefulness of methods
taken from computational psychiatry for studying the capable algorithms to
which we increasingly delegate authority and autonomy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Mapping of CVE Vulnerability Records to MITRE CWE Weaknesses. (arXiv:2304.11130v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11130">
<div class="article-summary-box-inner">
<span><p>In recent years, a proliferation of cyber-security threats and diversity has
been on the rise culminating in an increase in their reporting and analysis. To
counter that, many non-profit organizations have emerged in this domain, such
as MITRE and OSWAP, which have been actively tracking vulnerabilities, and
publishing defense recommendations in standardized formats. As producing data
in such formats manually is very time-consuming, there have been some proposals
to automate the process. Unfortunately, a major obstacle to adopting supervised
machine learning for this problem has been the lack of publicly available
specialized datasets. Here, we aim to bridge this gap. In particular, we focus
on mapping CVE records into MITRE CWE Weaknesses, and we release to the
research community a manually annotated dataset of 4,012 records for this task.
With a human-in-the-loop framework in mind, we approach the problem as a
ranking task and aim to incorporate reinforced learning to make use of the
human feedback in future work. Our experimental results using fine-tuned deep
learning models, namely Sentence-BERT and rankT5, show sizable performance
gains over BM25, BERT, and RoBERTa, which demonstrates the need for an
architecture capable of good semantic understanding for this task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emergent and Predictable Memorization in Large Language Models. (arXiv:2304.11158v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11158">
<div class="article-summary-box-inner">
<span><p>Memorization, or the tendency of large language models (LLMs) to output
entire sequences from their training data verbatim, is a key concern for safely
deploying language models. In particular, it is vital to minimize a model's
memorization of sensitive datapoints such as those containing personal
identifiable information (PII). The prevalence of such undesirable memorization
can pose issues for model trainers, and may even require discarding an
otherwise functional model. We therefore seek to predict which sequences will
be memorized before a large model's full train-time by extrapolating the
memorization behavior of lower-compute trial runs. We measure memorization of
the Pythia model suite, and find that intermediate checkpoints are better
predictors of a model's memorization behavior than smaller fully-trained
models. We additionally provide further novel discoveries on the distribution
of memorization scores across models and data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large scale analysis of gender bias and sexism in song lyrics. (arXiv:2208.02052v4 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.02052">
<div class="article-summary-box-inner">
<span><p>We employ Natural Language Processing techniques to analyse 377808 English
song lyrics from the "Two Million Song Database" corpus, focusing on the
expression of sexism across five decades (1960-2010) and the measurement of
gender biases. Using a sexism classifier, we identify sexist lyrics at a larger
scale than previous studies using small samples of manually annotated popular
songs. Furthermore, we reveal gender biases by measuring associations in word
embeddings learned on song lyrics. We find sexist content to increase across
time, especially from male artists and for popular songs appearing in Billboard
charts. Songs are also shown to contain different language biases depending on
the gender of the performer, with male solo artist songs containing more and
stronger biases. This is the first large scale analysis of this type, giving
insights into language usage in such an influential part of popular culture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distill the Image to Nowhere: Inversion Knowledge Distillation for Multimodal Machine Translation. (arXiv:2210.04468v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04468">
<div class="article-summary-box-inner">
<span><p>Past works on multimodal machine translation (MMT) elevate bilingual setup by
incorporating additional aligned vision information. However, an image-must
requirement of the multimodal dataset largely hinders MMT's development --
namely that it demands an aligned form of [image, source text, target text].
This limitation is generally troublesome during the inference phase especially
when the aligned image is not provided as in the normal NMT setup. Thus, in
this work, we introduce IKD-MMT, a novel MMT framework to support the
image-free inference phase via an inversion knowledge distillation scheme. In
particular, a multimodal feature generator is executed with a knowledge
distillation module, which directly generates the multimodal feature from
(only) source texts as the input. While there have been a few prior works
entertaining the possibility to support image-free inference for machine
translation, their performances have yet to rival the image-must translation.
In our experiments, we identify our method as the first image-free approach to
comprehensively rival or even surpass (almost) all image-must frameworks, and
achieved the state-of-the-art result on the often-used Multi30k benchmark. Our
code and data are available at: https://github.com/pengr/IKD-mmt/tree/master..
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">tieval: An Evaluation Framework for Temporal Information Extraction Systems. (arXiv:2301.04643v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.04643">
<div class="article-summary-box-inner">
<span><p>Temporal information extraction (TIE) has attracted a great deal of interest
over the last two decades, leading to the development of a significant number
of datasets. Despite its benefits, having access to a large volume of corpora
makes it difficult when it comes to benchmark TIE systems. On the one hand,
different datasets have different annotation schemes, thus hindering the
comparison between competitors across different corpora. On the other hand, the
fact that each corpus is commonly disseminated in a different format requires a
considerable engineering effort for a researcher/practitioner to develop
parsers for all of them. This constraint forces researchers to select a limited
amount of datasets to evaluate their systems which consequently limits the
comparability of the systems. Yet another obstacle that hinders the
comparability of the TIE systems is the evaluation metric employed. While most
research works adopt traditional metrics such as precision, recall, and $F_1$,
a few others prefer temporal awareness -- a metric tailored to be more
comprehensive on the evaluation of temporal systems. Although the reason for
the absence of temporal awareness in the evaluation of most systems is not
clear, one of the factors that certainly weights this decision is the necessity
to implement the temporal closure algorithm in order to compute temporal
awareness, which is not straightforward to implement neither is currently
easily available. All in all, these problems have limited the fair comparison
between approaches and consequently, the development of temporal extraction
systems. To mitigate these problems, we have developed tieval, a Python library
that provides a concise interface for importing different corpora and
facilitates system evaluation. In this paper, we present the first public
release of tieval and highlight its most relevant features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models are Versatile Decomposers: Decompose Evidence and Questions for Table-based Reasoning. (arXiv:2301.13808v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.13808">
<div class="article-summary-box-inner">
<span><p>Table-based reasoning has shown remarkable progress in combining deep models
with discrete reasoning, which requires reasoning over both free-form natural
language (NL) questions and structured tabular data. However, previous
table-based reasoning solutions usually suffer from significant performance
degradation on huge evidence (tables). In addition, most existing methods
struggle to reason over complex questions since the required information is
scattered in different places. To alleviate the above challenges, we exploit
large language models (LLMs) as decomposers for effective table-based
reasoning, which (i) decompose huge evidence (a huge table) into sub-evidence
(a small table) to mitigate the interference of useless information for table
reasoning; and (ii) decompose complex questions into simpler sub-questions for
text reasoning. Specifically, we first use the LLMs to break down the evidence
(tables) involved in the current question, retaining the relevant evidence and
excluding the remaining irrelevant evidence from the huge table. In addition,
we propose a "parsing-execution-filling" strategy to alleviate the
hallucination dilemma of the chain of thought by decoupling logic and numerical
computation in each step. Extensive experiments show that our method can
effectively leverage decomposed evidence and questions and outperforms the
strong baselines on TabFact, WikiTableQuestion, and FetaQA datasets. Notably,
our model outperforms human performance for the first time on the TabFact
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews on Social Media. (arXiv:2302.07731v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07731">
<div class="article-summary-box-inner">
<span><p>Recent advances in generative models such as GPT may be used to fabricate
indistinguishable fake customer reviews at a much lower cost, thus posing
challenges for social media platforms to detect these machine-generated fake
reviews. We propose to leverage the high-quality elite restaurant reviews
verified by Yelp to generate fake reviews from the OpenAI GPT review creator
and ultimately fine-tune a GPT output detector to predict fake reviews that
significantly outperform existing solutions. We further apply the model to
predict non-elite reviews and identify the patterns across several dimensions,
such as review, user and restaurant characteristics, and writing style. We show
that social media platforms are continuously challenged by machine-generated
fake reviews, although they may implement detection systems to filter out
suspicious reviews.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Design Translation Prompts for ChatGPT: An Empirical Study. (arXiv:2304.02182v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.02182">
<div class="article-summary-box-inner">
<span><p>The recently released ChatGPT has demonstrated surprising abilities in
natural language understanding and natural language generation. Machine
translation relies heavily on the abilities of language understanding and
generation. Thus, in this paper, we explore how to assist machine translation
with ChatGPT. We adopt several translation prompts on a wide range of
translations. Our experimental results show that ChatGPT with designed
translation prompts can achieve comparable or better performance over
commercial translation systems for high-resource language translations. We
further evaluate the translation quality using multiple references, and ChatGPT
achieves superior performance compared to commercial systems. We also conduct
experiments on domain-specific translations, the final results show that
ChatGPT is able to comprehend the provided domain keyword and adjust
accordingly to output proper translations. At last, we perform few-shot prompts
that show consistent improvement across different base prompts. Our work
provides empirical evidence that ChatGPT still has great potential in
translations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An investigation of speaker independent phrase break models in End-to-End TTS systems. (arXiv:2304.04157v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.04157">
<div class="article-summary-box-inner">
<span><p>This paper presents our work on phrase break prediction in the context of
end-to-end TTS systems, motivated by the following questions: (i) Is there any
utility in incorporating an explicit phrasing model in an end-to-end TTS
system?, and (ii) How do you evaluate the effectiveness of a phrasing model in
an end-to-end TTS system? In particular, the utility and effectiveness of
phrase break prediction models are evaluated in in the context of childrens
story synthesis, using listener comprehension. We show by means of perceptual
listening evaluations that there is a clear preference for stories synthesized
after predicting the location of phrase breaks using a trained phrasing model,
over stories directly synthesized without predicting the location of phrase
breaks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chinese Open Instruction Generalist: A Preliminary Release. (arXiv:2304.07987v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07987">
<div class="article-summary-box-inner">
<span><p>Instruction tuning is widely recognized as a key technique for building
generalist language models, which has attracted the attention of researchers
and the public with the release of InstructGPT~\citep{ouyang2022training} and
ChatGPT\footnote{\url{https://chat.openai.com/}}. Despite impressive progress
in English-oriented large-scale language models (LLMs), it is still
under-explored whether English-based foundation LLMs can perform similarly on
multilingual tasks compared to English tasks with well-designed instruction
tuning and how we can construct the corpora needed for the tuning. To remedy
this gap, we propose the project as an attempt to create a Chinese instruction
dataset by various methods adapted to the intrinsic characteristics of 4
sub-tasks. We collect around 200k Chinese instruction tuning samples, which
have been manually checked to guarantee high quality. We also summarize the
existing English and Chinese instruction corpora and briefly describe some
potential applications of the newly constructed Chinese instruction corpora.
The resulting \textbf{C}hinese \textbf{O}pen \textbf{I}nstruction
\textbf{G}eneralist (\textbf{COIG}) corpora are available in
Huggingface\footnote{\url{https://huggingface.co/datasets/BAAI/COIG}} and
Github\footnote{\url{https://github.com/BAAI-Zlab/COIG}}, and will be
continuously updated.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards a Benchmark for Scientific Understanding in Humans and Machines. (arXiv:2304.10327v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.10327">
<div class="article-summary-box-inner">
<span><p>Scientific understanding is a fundamental goal of science, allowing us to
explain the world. There is currently no good way to measure the scientific
understanding of agents, whether these be humans or Artificial Intelligence
systems. Without a clear benchmark, it is challenging to evaluate and compare
different levels of and approaches to scientific understanding. In this
Roadmap, we propose a framework to create a benchmark for scientific
understanding, utilizing tools from philosophy of science. We adopt a
behavioral notion according to which genuine understanding should be recognized
as an ability to perform certain tasks. We extend this notion by considering a
set of questions that can gauge different levels of scientific understanding,
covering information retrieval, the capability to arrange information to
produce an explanation, and the ability to infer how things would be different
under different circumstances. The Scientific Understanding Benchmark (SUB),
which is formed by a set of these tests, allows for the evaluation and
comparison of different approaches. Benchmarking plays a crucial role in
establishing trust, ensuring quality control, and providing a basis for
performance evaluation. By aligning machine and human scientific understanding
we can improve their utility, ultimately advancing scientific understanding and
helping to discover new insights within machines.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-04-24 23:11:38.226945308 UTC">2023-04-24 23:11:38 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>