<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-04-20T01:30:00Z">04-20</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Token Imbalance Adaptation for Radiology Report Generation. (arXiv:2304.09185v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09185">
<div class="article-summary-box-inner">
<span><p>Imbalanced token distributions naturally exist in text documents, leading
neural language models to overfit on frequent tokens. The token imbalance may
dampen the robustness of radiology report generators, as complex medical terms
appear less frequently but reflect more medical information. In this study, we
demonstrate how current state-of-the-art models fail to generate infrequent
tokens on two standard benchmark datasets (IU X-RAY and MIMIC-CXR) of radiology
report generation. % However, no prior study has proposed methods to adapt
infrequent tokens for text generators feeding with medical images. To solve the
challenge, we propose the \textbf{T}oken \textbf{Im}balance Adapt\textbf{er}
(\textit{TIMER}), aiming to improve generation robustness on infrequent tokens.
The model automatically leverages token imbalance by an unlikelihood loss and
dynamically optimizes generation processes to augment infrequent tokens. We
compare our approach with multiple state-of-the-art methods on the two
benchmarks. Experiments demonstrate the effectiveness of our approach in
enhancing model robustness overall and infrequent tokens. Our ablation analysis
shows that our reinforcement learning method has a major effect in adapting
token imbalance for radiology report generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Neural Lambda Calculus: Neurosymbolic AI meets the foundations of computing and functional programming. (arXiv:2304.09276v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09276">
<div class="article-summary-box-inner">
<span><p>Over the last decades, deep neural networks based-models became the dominant
paradigm in machine learning. Further, the use of artificial neural networks in
symbolic learning has been seen as increasingly relevant recently. To study the
capabilities of neural networks in the symbolic AI domain, researchers have
explored the ability of deep neural networks to learn mathematical
constructions, such as addition and multiplication, logic inference, such as
theorem provers, and even the execution of computer programs. The latter is
known to be too complex a task for neural networks. Therefore, the results were
not always successful, and often required the introduction of biased elements
in the learning process, in addition to restricting the scope of possible
programs to be executed. In this work, we will analyze the ability of neural
networks to learn how to execute programs as a whole. To do so, we propose a
different approach. Instead of using an imperative programming language, with
complex structures, we use the Lambda Calculus ({\lambda}-Calculus), a simple,
but Turing-Complete mathematical formalism, which serves as the basis for
modern functional programming languages and is at the heart of computability
theory. We will introduce the use of integrated neural learning and lambda
calculi formalization. Finally, we explore execution of a program in
{\lambda}-Calculus is based on reductions, we will show that it is enough to
learn how to perform these reductions so that we can execute any program.
Keywords: Machine Learning, Lambda Calculus, Neurosymbolic AI, Neural Networks,
Transformer Model, Sequence-to-Sequence Models, Computational Models
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BIM-GPT: a Prompt-Based Virtual Assistant Framework for BIM Information Retrieval. (arXiv:2304.09333v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09333">
<div class="article-summary-box-inner">
<span><p>Efficient information retrieval (IR) from building information models (BIMs)
poses significant challenges due to the necessity for deep BIM knowledge or
extensive engineering efforts for automation. We introduce BIM-GPT, a
prompt-based virtual assistant (VA) framework integrating BIM and generative
pre-trained transformer (GPT) technologies to support NL-based IR. A prompt
manager and dynamic template generate prompts for GPT models, enabling
interpretation of NL queries, summarization of retrieved information, and
answering BIM-related questions. In tests on a BIM IR dataset, our approach
achieved 83.5% and 99.5% accuracy rates for classifying NL queries with no data
and 2% data incorporated in prompts, respectively. Additionally, we validated
the functionality of BIM-GPT through a VA prototype for a hospital building.
This research contributes to the development of effective and versatile VAs for
BIM IR in the construction industry, significantly enhancing BIM accessibility
and reducing engineering efforts and training data requirements for processing
NL queries.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Unintended Consequences of Censoring Digital Technology -- Evidence from Italy's ChatGPT Ban. (arXiv:2304.09339v1 [econ.GN])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09339">
<div class="article-summary-box-inner">
<span><p>We analyse the effects of the ban of ChatGPT, a generative pre-trained
transformer chatbot, on individual productivity. We first compile data on the
hourly coding output of over 8,000 professional GitHub users in Italy and other
European countries to analyse the impact of the ban on individual productivity.
Combining the high-frequency data with the sudden announcement of the ban in a
difference-in-differences framework, we find that the output of Italian
developers decreased by around 50% in the first two business days after the ban
and recovered after that. Applying a synthetic control approach to daily Google
search and Tor usage data shows that the ban led to a significant increase in
the use of censorship bypassing tools. Our findings show that users swiftly
implement strategies to bypass Internet restrictions but this adaptation
activity creates short-term disruptions and hampers productivity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM as A Robotic Brain: Unifying Egocentric Memory and Control. (arXiv:2304.09349v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09349">
<div class="article-summary-box-inner">
<span><p>Embodied AI focuses on the study and development of intelligent systems that
possess a physical or virtual embodiment (i.e. robots) and are able to
dynamically interact with their environment. Memory and control are the two
essential parts of an embodied system and usually require separate frameworks
to model each of them. In this paper, we propose a novel and generalizable
framework called LLM-Brain: using Large-scale Language Model as a robotic brain
to unify egocentric memory and control. The LLM-Brain framework integrates
multiple multimodal language models for robotic tasks, utilizing a zero-shot
learning approach. All components within LLM-Brain communicate using natural
language in closed-loop multi-round dialogues that encompass perception,
planning, control, and memory. The core of the system is an embodied LLM to
maintain egocentric memory and control the robot. We demonstrate LLM-Brain by
examining two downstream tasks: active exploration and embodied question
answering. The active exploration tasks require the robot to extensively
explore an unknown environment within a limited number of actions. Meanwhile,
the embodied question answering tasks necessitate that the robot answers
questions based on observations acquired during prior explorations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shuffle & Divide: Contrastive Learning for Long Text. (arXiv:2304.09374v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09374">
<div class="article-summary-box-inner">
<span><p>We propose a self-supervised learning method for long text documents based on
contrastive learning. A key to our method is Shuffle and Divide (SaD), a simple
text augmentation algorithm that sets up a pretext task required for
contrastive updates to BERT-based document embedding. SaD splits a document
into two sub-documents containing randomly shuffled words in the entire
documents. The sub-documents are considered positive examples, leaving all
other documents in the corpus as negatives. After SaD, we repeat the
contrastive update and clustering phases until convergence. It is naturally a
time-consuming, cumbersome task to label text documents, and our method can
help alleviate human efforts, which are most expensive resources in AI. We have
empirically evaluated our method by performing unsupervised text classification
on the 20 Newsgroups, Reuters-21578, BBC, and BBCSport datasets. In particular,
our method pushes the current state-of-the-art, SS-SB-MT, on 20 Newsgroups by
20.94% in accuracy. We also achieve the state-of-the-art performance on
Reuters-21578 and exceptionally-high accuracy performances (over 95%) for
unsupervised classification on the BBC and BBCSport datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Study of Leveraging Knowledge Distillation for Compressing Multilingual Neural Machine Translation Models. (arXiv:2304.09388v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09388">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation (KD) is a well-known method for compressing neural
models. However, works focusing on distilling knowledge from large multilingual
neural machine translation (MNMT) models into smaller ones are practically
nonexistent, despite the popularity and superiority of MNMT. This paper bridges
this gap by presenting an empirical investigation of knowledge distillation for
compressing MNMT models. We take Indic to English translation as a case study
and demonstrate that commonly used language-agnostic and language-aware KD
approaches yield models that are 4-5x smaller but also suffer from performance
drops of up to 3.5 BLEU. To mitigate this, we then experiment with design
considerations such as shallower versus deeper models, heavy parameter sharing,
multi-stage training, and adapters. We observe that deeper compact models tend
to be as good as shallower non-compact ones, and that fine-tuning a distilled
model on a High-Quality subset slightly boosts translation quality. Overall, we
conclude that compressing MNMT models via KD is challenging, indicating immense
scope for further research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MixPro: Simple yet Effective Data Augmentation for Prompt-based Learning. (arXiv:2304.09402v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09402">
<div class="article-summary-box-inner">
<span><p>Prompt-based learning reformulates downstream tasks as cloze problems by
combining the original input with a template. This technique is particularly
useful in few-shot learning, where a model is trained on a limited amount of
data. However, the limited templates and text used in few-shot prompt-based
learning still leave significant room for performance improvement.
Additionally, existing methods using model ensembles can constrain the model
efficiency. To address these issues, we propose an augmentation method called
MixPro, which augments both the vanilla input text and the templates through
token-level, sentence-level, and epoch-level Mixup strategies. We conduct
experiments on five few-shot datasets, and the results show that MixPro
outperforms other augmentation baselines, improving model performance by an
average of 5.08% compared to before augmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Do Things with Deep Learning Code. (arXiv:2304.09406v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09406">
<div class="article-summary-box-inner">
<span><p>The premise of this article is that a basic understanding of the composition
and functioning of large language models is critically urgent. To that end, we
extract a representational map of OpenAI's GPT-2 with what we articulate as two
classes of deep learning code, that which pertains to the model and that which
underwrites applications built around the model. We then verify this map
through case studies of two popular GPT-2 applications: the text adventure
game, AI Dungeon, and the language art project, This Word Does Not Exist. Such
an exercise allows us to test the potential of Critical Code Studies when the
object of study is deep learning code and to demonstrate the validity of code
as an analytical focus for researchers in the subfields of Critical Artificial
Intelligence and Critical Machine Learning Studies. More broadly, however, our
work draws attention to the means by which ordinary users might interact with,
and even direct, the behavior of deep learning systems, and by extension works
toward demystifying some of the auratic mystery of "AI." What is at stake is
the possibility of achieving an informed sociotechnical consensus about the
responsible applications of large language models, as well as a more expansive
sense of their creative capabilities-indeed, understanding how and where
engagement occurs allows all of us to become more active participants in the
development of machine learning systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TieFake: Title-Text Similarity and Emotion-Aware Fake News Detection. (arXiv:2304.09421v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09421">
<div class="article-summary-box-inner">
<span><p>Fake news detection aims to detect fake news widely spreading on social media
platforms, which can negatively influence the public and the government. Many
approaches have been developed to exploit relevant information from news
images, text, or videos. However, these methods may suffer from the following
limitations: (1) ignore the inherent emotional information of the news, which
could be beneficial since it contains the subjective intentions of the authors;
(2) pay little attention to the relation (similarity) between the title and
textual information in news articles, which often use irrelevant title to
attract reader' attention. To this end, we propose a novel Title-Text
similarity and emotion-aware Fake news detection (TieFake) method by jointly
modeling the multi-modal context information and the author sentiment in a
unified framework. Specifically, we respectively employ BERT and ResNeSt to
learn the representations for text and images, and utilize publisher emotion
extractor to capture the author's subjective emotion in the news content. We
also propose a scale-dot product attention mechanism to capture the similarity
between title features and textual features. Experiments are conducted on two
publicly available multi-modal datasets, and the results demonstrate that our
proposed method can significantly improve the performance of fake news
detection. Our code is available at https://github.com/UESTC-GQJ/TieFake.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes. (arXiv:2304.09433v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09433">
<div class="article-summary-box-inner">
<span><p>A long standing goal of the data management community is to develop general,
automated systems that ingest semi-structured documents and output queryable
tables without human effort or domain specific customization. Given the sheer
variety of potential documents, state-of-the art systems make simplifying
assumptions and use domain specific training. In this work, we ask whether we
can maintain generality by using large language models (LLMs). LLMs, which are
pretrained on broad data, can perform diverse downstream tasks simply
conditioned on natural language task descriptions.
</p>
<p>We propose and evaluate EVAPORATE, a simple, prototype system powered by
LLMs. We identify two fundamentally different strategies for implementing this
system: prompt the LLM to directly extract values from documents or prompt the
LLM to synthesize code that performs the extraction. Our evaluations show a
cost-quality tradeoff between these two approaches. Code synthesis is cheap,
but far less accurate than directly processing each document with the LLM. To
improve quality while maintaining low cost, we propose an extended code
synthesis implementation, EVAPORATE-CODE+, which achieves better quality than
direct extraction. Our key insight is to generate many candidate functions and
ensemble their extractions using weak supervision. EVAPORATE-CODE+ not only
outperforms the state-of-the art systems, but does so using a sublinear pass
over the documents with the LLM. This equates to a 110x reduction in the number
of tokens the LLM needs to process, averaged across 16 real-world evaluation
settings of 10k documents each.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EC^2: Emergent Communication for Embodied Control. (arXiv:2304.09448v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09448">
<div class="article-summary-box-inner">
<span><p>Embodied control requires agents to leverage multi-modal pre-training to
quickly learn how to act in new environments, where video demonstrations
contain visual and motion details needed for low-level perception and control,
and language instructions support generalization with abstract, symbolic
structures. While recent approaches apply contrastive learning to force
alignment between the two modalities, we hypothesize better modeling their
complementary differences can lead to more holistic representations for
downstream adaption. To this end, we propose Emergent Communication for
Embodied Control (EC^2), a novel scheme to pre-train video-language
representations for few-shot embodied control. The key idea is to learn an
unsupervised "language" of videos via emergent communication, which bridges the
semantics of video details and structures of natural language. We learn
embodied representations of video trajectories, emergent language, and natural
language using a language model, which is then used to finetune a lightweight
policy network for downstream control. Through extensive experiments in
Metaworld and Franka Kitchen embodied benchmarks, EC^2 is shown to consistently
outperform previous contrastive learning methods for both videos and texts as
task inputs. Further ablations confirm the importance of the emergent language,
which is beneficial for both video and language learning, and significantly
superior to using pre-trained video captions. We also present a quantitative
and qualitative analysis of the emergent language and discuss future directions
toward better understanding and leveraging emergent communication in embodied
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emotion fusion for mental illness detection from social media: A survey. (arXiv:2304.09493v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09493">
<div class="article-summary-box-inner">
<span><p>Mental illnesses are one of the most prevalent public health problems
worldwide, which negatively influence people's lives and society's health. With
the increasing popularity of social media, there has been a growing research
interest in the early detection of mental illness by analysing user-generated
posts on social media. According to the correlation between emotions and mental
illness, leveraging and fusing emotion information has developed into a
valuable research topic. In this article, we provide a comprehensive survey of
approaches to mental illness detection in social media that incorporate emotion
fusion. We begin by reviewing different fusion strategies, along with their
advantages and disadvantages. Subsequently, we discuss the major challenges
faced by researchers working in this area, including issues surrounding the
availability and quality of datasets, the performance of algorithms and
interpretability. We additionally suggest some potential directions for future
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controlling keywords and their positions in text generation. (arXiv:2304.09516v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09516">
<div class="article-summary-box-inner">
<span><p>One of the challenges in text generation is to control generation as intended
by a user. Previous studies have proposed to specify the keywords that should
be included in the generated text. However, this is insufficient to generate
text which reflect the user intent. For example, placing the important keyword
beginning of the text would helps attract the reader's attention, but existing
methods do not enable such flexible control. In this paper, we tackle a novel
task of controlling not only keywords but also the position of each keyword in
the text generation. To this end, we show that a method using special tokens
can control the relative position of keywords. Experimental results on
summarization and story generation tasks show that the proposed method can
control keywords and their positions. We also demonstrate that controlling the
keyword positions can generate summary texts that are closer to the user's
intent than baseline. We release our code.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent. (arXiv:2304.09542v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09542">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have demonstrated a remarkable ability to
generalize zero-shot to various language-related tasks. This paper focuses on
the study of exploring generative LLMs such as ChatGPT and GPT-4 for relevance
ranking in Information Retrieval (IR). Surprisingly, our experiments reveal
that properly instructed ChatGPT and GPT-4 can deliver competitive, even
superior results than supervised methods on popular IR benchmarks. Notably,
GPT-4 outperforms the fully fine-tuned monoT5-3B on MS MARCO by an average of
2.7 nDCG on TREC datasets, an average of 2.3 nDCG on eight BEIR datasets, and
an average of 2.7 nDCG on ten low-resource languages Mr.TyDi. Subsequently, we
delve into the potential for distilling the ranking capabilities of ChatGPT
into a specialized model. Our small specialized model that trained on 10K
ChatGPT generated data outperforms monoT5 trained on 400K annotated MS MARCO
data on BEIR. The code to reproduce our results is available at
www.github.com/sunnweiwei/RankGPT
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SemEval 2023 Task 6: LegalEval -- Understanding Legal Texts. (arXiv:2304.09548v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09548">
<div class="article-summary-box-inner">
<span><p>In populous countries, pending legal cases have been growing exponentially.
There is a need for developing NLP-based techniques for processing and
automatically understanding legal documents. To promote research in the area of
Legal NLP we organized the shared task LegalEval - Understanding Legal Texts at
SemEval 2023. LegalEval task has three sub-tasks: Task-A (Rhetorical Roles
Labeling) is about automatically structuring legal documents into semantically
coherent units, Task-B (Legal Named Entity Recognition) deals with identifying
relevant entities in a legal document and Task-C (Court Judgement Prediction
with Explanation) explores the possibility of automatically predicting the
outcome of a legal case along with providing an explanation for the prediction.
In total 26 teams (approx. 100 participants spread across the world) submitted
systems paper. In each of the sub-tasks, the proposed systems outperformed the
baselines; however, there is a lot of scope for improvement. This paper
describes the tasks, and analyzes techniques proposed by various teams.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Robustness of Aspect-based Sentiment Analysis: Rethinking Model, Data, and Training. (arXiv:2304.09563v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09563">
<div class="article-summary-box-inner">
<span><p>Aspect-based sentiment analysis (ABSA) aims at automatically inferring the
specific sentiment polarities toward certain aspects of products or services
behind the social media texts or reviews, which has been a fundamental
application to the real-world society. Since the early 2010s, ABSA has achieved
extraordinarily high accuracy with various deep neural models. However,
existing ABSA models with strong in-house performances may fail to generalize
to some challenging cases where the contexts are variable, i.e., low robustness
to real-world environments. In this study, we propose to enhance the ABSA
robustness by systematically rethinking the bottlenecks from all possible
angles, including model, data, and training. First, we strengthen the current
best-robust syntax-aware models by further incorporating the rich external
syntactic dependencies and the labels with aspect simultaneously with a
universal-syntax graph convolutional network. In the corpus perspective, we
propose to automatically induce high-quality synthetic training data with
various types, allowing models to learn sufficient inductive bias for better
robustness. Last, we based on the rich pseudo data perform adversarial training
to enhance the resistance to the context perturbation and meanwhile employ
contrastive learning to reinforce the representations of instances with
contrastive sentiments. Extensive robustness evaluations are conducted. The
results demonstrate that our enhanced syntax-aware model achieves better
robustness performances than all the state-of-the-art baselines. By
additionally incorporating our synthetic corpus, the robust testing results are
pushed with around 10% accuracy, which are then further improved by installing
the advanced training strategies. In-depth analyses are presented for revealing
the factors influencing the ABSA robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is ChatGPT Equipped with Emotional Dialogue Capabilities?. (arXiv:2304.09582v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09582">
<div class="article-summary-box-inner">
<span><p>This report presents a study on the emotional dialogue capability of ChatGPT,
an advanced language model developed by OpenAI. The study evaluates the
performance of ChatGPT on emotional dialogue understanding and generation
through a series of experiments on several downstream tasks. Our findings
indicate that while ChatGPT's performance on emotional dialogue understanding
may still lag behind that of supervised models, it exhibits promising results
in generating emotional responses. Furthermore, the study suggests potential
avenues for future research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CB-Conformer: Contextual biasing Conformer for biased word recognition. (arXiv:2304.09607v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09607">
<div class="article-summary-box-inner">
<span><p>Due to the mismatch between the source and target domains, how to better
utilize the biased word information to improve the performance of the automatic
speech recognition model in the target domain becomes a hot research topic.
Previous approaches either decode with a fixed external language model or
introduce a sizeable biasing module, which leads to poor adaptability and slow
inference. In this work, we propose CB-Conformer to improve biased word
recognition by introducing the Contextual Biasing Module and the Self-Adaptive
Language Model to vanilla Conformer. The Contextual Biasing Module combines
audio fragments and contextual information, with only 0.2% model parameters of
the original Conformer. The Self-Adaptive Language Model modifies the internal
weights of biased words based on their recall and precision, resulting in a
greater focus on biased words and more successful integration with the
automatic speech recognition model than the standard fixed language model. In
addition, we construct and release an open-source Mandarin biased-word dataset
based on WenetSpeech. Experiments indicate that our proposed method brings a
15.34% character error rate reduction, a 14.13% biased word recall increase,
and a 6.80% biased word F1-score increase compared with the base Conformer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bridging Natural Language Processing and Psycholinguistics: computationally grounded semantic similarity and relatedness datasets for Basque and Spanish. (arXiv:2304.09616v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09616">
<div class="article-summary-box-inner">
<span><p>We present a computationally-grounded word similarity dataset based on two
well-known Natural Language Processing resources; text corpora and knowledge
bases. This dataset aims to fulfil a gap in psycholinguistic research by
providing a variety of quantifications of semantic similarity in an extensive
set of noun pairs controlled by variables that play a significant role in
lexical processing. The dataset creation has consisted in three steps, 1)
computing four key psycholinguistic features for each noun; concreteness,
frequency, semantic and phonological neighbourhood density; 2) pairing nouns
across these four variables; 3) for each noun pair, assigning three types of
word similarity measurements, computed out of text, Wordnet and hybrid
embeddings. The present dataset includes noun pairs' information in Basque and
European Spanish, but further work intends to extend it to more languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BRENT: Bidirectional Retrieval Enhanced Norwegian Transformer. (arXiv:2304.09649v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09649">
<div class="article-summary-box-inner">
<span><p>Retrieval-based language models are increasingly employed in
question-answering tasks. These models search in a corpus of documents for
relevant information instead of having all factual knowledge stored in its
parameters, thereby enhancing efficiency, transparency, and adaptability. We
develop the first Norwegian retrieval-based model by adapting the REALM
framework and evaluating it on various tasks. After training, we also separate
the language model, which we call the reader, from the retriever components,
and show that this can be fine-tuned on a range of downstream tasks. Results
show that retrieval augmented language modeling improves the reader's
performance on extractive question-answering, suggesting that this type of
training improves language models' general ability to use context and that this
does not happen at the expense of other abilities such as part-of-speech
tagging, dependency parsing, named entity recognition, and lemmatization. Code,
trained models, and data are made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MPMQA: Multimodal Question Answering on Product Manuals. (arXiv:2304.09660v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09660">
<div class="article-summary-box-inner">
<span><p>Visual contents, such as illustrations and images, play a big role in product
manual understanding. Existing Product Manual Question Answering (PMQA)
datasets tend to ignore visual contents and only retain textual parts. In this
work, to emphasize the importance of multimodal contents, we propose a
Multimodal Product Manual Question Answering (MPMQA) task. For each question,
MPMQA requires the model not only to process multimodal contents but also to
provide multimodal answers. To support MPMQA, a large-scale dataset PM209 is
constructed with human annotations, which contains 209 product manuals from 27
well-known consumer electronic brands. Human annotations include 6 types of
semantic regions for manual contents and 22,021 pairs of question and answer.
Especially, each answer consists of a textual sentence and related visual
regions from manuals. Taking into account the length of product manuals and the
fact that a question is always related to a small number of pages, MPMQA can be
naturally split into two subtasks: retrieving most related pages and then
generating multimodal answers. We further propose a unified model that can
perform these two subtasks all together and achieve comparable performance with
multiple task-specific models. The PM209 dataset is available at
https://github.com/AIM3-RUC/MPMQA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GeneGPT: Teaching Large Language Models to Use NCBI Web APIs. (arXiv:2304.09667v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09667">
<div class="article-summary-box-inner">
<span><p>In this paper, we present GeneGPT, a novel method for teaching large language
models (LLMs) to use the Web Application Programming Interfaces (APIs) of the
National Center for Biotechnology Information (NCBI) and answer genomics
questions. Specifically, we prompt Codex (code-davinci-002) to solve the
GeneTuring tests with few-shot URL requests of NCBI API calls as demonstrations
for in-context learning. During inference, we stop the decoding once a call
request is detected and make the API call with the generated URL. We then
append the raw execution results returned by NCBI APIs to the generated texts
and continue the generation until the answer is found or another API call is
detected. Our preliminary results show that GeneGPT achieves state-of-the-art
results on three out of four one-shot tasks and four out of five zero-shot
tasks in the GeneTuring dataset. Overall, GeneGPT achieves a macro-average
score of 0.76, which is much higher than retrieval-augmented LLMs such as the
New Bing (0.44), biomedical LLMs such as BioMedLM (0.08) and BioGPT (0.04), as
well as other LLMs such as GPT-3 (0.16) and ChatGPT (0.12).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Progressive-Hint Prompting Improves Reasoning in Large Language Models. (arXiv:2304.09797v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09797">
<div class="article-summary-box-inner">
<span><p>The performance of Large Language Models (LLMs) in reasoning tasks depends
heavily on prompt design, with Chain-of-Thought (CoT) and self-consistency
being critical methods that enhance this ability. However, these methods do not
fully exploit the answers generated by the LLM to guide subsequent responses.
This paper proposes a new prompting method, named Progressive-Hint Prompting
(PHP), that enables automatic multiple interactions between users and LLMs by
using previously generated answers as hints to progressively guide toward the
correct answers. PHP is orthogonal to CoT and self-consistency, making it easy
to combine with state-of-the-art techniques to further improve performance. We
conducted an extensive and comprehensive evaluation to demonstrate the
effectiveness of the proposed method. Our experimental results on six
benchmarks show that combining CoT and self-consistency with PHP significantly
improves accuracy while remaining highly efficient. For instance, with
text-davinci-003, we observed a 4.2% improvement on GSM8K with greedy decoding
compared to Complex CoT, and a 46.17% reduction in sample paths with
self-consistency. With GPT-4 and PHP, we achieve state-of-the-art performances
on SVAMP (91.9%), GSM8K (95.5%) and AQuA (79.9%).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Corpora for Germanic Low-Resource Languages and Dialects. (arXiv:2304.09805v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09805">
<div class="article-summary-box-inner">
<span><p>Despite much progress in recent years, the vast majority of work in natural
language processing (NLP) is on standard languages with many speakers. In this
work, we instead focus on low-resource languages and in particular
non-standardized low-resource languages. Even within branches of major language
families, often considered well-researched, little is known about the extent
and type of available resources and what the major NLP challenges are for these
language varieties. The first step to address this situation is a systematic
survey of available corpora (most importantly, annotated corpora, which are
particularly valuable for NLP research). Focusing on Germanic low-resource
language varieties, we provide such a survey in this paper. Except for
geolocation (origin of speaker or document), we find that manually annotated
linguistic resources are sparse and, if they exist, mostly cover morphosyntax.
Despite this lack of resources, we observe that interest in this area is
increasing: there is active development and a growing research community. To
facilitate research, we make our overview of over 80 corpora publicly
available. We share a companion website of this overview at
https://github.com/mainlp/germanic-lrl-corpora .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Two-Stage Framework with Self-Supervised Distillation For Cross-Domain Text Classification. (arXiv:2304.09820v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09820">
<div class="article-summary-box-inner">
<span><p>Cross-domain text classification aims to adapt models to a target domain that
lacks labeled data. It leverages or reuses rich labeled data from the different
but related source domain(s) and unlabeled data from the target domain. To this
end, previous work focuses on either extracting domain-invariant features or
task-agnostic features, ignoring domain-aware features that may be present in
the target domain and could be useful for the downstream task. In this paper,
we propose a two-stage framework for cross-domain text classification. In the
first stage, we finetune the model with mask language modeling (MLM) and
labeled data from the source domain. In the second stage, we further fine-tune
the model with self-supervised distillation (SSD) and unlabeled data from the
target domain. We evaluate its performance on a public cross-domain text
classification benchmark and the experiment results show that our method
achieves new state-of-the-art results for both single-source domain adaptations
(94.17% $\uparrow$1.03%) and multi-source domain adaptations (95.09%
$\uparrow$1.34%).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fairness in AI and Its Long-Term Implications on Society. (arXiv:2304.09826v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09826">
<div class="article-summary-box-inner">
<span><p>Successful deployment of artificial intelligence (AI) in various settings has
led to numerous positive outcomes for individuals and society. However, AI
systems have also been shown to harm parts of the population due to biased
predictions. We take a closer look at AI fairness and analyse how lack of AI
fairness can lead to deepening of biases over time and act as a social
stressor. If the issues persist, it could have undesirable long-term
implications on society, reinforced by interactions with other risks. We
examine current strategies for improving AI fairness, assess their limitations
in terms of real-world deployment, and explore potential paths forward to
ensure we reap AI's benefits without harming significant parts of the society.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models. (arXiv:2304.09842v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09842">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have achieved remarkable progress in various
natural language processing tasks with emergent abilities. However, they face
inherent limitations, such as an inability to access up-to-date information,
utilize external tools, or perform precise mathematical reasoning. In this
paper, we introduce Chameleon, a plug-and-play compositional reasoning
framework that augments LLMs to help address these challenges. Chameleon
synthesizes programs to compose various tools, including LLM models,
off-the-shelf vision models, web search engines, Python functions, and
rule-based modules tailored to user interests. Built on top of an LLM as a
natural language planner, Chameleon infers the appropriate sequence of tools to
compose and execute in order to generate a final response. We showcase the
adaptability and effectiveness of Chameleon on two tasks: ScienceQA and TabMWP.
Notably, Chameleon with GPT-4 achieves an 86.54% accuracy on ScienceQA,
significantly improving upon the best published few-shot model by 11.37%; using
GPT-4 as the underlying LLM, Chameleon achieves a 17.8% increase over the
state-of-the-art model, leading to a 98.78% overall accuracy on TabMWP. Further
studies suggest that using GPT-4 as a planner exhibits more consistent and
rational tool selection and is able to infer potential constraints given the
instructions, compared to other LLMs like ChatGPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Verifiability in Generative Search Engines. (arXiv:2304.09848v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09848">
<div class="article-summary-box-inner">
<span><p>Generative search engines directly generate responses to user queries, along
with in-line citations. A prerequisite trait of a trustworthy generative search
engine is verifiability, i.e., systems should cite comprehensively (high
citation recall; all statements are fully supported by citations) and
accurately (high citation precision; every cite supports its associated
statement). We conduct human evaluation to audit four popular generative search
engines -- Bing Chat, NeevaAI, perplexity.ai, and YouChat -- across a diverse
set of queries from a variety of sources (e.g., historical Google user queries,
dynamically-collected open-ended questions on Reddit, etc.). We find that
responses from existing generative search engines are fluent and appear
informative, but frequently contain unsupported statements and inaccurate
citations: on average, a mere 51.5% of generated sentences are fully supported
by citations and only 74.5% of citations support their associated sentence. We
believe that these results are concerningly low for systems that may serve as a
primary tool for information-seeking users, especially given their facade of
trustworthiness. We hope that our results further motivate the development of
trustworthy generative search engines and help researchers and users better
understand the shortcomings of existing commercial systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PMC-Patients: A Large-scale Dataset of Patient Summaries and Relations for Benchmarking Retrieval-based Clinical Decision Support Systems. (arXiv:2202.13876v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.13876">
<div class="article-summary-box-inner">
<span><p>Objective: Retrieval-based Clinical Decision Support (ReCDS) can aid clinical
workflow by providing relevant literature and similar patients for a given
patient. However, the development of ReCDS systems has been severely obstructed
by the lack of diverse patient collections and publicly available large-scale
patient-level annotation datasets. In this paper, we aim to define and
benchmark two ReCDS tasks: Patient-to-Article Retrieval (ReCDS-PAR) and
Patient-to-Patient Retrieval (ReCDS-PPR) using a novel dataset called
PMC-Patients. Methods: We extract patient summaries from PubMed Central
articles using simple heuristics and utilize the PubMed citation graph to
define patient-article relevance and patient-patient similarity. We also
implement and evaluate several ReCDS systems on the PMC-Patients benchmarks,
including sparse retrievers, dense retrievers, and nearest neighbor retrievers.
We conduct several case studies to show the clinical utility of PMC-Patients.
Results: PMC-Patients contains 167k patient summaries with 3.1M patient-article
relevance annotations and 293k patient-patient similarity annotations, which is
the largest-scale resource for ReCDS and also one of the largest patient
collections. Human evaluation and analysis show that PMC-Patients is a diverse
dataset with high-quality annotations. The evaluation of various ReCDS systems
shows that the PMC-Patients benchmark is challenging and calls for further
research. Conclusion: We present PMC-Patients, a large-scale, diverse, and
publicly available patient summary dataset with the largest-scale patient-level
relation annotations. Based on PMC-Patients, we formally define two benchmark
tasks for ReCDS systems and evaluate various existing retrieval methods.
PMC-Patients can largely facilitate methodology research on ReCDS systems and
shows real-world clinical utility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive language and vision learning of general fashion concepts. (arXiv:2204.03972v4 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.03972">
<div class="article-summary-box-inner">
<span><p>The steady rise of online shopping goes hand in hand with the development of
increasingly complex ML and NLP models. While most use cases are cast as
specialized supervised learning problems, we argue that practitioners would
greatly benefit from more transferable representations of products. In this
work, we build on recent developments in contrastive learning to train
FashionCLIP, a CLIP-like model for the fashion industry. We showcase its
capabilities for retrieval, classification and grounding, and release our model
and code to the community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CodeAttack: Code-Based Adversarial Attacks for Pre-trained Programming Language Models. (arXiv:2206.00052v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.00052">
<div class="article-summary-box-inner">
<span><p>Pre-trained programming language (PL) models (such as CodeT5, CodeBERT,
GraphCodeBERT, etc.,) have the potential to automate software engineering tasks
involving code understanding and code generation. However, these models operate
in the natural channel of code, i.e., they are primarily concerned with the
human understanding of the code. They are not robust to changes in the input
and thus, are potentially susceptible to adversarial attacks in the natural
channel. We propose, CodeAttack, a simple yet effective black-box attack model
that uses code structure to generate effective, efficient, and imperceptible
adversarial code samples and demonstrates the vulnerabilities of the
state-of-the-art PL models to code-specific adversarial attacks. We evaluate
the transferability of CodeAttack on several code-code (translation and repair)
and code-NL (summarization) tasks across different programming languages.
CodeAttack outperforms state-of-the-art adversarial NLP attack models to
achieve the best overall drop in performance while being more efficient,
imperceptible, consistent, and fluent. The code can be found at
https://github.com/reddy-lab-code-research/CodeAttack.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discourse-Aware Graph Networks for Textual Logical Reasoning. (arXiv:2207.01450v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.01450">
<div class="article-summary-box-inner">
<span><p>Textual logical reasoning, especially question-answering (QA) tasks with
logical reasoning, requires awareness of particular logical structures. The
passage-level logical relations represent entailment or contradiction between
propositional units (e.g., a concluding sentence). However, such structures are
unexplored as current QA systems focus on entity-based relations. In this work,
we propose logic structural-constraint modeling to solve the logical reasoning
QA and introduce discourse-aware graph networks (DAGNs). The networks first
construct logic graphs leveraging in-line discourse connectives and generic
logic theories, then learn logic representations by end-to-end evolving the
logic relations with an edge-reasoning mechanism and updating the graph
features. This pipeline is applied to a general encoder, whose fundamental
features are joined with the high-level logic features for answer prediction.
Experiments on three textual logical reasoning datasets demonstrate the
reasonability of the logical structures built in DAGNs and the effectiveness of
the learned logic features. Moreover, zero-shot transfer results show the
features' generality to unseen logical texts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Code Translation with Compiler Representations. (arXiv:2207.03578v4 [cs.PL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.03578">
<div class="article-summary-box-inner">
<span><p>In this paper, we leverage low-level compiler intermediate representations
(IR) to improve code translation. Traditional transpilers rely on syntactic
information and handcrafted rules, which limits their applicability and
produces unnatural-looking code. Applying neural machine translation (NMT)
approaches to code has successfully broadened the set of programs on which one
can get a natural-looking translation. However, they treat the code as
sequences of text tokens, and still do not differentiate well enough between
similar pieces of code which have different semantics in different languages.
The consequence is low quality translation, reducing the practicality of NMT,
and stressing the need for an approach significantly increasing its accuracy.
Here we propose to augment code translation with IRs, specifically LLVM IR,
with results on the C++, Java, Rust, and Go languages. Our method improves upon
the state of the art for unsupervised code translation, increasing the number
of correct translations by 11% on average, and up to 79% for the Java -&gt; Rust
pair with greedy decoding. With beam search, it increases the number of correct
translations by 5.5% in average. We extend previous test sets for code
translation, by adding hundreds of Go and Rust functions. Additionally, we
train models with high performance on the problem of IR decompilation,
generating programming source code from IR, and study using IRs as intermediary
pivot for translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COLO: A Contrastive Learning based Re-ranking Framework for One-Stage Summarization. (arXiv:2209.14569v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.14569">
<div class="article-summary-box-inner">
<span><p>Traditional training paradigms for extractive and abstractive summarization
systems always only use token-level or sentence-level training objectives.
However, the output summary is always evaluated from summary-level which leads
to the inconsistency in training and evaluation. In this paper, we propose a
Contrastive Learning based re-ranking framework for one-stage summarization
called COLO. By modeling a contrastive objective, we show that the
summarization model is able to directly generate summaries according to the
summary-level score without additional modules and parameters. Extensive
experiments demonstrate that COLO boosts the extractive and abstractive results
of one-stage systems on CNN/DailyMail benchmark to 44.58 and 46.33 ROUGE-1
score while preserving the parameter efficiency and inference efficiency.
Compared with state-of-the-art multi-stage systems, we save more than 100 GPU
training hours and obtaining 3~8 speed-up ratio during inference while
maintaining comparable results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fighting FIRe with FIRE: Assessing the Validity of Text-to-Video Retrieval Benchmarks. (arXiv:2210.05038v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.05038">
<div class="article-summary-box-inner">
<span><p>Searching troves of videos with textual descriptions is a core multimodal
retrieval task. Owing to the lack of a purpose-built dataset for text-to-video
retrieval, video captioning datasets have been re-purposed to evaluate models
by (1) treating captions as positive matches to their respective videos and (2)
assuming all other videos to be negatives. However, this methodology leads to a
fundamental flaw during evaluation: since captions are marked as relevant only
to their original video, many alternate videos also match the caption, which
introduces false-negative caption-video pairs. We show that when these false
negatives are corrected, a recent state-of-the-art model gains 25\% recall
points -- a difference that threatens the validity of the benchmark itself. To
diagnose and mitigate this issue, we annotate and release 683K additional
caption-video pairs. Using these, we recompute effectiveness scores for three
models on two standard benchmarks (MSR-VTT and MSVD). We find that (1) the
recomputed metrics are up to 25\% recall points higher for the best models, (2)
these benchmarks are nearing saturation for Recall@10, (3) caption length
(generality) is related to the number of positives, and (4) annotation costs
can be mitigated through sampling. We recommend retiring these benchmarks in
their current form, and we make recommendations for future text-to-video
retrieval benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DyLoRA: Parameter Efficient Tuning of Pre-trained Models using Dynamic Search-Free Low-Rank Adaptation. (arXiv:2210.07558v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07558">
<div class="article-summary-box-inner">
<span><p>With the ever-growing size of pretrained models (PMs), fine-tuning them has
become more expensive and resource-hungry. As a remedy, low-rank adapters
(LoRA) keep the main pretrained weights of the model frozen and just introduce
some learnable truncated SVD modules (so-called LoRA blocks) to the model.
While LoRA blocks are parameter-efficient, they suffer from two major problems:
first, the size of these blocks is fixed and cannot be modified after training
(for example, if we need to change the rank of LoRA blocks, then we need to
re-train them from scratch); second, optimizing their rank requires an
exhaustive search and effort. In this work, we introduce a dynamic low-rank
adaptation (DyLoRA) technique to address these two problems together. Our
DyLoRA method trains LoRA blocks for a range of ranks instead of a single rank
by sorting the representation learned by the adapter module at different ranks
during training. We evaluate our solution on different natural language
understanding (GLUE benchmark) and language generation tasks (E2E, DART and
WebNLG) using different pretrained models such as RoBERTa and GPT with
different sizes. Our results show that we can train dynamic search-free models
with DyLoRA at least 4 to 7 times (depending to the task) faster than LoRA
without significantly compromising performance. Moreover, our models can
perform consistently well on a much larger range of ranks compared to LoRA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InferEM: Inferring the Speaker's Intention for Empathetic Dialogue Generation. (arXiv:2212.06373v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.06373">
<div class="article-summary-box-inner">
<span><p>Current approaches to empathetic response generation typically encode the
entire dialogue history directly and put the output into a decoder to generate
friendly feedback. These methods focus on modelling contextual information but
neglect capturing the direct intention of the speaker. We argue that the last
utterance in the dialogue empirically conveys the intention of the speaker.
Consequently, we propose a novel model named InferEM for empathetic response
generation. We separately encode the last utterance and fuse it with the entire
dialogue through the multi-head attention based intention fusion module to
capture the speaker's intention. Besides, we utilize previous utterances to
predict the last utterance, which simulates human's psychology to guess what
the interlocutor may speak in advance. To balance the optimizing rates of the
utterance prediction and response generation, a multi-task learning strategy is
designed for InferEM. Experimental results demonstrate the plausibility and
validity of InferEM in improving empathetic expression.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge. (arXiv:2303.14070v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.14070">
<div class="article-summary-box-inner">
<span><p>Recent large language models (LLMs) in the general domain, such as ChatGPT,
have shown remarkable success in following instructions and producing
human-like responses. However, such language models have yet to be adapted for
the medical domain, resulting in poor accuracy of responses and an inability to
provide sound advice on medical diagnoses, medications, etc. To address this
problem, we fine-tuned our ChatDoctor model based on 100k real-world
patient-physician conversations from an online medical consultation site.
Besides, we add autonomous knowledge retrieval capabilities to our ChatDoctor,
for example, Wikipedia or a disease database as a knowledge brain. By
fine-tuning the LLMs using these 100k patient-physician conversations, our
model showed significant improvements in understanding patients' needs and
providing informed advice. The autonomous ChatDoctor model based on Wikipedia
and Database Brain can access real-time and authoritative information and
answer patient questions based on this information, significantly improving the
accuracy of the model's responses, which shows extraordinary potential for the
medical field with a low tolerance for error. To facilitate the further
development of dialogue models in the medical field, we make available all
source code, datasets, and model weights available at:
https://github.com/Kent0n-Li/ChatDoctor.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inductive Relation Prediction from Relational Paths and Context with Hierarchical Transformers. (arXiv:2304.00215v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.00215">
<div class="article-summary-box-inner">
<span><p>Relation prediction on knowledge graphs (KGs) is a key research topic.
Dominant embedding-based methods mainly focus on the transductive setting and
lack the inductive ability to generalize to new entities for inference.
Existing methods for inductive reasoning mostly mine the connections between
entities, i.e., relational paths, without considering the nature of head and
tail entities contained in the relational context. This paper proposes a novel
method that captures both connections between entities and the intrinsic nature
of entities, by simultaneously aggregating RElational Paths and cOntext with a
unified hieRarchical Transformer framework, namely REPORT. REPORT relies solely
on relation semantics and can naturally generalize to the fully-inductive
setting, where KGs for training and inference have no common entities. In the
experiments, REPORT performs consistently better than all baselines on almost
all the eight version subsets of two fully-inductive datasets. Moreover. REPORT
is interpretable by providing each element's contribution to the prediction
results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPT detectors are biased against non-native English writers. (arXiv:2304.02819v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.02819">
<div class="article-summary-box-inner">
<span><p>The rapid adoption of generative language models has brought about
substantial advancements in digital communication, while simultaneously raising
concerns regarding the potential misuse of AI-generated content. Although
numerous detection methods have been proposed to differentiate between AI and
human-generated content, the fairness and robustness of these detectors remain
underexplored. In this study, we evaluate the performance of several
widely-used GPT detectors using writing samples from native and non-native
English writers. Our findings reveal that these detectors consistently
misclassify non-native English writing samples as AI-generated, whereas native
writing samples are accurately identified. Furthermore, we demonstrate that
simple prompting strategies can not only mitigate this bias but also
effectively bypass GPT detectors, suggesting that GPT detectors may
unintentionally penalize writers with constrained linguistic expressions. Our
results call for a broader conversation about the ethical implications of
deploying ChatGPT content detectors and caution against their use in evaluative
or educational settings, particularly when they may inadvertently penalize or
exclude non-native English speakers from the global discourse.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models. (arXiv:2304.03738v2 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.03738">
<div class="article-summary-box-inner">
<span><p>As the capabilities of generative language models continue to advance, the
implications of biases ingrained within these models have garnered increasing
attention from researchers, practitioners, and the broader public. This article
investigates the challenges and risks associated with biases in large-scale
language models like ChatGPT. We discuss the origins of biases, stemming from,
among others, the nature of training data, model specifications, algorithmic
constraints, product design, and policy decisions. We explore the ethical
concerns arising from the unintended consequences of biased model outputs. We
further analyze the potential opportunities to mitigate biases, the
inevitability of some biases, and the implications of deploying these models in
various applications, such as virtual assistants, content generation, and
chatbots. Finally, we review the current approaches to identify, quantify, and
mitigate biases in language models, emphasizing the need for a
multi-disciplinary, collaborative effort to develop more equitable,
transparent, and responsible AI systems. This article aims to stimulate a
thoughtful dialogue within the artificial intelligence community, encouraging
researchers and developers to reflect on the role of biases in generative
language models and the ongoing pursuit of ethical AI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PDFVQA: A New Dataset for Real-World VQA on PDF Documents. (arXiv:2304.06447v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.06447">
<div class="article-summary-box-inner">
<span><p>Document-based Visual Question Answering examines the document understanding
of document images in conditions of natural language questions. We proposed a
new document-based VQA dataset, PDF-VQA, to comprehensively examine the
document understanding from various aspects, including document element
recognition, document layout structural understanding as well as contextual
understanding and key information extraction. Our PDF-VQA dataset extends the
current scale of document understanding that limits on the single document page
to the new scale that asks questions over the full document of multiple pages.
We also propose a new graph-based VQA model that explicitly integrates the
spatial and hierarchically structural relationships between different document
elements to boost the document structural understanding. The performances are
compared with several baselines over different question types and
tasks\footnote{The full dataset will be released after paper acceptance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sabi\'a: Portuguese Large Language Models. (arXiv:2304.07880v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07880">
<div class="article-summary-box-inner">
<span><p>As the capabilities of language models continue to advance, it is conceivable
that "one-size-fits-all" model will remain as the main paradigm. For instance,
given the vast number of languages worldwide, many of which are low-resource,
the prevalent practice is to pretrain a single model on multiple languages. In
this paper, we add to the growing body of evidence that challenges this
practice, demonstrating that monolingual pretraining on the target language
significantly improves models already extensively trained on diverse corpora.
More specifically, we further pretrain GPT-J and LLaMA models on Portuguese
texts using 3% or less of their original pretraining budget. Few-shot
evaluations on Poeta, a suite of 14 Portuguese datasets, reveal that our models
outperform English-centric and multilingual counterparts by a significant
margin. Our best model, Sabi\'a-65B, performs on par with GPT-3.5-turbo. By
evaluating on datasets originally conceived in the target language as well as
translated ones, we study the contributions of language-specific pretraining in
terms of 1) capturing linguistic nuances and structures inherent to the target
language, and 2) enriching the model's knowledge about a domain or culture. Our
results indicate that the majority of the benefits stem from the
domain-specific knowledge acquired through monolingual pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speaker Profiling in Multiparty Conversations. (arXiv:2304.08801v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.08801">
<div class="article-summary-box-inner">
<span><p>In conversational settings, individuals exhibit unique behaviors, rendering a
one-size-fits-all approach insufficient for generating responses by dialogue
agents. Although past studies have aimed to create personalized dialogue agents
using speaker persona information, they have relied on the assumption that the
speaker's persona is already provided. However, this assumption is not always
valid, especially when it comes to chatbots utilized in industries like
banking, hotel reservations, and airline bookings. This research paper aims to
fill this gap by exploring the task of Speaker Profiling in Conversations
(SPC). The primary objective of SPC is to produce a summary of persona
characteristics for each individual speaker present in a dialogue. To
accomplish this, we have divided the task into three subtasks: persona
discovery, persona-type identification, and persona-value extraction. Given a
dialogue, the first subtask aims to identify all utterances that contain
persona information. Subsequently, the second task evaluates these utterances
to identify the type of persona information they contain, while the third
subtask identifies the specific persona values for each identified type. To
address the task of SPC, we have curated a new dataset named SPICE, which comes
with specific labels. We have evaluated various baselines on this dataset and
benchmarked it with a new neural model, SPOT, which we introduce in this paper.
Furthermore, we present a comprehensive analysis of SPOT, examining the
limitations of individual modules both quantitatively and qualitatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting the Role of Similarity and Dissimilarity in Best Counter Argument Retrieval. (arXiv:2304.08807v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.08807">
<div class="article-summary-box-inner">
<span><p>This paper studies the task of best counter-argument retrieval given an input
argument. Following the definition that the best counter-argument addresses the
same aspects as the input argument while having the opposite stance, we aim to
develop an efficient and effective model for scoring counter-arguments based on
similarity and dissimilarity metrics. We first conduct an experimental study on
the effectiveness of available scoring methods, including traditional
Learning-To-Rank (LTR) and recent neural scoring models. We then propose
Bipolar-encoder, a novel BERT-based model to learn an optimal representation
for simultaneous similarity and dissimilarity. Experimental results show that
our proposed method can achieve the accuracy@1 of 49.04\%, which significantly
outperforms other baselines by a large margin. When combined with an
appropriate caching technique, Bipolar-encoder is comparably efficient at
prediction time.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-04-20 23:11:56.892610405 UTC">2023-04-20 23:11:56 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>