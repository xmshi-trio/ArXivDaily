<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-07-03T01:30:00Z">07-03</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Empowering NLG: Offline Reinforcement Learning for Informal Summarization in Online Domains. (arXiv:2306.17174v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17174">
<div class="article-summary-box-inner">
<span><p>Our research introduces an innovative Natural Language Generation (NLG)
approach that aims to optimize user experience and alleviate the workload of
human customer support agents. Our primary objective is to generate informal
summaries for online articles and posts using an offline reinforcement learning
technique. In our study, we compare our proposed method with existing
approaches to text generation and provide a comprehensive overview of our
architectural design, which incorporates crawling, reinforcement learning, and
text generation modules. By presenting this original approach, our paper makes
a valuable contribution to the field of NLG by offering a fresh perspective on
generating natural language summaries for online content. Through the
implementation of Empowering NLG, we are able to generate higher-quality
replies in the online domain. The experimental results demonstrate a
significant improvement in the average "like" score, increasing from 0.09954378
to 0.5000152. This advancement has the potential to enhance the efficiency and
effectiveness of customer support services and elevate the overall user
experience when consuming online content.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RECAP-KG: Mining Knowledge Graphs from Raw GP Notes for Remote COVID-19 Assessment in Primary Care. (arXiv:2306.17175v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17175">
<div class="article-summary-box-inner">
<span><p>Clinical decision-making is a fundamental stage in delivering appropriate
care to patients. In recent years several decision-making systems designed to
aid the clinician in this process have been developed. However, technical
solutions currently in use are based on simple regression models and are only
able to take into account simple pre-defined multiple-choice features, such as
patient age, pre-existing conditions, smoker status, etc. One particular source
of patient data, that available decision-making systems are incapable of
processing is the collection of patient consultation GP notes. These contain
crucial signs and symptoms - the information used by clinicians in order to
make a final decision and direct the patient to the appropriate care.
Extracting information from GP notes is a technically challenging problem, as
they tend to include abbreviations, typos, and incomplete sentences.
</p>
<p>This paper addresses this open challenge. We present a framework that
performs knowledge graph construction from raw GP medical notes written during
or after patient consultations. By relying on support phrases mined from the
SNOMED ontology, as well as predefined supported facts from values used in the
RECAP (REmote COVID-19 Assessment in Primary Care) patient risk prediction
tool, our graph generative framework is able to extract structured knowledge
graphs from the highly unstructured and inconsistent format that consultation
notes are written in. Our knowledge graphs include information about existing
patient symptoms, their duration, and their severity.
</p>
<p>We apply our framework to consultation notes of COVID-19 patients in the UK
COVID-19 Clinical Assesment Servcie (CCAS) patient dataset. We provide a
quantitative evaluation of the performance of our framework, demonstrating that
our approach has better accuracy than traditional NLP methods when answering
questions about patients.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">News Verifiers Showdown: A Comparative Performance Evaluation of ChatGPT 3.5, ChatGPT 4.0, Bing AI, and Bard in News Fact-Checking. (arXiv:2306.17176v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17176">
<div class="article-summary-box-inner">
<span><p>This study aimed to evaluate the proficiency of prominent Large Language
Models (LLMs), namely OpenAI's ChatGPT 3.5 and 4.0, Google's Bard(LaMDA), and
Microsoft's Bing AI in discerning the truthfulness of news items using black
box testing. A total of 100 fact-checked news items, all sourced from
independent fact-checking agencies, were presented to each of these LLMs under
controlled conditions. Their responses were classified into one of three
categories: True, False, and Partially True/False. The effectiveness of the
LLMs was gauged based on the accuracy of their classifications against the
verified facts provided by the independent agencies. The results showed a
moderate proficiency across all models, with an average score of 65.25 out of
100. Among the models, OpenAI's GPT-4.0 stood out with a score of 71,
suggesting an edge in newer LLMs' abilities to differentiate fact from
deception. However, when juxtaposed against the performance of human
fact-checkers, the AI models, despite showing promise, lag in comprehending the
subtleties and contexts inherent in news information. The findings highlight
the potential of AI in the domain of fact-checking while underscoring the
continued importance of human cognitive skills and the necessity for persistent
advancements in AI capabilities. Finally, the experimental data produced from
the simulation of this work is openly available on Kaggle.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging ChatGPT As Text Annotation Tool For Sentiment Analysis. (arXiv:2306.17177v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17177">
<div class="article-summary-box-inner">
<span><p>Sentiment analysis is a well-known natural language processing task that
involves identifying the emotional tone or polarity of a given piece of text.
With the growth of social media and other online platforms, sentiment analysis
has become increasingly crucial for businesses and organizations seeking to
monitor and comprehend customer feedback as well as opinions. Supervised
learning algorithms have been popularly employed for this task, but they
require human-annotated text to create the classifier. To overcome this
challenge, lexicon-based tools have been used. A drawback of lexicon-based
algorithms is their reliance on pre-defined sentiment lexicons, which may not
capture the full range of sentiments in natural language. ChatGPT is a new
product of OpenAI and has emerged as the most popular AI product. It can answer
questions on various topics and tasks. This study explores the use of ChatGPT
as a tool for data labeling for different sentiment analysis tasks. It is
evaluated on two distinct sentiment analysis datasets with varying purposes.
The results demonstrate that ChatGPT outperforms other lexicon-based
unsupervised methods with significant improvements in overall accuracy.
Specifically, compared to the best-performing lexical-based algorithms, ChatGPT
achieves a remarkable increase in accuracy of 20% for the tweets dataset and
approximately 25% for the Amazon reviews dataset. These findings highlight the
exceptional performance of ChatGPT in sentiment analysis tasks, surpassing
existing lexicon-based approaches by a significant margin. The evidence
suggests it can be used for annotation on different sentiment analysis events
and taskss.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Replace and Report: NLP Assisted Radiology Report Generation. (arXiv:2306.17180v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17180">
<div class="article-summary-box-inner">
<span><p>Clinical practice frequently uses medical imaging for diagnosis and
treatment. A significant challenge for automatic radiology report generation is
that the radiology reports are long narratives consisting of multiple sentences
for both abnormal and normal findings. Therefore, applying conventional image
captioning approaches to generate the whole report proves to be insufficient,
as these are designed to briefly describe images with short sentences. We
propose a template-based approach to generate radiology reports from
radiographs. Our approach involves the following: i) using a multilabel image
classifier, produce the tags for the input radiograph; ii) using a
transformer-based model, generate pathological descriptions (a description of
abnormal findings seen on radiographs) from the tags generated in step (i);
iii) using a BERT-based multi-label text classifier, find the spans in the
normal report template to replace with the generated pathological descriptions;
and iv) using a rule-based system, replace the identified span with the
generated pathological description. We performed experiments with the two most
popular radiology report datasets, IU Chest X-ray and MIMIC-CXR and
demonstrated that the BLEU-1, ROUGE-L, METEOR, and CIDEr scores are better than
the State-of-the-Art models by 25%, 36%, 44% and 48% respectively, on the IU
X-RAY dataset. To the best of our knowledge, this is the first attempt to
generate chest X-ray radiology reports by first creating small sentences for
abnormal findings and then replacing them in the normal report template.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Text Embedding Space Generation Using Generative Adversarial Networks for Text Synthesis. (arXiv:2306.17181v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17181">
<div class="article-summary-box-inner">
<span><p>Generative Adversarial Networks (GAN) is a model for data synthesis, which
creates plausible data through the competition of generator and discriminator.
Although GAN application to image synthesis is extensively studied, it has
inherent limitations to natural language generation. Because natural language
is composed of discrete tokens, a generator has difficulty updating its
gradient through backpropagation; therefore, most text-GAN studies generate
sentences starting with a random token based on a reward system. Thus, the
generators of previous studies are pre-trained in an autoregressive way before
adversarial training, causing data memorization that synthesized sentences
reproduce the training data. In this paper, we synthesize sentences using a
framework similar to the original GAN. More specifically, we propose Text
Embedding Space Generative Adversarial Networks (TESGAN) which generate
continuous text embedding spaces instead of discrete tokens to solve the
gradient backpropagation problem. Furthermore, TESGAN conducts unsupervised
learning which does not directly refer to the text of the training data to
overcome the data memorization issue. By adopting this novel method, TESGAN can
synthesize new sentences, showing the potential of unsupervised learning for
text synthesis. We expect to see extended research combining Large Language
Models with a new perspective of viewing text as an continuous space.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Why can neural language models solve next-word prediction? A mathematical perspective. (arXiv:2306.17184v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17184">
<div class="article-summary-box-inner">
<span><p>Recently, deep learning has revolutionized the field of natural language
processing, with neural language models proving to be very effective for
next-word prediction. However, a rigorous theoretical explanation for their
success in the context of formal language theory has not yet been developed, as
it is unclear why neural language models can learn the combinatorial rules that
govern the next-word prediction task. In this paper, we study a class of formal
languages that can be used to model real-world examples of English sentences.
We construct neural language models can solve the next-word prediction task in
this context with zero error. Our proof highlights the different roles of the
embedding layer and the fully connected component within the neural language
model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Exploitability of Instruction Tuning. (arXiv:2306.17194v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17194">
<div class="article-summary-box-inner">
<span><p>Instruction tuning is an effective technique to align large language models
(LLMs) with human intents. In this work, we investigate how an adversary can
exploit instruction tuning by injecting specific instruction-following examples
into the training data that intentionally changes the model's behavior. For
example, an adversary can achieve content injection by injecting training
examples that mention target content and eliciting such behavior from
downstream models. To achieve this goal, we propose \textit{AutoPoison}, an
automated data poisoning pipeline. It naturally and coherently incorporates
versatile attack goals into poisoned data with the help of an oracle LLM. We
showcase two example attacks: content injection and over-refusal attacks, each
aiming to induce a specific exploitable behavior. We quantify and benchmark the
strength and the stealthiness of our data poisoning scheme. Our results show
that AutoPoison allows an adversary to change a model's behavior by poisoning
only a small fraction of data while maintaining a high level of stealthiness in
the poisoned examples. We hope our work sheds light on how data quality affects
the behavior of instruction-tuned models and raises awareness of the importance
of data quality for responsible deployments of LLMs. Code is available at
\url{https://github.com/azshue/AutoPoison}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Multilingual Expressive Speech Representation for Prosody Prediction without Parallel Data. (arXiv:2306.17199v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17199">
<div class="article-summary-box-inner">
<span><p>We propose a method for speech-to-speech emotionpreserving translation that
operates at the level of discrete speech units. Our approach relies on the use
of multilingual emotion embedding that can capture affective information in a
language-independent manner. We show that this embedding can be used to predict
the pitch and duration of speech units in a target language, allowing us to
resynthesize the source speech signal with the same emotional content. We
evaluate our approach to English and French speech signals and show that it
outperforms a baseline method that does not use emotional information,
including when the emotion embedding is extracted from a different language.
Even if this preliminary study does not address directly the machine
translation issue, our results demonstrate the effectiveness of our approach
for cross-lingual emotion preservation in the context of speech resynthesis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Personalized Cold-Start Recommendation with Prompts. (arXiv:2306.17256v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17256">
<div class="article-summary-box-inner">
<span><p>Recommender systems play a crucial role in helping users discover information
that aligns with their interests based on their past behaviors. However,
developing personalized recommendation systems becomes challenging when
historical records of user-item interactions are unavailable, leading to what
is known as the system cold-start recommendation problem. This issue is
particularly prominent in start-up businesses or platforms with insufficient
user engagement history. Previous studies focus on user or item cold-start
scenarios, where systems could make recommendations for new users or items but
are still trained with historical user-item interactions in the same domain,
which cannot solve our problem. To bridge the gap, our research introduces an
innovative and effective approach, capitalizing on the capabilities of
pre-trained language models. We transform the recommendation process into
sentiment analysis of natural languages containing information of user profiles
and item attributes, where the sentiment polarity is predicted with prompt
learning. By harnessing the extensive knowledge housed within language models,
the prediction can be made without historical user-item interaction records. A
benchmark is also introduced to evaluate the proposed method under the
cold-start setting, and the results demonstrate the effectiveness of our
method. To the best of our knowledge, this is the first study to tackle the
system cold-start recommendation problem. The benchmark and implementation of
the method are available at https://github.com/JacksonWuxs/PromptRec.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prediction of COVID-19 Patients' Emergency Room Revisit using Multi-Source Transfer Learning. (arXiv:2306.17257v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17257">
<div class="article-summary-box-inner">
<span><p>The coronavirus disease 2019 (COVID-19) has led to a global pandemic of
significant severity. In addition to its high level of contagiousness, COVID-19
can have a heterogeneous clinical course, ranging from asymptomatic carriers to
severe and potentially life-threatening health complications. Many patients
have to revisit the emergency room (ER) within a short time after discharge,
which significantly increases the workload for medical staff. Early
identification of such patients is crucial for helping physicians focus on
treating life-threatening cases. In this study, we obtained Electronic Health
Records (EHRs) of 3,210 encounters from 13 affiliated ERs within the University
of Pittsburgh Medical Center between March 2020 and January 2021. We leveraged
a Natural Language Processing technique, ScispaCy, to extract clinical concepts
and used the 1001 most frequent concepts to develop 7-day revisit models for
COVID-19 patients in ERs. The research data we collected from 13 ERs may have
distributional differences that could affect the model development. To address
this issue, we employed a classic deep transfer learning method called the
Domain Adversarial Neural Network (DANN) and evaluated different modeling
strategies, including the Multi-DANN algorithm, the Single-DANN algorithm, and
three baseline methods. Results showed that the Multi-DANN models outperformed
the Single-DANN models and baseline models in predicting revisits of COVID-19
patients to the ER within 7 days after discharge. Notably, the Multi-DANN
strategy effectively addressed the heterogeneity among multiple source domains
and improved the adaptation of source data to the target domain. Moreover, the
high performance of Multi-DANN models indicates that EHRs are informative for
developing a prediction model to identify COVID-19 patients who are very likely
to revisit an ER within 7 days after discharge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Open-Domain Topic Classification. (arXiv:2306.17290v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17290">
<div class="article-summary-box-inner">
<span><p>We introduce an open-domain topic classification system that accepts
user-defined taxonomy in real time. Users will be able to classify a text
snippet with respect to any candidate labels they want, and get instant
response from our web interface. To obtain such flexibility, we build the
backend model in a zero-shot way. By training on a new dataset constructed from
Wikipedia, our label-aware text classifier can effectively utilize implicit
knowledge in the pretrained language model to handle labels it has never seen
before. We evaluate our model across four datasets from various domains with
different label sets. Experiments show that the model significantly improves
over existing zero-shot baselines in open-domain scenarios, and performs
competitively with weakly-supervised models trained on in-domain data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Citations as Queries: Source Attribution Using Language Models as Rerankers. (arXiv:2306.17322v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17322">
<div class="article-summary-box-inner">
<span><p>This paper explores new methods for locating the sources used to write a
text, by fine-tuning a variety of language models to rerank candidate sources.
After retrieving candidates sources using a baseline BM25 retrieval model, a
variety of reranking methods are tested to see how effective they are at the
task of source attribution. We conduct experiments on two datasets, English
Wikipedia and medieval Arabic historical writing, and employ a variety of
retrieval and generation based reranking models. In particular, we seek to
understand how the degree of supervision required affects the performance of
various reranking models. We find that semisupervised methods can be nearly as
effective as fully supervised methods while avoiding potentially costly
span-level annotation of the target and source documents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SummQA at MEDIQA-Chat 2023:In-Context Learning with GPT-4 for Medical Summarization. (arXiv:2306.17384v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17384">
<div class="article-summary-box-inner">
<span><p>Medical dialogue summarization is challenging due to the unstructured nature
of medical conversations, the use of medical terminology in gold summaries, and
the need to identify key information across multiple symptom sets. We present a
novel system for the Dialogue2Note Medical Summarization tasks in the MEDIQA
2023 Shared Task. Our approach for section-wise summarization (Task A) is a
two-stage process of selecting semantically similar dialogues and using the
top-k similar dialogues as in-context examples for GPT-4. For full-note
summarization (Task B), we use a similar solution with k=1. We achieved 3rd
place in Task A (2nd among all teams), 4th place in Task B Division Wise
Summarization (2nd among all teams), 15th place in Task A Section Header
Classification (9th among all teams), and 8th place among all teams in Task B.
Our results highlight the effectiveness of few-shot prompting for this task,
though we also identify several weaknesses of prompting-based approaches. We
compare GPT-4 performance with several finetuned baselines. We find that GPT-4
summaries are more abstractive and shorter. We make our code publicly
available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Japanese Lexical Complexity for Non-Native Readers: A New Dataset. (arXiv:2306.17399v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17399">
<div class="article-summary-box-inner">
<span><p>Lexical complexity prediction (LCP) is the task of predicting the complexity
of words in a text on a continuous scale. It plays a vital role in simplifying
or annotating complex words to assist readers. To study lexical complexity in
Japanese, we construct the first Japanese LCP dataset. Our dataset provides
separate complexity scores for Chinese/Korean annotators and others to address
the readers' L1-specific needs. In the baseline experiment, we demonstrate the
effectiveness of a BERT-based system for Japanese LCP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection. (arXiv:2306.17408v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17408">
<div class="article-summary-box-inner">
<span><p>As malicious actors employ increasingly advanced and widespread bots to
disseminate misinformation and manipulate public opinion, the detection of
Twitter bots has become a crucial task. Though graph-based Twitter bot
detection methods achieve state-of-the-art performance, we find that their
inference depends on the neighbor users multi-hop away from the targets, and
fetching neighbors is time-consuming and may introduce bias. At the same time,
we find that after finetuning on Twitter bot detection, pretrained language
models achieve competitive performance and do not require a graph structure
during deployment. Inspired by this finding, we propose a novel bot detection
framework LMBot that distills the knowledge of graph neural networks (GNNs)
into language models (LMs) for graph-less deployment in Twitter bot detection
to combat the challenge of data dependency. Moreover, LMBot is compatible with
graph-based and graph-less datasets. Specifically, we first represent each user
as a textual sequence and feed them into the LM for domain adaptation. For
graph-based datasets, the output of LMs provides input features for the GNN,
enabling it to optimize for bot detection and distill knowledge back to the LM
in an iterative, mutually enhancing process. Armed with the LM, we can perform
graph-less inference, which resolves the graph data dependency and sampling
bias issues. For datasets without graph structure, we simply replace the GNN
with an MLP, which has also shown strong performance. Our experiments
demonstrate that LMBot achieves state-of-the-art performance on four Twitter
bot detection benchmarks. Extensive studies also show that LMBot is more
robust, versatile, and efficient compared to graph-based Twitter bot detection
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Provable Robust Watermarking for AI-Generated Text. (arXiv:2306.17439v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17439">
<div class="article-summary-box-inner">
<span><p>As AI-generated text increasingly resembles human-written content, the
ability to detect machine-generated text becomes crucial. To address this
challenge, we present GPTWatermark, a robust and high-quality solution designed
to ascertain whether a piece of text originates from a specific model. Our
approach extends existing watermarking strategies and employs a fixed group
design to enhance robustness against editing and paraphrasing attacks. We show
that our watermarked language model enjoys strong provable guarantees on
generation quality, correctness in detection, and security against evasion
attacks. Experimental results on various large language models (LLMs) and
diverse datasets demonstrate that our method achieves superior detection
accuracy and comparable generation quality in perplexity, thus promoting the
responsible use of LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Progressive Multi-task Learning Framework for Chinese Text Error Correction. (arXiv:2306.17447v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17447">
<div class="article-summary-box-inner">
<span><p>Chinese Text Error Correction (CTEC) aims to detect and correct errors in the
input text, which benefits human's daily life and various downstream tasks.
Recent approaches mainly employ Pre-trained Language Models (PLMs) to resolve
CTEC task and achieve tremendous success. However, previous approaches suffer
from issues of over-correction and under-correction, and the former is
especially conspicuous in the precision-critical CTEC task. To mitigate the
issue of overcorrection, we propose a novel model-agnostic progressive
multitask learning framework for CTEC, named ProTEC, which guides a CTEC model
to learn the task from easy to difficult. We divide CTEC task into three
sub-tasks from easy to difficult: Error Detection, Error Type Identification,
and Correction Result Generation. During the training process, ProTEC guides
the model to learn text error correction progressively by incorporating these
sub-tasks into a multi-task training objective. During the inference process,
the model completes these sub-tasks in turn to generate the correction results.
Extensive experiments and detailed analyses fully demonstrate the effectiveness
and efficiency of our proposed framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Harnessing LLMs in Curricular Design: Using GPT-4 to Support Authoring of Learning Objectives. (arXiv:2306.17459v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17459">
<div class="article-summary-box-inner">
<span><p>We evaluated the capability of a generative pre-trained transformer (GPT-4)
to automatically generate high-quality learning objectives (LOs) in the context
of a practically oriented university course on Artificial Intelligence.
Discussions of opportunities (e.g., content generation, explanation) and risks
(e.g., cheating) of this emerging technology in education have intensified, but
to date there has not been a study of the models' capabilities in supporting
the course design and authoring of LOs. LOs articulate the knowledge and skills
learners are intended to acquire by engaging with a course. To be effective,
LOs must focus on what students are intended to achieve, focus on specific
cognitive processes, and be measurable. Thus, authoring high-quality LOs is a
challenging and time consuming (i.e., expensive) effort. We evaluated 127 LOs
that were automatically generated based on a carefully crafted prompt (detailed
guidelines on high-quality LOs authoring) submitted to GPT-4 for conceptual
modules and projects of an AI Practitioner course. We analyzed the generated
LOs if they follow certain best practices such as beginning with action verbs
from Bloom's taxonomy in regards to the level of sophistication intended. Our
analysis showed that the generated LOs are sensible, properly expressed (e.g.,
starting with an action verb), and that they largely operate at the appropriate
level of Bloom's taxonomy, respecting the different nature of the conceptual
modules (lower levels) and projects (higher levels). Our results can be
leveraged by instructors and curricular designers wishing to take advantage of
the state-of-the-art generative models to support their curricular and course
design efforts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Base Completion for Long-Tail Entities. (arXiv:2306.17472v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17472">
<div class="article-summary-box-inner">
<span><p>Despite their impressive scale, knowledge bases (KBs), such as Wikidata,
still contain significant gaps. Language models (LMs) have been proposed as a
source for filling these gaps. However, prior works have focused on prominent
entities with rich coverage by LMs, neglecting the crucial case of long-tail
entities. In this paper, we present a novel method for LM-based-KB completion
that is specifically geared for facts about long-tail entities. The method
leverages two different LMs in two stages: for candidate retrieval and for
candidate verification and disambiguation. To evaluate our method and various
baselines, we introduce a novel dataset, called MALT, rooted in Wikidata. Our
method outperforms all baselines in F1, with major gains especially in recall.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Preference Ranking Optimization for Human Alignment. (arXiv:2306.17492v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17492">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) often contain misleading content, emphasizing
the need to align them with human values to ensure secur AI systems.
Reinforcement learning from human feedback (RLHF) has been employed to achieve
this alignment by combining a reward model, typically based on Bradley-Terry
paired comparison, with an RL algorithm such as Proximal Policy Optimization
(PPO) to optimize LLM responses. However, RLHF exhibits complexity,
instability, and sensitivity to hyperparameters. In this paper, we propose
Preference Ranking Optimization (PRO) as an alternative to PPO for directly
aligning LLMs with the Bradley-Terry comparison. PRO extends the pairwise
Bradley-Terry comparison to accommodate preference rankings of any length. By
iteratively contrasting the likelihood of generating responses, PRO instructs
the LLM to prioritize the best response while progressively ranking the
remaining responses. In this manner, PRO effectively transforms human alignment
into aligning the probability ranking of $n$ responses generated by LLM with
the preference ranking of humans towards these responses. Experiments have
shown that PRO outperforms existing alignment algorithms, achieving comparable
results to ChatGPT and human responses through automatic-based, reward-based,
GPT-4, and human evaluations. Furthermore, we demonstrate that longer, more
diverse, and higher-quality preference ranking sequences can consistently
enhance the performance of human alignment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models. (arXiv:2306.17519v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17519">
<div class="article-summary-box-inner">
<span><p>Relation extraction (RE) is a crucial task in natural language processing
(NLP) that aims to identify and classify relationships between entities
mentioned in text. In the financial domain, relation extraction plays a vital
role in extracting valuable information from financial documents, such as news
articles, earnings reports, and company filings. This paper describes our
solution to relation extraction on one such dataset REFinD. The dataset was
released along with shared task as a part of the Fourth Workshop on Knowledge
Discovery from Unstructured Data in Financial Services, co-located with SIGIR
2023. In this paper, we employed OpenAI models under the framework of
in-context learning (ICL). We utilized two retrieval strategies to find top K
relevant in-context learning demonstrations / examples from training data for a
given test example. The first retrieval mechanism, we employed, is a
learning-free dense retriever and the other system is a learning-based
retriever. We were able to achieve 4th rank on the leaderboard. Our best
F1-score is 0.718.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards the extraction of robust sign embeddings for low resource sign language recognition. (arXiv:2306.17558v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17558">
<div class="article-summary-box-inner">
<span><p>Isolated Sign Language Recognition (SLR) has mostly been applied on
relatively large datasets containing signs executed slowly and clearly by a
limited group of signers. In real-world scenarios, however, we are met with
challenging visual conditions, coarticulated signing, small datasets, and the
need for signer independent models. To tackle this difficult problem, we
require a robust feature extractor to process the sign language videos. One
could expect human pose estimators to be ideal candidates. However, due to a
domain mismatch with their training sets and challenging poses in sign
language, they lack robustness on sign language data and image based models
often still outperform keypoint based models. Furthermore, whereas the common
practice of transfer learning with image based models yields even higher
accuracy, keypoint based models are typically trained from scratch on every SLR
dataset. These factors limit their usefulness for SLR. From the existing
literature, it is also not clear which, if any, pose estimator performs best
for SLR. We compare the three most popular pose estimators for SLR: OpenPose,
MMPose and MediaPipe. We show that through keypoint normalization, missing
keypoint imputation, and learning a pose embedding, we can obtain significantly
better results and enable transfer learning. We show that keypoint-based
embeddings contain cross-lingual features: they can transfer between sign
languages and achieve competitive performance even when fine-tuning only the
classifier layer of an SLR model on a target sign language. We furthermore
achieve better performance using fine-tuned transferred embeddings than models
trained only on the target sign language. The application of these embeddings
could prove particularly useful for low resource sign languages in the future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting. (arXiv:2306.17563v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17563">
<div class="article-summary-box-inner">
<span><p>Ranking documents using Large Language Models (LLMs) by directly feeding the
query and candidate documents into the prompt is an interesting and practical
problem. However, there has been limited success so far, as researchers have
found it difficult to outperform fine-tuned baseline rankers on benchmark
datasets. We analyze pointwise and listwise ranking prompts used by existing
methods and argue that off-the-shelf LLMs do not fully understand these ranking
formulations, possibly due to the nature of how LLMs are trained. In this
paper, we propose to significantly reduce the burden on LLMs by using a new
technique called Pairwise Ranking Prompting (PRP). Our results are the first in
the literature to achieve state-of-the-art ranking performance on standard
benchmarks using moderate-sized open-sourced LLMs. On TREC-DL2020, PRP based on
the Flan-UL2 model with 20B parameters outperforms the previous best approach
in the literature, which is based on the blackbox commercial GPT-4 that has 50x
(estimated) model size, by over 5% at NDCG@1. On TREC-DL2019, PRP is only
inferior to the GPT-4 solution on the NDCG@5 and NDCG@10 metrics, while
outperforming other existing solutions, such as InstructGPT which has 175B
parameters, by over 10% for nearly all ranking metrics. Furthermore, we propose
several variants of PRP to improve efficiency and show that it is possible to
achieve competitive results even with linear complexity. We also discuss other
benefits of PRP, such as supporting both generation and scoring LLM APIs, as
well as being insensitive to input ordering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Cost-aware Study of Depression Language on Social Media using Topic and Affect Contextualization. (arXiv:2306.17564v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17564">
<div class="article-summary-box-inner">
<span><p>Depression is a growing issue in society's mental health that affects all
areas of life and can even lead to suicide. Fortunately, prevention programs
can be effective in its treatment. In this context, this work proposes an
automatic system for detecting depression on social media based on machine
learning and natural language processing methods. This paper presents the
following contributions: (i) an ensemble learning system that combines several
types of text representations for depression detection, including recent
advances in the field; (ii) a contextualization schema through topic and
affective information; (iii) an analysis of models' energy consumption,
establishing a trade-off between classification performance and overall
computational costs. To assess the proposed models' effectiveness, a thorough
evaluation is performed in two datasets that model depressive text. Experiments
indicate that the proposed contextualization strategies can improve the
classification and that approaches that use Transformers can improve the
overall F-score by 2% while augmenting the energy cost a hundred times.
Finally, this work paves the way for future energy-wise systems by considering
both the performance classification and the energy consumption.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Augmenting Holistic Review in University Admission using Natural Language Processing for Essays and Recommendation Letters. (arXiv:2306.17575v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17575">
<div class="article-summary-box-inner">
<span><p>University admission at many highly selective institutions uses a holistic
review process, where all aspects of the application, including protected
attributes (e.g., race, gender), grades, essays, and recommendation letters are
considered, to compose an excellent and diverse class. In this study, we
empirically evaluate how influential protected attributes are for predicting
admission decisions using a machine learning (ML) model, and in how far textual
information (e.g., personal essay, teacher recommendation) may substitute for
the loss of protected attributes in the model. Using data from 14,915
applicants to an undergraduate admission office at a selective U.S. institution
in the 2022-2023 cycle, we find that the exclusion of protected attributes from
the ML model leads to substantially reduced admission-prediction performance.
The inclusion of textual information via both a TF-IDF representation and a
Latent Dirichlet allocation (LDA) model partially restores model performance,
but does not appear to provide a full substitute for admitting a similarly
diverse class. In particular, while the text helps with gender diversity, the
proportion of URM applicants is severely impacted by the exclusion of protected
attributes, and the inclusion of new attributes generated from the textual
information does not recover this performance loss.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT for Robotics: Design Principles and Model Abilities. (arXiv:2306.17582v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17582">
<div class="article-summary-box-inner">
<span><p>This paper presents an experimental study regarding the use of OpenAI's
ChatGPT for robotics applications. We outline a strategy that combines design
principles for prompt engineering and the creation of a high-level function
library which allows ChatGPT to adapt to different robotics tasks, simulators,
and form factors. We focus our evaluations on the effectiveness of different
prompt engineering techniques and dialog strategies towards the execution of
various types of robotics tasks. We explore ChatGPT's ability to use free-form
dialog, parse XML tags, and to synthesize code, in addition to the use of
task-specific prompting functions and closed-loop reasoning through dialogues.
Our study encompasses a range of tasks within the robotics domain, from basic
logical, geometrical, and mathematical reasoning all the way to complex domains
such as aerial navigation, manipulation, and embodied agents. We show that
ChatGPT can be effective at solving several of such tasks, while allowing users
to interact with it primarily via natural language instructions. In addition to
these studies, we introduce an open-sourced research tool called PromptCraft,
which contains a platform where researchers can collaboratively upload and vote
on examples of good prompting schemes for robotics applications, as well as a
sample robotics simulator with ChatGPT integration, making it easier for users
to get started with using ChatGPT for robotics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feature Representation Learning for NL2SQL Generation Based on Coupling and Decoupling. (arXiv:2306.17646v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17646">
<div class="article-summary-box-inner">
<span><p>The NL2SQL task involves parsing natural language statements into SQL
queries. While most state-of-the-art methods treat NL2SQL as a slot-filling
task and use feature representation learning techniques, they overlook explicit
correlation features between the SELECT and WHERE clauses and implicit
correlation features between sub-tasks within a single clause. To address this
issue, we propose the Clause Feature Correlation Decoupling and Coupling
(CFCDC) model, which uses a feature representation decoupling method to
separate the SELECT and WHERE clauses at the parameter level. Next, we
introduce a multi-task learning architecture to decouple implicit correlation
feature representation between different SQL tasks in a specific clause.
Moreover, we present an improved feature representation coupling module to
integrate the decoupled tasks in the SELECT and WHERE clauses and predict the
final SQL query. Our proposed CFCDC model demonstrates excellent performance on
the WikiSQL dataset, with significant improvements in logic precision and
execution accuracy. The source code for the model will be publicly available on
GitHub
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Biomedical Language Models are Robust to Sub-optimal Tokenization. (arXiv:2306.17649v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17649">
<div class="article-summary-box-inner">
<span><p>As opposed to general English, many concepts in biomedical terminology have
been designed in recent history by biomedical professionals with the goal of
being precise and concise. This is often achieved by concatenating meaningful
biomedical morphemes to create new semantic units. Nevertheless, most modern
biomedical language models (LMs) are pre-trained using standard domain-specific
tokenizers derived from large scale biomedical corpus statistics without
explicitly leveraging the agglutinating nature of biomedical language. In this
work, we first find that standard open-domain and biomedical tokenizers are
largely unable to segment biomedical terms into meaningful components.
Therefore, we hypothesize that using a tokenizer which segments biomedical
terminology more accurately would enable biomedical LMs to improve their
performance on downstream biomedical NLP tasks, especially ones which involve
biomedical terms directly such as named entity recognition (NER) and entity
linking. Surprisingly, we find that pre-training a biomedical LM using a more
accurate biomedical tokenizer does not improve the entity representation
quality of a language model as measured by several intrinsic and extrinsic
measures such as masked language modeling prediction (MLM) accuracy as well as
NER and entity linking performance. These quantitative findings, along with a
case study which explores entity representation quality more directly, suggest
that the biomedical pre-training process is quite robust to instances of
sub-optimal tokenization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">X-RiSAWOZ: High-Quality End-to-End Multilingual Dialogue Datasets and Few-shot Agents. (arXiv:2306.17674v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17674">
<div class="article-summary-box-inner">
<span><p>Task-oriented dialogue research has mainly focused on a few popular languages
like English and Chinese, due to the high dataset creation cost for a new
language. To reduce the cost, we apply manual editing to automatically
translated data. We create a new multilingual benchmark, X-RiSAWOZ, by
translating the Chinese RiSAWOZ to 4 languages: English, French, Hindi, Korean;
and a code-mixed English-Hindi language. X-RiSAWOZ has more than 18,000
human-verified dialogue utterances for each language, and unlike most
multilingual prior work, is an end-to-end dataset for building
fully-functioning agents.
</p>
<p>The many difficulties we encountered in creating X-RiSAWOZ led us to develop
a toolset to accelerate the post-editing of a new language dataset after
translation. This toolset improves machine translation with a hybrid entity
alignment technique that combines neural with dictionary-based methods, along
with many automated and semi-automated validation checks.
</p>
<p>We establish strong baselines for X-RiSAWOZ by training dialogue agents in
the zero- and few-shot settings where limited gold data is available in the
target language. Our results suggest that our translation and post-editing
methodology and toolset can be used to create new high-quality multilingual
dialogue agents cost-effectively. Our dataset, code, and toolkit are released
open-source.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Task and Dataset on Detecting Attacks on Human Rights Defenders. (arXiv:2306.17695v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17695">
<div class="article-summary-box-inner">
<span><p>The ability to conduct retrospective analyses of attacks on human rights
defenders over time and by location is important for humanitarian organizations
to better understand historical or ongoing human rights violations and thus
better manage the global impact of such events. We hypothesize that NLP can
support such efforts by quickly processing large collections of news articles
to detect and summarize the characteristics of attacks on human rights
defenders. To that end, we propose a new dataset for detecting Attacks on Human
Rights Defenders (HRDsAttack) consisting of crowdsourced annotations on 500
online news articles. The annotations include fine-grained information about
the type and location of the attacks, as well as information about the
victim(s). We demonstrate the usefulness of the dataset by using it to train
and evaluate baseline models on several sub-tasks to predict the annotated
characteristics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Neural-on-Neural Approaches to Speaker Gender Protection. (arXiv:2306.17700v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17700">
<div class="article-summary-box-inner">
<span><p>Recent research has proposed approaches that modify speech to defend against
gender inference attacks. The goal of these protection algorithms is to control
the availability of information about a speaker's gender, a privacy-sensitive
attribute. Currently, the common practice for developing and testing gender
protection algorithms is "neural-on-neural", i.e., perturbations are generated
and tested with a neural network. In this paper, we propose to go beyond this
practice to strengthen the study of gender protection. First, we demonstrate
the importance of testing gender inference attacks that are based on speech
features historically developed by speech scientists, alongside the
conventionally used neural classifiers. Next, we argue that researchers should
use speech features to gain insight into how protective modifications change
the speech signal. Finally, we point out that gender-protection algorithms
should be compared with novel "vocal adversaries", human-executed voice
adaptations, in order to improve interpretability and enable before-the-mic
protection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved NL2SQL based on Multi-layer Expert Network. (arXiv:2306.17727v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17727">
<div class="article-summary-box-inner">
<span><p>The Natural Language to SQL (NL2SQL) technique is used to convert natural
language queries into executable SQL statements. Typically, slot-filling is
employed as a classification method for multi-task cases to achieve this goal.
However, slot-filling can result in inaccurate SQL statement generation due to
negative migration issues arising from different classification tasks. To
overcome this limitation, this study introduces a new approach called
Multi-Layer Expert Generate SQL (MLEG-SQL), which utilizes a dedicated
multi-task hierarchical network. The lower layer of the network extracts
semantic features of natural language statements, while the upper layer builds
a specialized expert system for handling specific classification tasks. This
hierarchical approach mitigates performance degradation resulting from
different task conflicts. The proposed method was evaluated on the WiKSQL
dataset and was found to be effective in generating accurate SQL statements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Token-Event-Role Structure-based Multi-Channel Document-Level Event Extraction. (arXiv:2306.17733v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17733">
<div class="article-summary-box-inner">
<span><p>Document-level event extraction is a long-standing challenging information
retrieval problem involving a sequence of sub-tasks: entity extraction, event
type judgment, and event type-specific multi-event extraction. However,
addressing the problem as multiple learning tasks leads to increased model
complexity. Also, existing methods insufficiently utilize the correlation of
entities crossing different events, resulting in limited event extraction
performance. This paper introduces a novel framework for document-level event
extraction, incorporating a new data structure called token-event-role and a
multi-channel argument role prediction module. The proposed data structure
enables our model to uncover the primary role of tokens in multiple events,
facilitating a more comprehensive understanding of event relationships. By
leveraging the multi-channel prediction module, we transform entity and
multi-event extraction into a single task of predicting token-event pairs,
thereby reducing the overall parameter size and enhancing model efficiency. The
results demonstrate that our approach outperforms the state-of-the-art method
by 9.5 percentage points in terms of the F1 score, highlighting its superior
performance in event extraction. Furthermore, an ablation study confirms the
significant value of the proposed data structure in improving event extraction
tasks, further validating its importance in enhancing the overall performance
of the framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Should you marginalize over possible tokenizations?. (arXiv:2306.17757v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17757">
<div class="article-summary-box-inner">
<span><p>Autoregressive language models (LMs) map token sequences to probabilities.
The usual practice for computing the probability of any character string (e.g.
English sentences) is to first transform it into a sequence of tokens that is
scored by the model. However, there are exponentially many token sequences that
represent any given string. To truly compute the probability of a string one
should marginalize over all tokenizations, which is typically intractable.
Here, we analyze whether the practice of ignoring the marginalization is
justified. To this end, we devise an importance-sampling-based algorithm that
allows us to compute estimates of the marginal probabilities and compare them
to the default procedure in a range of state-of-the-art models and datasets.
Our results show that the gap in log-likelihood is no larger than 0.5% in most
cases, but that it becomes more pronounced for data with long complex words.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Improving the Performance of Pre-Trained Speech Models for Low-Resource Languages Through Lateral Inhibition. (arXiv:2306.17792v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17792">
<div class="article-summary-box-inner">
<span><p>With the rise of bidirectional encoder representations from Transformer
models in natural language processing, the speech community has adopted some of
their development methodologies. Therefore, the Wav2Vec models were introduced
to reduce the data required to obtain state-of-the-art results. This work
leverages this knowledge and improves the performance of the pre-trained speech
models by simply replacing the fine-tuning dense layer with a lateral
inhibition layer inspired by the biological process. Our experiments on
Romanian, a low-resource language, show an average improvement of 12.5% word
error rate (WER) using the lateral inhibition layer. In addition, we obtain
state-of-the-art results on both the Romanian Speech Corpus and the Robin
Technical Acquisition Corpus with 1.78% WER and 29.64% WER, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stay on topic with Classifier-Free Guidance. (arXiv:2306.17806v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17806">
<div class="article-summary-box-inner">
<span><p>Classifier-Free Guidance (CFG) has recently emerged in text-to-image
generation as a lightweight technique to encourage prompt-adherence in
generations. In this work, we demonstrate that CFG can be used broadly as an
inference-time technique in pure language modeling. We show that CFG (1)
improves the performance of Pythia, GPT-2 and LLaMA-family models across an
array of tasks: Q\&amp;A, reasoning, code generation, and machine translation,
achieving SOTA on LAMBADA with LLaMA-7B over PaLM-540B; (2) brings improvements
equivalent to a model with twice the parameter-count; (3) can stack alongside
other inference-time methods like Chain-of-Thought and Self-Consistency,
yielding further improvements in difficult tasks; (4) can be used to increase
the faithfulness and coherence of assistants in challenging form-driven and
content-driven prompts: in a human evaluation we show a 75\% preference for
GPT4All using CFG over baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Massive Scale Semantic Similarity Dataset of Historical English. (arXiv:2306.17810v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17810">
<div class="article-summary-box-inner">
<span><p>A diversity of tasks use language models trained on semantic similarity data.
While there are a variety of datasets that capture semantic similarity, they
are either constructed from modern web data or are relatively small datasets
created in the past decade by human annotators. This study utilizes a novel
source, newly digitized articles from off-copyright, local U.S. newspapers, to
assemble a massive-scale semantic similarity dataset spanning 70 years from
1920 to 1989 and containing nearly 400M positive semantic similarity pairs.
Historically, around half of articles in U.S. local newspapers came from
newswires like the Associated Press. While local papers reproduced articles
from the newswire, they wrote their own headlines, which form abstractive
summaries of the associated articles. We associate articles and their headlines
by exploiting document layouts and language understanding. We then use deep
neural methods to detect which articles are from the same underlying source, in
the presence of substantial noise and abridgement. The headlines of reproduced
articles form positive semantic similarity pairs. The resulting publicly
available HEADLINES dataset is significantly larger than most existing semantic
similarity datasets and covers a much longer span of time. It will facilitate
the application of contrastively trained semantic similarity models to a
variety of tasks, including the study of semantic change across space and time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-Reasoning: Semantics-Symbol Deconstruction For Large Language Models. (arXiv:2306.17820v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17820">
<div class="article-summary-box-inner">
<span><p>Symbolization methods in large language models (LLMs) have been shown
effective to improve LLMs' reasoning ability. However, most of these approaches
hinge on mapping natural languages to formal languages (e.g., Python, SQL) that
are more syntactically complete and free of ambiguity. Although effective, they
depart from the natural language itself and deviate from the habits of human
thinking, and instead cater more to the execution mindset of computers. In
contrast, we hope to simplify natural language by starting from the concept of
symbols in linguistics itself, so that LLMs can learn the common formulation
and general solution of reasoning problems wrapped in different natural
semantics. From this consideration, we propose \textbf{Meta-Reasoning}, which
allows LLMs to automatically accomplish semantic-symbol deconstruction, i.e.,
semantic resolution, to maximally reduce different questions of certain
reasoning tasks to similar natural language representation, thus gaining the
ability to learn by analogy and facilitating data-efficient in-context
learning. Our experiments show that the Meta-Reasoning paradigm saliently
enhances LLMs' reasoning performance with fewer demonstrations. They can learn
not only reasoning chains but also general solutions to certain types of tasks.
In particular, for symbolic reasoning tasks, such as 7-step Tracking Shuffled
Objects, GPT-3 (text-davinci-002) achieves over 99% accuracy with only one
Meta-Reasoning demonstration, outperforming all current LLMs with the standard
chain-of-thought prompting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Statler: State-Maintaining Language Models for Embodied Reasoning. (arXiv:2306.17840v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17840">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) provide a promising tool that enable robots to
perform complex robot reasoning tasks. However, the limited context window of
contemporary LLMs makes reasoning over long time horizons difficult. Embodied
tasks such as those that one might expect a household robot to perform
typically require that the planner consider information acquired a long time
ago (e.g., properties of the many objects that the robot previously encountered
in the environment). Attempts to capture the world state using an LLM's
implicit internal representation is complicated by the paucity of task- and
environment-relevant information available in a robot's action history, while
methods that rely on the ability to convey information via the prompt to the
LLM are subject to its limited context window. In this paper, we propose
Statler, a framework that endows LLMs with an explicit representation of the
world state as a form of ``memory'' that is maintained over time. Integral to
Statler is its use of two instances of general LLMs -- a world-model reader and
a world-model writer -- that interface with and maintain the world state. By
providing access to this world state ``memory'', Statler improves the ability
of existing LLMs to reason over longer time horizons without the constraint of
context length. We evaluate the effectiveness of our approach on three
simulated table-top manipulation domains and a real robot domain, and show that
it improves the state-of-the-art in LLM-based robot reasoning. Project website:
https://statler-lm.github.io/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs. (arXiv:2306.17842v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17842">
<div class="article-summary-box-inner">
<span><p>In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling
frozen LLMs to perform both understanding and generation tasks involving
non-linguistic modalities such as images or videos. SPAE converts between raw
pixels and interpretable lexical tokens (or words) extracted from the LLM's
vocabulary. The resulting tokens capture both the semantic meaning and the
fine-grained details needed for visual reconstruction, effectively translating
the visual content into a language comprehensible to the LLM, and empowering it
to perform a wide array of multimodal tasks. Our approach is validated through
in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set
of image understanding and generation tasks. Our method marks the first
successful attempt to enable a frozen LLM to generate image content while
surpassing state-of-the-art performance in image understanding tasks, under the
same setting, by over 25%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Gender Fairness of Pre-Trained Language Models without Catastrophic Forgetting. (arXiv:2110.05367v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.05367">
<div class="article-summary-box-inner">
<span><p>Existing studies addressing gender bias of pre-trained language models,
usually build a small gender-neutral data set and conduct a second phase
pre-training on the model with such data. However, given the limited size and
concentrated focus of the gender-neutral data, catastrophic forgetting would
occur during second-phase pre-training. Forgetting information in the original
training data may damage the model's downstream performance by a large margin.
In this work, we empirically show that catastrophic forgetting occurs in such
methods by evaluating them with general NLP tasks in GLUE. Then, we propose a
new method, GEnder Equality Prompt (GEEP), to improve gender fairness of
pre-trained models with less forgetting. GEEP freezes the pre-trained model and
learns gender-related prompts with gender-neutral data. Empirical results show
that GEEP not only achieves SOTA performances on gender fairness tasks, but
also forgets less and performs better on GLUE by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conversational Question Answering on Heterogeneous Sources. (arXiv:2204.11677v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11677">
<div class="article-summary-box-inner">
<span><p>Conversational question answering (ConvQA) tackles sequential information
needs where contexts in follow-up questions are left implicit. Current ConvQA
systems operate over homogeneous sources of information: either a knowledge
base (KB), or a text corpus, or a collection of tables. This paper addresses
the novel issue of jointly tapping into all of these together, this way
boosting answer coverage and confidence. We present CONVINSE, an end-to-end
pipeline for ConvQA over heterogeneous sources, operating in three stages: i)
learning an explicit structured representation of an incoming question and its
conversational context, ii) harnessing this frame-like representation to
uniformly capture relevant evidences from KB, text, and tables, and iii)
running a fusion-in-decoder model to generate the answer. We construct and
release the first benchmark, ConvMix, for ConvQA over heterogeneous sources,
comprising 3000 real-user conversations with 16000 questions, along with entity
annotations, completed question utterances, and question paraphrases.
Experiments demonstrate the viability and advantages of our method, compared to
state-of-the-art baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers. (arXiv:2301.13741v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.13741">
<div class="article-summary-box-inner">
<span><p>Real-world data contains a vast amount of multimodal information, among which
vision and language are the two most representative modalities. Moreover,
increasingly heavier models, \textit{e}.\textit{g}., Transformers, have
attracted the attention of researchers to model compression. However, how to
compress multimodal models, especially vison-language Transformers, is still
under-explored. This paper proposes the \textbf{U}nified and
\textbf{P}r\textbf{o}gressive \textbf{P}runing (\textbf{\emph{UPop}}) as a
universal vison-language Transformer compression framework, which incorporates
1) unifiedly searching multimodal subnets in a continuous optimization space
from the original model, which enables automatic assignment of pruning ratios
among compressible modalities and structures; 2) progressively searching and
retraining the subnet, which maintains convergence between the search and
retrain to attain higher compression ratios. Experiments on various tasks,
datasets, and model architectures demonstrate the effectiveness and versatility
of the proposed UPop framework. The code is available at
https://github.com/sdc17/UPop.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Eliciting the Translation Ability of Large Language Models via Multilingual Finetuning with Translation Instructions. (arXiv:2305.15083v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15083">
<div class="article-summary-box-inner">
<span><p>Large-scale Pretrained Language Models (LLMs), such as ChatGPT and GPT4, have
shown strong abilities in multilingual translations, without being explicitly
trained on parallel corpora. It is interesting how the LLMs obtain their
ability to carry out translation instructions for different languages. In this
paper, we present a detailed analysis by finetuning a multilingual pretrained
language model, XGLM-7B, to perform multilingual translation following given
instructions. Firstly, we show that multilingual LLMs have stronger translation
abilities than previously demonstrated. For a certain language, the performance
depends on its similarity to English and the amount of data used in the
pretraining phase. Secondly, we find that LLMs' ability to carry out
translation instructions relies on the understanding of translation
instructions and the alignment among different languages. With multilingual
finetuning, LLMs could learn to perform the translation task well even for
those language pairs unseen during the instruction tuning phase.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Faithfulness Tests for Natural Language Explanations. (arXiv:2305.18029v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18029">
<div class="article-summary-box-inner">
<span><p>Explanations of neural models aim to reveal a model's decision-making process
for its predictions. However, recent work shows that current methods giving
explanations such as saliency maps or counterfactuals can be misleading, as
they are prone to present reasons that are unfaithful to the model's inner
workings. This work explores the challenging question of evaluating the
faithfulness of natural language explanations (NLEs). To this end, we present
two tests. First, we propose a counterfactual input editor for inserting
reasons that lead to counterfactual predictions but are not reflected by the
NLEs. Second, we reconstruct inputs from the reasons stated in the generated
NLEs and check how often they lead to the same predictions. Our tests can
evaluate emerging NLE models, proving a fundamental tool in the development of
faithful NLEs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering. (arXiv:2306.00526v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00526">
<div class="article-summary-box-inner">
<span><p>The pre-training-fine-tuning paradigm based on layout-aware multimodal
pre-trained models has achieved significant progress on document image question
answering. However, domain pre-training and task fine-tuning for additional
visual, layout, and task modules prevent them from directly utilizing
off-the-shelf instruction-tuning language foundation models, which have
recently shown promising potential in zero-shot learning. Contrary to aligning
language models to the domain of document image question answering, we align
document image question answering to off-the-shell instruction-tuning language
foundation models to utilize their zero-shot capability. Specifically, we
propose layout and task aware instruction prompt called LATIN-Prompt, which
consists of layout-aware document content and task-aware descriptions. The
former recovers the layout information among text segments from OCR tools by
appropriate spaces and line breaks. The latter ensures that the model generates
answers that meet the requirements, especially format requirements, through a
detailed description of task. Experimental results on three benchmarks show
that LATIN-Prompt can improve the zero-shot performance of instruction-tuning
language foundation models on document image question answering and help them
achieve comparable levels to SOTAs based on the pre-training-fine-tuning
paradigm. Quantitative analysis and qualitative analysis demonstrate the
effectiveness of LATIN-Prompt. We provide the code in supplementary and will
release the code to facilitate future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identity Construction in a Misogynist Incels Forum. (arXiv:2306.15745v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15745">
<div class="article-summary-box-inner">
<span><p>Online communities of involuntary celibates (incels) are a prominent source
of misogynist hate speech. In this paper, we use quantitative text and network
analysis approaches to examine how identity groups are discussed on
&lt;incels.is&gt;, the largest black-pilled incels forum. We find that this community
produces a wide range of novel identity terms and, while terms for women are
most common, mentions of other minoritized identities are increasing. An
analysis of the associations made with identity groups suggests an essentialist
ideology where physical appearance, as well as gender and racial hierarchies,
determine human value. We discuss implications for research into automated
misogynist hate speech detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors. (arXiv:2306.17156v2 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17156">
<div class="article-summary-box-inner">
<span><p>Generative AI and large language models hold great promise in enhancing
computing education by powering next-generation educational technologies for
introductory programming. Recent works have studied these models for different
scenarios relevant to programming education; however, these works are limited
for several reasons, as they typically consider already outdated models or only
specific scenario(s). Consequently, there is a lack of a systematic study that
benchmarks state-of-the-art models for a comprehensive set of programming
education scenarios. In our work, we systematically evaluate two models,
ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human
tutors for a variety of scenarios. We evaluate using five introductory Python
programming problems and real-world buggy programs from an online platform, and
assess performance using expert-based annotations. Our results show that GPT-4
drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human
tutors' performance for several scenarios. These results also highlight
settings where GPT-4 still struggles, providing exciting future directions on
developing techniques to improve the performance of these models.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-07-03 23:13:40.920938013 UTC">2023-07-03 23:13:40 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>