<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-02-03T01:30:00Z">02-03</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Inference of Partial Colexifications from Multilingual Wordlists. (arXiv:2302.00739v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00739">
<div class="article-summary-box-inner">
<span><p>The past years have seen a drastic rise in studies devoted to the
investigation of colexification patterns in individual languages families in
particular and the languages of the world in specific. Specifically
computational studies have profited from the fact that colexification as a
scientific construct is easy to operationalize, enabling scholars to infer
colexification patterns for large collections of cross-linguistic data. Studies
devoted to partial colexifications -- colexification patterns that do not
involve entire words, but rather various parts of words--, however, have been
rarely conducted so far. This is not surprising, since partial colexifications
are less easy to deal with in computational approaches and may easily suffer
from all kinds of noise resulting from false positive matches. In order to
address this problem, this study proposes new approaches to the handling of
partial colexifications by (1) proposing new models with which partial
colexification patterns can be represented, (2) developing new efficient
methods and workflows which help to infer various types of partial
colexification patterns from multilingual wordlists, and (3) illustrating how
inferred patterns of partial colexifications can be computationally analyzed
and interactively visualized.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AmbiCoref: Evaluating Human and Model Sensitivity to Ambiguous Coreference. (arXiv:2302.00762v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00762">
<div class="article-summary-box-inner">
<span><p>Given a sentence "Abby told Brittney that she upset Courtney", one would
struggle to understand who "she" refers to, and ask for clarification. However,
if the word "upset" were replaced with "hugged", "she" unambiguously refers to
Abby. We study if modern coreference resolution models are sensitive to such
pronominal ambiguity. To this end, we construct AmbiCoref, a diagnostic corpus
of minimal sentence pairs with ambiguous and unambiguous referents. Our
examples generalize psycholinguistic studies of human perception of ambiguity
around particular arrangements of verbs and their arguments. Analysis shows
that (1) humans are less sure of referents in ambiguous AmbiCoref examples than
unambiguous ones, and (2) most coreference models show little difference in
output between ambiguous and unambiguous pairs. We release AmbiCoref as a
diagnostic corpus for testing whether models treat ambiguity similarly to
human.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Collaborating with language models for embodied reasoning. (arXiv:2302.00763v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00763">
<div class="article-summary-box-inner">
<span><p>Reasoning in a complex and ambiguous environment is a key goal for
Reinforcement Learning (RL) agents. While some sophisticated RL agents can
successfully solve difficult tasks, they require a large amount of training
data and often struggle to generalize to new unseen environments and new tasks.
On the other hand, Large Scale Language Models (LSLMs) have exhibited strong
reasoning ability and the ability to to adapt to new tasks through in-context
learning. However, LSLMs do not inherently have the ability to interrogate or
intervene on the environment. In this work, we investigate how to combine these
complementary abilities in a single system consisting of three parts: a
Planner, an Actor, and a Reporter. The Planner is a pre-trained language model
that can issue commands to a simple embodied agent (the Actor), while the
Reporter communicates with the Planner to inform its next command. We present a
set of tasks that require reasoning, test this system's ability to generalize
zero-shot and investigate failure cases, and demonstrate how components of this
system can be trained with reinforcement-learning to improve performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visually Grounded Keyword Detection and Localisation for Low-Resource Languages. (arXiv:2302.00765v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00765">
<div class="article-summary-box-inner">
<span><p>This study investigates the use of Visually Grounded Speech (VGS) models for
keyword localisation in speech. The study focusses on two main research
questions: (1) Is keyword localisation possible with VGS models and (2) Can
keyword localisation be done cross-lingually in a real low-resource setting?
Four methods for localisation are proposed and evaluated on an English dataset,
with the best-performing method achieving an accuracy of 57%. A new dataset
containing spoken captions in Yoruba language is also collected and released
for cross-lingual keyword localisation. The cross-lingual model obtains a
precision of 16% in actual keyword localisation and this performance can be
improved by initialising from a model pretrained on English data. The study
presents a detailed analysis of the model's success and failure modes and
highlights the challenges of using VGS models for keyword localisation in
low-resource settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging task dependency and contrastive learning for Legal Judgement Prediction on the European Court of Human Rights. (arXiv:2302.00768v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00768">
<div class="article-summary-box-inner">
<span><p>We report on an experiment in legal judgement prediction on European Court of
Human Rights cases where our model first learns to predict the convention
articles allegedly violated by the state from case facts descriptions, and
subsequently utilizes that information to predict a finding of a violation by
the court. We assess the dependency between these two tasks at the feature and
outcome level. Furthermore, we leverage a hierarchical contrastive loss to pull
together article specific representations of cases at the higher level level,
leading to distinctive article clusters, and further pulls the cases in each
article cluster based on their outcome leading to sub-clusters of cases with
similar outcomes. Our experiment results demonstrate that, given a static
pre-trained encoder, our models produce a small but consistent improvement in
prediction performance over single-task and joint models without contrastive
loss.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">User Study for Improving Tools for Bible Translation. (arXiv:2302.00778v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00778">
<div class="article-summary-box-inner">
<span><p>Technology has increasingly become an integral part of the Bible translation
process. Over time, both the translation process and relevant technology have
evolved greatly. More recently, the field of Natural Language Processing (NLP)
has made great progress in solving some problems previously thought
impenetrable. Through this study we endeavor to better understand and
communicate about a segment of the current landscape of the Bible translation
process as it relates to technology and identify pertinent issues. We conduct
several interviews with individuals working in different levels of the Bible
translation process from multiple organizations to identify gaps and
bottlenecks where technology (including recent advances in AI) could
potentially play a pivotal role in reducing translation time and improving
overall quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Entity Alignment for Temporal Knowledge Graphs. (arXiv:2302.00796v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00796">
<div class="article-summary-box-inner">
<span><p>Entity alignment (EA) is a fundamental data integration task that identifies
equivalent entities between different knowledge graphs (KGs). Temporal
Knowledge graphs (TKGs) extend traditional knowledge graphs by introducing
timestamps, which have received increasing attention. State-of-the-art
time-aware EA studies have suggested that the temporal information of TKGs
facilitates the performance of EA. However, existing studies have not
thoroughly exploited the advantages of temporal information in TKGs. Also, they
perform EA by pre-aligning entity pairs, which can be labor-intensive and thus
inefficient.
</p>
<p>In this paper, we present DualMatch which effectively fuses the relational
and temporal information for EA. DualMatch transfers EA on TKGs into a weighted
graph matching problem. More specifically, DualMatch is equipped with an
unsupervised method, which achieves EA without necessitating seed alignment.
DualMatch has two steps: (i) encoding temporal and relational information into
embeddings separately using a novel label-free encoder, Dual-Encoder; and (ii)
fusing both information and transforming it into alignment using a novel
graph-matching-based decoder, GM-Decoder. DualMatch is able to perform EA on
TKGs with or without supervision, due to its capability of effectively
capturing temporal information. Extensive experiments on three real-world TKG
datasets offer the insight that DualMatch outperforms the state-of-the-art
methods in terms of H@1 by 2.4% - 10.7% and MRR by 1.7% - 7.6%, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Rare Words Recognition through Homophone Extension and Unified Writing for Low-resource Cantonese Speech Recognition. (arXiv:2302.00836v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00836">
<div class="article-summary-box-inner">
<span><p>Homophone characters are common in tonal syllable-based languages, such as
Mandarin and Cantonese. The data-intensive end-to-end Automatic Speech
Recognition (ASR) systems are more likely to mis-recognize homophone characters
and rare words under low-resource settings. For the problem of lowresource
Cantonese speech recognition, this paper presents a novel homophone extension
method to integrate human knowledge of the homophone lexicon into the beam
search decoding process with language model re-scoring. Besides, we propose an
automatic unified writing method to merge the variants of Cantonese characters
and standardize speech annotation guidelines, which enables more efficient
utilization of labeled utterances by providing more samples for the merged
characters. We empirically show that both homophone extension and unified
writing improve the recognition performance significantly on both in-domain and
out-of-domain test sets, with an absolute Character Error Rate (CER) decrease
of around 5% and 18%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">idT5: Indonesian Version of Multilingual T5 Transformer. (arXiv:2302.00856v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00856">
<div class="article-summary-box-inner">
<span><p>Indonesian language is spoken by almost 200 million people and is the 10th
most spoken language in the world, but it is under-represented in NLP (Natural
Language Processing) research. A sparsity of language resources has hampered
previous work on Indonesian. The Transformer is a new architecture rapidly
becoming dominant for NLP, surpassing alternatives like convolutional and
recurrent neural networks. T5 (Text-to-Text Transfer Transformer) is a
Transformer model that converts all text-based language problems to
text-to-text format for English. The multilingual variant is mT5 (multilingual
T5) which has shown promising results on many NLP tasks across languages.
However, the size of this multilingual model is a drawback for its application
in real production applications, which sometimes require only one language. In
this study, the mT5 model was adapted for only one language, Indonesian,
resulting in a pre-trained T5 model that was specific only for Indonesian with
a smaller size. For performance comparison, we fine-tuned this model and the
mT5 model to the Sentiment Analysis (SA), Question Generation (QG), and
Question Answering (QA) tasks with the exact mechanism and dataset. Fine-tuned
model based on our model achieved 77.18% accuracy on SA, 8% higher than the
mT5-based model, and obtained nearly the same score as the mT5-based model on
QG and QA. The results confirm that it is possible to produce a smaller
pre-trained model that maintains comparable yields while reducing the model
size by up to 58%. In addition, the resulting model requires less memory, loads
faster, and inference times faster.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using In-Context Learning to Improve Dialogue Safety. (arXiv:2302.00871v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00871">
<div class="article-summary-box-inner">
<span><p>While large neural-based conversational models have become increasingly
proficient as dialogue agents, recent work has highlighted safety issues with
these systems. For example, these systems can be goaded into generating toxic
content, which often perpetuates social biases or stereotypes. We investigate a
retrieval-based framework for reducing bias and toxicity in responses generated
from neural-based chatbots. It uses in-context learning to steer a model
towards safer generations. Concretely, to generate a response to an unsafe
dialogue context, we retrieve demonstrations of safe model responses to similar
dialogue contexts. We find our proposed approach performs competitively with
strong baselines which use fine-tuning. For instance, using automatic
evaluation, we find our best fine-tuned baseline only generates safe responses
to unsafe dialogue contexts from DiaSafety 2.92% more than our approach.
Finally, we also propose a straightforward re-ranking procedure which can
further improve response safeness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to choose "Good" Samples for Text Data Augmentation. (arXiv:2302.00894v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00894">
<div class="article-summary-box-inner">
<span><p>Deep learning-based text classification models need abundant labeled data to
obtain competitive performance. Unfortunately, annotating large-size corpus is
time-consuming and laborious. To tackle this, multiple researches try to use
data augmentation to expand the corpus size. However, data augmentation may
potentially produce some noisy augmented samples. There are currently no works
exploring sample selection for augmented samples in nature language processing
field. In this paper, we propose a novel self-training selection framework with
two selectors to select the high-quality samples from data augmentation.
Specifically, we firstly use an entropy-based strategy and the model prediction
to select augmented samples. Considering some samples with high quality at the
above step may be wrongly filtered, we propose to recall them from two
perspectives of word overlap and semantic similarity. Experimental results show
the effectiveness and simplicity of our framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Quantized AutoEncoders: Towards Unsupervised Text-Image Alignment. (arXiv:2302.00902v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00902">
<div class="article-summary-box-inner">
<span><p>Recent progress in scaling up large language models has shown impressive
capabilities in performing few-shot learning across a wide range of text-based
tasks. However, a key limitation is that these language models fundamentally
lack visual perception - a crucial attribute needed to extend these models to
be able to interact with the real world and solve vision tasks, such as in
visual-question answering and robotics. Prior works have largely connected
image to text through pretraining and/or fine-tuning on curated image-text
datasets, which can be a costly and expensive process. In order to resolve this
limitation, we propose a simple yet effective approach called
Language-Quantized AutoEncoder (LQAE), a modification of VQ-VAE that learns to
align text-image data in an unsupervised manner by leveraging pretrained
language models (e.g., BERT, RoBERTa). Our main idea is to encode image as
sequences of text tokens by directly quantizing image embeddings using a
pretrained language codebook. We then apply random masking followed by a BERT
model, and have the decoder reconstruct the original image from BERT predicted
text token embeddings. By doing so, LQAE learns to represent similar images
with similar clusters of text tokens, thereby aligning these two modalities
without the use of aligned text-image pairs. This enables few-shot image
classification with large language models (e.g., GPT-3) as well as linear
classification of images based on BERT text features. To the best of our
knowledge, our work is the first work that uses unaligned images for multimodal
tasks by leveraging the power of pretrained language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">History-Aware Hierarchical Transformer for Multi-session Open-domain Dialogue System. (arXiv:2302.00907v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00907">
<div class="article-summary-box-inner">
<span><p>With the evolution of pre-trained language models, current open-domain
dialogue systems have achieved great progress in conducting one-session
conversations. In contrast, Multi-Session Conversation (MSC), which consists of
multiple sessions over a long term with the same user, is under-investigated.
In this paper, we propose History-Aware Hierarchical Transformer (HAHT) for
multi-session open-domain dialogue. HAHT maintains a long-term memory of
history conversations and utilizes history information to understand current
conversation context and generate well-informed and context-relevant responses.
Specifically, HAHT first encodes history conversation sessions hierarchically
into a history memory. Then, HAHT leverages historical information to
facilitate the understanding of the current conversation context by encoding
the history memory together with the current context with attention-based
mechanisms. Finally, to explicitly utilize historical information, HAHT uses a
history-aware response generator that switches between a generic vocabulary and
a history-aware vocabulary. Experimental results on a large-scale MSC dataset
suggest that the proposed HAHT model consistently outperforms baseline models.
Human evaluation results support that HAHT generates more human-like,
context-relevant and history-relevant responses than baseline models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Chain-of-Thought Reasoning in Language Models. (arXiv:2302.00923v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00923">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have shown impressive performance on complex
reasoning by leveraging chain-of-thought (CoT) prompting to generate
intermediate reasoning chains as the rationale to infer the answer. However,
existing CoT studies are mostly isolated in the language modality with LLMs,
where LLMs are hard to deploy. To elicit CoT reasoning in multimodality, a
possible solution is to fine-tune small language models by fusing the vision
and language features to perform CoT reasoning. The key challenge is that those
language models tend to generate hallucinated reasoning chains that mislead the
answer inference. To mitigate the effect of such mistakes, we propose
Multimodal-CoT that incorporates vision features in a decoupled training
framework. The framework separates the rationale generation and answer
inference into two stages. By incorporating the vision features in both stages,
the model is able to generate effective rationales that contribute to answer
inference. With Multimodal-CoT, our model under 1 billion parameters
outperforms the previous state-of-the-art LLM (GPT-3.5) by 16% (75.17%-&gt;91.68%)
on the ScienceQA benchmark and even surpasses human performance. Code is
publicly available at https://github.com/amazon-science/mm-cot.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Fewer Splits are Better: Deconstructing Readability in Sentence Splitting. (arXiv:2302.00937v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00937">
<div class="article-summary-box-inner">
<span><p>In this work, we focus on sentence splitting, a subfield of text
simplification, motivated largely by an unproven idea that if you divide a
sentence in pieces, it should become easier to understand. Our primary goal in
this paper is to find out whether this is true. In particular, we ask, does it
matter whether we break a sentence into two or three? We report on our findings
based on Amazon Mechanical Turk.
</p>
<p>More specifically, we introduce a Bayesian modeling framework to further
investigate to what degree a particular way of splitting the complex sentence
affects readability, along with a number of other parameters adopted from
diverse perspectives, including clinical linguistics, and cognitive
linguistics. The Bayesian modeling experiment provides clear evidence that
bisecting the sentence leads to enhanced readability to a degree greater than
what we create by trisection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TransFool: An Adversarial Attack against Neural Machine Translation Models. (arXiv:2302.00944v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00944">
<div class="article-summary-box-inner">
<span><p>Deep neural networks have been shown to be vulnerable to small perturbations
of their inputs, known as adversarial attacks. In this paper, we investigate
the vulnerability of Neural Machine Translation (NMT) models to adversarial
attacks and propose a new attack algorithm called TransFool. To fool NMT
models, TransFool builds on a multi-term optimization problem and a gradient
projection step. By integrating the embedding representation of a language
model, we generate fluent adversarial examples in the source language that
maintain a high level of semantic similarity with the clean samples.
Experimental results demonstrate that, for different translation tasks and NMT
architectures, our white-box attack can severely degrade the translation
quality while the semantic similarity between the original and the adversarial
sentences stays high. Moreover, we show that TransFool is transferable to
unknown target models. Finally, based on automatic and human evaluations,
TransFool leads to improvement in terms of success rate, semantic similarity,
and fluency compared to the existing attacks both in white-box and black-box
settings. Thus, TransFool permits us to better characterize the vulnerability
of NMT models and outlines the necessity to design strong defense mechanisms
and more robust NMT systems for real-life applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Curriculum-guided Abstractive Summarization for Mental Health Online Posts. (arXiv:2302.00954v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00954">
<div class="article-summary-box-inner">
<span><p>Automatically generating short summaries from users' online mental health
posts could save counselors' reading time and reduce their fatigue so that they
can provide timely responses to those seeking help for improving their mental
state. Recent Transformers-based summarization models have presented a
promising approach to abstractive summarization. They go beyond sentence
selection and extractive strategies to deal with more complicated tasks such as
novel word generation and sentence paraphrasing. Nonetheless, these models have
a prominent shortcoming; their training strategy is not quite efficient, which
restricts the model's performance. In this paper, we include a curriculum
learning approach to reweigh the training samples, bringing about an efficient
learning procedure. We apply our model on extreme summarization dataset of
MentSum posts -- a dataset of mental health related posts from Reddit social
media. Compared to the state-of-the-art model, our proposed method makes
substantial gains in terms of Rouge and Bertscore evaluation metrics, yielding
3.5% (Rouge-1), 10.4% (Rouge-2), and 4.7% (Rouge-L), 1.5% (Bertscore) relative
improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predefined domain specific embeddings of food concepts and recipes: A case study on heterogeneous recipe datasets. (arXiv:2302.01005v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01005">
<div class="article-summary-box-inner">
<span><p>Although recipe data are very easy to come by nowadays, it is really hard to
find a complete recipe dataset - with a list of ingredients, nutrient values
per ingredient, and per recipe, allergens, etc. Recipe datasets are usually
collected from social media websites where users post and publish recipes.
Usually written with little to no structure, using both standardized and
non-standardized units of measurement. We collect six different recipe
datasets, publicly available, in different formats, and some including data in
different languages. Bringing all of these datasets to the needed format for
applying a machine learning (ML) pipeline for nutrient prediction [1], [2],
includes data normalization using dictionary-based named entity recognition
(NER), rule-based NER, as well as conversions using external domain-specific
resources. From the list of ingredients, domain-specific embeddings are created
using the same embedding space for all recipes - one ingredient dataset is
generated. The result from this normalization process is two corpora - one with
predefined ingredient embeddings and one with predefined recipe embeddings. On
all six recipe datasets, the ML pipeline is evaluated. The results from this
use case also confirm that the embeddings merged using the domain heuristic
yield better results than the baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Coherence Markers for the Early Diagnosis of the Alzheimer Disease. (arXiv:2302.01025v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01025">
<div class="article-summary-box-inner">
<span><p>In this work we explore how language models can be employed to analyze
language and discriminate between mentally impaired and healthy subjects
through the perplexity metric. Perplexity was originally conceived as an
information-theoretic measure to assess how much a given language model is
suited to predict a text sequence or, equivalently, how much a word sequence
fits into a specific language model. We carried out an extensive
experimentation with the publicly available data, and employed language models
as diverse as N-grams, from 2-grams to 5-grams, and GPT-2, a transformer-based
language model. We investigated whether perplexity scores may be used to
discriminate between the transcripts of healthy subjects and subjects suffering
from Alzheimer Disease (AD). Our best performing models achieved full accuracy
and F-score (1.00 in both precision/specificity and recall/sensitivity) in
categorizing subjects from both the AD class and control subjects. These
results suggest that perplexity can be a valuable analytical metrics with
potential application to supporting early diagnosis of symptoms of mental
disorders.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">New Linear-time Algorithm for SubTree Kernel Computation based on Root-Weighted Tree Automata. (arXiv:2302.01097v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01097">
<div class="article-summary-box-inner">
<span><p>Tree kernels have been proposed to be used in many areas as the automatic
learning of natural language applications. In this paper, we propose a new
linear time algorithm based on the concept of weighted tree automata for
SubTree kernel computation. First, we introduce a new class of weighted tree
automata, called Root-Weighted Tree Automata, and their associated formal tree
series. Then we define, from this class, the SubTree automata that represent
compact computational models for finite tree languages. This allows us to
design a theoretically guaranteed linear-time algorithm for computing the
SubTree Kernel based on weighted tree automata intersection. The key idea
behind the proposed algorithm is to replace DAG reduction and nodes sorting
steps used in previous approaches by states equivalence classes computation
allowed in the weighted tree automata approach. Our approach has three major
advantages: it is output-sensitive, it is free sensitive from the tree types
(ordered trees versus unordered trees), and it is well adapted to any
incremental tree kernel based learning methods. Finally, we conduct a variety
of comparative experiments on a wide range of synthetic tree languages datasets
adapted for a deep algorithm analysis. The obtained results show that the
proposed algorithm outperforms state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Combining Deep Neural Reranking and Unsupervised Extraction for Multi-Query Focused Summarization. (arXiv:2302.01148v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01148">
<div class="article-summary-box-inner">
<span><p>The CrisisFACTS Track aims to tackle challenges such as multi-stream
fact-finding in the domain of event tracking; participants' systems extract
important facts from several disaster-related events while incorporating the
temporal order. We propose a combination of retrieval, reranking, and the
well-known Integer Linear Programming (ILP) and Maximal Marginal Relevance
(MMR) frameworks. In the former two modules, we explore various methods
including an entity-based baseline, pre-trained and fine-tuned Question
Answering systems, and ColBERT. We then use the latter module as an extractive
summarization component by taking diversity and novelty criteria into account.
The automatic scoring runs show strong results across the evaluation setups but
also reveal shortcomings and challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How learners produce data from text in classifying clickbait. (arXiv:2302.01292v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01292">
<div class="article-summary-box-inner">
<span><p>Text provides a compelling example of unstructured data that can be used to
motivate and explore classification problems. Challenges arise regarding the
representation of features of text and student linkage between text
representations as character strings and identification of features that embed
connections with underlying phenomena. In order to observe how students reason
with text data in scenarios designed to elicit certain aspects of the domain,
we employed a task-based interview method using a structured protocol with six
pairs of undergraduate students. Our goal was to shed light on students'
understanding of text as data using a motivating task to classify headlines as
"clickbait" or "news". Three types of features (function, content, and form)
surfaced, the majority from the first scenario. Our analysis of the interviews
indicates that this sequence of activities engaged the participants in thinking
at both the human-perception level and the computer-extraction level and
conceptualizing connections between them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What Language Reveals about Perception: Distilling Psychophysical Knowledge from Large Language Models. (arXiv:2302.01308v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01308">
<div class="article-summary-box-inner">
<span><p>Understanding the extent to which the perceptual world can be recovered from
language is a fundamental problem in cognitive science. We reformulate this
problem as that of distilling psychophysical information from text and show how
this can be done by combining large language models (LLMs) with a classic
psychophysical method based on similarity judgments. Specifically, we use the
prompt auto-completion functionality of GPT3, a state-of-the-art LLM, to elicit
similarity scores between stimuli and then apply multidimensional scaling to
uncover their underlying psychological space. We test our approach on six
perceptual domains and show that the elicited judgments strongly correlate with
human data and successfully recover well-known psychophysical structures such
as the color wheel and pitch spiral. We also explore meaningful divergences
between LLM and human representations. Our work showcases how combining
state-of-the-art machine models with well-known cognitive paradigms can shed
new light on fundamental questions in perception and language research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Double Permutation Equivariance for Knowledge Graph Completion. (arXiv:2302.01313v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01313">
<div class="article-summary-box-inner">
<span><p>This work provides a formalization of Knowledge Graphs (KGs) as a new class
of graphs that we denote doubly exchangeable attributed graphs, where node and
pairwise (joint 2-node) representations must be equivariant to permutations of
both node ids and edge (&amp; node) attributes (relations &amp; node features).
Double-permutation equivariant KG representations open a new research direction
in KGs. We show that this equivariance imposes a structural representation of
relations that allows neural networks to perform complex logical reasoning
tasks in KGs. Finally, we introduce a general blueprint for such equivariant
representations and test a simple GNN-based double-permutation equivariant
neural architecture that achieve 100% Hits@10 test accuracy in both the
WN18RRv1 and NELL995v1 inductive KG completion tasks, and can accurately
perform logical reasoning tasks that no existing methods can perform, to the
best of our knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accelerating Large Language Model Decoding with Speculative Sampling. (arXiv:2302.01318v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01318">
<div class="article-summary-box-inner">
<span><p>We present speculative sampling, an algorithm for accelerating transformer
decoding by enabling the generation of multiple tokens from each transformer
call. Our algorithm relies on the observation that the latency of parallel
scoring of short continuations, generated by a faster but less powerful draft
model, is comparable to that of sampling a single token from the larger target
model. This is combined with a novel modified rejection sampling scheme which
preserves the distribution of the target model within hardware numerics. We
benchmark speculative sampling with Chinchilla, a 70 billion parameter language
model, achieving a 2-2.5x decoding speedup in a distributed setup, without
compromising the sample quality or making modifications to the model itself.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">$IC^3$: Image Captioning by Committee Consensus. (arXiv:2302.01328v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01328">
<div class="article-summary-box-inner">
<span><p>If you ask a human to describe an image, they might do so in a thousand
different ways. Traditionally, image captioning models are trained to
approximate the reference distribution of image captions, however, doing so
encourages captions that are viewpoint-impoverished. Such captions often focus
on only a subset of the possible details, while ignoring potentially useful
information in the scene. In this work, we introduce a simple, yet novel,
method: "Image Captioning by Committee Consensus" ($IC^3$), designed to
generate a single caption that captures high-level details from several
viewpoints. Notably, humans rate captions produced by $IC^3$ at least as
helpful as baseline SOTA models more than two thirds of the time, and $IC^3$
captions can improve the performance of SOTA automated recall systems by up to
84%, indicating significant material improvements over existing SOTA approaches
for visual description. Our code is publicly available at
https://github.com/DavidMChan/caption-by-committee
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Extraction in Low-Resource Scenarios: Survey and Perspective. (arXiv:2202.08063v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.08063">
<div class="article-summary-box-inner">
<span><p>Knowledge Extraction (KE), aiming to extract structural information from
unstructured texts, often suffers from data scarcity and emerging unseen types,
i.e., low-resource scenarios. Many neural approaches to low-resource KE have
been widely investigated and achieved impressive performance. In this paper, we
present a literature review towards KE in low-resource scenarios, and
systematically categorize existing works into three paradigms: (1) exploiting
higher-resource data, (2) exploiting stronger models, and (3) exploiting data
and models together. In addition, we highlight promising applications and
outline some potential directions for future research. We hope that our survey
can help both the academic and industrial communities to better understand this
field, inspire more ideas, and boost broader applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GausSetExpander: A Simple Approach for Entity Set Expansion. (arXiv:2202.13649v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.13649">
<div class="article-summary-box-inner">
<span><p>Entity Set Expansion is an important NLP task that aims at expanding a small
set of entities into a larger one with items from a large pool of candidates.
In this paper, we propose GausSetExpander, an unsupervised approach based on
optimal transport techniques. We propose to re-frame the problem as choosing
the entity that best completes the seed set. For this, we interpret a set as an
elliptical distribution with a centroid which represents the mean and a spread
that is represented by the scale parameter. The best entity is the one that
increases the spread of the set the least. We demonstrate the validity of our
approach by comparing to state-of-the art approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning. (arXiv:2206.08657v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08657">
<div class="article-summary-box-inner">
<span><p>Vision-Language (VL) models with the Two-Tower architecture have dominated
visual-language representation learning in recent years. Current VL models
either use lightweight uni-modal encoders and learn to extract, align and fuse
both modalities simultaneously in a deep cross-modal encoder, or feed the
last-layer uni-modal representations from the deep pre-trained uni-modal
encoders into the top cross-modal encoder. Both approaches potentially restrict
vision-language representation learning and limit model performance. In this
paper, we propose BridgeTower, which introduces multiple bridge layers that
build a connection between the top layers of uni-modal encoders and each layer
of the cross-modal encoder. This enables effective bottom-up cross-modal
alignment and fusion between visual and textual representations of different
semantic levels of pre-trained uni-modal encoders in the cross-modal encoder.
Pre-trained with only 4M images, BridgeTower achieves state-of-the-art
performance on various downstream vision-language tasks. In particular, on the
VQAv2 test-std set, BridgeTower achieves an accuracy of 78.73%, outperforming
the previous state-of-the-art model METER by 1.09% with the same pre-training
data and almost negligible additional parameters and computational costs.
Notably, when further scaling the model, BridgeTower achieves an accuracy of
81.15%, surpassing models that are pre-trained on orders-of-magnitude larger
datasets. Code and checkpoints are available at
https://github.com/microsoft/BridgeTower.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic Search. (arXiv:2207.09068v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.09068">
<div class="article-summary-box-inner">
<span><p>While contextualized word embeddings have been a de-facto standard, learning
contextualized phrase embeddings is less explored and being hindered by the
lack of a human-annotated benchmark that tests machine understanding of phrase
semantics given a context sentence or paragraph (instead of phrases alone). To
fill this gap, we propose PiC -- a dataset of ~28K of noun phrases accompanied
by their contextual Wikipedia pages and a suite of three tasks for training and
evaluating phrase embeddings. Training on PiC improves ranking models' accuracy
and remarkably pushes span-selection (SS) models (i.e., predicting the start
and end index of the target phrase) near-human accuracy, which is 95% Exact
Match (EM) on semantic search given a query phrase and a passage.
Interestingly, we find evidence that such impressive performance is because the
SS models learn to better capture the common meaning of a phrase regardless of
its actual context. SotA models perform poorly in distinguishing two senses of
the same phrase in two contexts (~60% EM) and in estimating the similarity
between two different phrases in the same context (~70% EM).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Summarization Programs: Interpretable Abstractive Summarization with Neural Modular Trees. (arXiv:2209.10492v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.10492">
<div class="article-summary-box-inner">
<span><p>Current abstractive summarization models either suffer from a lack of clear
interpretability or provide incomplete rationales by only highlighting parts of
the source document. To this end, we propose the Summarization Program (SP), an
interpretable modular framework consisting of an (ordered) list of binary
trees, each encoding the step-by-step generative process of an abstractive
summary sentence from the source document. A Summarization Program contains one
root node per summary sentence, and a distinct tree connects each summary
sentence (root node) to the document sentences (leaf nodes) from which it is
derived, with the connecting nodes containing intermediate generated sentences.
Edges represent different modular operations involved in summarization such as
sentence fusion, compression, and paraphrasing. We first propose an efficient
best-first search method over neural modules, SP-Search that identifies SPs for
human summaries by directly optimizing for ROUGE scores. Next, using these
programs as automatic supervision, we propose seq2seq models that generate
Summarization Programs, which are then executed to obtain final summaries. We
demonstrate that SP-Search effectively represents the generative process behind
human summaries using modules that are typically faithful to their intended
behavior. We also conduct a simulation study to show that Summarization
Programs improve the interpretability of summarization models by allowing
humans to better simulate model reasoning. Summarization Programs constitute a
promising step toward interpretable and modular abstractive summarization, a
complex task previously addressed primarily through blackbox end-to-end neural
systems. Supporting code available at
https://github.com/swarnaHub/SummarizationPrograms
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ESIE-BERT: Enriching Sub-words Information Explicitly with BERT for Joint Intent Classification and SlotFilling. (arXiv:2211.14829v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.14829">
<div class="article-summary-box-inner">
<span><p>Natural language understanding (NLU) has two core tasks: intent
classification and slot filling. The success of pre-training language models
resulted in a significant breakthrough in the two tasks. One of the promising
solutions called BERT can jointly optimize the two tasks. We note that
BERT-based models convert each complex token into multiple sub-tokens by
wordpiece algorithm, which generates a mismatch between the lengths of the
tokens and the labels. This leads to BERT-based models do not do well in label
prediction which limits model performance improvement. Many existing models can
be compatible with this issue but some hidden semantic information is discarded
in the fine-tuning process. We address the problem by introducing a novel joint
method on top of BERT which explicitly models the multiple sub-tokens features
after wordpiece tokenization, thereby contributing to the two tasks. Our method
can well extract the contextual features from complex tokens by the proposed
sub-words attention adapter (SAA), which preserves overall utterance
information. Additionally, we propose an intent attention adapter (IAA) to
obtain the full sentence features to aid users to predict intent. Experimental
results confirm that our proposed model is significantly improved on two public
benchmark datasets. In particular, the slot filling F1 score is improved from
96.1 to 98.2 (2.1% absolute) on the Airline Travel Information Systems (ATIS)
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Table-and-Text HybridQA: Concepts, Methods, Challenges and Future Directions. (arXiv:2212.13465v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.13465">
<div class="article-summary-box-inner">
<span><p>Table-and-text hybrid question answering (HybridQA) is a widely used and
challenging NLP task commonly applied in the financial and scientific domain.
The early research focuses on migrating other QA task methods to HybridQA,
while with further research, more and more HybridQA-specific methods have been
present. With the rapid development of HybridQA, the systematic survey is still
under-explored to summarize the main techniques and advance further research.
So we present this work to summarize the current HybridQA benchmarks and
methods, then analyze the challenges and future directions of this task. The
contributions of this paper can be summarized in three folds: (1) first survey,
to our best knowledge, including benchmarks, methods and challenges for
HybridQA; (2) systematic investigation with the reasonable comparison of the
existing systems to articulate their advantages and shortcomings; (3) detailed
analysis of challenges in four important dimensions to shed light on future
directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grammar construction methods for extended deterministic expressions. (arXiv:2301.01621v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01621">
<div class="article-summary-box-inner">
<span><p>Extended regular expressions with counting and interleaving are widely used
in practice. However the related theoretical studies for this kind of
expressions currently cannot meet the need of practical work. This paper
develops syntax definitions for extended deterministic expressions and their
subclasses, hope to completely solve the long-standing problem that there are
no syntax definitions for this kind of expressions, which has become an
important reason for restricting the use of extended expressions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Faithful Chain-of-Thought Reasoning. (arXiv:2301.13379v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.13379">
<div class="article-summary-box-inner">
<span><p>While Chain-of-Thought (CoT) prompting boosts Language Models' (LM)
performance on a gamut of complex reasoning tasks, the generated reasoning
chain does not necessarily reflect how the model arrives at the answer (aka.
faithfulness). We propose Faithful CoT, a faithful-by-construction framework
that decomposes a reasoning task into two stages: Translation (Natural Language
query $\rightarrow$ symbolic reasoning chain) and Problem Solving (reasoning
chain $\rightarrow$ answer), using an LM and a deterministic solver
respectively. We demonstrate the efficacy of our approach on 10 reasoning
datasets from 4 diverse domains. It outperforms traditional CoT prompting on 9
out of the 10 datasets, with an average accuracy gain of 4.4 on Math Word
Problems, 1.9 on Planning, 4.0 on Multi-hop Question Answering (QA), and 18.1
on Logical Inference, under greedy decoding. Together with self-consistency
decoding, we achieve new state-of-the-art few-shot performance on 7 out of the
10 datasets, showing a strong synergy between faithfulness and accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-Learning with Dynamic-Memory-Based Prototypical Network for Few-Shot Event Detection. (arXiv:1910.11621v2 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.11621">
<div class="article-summary-box-inner">
<span><p>Event detection (ED), a sub-task of event extraction, involves identifying
triggers and categorizing event mentions. Existing methods primarily rely upon
supervised learning and require large-scale labeled event datasets which are
unfortunately not readily available in many real-life applications. In this
paper, we consider and reformulate the ED task with limited labeled data as a
Few-Shot Learning problem. We propose a Dynamic-Memory-Based Prototypical
Network (DMB-PN), which exploits Dynamic Memory Network (DMN) to not only learn
better prototypes for event types, but also produce more robust sentence
encodings for event mentions. Differing from vanilla prototypical networks
simply computing event prototypes by averaging, which only consume event
mentions once, our model is more robust and is capable of distilling contextual
information from event mentions for multiple times due to the multi-hop
mechanism of DMNs. The experiments show that DMB-PN not only deals with sample
scarcity better than a series of baseline models but also performs more
robustly when the variety of event types is relatively large and the instance
quantity is extremely small.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OntoED: Low-resource Event Detection with Ontology Embedding. (arXiv:2105.10922v4 [cs.IR] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10922">
<div class="article-summary-box-inner">
<span><p>Event Detection (ED) aims to identify event trigger words from a given text
and classify it into an event type. Most of current methods to ED rely heavily
on training instances, and almost ignore the correlation of event types. Hence,
they tend to suffer from data scarcity and fail to handle new unseen event
types. To address these problems, we formulate ED as a process of event
ontology population: linking event instances to pre-defined event types in
event ontology, and propose a novel ED framework entitled OntoED with ontology
embedding. We enrich event ontology with linkages among event types, and
further induce more event-event correlations. Based on the event ontology,
OntoED can leverage and propagate correlation knowledge, particularly from
data-rich to data-poor event types. Furthermore, OntoED can be applied to new
unseen event types, by establishing linkages to existing ones. Experiments
indicate that OntoED is more predominant and robust than previous approaches to
ED, especially in data-scarce scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Construction and Applications of Billion-Scale Pre-trained Multimodal Business Knowledge Graph. (arXiv:2209.15214v3 [cs.AI] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.15214">
<div class="article-summary-box-inner">
<span><p>Business Knowledge Graphs (KGs) are important to many enterprises today,
providing factual knowledge and structured data that steer many products and
make them more intelligent. Despite their promising benefits, building business
KG necessitates solving prohibitive issues of deficient structure and multiple
modalities. In this paper, we advance the understanding of the practical
challenges related to building KG in non-trivial real-world systems. We
introduce the process of building an open business knowledge graph (OpenBG)
derived from a well-known enterprise, Alibaba Group. Specifically, we define a
core ontology to cover various abstract products and consumption demands, with
fine-grained taxonomy and multimodal facts in deployed applications. OpenBG is
an open business KG of unprecedented scale: 2.6 billion triples with more than
88 million entities covering over 1 million core classes/concepts and 2,681
types of relations. We release all the open resources (OpenBG benchmarks)
derived from it for the community and report experimental results of KG-centric
tasks. We also run up an online competition based on OpenBG benchmarks, and has
attracted thousands of teams. We further pre-train OpenBG and apply it to many
KG- enhanced downstream tasks in business scenarios, demonstrating the
effectiveness of billion-scale multimodal knowledge for e-commerce. All the
resources with codes have been released at
\url{https://github.com/OpenBGBenchmark/OpenBG}.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-02-05 23:12:46.990065125 UTC">2023-02-05 23:12:46 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>