<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-03-31T01:30:00Z">03-31</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">BEVERS: A General, Simple, and Performant Framework for Automatic Fact Verification. (arXiv:2303.16974v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.16974">
<div class="article-summary-box-inner">
<span><p>Automatic fact verification has become an increasingly popular topic in
recent years and among datasets the Fact Extraction and VERification (FEVER)
dataset is one of the most popular. In this work we present BEVERS, a tuned
baseline system for the FEVER dataset. Our pipeline uses standard approaches
for document retrieval, sentence selection, and final claim classification,
however, we spend considerable effort ensuring optimal performance for each
component. The results are that BEVERS achieves the highest FEVER score and
label accuracy among all systems, published or unpublished. We also apply this
pipeline to another fact verification dataset, Scifact, and achieve the highest
label accuracy among all systems on that dataset as well. We also make our full
code available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adapting to the Low-Resource Double-Bind: Investigating Low-Compute Methods on Low-Resource African Languages. (arXiv:2303.16985v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.16985">
<div class="article-summary-box-inner">
<span><p>Many natural language processing (NLP) tasks make use of massively
pre-trained language models, which are computationally expensive. However,
access to high computational resources added to the issue of data scarcity of
African languages constitutes a real barrier to research experiments on these
languages. In this work, we explore the applicability of low-compute approaches
such as language adapters in the context of this low-resource double-bind. We
intend to answer the following question: do language adapters allow those who
are doubly bound by data and compute to practically build useful models?
Through fine-tuning experiments on African languages, we evaluate their
effectiveness as cost-effective approaches to low-resource African NLP. Using
solely free compute resources, our results show that language adapters achieve
comparable performances to massive pre-trained language models which are heavy
on computational resources. This opens the door to further experimentation and
exploration on full-extent of language adapters capacities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ContraSim -- A Similarity Measure Based on Contrastive Learning. (arXiv:2303.16992v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.16992">
<div class="article-summary-box-inner">
<span><p>Recent work has compared neural network representations via similarity-based
analyses, shedding light on how different aspects (architecture, training data,
etc.) affect models' internal representations. The quality of a similarity
measure is typically evaluated by its success in assigning a high score to
representations that are expected to be matched. However, existing similarity
measures perform mediocrely on standard benchmarks. In this work, we develop a
new similarity measure, dubbed ContraSim, based on contrastive learning. In
contrast to common closed-form similarity measures, ContraSim learns a
parameterized measure by using both similar and dissimilar examples. We perform
an extensive experimental evaluation of our method, with both language and
vision models, on the standard layer prediction benchmark and two new
benchmarks that we introduce: the multilingual benchmark and the image-caption
benchmark. In all cases, ContraSim achieves much higher accuracy than previous
similarity measures, even when presented with challenging examples, and reveals
new insights not captured by previous measures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating GPT-3.5 and GPT-4 Models on Brazilian University Admission Exams. (arXiv:2303.17003v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17003">
<div class="article-summary-box-inner">
<span><p>The present study aims to explore the capabilities of Language Models (LMs)
in tackling high-stakes multiple-choice tests, represented here by the Exame
Nacional do Ensino M\'edio (ENEM), a multidisciplinary entrance examination
widely adopted by Brazilian universities. This exam poses challenging tasks for
LMs, since its questions may span into multiple fields of knowledge, requiring
understanding of information from diverse domains. For instance, a question may
require comprehension of both statistics and biology to be solved. This work
analyzed responses generated by GPT-3.5 and GPT-4 models for questions
presented in the 2009-2017 exams, as well as for questions of the 2022 exam,
which were made public after the training of the models was completed.
Furthermore, different prompt strategies were tested, including the use of
Chain-of-Thought (CoT) prompts to generate explanations for answers. On the
2022 edition, the best-performing model, GPT-4 with CoT, achieved an accuracy
of 87%, largely surpassing GPT-3.5 by 11 points. The code and data used on
experiments are available at https://github.com/piresramon/gpt-4-enem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How do decoding algorithms distribute information in dialogue responses?. (arXiv:2303.17006v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17006">
<div class="article-summary-box-inner">
<span><p>Humans tend to follow the Uniform Information Density (UID) principle by
distributing information evenly in utterances. We study if decoding algorithms
implicitly follow this UID principle, and under what conditions adherence to
UID might be desirable for dialogue generation. We generate responses using
different decoding algorithms with GPT-2 on the Persona-Chat dataset and
collect human judgments on their quality using Amazon Mechanical Turk. We find
that (i) surprisingly, model-generated responses follow the UID principle to a
greater extent than human responses, and (ii) decoding algorithms that promote
UID do not generate higher-quality responses. Instead, when we control for
surprisal, non-uniformity of information density correlates with the quality of
responses with very low/high surprisal. Our findings indicate that encouraging
non-uniform responses is a potential solution to the ``likelihood trap''
problem (quality degradation in very high-likelihood text). Our dataset
containing multiple candidate responses per dialog history along with
human-annotated quality ratings is available at
https://huggingface.co/datasets/saranya132/dialog_uid_gpt2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents. (arXiv:2303.17071v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17071">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have emerged as valuable tools for many natural
language understanding tasks. In safety-critical applications such as
healthcare, the utility of these models is governed by their ability to
generate outputs that are factually accurate and complete. In this work, we
present dialog-enabled resolving agents (DERA). DERA is a paradigm made
possible by the increased conversational abilities of LLMs, namely GPT-4. It
provides a simple, interpretable forum for models to communicate feedback and
iteratively improve output. We frame our dialog as a discussion between two
agent types - a Researcher, who processes information and identifies crucial
problem components, and a Decider, who has the autonomy to integrate the
Researcher's information and makes judgments on the final output.
</p>
<p>We test DERA against three clinically-focused tasks. For medical conversation
summarization and care plan generation, DERA shows significant improvement over
the base GPT-4 performance in both human expert preference evaluations and
quantitative metrics. In a new finding, we also show that GPT-4's performance
(70%) on an open-ended version of the MedQA question-answering (QA) dataset
(Jin et al. 2021, USMLE) is well above the passing level (60%), with DERA
showing similar performance. We release the open-ended MEDQA dataset at
https://github.com/curai/curai-research/tree/main/DERA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TLAG: An Informative Trigger and Label-Aware Knowledge Guided Model for Dialogue-based Relation Extraction. (arXiv:2303.17119v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17119">
<div class="article-summary-box-inner">
<span><p>Dialogue-based Relation Extraction (DRE) aims to predict the relation type of
argument pairs that are mentioned in dialogue. The latest trigger-enhanced
methods propose trigger prediction tasks to promote DRE. However, these methods
are not able to fully leverage the trigger information and even bring noise to
relation extraction. To solve these problems, we propose TLAG, which fully
leverages the trigger and label-aware knowledge to guide the relation
extraction. First, we design an adaptive trigger fusion module to fully
leverage the trigger information. Then, we introduce label-aware knowledge to
further promote our model's performance. Experimental results on the DialogRE
dataset show that our TLAG outperforms the baseline models, and detailed
analyses demonstrate the effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TreePiece: Faster Semantic Parsing via Tree Tokenization. (arXiv:2303.17161v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17161">
<div class="article-summary-box-inner">
<span><p>Autoregressive (AR) encoder-decoder neural networks have proved successful in
many NLP problems, including Semantic Parsing -- a task that translates natural
language to machine-readable parse trees. However, the sequential prediction
process of AR models can be slow. To accelerate AR for semantic parsing, we
introduce a new technique called TreePiece that tokenizes a parse tree into
subtrees and generates one subtree per decoding step. On TopV2 benchmark,
TreePiece shows 4.6 times faster decoding speed than standard AR, and
comparable speed but significantly higher accuracy compared to
Non-Autoregressive (NAR).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Nordic Pile: A 1.2TB Nordic Dataset for Language Modeling. (arXiv:2303.17183v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17183">
<div class="article-summary-box-inner">
<span><p>Pre-training Large Language Models (LLMs) require massive amounts of text
data, and the performance of the LLMs typically correlates with the scale and
quality of the datasets. This means that it may be challenging to build LLMs
for smaller languages such as Nordic ones, where the availability of text
corpora is limited. In order to facilitate the development of the LLMS in the
Nordic languages, we curate a high-quality dataset consisting of 1.2TB of text,
in all of the major North Germanic languages (Danish, Icelandic, Norwegian, and
Swedish), as well as some high-quality English data. This paper details our
considerations and processes for collecting, cleaning, and filtering the
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure. (arXiv:2303.17276v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17276">
<div class="article-summary-box-inner">
<span><p>Increase in computational scale and fine-tuning has seen a dramatic
improvement in the quality of outputs of large language models (LLMs) like GPT.
Given that both GPT-3 and GPT-4 were trained on large quantities of
human-generated text, we might ask to what extent their outputs reflect
patterns of human thinking, both for correct and incorrect cases. The Erotetic
Theory of Reason (ETR) provides a symbolic generative model of both human
success and failure in thinking, across propositional, quantified, and
probabilistic reasoning, as well as decision-making. We presented GPT-3,
GPT-3.5, and GPT-4 with 61 central inference and judgment problems from a
recent book-length presentation of ETR, consisting of experimentally verified
data-points on human judgment and extrapolated data-points predicted by ETR,
with correct inference patterns as well as fallacies and framing effects (the
ETR61 benchmark). ETR61 includes classics like Wason's card task, illusory
inferences, the decoy effect, and opportunity-cost neglect, among others. GPT-3
showed evidence of ETR-predicted outputs for 59% of these examples, rising to
77% in GPT-3.5 and 75% in GPT-4. Remarkably, the production of human-like
fallacious judgments increased from 18% in GPT-3 to 33% in GPT-3.5 and 34% in
GPT-4. This suggests that larger and more advanced LLMs may develop a tendency
toward more human-like mistakes, as relevant thought patterns are inherent in
human-produced training data. According to ETR, the same fundamental patterns
are involved both in successful and unsuccessful ordinary reasoning, so that
the "bad" cases could paradoxically be learned from the "good" cases. We
further present preliminary evidence that ETR-inspired prompt engineering could
reduce instances of these mistakes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Yes but.. Can ChatGPT Identify Entities in Historical Documents?. (arXiv:2303.17322v1 [cs.DL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17322">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have been leveraged for several years now,
obtaining state-of-the-art performance in recognizing entities from modern
documents. For the last few months, the conversational agent ChatGPT has
"prompted" a lot of interest in the scientific community and public due to its
capacity of generating plausible-sounding answers. In this paper, we explore
this ability by probing it in the named entity recognition and classification
(NERC) task in primary sources (e.g., historical newspapers and classical
commentaries) in a zero-shot manner and by comparing it with state-of-the-art
LM-based systems. Our findings indicate several shortcomings in identifying
entities in historical text that range from the consistency of entity
annotation guidelines, entity complexity, and code-switching, to the
specificity of prompting. Moreover, as expected, the inaccessibility of
historical archives to the public (and thus on the Internet) also impacts its
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topics in the Haystack: Extracting and Evaluating Topics beyond Coherence. (arXiv:2303.17324v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17324">
<div class="article-summary-box-inner">
<span><p>Extracting and identifying latent topics in large text corpora has gained
increasing importance in Natural Language Processing (NLP). Most models,
whether probabilistic models similar to Latent Dirichlet Allocation (LDA) or
neural topic models, follow the same underlying approach of topic
interpretability and topic extraction. We propose a method that incorporates a
deeper understanding of both sentence and document themes, and goes beyond
simply analyzing word frequencies in the data. This allows our model to detect
latent topics that may include uncommon words or neologisms, as well as words
not present in the documents themselves. Additionally, we propose several new
evaluation metrics based on intruder words and similarity measures in the
semantic space. We present correlation coefficients with human identification
of intruder words and achieve near-human level results at the word-intrusion
task. We demonstrate the competitive performance of our method with a large
benchmark study, and achieve superior results compared to state-of-the-art
topic modeling and document clustering models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A BERT-based Unsupervised Grammatical Error Correction Framework. (arXiv:2303.17367v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17367">
<div class="article-summary-box-inner">
<span><p>Grammatical error correction (GEC) is a challenging task of natural language
processing techniques. While more attempts are being made in this approach for
universal languages like English or Chinese, relatively little work has been
done for low-resource languages for the lack of large annotated corpora. In
low-resource languages, the current unsupervised GEC based on language model
scoring performs well. However, the pre-trained language model is still to be
explored in this context. This study proposes a BERT-based unsupervised GEC
framework, where GEC is viewed as multi-class classification task. The
framework contains three modules: data flow construction module, sentence
perplexity scoring module, and error detecting and correcting module. We
propose a novel scoring method for pseudo-perplexity to evaluate a sentence's
probable correctness and construct a Tagalog corpus for Tagalog GEC research.
It obtains competitive performance on the Tagalog corpus we construct and
open-source Indonesian corpus and it demonstrates that our framework is
complementary to baseline method for low-resource GEC task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research. (arXiv:2303.17395v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17395">
<div class="article-summary-box-inner">
<span><p>The advancement of audio-language (AL) multimodal learning tasks has been
significant in recent years. However, researchers face challenges due to the
costly and time-consuming collection process of existing audio-language
datasets, which are limited in size. To address this data scarcity issue, we
introduce WavCaps, the first large-scale weakly-labelled audio captioning
dataset, comprising approximately 400k audio clips with paired captions. We
sourced audio clips and their raw descriptions from web sources and a sound
event detection dataset. However, the online-harvested raw descriptions are
highly noisy and unsuitable for direct use in tasks such as automated audio
captioning. To overcome this issue, we propose a three-stage processing
pipeline for filtering noisy data and generating high-quality captions, where
ChatGPT, a large language model, is leveraged to filter and transform raw
descriptions automatically. We conduct a comprehensive analysis of the
characteristics of WavCaps dataset and evaluate it on multiple downstream
audio-language multimodal learning tasks. The systems trained on WavCaps
outperform previous state-of-the-art (SOTA) models by a significant margin. Our
aspiration is for the WavCaps dataset we have proposed to facilitate research
in audio-language multimodal learning and demonstrate the potential of
utilizing ChatGPT to enhance academic research. Our dataset and codes are
available at https://github.com/XinhaoMei/WavCaps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Medical Intervention Duration Estimation Using Language-enhanced Transformer Encoder with Medical Prompts. (arXiv:2303.17408v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17408">
<div class="article-summary-box-inner">
<span><p>In recent years, estimating the duration of medical intervention based on
electronic health records (EHRs) has gained significant attention in the filed
of clinical decision support. However, current models largely focus on
structured data, leaving out information from the unstructured clinical
free-text data. To address this, we present a novel language-enhanced
transformer-based framework, which projects all relevant clinical data
modalities (continuous, categorical, binary, and free-text features) into a
harmonized language latent space using a pre-trained sentence encoder with the
help of medical prompts. The proposed method enables the integration of
information from different modalities within the cell transformer encoder and
leads to more accurate duration estimation for medical intervention. Our
experimental results on both US-based (length of stay in ICU estimation) and
Asian (surgical duration prediction) medical datasets demonstrate the
effectiveness of our proposed framework, which outperforms tailored baseline
approaches and exhibits robustness to data corruption in EHRs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study. (arXiv:2303.17466v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17466">
<div class="article-summary-box-inner">
<span><p>The recent release of ChatGPT has garnered widespread recognition for its
exceptional ability to generate human-like responses in dialogue. Given its
usage by users from various nations and its training on a vast multilingual
corpus that incorporates diverse cultural and societal norms, it is crucial to
evaluate its effectiveness in cultural adaptation. In this paper, we
investigate the underlying cultural background of ChatGPT by analyzing its
responses to questions designed to quantify human cultural differences. Our
findings suggest that, when prompted with American context, ChatGPT exhibits a
strong alignment with American culture, but it adapts less effectively to other
cultural contexts. Furthermore, by using different prompts to probe the model,
we show that English prompts reduce the variance in model responses, flattening
out cultural differences and biasing them towards American culture. This study
provides valuable insights into the cultural implications of ChatGPT and
highlights the necessity of greater diversity and cultural awareness in
language technologies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient distributed representations beyond negative sampling. (arXiv:2303.17475v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17475">
<div class="article-summary-box-inner">
<span><p>This article describes an efficient method to learn distributed
representations, also known as embeddings. This is accomplished minimizing an
objective function similar to the one introduced in the Word2Vec algorithm and
later adopted in several works. The optimization computational bottleneck is
the calculation of the softmax normalization constants for which a number of
operations scaling quadratically with the sample size is required. This
complexity is unsuited for large datasets and negative sampling is a popular
workaround, allowing one to obtain distributed representations in linear time
with respect to the sample size. Negative sampling consists, however, in a
change of the loss function and hence solves a different optimization problem
from the one originally proposed. Our contribution is to show that the sotfmax
normalization constants can be estimated in linear time, allowing us to design
an efficient optimization strategy to learn distributed representations. We
test our approximation on two popular applications related to word and node
embeddings. The results evidence competing performance in terms of accuracy
with respect to negative sampling with a remarkably lower computational time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models can Solve Computer Tasks. (arXiv:2303.17491v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17491">
<div class="article-summary-box-inner">
<span><p>Agents capable of carrying out general tasks on a computer can improve
efficiency and productivity by automating repetitive tasks and assisting in
complex problem-solving. Ideally, such agents should be able to solve new
computer tasks presented to them through natural language commands. However,
previous approaches to this problem require large amounts of expert
demonstrations and task-specific reward functions, both of which are
impractical for new tasks. In this work, we show that a pre-trained large
language model (LLM) agent can execute computer tasks guided by natural
language using a simple prompting scheme where the agent recursively criticizes
and improves its output (RCI). The RCI approach significantly outperforms
existing LLM methods for automating computer tasks and surpasses supervised
learning (SL) and reinforcement learning (RL) approaches on the MiniWoB++
benchmark. RCI is competitive with the state-of-the-art SL+RL method, using
only a handful of demonstrations per task rather than tens of thousands, and
without a task-specific reward function. Furthermore, we demonstrate RCI
prompting's effectiveness in enhancing LLMs' reasoning abilities on a suite of
natural language reasoning tasks, outperforming chain of thought (CoT)
prompting. We find that RCI combined with CoT performs better than either
separately.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On pitfalls (and advantages) of sophisticated large language models. (arXiv:2303.17511v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17511">
<div class="article-summary-box-inner">
<span><p>Natural language processing based on large language models (LLMs) is a
booming field of AI research. After neural networks have proven to outperform
humans in games and practical domains based on pattern recognition, we might
stand now at a road junction where artificial entities might eventually enter
the realm of human communication. However, this comes with serious risks. Due
to the inherent limitations regarding the reliability of neural networks,
overreliance on LLMs can have disruptive consequences. Since it will be
increasingly difficult to distinguish between human-written and
machine-generated text, one is confronted with new ethical challenges. This
begins with the no longer undoubtedly verifiable human authorship and continues
with various types of fraud, such as a new form of plagiarism. This also
concerns the violation of privacy rights, the possibility of circulating
counterfeits of humans, and, last but not least, it makes a massive spread of
misinformation possible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving the Diproche CNL through autoformalization via GPT-3. (arXiv:2303.17513v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17513">
<div class="article-summary-box-inner">
<span><p>The Diproche system is an automated proof checker for texts written in a
controlled fragment of German, designed for didactical applications in classes
introducing students to proofs for the first time. The first version of the
system used a controlled natural language for which a Prolog formalization
routine was written. In this paper, we explore the possibility of prompting
large language models for autoformalization in the context of Diproche, with
encouraging first results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hindi as a Second Language: Improving Visually Grounded Speech with Semantically Similar Samples. (arXiv:2303.17517v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17517">
<div class="article-summary-box-inner">
<span><p>The objective of this work is to explore the learning of visually grounded
speech models (VGS) from multilingual perspective. Bilingual VGS models are
generally trained with an equal number of spoken captions from both languages.
However, in reality, there can be an imbalance among the languages for the
available spoken captions. Our key contribution in this work is to leverage the
power of a high-resource language in a bilingual visually grounded speech model
to improve the performance of a low-resource language. We introduce two methods
to distill the knowledge of high-resource language into low-resource languages:
(1) incorporating a strong pre-trained high-resource language encoder and (2)
using semantically similar spoken captions. Our experiments show that combining
these two approaches effectively enables the low-resource language to surpass
the performances of monolingual and bilingual counterparts for cross-modal
retrieval tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Whose Opinions Do Language Models Reflect?. (arXiv:2303.17548v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17548">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) are increasingly being used in open-ended contexts,
where the opinions reflected by LMs in response to subjective queries can have
a profound impact, both on user satisfaction, as well as shaping the views of
society at large. In this work, we put forth a quantitative framework to
investigate the opinions reflected by LMs -- by leveraging high-quality public
opinion polls and their associated human responses. Using this framework, we
create OpinionsQA, a new dataset for evaluating the alignment of LM opinions
with those of 60 US demographic groups over topics ranging from abortion to
automation. Across topics, we find substantial misalignment between the views
reflected by current LMs and those of US demographic groups: on par with the
Democrat-Republican divide on climate change. Notably, this misalignment
persists even after explicitly steering the LMs towards particular demographic
groups. Our analysis not only confirms prior observations about the
left-leaning tendencies of some human feedback-tuned LMs, but also surfaces
groups whose opinions are poorly reflected by current LMs (e.g., 65+ and
widowed individuals). Our code and data are available at
https://github.com/tatsu-lab/opinions_qa.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recognition, recall, and retention of few-shot memories in large language models. (arXiv:2303.17557v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17557">
<div class="article-summary-box-inner">
<span><p>The training of modern large language models (LLMs) takes place in a regime
where most training examples are seen only a few times by the model during the
course of training. What does a model remember about such examples seen only a
few times during training and how long does that memory persist in the face of
continuous training with new examples? Here, we investigate these questions
through simple recognition, recall, and retention experiments with LLMs. In
recognition experiments, we ask if the model can distinguish the seen example
from a novel example; in recall experiments, we ask if the model can correctly
recall the seen example when cued by a part of it; and in retention
experiments, we periodically probe the model's memory for the original examples
as the model is trained continuously with new examples. We find that a single
exposure is generally sufficient for a model to achieve near perfect accuracy
even in very challenging recognition experiments. We estimate that the
recognition performance of even small language models easily exceeds human
recognition performance reported in similar experiments with humans (Shepard,
1967). Achieving near perfect recall takes more exposures, but most models can
do it in just 3 exposures. The flip side of this remarkable capacity for fast
learning is that precise memories are quickly overwritten: recall performance
for the original examples drops steeply over the first 10 training updates with
new examples, followed by a more gradual decline. Even after 100K updates,
however, some of the original examples are still recalled near perfectly. A
qualitatively similar retention pattern has been observed in human long-term
memory retention studies before (Bahrick, 1984). Finally, recognition is much
more robust to interference than recall and memory for natural language
sentences is generally superior to memory for stimuli without structure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BloombergGPT: A Large Language Model for Finance. (arXiv:2303.17564v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17564">
<div class="article-summary-box-inner">
<span><p>The use of NLP in the realm of financial technology is broad and complex,
with applications ranging from sentiment analysis and named entity recognition
to question answering. Large Language Models (LLMs) have been shown to be
effective on a variety of tasks; however, no LLM specialized for the financial
domain has been reported in literature. In this work, we present BloombergGPT,
a 50 billion parameter language model that is trained on a wide range of
financial data. We construct a 363 billion token dataset based on Bloomberg's
extensive data sources, perhaps the largest domain-specific dataset yet,
augmented with 345 billion tokens from general purpose datasets. We validate
BloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suite
of internal benchmarks that most accurately reflect our intended usage. Our
mixed dataset training leads to a model that outperforms existing models on
financial tasks by significant margins without sacrificing performance on
general LLM benchmarks. Additionally, we explain our modeling choices, training
process, and evaluation methodology. As a next step, we plan to release
training logs (Chronicles) detailing our experience in training BloombergGPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Elastic Weight Removal for Faithful and Abstractive Dialogue Generation. (arXiv:2303.17574v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17574">
<div class="article-summary-box-inner">
<span><p>Ideally, dialogue systems should generate responses that are faithful to the
knowledge contained in relevant documents. However, many models generate
hallucinated responses instead that contradict it or contain unverifiable
information. To mitigate such undesirable behaviour, it has been proposed to
fine-tune a `negative expert' on negative examples and subtract its parameters
from those of a pre-trained model. However, intuitively, this does not take
into account that some parameters are more responsible than others in causing
hallucinations. Thus, we propose to weigh their individual importance via (an
approximation of) the Fisher Information matrix, which measures the uncertainty
of their estimate. We call this method Elastic Weight Removal (EWR). We
evaluate our method -- using different variants of Flan-T5 as a backbone
language model -- on multiple datasets for information-seeking dialogue
generation and compare our method with state-of-the-art techniques for
faithfulness, such as CTRL, Quark, DExperts, and Noisy Channel reranking.
Extensive automatic and human evaluation shows that EWR systematically
increases faithfulness at minor costs in terms of other metrics. However, we
notice that only discouraging hallucinations may increase extractiveness, i.e.
shallow copy-pasting of document spans, which can be undesirable. Hence, as a
second main contribution, we show that our method can be extended to
simultaneously discourage hallucinations and extractive responses. We publicly
release the code for reproducing EWR and all baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Image-Text Matching Improves Retrieval-based Chest X-Ray Report Generation. (arXiv:2303.17579v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17579">
<div class="article-summary-box-inner">
<span><p>Automated generation of clinically accurate radiology reports can improve
patient care. Previous report generation methods that rely on image captioning
models often generate incoherent and incorrect text due to their lack of
relevant domain knowledge, while retrieval-based attempts frequently retrieve
reports that are irrelevant to the input image. In this work, we propose
Contrastive X-Ray REport Match (X-REM), a novel retrieval-based radiology
report generation module that uses an image-text matching score to measure the
similarity of a chest X-ray image and radiology report for report retrieval. We
observe that computing the image-text matching score with a language-image
model can effectively capture the fine-grained interaction between image and
text that is often lost when using cosine similarity. X-REM outperforms
multiple prior radiology report generation modules in terms of both natural
language and clinical metrics. Human evaluation of the generated reports
suggests that X-REM increased the number of zero-error reports and decreased
the average error severity compared to the baseline retrieval approach. Our
code is available at: https://github.com/rajpurkarlab/X-REM
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace. (arXiv:2303.17580v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17580">
<div class="article-summary-box-inner">
<span><p>Solving complicated AI tasks with different domains and modalities is a key
step toward artificial general intelligence (AGI). While there are abundant AI
models available for different domains and modalities, they cannot handle
complicated AI tasks. Considering large language models (LLMs) have exhibited
exceptional ability in language understanding, generation, interaction, and
reasoning, we advocate that LLMs could act as a controller to manage existing
AI models to solve complicated AI tasks and language could be a generic
interface to empower this. Based on this philosophy, we present HuggingGPT, a
system that leverages LLMs (e.g., ChatGPT) to connect various AI models in
machine learning communities (e.g., HuggingFace) to solve AI tasks.
Specifically, we use ChatGPT to conduct task planning when receiving a user
request, select models according to their function descriptions available in
HuggingFace, execute each subtask with the selected AI model, and summarize the
response according to the execution results. By leveraging the strong language
capability of ChatGPT and abundant AI models in HuggingFace, HuggingGPT is able
to cover numerous sophisticated AI tasks in different modalities and domains
and achieve impressive results in language, vision, speech, and other
challenging tasks, which paves a new way towards AGI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Going Beyond Nouns With Vision & Language Models Using Synthetic Data. (arXiv:2303.17590v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.17590">
<div class="article-summary-box-inner">
<span><p>Large-scale pre-trained Vision &amp; Language (VL) models have shown remarkable
performance in many applications, enabling replacing a fixed set of supported
classes with zero-shot open vocabulary reasoning over (almost arbitrary)
natural language prompts. However, recent works have uncovered a fundamental
weakness of these models. For example, their difficulty to understand Visual
Language Concepts (VLC) that go 'beyond nouns' such as the meaning of
non-object words (e.g., attributes, actions, relations, states, etc.), or
difficulty in performing compositional reasoning such as understanding the
significance of the order of the words in a sentence. In this work, we
investigate to which extent purely synthetic data could be leveraged to teach
these models to overcome such shortcomings without compromising their zero-shot
capabilities. We contribute Synthetic Visual Concepts (SyViC) - a million-scale
synthetic dataset and data generation codebase allowing to generate additional
suitable data to improve VLC understanding and compositional reasoning of VL
models. Additionally, we propose a general VL finetuning strategy for
effectively leveraging SyViC towards achieving these improvements. Our
extensive experiments and ablations on VL-Checklist, Winoground, and ARO
benchmarks demonstrate that it is possible to adapt strong pre-trained VL
models with synthetic data significantly enhancing their VLC understanding
(e.g. by 9.9% on ARO and 4.3% on VL-Checklist) with under 1% drop in their
zero-shot accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Continual Learning with Global Prototypes: Counteracting Negative Representation Drift. (arXiv:2205.12186v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12186">
<div class="article-summary-box-inner">
<span><p>Continual learning (CL) aims to learn a sequence of tasks over time, with
data distributions shifting from one task to another. When training on new task
data, data representations from old tasks may drift. Some negative
representation drift can result in catastrophic forgetting, by causing the
locally learned class prototypes and data representations to correlate poorly
across tasks. To mitigate such representation drift, we propose a method that
finds global prototypes to guide the learning, and learns data representations
with the regularization of the self-supervised information. Specifically, for
NLP tasks, we formulate each task in a masked language modeling style, and
learn the task via a neighbor attention mechanism over a pre-trained language
model. Experimental results show that our proposed method can learn fairly
consistent representations with less representation drift, and significantly
reduce catastrophic forgetting in CL without resampling data from past tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-grained Image Captioning with CLIP Reward. (arXiv:2205.13115v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.13115">
<div class="article-summary-box-inner">
<span><p>Modern image captioning models are usually trained with text similarity
objectives. However, since reference captions in public datasets often describe
the most salient common objects, models trained with text similarity objectives
tend to ignore specific and detailed aspects of an image that distinguish it
from others. Toward more descriptive and distinctive caption generation, we
propose using CLIP, a multimodal encoder trained on huge image-text pairs from
web, to calculate multimodal similarity and use it as a reward function. We
also propose a simple finetuning strategy of the CLIP text encoder to improve
grammar that does not require extra text annotation. This completely eliminates
the need for reference captions during the reward computation. To
comprehensively evaluate descriptive captions, we introduce FineCapEval, a new
dataset for caption evaluation with fine-grained criteria: overall, background,
object, relations. In our experiments on text-to-image retrieval and
FineCapEval, the proposed CLIP-guided model generates more distinctive captions
than the CIDEr-optimized model. We also show that our unsupervised grammar
finetuning of the CLIP text encoder alleviates the degeneration problem of the
naive CLIP reward. Lastly, we show human analysis where the annotators strongly
prefer the CLIP reward to the CIDEr and MLE objectives according to various
criteria. Code and Data: https://github.com/j-min/CLIP-Caption-Reward
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition. (arXiv:2206.08317v3 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08317">
<div class="article-summary-box-inner">
<span><p>Transformers have recently dominated the ASR field. Although able to yield
good performance, they involve an autoregressive (AR) decoder to generate
tokens one by one, which is computationally inefficient. To speed up inference,
non-autoregressive (NAR) methods, e.g. single-step NAR, were designed, to
enable parallel generation. However, due to an independence assumption within
the output tokens, performance of single-step NAR is inferior to that of AR
models, especially with a large-scale corpus. There are two challenges to
improving single-step NAR: Firstly to accurately predict the number of output
tokens and extract hidden variables; secondly, to enhance modeling of
interdependence between output tokens. To tackle both challenges, we propose a
fast and accurate parallel transformer, termed Paraformer. This utilizes a
continuous integrate-and-fire based predictor to predict the number of tokens
and generate hidden variables. A glancing language model (GLM) sampler then
generates semantic embeddings to enhance the NAR decoder's ability to model
context interdependence. Finally, we design a strategy to generate negative
samples for minimum word error rate training to further improve performance.
Experiments using the public AISHELL-1, AISHELL-2 benchmark, and an
industrial-level 20,000 hour task demonstrate that the proposed Paraformer can
attain comparable performance to the state-of-the-art AR transformer, with more
than 10x speedup.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence. (arXiv:2209.02970v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.02970">
<div class="article-summary-box-inner">
<span><p>Nowadays, foundation models become one of fundamental infrastructures in
artificial intelligence, paving ways to the general intelligence. However, the
reality presents two urgent challenges: existing foundation models are
dominated by the English-language community; users are often given limited
resources and thus cannot always use foundation models. To support the
development of the Chinese-language community, we introduce an open-source
project, called Fengshenbang, which leads by the research center for Cognitive
Computing and Natural Language (CCNL). Our project has comprehensive
capabilities, including large pre-trained models, user-friendly APIs,
benchmarks, datasets, and others. We wrap all these in three sub-projects: the
Fengshenbang Model, the Fengshen Framework, and the Fengshen Benchmark. An
open-source roadmap, Fengshenbang, aims to re-evaluate the open-source
community of Chinese pre-trained large-scale models, prompting the development
of the entire Chinese large-scale model community. We also want to build a
user-centered open-source ecosystem to allow individuals to access the desired
models to match their computing resources. Furthermore, we invite companies,
colleges, and research institutions to collaborate with us to build the
large-scale open-source model-based ecosystem. We hope that this project will
be the foundation of Chinese cognitive intelligence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language-Family Adapters for Low-Resource Multilingual Neural Machine Translation. (arXiv:2209.15236v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.15236">
<div class="article-summary-box-inner">
<span><p>Large multilingual models trained with self-supervision achieve
state-of-the-art results in a wide range of natural language processing tasks.
Self-supervised pretrained models are often fine-tuned on parallel data from
one or multiple language pairs for machine translation. Multilingual
fine-tuning improves performance on low-resource languages but requires
modifying the entire model and can be prohibitively expensive. Training a new
adapter on each language pair or training a single adapter on all language
pairs without updating the pretrained model has been proposed as a
parameter-efficient alternative. However, the former does not permit any
sharing between languages, while the latter shares parameters for all languages
and is susceptible to negative interference. In this paper, we propose training
language-family adapters on top of mBART-50 to facilitate cross-lingual
transfer. Our approach outperforms related baselines, yielding higher
translation scores on average when translating from English to 17 different
low-resource languages. We also show that language-family adapters provide an
effective method to translate to languages unseen during pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Temporal Modelling of Clinical Depression through Social Media Text. (arXiv:2211.07717v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.07717">
<div class="article-summary-box-inner">
<span><p>We describe the development of a model to detect user-level clinical
depression based on a user's temporal social media posts. Our model uses a
Depression Symptoms Detection (DSD) classifier, which is trained on the largest
existing samples of clinician annotated tweets for clinical depression
symptoms. We subsequently use our DSD model to extract clinically relevant
features, e.g., depression scores and their consequent temporal patterns, as
well as user posting activity patterns, e.g., quantifying their ``no activity''
or ``silence.'' Furthermore, to evaluate the efficacy of these extracted
features, we create three kinds of datasets including a test dataset, from two
existing well-known benchmark datasets for user-level depression detection. We
then provide accuracy measures based on single features, baseline features and
feature ablation tests, at several different levels of temporal granularity.
The relevant data distributions and clinical depression detection related
settings can be exploited to draw a complete picture of the impact of different
features across our created datasets. Finally, we show that, in general, only
semantic oriented representation models perform well. However, clinical
features may enhance overall performance provided that the training and testing
distribution is similar, and there is more data in a user's timeline. The
consequence is that the predictive capability of depression scores increase
significantly while used in a more sensitive clinical depression detection
settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models. (arXiv:2212.04088v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04088">
<div class="article-summary-box-inner">
<span><p>This study focuses on using large language models (LLMs) as a planner for
embodied agents that can follow natural language instructions to complete
complex tasks in a visually-perceived environment. The high data cost and poor
sample efficiency of existing methods hinders the development of versatile
agents that are capable of many tasks and can learn new tasks quickly. In this
work, we propose a novel method, LLM-Planner, that harnesses the power of large
language models to do few-shot planning for embodied agents. We further propose
a simple but effective way to enhance LLMs with physical grounding to generate
and update plans that are grounded in the current environment. Experiments on
the ALFRED dataset show that our method can achieve very competitive few-shot
performance: Despite using less than 0.5% of paired training data, LLM-Planner
achieves competitive performance with recent baselines that are trained using
the full training data. Existing methods can barely complete any task
successfully under the same few-shot setting. Our work opens the door for
developing versatile and sample-efficient embodied agents that can quickly
learn many tasks. Website: https://dki-lab.github.io/LLM-Planner
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TempCLR: Temporal Alignment Representation with Contrastive Learning. (arXiv:2212.13738v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.13738">
<div class="article-summary-box-inner">
<span><p>Video representation learning has been successful in video-text pre-training
for zero-shot transfer, where each sentence is trained to be close to the
paired video clips in a common feature space. For long videos, given a
paragraph of description where the sentences describe different segments of the
video, by matching all sentence-clip pairs, the paragraph and the full video
are aligned implicitly. However, such unit-level comparison may ignore global
temporal context, which inevitably limits the generalization ability. In this
paper, we propose a contrastive learning framework TempCLR to compare the full
video and the paragraph explicitly. As the video/paragraph is formulated as a
sequence of clips/sentences, under the constraint of their temporal order, we
use dynamic time warping to compute the minimum cumulative cost over
sentence-clip pairs as the sequence-level distance. To explore the temporal
dynamics, we break the consistency of temporal succession by shuffling video
clips w.r.t. temporal granularity. Then, we obtain the representations for
clips/sentences, which perceive the temporal information and thus facilitate
the sequence alignment. In addition to pre-training on the video and paragraph,
our approach can also generalize on the matching between video instances. We
evaluate our approach on video retrieval, action step localization, and
few-shot action recognition, and achieve consistent performance gain over all
three tasks. Detailed ablation studies are provided to justify the approach
design.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"Correct answers" from the psychology of artificial intelligence. (arXiv:2302.07267v4 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07267">
<div class="article-summary-box-inner">
<span><p>We re-replicate 14 psychology studies from the Many Labs 2 replication
project (Klein et al., 2018) with OpenAI's text-davinci-003 model, colloquially
known as GPT3.5. Among the eight studies we could analyse, our GPT sample
replicated 37.5% of the original results and 37.5% of the Many Labs 2 results.
We could not analyse the remaining six studies, due to an unexpected phenomenon
we call the "correct answer" effect. Different runs of GPT3.5 answered nuanced
questions probing political orientation, economic preference, judgement, and
moral philosophy with zero or near-zero variation in responses: with the
supposedly "correct answer." Most but not all of these "correct answers" were
robust to changing the order of answer choices. One exception occurred in the
Moral Foundations Theory survey (Graham et al., 2009), for which GPT3.5 almost
always identified as a conservative in the original condition (N=1,030, 99.6%)
and as a liberal in the reverse-order condition (N=1,030, 99.3%). GPT3.5's
responses to subsequent questions revealed post-hoc rationalisation; there was
a relative bias in the direction of its previously reported political
orientation. But both self-reported GPT conservatives and self-reported GPT
liberals revealed right-leaning Moral Foundations, although the right-leaning
bias of self-reported GPT liberals was weaker. We hypothesise that this pattern
was learned from a conservative bias in the model's largely Internet-based
training data. Since AI models of the future may be trained on much of the same
Internet data as GPT3.5, our results raise concerns that a hypothetical AI-led
future may be subject to a diminished diversity of thought.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT. (arXiv:2302.09419v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.09419">
<div class="article-summary-box-inner">
<span><p>Pretrained Foundation Models (PFMs) are regarded as the foundation for
various downstream tasks with different data modalities. A PFM (e.g., BERT,
ChatGPT, and GPT-4) is trained on large-scale data which provides a reasonable
parameter initialization for a wide range of downstream applications. BERT
learns bidirectional encoder representations from Transformers, which are
trained on large datasets as contextual language models. Similarly, the
generative pretrained transformer (GPT) method employs Transformers as the
feature extractor and is trained using an autoregressive paradigm on large
datasets. Recently, ChatGPT shows promising success on large language models,
which applies an autoregressive language model with zero shot or few shot
prompting. The remarkable achievements of PFM have brought significant
breakthroughs to various fields of AI. Numerous studies have proposed different
methods, raising the demand for an updated survey. This study provides a
comprehensive review of recent research advancements, challenges, and
opportunities for PFMs in text, image, graph, as well as other data modalities.
The review covers the basic components and existing pretraining methods used in
natural language processing, computer vision, and graph learning. Additionally,
it explores advanced PFMs used for different data modalities and unified PFMs
that consider data quality and quantity. The review also discusses research
related to the fundamentals of PFMs, such as model efficiency and compression,
security, and privacy. Finally, the study provides key implications, future
research directions, challenges, and open problems in the field of PFMs.
Overall, this survey aims to shed light on the research of the PFMs on
scalability, security, logical reasoning ability, cross-domain learning
ability, and the user-friendly interactive ability for artificial general
intelligence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified Text Structuralization with Instruction-tuned Language Models. (arXiv:2303.14956v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.14956">
<div class="article-summary-box-inner">
<span><p>Text structuralization is one of the important fields of natural language
processing (NLP) consists of information extraction (IE) and structure
formalization. However, current studies of text structuralization suffer from a
shortage of manually annotated high-quality datasets from different domains and
languages, which require specialized professional knowledge. In addition, most
IE methods are designed for a specific type of structured data, e.g., entities,
relations, and events, making them hard to generalize to others. In this work,
we propose a simple and efficient approach to instruct large language model
(LLM) to extract a variety of structures from texts. More concretely, we add a
prefix and a suffix instruction to indicate the desired IE task and structure
type, respectively, before feeding the text into a LLM. Experiments on two LLMs
show that this approach can enable language models to perform comparable with
other state-of-the-art methods on datasets of a variety of languages and
knowledge, and can generalize to other IE sub-tasks via changing the content of
instruction. Another benefit of our approach is that it can help researchers to
build datasets in low-source and domain-specific scenarios, e.g., fields in
finance and law, with low cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks. (arXiv:2303.16839v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.16839">
<div class="article-summary-box-inner">
<span><p>The development of language models have moved from encoder-decoder to
decoder-only designs. In addition, the common knowledge has it that the two
most popular multimodal tasks, the generative and contrastive tasks, tend to
conflict with one another, are hard to accommodate in one architecture, and
further need complex adaptations for downstream tasks. We propose a novel
paradigm of training with a decoder-only model for multimodal tasks, which is
surprisingly effective in jointly learning of these disparate vision-language
tasks. This is done with a simple model, called MaMMUT. It consists of a single
vision encoder and a text decoder, and is able to accommodate contrastive and
generative learning by a novel two-pass approach on the text decoder. We
demonstrate that joint learning of these diverse objectives is simple,
effective, and maximizes the weight-sharing of the model across these tasks.
Furthermore, the same architecture enables straightforward extensions to
open-vocabulary object detection and video-language tasks. The model tackles a
diverse range of tasks, while being modest in capacity. Our model achieves the
state of the art on image-text and text-image retrieval, video question
answering and open-vocabulary detection tasks, outperforming much larger and
more extensively trained foundational models. It shows very competitive results
on VQA and Video Captioning, especially considering its capacity. Ablations
confirm the flexibility and advantages of our approach.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-04-01 23:10:50.382743040 UTC">2023-04-01 23:10:50 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>