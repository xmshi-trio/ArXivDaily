<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-04-26T01:30:00Z">04-26</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-trained Embeddings for Entity Resolution: An Experimental Analysis [Experiment, Analysis & Benchmark]. (arXiv:2304.12329v1 [cs.DB])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12329">
<div class="article-summary-box-inner">
<span><p>Many recent works on Entity Resolution (ER) leverage Deep Learning techniques
involving language models to improve effectiveness. This is applied to both
main steps of ER, i.e., blocking and matching. Several pre-trained embeddings
have been tested, with the most popular ones being fastText and variants of the
BERT model. However, there is no detailed analysis of their pros and cons. To
cover this gap, we perform a thorough experimental analysis of 12 popular
language models over 17 established benchmark datasets. First, we assess their
vectorization overhead for converting all input entities into dense embeddings
vectors. Second, we investigate their blocking performance, performing a
detailed scalability analysis, and comparing them with the state-of-the-art
deep learning-based blocking method. Third, we conclude with their relative
performance for both supervised and unsupervised matching. Our experimental
results provide novel insights into the strengths and weaknesses of the main
language models, facilitating researchers and practitioners to select the most
suitable ones in practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">USTEP: Structuration des logs en flux gr{\^a}ce {\`a} un arbre de recherche {\'e}volutif. (arXiv:2304.12331v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12331">
<div class="article-summary-box-inner">
<span><p>Logs record valuable system information at runtime. They are widely used by
data-driven approaches for development and monitoring purposes. Parsing log
messages to structure their format is a classic preliminary step for log-mining
tasks. As they appear upstream, parsing operations can become a processing time
bottleneck for downstream applications. The quality of parsing also has a
direct influence on their efficiency. Here, we propose USTEP, an online log
parsing method based on an evolving tree structure. Evaluation results on a
wide panel of datasets coming from different real-world systems demonstrate
USTEP superiority in terms of both effectiveness and robustness when compared
to other online methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Better Question-Answering Models on a Budget. (arXiv:2304.12370v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12370">
<div class="article-summary-box-inner">
<span><p>Low-rank adaptation (LoRA) and question-answer datasets from large language
models have made it much easier for much smaller models to be finetuned to the
point where they display sophisticated conversational abilities. In this paper,
we present Eluwa, a family of LoRA models that use the Stanford Alpaca dataset
and massively improve the capabilities of Facebook's OPT 1.3B, 2.7B and 6.7B
models. We benchmark these models in multiple ways, including letting GPT-4
judge their answers to prompts that span general knowledge, writing,
programming and other tasks. We show that smaller models here can be fine-tuned
to be as performant as models 3x larger - all for as little as 40 USD in
compute.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extreme Classification for Answer Type Prediction in Question Answering. (arXiv:2304.12395v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12395">
<div class="article-summary-box-inner">
<span><p>Semantic answer type prediction (SMART) is known to be a useful step towards
effective question answering (QA) systems. The SMART task involves predicting
the top-$k$ knowledge graph (KG) types for a given natural language question.
This is challenging due to the large number of types in KGs. In this paper, we
propose use of extreme multi-label classification using Transformer models
(XBERT) by clustering KG types using structural and semantic features based on
question text. We specifically improve the clustering stage of the XBERT
pipeline using textual and structural features derived from KGs. We show that
these features can improve end-to-end performance for the SMART task, and yield
state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research. (arXiv:2304.12397v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12397">
<div class="article-summary-box-inner">
<span><p>Perception of toxicity evolves over time and often differs between
geographies and cultural backgrounds. Similarly, black-box commercially
available APIs for detecting toxicity, such as the Perspective API, are not
static, but frequently retrained to address any unattended weaknesses and
biases. We evaluate the implications of these changes on the reproducibility of
findings that compare the relative merits of models and methods that aim to
curb toxicity. Our findings suggest that research that relied on inherited
automatic toxicity scores to compare models and techniques may have resulted in
inaccurate findings. Rescoring all models from HELM, a widely respected living
benchmark, for toxicity with the recent version of the API led to a different
ranking of widely used foundation models. We suggest caution in applying
apples-to-apples comparisons between studies and lay recommendations for a more
structured approach to evaluating toxicity over time. Code and data are
available at https://github.com/for-ai/black-box-api-challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Tokenizer for Enhanced Natural Language Processing. (arXiv:2304.12404v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12404">
<div class="article-summary-box-inner">
<span><p>Traditionally, NLP performance improvement has been focused on improving
models and increasing the number of model parameters. NLP vocabulary
construction has remained focused on maximizing the number of words represented
through subword regularization. We present a novel tokenizer that uses
semantics to drive vocabulary construction. The tokenizer includes a trainer
that uses stemming to enhance subword formation. Further optimizations and
adaptations are implemented to minimize the number of words that cannot be
encoded. The encoder is updated to integrate with the trainer. The tokenizer is
implemented as a drop-in replacement for the SentencePiece tokenizer. The new
tokenizer more than doubles the number of wordforms represented in the
vocabulary. The enhanced vocabulary significantly improves NLP model
convergence, and improves quality of word and sentence embeddings. Our
experimental results show top performance on two Glue tasks using BERT-base,
improving on models more than 50X in size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PEFT-Ref: A Modular Reference Architecture and Typology for Parameter-Efficient Finetuning Techniques. (arXiv:2304.12410v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12410">
<div class="article-summary-box-inner">
<span><p>Recent parameter-efficient finetuning (PEFT) techniques aim to improve over
the considerable cost of fully finetuning large pretrained language models
(PLM). As different PEFT techniques proliferate, it is becoming difficult to
compare them, in particular in terms of (i) the structure and functionality
they add to the PLM, (ii) the different types and degrees of efficiency
improvements achieved, (iii) performance at different downstream tasks, and
(iv) how differences in structure and functionality relate to efficiency and
task performance. To facilitate such comparisons, this paper presents a
reference framework which standardises aspects shared by different PEFT
techniques, while isolating differences to specific locations and interactions
with the standard components. Through this process of standardising and
isolating differences, a modular view of PEFT techniques emerges, supporting
not only direct comparison of different techniques and their efficiency and
task performance, but also systematic exploration of reusability and
composability of the different types of finetuned modules. We demonstrate how
the reference framework can be applied to understand properties and relative
advantages of PEFT techniques, hence to inform selection of techniques for
specific tasks, and design choices for new PEFT techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT (Feb 13 Version) is a Chinese Room. (arXiv:2304.12411v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12411">
<div class="article-summary-box-inner">
<span><p>ChatGPT has gained both positive and negative publicity after reports
suggesting that it is able to pass various professional and licensing
examinations. This suggests that ChatGPT may pass Turing Test in the near
future. However, a computer program that passing Turing Test can either mean
that it is a Chinese Room or artificially conscious. Hence, the question of
whether the current state of ChatGPT is more of a Chinese Room or approaching
artificial consciousness remains. Here, I demonstrate that the current version
of ChatGPT (Feb 13 version) is a Chinese Room. Despite potential evidence of
cognitive connections, ChatGPT exhibits critical errors in causal reasoning. At
the same time, I demonstrate that ChatGPT can generate all possible categorical
responses to the same question and response with erroneous examples; thus,
questioning its utility as a learning tool. I also show that ChatGPT is capable
of artificial hallucination, which is defined as generating confidently wrong
replies. It is likely that errors in causal reasoning leads to hallucinations.
More critically, ChatGPT generates false references to mimic real publications.
Therefore, its utility is cautioned.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TIGTEC : Token Importance Guided TExt Counterfactuals. (arXiv:2304.12425v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12425">
<div class="article-summary-box-inner">
<span><p>Counterfactual examples explain a prediction by highlighting changes of
instance that flip the outcome of a classifier. This paper proposes TIGTEC, an
efficient and modular method for generating sparse, plausible and diverse
counterfactual explanations for textual data. TIGTEC is a text editing
heuristic that targets and modifies words with high contribution using local
feature importance. A new attention-based local feature importance is proposed.
Counterfactual candidates are generated and assessed with a cost function
integrating semantic distance, while the solution space is efficiently explored
in a beam search fashion. The conducted experiments show the relevance of
TIGTEC in terms of success rate, sparsity, diversity and plausibility. This
method can be used in both model-specific or model-agnostic way, which makes it
very convenient for generating counterfactual explanations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding and Predicting Human Label Variation in Natural Language Inference through Explanation. (arXiv:2304.12443v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12443">
<div class="article-summary-box-inner">
<span><p>Human label variation (Plank 2022), or annotation disagreement, exists in
many natural language processing (NLP) tasks. To be robust and trusted, NLP
models need to identify such variation and be able to explain it. To this end,
we created the first ecologically valid explanation dataset with diverse
reasoning, LiveNLI. LiveNLI contains annotators' highlights and free-text
explanations for the label(s) of their choice for 122 English Natural Language
Inference items, each with at least 10 annotations. We used its explanations
for chain-of-thought prompting, and found there is still room for improvement
in GPT-3's ability to predict label distribution with in-context learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RenderDiffusion: Text Generation as Image Generation. (arXiv:2304.12519v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12519">
<div class="article-summary-box-inner">
<span><p>Diffusion models have become a new generative paradigm for text generation.
Considering the discrete categorical nature of text, in this paper, we propose
\textsc{RenderDiffusion}, a novel diffusion approach for text generation via
text-guided image generation. Our key idea is to render the target text as a
\emph{glyph image} containing visual language content. In this way, conditional
text generation can be cast as a glyph image generation task, and it is then
natural to apply continuous diffusion models to discrete texts. Specially, we
utilize a cascaded architecture (\ie a base and a super-resolution diffusion
model) to generate high-fidelity glyph images, conditioned on the input text.
Furthermore, we design a text grounding module to transform and refine the
visual language content from generated glyph images into the final texts. In
experiments over four conditional text generation tasks and two classes of
metrics (\ie quality and diversity), \textsc{RenderDiffusion} can achieve
comparable or even better results than several baselines, including pretrained
language models. Our model also makes significant improvements compared to the
recent diffusion model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KINLP at SemEval-2023 Task 12: Kinyarwanda Tweet Sentiment Analysis. (arXiv:2304.12569v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12569">
<div class="article-summary-box-inner">
<span><p>This paper describes the system entered by the author to the SemEval-2023
Task 12: Sentiment analysis for African languages. The system focuses on the
Kinyarwanda language and uses a language-specific model. Kinyarwanda morphology
is modeled in a two tier transformer architecture and the transformer model is
pre-trained on a large text corpus using multi-task masked morphology
prediction. The model is deployed on an experimental platform that allows users
to experiment with the pre-trained language model fine-tuning without the need
to write machine learning code. Our final submission to the shared task
achieves second ranking out of 34 teams in the competition, achieving 72.50%
weighted F1 score. Our analysis of the evaluation results highlights challenges
in achieving high accuracy on the task and identifies areas for improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explain like I am BM25: Interpreting a Dense Model's Ranked-List with a Sparse Approximation. (arXiv:2304.12631v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12631">
<div class="article-summary-box-inner">
<span><p>Neural retrieval models (NRMs) have been shown to outperform their
statistical counterparts owing to their ability to capture semantic meaning via
dense document representations. These models, however, suffer from poor
interpretability as they do not rely on explicit term matching. As a form of
local per-query explanations, we introduce the notion of equivalent queries
that are generated by maximizing the similarity between the NRM's results and
the result set of a sparse retrieval system with the equivalent query. We then
compare this approach with existing methods such as RM3-based query expansion
and contrast differences in retrieval effectiveness and in the terms generated
by each approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PUNR: Pre-training with User Behavior Modeling for News Recommendation. (arXiv:2304.12633v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12633">
<div class="article-summary-box-inner">
<span><p>News recommendation aims to predict click behaviors based on user behaviors.
How to effectively model the user representations is the key to recommending
preferred news. Existing works are mostly focused on improvements in the
supervised fine-tuning stage. However, there is still a lack of PLM-based
unsupervised pre-training methods optimized for user representations. In this
work, we propose an unsupervised pre-training paradigm with two tasks, i.e.
user behavior masking and user behavior generation, both towards effective user
behavior modeling. Firstly, we introduce the user behavior masking pre-training
task to recover the masked user behaviors based on their contextual behaviors.
In this way, the model could capture a much stronger and more comprehensive
user news reading pattern. Besides, we incorporate a novel auxiliary user
behavior generation pre-training task to enhance the user representation vector
derived from the user encoder. We use the above pre-trained user modeling
encoder to obtain news and user representations in downstream fine-tuning.
Evaluations on the real-world news benchmark show significant performance
improvements over existing baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Compressing Sentence Representation with maximum Coding Rate Reduction. (arXiv:2304.12674v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12674">
<div class="article-summary-box-inner">
<span><p>In most natural language inference problems, sentence representation is
needed for semantic retrieval tasks. In recent years, pre-trained large
language models have been quite effective for computing such representations.
These models produce high-dimensional sentence embeddings. An evident
performance gap between large and small models exists in practice. Hence, due
to space and time hardware limitations, there is a need to attain comparable
results when using the smaller model, which is usually a distilled version of
the large language model. In this paper, we assess the model distillation of
the sentence representation model Sentence-BERT by augmenting the pre-trained
distilled model with a projection layer additionally learned on the Maximum
Coding Rate Reduction (MCR2)objective, a novel approach developed for
general-purpose manifold clustering. We demonstrate that the new language model
with reduced complexity and sentence embedding size can achieve comparable
results on semantic retrieval benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What does BERT learn about prosody?. (arXiv:2304.12706v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12706">
<div class="article-summary-box-inner">
<span><p>Language models have become nearly ubiquitous in natural language processing
applications achieving state-of-the-art results in many tasks including
prosody. As the model design does not define predetermined linguistic targets
during training but rather aims at learning generalized representations of the
language, analyzing and interpreting the representations that models implicitly
capture is important in bridging the gap between interpretability and model
performance. Several studies have explored the linguistic information that
models capture providing some insights on their representational capacity.
However, the current studies have not explored whether prosody is part of the
structural information of the language that models learn. In this work, we
perform a series of experiments on BERT probing the representations captured at
different layers. Our results show that information about prosodic prominence
spans across many layers but is mostly focused in middle layers suggesting that
BERT relies mostly on syntactic and semantic information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CitePrompt: Using Prompts to Identify Citation Intent in Scientific Papers. (arXiv:2304.12730v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12730">
<div class="article-summary-box-inner">
<span><p>Citations in scientific papers not only help us trace the intellectual
lineage but also are a useful indicator of the scientific significance of the
work. Citation intents prove beneficial as they specify the role of the
citation in a given context. In this paper, we present CitePrompt, a framework
which uses the hitherto unexplored approach of prompt-based learning for
citation intent classification. We argue that with the proper choice of the
pretrained language model, the prompt template, and the prompt verbalizer, we
can not only get results that are better than or comparable to those obtained
with the state-of-the-art methods but also do it with much less exterior
information about the scientific document. We report state-of-the-art results
on the ACL-ARC dataset, and also show significant improvement on the SciCite
dataset over all baseline models except one. As suitably large labelled
datasets for citation intent classification can be quite hard to find, in a
first, we propose the conversion of this task to the few-shot and zero-shot
settings. For the ACL-ARC dataset, we report a 53.86% F1 score for the
zero-shot setting, which improves to 63.61% and 66.99% for the 5-shot and
10-shot settings, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Test-Time Adaptation with Perturbation Consistency Learning. (arXiv:2304.12764v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12764">
<div class="article-summary-box-inner">
<span><p>Currently, pre-trained language models (PLMs) do not cope well with the
distribution shift problem, resulting in models trained on the training set
failing in real test scenarios. To address this problem, the test-time
adaptation (TTA) shows great potential, which updates model parameters to suit
the test data at the testing time. Existing TTA methods rely on well-designed
auxiliary tasks or self-training strategies based on pseudo-label. However,
these methods do not achieve good trade-offs regarding performance gains and
computational costs. To obtain some insights into such a dilemma, we take two
representative TTA methods, i.e., Tent and OIL, for exploration and find that
stable prediction is the key to achieving a good balance. Accordingly, in this
paper, we propose perturbation consistency learning (PCL), a simple test-time
adaptation method to promote the model to make stable predictions for samples
with distribution shifts. Extensive experiments on adversarial robustness and
cross-lingual transferring demonstrate that our method can achieve higher or
comparable performance with less inference time over strong PLM backbones and
previous state-of-the-art TTA methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">State Spaces Aren't Enough: Machine Translation Needs Attention. (arXiv:2304.12776v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12776">
<div class="article-summary-box-inner">
<span><p>Structured State Spaces for Sequences (S4) is a recently proposed sequence
model with successful applications in various tasks, e.g. vision, language
modeling, and audio. Thanks to its mathematical formulation, it compresses its
input to a single hidden state, and is able to capture long range dependencies
while avoiding the need for an attention mechanism. In this work, we apply S4
to Machine Translation (MT), and evaluate several encoder-decoder variants on
WMT'14 and WMT'16. In contrast with the success in language modeling, we find
that S4 lags behind the Transformer by approximately 4 BLEU points, and that it
counter-intuitively struggles with long sentences. Finally, we show that this
gap is caused by S4's inability to summarize the full source sentence in a
single hidden state, and show that we can close the gap by introducing an
attention mechanism.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Voice Assistants Sound Cute? Towards a Model of Kawaii Vocalics. (arXiv:2304.12809v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12809">
<div class="article-summary-box-inner">
<span><p>The Japanese notion of "kawaii" or expressions of cuteness, vulnerability,
and/or charm is a global cultural export. Work has explored kawaii-ness as a
design feature and factor of user experience in the visual appearance,
nonverbal behaviour, and sound of robots and virtual characters. In this
initial work, we consider whether voices can be kawaii by exploring the vocal
qualities of voice assistant speech, i.e., kawaii vocalics. Drawing from an
age-inclusive model of kawaii, we ran a user perceptions study on the
kawaii-ness of younger- and older-sounding Japanese computer voices. We found
that kawaii-ness intersected with perceptions of gender and age, i.e., gender
ambiguous and girlish, as well as VA features, i.e., fluency and artificiality.
We propose an initial model of kawaii vocalics to be validated through the
identification and study of vocal qualities, cognitive appraisals, behavioural
responses, and affective reports.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transcending the "Male Code": Implicit Masculine Biases in NLP Contexts. (arXiv:2304.12810v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12810">
<div class="article-summary-box-inner">
<span><p>Critical scholarship has elevated the problem of gender bias in data sets
used to train virtual assistants (VAs). Most work has focused on explicit
biases in language, especially against women, girls, femme-identifying people,
and genderqueer folk; implicit associations through word embeddings; and
limited models of gender and masculinities, especially toxic masculinities,
conflation of sex and gender, and a sex/gender binary framing of the masculine
as diametric to the feminine. Yet, we must also interrogate how masculinities
are "coded" into language and the assumption of "male" as the linguistic
default: implicit masculine biases. To this end, we examined two natural
language processing (NLP) data sets. We found that when gendered language was
present, so were gender biases and especially masculine biases. Moreover, these
biases related in nuanced ways to the NLP context. We offer a new dictionary
called AVA that covers ambiguous associations between gendered language and the
language of VAs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Dual of Shannon Information and Weighting Scheme. (arXiv:2304.12814v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12814">
<div class="article-summary-box-inner">
<span><p>Shannon Information theory has achieved great success in not only
communication technology where it was originally developed for but also many
other science and engineering fields such as machine learning and artificial
intelligence. Inspired by the famous weighting scheme TF-IDF, we discovered
that information entropy has a natural dual. We complement the classical
Shannon information theory by proposing a novel quantity, namely troenpy.
Troenpy measures the certainty, commonness and similarity of the underlying
distribution. To demonstrate its usefulness, we propose a troenpy based
weighting scheme for document with class labels, namely positive class
frequency (PCF). On a collection of public datasets we show the PCF based
weighting scheme outperforms the classical TF-IDF and a popular Optimal
Transportation based word moving distance algorithm in a kNN setting. We
further developed a new odds-ratio type feature, namely Expected Class
Information Bias(ECIB), which can be regarded as the expected odds ratio of the
information quantity entropy and troenpy. In the experiments we observe that
including the new ECIB features and simple binary term features in a simple
logistic regression model can further significantly improve the performance.
The simple new weighting scheme and ECIB features are very effective and can be
computed with linear order complexity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Information Theory of Certainty for Machine Learning. (arXiv:2304.12833v1 [cs.IT])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12833">
<div class="article-summary-box-inner">
<span><p>Claude Shannon coined entropy to quantify the uncertainty of a random
distribution for communication coding theory. We observe that the uncertainty
nature of entropy also limits its direct usage in mathematical modeling.
Therefore we propose a new concept troenpy,as the canonical dual of entropy, to
quantify the certainty of the underlying distribution. We demonstrate two
applications in machine learning. The first is for the classical document
classification, we develop a troenpy based weighting scheme to leverage the
document class label. The second is a self-troenpy weighting scheme for
sequential data and show that it can be easily included in neural network based
language models and achieve dramatic perplexity reduction. We also define
quantum troenpy as the dual of the Von Neumann entropy to quantify the
certainty of quantum systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lessons Learned from a Citizen Science Project for Natural Language Processing. (arXiv:2304.12836v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12836">
<div class="article-summary-box-inner">
<span><p>Many Natural Language Processing (NLP) systems use annotated corpora for
training and evaluation. However, labeled data is often costly to obtain and
scaling annotation projects is difficult, which is why annotation tasks are
often outsourced to paid crowdworkers. Citizen Science is an alternative to
crowdsourcing that is relatively unexplored in the context of NLP. To
investigate whether and how well Citizen Science can be applied in this
setting, we conduct an exploratory study into engaging different groups of
volunteers in Citizen Science for NLP by re-annotating parts of a pre-existing
crowdsourced dataset. Our results show that this can yield high-quality
annotations and attract motivated volunteers, but also requires considering
factors such as scalability, participation over time, and legal and ethical
issues. We summarize lessons learned in the form of guidelines and provide our
code and data to aid future work on Citizen Science.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NLP-LTU at SemEval-2023 Task 10: The Impact of Data Augmentation and Semi-Supervised Learning Techniques on Text Classification Performance on an Imbalanced Dataset. (arXiv:2304.12847v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12847">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a methodology for task 10 of SemEval23, focusing on
detecting and classifying online sexism in social media posts. The task is
tackling a serious issue, as detecting harmful content on social media
platforms is crucial for mitigating the harm of these posts on users. Our
solution for this task is based on an ensemble of fine-tuned transformer-based
models (BERTweet, RoBERTa, and DeBERTa). To alleviate problems related to class
imbalance, and to improve the generalization capability of our model, we also
experiment with data augmentation and semi-supervised learning. In particular,
for data augmentation, we use back-translation, either on all classes, or on
the underrepresented classes only. We analyze the impact of these strategies on
the overall performance of the pipeline through extensive experiments. while
for semi-supervised learning, we found that with a substantial amount of
unlabelled, in-domain data available, semi-supervised learning can enhance the
performance of certain models. Our proposed method (for which the source code
is available on Github attains an F1-score of 0.8613 for sub-taskA, which
ranked us 10th in the competition
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Out-of-distribution Evidence-aware Fake News Detection via Dual Adversarial Debiasing. (arXiv:2304.12888v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12888">
<div class="article-summary-box-inner">
<span><p>Evidence-aware fake news detection aims to conduct reasoning between news and
evidence, which is retrieved based on news content, to find uniformity or
inconsistency. However, we find evidence-aware detection models suffer from
biases, i.e., spurious correlations between news/evidence contents and
true/fake news labels, and are hard to be generalized to Out-Of-Distribution
(OOD) situations. To deal with this, we propose a novel Dual Adversarial
Learning (DAL) approach. We incorporate news-aspect and evidence-aspect
debiasing discriminators, whose targets are both true/fake news labels, in DAL.
Then, DAL reversely optimizes news-aspect and evidence-aspect debiasing
discriminators to mitigate the impact of news and evidence content biases. At
the same time, DAL also optimizes the main fake news predictor, so that the
news-evidence interaction module can be learned. This process allows us to
teach evidence-aware fake news detection models to better conduct news-evidence
reasoning, and minimize the impact of content biases. To be noted, our proposed
DAL approach is a plug-and-play module that works well with existing backbones.
We conduct comprehensive experiments under two OOD settings, and plug DAL in
four evidence-aware fake news detection backbones. Results demonstrate that,
DAL significantly and stably outperforms the original backbones and some
competitive debiasing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topological properties and organizing principles of semantic networks. (arXiv:2304.12940v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12940">
<div class="article-summary-box-inner">
<span><p>Interpreting natural language is an increasingly important task in computer
algorithms due to the growing availability of unstructured textual data.
Natural Language Processing (NLP) applications rely on semantic networks for
structured knowledge representation. The fundamental properties of semantic
networks must be taken into account when designing NLP algorithms, yet they
remain to be structurally investigated. We study the properties of semantic
networks from ConceptNet, defined by 7 semantic relations from 11 different
languages. We find that semantic networks have universal basic properties: they
are sparse, highly clustered, and exhibit power-law degree distributions. Our
findings show that the majority of the considered networks are scale-free. Some
networks exhibit language-specific properties determined by grammatical rules,
for example networks from highly inflected languages, such as e.g. Latin,
German, French and Spanish, show peaks in the degree distribution that deviate
from a power law. We find that depending on the semantic relation type and the
language, the link formation in semantic networks is guided by different
principles. In some networks the connections are similarity-based, while in
others the connections are more complementarity-based. Finally, we demonstrate
how knowledge of similarity and complementarity in semantic networks can
improve NLP algorithms in missing link inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Nondeterministic Stacks in Neural Networks. (arXiv:2304.12955v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12955">
<div class="article-summary-box-inner">
<span><p>Human language is full of compositional syntactic structures, and although
neural networks have contributed to groundbreaking improvements in computer
systems that process language, widely-used neural network architectures still
exhibit limitations in their ability to process syntax. To address this issue,
prior work has proposed adding stack data structures to neural networks,
drawing inspiration from theoretical connections between syntax and stacks.
However, these methods employ deterministic stacks that are designed to track
one parse at a time, whereas syntactic ambiguity, which requires a
nondeterministic stack to parse, is extremely common in language. In this
dissertation, we remedy this discrepancy by proposing a method of incorporating
nondeterministic stacks into neural networks. We develop a differentiable data
structure that efficiently simulates a nondeterministic pushdown automaton,
representing an exponential number of computations with a dynamic programming
algorithm. We incorporate this module into two predominant architectures:
recurrent neural networks (RNNs) and transformers. We show that this raises
their formal recognition power to arbitrary context-free languages, and also
aids training, even on deterministic context-free languages. Empirically,
neural networks with nondeterministic stacks learn context-free languages much
more effectively than prior stack-augmented models, including a language with
theoretically maximal parsing difficulty. We also show that an RNN augmented
with a nondeterminsitic stack is capable of surprisingly powerful behavior,
such as learning cross-serial dependencies, a well-known non-context-free
pattern. We demonstrate improvements on natural language modeling and provide
analysis on a syntactic generalization benchmark. This work represents an
important step toward building systems that learn to use syntax in more
human-like fashion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Escaping the sentence-level paradigm in machine translation. (arXiv:2304.12959v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12959">
<div class="article-summary-box-inner">
<span><p>It is well-known that document context is vital for resolving a range of
translation ambiguities, and in fact the document setting is the most natural
setting for nearly all translation. It is therefore unfortunate that machine
translation -- both research and production -- largely remains stuck in a
decades-old sentence-level translation paradigm. It is also an increasingly
glaring problem in light of competitive pressure from large language models,
which are natively document-based. Much work in document-context machine
translation exists, but for various reasons has been unable to catch hold. This
paper suggests a path out of this rut by addressing three impediments at once:
what architectures should we use? where do we get document-level information
for training them? and how do we know whether they are any good? In contrast to
work on specialized architectures, we show that the standard Transformer
architecture is sufficient, provided it has enough capacity. Next, we address
the training data issue by taking document samples from back-translated data
only, where the data is not only more readily available, but is also of higher
quality compared to parallel document data, which may contain machine
translation output. Finally, we propose generative variants of existing
contrastive metrics that are better able to discriminate among document
systems. Results in four large-data language pairs (DE$\rightarrow$EN,
EN$\rightarrow$DE, EN$\rightarrow$FR, and EN$\rightarrow$RU) establish the
success of these three pieces together in improving document-level performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GMNLP at SemEval-2023 Task 12: Sentiment Analysis with Phylogeny-Based Adapters. (arXiv:2304.12979v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12979">
<div class="article-summary-box-inner">
<span><p>This report describes GMU's sentiment analysis system for the SemEval-2023
shared task AfriSenti-SemEval. We participated in all three sub-tasks:
Monolingual, Multilingual, and Zero-Shot. Our approach uses models initialized
with AfroXLMR-large, a pre-trained multilingual language model trained on
African languages and fine-tuned correspondingly. We also introduce augmented
training data along with original training data. Alongside finetuning, we
perform phylogeny-based adapter tuning to create several models and ensemble
the best models for the final submission. Our system achieves the best F1-score
on track 5: Amharic, with 6.2 points higher F1-score than the second-best
performing system on this track. Overall, our system ranks 5th among the 10
systems participating in all 15 tracks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Intent Induction from Conversations for Task-Oriented Dialogue Track at DSTC 11. (arXiv:2304.12982v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12982">
<div class="article-summary-box-inner">
<span><p>With increasing demand for and adoption of virtual assistants, recent work
has investigated ways to accelerate bot schema design through the automatic
induction of intents or the induction of slots and dialogue states. However, a
lack of dedicated benchmarks and standardized evaluation has made progress
difficult to track and comparisons between systems difficult to make. This
challenge track, held as part of the Eleventh Dialog Systems Technology
Challenge, introduces a benchmark that aims to evaluate methods for the
automatic induction of customer intents in a realistic setting of customer
service interactions between human agents and customers. We propose two
subtasks for progressively tackling the automatic induction of intents and
corresponding evaluation methodologies. We then present three datasets suitable
for evaluating the tasks and propose simple baselines. Finally, we summarize
the submissions and results of the challenge track, for which we received
submissions from 34 teams.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Measuring Massive Multitask Chinese Understanding. (arXiv:2304.12986v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12986">
<div class="article-summary-box-inner">
<span><p>The development of large-scale Chinese language models is flourishing, yet
there is a lack of corresponding capability assessments. Therefore, we propose
a test to measure the multitask accuracy of large Chinese language models. This
test encompasses four major domains, including medicine, law, psychology, and
education, with 15 subtasks in medicine and 8 subtasks in education. We found
that the best-performing models in the zero-shot setting outperformed the
worst-performing models by nearly 22 percentage points on average. Across the
four major domains, the average zero-shot accuracy of all models did not exceed
0.5. In the subdomains, only the GPT-3.5-turbo model achieved a zero-shot
accuracy of 0.703 in clinical medicine, which was the highest accuracy among
all models across all subtasks. All models performed poorly in the legal
domain, with the highest zero-shot accuracy reaching only 0.259. By
comprehensively evaluating the breadth and depth of knowledge across multiple
disciplines, this test can more accurately identify the shortcomings of the
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head. (arXiv:2304.12995v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12995">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have exhibited remarkable capabilities across a
variety of domains and tasks, challenging our understanding of learning and
cognition. Despite the recent success, current LLMs are not capable of
processing complex audio information or conducting spoken conversations (like
Siri or Alexa). In this work, we propose a multi-modal AI system named
AudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to
process complex audio information and solve numerous understanding and
generation tasks; and 2) the input/output interface (ASR, TTS) to support
spoken dialogue. With an increasing demand to evaluate multi-modal LLMs of
human intention understanding and cooperation with foundation models, we
outline the principles and processes and test AudioGPT in terms of consistency,
capability, and robustness. Experimental results demonstrate the capabilities
of AudioGPT in solving AI tasks with speech, music, sound, and talking head
understanding and generation in multi-round dialogues, which empower humans to
create rich and diverse audio content with unprecedented ease. Our system is
publicly available at \url{https://github.com/AIGC-Audio/AudioGPT}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatLLM Network: More brains, More intelligence. (arXiv:2304.12998v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12998">
<div class="article-summary-box-inner">
<span><p>Dialogue-based language models mark a huge milestone in the field of
artificial intelligence, by their impressive ability to interact with users, as
well as a series of challenging tasks prompted by customized instructions.
However, the prevalent large-scale dialogue-based language models like ChatGPT
still have room for improvement, such as unstable responses to questions and
the inability to think cooperatively like humans. Considering the ability of
dialogue-based language models in conversation and their inherent randomness in
thinking, we propose ChatLLM network that allows multiple dialogue-based
language models to interact, provide feedback, and think together. We design
the network of ChatLLMs based on ChatGPT. Specifically, individual instances of
ChatGPT may possess distinct perspectives towards the same problem, and by
consolidating these diverse viewpoints via a separate ChatGPT, the ChatLLM
network system can conduct decision-making more objectively and
comprehensively. In addition, a language-based feedback mechanism comparable to
backpropagation is devised to update the ChatGPTs within the network.
Experiments on two datasets demonstrate that our network attains significant
improvements in problem-solving, leading to observable progress amongst each
member.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Inter-Bilingual Semantic Parsing for Indian Languages. (arXiv:2304.13005v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.13005">
<div class="article-summary-box-inner">
<span><p>Despite significant progress in Natural Language Generation for Indian
languages (IndicNLP), there is a lack of datasets around complex structured
tasks such as semantic parsing. One reason for this imminent gap is the
complexity of the logical form, which makes English to multilingual translation
difficult. The process involves alignment of logical forms, intents and slots
with translated unstructured utterance. To address this, we propose an
Inter-bilingual Seq2seq Semantic parsing dataset IE-SEMPARSE for 11 distinct
Indian languages. We highlight the proposed task's practicality, and evaluate
existing multilingual seq2seq models across several train-test strategies. Our
experiment reveals a high correlation across performance of original
multilingual semantic parsing datasets (such as mTOP, multilingual TOP and
multiATIS++) and our proposed IE-SEMPARSE suite.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Answering Questions by Meta-Reasoning over Multiple Chains of Thought. (arXiv:2304.13007v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.13007">
<div class="article-summary-box-inner">
<span><p>Modern systems for multi-hop question answering (QA) typically break
questions into a sequence of reasoning steps, termed chain-of-thought (CoT),
before arriving at a final answer. Often, multiple chains are sampled and
aggregated through a voting mechanism over the final answers, but the
intermediate steps themselves are discarded. While such approaches improve
performance, they do not consider the relations between intermediate steps
across chains and do not provide a unified explanation for the predicted
answer. We introduce Multi-Chain Reasoning (MCR), an approach which prompts
large language models to meta-reason over multiple chains of thought, rather
than aggregating their answers. MCR examines different reasoning chains, mixes
information between them and selects the most relevant facts in generating an
explanation and predicting the answer. MCR outperforms strong baselines on 7
multi-hop QA datasets. Moreover, our analysis reveals that MCR explanations
exhibit high quality, enabling humans to verify its answers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unstructured and structured data: Can we have the best of both worlds with large language models?. (arXiv:2304.13010v1 [cs.DB])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.13010">
<div class="article-summary-box-inner">
<span><p>This paper presents an opinion on the potential of using large language
models to query on both unstructured and structured data. It also outlines some
research challenges related to the topic of building question-answering systems
for both types of data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating the Tradeoff Between Abstractiveness and Factuality in Abstractive Summarization. (arXiv:2108.02859v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02859">
<div class="article-summary-box-inner">
<span><p>Neural models for abstractive summarization tend to generate output that is
fluent and well-formed but lacks semantic faithfulness, or factuality, with
respect to the input documents. In this paper, we analyze the tradeoff between
abstractiveness and factuality of generated summaries across multiple datasets
and models, using extensive human evaluations of factuality. In our analysis,
we visualize the rates of change in factuality as we gradually increase
abstractiveness using a decoding constraint, and we observe that, while
increased abstractiveness generally leads to a drop in factuality, the rate of
factuality decay depends on factors such as the data that the system was
trained on. We introduce two datasets with human factuality judgements; one
containing 10.2k generated summaries with systematically varied degrees of
abstractiveness; the other containing 4.2k summaries from five different
summarization models. We propose new factuality metrics that adjust for the
degree of abstractiveness, and we use them to compare the
abstractiveness-adjusted factuality of previous summarization works, providing
baselines for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting Hate Intensity of Twitter Conversation Threads. (arXiv:2206.08406v3 [cs.SI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08406">
<div class="article-summary-box-inner">
<span><p>Tweets are the most concise form of communication in online social media,
wherein a single tweet has the potential to make or break the discourse of the
conversation. Online hate speech is more accessible than ever, and stifling its
propagation is of utmost importance for social media companies and users for
congenial communication. Most of the research barring a recent few has focused
on classifying an individual tweet regardless of the tweet thread/context
leading up to that point. One of the classical approaches to curb hate speech
is to adopt a reactive strategy after the hate speech postage. The ex-post
facto strategy results in neglecting subtle posts that do not show the
potential to instigate hate speech on their own but may portend in the
subsequent discussion ensuing in the post's replies. In this paper, we propose
DRAGNET++, which aims to predict the intensity of hatred that a tweet can bring
in through its reply chain in the future. It uses the semantic and propagating
structure of the tweet threads to maximize the contextual information leading
up to and the fall of hate intensity at each subsequent tweet. We explore three
publicly available Twitter datasets -- Anti-Racism contains the reply tweets of
a collection of social media discourse on racist remarks during US political
and Covid-19 background; Anti-Social presents a dataset of 40 million tweets
amidst the COVID-19 pandemic on anti-social behaviours; and Anti-Asian presents
Twitter datasets collated based on anti-Asian behaviours during COVID-19
pandemic. All the curated datasets consist of structural graph information of
the Tweet threads. We show that DRAGNET++ outperforms all the state-of-the-art
baselines significantly. It beats the best baseline by an 11% margin on the
Person correlation coefficient and a decrease of 25% on RMSE for the
Anti-Racism dataset with a similar performance on the other two datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Abstractive Meeting Summarization: A Survey. (arXiv:2208.04163v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.04163">
<div class="article-summary-box-inner">
<span><p>A system that could reliably identify and sum up the most important points of
a conversation would be valuable in a wide variety of real-world contexts, from
business meetings to medical consultations to customer service calls. Recent
advances in deep learning, and especially the invention of encoder-decoder
architectures, has significantly improved language generation systems, opening
the door to improved forms of abstractive summarization, a form of
summarization particularly well-suited for multi-party conversation. In this
paper, we provide an overview of the challenges raised by the task of
abstractive meeting summarization and of the data sets, models and evaluation
metrics that have been used to tackle the problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Augmenting Interpretable Models with LLMs during Training. (arXiv:2209.11799v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.11799">
<div class="article-summary-box-inner">
<span><p>Recent large language models (LLMs) have demonstrated remarkable prediction
performance for a growing array of tasks. However, their proliferation into
high-stakes domains (e.g. medicine) and compute-limited settings has created a
burgeoning need for interpretability and efficiency. We address this need by
proposing Augmented Interpretable Models (Aug-imodels), a framework for
leveraging the knowledge learned by LLMs to build extremely efficient and
interpretable models. Aug-imodels use LLMs during fitting but not during
inference, allowing complete transparency and often a speed/memory improvement
of greater than 1,000x for inference compared to LLMs. We explore two
instantiations of Aug-imodels in natural-language processing: (i) Aug-GAM,
which augments a generalized additive model with decoupled embeddings from an
LLM and (ii) Aug-Tree, which augments a decision tree with LLM feature
expansions. Across a variety of text-classification datasets, both outperform
their non-augmented counterparts. Aug-GAM can even outperform much larger
models (e.g. a 6-billion parameter GPT-J model), despite having 10,000x fewer
parameters and being fully transparent. We further explore Aug-imodels in a
natural-language fMRI study, where they generate interesting interpretations
from scientific data. All code for using Aug-imodels and reproducing results is
made available on Github.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StructDiffusion: Language-Guided Creation of Physically-Valid Structures using Unseen Objects. (arXiv:2211.04604v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.04604">
<div class="article-summary-box-inner">
<span><p>Robots operating in human environments must be able to rearrange objects into
semantically-meaningful configurations, even if these objects are previously
unseen. In this work, we focus on the problem of building physically-valid
structures without step-by-step instructions. We propose StructDiffusion, which
combines a diffusion model and an object-centric transformer to construct
structures given partial-view point clouds and high-level language goals, such
as "set the table". Our method can perform multiple challenging
language-conditioned multi-step 3D planning tasks using one model.
StructDiffusion even improves the success rate of assembling physically-valid
structures out of unseen objects by on average 16% over an existing multi-modal
transformer model trained on specific structures. We show experiments on
held-out objects in both simulation and on real-world rearrangement tasks.
Importantly, we show how integrating both a diffusion model and a
collision-discriminator model allows for improved generalization over other
methods when rearranging previously-unseen objects. For videos and additional
results, see our website: https://structdiffusion.github.io/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relation-Aware Language-Graph Transformer for Question Answering. (arXiv:2212.00975v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.00975">
<div class="article-summary-box-inner">
<span><p>Question Answering (QA) is a task that entails reasoning over natural
language contexts, and many relevant works augment language models (LMs) with
graph neural networks (GNNs) to encode the Knowledge Graph (KG) information.
However, most existing GNN-based modules for QA do not take advantage of rich
relational information of KGs and depend on limited information interaction
between the LM and the KG. To address these issues, we propose Question
Answering Transformer (QAT), which is designed to jointly reason over language
and graphs with respect to entity relations in a unified manner. Specifically,
QAT constructs Meta-Path tokens, which learn relation-centric embeddings based
on diverse structural and semantic relations. Then, our Relation-Aware
Self-Attention module comprehensively integrates different modalities via the
Cross-Modal Relative Position Bias, which guides information exchange between
relevant entites of different modalities. We validate the effectiveness of QAT
on commonsense question answering datasets like CommonsenseQA and OpenBookQA,
and on a medical question answering dataset, MedQA-USMLE. On all the datasets,
our method achieves state-of-the-art performance. Our code is available at
<a href="http://github.com/mlvlab/QAT.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InferEM: Inferring the Speaker's Intention for Empathetic Dialogue Generation. (arXiv:2212.06373v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.06373">
<div class="article-summary-box-inner">
<span><p>Current approaches to empathetic response generation typically encode the
entire dialogue history directly and put the output into a decoder to generate
friendly feedback. These methods focus on modelling contextual information but
neglect capturing the direct intention of the speaker. We argue that the last
utterance in the dialogue empirically conveys the intention of the speaker.
Consequently, we propose a novel model named InferEM for empathetic response
generation. We separately encode the last utterance and fuse it with the entire
dialogue through the multi-head attention based intention fusion module to
capture the speaker's intention. Besides, we utilize previous utterances to
predict the last utterance, which simulates human's psychology to guess what
the interlocutor may speak in advance. To balance the optimizing rates of the
utterance prediction and response generation, a multi-task learning strategy is
designed for InferEM. Experimental results demonstrate the plausibility and
validity of InferEM in improving empathetic expression.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Poor Man's Quality Estimation: Predicting Reference-Based MT Metrics Without the Reference. (arXiv:2301.09008v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09008">
<div class="article-summary-box-inner">
<span><p>Machine translation quality estimation (QE) predicts human judgements of a
translation hypothesis without seeing the reference. State-of-the-art QE
systems based on pretrained language models have been achieving remarkable
correlations with human judgements yet they are computationally heavy and
require human annotations, which are slow and expensive to create. To address
these limitations, we define the problem of metric estimation (ME) where one
predicts the automated metric scores also without the reference. We show that
even without access to the reference, our model can estimate automated metrics
($\rho$=60% for BLEU, $\rho$=51% for other metrics) at the sentence-level.
Because automated metrics correlate with human judgements, we can leverage the
ME task for pre-training a QE model. For the QE task, we find that pre-training
on TER is better ($\rho$=23%) than training for scratch ($\rho$=20%).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hitachi at SemEval-2023 Task 3: Exploring Cross-lingual Multi-task Strategies for Genre and Framing Detection in Online News. (arXiv:2303.01794v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01794">
<div class="article-summary-box-inner">
<span><p>This paper explains the participation of team Hitachi to SemEval-2023 Task 3
"Detecting the genre, the framing, and the persuasion techniques in online news
in a multi-lingual setup.'' Based on the multilingual, multi-task nature of the
task and the low-resource setting, we investigated different cross-lingual and
multi-task strategies for training the pretrained language models. Through
extensive experiments, we found that (a) cross-lingual/multi-task training, and
(b) collecting an external balanced dataset, can benefit the genre and framing
detection. We constructed ensemble models from the results and achieved the
highest macro-averaged F1 scores in Italian and Russian genre categorization
subtasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is ChatGPT a Good NLG Evaluator? A Preliminary Study. (arXiv:2303.04048v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04048">
<div class="article-summary-box-inner">
<span><p>Recently, the emergence of ChatGPT has attracted wide attention from the
computational linguistics community. Many prior studies have shown that ChatGPT
achieves remarkable performance on various NLP tasks in terms of automatic
evaluation metrics. However, the ability of ChatGPT to serve as an evaluation
metric is still underexplored. Considering assessing the quality of natural
language generation (NLG) models is an arduous task and NLG metrics notoriously
show their poor correlation with human judgments, we wonder whether ChatGPT is
a good NLG evaluation metric. In this report, we provide a preliminary
meta-evaluation on ChatGPT to show its reliability as an NLG metric. In detail,
we regard ChatGPT as a human evaluator and give task-specific (e.g.,
summarization) and aspect-specific (e.g., relevance) instruction to prompt
ChatGPT to evaluate the generated results of NLG models. We conduct experiments
on five NLG meta-evaluation datasets (including summarization, story generation
and data-to-text tasks). Experimental results show that compared with previous
automatic metrics, ChatGPT achieves state-of-the-art or competitive correlation
with human judgments in most cases. In addition, we find that the effectiveness
of the ChatGPT evaluator might be influenced by the creation method of the
meta-evaluation datasets. For the meta-evaluation datasets which are created
greatly depending on the reference and thus are biased, the ChatGPT evaluator
might lose its effectiveness. We hope our preliminary study could prompt the
emergence of a general-purposed reliable NLG metric.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Large Language Models. (arXiv:2303.18223v7 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18223">
<div class="article-summary-box-inner">
<span><p>Language is essentially a complex, intricate system of human expressions
governed by grammatical rules. It poses a significant challenge to develop
capable AI algorithms for comprehending and grasping a language. As a major
approach, language modeling has been widely studied for language understanding
and generation in the past two decades, evolving from statistical language
models to neural language models. Recently, pre-trained language models (PLMs)
have been proposed by pre-training Transformer models over large-scale corpora,
showing strong capabilities in solving various NLP tasks. Since researchers
have found that model scaling can lead to performance improvement, they further
study the scaling effect by increasing the model size to an even larger size.
Interestingly, when the parameter scale exceeds a certain level, these enlarged
language models not only achieve a significant performance improvement but also
show some special abilities that are not present in small-scale language
models. To discriminate the difference in parameter scale, the research
community has coined the term large language models (LLM) for the PLMs of
significant size. Recently, the research on LLMs has been largely advanced by
both academia and industry, and a remarkable progress is the launch of ChatGPT,
which has attracted widespread attention from society. The technical evolution
of LLMs has been making an important impact on the entire AI community, which
would revolutionize the way how we develop and use AI algorithms. In this
survey, we review the recent advances of LLMs by introducing the background,
key findings, and mainstream techniques. In particular, we focus on four major
aspects of LLMs, namely pre-training, adaptation tuning, utilization, and
capacity evaluation. Besides, we also summarize the available resources for
developing LLMs and discuss the remaining issues for future directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RPTQ: Reorder-based Post-training Quantization for Large Language Models. (arXiv:2304.01089v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.01089">
<div class="article-summary-box-inner">
<span><p>Large-scale language models (LLMs) have demonstrated outstanding performance
on various tasks, but their deployment poses challenges due to their enormous
model size. In this paper, we identify that the main challenge in quantizing
LLMs stems from the different activation ranges between the channels, rather
than just the issue of outliers.We propose a novel reorder-based quantization
approach, RPTQ, that addresses the issue of quantizing the activations of LLMs.
RPTQ rearranges the channels in the activations and then quantizing them in
clusters, thereby reducing the impact of range difference of channels. In
addition, we reduce the storage and computation overhead by avoiding explicit
reordering. By implementing this approach, we achieved a significant
breakthrough by pushing LLM models to 3 bit activation for the first time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Context-Aware Classification of Legal Document Pages. (arXiv:2304.02787v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.02787">
<div class="article-summary-box-inner">
<span><p>For many business applications that require the processing, indexing, and
retrieval of professional documents such as legal briefs (in PDF format etc.),
it is often essential to classify the pages of any given document into their
corresponding types beforehand. Most existing studies in the field of document
image classification either focus on single-page documents or treat multiple
pages in a document independently. Although in recent years a few techniques
have been proposed to exploit the context information from neighboring pages to
enhance document page classification, they typically cannot be utilized with
large pre-trained language models due to the constraint on input length. In
this paper, we present a simple but effective approach that overcomes the above
limitation. Specifically, we enhance the input with extra tokens carrying
sequential information about previous pages - introducing recurrence - which
enables the usage of pre-trained Transformer models like BERT for context-aware
page classification. Our experiments conducted on two legal datasets in English
and Portuguese respectively show that the proposed approach can significantly
improve the performance of document page classification compared to the
non-recurrent setup as well as the other context-aware baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Selective Data Augmentation for Robust Speech Translation. (arXiv:2304.03169v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.03169">
<div class="article-summary-box-inner">
<span><p>Speech translation (ST) systems translate speech in one language to text in
another language. End-to-end ST systems (e2e-ST) have gained popularity over
cascade systems because of their enhanced performance due to reduced latency
and computational cost. Though resource intensive, e2e-ST systems have the
inherent ability to retain para and non-linguistic characteristics of the
speech unlike cascade systems. In this paper, we propose to use an e2e
architecture for English-Hindi (en-hi) ST. We use two imperfect machine
translation (MT) services to translate Libri-trans en text into hi text. While
each service gives MT data individually to generate parallel ST data, we
propose a data augmentation strategy of noisy MT data to aid robust ST. The
main contribution of this paper is the proposal of a data augmentation
strategy. We show that this results in better ST (BLEU score) compared to brute
force augmentation of MT data. We observed an absolute improvement of 1.59 BLEU
score with our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chinese Open Instruction Generalist: A Preliminary Release. (arXiv:2304.07987v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07987">
<div class="article-summary-box-inner">
<span><p>Instruction tuning is widely recognized as a key technique for building
generalist language models, which has attracted the attention of researchers
and the public with the release of InstructGPT~\citep{ouyang2022training} and
ChatGPT\footnote{\url{https://chat.openai.com/}}. Despite impressive progress
in English-oriented large-scale language models (LLMs), it is still
under-explored whether English-based foundation LLMs can perform similarly on
multilingual tasks compared to English tasks with well-designed instruction
tuning and how we can construct the corpora needed for the tuning. To remedy
this gap, we propose the project as an attempt to create a Chinese instruction
dataset by various methods adapted to the intrinsic characteristics of 4
sub-tasks. We collect around 200k Chinese instruction tuning samples, which
have been manually checked to guarantee high quality. We also summarize the
existing English and Chinese instruction corpora and briefly describe some
potential applications of the newly constructed Chinese instruction corpora.
The resulting \textbf{C}hinese \textbf{O}pen \textbf{I}nstruction
\textbf{G}eneralist (\textbf{COIG}) corpora are available in
Huggingface\footnote{\url{https://huggingface.co/datasets/BAAI/COIG}} and
Github\footnote{\url{https://github.com/BAAI-Zlab/COIG}}, and will be
continuously updated.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Autoregressive NLP Tasks via Modular Linearized Attention. (arXiv:2304.08453v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.08453">
<div class="article-summary-box-inner">
<span><p>Various natural language processing (NLP) tasks necessitate models that are
efficient and small based on their ultimate application at the edge or in other
resource-constrained environments. While prior research has reduced the size of
these models, increasing computational efficiency without considerable
performance impacts remains difficult, especially for autoregressive tasks.
This paper proposes {modular linearized attention (MLA), which combines
multiple efficient attention mechanisms, including cosFormer, to maximize
inference quality while achieving notable speedups. We validate this approach
on several autoregressive NLP tasks, including speech-to-text neural machine
translation (S2T NMT), speech-to-text simultaneous translation (SimulST), and
autoregressive text-to-spectrogram, noting efficiency gains on TTS and
competitive performance for NMT and SimulST during training and inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CB-Conformer: Contextual biasing Conformer for biased word recognition. (arXiv:2304.09607v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09607">
<div class="article-summary-box-inner">
<span><p>Due to the mismatch between the source and target domains, how to better
utilize the biased word information to improve the performance of the automatic
speech recognition model in the target domain becomes a hot research topic.
Previous approaches either decode with a fixed external language model or
introduce a sizeable biasing module, which leads to poor adaptability and slow
inference. In this work, we propose CB-Conformer to improve biased word
recognition by introducing the Contextual Biasing Module and the Self-Adaptive
Language Model to vanilla Conformer. The Contextual Biasing Module combines
audio fragments and contextual information, with only 0.2% model parameters of
the original Conformer. The Self-Adaptive Language Model modifies the internal
weights of biased words based on their recall and precision, resulting in a
greater focus on biased words and more successful integration with the
automatic speech recognition model than the standard fixed language model. In
addition, we construct and release an open-source Mandarin biased-word dataset
based on WenetSpeech. Experiments indicate that our proposed method brings a
15.34% character error rate reduction, a 14.13% biased word recall increase,
and a 6.80% biased word F1-score increase compared with the base Conformer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learn What NOT to Learn: Towards Generative Safety in Chatbots. (arXiv:2304.11220v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11220">
<div class="article-summary-box-inner">
<span><p>Conversational models that are generative and open-domain are particularly
susceptible to generating unsafe content since they are trained on web-based
social data. Prior approaches to mitigating this issue have drawbacks, such as
disrupting the flow of conversation, limited generalization to unseen toxic
input contexts, and sacrificing the quality of the dialogue for the sake of
safety. In this paper, we present a novel framework, named "LOT" (Learn NOT
to), that employs a contrastive loss to enhance generalization by learning from
both positive and negative training signals. Our approach differs from the
standard contrastive learning framework in that it automatically obtains
positive and negative signals from the safe and unsafe language distributions
that have been learned beforehand. The LOT framework utilizes divergence to
steer the generations away from the unsafe subspace and towards the safe
subspace while sustaining the flow of conversation. Our approach is memory and
time-efficient during decoding and effectively reduces toxicity while
preserving engagingness and fluency. Empirical results indicate that LOT
reduces toxicity by up to four-fold while achieving four to six-fold higher
rates of engagingness and fluency compared to baseline models. Our findings are
further corroborated by human evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UBC-DLNLP at SemEval-2023 Task 12: Impact of Transfer Learning on African Sentiment Analysis. (arXiv:2304.11256v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11256">
<div class="article-summary-box-inner">
<span><p>We describe our contribution to the SemEVAl 2023 AfriSenti-SemEval shared
task, where we tackle the task of sentiment analysis in 14 different African
languages. We develop both monolingual and multilingual models under a full
supervised setting (subtasks A and B). We also develop models for the zero-shot
setting (subtask C). Our approach involves experimenting with transfer learning
using six language models, including further pertaining of some of these models
as well as a final finetuning stage. Our best performing models achieve an
F1-score of 70.36 on development data and an F1-score of 66.13 on test data.
Unsurprisingly, our results demonstrate the effectiveness of transfer learning
and fine-tuning techniques for sentiment analysis across multiple languages.
Our approach can be applied to other sentiment analysis tasks in different
languages and domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Theory-of-Mind Performance in Large Language Models via Prompting. (arXiv:2304.11490v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11490">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) excel in many tasks in 2023, but they still face
challenges in complex reasoning. Theory-of-mind (ToM) tasks, which require
understanding agents' beliefs, goals, and mental states, are essential for
common-sense reasoning involving humans, making it crucial to enhance LLM
performance in this area. This study measures the ToM performance of GPT-4 and
three GPT-3.5 variants (Davinci-2, Davinci-3, GPT-3.5-Turbo), and investigates
the effectiveness of in-context learning in improving their ToM comprehension.
We evaluated prompts featuring two-shot chain of thought reasoning and
step-by-step thinking instructions. We found that LLMs trained with
Reinforcement Learning from Human Feedback (RLHF) (all models excluding
Davinci-2) improved their ToM accuracy via in-context learning. GPT-4 performed
best in zero-shot settings, reaching nearly 80% ToM accuracy, but still fell
short of the 87% human accuracy on the test set. However, when supplied with
prompts for in-context learning, all RLHF-trained LLMs exceeded 80% ToM
accuracy, with GPT-4 reaching 100%. These results demonstrate that appropriate
prompting enhances LLM ToM reasoning, and they underscore the context-dependent
nature of LLM cognitive capacities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NAIST-SIC-Aligned: Automatically-Aligned English-Japanese Simultaneous Interpretation Corpus. (arXiv:2304.11766v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.11766">
<div class="article-summary-box-inner">
<span><p>It remains a question that how simultaneous interpretation (SI) data affects
simultaneous machine translation (SiMT). Research has been limited due to the
lack of a large-scale training corpus. In this work, we aim to fill in the gap
by introducing NAIST-SIC-Aligned, which is an automatically-aligned parallel
English-Japanese SI dataset. Starting with a non-aligned corpus NAIST-SIC, we
propose a two-stage alignment approach to make the corpus parallel and thus
suitable for model training. The first stage is coarse alignment where we
perform a many-to-many mapping between source and target sentences, and the
second stage is fine-grained alignment where we perform intra- and
inter-sentence filtering to improve the quality of aligned pairs. To ensure the
quality of the corpus, each step has been validated either quantitatively or
qualitatively. This is the first open-sourced large-scale parallel SI dataset
in the literature. We also manually curated a small test set for evaluation
purposes. We hope our work advances research on SI corpora construction and
SiMT. Please find our data at \url{https://github.com/mingzi151/AHC-SI}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Post-hoc Explanations for Skip-gram-based Node Embeddings by Identifying Important Nodes with Bridgeness. (arXiv:2304.12036v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.12036">
<div class="article-summary-box-inner">
<span><p>Node representation learning in a network is an important machine learning
technique for encoding relational information in a continuous vector space
while preserving the inherent properties and structures of the network.
Recently, unsupervised node embedding methods such as DeepWalk, LINE,
struc2vec, PTE, UserItem2vec, and RWJBG have emerged from the Skip-gram model
and perform better performance in several downstream tasks such as node
classification and link prediction than the existing relational models.
However, providing post-hoc explanations of Skip-gram-based embeddings remains
a challenging problem because of the lack of explanation methods and
theoretical studies applicable for embeddings. In this paper, we first show
that global explanations to the Skip-gram-based embeddings can be found by
computing bridgeness under a spectral cluster-aware local perturbation.
Moreover, a novel gradient-based explanation method, which we call GRAPH-wGD,
is proposed that allows the top-q global explanations about learned graph
embedding vectors more efficiently. Experiments show that the ranking of nodes
by scores using GRAPH-wGD is highly correlated with true bridgeness scores. We
also observe that the top-q node-level explanations selected by GRAPH-wGD have
higher importance scores and produce more changes in class label prediction
when perturbed, compared with the nodes selected by recent alternatives, using
five real-world graphs.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-04-26 23:11:53.787962255 UTC">2023-04-26 23:11:53 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>