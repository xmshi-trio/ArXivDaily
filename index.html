<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-09-04T01:30:00Z">09-04</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">YaRN: Efficient Context Window Extension of Large Language Models. (arXiv:2309.00071v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00071">
<div class="article-summary-box-inner">
<span><p>Rotary Position Embeddings (RoPE) have been shown to effectively encode
positional information in transformer-based language models. However, these
models fail to generalize past the sequence length they were trained on. We
present YaRN (Yet another RoPE extensioN method), a compute-efficient method to
extend the context window of such models, requiring 10x less tokens and 2.5x
less training steps than previous methods. Using YaRN, we show that LLaMA
models can effectively utilize and extrapolate to context lengths much longer
than their original pre-training would allow, while also surpassing previous
the state-of-the-art at context window extension. In addition, we demonstrate
that YaRN exhibits the capability to extrapolate beyond the limited context of
a fine-tuning dataset. We publish the checkpoints of Llama 2 7B/13B fine-tuned
using YaRN with 64k and 128k context windows at
https://github.com/jquesnelle/yarn
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large language models in medicine: the potentials and pitfalls. (arXiv:2309.00087v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00087">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have been applied to tasks in healthcare,
ranging from medical exam questions to responding to patient questions. With
increasing institutional partnerships between companies producing LLMs and
healthcare systems, real world clinical application is coming closer to
reality. As these models gain traction, it is essential for healthcare
practitioners to understand what LLMs are, their development, their current and
potential applications, and the associated pitfalls when utilized in medicine.
This review and accompanying tutorial aim to give an overview of these topics
to aid healthcare practitioners in understanding the rapidly changing landscape
of LLMs as applied to medicine.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QS-TTS: Towards Semi-Supervised Text-to-Speech Synthesis via Vector-Quantized Self-Supervised Speech Representation Learning. (arXiv:2309.00126v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00126">
<div class="article-summary-box-inner">
<span><p>This paper proposes a novel semi-supervised TTS framework, QS-TTS, to improve
TTS quality with lower supervised data requirements via Vector-Quantized
Self-Supervised Speech Representation Learning (VQ-S3RL) utilizing more
unlabeled speech audio. This framework comprises two VQ-S3R learners: first,
the principal learner aims to provide a generative Multi-Stage Multi-Codebook
(MSMC) VQ-S3R via the MSMC-VQ-GAN combined with the contrastive S3RL, while
decoding it back to the high-quality audio; then, the associate learner further
abstracts the MSMC representation into a highly-compact VQ representation
through a VQ-VAE. These two generative VQ-S3R learners provide profitable
speech representations and pre-trained models for TTS, significantly improving
synthesis quality with the lower requirement for supervised data. QS-TTS is
evaluated comprehensively under various scenarios via subjective and objective
tests in experiments. The results powerfully demonstrate the superior
performance of QS-TTS, winning the highest MOS over supervised or
semi-supervised baseline TTS approaches, especially in low-resource scenarios.
Moreover, comparing various speech representations and transfer learning
methods in TTS further validates the notable improvement of the proposed
VQ-S3RL to TTS, showing the best audio quality and intelligibility metrics. The
trend of slower decay in the synthesis quality of QS-TTS with decreasing
supervised data further highlights its lower requirements for supervised data,
indicating its great potential in low-resource scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Construction Grammar and Artificial Intelligence. (arXiv:2309.00135v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00135">
<div class="article-summary-box-inner">
<span><p>In this chapter, we argue that it is highly beneficial for the contemporary
construction grammarian to have a thorough understanding of the strong
relationship between the research fields of construction grammar and artificial
intelligence. We start by unravelling the historical links between the two
fields, showing that their relationship is rooted in a common attitude towards
human communication and language. We then discuss the first direction of
influence, focussing in particular on how insights and techniques from the
field of artificial intelligence play an important role in operationalising,
validating and scaling constructionist approaches to language. We then proceed
to the second direction of influence, highlighting the relevance of
construction grammar insights and analyses to the artificial intelligence
endeavour of building truly intelligent agents. We support our case with a
variety of illustrative examples and conclude that the further elaboration of
this relationship will play a key role in shaping the future of the field of
construction grammar.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM in the Shell: Generative Honeypots. (arXiv:2309.00155v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00155">
<div class="article-summary-box-inner">
<span><p>Honeypots are essential tools in cybersecurity. However, most of them (even
the high-interaction ones) lack the required realism to engage and fool human
attackers. This limitation makes them easily discernible, hindering their
effectiveness. This work introduces a novel method to create dynamic and
realistic software honeypots based on Large Language Models. Preliminary
results indicate that LLMs can create credible and dynamic honeypots capable of
addressing important limitations of previous honeypots, such as deterministic
responses, lack of adaptability, etc. We evaluated the realism of each command
by conducting an experiment with human attackers who needed to say if the
answer from the honeypot was fake or not. Our proposed honeypot, called shelLM,
reached an accuracy rate of 0.92.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Will Sentiment Analysis Need Subculture? A New Data Augmentation Approach. (arXiv:2309.00178v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00178">
<div class="article-summary-box-inner">
<span><p>The renowned proverb that "The pen is mightier than the sword" underscores
the formidable influence wielded by text expressions in shaping sentiments.
Indeed, well-crafted written can deeply resonate within cultures, conveying
profound sentiments. Nowadays, the omnipresence of the Internet has fostered a
subculture that congregates around the contemporary milieu. The subculture
artfully articulates the intricacies of human feelings by ardently pursuing the
allure of novelty, a fact that cannot be disregarded in the sentiment analysis.
This paper strives to enrich data through the lens of subculture, to address
the insufficient training data faced by sentiment analysis. To this end, a new
approach of subculture-based data augmentation (SCDA) is proposed, which
engenders six enhanced texts for each training text by leveraging the creation
of six diverse subculture expression generators. The extensive experiments
attest to the effectiveness and potential of SCDA. The results also shed light
on the phenomenon that disparate subculture expressions elicit varying degrees
of sentiment stimulation. Moreover, an intriguing conjecture arises, suggesting
the linear reversibility of certain subculture expressions. It is our fervent
aspiration that this study serves as a catalyst in fostering heightened
perceptiveness towards the tapestry of information, sentiment and culture,
thereby enriching our collective understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the law of text geographic information. (arXiv:2309.00180v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00180">
<div class="article-summary-box-inner">
<span><p>Textual geographic information is indispensable and heavily relied upon in
practical applications. The absence of clear distribution poses challenges in
effectively harnessing geographic information, thereby driving our quest for
exploration. We contend that geographic information is influenced by human
behavior, cognition, expression, and thought processes, and given our intuitive
understanding of natural systems, we hypothesize its conformity to the Gamma
distribution. Through rigorous experiments on a diverse range of 24 datasets
encompassing different languages and types, we have substantiated this
hypothesis, unearthing the underlying regularities governing the dimensions of
quantity, length, and distance in geographic information. Furthermore,
theoretical analyses and comparisons with Gaussian distributions and Zipf's law
have refuted the contingency of these laws. Significantly, we have estimated
the upper bounds of human utilization of geographic information, pointing
towards the existence of uncharted territories. Also, we provide guidance in
geographic information extraction. Hope we peer its true countenance uncovering
the veil of geographic information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models for Semantic Monitoring of Corporate Disclosures: A Case Study on Korea's Top 50 KOSPI Companies. (arXiv:2309.00208v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00208">
<div class="article-summary-box-inner">
<span><p>In the rapidly advancing domain of artificial intelligence, state-of-the-art
language models such as OpenAI's GPT-3.5-turbo and GPT-4 offer unprecedented
opportunities for automating complex tasks. This research paper delves into the
capabilities of these models for semantically analyzing corporate disclosures
in the Korean context, specifically for timely disclosure. The study focuses on
the top 50 publicly traded companies listed on the Korean KOSPI, based on
market capitalization, and scrutinizes their monthly disclosure summaries over
a period of 17 months. Each summary was assigned a sentiment rating on a scale
ranging from 1(very negative) to 5(very positive). To gauge the effectiveness
of the language models, their sentiment ratings were compared with those
generated by human experts. Our findings reveal a notable performance disparity
between GPT-3.5-turbo and GPT-4, with the latter demonstrating significant
accuracy in human evaluation tests. The Spearman correlation coefficient was
registered at 0.61, while the simple concordance rate was recorded at 0.82.
This research contributes valuable insights into the evaluative characteristics
of GPT models, thereby laying the groundwork for future innovations in the
field of automated semantic monitoring.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Addressing the Misalignment of Object Proposal Evaluation for Vision-Language Tasks via Semantic Grounding. (arXiv:2309.00215v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00215">
<div class="article-summary-box-inner">
<span><p>Object proposal generation serves as a standard pre-processing step in
Vision-Language (VL) tasks (image captioning, visual question answering, etc.).
The performance of object proposals generated for VL tasks is currently
evaluated across all available annotations, a protocol that we show is
misaligned - higher scores do not necessarily correspond to improved
performance on downstream VL tasks. Our work serves as a study of this
phenomenon and explores the effectiveness of semantic grounding to mitigate its
effects. To this end, we propose evaluating object proposals against only a
subset of available annotations, selected by thresholding an annotation
importance score. Importance of object annotations to VL tasks is quantified by
extracting relevant semantic information from text describing the image. We
show that our method is consistent and demonstrates greatly improved alignment
with annotations selected by image captioning metrics and human annotation when
compared against existing techniques. Lastly, we compare current detectors used
in the Scene Graph Generation (SGG) benchmark as a use case, which serves as an
example of when traditional object proposal evaluation techniques are
misaligned.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The FruitShell French synthesis system at the Blizzard 2023 Challenge. (arXiv:2309.00223v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00223">
<div class="article-summary-box-inner">
<span><p>This paper presents a French text-to-speech synthesis system for the Blizzard
Challenge 2023. The challenge consists of two tasks: generating high-quality
speech from female speakers and generating speech that closely resembles
specific individuals. Regarding the competition data, we conducted a screening
process to remove missing or erroneous text data. We organized all symbols
except for phonemes and eliminated symbols that had no pronunciation or zero
duration. Additionally, we added word boundary and start/end symbols to the
text, which we have found to improve speech quality based on our previous
experience. For the Spoke task, we performed data augmentation according to the
competition rules. We used an open-source G2P model to transcribe the French
texts into phonemes. As the G2P model uses the International Phonetic Alphabet
(IPA), we applied the same transcription process to the provided competition
data for standardization. However, due to compiler limitations in recognizing
special symbols from the IPA chart, we followed the rules to convert all
phonemes into the phonetic scheme used in the competition data. Finally, we
resampled all competition audio to a uniform sampling rate of 16 kHz. We
employed a VITS-based acoustic model with the hifigan vocoder. For the Spoke
task, we trained a multi-speaker model and incorporated speaker information
into the duration predictor, vocoder, and flow layers of the model. The
evaluation results of our system showed a quality MOS score of 3.6 for the Hub
task and 3.4 for the Spoke task, placing our system at an average level among
all participating teams.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">JoTR: A Joint Transformer and Reinforcement Learning Framework for Dialog Policy Learning. (arXiv:2309.00230v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00230">
<div class="article-summary-box-inner">
<span><p>Dialogue policy learning (DPL) is a crucial component of dialogue modelling.
Its primary role is to determine the appropriate abstract response, commonly
referred to as the "dialogue action". Traditional DPL methodologies have
treated this as a sequential decision problem, using pre-defined action
candidates extracted from a corpus. However, these incomplete candidates can
significantly limit the diversity of responses and pose challenges when dealing
with edge cases, which are scenarios that occur only at extreme operating
parameters. To address these limitations, we introduce a novel framework, JoTR.
This framework is unique as it leverages a text-to-text Transformer-based model
to generate flexible dialogue actions. Unlike traditional methods, JoTR
formulates a word-level policy that allows for a more dynamic and adaptable
dialogue action generation, without the need for any action templates. This
setting enhances the diversity of responses and improves the system's ability
to handle edge cases effectively. In addition, JoTR employs reinforcement
learning with a reward-shaping mechanism to efficiently finetune the word-level
dialogue policy, which allows the model to learn from its interactions,
improving its performance over time. We conducted an extensive evaluation of
JoTR to assess its effectiveness. Our extensive evaluation shows that JoTR
achieves state-of-the-art performance on two benchmark dialogue modelling
tasks, as assessed by both user simulators and human evaluators.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Hijacking: Adversarial Images can Control Generative Models at Runtime. (arXiv:2309.00236v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00236">
<div class="article-summary-box-inner">
<span><p>Are foundation models secure from malicious actors? In this work, we focus on
the image input to a vision-language model (VLM). We discover image hijacks,
adversarial images that control generative models at runtime. We introduce
Behavior Matching, a general method for creating image hijacks, and we use it
to explore three types of attacks. Specific string attacks generate arbitrary
output of the adversary's choosing. Leak context attacks leak information from
the context window into the output. Jailbreak attacks circumvent a model's
safety training. We study these attacks against LLaVA-2, a state-of-the-art VLM
based on CLIP and LLaMA-2, and find that all our attack types have above a 90\%
success rate. Moreover, our attacks are automated and require only small image
perturbations. These findings raise serious concerns about the security of
foundation models. If image hijacks are as difficult to defend against as
adversarial examples in CIFAR-10, then it might be many years before a solution
is found -- if it even exists.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes. (arXiv:2309.00237v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00237">
<div class="article-summary-box-inner">
<span><p>The development of large language models tailored for handling patients'
clinical notes is often hindered by the limited accessibility and usability of
these notes due to strict privacy regulations. To address these challenges, we
first create synthetic large-scale clinical notes using publicly available case
reports extracted from biomedical literature. We then use these synthetic notes
to train our specialized clinical large language model, Asclepius. While
Asclepius is trained on synthetic data, we assess its potential performance in
real-world applications by evaluating it using real clinical notes. We
benchmark Asclepius against several other large language models, including
GPT-3.5-turbo and other open-source alternatives. To further validate our
approach using synthetic notes, we also compare Asclepius with its variants
trained on real clinical notes. Our findings convincingly demonstrate that
synthetic clinical notes can serve as viable substitutes for real ones when
constructing high-performing clinical language models. This conclusion is
supported by detailed evaluations conducted by both GPT-4 and medical
professionals. All resources including weights, codes, and data used in the
development of Asclepius are made publicly accessible for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ALJP: An Arabic Legal Judgment Prediction in Personal Status Cases Using Machine Learning Models. (arXiv:2309.00238v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00238">
<div class="article-summary-box-inner">
<span><p>Legal Judgment Prediction (LJP) aims to predict judgment outcomes based on
case description. Several researchers have developed techniques to assist
potential clients by predicting the outcome in the legal profession. However,
none of the proposed techniques were implemented in Arabic, and only a few
attempts were implemented in English, Chinese, and Hindi. In this paper, we
develop a system that utilizes deep learning (DL) and natural language
processing (NLP) techniques to predict the judgment outcome from Arabic case
scripts, especially in cases of custody and annulment of marriage. This system
will assist judges and attorneys in improving their work and time efficiency
while reducing sentencing disparity. In addition, it will help litigants,
lawyers, and law students analyze the probable outcomes of any given case
before trial. We use a different machine and deep learning models such as
Support Vector Machine (SVM), Logistic regression (LR), Long Short Term Memory
(LSTM), and Bidirectional Long Short-Term Memory (BiLSTM) using representation
techniques such as TF-IDF and word2vec on the developed dataset. Experimental
results demonstrate that compared with the five baseline methods, the SVM model
with word2vec and LR with TF-IDF achieve the highest accuracy of 88% and 78% in
predicting the judgment on custody cases and annulment of marriage,
respectively. Furthermore, the LR and SVM with word2vec and BiLSTM model with
TF-IDF achieved the highest accuracy of 88% and 69% in predicting the
probability of outcomes on custody cases and annulment of marriage,
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking. (arXiv:2309.00240v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00240">
<div class="article-summary-box-inner">
<span><p>Automatic fact-checking plays a crucial role in combating the spread of
misinformation. Large Language Models (LLMs) and Instruction-Following
variants, such as InstructGPT and Alpaca, have shown remarkable performance in
various natural language processing tasks. However, their knowledge may not
always be up-to-date or sufficient, potentially leading to inaccuracies in
fact-checking. To address this limitation, we propose combining the power of
instruction-following language models with external evidence retrieval to
enhance fact-checking performance. Our approach involves leveraging search
engines to retrieve relevant evidence for a given input claim. This external
evidence serves as valuable supplementary information to augment the knowledge
of the pretrained language model. Then, we instruct-tune an open-sourced
language model, called LLaMA, using this evidence, enabling it to predict the
veracity of the input claim more accurately. To evaluate our method, we
conducted experiments on two widely used fact-checking datasets: RAWFC and
LIAR. The results demonstrate that our approach achieves state-of-the-art
performance in fact-checking tasks. By integrating external evidence, we bridge
the gap between the model's knowledge and the most up-to-date and sufficient
context available, leading to improved fact-checking outcomes. Our findings
have implications for combating misinformation and promoting the dissemination
of accurate information on online platforms. Our released materials are
accessible at: https://thcheung.github.io/factllama.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeuroSurgeon: A Toolkit for Subnetwork Analysis. (arXiv:2309.00244v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00244">
<div class="article-summary-box-inner">
<span><p>Despite recent advances in the field of explainability, much remains unknown
about the algorithms that neural networks learn to represent. Recent work has
attempted to understand trained models by decomposing them into functional
circuits (Csord\'as et al., 2020; Lepori et al., 2023). To advance this
research, we developed NeuroSurgeon, a python library that can be used to
discover and manipulate subnetworks within models in the Huggingface
Transformers library (Wolf et al., 2019). NeuroSurgeon is freely available at
https://github.com/mlepori1/NeuroSurgeon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Suicidality in Arabic Tweets Using Machine Learning and Deep Learning Techniques. (arXiv:2309.00246v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00246">
<div class="article-summary-box-inner">
<span><p>Social media platforms have revolutionized traditional communication
techniques by enabling people globally to connect instantaneously, openly, and
frequently. People use social media to share personal stories and express their
opinion. Negative emotions such as thoughts of death, self-harm, and hardship
are commonly expressed on social media, particularly among younger generations.
As a result, using social media to detect suicidal thoughts will help provide
proper intervention that will ultimately deter others from self-harm and
committing suicide and stop the spread of suicidal ideation on social media. To
investigate the ability to detect suicidal thoughts in Arabic tweets
automatically, we developed a novel Arabic suicidal tweets dataset, examined
several machine learning models, including Na\"ive Bayes, Support Vector
Machine, K-Nearest Neighbor, Random Forest, and XGBoost, trained on word
frequency and word embedding features, and investigated the ability of
pre-trained deep learning models, AraBert, AraELECTRA, and AraGPT2, to identify
suicidal thoughts in Arabic tweets. The results indicate that SVM and RF models
trained on character n-gram features provided the best performance in the
machine learning models, with 86% accuracy and an F1 score of 79%. The results
of the deep learning models show that AraBert model outperforms other machine
and deep learning models, achieving an accuracy of 91\% and an F1-score of 88%,
which significantly improves the detection of suicidal ideation in the Arabic
tweets dataset. To the best of our knowledge, this is the first study to
develop an Arabic suicidality detection dataset from Twitter and to use
deep-learning approaches in detecting suicidality in Arabic posts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Why do universal adversarial attacks work on large language models?: Geometry might be the answer. (arXiv:2309.00254v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00254">
<div class="article-summary-box-inner">
<span><p>Transformer based large language models with emergent capabilities are
becoming increasingly ubiquitous in society. However, the task of understanding
and interpreting their internal workings, in the context of adversarial
attacks, remains largely unsolved. Gradient-based universal adversarial attacks
have been shown to be highly effective on large language models and potentially
dangerous due to their input-agnostic nature. This work presents a novel
geometric perspective explaining universal adversarial attacks on large
language models. By attacking the 117M parameter GPT-2 model, we find evidence
indicating that universal adversarial triggers could be embedding vectors which
merely approximate the semantic information in their adversarial training
region. This hypothesis is supported by white-box model analysis comprising
dimensionality reduction and similarity measurement of hidden representations.
We believe this new geometric perspective on the underlying mechanism driving
universal attacks could help us gain deeper insight into the internal workings
and failure modes of LLMs, thus enabling their mitigation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback. (arXiv:2309.00267v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00267">
<div class="article-summary-box-inner">
<span><p>Reinforcement learning from human feedback (RLHF) is effective at aligning
large language models (LLMs) to human preferences, but gathering high quality
human preference labels is a key bottleneck. We conduct a head-to-head
comparison of RLHF vs. RL from AI Feedback (RLAIF) - a technique where
preferences are labeled by an off-the-shelf LLM in lieu of humans, and we find
that they result in similar improvements. On the task of summarization, human
evaluators prefer generations from both RLAIF and RLHF over a baseline
supervised fine-tuned model in ~70% of cases. Furthermore, when asked to rate
RLAIF vs. RLHF summaries, humans prefer both at equal rates. These results
suggest that RLAIF can yield human-level performance, offering a potential
solution to the scalability limitations of RLHF.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing the vocal range of single-speaker singing voice synthesis with melody-unsupervised pre-training. (arXiv:2309.00284v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00284">
<div class="article-summary-box-inner">
<span><p>The single-speaker singing voice synthesis (SVS) usually underperforms at
pitch values that are out of the singer's vocal range or associated with
limited training samples. Based on our previous work, this work proposes a
melody-unsupervised multi-speaker pre-training method conducted on a
multi-singer dataset to enhance the vocal range of the single-speaker, while
not degrading the timbre similarity. This pre-training method can be deployed
to a large-scale multi-singer dataset, which only contains audio-and-lyrics
pairs without phonemic timing information and pitch annotation. Specifically,
in the pre-training step, we design a phoneme predictor to produce the
frame-level phoneme probability vectors as the phonemic timing information and
a speaker encoder to model the timbre variations of different singers, and
directly estimate the frame-level f0 values from the audio to provide the pitch
information. These pre-trained model parameters are delivered into the
fine-tuning step as prior knowledge to enhance the single speaker's vocal
range. Moreover, this work also contributes to improving the sound quality and
rhythm naturalness of the synthesized singing voices. It is the first to
introduce a differentiable duration regulator to improve the rhythm naturalness
of the synthesized voice, and a bi-directional flow model to improve the sound
quality. Experimental results verify that the proposed SVS system outperforms
the baseline on both sound quality and naturalness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparative Topic Modeling for Determinants of Divergent Report Results Applied to Macular Degeneration Studies. (arXiv:2309.00312v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00312">
<div class="article-summary-box-inner">
<span><p>Topic modeling and text mining are subsets of Natural Language Processing
with relevance for conducting meta-analysis (MA) and systematic review (SR).
For evidence synthesis, the above NLP methods are conventionally used for
topic-specific literature searches or extracting values from reports to
automate essential phases of SR and MA. Instead, this work proposes a
comparative topic modeling approach to analyze reports of contradictory results
on the same general research question. Specifically, the objective is to find
topics exhibiting distinct associations with significant results for an outcome
of interest by ranking them according to their proportional occurrence and
consistency of distribution across reports of significant results. The proposed
method was tested on broad-scope studies addressing whether supplemental
nutritional compounds significantly benefit macular degeneration (MD). Eight
compounds were identified as having a particular association with reports of
significant results for benefitting MD. Six of these were further supported in
terms of effectiveness upon conducting a follow-up literature search for
validation (omega-3 fatty acids, copper, zeaxanthin, lutein, zinc, and
nitrates). The two not supported by the follow-up literature search (niacin and
molybdenum) also had the lowest scores under the proposed methods ranking
system, suggesting that the proposed method's score for a given topic is a
viable proxy for its degree of association with the outcome of interest. These
results underpin the proposed methods potential to add specificity in
understanding effects from broad-scope reports, elucidate topics of interest
for future research, and guide evidence synthesis in a systematic and scalable
way.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior. (arXiv:2309.00359v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00359">
<div class="article-summary-box-inner">
<span><p>Shannon, in his seminal paper introducing information theory, divided the
communication into three levels: technical, semantic, and effectivenss. While
the technical level is concerned with accurate reconstruction of transmitted
symbols, the semantic and effectiveness levels deal with the inferred meaning
and its effect on the receiver. Thanks to telecommunications, the first level
problem has produced great advances like the internet. Large Language Models
(LLMs) make some progress towards the second goal, but the third level still
remains largely untouched. The third problem deals with predicting and
optimizing communication for desired receiver behavior. LLMs, while showing
wide generalization capabilities across a wide range of tasks, are unable to
solve for this. One reason for the underperformance could be a lack of
"behavior tokens" in LLMs' training corpora. Behavior tokens define receiver
behavior over a communication, such as shares, likes, clicks, purchases,
retweets, etc. While preprocessing data for LLM training, behavior tokens are
often removed from the corpora as noise. Therefore, in this paper, we make some
initial progress towards reintroducing behavior tokens in LLM training. The
trained models, other than showing similar performance to LLMs on content
understanding tasks, show generalization capabilities on behavior simulation,
content simulation, behavior understanding, and behavior domain adaptation.
Using a wide range of tasks on two corpora, we show results on all these
capabilities. We call these models Large Content and Behavior Models (LCBMs).
Further, to spur more research on LCBMs, we release our new Content Behavior
Corpus (CBC), a repository containing communicator, message, and corresponding
receiver behavior.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Do Discourse Markers Affect Computational Sentence Understanding?. (arXiv:2309.00368v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00368">
<div class="article-summary-box-inner">
<span><p>The capabilities and use cases of automatic natural language processing (NLP)
have grown significantly over the last few years. While much work has been
devoted to understanding how humans deal with discourse connectives, this
phenomenon is understudied in computational systems. Therefore, it is important
to put NLP models under the microscope and examine whether they can adequately
comprehend, process, and reason within the complexity of natural language. In
this chapter, we introduce the main mechanisms behind automatic sentence
processing systems step by step and then focus on evaluating discourse
connective processing. We assess nine popular systems in their ability to
understand English discourse connectives and analyze how context and language
understanding tasks affect their connective comprehension. The results show
that NLP systems do not process all discourse connectives equally well and that
the computational processing complexity of different connective kinds is not
always consistently in line with the presumed complexity order found in human
processing. In addition, while humans are more inclined to be influenced during
the reading procedure but not necessarily in the final comprehension
performance, discourse connectives have a significant impact on the final
accuracy of NLP systems. The richer knowledge of connectives a system learns,
the more negative effect inappropriate connectives have on it. This suggests
that the correct explicitation of discourse connectives is important for
computational natural language processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Long-Term Memorability On Advertisements. (arXiv:2309.00378v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00378">
<div class="article-summary-box-inner">
<span><p>Marketers spend billions of dollars on advertisements but to what end? At the
purchase time, if customers cannot recognize a brand for which they saw an ad,
the money spent on the ad is essentially wasted. Despite its importance in
marketing, until now, there has been no study on the memorability of ads in the
ML literature. Most studies have been conducted on short-term recall (&lt;5 mins)
on specific content types like object and action videos. On the other hand, the
advertising industry only cares about long-term memorability (a few hours or
longer), and advertisements are almost always highly multimodal, depicting a
story through its different modalities (text, images, and videos). With this
motivation, we conduct the first large scale memorability study consisting of
1203 participants and 2205 ads covering 276 brands. Running statistical tests
over different participant subpopulations and ad-types, we find many
interesting insights into what makes an ad memorable - both content and human
factors. For example, we find that brands which use commercials with fast
moving scenes are more memorable than those with slower scenes (p=8e-10) and
that people who use ad-blockers remember lower number of ads than those who
don't (p=5e-3). Further, with the motivation of simulating the memorability of
marketing materials for a particular audience, ultimately helping create one,
we present a novel model, Sharingan, trained to leverage real-world knowledge
of LLMs and visual knowledge of visual encoders to predict the memorability of
a content. We test our model on all the prominent memorability datasets in
literature (both images and videos) and achieve state of the art across all of
them. We conduct extensive ablation studies across memory types, modality,
brand, and architectural choices to find insights into what drives memory.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BatchPrompt: Accomplish more with less. (arXiv:2309.00384v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00384">
<div class="article-summary-box-inner">
<span><p>Many LLMs are trained to perform zero-shot or few-shot inference using
instruction-based prompts. Crafting prompts for these LLMs typically requires
the user to provide a detailed task description, examples of context and
completion, and single example of context for inference. This regular prompt
baseline is referred to as SinglePrompt in this paper. However, for NLP tasks
where each data point for inference is not necessarily lengthy, the token count
for instructions and few-shot examples in the prompt may be considerably larger
than that of the data point, resulting in lower token-resource utilization
compared with encoder-based models like fine-tuned BERT. This cost-efficiency
issue, affecting inference speed and compute budget, counteracts the many
benefits LLMs have to offer. This paper aims to alleviate the preceding problem
by batching multiple data points into a single prompt, a prompting strategy we
refer to as BatchPrompt. This strategy increases the density of data points,
which in turn leads to improved token utilization. Applying BatchPrompt
naively, however, is very challenging due to significant performance
degradation, as observed in our experiments. We also noticed varying inference
outcomes for the same data point appearing in different positions within a
prompt. To address the quality issue while remain high token-resource
utilization, we introduce Batch Permutation and Ensembling for BatchPrompt, a
simple way that recovers labeling quality through majority votes from data
points placed in varying positions in a batch at the price of more token usage.
To counterbalance the additional token usage caused by the voting process, we
further propose Self-reflection-guided EArly Stopping, which can terminate the
voting process early for data points the LLM confidently handles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Satisfiability Checking of Multi-Variable TPTL with Unilateral Intervals Is PSPACE-Complete. (arXiv:2309.00386v1 [cs.LO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00386">
<div class="article-summary-box-inner">
<span><p>We investigate the decidability of the ${0,\infty}$ fragment of Timed
Propositional Temporal Logic (TPTL). We show that the satisfiability checking
of TPTL$^{0,\infty}$ is PSPACE-complete. Moreover, even its 1-variable fragment
(1-TPTL$^{0,\infty}$) is strictly more expressive than Metric Interval Temporal
Logic (MITL) for which satisfiability checking is EXPSPACE complete. Hence, we
have a strictly more expressive logic with computationally easier
satisfiability checking. To the best of our knowledge, TPTL$^{0,\infty}$ is the
first multi-variable fragment of TPTL for which satisfiability checking is
decidable without imposing any bounds/restrictions on the timed words (e.g.
bounded variability, bounded time, etc.). The membership in PSPACE is obtained
by a reduction to the emptiness checking problem for a new "non-punctual"
subclass of Alternating Timed Automata with multiple clocks called Unilateral
Very Weak Alternating Timed Automata (VWATA$^{0,\infty}$) which we prove to be
in PSPACE. We show this by constructing a simulation equivalent
non-deterministic timed automata whose number of clocks is polynomial in the
size of the given VWATA$^{0,\infty}$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CPSP: Learning Speech Concepts From Phoneme Supervision. (arXiv:2309.00424v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00424">
<div class="article-summary-box-inner">
<span><p>For fine-grained generation and recognition tasks such as
minimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic
speech recognition (ASR), the intermediate representation extracted from speech
should contain information that is between text coding and acoustic coding. The
linguistic content is salient, while the paralinguistic information such as
speaker identity and acoustic details should be removed. However, existing
methods for extracting fine-grained intermediate representations from speech
suffer from issues of excessive redundancy and dimension explosion.
Additionally, existing contrastive learning methods in the audio field focus on
extracting global descriptive information for downstream audio classification
tasks, making them unsuitable for TTS, VC, and ASR tasks. To address these
issues, we propose a method named Contrastive Phoneme-Speech Pretraining
(CPSP), which uses three encoders, one decoder, and contrastive learning to
bring phoneme and speech into a joint multimodal space, learning how to connect
phoneme and speech at the frame level. The CPSP model is trained on 210k speech
and phoneme text pairs, achieving minimally-supervised TTS, VC, and ASR. The
proposed CPSP method offers a promising solution for fine-grained generation
and recognition downstream tasks in speech processing. We provide a website
with audio samples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Baseline Defenses for Adversarial Attacks Against Aligned Language Models. (arXiv:2309.00614v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00614">
<div class="article-summary-box-inner">
<span><p>As Large Language Models quickly become ubiquitous, their security
vulnerabilities are critical to understand. Recent work shows that text
optimizers can produce jailbreaking prompts that bypass moderation and
alignment. Drawing from the rich body of work on adversarial machine learning,
we approach these attacks with three questions: What threat models are
practically useful in this domain? How do baseline defense techniques perform
in this new domain? How does LLM security differ from computer vision?
</p>
<p>We evaluate several baseline defense strategies against leading adversarial
attacks on LLMs, discussing the various settings in which each is feasible and
effective. Particularly, we look at three types of defenses: detection
(perplexity based), input preprocessing (paraphrase and retokenization), and
adversarial training. We discuss white-box and gray-box settings and discuss
the robustness-performance trade-off for each of the defenses considered.
Surprisingly, we find much more success with filtering and preprocessing than
we would expect from other domains, such as vision, providing a first
indication that the relative strengths of these defenses may be weighed
differently in these domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Point-Bind & Point-LLM: Aligning Point Cloud with Multi-modality for 3D Understanding, Generation, and Instruction Following. (arXiv:2309.00615v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.00615">
<div class="article-summary-box-inner">
<span><p>We introduce Point-Bind, a 3D multi-modality model aligning point clouds with
2D image, language, audio, and video. Guided by ImageBind, we construct a joint
embedding space between 3D and multi-modalities, enabling many promising
applications, e.g., any-to-3D generation, 3D embedding arithmetic, and 3D
open-world understanding. On top of this, we further present Point-LLM, the
first 3D large language model (LLM) following 3D multi-modal instructions. By
parameter-efficient fine-tuning techniques, Point-LLM injects the semantics of
Point-Bind into pre-trained LLMs, e.g., LLaMA, which requires no 3D instruction
data, but exhibits superior 3D and multi-modal question-answering capacity. We
hope our work may cast a light on the community for extending 3D point clouds
to multi-modality applications. Code is available at
https://github.com/ZiyuGuo99/Point-Bind_Point-LLM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Multifractal-based Deep Learning Model for Text Mining. (arXiv:2111.13861v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.13861">
<div class="article-summary-box-inner">
<span><p>In this world full of uncertainty, where the fabric of existence weaves
patterns of complexity, multifractal emerges as beacons of insight,
illuminating them. As we delve into the realm of text mining that underpins
various natural language processing applications and powers a range of
intelligent services, we recognize that behind the veil of text lies a
manifestation of human thought and cognition, intricately intertwined with the
complexities. Building upon the foundation of perceiving text as a complex
system, this study embarks on a journey to unravel the hidden treasures within,
armed with the proposed multifractal method that deciphers the multifractal
attributes embedded within the text landscape. This endeavor culminates in the
birth of our novel model, which also harnesses the power of the proposed
activation function to facilitate nonlinear information transmission within its
neural network architecture. The success on experiments anchored in real-world
technical reports covering the extraction of technical term and classification
of hazard events, stands as a testament to our endeavors. This research venture
not only expands our understanding of text mining but also opens new horizons
for knowledge discovery across various domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Zipf's Law-based Text Generation Approach for Addressing Imbalance in Entity Extraction. (arXiv:2205.12636v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12636">
<div class="article-summary-box-inner">
<span><p>Entity extraction is critical in the intelligent advancement across diverse
domains. Nevertheless, a challenge to its effectiveness arises from the data
imbalance. This paper proposes a novel approach by viewing the issue through
the quantitative information, recognizing that entities exhibit certain levels
of commonality while others are scarce, which can be reflected in the
quantifiable distribution of words. The Zipf's Law emerges as a well-suited
adoption, and to transition from words to entities, words within the documents
are classified as common and rare ones. Subsequently, sentences are classified
into common and rare ones, and are further processed by text generation models
accordingly. Rare entities within the generated sentences are then labeled
using human-designed rules, serving as a supplement to the raw dataset, thereby
mitigating the imbalance problem. The study presents a case of extracting
entities from technical documents, and experimental results from two datasets
prove the effectiveness of the proposed method. Furthermore, the significance
of Zipf's law in driving the progress of AI is discussed, broadening the reach
and coverage of Informetrics. This paper presents a successful demonstration of
extending Informetrics to interface with AI through Zipf's Law.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ComCLIP: Training-Free Compositional Image and Text Matching. (arXiv:2211.13854v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.13854">
<div class="article-summary-box-inner">
<span><p>Contrastive Language-Image Pretraining (CLIP) has demonstrated great
zero-shot performance for matching images and text. However, it is still
challenging to adapt vision-lanaguage pretrained models like CLIP to
compositional image and text matching -- a more challenging image and text
matching task requiring the model understanding of compositional word concepts
and visual components. Towards better compositional generalization in zero-shot
image and text matching, in this paper, we study the problem from a causal
perspective: the erroneous semantics of individual entities are essentially
confounders that cause the matching failure. Therefore, we propose a novel
\textbf{\textit{training-free}} compositional CLIP model (ComCLIP). ComCLIP
disentangles input images into subjects, objects, and action sub-images and
composes CLIP's vision encoder and text encoder to perform evolving matching
over compositional text embedding and sub-image embeddings. In this way,
ComCLIP can mitigate spurious correlations introduced by the pretrained CLIP
models and dynamically evaluate the importance of each component. Experiments
on four compositional image-text matching datasets: SVO, ComVG, Winoground, and
VL-checklist, and two general image-text retrieval datasets: Flick30K, and
MSCOCO demonstrate the effectiveness of our plug-and-play method, which boosts
the \textbf{\textit{zero-shot}} inference ability of CLIP, SLIP, and BLIP2 even
without further training or fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain-Agnostic Molecular Generation with Self-feedback. (arXiv:2301.11259v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.11259">
<div class="article-summary-box-inner">
<span><p>The generation of molecules with desired properties has gained tremendous
popularity, revolutionizing the way scientists design molecular structures and
providing valuable support for chemical and drug design. However, despite the
potential of language models in molecule generation, they face numerous
challenges such as the generation of syntactically or chemically flawed
molecules, narrow domain focus, and limitations in creating diverse and
directionally feasible molecules due to a dearth of annotated data or external
molecular databases. To this end, we introduce MolGen, a pre-trained molecular
language model tailored specifically for molecule generation. MolGen acquires
intrinsic structural and grammatical insights by reconstructing over 100
million molecular SELFIES, while facilitating knowledge transfer between
different domains through domain-agnostic molecular prefix tuning. Moreover, we
present a self-feedback paradigm that inspires the pre-trained model to align
with the ultimate goal of producing molecules with desirable properties.
Extensive experiments on well-known benchmarks confirm MolGen's optimization
capabilities, encompassing penalized logP, QED, and molecular docking
properties. Further analysis shows that MolGen can accurately capture molecule
distributions, implicitly learn their structural characteristics, and
efficiently explore chemical space. The pre-trained model, codes, and datasets
are publicly available for future research at https://github.com/zjunlp/MolGen.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speculative Decoding with Big Little Decoder. (arXiv:2302.07863v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07863">
<div class="article-summary-box-inner">
<span><p>The recent emergence of Large Language Models based on the Transformer
architecture has enabled dramatic advancements in the field of Natural Language
Processing. However, these models have long inference latency, which limits
their deployment, and which makes them prohibitively expensive for various
real-time applications. The inference latency is further exacerbated by
autoregressive generative tasks, as models need to run iteratively to generate
tokens sequentially without leveraging token-level parallelization. To address
this, we propose Big Little Decoder (BiLD), a framework that can improve
inference efficiency and latency for a wide range of text generation
applications. The BiLD framework contains two models with different sizes that
collaboratively generate text. The small model runs autoregressively to
generate text with a low inference cost, and the large model is only invoked
occasionally to refine the small model's inaccurate predictions in a
non-autoregressive manner. To coordinate the small and large models, BiLD
introduces two simple yet effective policies: (1) the fallback policy that
determines when to hand control over to the large model; and (2) the rollback
policy that determines when the large model needs to correct the small model's
inaccurate predictions. To evaluate our framework across different tasks and
models, we apply BiLD to various text generation scenarios encompassing machine
translation on IWSLT 2017 De-En and WMT 2014 De-En, and summarization on XSUM
and CNN/DailyMail. On an NVIDIA T4 GPU, our framework achieves a speedup of up
to 2.12x speedup with minimal generation quality degradation. Furthermore, our
framework is fully plug-and-play and can be applied without any modifications
in the training process or model architecture. Our code is open-sourced
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEVER: Learning to Verify Language-to-Code Generation with Execution. (arXiv:2302.08468v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08468">
<div class="article-summary-box-inner">
<span><p>The advent of large language models trained on code (code LLMs) has led to
significant progress in language-to-code generation. State-of-the-art
approaches in this area combine LLM decoding with sample pruning and reranking
using test cases or heuristics based on the execution results. However, it is
challenging to obtain test cases for many real-world language-to-code
applications, and heuristics cannot well capture the semantic features of the
execution results, such as data type and value range, which often indicates the
correctness of the program. In this work, we propose LEVER, a simple approach
to improve language-to-code generation by learning to verify the generated
programs with their execution results. Specifically, we train verifiers to
determine whether a program sampled from the LLMs is correct or not based on
the natural language input, the program itself and its execution results. The
sampled programs are reranked by combining the verification score with the LLM
generation probability, and marginalizing over programs with the same execution
results. On four datasets across the domains of table QA, math QA and basic
Python programming, LEVER consistently improves over the base code LLMs(4.6% to
10.9% with code-davinci-002) and achieves new state-of-the-art results on all
of them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompting GPT-3.5 for Text-to-SQL with De-semanticization and Skeleton Retrieval. (arXiv:2304.13301v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.13301">
<div class="article-summary-box-inner">
<span><p>Text-to-SQL is a task that converts a natural language question into a
structured query language (SQL) to retrieve information from a database. Large
language models (LLMs) work well in natural language generation tasks, but they
are not specifically pre-trained to understand the syntax and semantics of SQL
commands. In this paper, we propose an LLM-based framework for Text-to-SQL
which retrieves helpful demonstration examples to prompt LLMs. However,
questions with different database schemes can vary widely, even if the
intentions behind them are similar and the corresponding SQL queries exhibit
similarities. Consequently, it becomes crucial to identify the appropriate SQL
demonstrations that align with our requirements. We design a de-semanticization
mechanism that extracts question skeletons, allowing us to retrieve similar
examples based on their structural similarity. We also model the relationships
between question tokens and database schema items (i.e., tables and columns) to
filter out scheme-related information. Our framework adapts the range of the
database schema in prompts to balance length and valuable information. A
fallback mechanism allows for a more detailed schema to be provided if the
generated SQL query fails. Ours outperforms state-of-the-art models and
demonstrates strong generalization ability on three cross-domain Text-to-SQL
benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Constructing Holistic Measures for Social Biases in Masked Language Models. (arXiv:2305.07795v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07795">
<div class="article-summary-box-inner">
<span><p>Masked Language Models (MLMs) have been successful in many natural language
processing tasks. However, real-world stereotype biases are likely to be
reflected in MLMs due to their learning from large text corpora. Most of the
evaluation metrics proposed in the past adopt different masking strategies,
designed with the log-likelihood of MLMs. They lack holistic considerations
such as variance for stereotype bias and anti-stereotype bias samples. In this
paper, the log-likelihoods of stereotype bias and anti-stereotype bias samples
output by MLMs are considered Gaussian distributions. Two evaluation metrics,
Kullback Leibler Divergence Score (KLDivS) and Jensen Shannon Divergence Score
(JSDivS) are proposed to evaluate social biases in MLMs The experimental
results on the public datasets StereoSet and CrowS-Pairs demonstrate that
KLDivS and JSDivS are more stable and interpretable compared to the metrics
proposed in the past.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RS5M: A Large Scale Vision-Language Dataset for Remote Sensing Vision-Language Foundation Model. (arXiv:2306.11300v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.11300">
<div class="article-summary-box-inner">
<span><p>Pre-trained Vision-Language Foundation Models utilizing extensive image-text
paired data have demonstrated unprecedented image-text association
capabilities, achieving remarkable results across various downstream tasks. A
critical challenge is how to make use of existing large-scale pre-trained VLMs,
which are trained on common objects, to perform the domain-specific transfer
for accomplishing domain-related downstream tasks. In this paper, we propose a
new framework that includes the Domain Foundation Model (DFM), bridging the gap
between the General Foundation Model (GFM) and domain-specific downstream
tasks. Moreover, we present an image-text paired dataset in the field of remote
sensing (RS), RS5M, which has 5 million RS images with English descriptions.
The dataset is obtained from filtering publicly available image-text paired
datasets and captioning label-only RS datasets with pre-trained VLM. These
constitute the first large-scale RS image-text paired dataset. Additionally, we
tried several Parameter-Efficient Fine-Tuning methods on RS5M to implement the
DFM. Experimental results show that our proposed dataset are highly effective
for various tasks, improving upon the baseline by $8 \% \sim 16 \%$ in
zero-shot classification tasks, and obtaining good results in both
Vision-Language Retrieval and Semantic Localization tasks.
\url{https://github.com/om-ai-lab/RS5M}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lingua Manga: A Generic Large Language Model Centric System for Data Curation. (arXiv:2306.11702v2 [cs.DB] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.11702">
<div class="article-summary-box-inner">
<span><p>Data curation is a wide-ranging area which contains many critical but
time-consuming data processing tasks. However, the diversity of such tasks
makes it challenging to develop a general-purpose data curation system. To
address this issue, we present Lingua Manga, a user-friendly and versatile
system that utilizes pre-trained large language models. Lingua Manga offers
automatic optimization for achieving high performance and label efficiency
while facilitating flexible and rapid development. Through three example
applications with distinct objectives and users of varying levels of technical
proficiency, we demonstrate that Lingua Manga can effectively assist both
skilled programmers and low-code or even no-code users in addressing data
curation challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ontology Enrichment from Texts: A Biomedical Dataset for Concept Discovery and Placement. (arXiv:2306.14704v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.14704">
<div class="article-summary-box-inner">
<span><p>Mentions of new concepts appear regularly in texts and require automated
approaches to harvest and place them into Knowledge Bases (KB), e.g.,
ontologies and taxonomies. Existing datasets suffer from three issues, (i)
mostly assuming that a new concept is pre-discovered and cannot support
out-of-KB mention discovery; (ii) only using the concept label as the input
along with the KB and thus lacking the contexts of a concept label; and (iii)
mostly focusing on concept placement w.r.t a taxonomy of atomic concepts,
instead of complex concepts, i.e., with logical operators. To address these
issues, we propose a new benchmark, adapting MedMentions dataset (PubMed
abstracts) with SNOMED CT versions in 2014 and 2017 under the Diseases
sub-category and the broader categories of Clinical finding, Procedure, and
Pharmaceutical / biologic product. We provide usage on the evaluation with the
dataset for out-of-KB mention discovery and concept placement, adapting recent
Large Language Model based methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">C-PMI: Conditional Pointwise Mutual Information for Turn-level Dialogue Evaluation. (arXiv:2306.15245v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.15245">
<div class="article-summary-box-inner">
<span><p>Existing reference-free turn-level evaluation metrics for chatbots
inadequately capture the interaction between the user and the system.
Consequently, they often correlate poorly with human evaluations. To address
this issue, we propose a novel model-agnostic approach that leverages
Conditional Pointwise Mutual Information (C-PMI) to measure the turn-level
interaction between the system and the user based on a given evaluation
dimension. Experimental results on the widely used FED dialogue evaluation
dataset demonstrate that our approach significantly improves the correlation
with human judgment compared with existing evaluation systems. By replacing the
negative log-likelihood-based scorer with our proposed C-PMI scorer, we achieve
a relative 62.6% higher Spearman correlation on average for the FED evaluation
metric. Our code is publicly available at https://github.com/renll/C-PMI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLIPAG: Towards Generator-Free Text-to-Image Generation. (arXiv:2306.16805v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.16805">
<div class="article-summary-box-inner">
<span><p>Perceptually Aligned Gradients (PAG) refer to an intriguing property observed
in robust image classification models, wherein their input gradients align with
human perception and pose semantic meanings. While this phenomenon has gained
significant research attention, it was solely studied in the context of
unimodal vision-only architectures. In this work, we extend the study of PAG to
Vision-Language architectures, which form the foundations for diverse
image-text tasks and applications. Through an adversarial robustification
finetuning of CLIP, we demonstrate that robust Vision-Language models exhibit
PAG in contrast to their vanilla counterparts. This work reveals the merits of
CLIP with PAG (CLIPAG) in several vision-language generative tasks. Notably, we
show that seamlessly integrating CLIPAG in a "plug-n-play" manner leads to
substantial improvements in vision-language generative applications.
Furthermore, leveraging its PAG property, CLIPAG enables text-to-image
generation without any generative model, which typically requires huge
generators.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Prompt in the Classroom to Understand AI Limits: A pilot study. (arXiv:2307.01540v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.01540">
<div class="article-summary-box-inner">
<span><p>Artificial intelligence's (AI) progress holds great promise in tackling
pressing societal concerns such as health and climate. Large Language Models
(LLM) and the derived chatbots, like ChatGPT, have highly improved the natural
language processing capabilities of AI systems allowing them to process an
unprecedented amount of unstructured data. However, the ensuing excitement has
led to negative sentiments, even as AI methods demonstrate remarkable
contributions (e.g. in health and genetics). A key factor contributing to this
sentiment is the misleading perception that LLMs can effortlessly provide
solutions across domains, ignoring their limitations such as hallucinations and
reasoning constraints. Acknowledging AI fallibility is crucial to address the
impact of dogmatic overconfidence in possibly erroneous suggestions generated
by LLMs. At the same time, it can reduce fear and other negative attitudes
toward AI. This necessitates comprehensive AI literacy interventions that
educate the public about LLM constraints and effective usage techniques, i.e
prompting strategies. With this aim, a pilot educational intervention was
performed in a high school with 21 students. It involved presenting high-level
concepts about intelligence, AI, and LLMs, followed by practical exercises
involving ChatGPT in creating natural educational conversations and applying
established prompting strategies. Encouraging preliminary results emerged,
including high appreciation of the activity, improved interaction quality with
the LLM, reduced negative AI sentiments, and a better grasp of limitations,
specifically unreliability, limited understanding of commands leading to
unsatisfactory responses, and limited presentation flexibility. Our aim is to
explore AI acceptance factors and refine this approach for more controlled
future studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity Using Contrastive Learning and Structured Knowledge. (arXiv:2307.07851v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.07851">
<div class="article-summary-box-inner">
<span><p>Generic sentence embeddings provide a coarse-grained approximation of
semantic textual similarity but ignore specific aspects that make texts
similar. Conversely, aspect-based sentence embeddings provide similarities
between texts based on certain predefined aspects. Thus, similarity predictions
of texts are more targeted to specific requirements and more easily
explainable. In this paper, we present AspectCSE, an approach for aspect-based
contrastive learning of sentence embeddings. Results indicate that AspectCSE
achieves an average improvement of 3.97% on information retrieval tasks across
multiple aspects compared to the previous best results. We also propose using
Wikidata knowledge graph properties to train models of multi-aspect sentence
embeddings in which multiple specific aspects are simultaneously considered
during similarity predictions. We demonstrate that multi-aspect embeddings
outperform single-aspect embeddings on aspect-specific information retrieval
tasks. Finally, we examine the aspect-based sentence embedding space and
demonstrate that embeddings of semantically similar aspect labels are often
close, even without explicit similarity training between different aspect
labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and Addressing Sociological Implications. (arXiv:2307.09162v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.09162">
<div class="article-summary-box-inner">
<span><p>Gender bias in artificial intelligence (AI) and natural language processing
has garnered significant attention due to its potential impact on societal
perceptions and biases. This research paper aims to analyze gender bias in
Large Language Models (LLMs) with a focus on multiple comparisons between GPT-2
and GPT-3.5, some prominent language models, to better understand its
implications. Through a comprehensive literature review, the study examines
existing research on gender bias in AI language models and identifies gaps in
the current knowledge. The methodology involves collecting and preprocessing
data from GPT-2 and GPT-3.5, and employing in-depth quantitative analysis
techniques to evaluate gender bias in the generated text. The findings shed
light on gendered word associations, language usage, and biased narratives
present in the outputs of these Large Language Models. The discussion explores
the ethical implications of gender bias and its potential consequences on
social perceptions and marginalized communities. Additionally, the paper
presents strategies for reducing gender bias in LLMs, including algorithmic
approaches and data augmentation techniques. The research highlights the
importance of interdisciplinary collaborations and the role of sociological
studies in mitigating gender bias in AI models. By addressing these issues, we
can pave the way for more inclusive and unbiased AI systems that have a
positive impact on society.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Psy-LLM: Scaling up Global Mental Health Psychological Services with AI-based Large Language Models. (arXiv:2307.11991v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11991">
<div class="article-summary-box-inner">
<span><p>The demand for psychological counselling has grown significantly in recent
years, particularly with the global outbreak of COVID-19, which has heightened
the need for timely and professional mental health support. Online
psychological counselling has emerged as the predominant mode of providing
services in response to this demand. In this study, we propose the Psy-LLM
framework, an AI-based assistive tool leveraging Large Language Models (LLMs)
for question-answering in psychological consultation settings to ease the
demand for mental health professions. Our framework combines pre-trained LLMs
with real-world professional Q\&amp;A from psychologists and extensively crawled
psychological articles. The Psy-LLM framework serves as a front-end tool for
healthcare professionals, allowing them to provide immediate responses and
mindfulness activities to alleviate patient stress. Additionally, it functions
as a screening tool to identify urgent cases requiring further assistance. We
evaluated the framework using intrinsic metrics, such as perplexity, and
extrinsic evaluation metrics, with human participant assessments of response
helpfulness, fluency, relevance, and logic. The results demonstrate the
effectiveness of the Psy-LLM framework in generating coherent and relevant
answers to psychological questions. This article discusses the potential and
limitations of using large language models to enhance mental health support
through AI technologies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding. (arXiv:2307.15484v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.15484">
<div class="article-summary-box-inner">
<span><p>Recently, there has been a growing interest in text-to-speech (TTS) methods
that can be trained with minimal supervision by combining two types of discrete
speech representations and using two sequence-to-sequence tasks to decouple
TTS. However, existing methods suffer from three problems: the high
dimensionality and waveform distortion of discrete speech representations, the
prosodic averaging problem caused by the duration prediction model in
non-autoregressive frameworks, and the information redundancy and dimension
explosion problems of existing semantic encoding methods. To address these
problems, three progressive methods are proposed. First, we propose
Diff-LM-Speech, an autoregressive structure consisting of a language model and
diffusion models, which models the semantic embedding into the mel-spectrogram
based on a diffusion model to achieve higher audio quality. We also introduce a
prompt encoder structure based on a variational autoencoder and a prosody
bottleneck to improve prompt representation ability. Second, we propose
Tetra-Diff-Speech, a non-autoregressive structure consisting of four diffusion
model-based modules that design a duration diffusion model to achieve diverse
prosodic expressions. Finally, we propose Tri-Diff-Speech, a non-autoregressive
structure consisting of three diffusion model-based modules that verify the
non-necessity of existing semantic encoding models and achieve the best
results. Experimental results show that our proposed methods outperform
baseline methods. We provide a website with audio samples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Breaking Language Barriers: A Question Answering Dataset for Hindi and Marathi. (arXiv:2308.09862v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.09862">
<div class="article-summary-box-inner">
<span><p>The recent advances in deep-learning have led to the development of highly
sophisticated systems with an unquenchable appetite for data. On the other
hand, building good deep-learning models for low-resource languages remains a
challenging task. This paper focuses on developing a Question Answering dataset
for two such languages- Hindi and Marathi. Despite Hindi being the 3rd most
spoken language worldwide, with 345 million speakers, and Marathi being the
11th most spoken language globally, with 83.2 million speakers, both languages
face limited resources for building efficient Question Answering systems. To
tackle the challenge of data scarcity, we have developed a novel approach for
translating the SQuAD 2.0 dataset into Hindi and Marathi. We release the
largest Question-Answering dataset available for these languages, with each
dataset containing 28,000 samples. We evaluate the dataset on various
architectures and release the best-performing models for both Hindi and
Marathi, which will facilitate further research in these languages. Leveraging
similarity tools, our method holds the potential to create datasets in diverse
languages, thereby enhancing the understanding of natural language across
varied linguistic contexts. Our fine-tuned models, code, and dataset will be
made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Activation Addition: Steering Language Models Without Optimization. (arXiv:2308.10248v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.10248">
<div class="article-summary-box-inner">
<span><p>Reliably controlling the behavior of large language models is a pressing open
problem. Existing methods include supervised finetuning, reinforcement learning
from human feedback, prompt engineering, and guided decoding. We instead
investigate activation engineering: modifying activations at inference time to
predictably alter model behavior. In particular, we bias the forward pass with
an added 'steering vector' implicitly specified through natural language.
</p>
<p>Unlike past work which learned these steering vectors, our Activation
Addition (ActAdd) method computes them by taking the activation differences
that result from pairs of prompts. We demonstrate ActAdd on GPT-2 on
OpenWebText and ConceptNet. Our inference-time approach yields control over
high-level properties of output and preserves off-target model performance. It
involves far less compute and implementation effort than finetuning, allows
users to provide natural language specifications, and its overhead scales
naturally with model size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Benchmarking (of Language Models). (arXiv:2308.11696v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.11696">
<div class="article-summary-box-inner">
<span><p>The increasing versatility of language models LMs has given rise to a new
class of benchmarks that comprehensively assess a broad range of capabilities.
Such benchmarks are associated with massive computational costs reaching
thousands of GPU hours per model. However the efficiency aspect of these
evaluation efforts had raised little discussion in the literature. In this work
we present the problem of Efficient Benchmarking namely intelligently reducing
the computation costs of LM evaluation without compromising reliability. Using
the HELM benchmark as a test case we investigate how different benchmark design
choices affect the computation-reliability tradeoff. We propose to evaluate the
reliability of such decisions by using a new measure Decision Impact on
Reliability DIoR for short. We find for example that the current leader on HELM
may change by merely removing a low-ranked model from the benchmark and observe
that a handful of examples suffice to obtain the correct benchmark ranking.
Conversely a slightly different choice of HELM scenarios varies ranking widely.
Based on our findings we outline a set of concrete recommendations for more
efficient benchmark design and utilization practices leading to dramatic cost
savings with minimal loss of benchmark reliability often reducing computation
by x100 or more.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is the U.S. Legal System Ready for AI's Challenges to Human Values?. (arXiv:2308.15906v2 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.15906">
<div class="article-summary-box-inner">
<span><p>Our interdisciplinary study investigates how effectively U.S. laws confront
the challenges posed by Generative AI to human values. Through an analysis of
diverse hypothetical scenarios crafted during an expert workshop, we have
identified notable gaps and uncertainties within the existing legal framework
regarding the protection of fundamental values, such as privacy, autonomy,
dignity, diversity, equity, and physical/mental well-being. Constitutional and
civil rights, it appears, may not provide sufficient protection against
AI-generated discriminatory outputs. Furthermore, even if we exclude the
liability shield provided by Section 230, proving causation for defamation and
product liability claims is a challenging endeavor due to the intricate and
opaque nature of AI systems. To address the unique and unforeseeable threats
posed by Generative AI, we advocate for legal frameworks that evolve to
recognize new threat and provide proactive, auditable guidelines to industry
stakeholders. Addressing these issues requires deep interdisciplinary
collaborations to identify harms, values, and mitigation strategies.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-09-04 23:10:42.081113301 UTC">2023-09-04 23:10:42 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>