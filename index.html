<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-05-05T01:30:00Z">05-05</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Language Models on Low-end Hardware. (arXiv:2305.02350v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02350">
<div class="article-summary-box-inner">
<span><p>This paper evaluates the viability of using fixed language models for
training text classification networks on low-end hardware. We combine language
models with a CNN architecture and put together a comprehensive benchmark with
8 datasets covering single-label and multi-label classification of topic,
sentiment, and genre. Our observations are distilled into a list of trade-offs,
concluding that there are scenarios, where not fine-tuning a language model
yields competitive effectiveness at faster training, requiring only a quarter
of the memory compared to fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Entity Tracking in Language Models. (arXiv:2305.02363v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02363">
<div class="article-summary-box-inner">
<span><p>Keeping track of how states and relations of entities change as a text or
dialog unfolds is a key prerequisite to discourse understanding. Despite this
fact, there have been few systematic investigations into the ability of large
language models (LLMs) to track discourse entities. In this work, we present a
task to probe to what extent a language model can infer the final state of an
entity given an English description of the initial state and a series of
state-changing operations. We use this task to first investigate whether
Flan-T5, GPT-3 and GPT-3.5 can track the state of entities, and find that only
GPT-3.5 models, which have been pretrained on large amounts of code, exhibit
this ability. We then investigate whether smaller models pretrained primarily
on text can learn to track entities, through finetuning T5 on several
training/evaluation splits. While performance degrades for more complex splits,
we find that even for splits with almost no lexical overlap between training
and evaluation, a finetuned model can often perform non-trivial entity
tracking. Taken together, these results suggest that language models can learn
to track entities but pretraining on large text corpora alone does not make
this capacity surface.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PeaCoK: Persona Commonsense Knowledge for Consistent and Engaging Narratives. (arXiv:2305.02364v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02364">
<div class="article-summary-box-inner">
<span><p>Sustaining coherent and engaging narratives requires dialogue or storytelling
agents to understand how the personas of speakers or listeners ground the
narrative. Specifically, these agents must infer personas of their listeners to
produce statements that cater to their interests. They must also learn to
maintain consistent speaker personas for themselves throughout the narrative,
so that their counterparts feel involved in a realistic conversation or story.
</p>
<p>However, personas are diverse and complex: they entail large quantities of
rich interconnected world knowledge that is challenging to robustly represent
in general narrative systems (e.g., a singer is good at singing, and may have
attended conservatoire). In this work, we construct a new large-scale persona
commonsense knowledge graph, PeaCoK, containing ~100K human-validated persona
facts. Our knowledge graph schematizes five dimensions of persona knowledge
identified in previous studies of human interactive behaviours, and distils
facts in this schema from both existing commonsense knowledge graphs and
large-scale pretrained language models. Our analysis indicates that PeaCoK
contains rich and precise world persona inferences that help downstream systems
generate more consistent and engaging narratives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Plagiarism Detection Approach Combining BERT-based Word Embedding, Attention-based LSTMs and an Improved Differential Evolution Algorithm. (arXiv:2305.02374v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02374">
<div class="article-summary-box-inner">
<span><p>Detecting plagiarism involves finding similar items in two different sources.
In this article, we propose a novel method for detecting plagiarism that is
based on attention mechanism-based long short-term memory (LSTM) and
bidirectional encoder representations from transformers (BERT) word embedding,
enhanced with optimized differential evolution (DE) method for pre-training and
a focal loss function for training. BERT could be included in a downstream task
and fine-tuned as a task-specific BERT can be included in a downstream task and
fine-tuned as a task-specific structure, while the trained BERT model is
capable of detecting various linguistic characteristics. Unbalanced
classification is one of the primary issues with plagiarism detection. We
suggest a focal loss-based training technique that carefully learns minority
class instances to solve this. Another issue that we tackle is the training
phase itself, which typically employs gradient-based methods like
back-propagation for the learning process and thus suffers from some drawbacks,
including sensitivity to initialization. To initiate the BP process, we suggest
a novel DE algorithm that makes use of a clustering-based mutation operator.
Here, a winning cluster is identified for the current DE population, and a
fresh updating method is used to produce potential answers. We evaluate our
proposed approach on three benchmark datasets ( MSRP, SNLI, and SemEval2014)
and demonstrate that it performs well when compared to both conventional and
population-based methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Approximating CKY with Transformers. (arXiv:2305.02386v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02386">
<div class="article-summary-box-inner">
<span><p>We investigate the ability of transformer models to approximate the CKY
algorithm, using them to directly predict a parse and thus avoid the CKY
algorithm's cubic dependence on sentence length. We find that on standard
constituency parsing benchmarks this approach achieves competitive or better
performance than comparable parsers that make use of CKY, while being faster.
We also evaluate the viability of this approach for parsing under random PCFGs.
Here we find that performance declines as the grammar becomes more ambiguous,
suggesting that the transformer is not fully capturing the CKY computation.
However, we also find that incorporating additional inductive bias is helpful,
and we propose a novel approach that makes use of gradients with respect to
chart representations in predicting the parse, in analogy with the CKY
algorithm being the subgradient of a partition function variant with respect to
the chart.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Defending against Insertion-based Textual Backdoor Attacks via Attribution. (arXiv:2305.02394v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02394">
<div class="article-summary-box-inner">
<span><p>Textual backdoor attack, as a novel attack model, has been shown to be
effective in adding a backdoor to the model during training. Defending against
such backdoor attacks has become urgent and important. In this paper, we
propose AttDef, an efficient attribution-based pipeline to defend against two
insertion-based poisoning attacks, BadNL and InSent. Specifically, we regard
the tokens with larger attribution scores as potential triggers since larger
attribution words contribute more to the false prediction results and therefore
are more likely to be poison triggers. Additionally, we further utilize an
external pre-trained language model to distinguish whether input is poisoned or
not. We show that our proposed method can generalize sufficiently well in two
common attack scenarios (poisoning training data and testing data), which
consistently improves previous methods. For instance, AttDef can successfully
mitigate both attacks with an average accuracy of 79.97% (56.59% up) and 48.34%
(3.99% up) under pre-training and post-training attack defense respectively,
achieving the new state-of-the-art performance on prediction recovery over four
benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents. (arXiv:2305.02412v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02412">
<div class="article-summary-box-inner">
<span><p>Pre-trained large language models (LLMs) capture procedural knowledge about
the world. Recent work has leveraged LLM's ability to generate abstract plans
to simplify challenging control tasks, either by action scoring, or action
modeling (fine-tuning). However, the transformer architecture inherits several
constraints that make it difficult for the LLM to directly serve as the agent:
e.g. limited input lengths, fine-tuning inefficiency, bias from pre-training,
and incompatibility with non-text environments. To maintain compatibility with
a low-level trainable actor, we propose to instead use the knowledge in LLMs to
simplify the control problem, rather than solving it. We propose the Plan,
Eliminate, and Track (PET) framework. The Plan module translates a task
description into a list of high-level sub-tasks. The Eliminate module masks out
irrelevant objects and receptacles from the observation for the current
sub-task. Finally, the Track module determines whether the agent has
accomplished each sub-task. On the AlfWorld instruction following benchmark,
the PET framework leads to a significant 15% improvement over SOTA for
generalization to human goal specifications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PTP: Boosting Stability and Performance of Prompt Tuning with Perturbation-Based Regularizer. (arXiv:2305.02423v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02423">
<div class="article-summary-box-inner">
<span><p>Recent studies show that prompt tuning can better leverage the power of large
language models than fine-tuning on downstream natural language understanding
tasks. However, the existing prompt tuning methods have training instability
issues, as the variance of scores under different random seeds is quite large.
To address this critical problem, we first investigate and find that the loss
landscape of vanilla prompt tuning is precipitous when it is visualized, where
a slight change of input data can cause a big fluctuation in the loss
landscape. This is an essential factor that leads to the instability of prompt
tuning. Based on this observation, we introduce perturbation-based
regularizers, which can smooth the loss landscape, into prompt tuning. We
propose a new algorithm, called Prompt Tuning with Perturbation-based
regularizer~(PTP), which can not only alleviate training instability
dramatically but also boost the performance of prompt tuning. We design two
kinds of perturbation-based regularizers, including random-noise-based and
adversarial-based. In particular, our proposed perturbations are flexible on
both text space and embedding space. Extensive experiments show the
effectiveness of our proposed methods in stabilizing the training. Our new
algorithms improve the state-of-the-art prompt tuning methods by 1.94\% and
2.34\% on SuperGLUE and FewGLUE benchmarks, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Backdoor Learning on Sequence to Sequence Models. (arXiv:2305.02424v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02424">
<div class="article-summary-box-inner">
<span><p>Backdoor learning has become an emerging research area towards building a
trustworthy machine learning system. While a lot of works have studied the
hidden danger of backdoor attacks in image or text classification, there is a
limited understanding of the model's robustness on backdoor attacks when the
output space is infinite and discrete. In this paper, we study a much more
challenging problem of testing whether sequence-to-sequence (seq2seq) models
are vulnerable to backdoor attacks. Specifically, we find by only injecting
0.2\% samples of the dataset, we can cause the seq2seq model to generate the
designated keyword and even the whole sentence. Furthermore, we utilize Byte
Pair Encoding (BPE) to create multiple new triggers, which brings new
challenges to backdoor detection since these backdoors are not static.
Extensive experiments on machine translation and text summarization have been
conducted to show our proposed methods could achieve over 90\% attack success
rate on multiple datasets and models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">evaluating bert and parsbert for analyzing persian advertisement data. (arXiv:2305.02426v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02426">
<div class="article-summary-box-inner">
<span><p>This paper discusses the impact of the Internet on modern trading and the
importance of data generated from these transactions for organizations to
improve their marketing efforts. The paper uses the example of Divar, an online
marketplace for buying and selling products and services in Iran, and presents
a competition to predict the percentage of a car sales ad that would be
published on the Divar website. Since the dataset provides a rich source of
Persian text data, the authors use the Hazm library, a Python library designed
for processing Persian text, and two state-of-the-art language models, mBERT
and ParsBERT, to analyze it. The paper's primary objective is to compare the
performance of mBERT and ParsBERT on the Divar dataset. The authors provide
some background on data mining, Persian language, and the two language models,
examine the dataset's composition and statistical features, and provide details
on their fine-tuning and training configurations for both approaches. They
present the results of their analysis and highlight the strengths and
weaknesses of the two language models when applied to Persian text data. The
paper offers valuable insights into the challenges and opportunities of working
with low-resource languages such as Persian and the potential of advanced
language models like BERT for analyzing such data. The paper also explains the
data mining process, including steps such as data cleaning and normalization
techniques. Finally, the paper discusses the types of machine learning
problems, such as supervised, unsupervised, and reinforcement learning, and the
pattern evaluation techniques, such as confusion matrix. Overall, the paper
provides an informative overview of the use of language models and data mining
techniques for analyzing text data in low-resource languages, using the example
of the Divar dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory. (arXiv:2305.02437v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02437">
<div class="article-summary-box-inner">
<span><p>With direct access to human-written reference as memory, retrieval-augmented
generation has achieved much progress in a wide range of text generation tasks.
Since better memory would typically prompt better generation~(we define this as
primal problem), previous works mainly focus on how to retrieve better memory.
However, one fundamental limitation exists for current literature: the memory
is retrieved from a fixed corpus and is bounded by the quality of the corpus.
Due to the finite retrieval space, bounded memory would greatly limit the
potential of the memory-augmented generation model. In this paper, by exploring
the duality of the primal problem: better generation also prompts better
memory, we propose a framework called Selfmem, which iteratively adopts a
retrieval-augmented generator itself to generate an unbounded memory pool and
uses a memory selector to pick one generated memory for the next generation
round. By combining the primal and dual problem, a retrieval-augmented
generation model could lift itself up with its own output in the infinite
generation space. To verify our framework, we conduct extensive experiments
across various text generation scenarios including neural machine translation,
abstractive summarization and dialogue generation over seven datasets and
achieve state-of-the-art results in JRC-Acquis(four directions), XSum(50.3
ROUGE-1) and BigPatent(62.9 ROUGE-1).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantifying the Dissimilarity of Texts. (arXiv:2305.02457v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02457">
<div class="article-summary-box-inner">
<span><p>Quantifying the dissimilarity of two texts is an important aspect of a number
of natural language processing tasks, including semantic information retrieval,
topic classification, and document clustering. In this paper, we compared the
properties and performance of different dissimilarity measures $D$ using three
different representations of texts -- vocabularies, word frequency
distributions, and vector embeddings -- and three simple tasks -- clustering
texts by author, subject, and time period. Using the Project Gutenberg
database, we found that the generalised Jensen--Shannon divergence applied to
word frequencies performed strongly across all tasks, that $D$'s based on
vector embedding representations led to stronger performance for smaller texts,
and that the optimal choice of approach was ultimately task-dependent. We also
investigated, both analytically and numerically, the behaviour of the different
$D$'s when the two texts varied in length by a factor $h$. We demonstrated that
the (natural) estimator of the Jaccard distance between vocabularies was
inconsistent and computed explicitly the $h$-dependency of the bias of the
estimator of the generalised Jensen--Shannon divergence applied to word
frequencies. We also found numerically that the Jensen--Shannon divergence and
embedding-based approaches were robust to changes in $h$, while the Jaccard
distance was not.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge. (arXiv:2305.02459v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02459">
<div class="article-summary-box-inner">
<span><p>While transformer-based systems have enabled greater accuracies with fewer
training examples, data acquisition obstacles still persist for rare-class
tasks -- when the class label is very infrequent (e.g. &lt; 5% of samples). Active
learning has in general been proposed to alleviate such challenges, but choice
of selection strategy, the criteria by which rare-class examples are chosen,
has not been systematically evaluated. Further, transformers enable iterative
transfer-learning approaches. We propose and investigate transfer- and active
learning solutions to the rare class problem of dissonance detection through
utilizing models trained on closely related tasks and the evaluation of
acquisition strategies, including a proposed probability-of-rare-class (PRC)
approach. We perform these experiments for a specific rare class problem:
collecting language samples of cognitive dissonance from social media. We find
that PRC is a simple and effective strategy to guide annotations and ultimately
improve model accuracy while transfer-learning in a specific order can improve
the cold-start performance of the learner but does not benefit iterations of
active learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction. (arXiv:2305.02466v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02466">
<div class="article-summary-box-inner">
<span><p>A proven therapeutic technique to overcome negative thoughts is to replace
them with a more hopeful "reframed thought." Although therapy can help people
practice and learn this Cognitive Reframing of Negative Thoughts, clinician
shortages and mental health stigma commonly limit people's access to therapy.
In this paper, we conduct a human-centered study of how language models may
assist people in reframing negative thoughts. Based on psychology literature,
we define a framework of seven linguistic attributes that can be used to
reframe a thought. We develop automated metrics to measure these attributes and
validate them with expert judgements from mental health practitioners. We
collect a dataset of 600 situations, thoughts and reframes from practitioners
and use it to train a retrieval-enhanced in-context learning model that
effectively generates reframed thoughts and controls their linguistic
attributes. To investigate what constitutes a "high-quality" reframe, we
conduct an IRB-approved randomized field study on a large mental health website
with over 2,000 participants. Amongst other findings, we show that people
prefer highly empathic or specific reframes, as opposed to reframes that are
overly positive. Our findings provide key implications for the use of LMs to
assist people in overcoming negative thoughts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System. (arXiv:2305.02468v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02468">
<div class="article-summary-box-inner">
<span><p>Task-Oriented Dialogue (TOD) systems are designed to carry out specific tasks
by tracking dialogue states and generating appropriate responses to help users
achieve defined goals. Recently, end-to-end dialogue models pre-trained based
on large datasets have shown promising performance in the conversational
system. However, they share the same parameters to train tasks of the dialogue
system (NLU, DST, NLG), so debugging each task is challenging. Also, they
require a lot of effort to fine-tune large parameters to create a task-oriented
chatbot, making it difficult for non-experts to handle. Therefore, we intend to
train relatively lightweight and fast models compared to PLM. In this paper, we
propose an End-to-end TOD system with Task-Optimized Adapters which learn
independently per task, adding only small number of parameters after fixed
layers of pre-trained network. We also enhance the performance of the DST and
NLG modules through reinforcement learning, overcoming the learning curve that
has lacked at the adapter learning and enabling the natural and consistent
response generation that is appropriate for the goal. Our method is a
model-agnostic approach and does not require prompt-tuning as only input data
without a prompt. As results of the experiment, our method shows competitive
performance on the MultiWOZ benchmark compared to the existing end-to-end
models. In particular, we attain state-of-the-art performance on the DST task
of 2.2 dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward the Automated Construction of Probabilistic Knowledge Graphs for the Maritime Domain. (arXiv:2305.02471v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02471">
<div class="article-summary-box-inner">
<span><p>International maritime crime is becoming increasingly sophisticated, often
associated with wider criminal networks. Detecting maritime threats by means of
fusing data purely related to physical movement (i.e., those generated by
physical sensors, or hard data) is not sufficient. This has led to research and
development efforts aimed at combining hard data with other types of data
(especially human-generated or soft data). Existing work often assumes that
input soft data is available in a structured format, or is focused on
extracting certain relevant entities or concepts to accompany or annotate hard
data. Much less attention has been given to extracting the rich knowledge about
the situations of interest implicitly embedded in the large amount of soft data
existing in unstructured formats (such as intelligence reports and news
articles). In order to exploit the potentially useful and rich information from
such sources, it is necessary to extract not only the relevant entities and
concepts but also their semantic relations, together with the uncertainty
associated with the extracted knowledge (i.e., in the form of probabilistic
knowledge graphs). This will increase the accuracy of and confidence in, the
extracted knowledge and facilitate subsequent reasoning and learning. To this
end, we propose Maritime DeepDive, an initial prototype for the automated
construction of probabilistic knowledge graphs from natural language data for
the maritime domain. In this paper, we report on the current implementation of
Maritime DeepDive, together with preliminary results on extracting
probabilistic events from maritime piracy incidents. This pipeline was
evaluated on a manually crafted gold standard, yielding promising results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT-steered Editing Instructor for Customization of Abstractive Summarization. (arXiv:2305.02483v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02483">
<div class="article-summary-box-inner">
<span><p>Tailoring outputs of large language models, such as ChatGPT, to specific user
needs remains a challenge despite their impressive generation quality. In this
paper, we propose a tri-agent generation pipeline consisting of a generator, an
instructor, and an editor to enhance the customization of generated outputs.
The generator produces an initial output, the user-specific instructor
generates editing instructions, and the editor generates a revised output
aligned with user preferences. The inference-only large language model
(ChatGPT) serves as both the generator and the editor, while a smaller model
acts as the user-specific instructor to guide the generation process toward
user needs. The instructor is trained using editor-steered reinforcement
learning, leveraging feedback from the large-scale editor model to optimize
instruction generation. Experimental results on two abstractive summarization
datasets demonstrate the effectiveness of our approach in generating outputs
that better fulfill user expectations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AutoML-GPT: Automatic Machine Learning with GPT. (arXiv:2305.02499v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02499">
<div class="article-summary-box-inner">
<span><p>AI tasks encompass a wide range of domains and fields. While numerous AI
models have been designed for specific tasks and applications, they often
require considerable human efforts in finding the right model architecture,
optimization algorithm, and hyperparameters. Recent advances in large language
models (LLMs) like ChatGPT show remarkable capabilities in various aspects of
reasoning, comprehension, and interaction. Consequently, we propose developing
task-oriented prompts and automatically utilizing LLMs to automate the training
pipeline. To implement this concept, we present the AutoML-GPT, which employs
GPT as the bridge to diverse AI models and dynamically trains models with
optimized hyperparameters. AutoML-GPT dynamically takes user requests from the
model and data cards and composes the corresponding prompt paragraph.
Ultimately, with this prompt paragraph, AutoML-GPT will automatically conduct
the experiments from data processing to model architecture, hyperparameter
tuning, and predicted training log. By leveraging {\ours}'s robust language
capabilities and the available AI models, AutoML-GPT can tackle numerous
intricate AI tasks across various tasks and datasets. This approach achieves
remarkable results in computer vision, natural language processing, and other
challenging areas. Extensive experiments and ablation studies demonstrate that
our method can be general, effective, and beneficial for many AI tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">USTC-NELSLIP at SemEval-2023 Task 2: Statistical Construction and Dual Adaptation of Gazetteer for Multilingual Complex NER. (arXiv:2305.02517v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02517">
<div class="article-summary-box-inner">
<span><p>This paper describes the system developed by the USTC-NELSLIP team for
SemEval-2023 Task 2 Multilingual Complex Named Entity Recognition (MultiCoNER
II). A method named Statistical Construction and Dual Adaptation of Gazetteer
(SCDAG) is proposed for Multilingual Complex NER. The method first utilizes a
statistics-based approach to construct a gazetteer. Secondly, the
representations of gazetteer networks and language models are adapted by
minimizing the KL divergence between them at both the sentence-level and
entity-level. Finally, these two networks are then integrated for supervised
named entity recognition (NER) training. The proposed method is applied to
XLM-R with a gazetteer built from Wikidata, and shows great generalization
ability across different tracks. Experimental results and detailed analysis
verify the effectiveness of the proposed method. The official results show that
our system ranked 1st on one track (Hindi) in this task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ANetQA: A Large-scale Benchmark for Fine-grained Compositional Reasoning over Untrimmed Videos. (arXiv:2305.02519v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02519">
<div class="article-summary-box-inner">
<span><p>Building benchmarks to systemically analyze different capabilities of video
question answering (VideoQA) models is challenging yet crucial. Existing
benchmarks often use non-compositional simple questions and suffer from
language biases, making it difficult to diagnose model weaknesses incisively. A
recent benchmark AGQA poses a promising paradigm to generate QA pairs
automatically from pre-annotated scene graphs, enabling it to measure diverse
reasoning abilities with granular control. However, its questions have
limitations in reasoning about the fine-grained semantics in videos as such
information is absent in its scene graphs. To this end, we present ANetQA, a
large-scale benchmark that supports fine-grained compositional reasoning over
the challenging untrimmed videos from ActivityNet. Similar to AGQA, the QA
pairs in ANetQA are automatically generated from annotated video scene graphs.
The fine-grained properties of ANetQA are reflected in the following: (i)
untrimmed videos with fine-grained semantics; (ii) spatio-temporal scene graphs
with fine-grained taxonomies; and (iii) diverse questions generated from
fine-grained templates. ANetQA attains 1.4 billion unbalanced and 13.4 million
balanced QA pairs, which is an order of magnitude larger than AGQA with a
similar number of videos. Comprehensive experiments are performed for
state-of-the-art methods. The best model achieves 44.5% accuracy while human
performance tops out at 84.5%, leaving sufficient room for improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language, Time Preferences, and Consumer Behavior: Evidence from Large Language Models. (arXiv:2305.02531v1 [econ.GN])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02531">
<div class="article-summary-box-inner">
<span><p>Language has a strong influence on our perceptions of time and rewards. This
raises the question of whether large language models, when asked in different
languages, show different preferences for rewards over time and if their
choices are similar to those of humans. In this study, we analyze the responses
of GPT-3.5 (hereafter referred to as GPT) to prompts in multiple languages,
exploring preferences between smaller, sooner rewards and larger, later
rewards. Our results show that GPT displays greater patience when prompted in
languages with weak future tense references (FTR), such as German and Mandarin,
compared to languages with strong FTR, like English and French. These findings
are consistent with existing literature and suggest a correlation between GPT's
choices and the preferences of speakers of these languages. However, further
analysis reveals that the preference for earlier or later rewards does not
systematically change with reward gaps, indicating a lexicographic preference
for earlier payments. While GPT may capture intriguing variations across
languages, our findings indicate that the choices made by these models do not
correspond to those of human decision-makers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences. (arXiv:2305.02547v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02547">
<div class="article-summary-box-inner">
<span><p>Despite the many use cases for large language models (LLMs) in the design of
chatbots in various industries and the research showing the importance of
personalizing chatbots to cater to different personality traits, little work
has been done to evaluate whether the behaviors of personalized LLMs can
reflect certain personality traits accurately and consistently. We consider
studying the behavior of LLM-based simulated agents which refer to as LLM
personas and present a case study with GPT-3.5 (text-davinci-003) to
investigate whether LLMs can generate content with consistent, personalized
traits when assigned Big Five personality types and gender roles. We created
320 LLM personas (5 females and 5 males for each of the 32 Big Five personality
types) and prompted them to complete the classic 44-item Big Five Inventory
(BFI) and then write an 800-word story about their childhood. Results showed
that LLM personas' self-reported BFI scores are consistent with their assigned
personality types, with large effect sizes found on all five traits. Moreover,
significant correlations were found between assigned personality types and some
Linguistic Inquiry and Word Count (LIWC) psycholinguistic features of their
writings. For instance, extroversion is associated with pro-social and active
words, and neuroticism is associated with words related to negative emotions
and mental health. Besides, we only found significant differences in using
technological and cultural words in writing between LLM-generated female and
male personas. This work provides a first step for further research on
personalized LLMs and their applications in Human-AI conversation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FormNetV2: Multimodal Graph Contrastive Learning for Form Document Information Extraction. (arXiv:2305.02549v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02549">
<div class="article-summary-box-inner">
<span><p>The recent advent of self-supervised pre-training techniques has led to a
surge in the use of multimodal learning in form document understanding.
However, existing approaches that extend the mask language modeling to other
modalities require careful multi-task tuning, complex reconstruction target
designs, or additional pre-training data. In FormNetV2, we introduce a
centralized multimodal graph contrastive learning strategy to unify
self-supervised pre-training for all modalities in one loss. The graph
contrastive objective maximizes the agreement of multimodal representations,
providing a natural interplay for all modalities without special customization.
In addition, we extract image features within the bounding box that joins a
pair of tokens connected by a graph edge, capturing more targeted visual cues
without loading a sophisticated and separately pre-trained image embedder.
FormNetV2 establishes new state-of-the-art performance on FUNSD, CORD, SROIE
and Payment benchmarks with a more compact model size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Faithful Question Answering with Monte-Carlo Planning. (arXiv:2305.02556v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02556">
<div class="article-summary-box-inner">
<span><p>Although large language models demonstrate remarkable question-answering
performances, revealing the intermediate reasoning steps that the models
faithfully follow remains challenging. In this paper, we propose FAME (FAithful
question answering with MontE-carlo planning) to answer questions based on
faithful reasoning steps. The reasoning steps are organized as a structured
entailment tree, which shows how premises are used to produce intermediate
conclusions that can prove the correctness of the answer. We formulate the task
as a discrete decision-making problem and solve it through the interaction of a
reasoning environment and a controller. The environment is modular and contains
several basic task-oriented modules, while the controller proposes actions to
assemble the modules. Since the search space could be large, we introduce a
Monte-Carlo planning algorithm to do a look-ahead search and select actions
that will eventually lead to high-quality steps. FAME achieves state-of-the-art
performance on the standard benchmark. It can produce valid and faithful
reasoning steps compared with large language models with a much smaller model
size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analyzing Hong Kong's Legal Judgments from a Computational Linguistics point-of-view. (arXiv:2305.02558v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02558">
<div class="article-summary-box-inner">
<span><p>Analysis and extraction of useful information from legal judgments using
computational linguistics was one of the earliest problems posed in the domain
of information retrieval. Presently, several commercial vendors exist who
automate such tasks. However, a crucial bottleneck arises in the form of
exorbitant pricing and lack of resources available in analysis of judgements
mete out by Hong Kong's Legal System. This paper attempts to bridge this gap by
providing several statistical, machine learning, deep learning and zero-shot
learning based methods to effectively analyze legal judgments from Hong Kong's
Court System. The methods proposed consists of: (1) Citation Network Graph
Generation, (2) PageRank Algorithm, (3) Keyword Analysis and Summarization, (4)
Sentiment Polarity, and (5) Paragrah Classification, in order to be able to
extract key insights from individual as well a group of judgments together.
This would make the overall analysis of judgments in Hong Kong less tedious and
more automated in order to extract insights quickly using fast inferencing. We
also provide an analysis of our results by benchmarking our results using Large
Language Models making robust use of the HuggingFace ecosystem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RetroMAE-2: Duplex Masked Auto-Encoder For Pre-Training Retrieval-Oriented Language Models. (arXiv:2305.02564v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02564">
<div class="article-summary-box-inner">
<span><p>To better support information retrieval tasks such as web search and
open-domain question answering, growing effort is made to develop
retrieval-oriented language models, e.g., RetroMAE and many others. Most of the
existing works focus on improving the semantic representation capability for
the contextualized embedding of the [CLS] token. However, recent study shows
that the ordinary tokens besides [CLS] may provide extra information, which
help to produce a better representation effect. As such, it's necessary to
extend the current methods where all contextualized embeddings can be jointly
pre-trained for the retrieval tasks. In this work, we propose a novel
pre-training method called Duplex Masked Auto-Encoder, a.k.a. DupMAE. It is
designed to improve the quality of semantic representation where all
contextualized embeddings of the pre-trained model can be leveraged. It takes
advantage of two complementary auto-encoding tasks: one reconstructs the input
sentence on top of the [CLS] embedding; the other one predicts the bag-of-words
feature of the input sentence based on the ordinary tokens' embeddings. The two
tasks are jointly conducted to train a unified encoder, where the whole
contextualized embeddings are aggregated in a compact way to produce the final
semantic representation. DupMAE is simple but empirically competitive: it
substantially improves the pre-trained model's representation capability and
transferability, where superior retrieval performances can be achieved on
popular benchmarks, like MS MARCO and BEIR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Statistical Methods to Deep Learning, Automatic Keyphrase Prediction: A Survey. (arXiv:2305.02579v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02579">
<div class="article-summary-box-inner">
<span><p>Keyphrase prediction aims to generate phrases (keyphrases) that highly
summarizes a given document. Recently, researchers have conducted in-depth
studies on this task from various perspectives. In this paper, we
comprehensively summarize representative studies from the perspectives of
dominant models, datasets and evaluation metrics. Our work analyzes up to 167
previous works, achieving greater coverage of this task than previous surveys.
Particularly, we focus highly on deep learning-based keyphrase prediction,
which attracts increasing attention of this task in recent years. Afterwards,
we conduct several groups of experiments to carefully compare representative
models. To the best of our knowledge, our work is the first attempt to compare
these models using the identical commonly-used datasets and evaluation metric,
facilitating in-depth analyses of their disadvantages and advantages. Finally,
we discuss the possible research directions of this task in the future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Re$^3$Dial: Retrieve, Reorganize and Rescale Dialogue Corpus for Long-Turn Open-Domain Dialogue Pre-training. (arXiv:2305.02606v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02606">
<div class="article-summary-box-inner">
<span><p>Large-scale open-domain dialogue data crawled from public social media has
greatly improved the performance of dialogue models. However, long-turn
dialogues are still highly scarce. Specifically, most dialogue sessions in
existing corpora have less than three turns. To alleviate this issue, we
propose the Retrieve, Reorganize and Rescale framework (Re$^3$Dial), which can
automatically construct a billion-scale long-turn dialogue corpus from existing
short-turn dialogue data. Re$^3$Dial first trains an Unsupervised Dense Session
Retriever (UDSR) to capture semantic and discourse relationships within
multi-turn dialogues for retrieving relevant and coherent sessions. It then
reorganizes the short-turn dialogues into long-turn sessions via recursively
retrieving and selecting the consecutive sessions with our proposed diversity
sampling strategy. Extensive evaluations on multiple multi-turn dialogue
benchmarks demonstrate that Re$^3$Dial consistently and significantly improves
the dialogue model's ability to utilize long-term context for modeling
multi-turn dialogues across different pre-training settings. Finally, we build
a toolkit for efficiently rescaling dialogue corpus with Re$^3$Dial, which
enables us to construct a corpus containing 1B Chinese dialogue sessions with
11.3 turns on average (5X longer than the original EVA corpus). We will release
our UDSR model, toolkit, and data for public use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DN at SemEval-2023 Task 12: Low-Resource Language Text Classification via Multilingual Pretrained Language Model Fine-tuning. (arXiv:2305.02607v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02607">
<div class="article-summary-box-inner">
<span><p>In recent years, sentiment analysis has gained significant importance in
natural language processing. However, most existing models and datasets for
sentiment analysis are developed for high-resource languages, such as English
and Chinese, leaving low-resource languages, particularly African languages,
largely unexplored. The AfriSenti-SemEval 2023 Shared Task 12 aims to fill this
gap by evaluating sentiment analysis models on low-resource African languages.
In this paper, we present our solution to the shared task, where we employed
different multilingual XLM-R models with classification head trained on various
data, including those retrained in African dialects and fine-tuned on target
languages. Our team achieved the third-best results in Subtask B, Track 16:
Multilingual, demonstrating the effectiveness of our approach. While our model
showed relatively good results on multilingual data, it performed poorly in
some languages. Our findings highlight the importance of developing more
comprehensive datasets and models for low-resource African languages to advance
sentiment analysis research. We also provided the solution on the github
repository.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Affective Reasoning at Utterance Level in Conversations: A Causal Discovery Approach. (arXiv:2305.02615v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02615">
<div class="article-summary-box-inner">
<span><p>The affective reasoning task is a set of emerging affect-based tasks in
conversation, including Emotion Recognition in Conversation (ERC),Emotion-Cause
Pair Extraction (ECPE), and Emotion-Cause Span Recognition (ECSR). Existing
methods make various assumptions on the apparent relationship while neglecting
the essential causal model due to the nonuniqueness of skeletons and
unobservability of implicit causes. This paper settled down the above two
problems and further proposed Conversational Affective Causal Discovery (CACD).
It is a novel causal discovery method showing how to discover causal
relationships in a conversation via designing a common skeleton and generating
a substitute for implicit causes. CACD contains two steps: (i) building a
common centering one graph node causal skeleton for all utterances in
variable-length conversations; (ii) Causal Auto-Encoder (CAE) correcting the
skeleton to yield causal representation through generated implicit causes and
known explicit causes. Comprehensive experiments demonstrate that our novel
method significantly outperforms the SOTA baselines in six affect-related
datasets on the three tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A framework for the emergence and analysis of language in social learning agents. (arXiv:2305.02632v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02632">
<div class="article-summary-box-inner">
<span><p>Artificial neural networks (ANNs) are increasingly used as research models,
but questions remain about their generalizability and representational
invariance. Biological neural networks under social constraints evolved to
enable communicable representations, demonstrating generalization capabilities.
This study proposes a communication protocol between cooperative agents to
analyze the formation of individual and shared abstractions and their impact on
task performance. This communication protocol aims to mimic language features
by encoding high-dimensional information through low-dimensional
representation. Using grid-world mazes and reinforcement learning, teacher ANNs
pass a compressed message to a student ANN for better task completion. Through
this, the student achieves a higher goal-finding rate and generalizes the goal
location across task worlds. Further optimizing message content to maximize
student reward improves information encoding, suggesting that an accurate
representation in the space of messages requires bi-directional input. This
highlights the role of language as a common representation between agents and
its implications on generalization capabilities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conformal Nucleus Sampling. (arXiv:2305.02633v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02633">
<div class="article-summary-box-inner">
<span><p>Language models generate text based on successively sampling the next word. A
decoding procedure based on nucleus (top-$p$) sampling chooses from the
smallest possible set of words whose cumulative probability exceeds the
probability $p$. In this work, we assess whether a top-$p$ set is indeed
aligned with its probabilistic meaning in various linguistic contexts. We
employ conformal prediction, a calibration procedure that focuses on the
construction of minimal prediction sets according to a desired confidence
level, to calibrate the parameter $p$ as a function of the entropy of the next
word distribution. We find that OPT models are overconfident, and that
calibration shows a moderate inverse scaling with model size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Weakly-Supervised Hate Speech Classification Across Datasets. (arXiv:2305.02637v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02637">
<div class="article-summary-box-inner">
<span><p>As pointed out by several scholars, current research on hate speech (HS)
recognition is characterized by unsystematic data creation strategies and
diverging annotation schemata. Subsequently, supervised-learning models tend to
generalize poorly to datasets they were not trained on, and the performance of
the models trained on datasets labeled using different HS taxonomies cannot be
compared. To ease this problem, we propose applying extremely weak supervision
that only relies on the class name rather than on class samples from the
annotated data. We demonstrate the effectiveness of a state-of-the-art
weakly-supervised text classification model in various in-dataset and
cross-dataset settings. Furthermore, we conduct an in-depth quantitative and
qualitative analysis of the source of poor generalizability of HS
classification models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Language-Specific Layers for Multilingual Machine Translation. (arXiv:2305.02665v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02665">
<div class="article-summary-box-inner">
<span><p>Multilingual Machine Translation promises to improve translation quality
between non-English languages. This is advantageous for several reasons, namely
lower latency (no need to translate twice), and reduced error cascades (e.g.,
avoiding losing gender and formality information when translating through
English). On the downside, adding more languages reduces model capacity per
language, which is usually countered by increasing the overall model size,
making training harder and inference slower. In this work, we introduce
Language-Specific Transformer Layers (LSLs), which allow us to increase model
capacity, while keeping the amount of computation and the number of parameters
used in the forward pass constant. The key idea is to have some layers of the
encoder be source or target language-specific, while keeping the remaining
layers shared. We study the best way to place these layers using a neural
architecture search inspired approach, and achieve an improvement of 1.3 chrF
(1.5 spBLEU) points over not using LSLs on a separate decoder architecture, and
1.9 chrF (2.2 spBLEU) on a shared decoder one.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neighboring Words Affect Human Interpretation of Saliency Explanations. (arXiv:2305.02679v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02679">
<div class="article-summary-box-inner">
<span><p>Word-level saliency explanations ("heat maps over words") are often used to
communicate feature-attribution in text-based models. Recent studies found that
superficial factors such as word length can distort human interpretation of the
communicated saliency scores. We conduct a user study to investigate how the
marking of a word's neighboring words affect the explainee's perception of the
word's importance in the context of a saliency explanation. We find that
neighboring words have significant effects on the word's importance rating.
Concretely, we identify that the influence changes based on neighboring
direction (left vs. right) and a-priori linguistic and computational measures
of phrases and collocations (vs. unrelated neighboring words). Our results
question whether text-based saliency explanations should be continued to be
communicated at word level, and inform future research on alternative saliency
explanation methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Big Data and Large Numbers. Interpreting Zipf's Law. (arXiv:2305.02687v1 [physics.soc-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02687">
<div class="article-summary-box-inner">
<span><p>It turns out that some empirical facts in Big Data are the effects of
properties of large numbers. Zipf's law noise is an example of such an
artefact. We expose several properties of the power law distributions and of
similar distribution that occur when the population is finite and the rank and
counts of elements in the population are natural numbers. Consequences in the
interpretation of Zipf's law are discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Asynchronous Updating Reinforcement Learning Framework for Task-oriented Dialog System. (arXiv:2305.02718v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02718">
<div class="article-summary-box-inner">
<span><p>Reinforcement learning has been applied to train the dialog systems in many
works. Previous approaches divide the dialog system into multiple modules
including DST (dialog state tracking) and DP (dialog policy), and train these
modules simultaneously. However, different modules influence each other during
training. The errors from DST might misguide the dialog policy, and the system
action brings extra difficulties for the DST module. To alleviate this problem,
we propose Asynchronous Updating Reinforcement Learning framework (AURL) that
updates the DST module and the DP module asynchronously under a cooperative
setting. Furthermore, curriculum learning is implemented to address the problem
of unbalanced data distribution during reinforcement learning sampling, and
multiple user models are introduced to increase the dialog diversity. Results
on the public SSD-PHONE dataset show that our method achieves a compelling
result with a 31.37% improvement on the dialog success rate. The code is
publicly available via https://github.com/shunjiu/AURL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Dialogue Topic Segmentation with Topic-aware Utterance Representation. (arXiv:2305.02747v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02747">
<div class="article-summary-box-inner">
<span><p>Dialogue Topic Segmentation (DTS) plays an essential role in a variety of
dialogue modeling tasks. Previous DTS methods either focus on semantic
similarity or dialogue coherence to assess topic similarity for unsupervised
dialogue segmentation. However, the topic similarity cannot be fully identified
via semantic similarity or dialogue coherence. In addition, the unlabeled
dialogue data, which contains useful clues of utterance relationships, remains
underexploited. In this paper, we propose a novel unsupervised DTS framework,
which learns topic-aware utterance representations from unlabeled dialogue data
through neighboring utterance matching and pseudo-segmentation. Extensive
experiments on two benchmark datasets (i.e., DialSeg711 and Doc2Dial)
demonstrate that our method significantly outperforms the strong baseline
methods. For reproducibility, we provide our code and data
at:https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/dial-start.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Proactive Dialogue Systems: Problems, Methods, and Prospects. (arXiv:2305.02750v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02750">
<div class="article-summary-box-inner">
<span><p>Proactive dialogue systems, related to a wide range of real-world
conversational applications, equip the conversational agent with the capability
of leading the conversation direction towards achieving pre-defined targets or
fulfilling certain goals from the system side. It is empowered by advanced
techniques to progress to more complicated tasks that require strategical and
motivational interactions. In this survey, we provide a comprehensive overview
of the prominent problems and advanced designs for conversational agent's
proactivity in different types of dialogues. Furthermore, we discuss challenges
that meet the real-world application needs but require a greater research focus
in the future. We hope that this first survey of proactive dialogue systems can
provide the community with a quick access and an overall picture to this
practical problem, and stimulate more progresses on conversational AI to the
next level.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VendorLink: An NLP approach for Identifying & Linking Vendor Migrants & Potential Aliases on Darknet Markets. (arXiv:2305.02763v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02763">
<div class="article-summary-box-inner">
<span><p>The anonymity on the Darknet allows vendors to stay undetected by using
multiple vendor aliases or frequently migrating between markets. Consequently,
illegal markets and their connections are challenging to uncover on the
Darknet. To identify relationships between illegal markets and their vendors,
we propose VendorLink, an NLP-based approach that examines writing patterns to
verify, identify, and link unique vendor accounts across text advertisements
(ads) on seven public Darknet markets. In contrast to existing literature,
VendorLink utilizes the strength of supervised pre-training to perform
closed-set vendor verification, open-set vendor identification, and
low-resource market adaption tasks. Through VendorLink, we uncover (i) 15
migrants and 71 potential aliases in the Alphabay-Dreams-Silk dataset, (ii) 17
migrants and 3 potential aliases in the Valhalla-Berlusconi dataset, and (iii)
75 migrants and 10 potential aliases in the Traderoute-Agora dataset.
Altogether, our approach can help Law Enforcement Agencies (LEA) make more
informed decisions by verifying and identifying migrating vendors and their
potential aliases on existing and Low-Resource (LR) emerging Darknet markets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Politics of Language Choice: How the Russian-Ukrainian War Influences Ukrainians' Language Use on Twitter. (arXiv:2305.02770v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02770">
<div class="article-summary-box-inner">
<span><p>The use of language is innately political and often a vehicle of cultural
identity as well as the basis for nation building. Here, we examine language
choice and tweeting activity of Ukrainian citizens based on more than 4 million
geo-tagged tweets from over 62,000 users before and during the
Russian-Ukrainian War, from January 2020 to October 2022. Using statistical
models, we disentangle sample effects, arising from the in- and outflux of
users on Twitter, from behavioural effects, arising from behavioural changes of
the users. We observe a steady shift from the Russian language towards the
Ukrainian language already before the war, which drastically speeds up with its
outbreak. We attribute these shifts in large part to users' behavioural
changes. Notably, we find that many Russian-tweeting users perform a
hard-switch to Ukrainian as a result of the war.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified Model Learning for Various Neural Machine Translation. (arXiv:2305.02777v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02777">
<div class="article-summary-box-inner">
<span><p>Existing neural machine translation (NMT) studies mainly focus on developing
dataset-specific models based on data from different tasks (e.g., document
translation and chat translation). Although the dataset-specific models have
achieved impressive performance, it is cumbersome as each dataset demands a
model to be designed, trained, and stored. In this work, we aim to unify these
translation tasks into a more general setting. Specifically, we propose a
``versatile'' model, i.e., the Unified Model Learning for NMT (UMLNMT) that
works with data from different tasks, and can translate well in multiple
settings simultaneously, and theoretically it can be as many as possible.
Through unified learning, UMLNMT is able to jointly train across multiple
tasks, implementing intelligent on-demand translation. On seven widely-used
translation tasks, including sentence translation, document translation, and
chat translation, our UMLNMT results in substantial improvements over
dataset-specific models with significantly reduced model deployment costs.
Furthermore, UMLNMT can achieve competitive or better performance than
state-of-the-art dataset-specific methods. Human evaluation and in-depth
analysis also demonstrate the superiority of our approach on generating diverse
and high-quality translations. Additionally, we provide a new genre translation
dataset about famous aphorisms with 186k Chinese-&gt;English sentence pairs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Code generation for Information Technology Tasks in YAML through Large Language Models. (arXiv:2305.02783v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02783">
<div class="article-summary-box-inner">
<span><p>The recent improvement in code generation capabilities due to the use of
large language models has mainly benefited general purpose programming
languages. Domain specific languages, such as the ones used for IT Automation,
have received far less attention, despite involving many active developers and
being an essential component of modern cloud platforms. This work focuses on
the generation of Ansible-YAML, a widely used markup language for IT
Automation. We present Ansible Wisdom, a natural-language to Ansible-YAML code
generation tool, aimed at improving IT automation productivity. Ansible Wisdom
is a transformer-based model, extended by training with a new dataset
containing Ansible-YAML. We also develop two novel performance metrics for YAML
and Ansible to capture the specific characteristics of this domain. Results
show that Ansible Wisdom can accurately generate Ansible script from natural
language prompts with performance comparable or better than existing state of
the art code generation models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BranchNorm: Robustly Scaling Extremely Deep Transformers. (arXiv:2305.02790v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02790">
<div class="article-summary-box-inner">
<span><p>Recently, DeepNorm scales Transformers into extremely deep (i.e., 1000
layers) and reveals the promising potential of deep scaling. To stabilize the
training of deep models, DeepNorm (Wang et al., 2022) attempts to constrain the
model update to a constant value. Although applying such a constraint can
benefit the early stage of model training, it may lead to undertrained models
during the whole training procedure. In this paper, we propose BranchNorm,
which dynamically rescales the non-residual branch of Transformer in accordance
with the training period. BranchNorm not only theoretically stabilizes the
training with smooth gradient norms at the early stage, but also encourages
better convergence in the subsequent training stage. Experiment results on
multiple translation tasks demonstrate that BranchNorm achieves a better
trade-off between training stability and converge performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Elephant in the Room: Analyzing the Presence of Big Tech in Natural Language Processing Research. (arXiv:2305.02797v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02797">
<div class="article-summary-box-inner">
<span><p>Recent advances in deep learning methods for natural language processing
(NLP) have created new business opportunities and made NLP research critical
for industry development. As one of the big players in the field of NLP,
together with governments and universities, it is important to track the
influence of industry on research. In this study, we seek to quantify and
characterize industry presence in the NLP community over time. Using a corpus
with comprehensive metadata of 78,187 NLP publications and 701 resumes of NLP
publication authors, we explore the industry presence in the field since the
early 90s. We find that industry presence among NLP authors has been steady
before a steep increase over the past five years (180% growth from 2017 to
2022). A few companies account for most of the publications and provide funding
to academic researchers through grants and internships. Our study shows that
the presence and impact of the industry on natural language processing research
are significant and fast-growing. This work calls for increased transparency of
industry influence in the field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpretable Sentence Representation with Variational Autoencoders and Attention. (arXiv:2305.02810v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02810">
<div class="article-summary-box-inner">
<span><p>In this thesis, we develop methods to enhance the interpretability of recent
representation learning techniques in natural language processing (NLP) while
accounting for the unavailability of annotated data. We choose to leverage
Variational Autoencoders (VAEs) due to their efficiency in relating
observations to latent generative factors and their effectiveness in
data-efficient learning and interpretable representation learning. As a first
contribution, we identify and remove unnecessary components in the functioning
scheme of semi-supervised VAEs making them faster, smaller and easier to
design. Our second and main contribution is to use VAEs and Transformers to
build two models with inductive bias to separate information in latent
representations into understandable concepts without annotated data. The first
model, Attention-Driven VAE (ADVAE), is able to separately represent and
control information about syntactic roles in sentences. The second model,
QKVAE, uses separate latent variables to form keys and values for its
Transformer decoder and is able to separate syntactic and semantic information
in its neural representations. In transfer experiments, QKVAE has competitive
performance compared to supervised models and equivalent performance to a
supervised model using 50K annotated samples. Additionally, QKVAE displays
improved syntactic role disentanglement capabilities compared to ADVAE.
Overall, we demonstrate that it is possible to enhance the interpretability of
state-of-the-art deep learning architectures for language modeling with
unannotated data in situations where text data is abundant but annotations are
scarce.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Space Grounded Weighted Decoding for Multi-Attribute Controllable Dialogue Generation. (arXiv:2305.02820v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02820">
<div class="article-summary-box-inner">
<span><p>Controlling chatbot utterance generation with multiple attributes such as
personalities, emotions and dialogue acts is a practically useful but
under-studied problem. We propose a novel controllable generation framework
called DASC that possesses strong controllability with weighted decoding
paradigm, while improving generation quality with the grounding in an attribute
semantics space. Generation with multiple attributes is then intuitively
implemented with an interpolation of multiple attribute embeddings. Experiments
show that DASC can achieve state-of-the-art control accuracy in 3-aspect
controllable generation tasks while also producing interesting and reasonably
sensible responses, even if in an out-of-distribution robustness test.
Visualization of the meaningful representations learned in the attribute
semantic space also supports its effectiveness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ReMask: A Robust Information-Masking Approach for Domain Counterfactual Generation. (arXiv:2305.02858v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02858">
<div class="article-summary-box-inner">
<span><p>Domain shift is a big challenge in NLP, thus, many approaches resort to
learning domain-invariant features to mitigate the inference phase domain
shift. Such methods, however, fail to leverage the domain-specific nuances
relevant to the task at hand. To avoid such drawbacks, domain counterfactual
generation aims to transform a text from the source domain to a given target
domain. However, due to the limited availability of data, such frequency-based
methods often miss and lead to some valid and spurious domain-token
associations. Hence, we employ a three-step domain obfuscation approach that
involves frequency and attention norm-based masking, to mask domain-specific
cues, and unmasking to regain the domain generic context. Our experiments
empirically show that the counterfactual samples sourced from our masked text
lead to improved domain transfer on 10 out of 12 domain sentiment
classification settings, with an average of 2% accuracy improvement over the
state-of-the-art for unsupervised domain adaptation (UDA). Further, our model
outperforms the state-of-the-art by achieving 1.4% average accuracy improvement
in the adversarial domain adaptation (ADA) setting. Moreover, our model also
shows its domain adaptation efficacy on a large multi-domain intent
classification dataset where it attains state-of-the-art results. We release
the codes publicly at \url{https://github.com/declare-lab/remask}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CausalAPM: Generalizable Literal Disentanglement for NLU Debiasing. (arXiv:2305.02865v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02865">
<div class="article-summary-box-inner">
<span><p>Dataset bias, i.e., the over-reliance on dataset-specific literal heuristics,
is getting increasing attention for its detrimental effect on the
generalization ability of NLU models. Existing works focus on eliminating
dataset bias by down-weighting problematic data in the training process, which
induce the omission of valid feature information while mitigating bias. In this
work, We analyze the causes of dataset bias from the perspective of causal
inference and propose CausalAPM, a generalizable literal disentangling
framework to ameliorate the bias problem from feature granularity. The proposed
approach projects literal and semantic information into independent feature
subspaces, and constrains the involvement of literal information in subsequent
predictions. Extensive experiments on three NLP benchmarks (MNLI, FEVER, and
QQP) demonstrate that our proposed framework significantly improves the OOD
generalization performance while maintaining ID performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">2x Faster Language Model Pre-training via Masked Structural Growth. (arXiv:2305.02869v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02869">
<div class="article-summary-box-inner">
<span><p>Acceleration of large language model pre-training is a critical issue in
present NLP research. In this paper, we focus on speeding up pre-training by
progressively growing from a small Transformer structure to a large one. There
are two main research problems related to progressive growth: growth schedule
and growth operator. For growth schedule, existing work has explored
multi-stage expansion of depth and feedforward layers. However, the impact of
each dimension on the schedule's efficiency is still an open question. For
growth operator, existing work relies on the initialization of new weights to
inherit knowledge, and achieve only non-strict function preservation, limiting
further optimization of training dynamics. To address these issues, we propose
Masked Structural Growth (MSG), including growth schedules involving all
possible dimensions and strictly function-preserving growth operators that is
independent of the initialization of new weights. Experiments show that MSG is
significantly faster than related work: we achieve a speed-up of 80% for
Bert-base and 120% for Bert-large pre-training. Moreover, MSG is able to
improve fine-tuning performances at the same time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An automatically discovered chain-of-thought prompt generalizes to novel models and datasets. (arXiv:2305.02897v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02897">
<div class="article-summary-box-inner">
<span><p>Emergent chain-of-thought (CoT) reasoning capabilities promise to improve
performance and explainability of large language models (LLMs). However,
uncertainties remain about how prompting strategies formulated for previous
model generations generalize to new model generations and different datasets.
In this small-scale study we compare the performance of a range of zero-shot
prompts for inducing CoT reasoning across six recently released LLMs
(davinci-002, davinci-003, GPT-3.5-turbo, GPT-4, Flan-T5-xxl and Cohere
command-xlarge) on a mixture of six question-answering datasets, including
datasets from scientific and medical domains. We find that a CoT prompt that
was previously discovered through automated prompt discovery shows robust
performance across experimental conditions and produces best results when
applied to the state-of-the-art model GPT-4.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-end spoken language understanding using joint CTC loss and self-supervised, pretrained acoustic encoders. (arXiv:2305.02937v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02937">
<div class="article-summary-box-inner">
<span><p>It is challenging to extract semantic meanings directly from audio signals in
spoken language understanding (SLU), due to the lack of textual information.
Popular end-to-end (E2E) SLU models utilize sequence-to-sequence automatic
speech recognition (ASR) models to extract textual embeddings as input to infer
semantics, which, however, require computationally expensive auto-regressive
decoding. In this work, we leverage self-supervised acoustic encoders
fine-tuned with Connectionist Temporal Classification (CTC) to extract textual
embeddings and use joint CTC and SLU losses for utterance-level SLU tasks.
Experiments show that our model achieves 4% absolute improvement over the the
state-of-the-art (SOTA) dialogue act classification model on the DSTC2 dataset
and 1.3% absolute improvement over the SOTA SLU model on the SLURP dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SemEval-2023 Task 7: Multi-Evidence Natural Language Inference for Clinical Trial Data. (arXiv:2305.02993v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02993">
<div class="article-summary-box-inner">
<span><p>This paper describes the results of SemEval 2023 task 7 -- Multi-Evidence
Natural Language Inference for Clinical Trial Data (NLI4CT) -- consisting of 2
tasks, a Natural Language Inference (NLI) task, and an evidence selection task
on clinical trial data. The proposed challenges require multi-hop biomedical
and numerical reasoning, which are of significant importance to the development
of systems capable of large-scale interpretation and retrieval of medical
evidence, to provide personalized evidence-based care.
</p>
<p>Task 1, the entailment task, received 643 submissions from 40 participants,
and Task 2, the evidence selection task, received 364 submissions from 23
participants. The tasks are challenging, with the majority of submitted systems
failing to significantly outperform the majority class baseline on the
entailment task, and we observe significantly better performance on the
evidence selection task than on the entailment task. Increasing the number of
model parameters leads to a direct increase in performance, far more
significant than the effect of biomedical pre-training. Future works could
explore the limitations of large models for generalization and numerical
inference, and investigate methods to augment clinical datasets to allow for
more rigorous testing and to facilitate fine-tuning.
</p>
<p>We envisage that the dataset, models, and results of this task will be useful
to the biomedical NLI and evidence retrieval communities. The dataset,
competition leaderboard, and website are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the nonlinear correlation of ML performance between data subpopulations. (arXiv:2305.02995v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02995">
<div class="article-summary-box-inner">
<span><p>Understanding the performance of machine learning (ML) models across diverse
data distributions is critically important for reliable applications. Despite
recent empirical studies positing a near-perfect linear correlation between
in-distribution (ID) and out-of-distribution (OOD) accuracies, we empirically
demonstrate that this correlation is more nuanced under subpopulation shifts.
Through rigorous experimentation and analysis across a variety of datasets,
models, and training epochs, we demonstrate that OOD performance often has a
nonlinear correlation with ID performance in subpopulation shifts. Our
findings, which contrast previous studies that have posited a linear
correlation in model performance during distribution shifts, reveal a "moon
shape" correlation (parabolic uptrend curve) between the test performance on
the majority subpopulation and the minority subpopulation. This non-trivial
nonlinear correlation holds across model architectures, hyperparameters,
training durations, and the imbalance between subpopulations. Furthermore, we
found that the nonlinearity of this "moon shape" is causally influenced by the
degree of spurious correlations in the training data. Our controlled
experiments show that stronger spurious correlation in the training data
creates more nonlinear performance correlation. We provide complementary
experimental and theoretical analyses for this phenomenon, and discuss its
implications for ML reliability and fairness. Our work highlights the
importance of understanding the nonlinear effects of model improvement on
performance in different subpopulations, and has the potential to inform the
development of more equitable and responsible machine learning models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Selection of Anchor Items for CUR-based k-NN search with Cross-Encoders. (arXiv:2305.02996v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02996">
<div class="article-summary-box-inner">
<span><p>Cross-encoder models, which jointly encode and score a query-item pair, are
typically prohibitively expensive for k-nearest neighbor search. Consequently,
k-NN search is performed not with a cross-encoder, but with a heuristic
retrieve (e.g., using BM25 or dual-encoder) and re-rank approach. Recent work
proposes ANNCUR (Yadav et al., 2022) which uses CUR matrix factorization to
produce an embedding space for efficient vector-based search that directly
approximates the cross-encoder without the need for dual-encoders. ANNCUR
defines this shared query-item embedding space by scoring the test query
against anchor items which are sampled uniformly at random. While this
minimizes average approximation error over all items, unsuitably high
approximation error on top-k items remains and leads to poor recall of top-k
(and especially top-1) items. Increasing the number of anchor items is a
straightforward way of improving the approximation error and hence k-NN recall
of ANNCUR but at the cost of increased inference latency. In this paper, we
propose a new method for adaptively choosing anchor items that minimizes the
approximation error for the practically important top-k neighbors for a query
with minimal computational overhead. Our proposed method incrementally selects
a suitable set of anchor items for a given test query over several rounds,
using anchors chosen in previous rounds to inform selection of more anchor
items. Empirically, our method consistently improves k-NN recall as compared to
both ANNCUR and the widely-used dual-encoder-based retrieve-and-rerank
approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NatCS: Eliciting Natural Customer Support Dialogues. (arXiv:2305.03007v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03007">
<div class="article-summary-box-inner">
<span><p>Despite growing interest in applications based on natural customer support
conversations, there exist remarkably few publicly available datasets that
reflect the expected characteristics of conversations in these settings.
Existing task-oriented dialogue datasets, which were collected to benchmark
dialogue systems mainly in written human-to-bot settings, are not
representative of real customer support conversations and do not provide
realistic benchmarks for systems that are applied to natural data. To address
this gap, we introduce NatCS, a multi-domain collection of spoken customer
service conversations. We describe our process for collecting synthetic
conversations between customers and agents based on natural language phenomena
observed in real conversations. Compared to previous dialogue datasets, the
conversations collected with our approach are more representative of real
human-to-human conversations along multiple metrics. Finally, we demonstrate
potential uses of NatCS, including dialogue act classification and intent
induction from conversations as potential applications, showing that dialogue
act annotations in NatCS provide more effective training data for modeling real
conversations compared to existing synthetic written datasets. We publicly
release NatCS to facilitate research in natural dialog systems
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentence Embedding Leaks More Information than You Expect: Generative Embedding Inversion Attack to Recover the Whole Sentence. (arXiv:2305.03010v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03010">
<div class="article-summary-box-inner">
<span><p>Sentence-level representations are beneficial for various natural language
processing tasks. It is commonly believed that vector representations can
capture rich linguistic properties. Currently, large language models (LMs)
achieve state-of-the-art performance on sentence embedding. However, some
recent works suggest that vector representations from LMs can cause information
leakage. In this work, we further investigate the information leakage issue and
propose a generative embedding inversion attack (GEIA) that aims to reconstruct
input sequences based only on their sentence embeddings. Given the black-box
access to a language model, we treat sentence embeddings as initial tokens'
representations and train or fine-tune a powerful decoder model to decode the
whole sequences directly. We conduct extensive experiments to demonstrate that
our generative inversion attack outperforms previous embedding inversion
attacks in classification metrics and generates coherent and contextually
similar sentences as the original inputs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Panda LLM: Training Data and Evaluation for Open-Sourced Chinese Instruction-Following Large Language Models. (arXiv:2305.03025v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03025">
<div class="article-summary-box-inner">
<span><p>This project focuses on enhancing open-source large language models through
instruction-tuning and providing comprehensive evaluations of their
performance. We explore how various training data factors, such as quantity,
quality, and linguistic distribution, influence the performance of
instruction-tuned models trained on publicly accessible high-quality
instruction datasets for both English and Chinese languages. Our goal is to
supplement evaluation with quantitative analyses, providing valuable insights
for the continued advancement of open-source chat models. Our model, data, and
code are publicly available for others to use and build upon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What changes when you randomly choose BPE merge operations? Not much. (arXiv:2305.03029v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03029">
<div class="article-summary-box-inner">
<span><p>We introduce three simple randomized variants of byte pair encoding (BPE) and
explore whether randomizing the selection of merge operations substantially
affects a downstream machine translation task. We focus on translation into
morphologically rich languages, hypothesizing that this task may show
sensitivity to the method of choosing subwords. Analysis using a Bayesian
linear model indicates that two of the variants perform nearly
indistinguishably compared to standard BPE while the other degrades performance
less than we anticipated. We conclude that although standard BPE is widely
used, there exists an interesting universe of potential variations on it worth
investigating. Our code is available at: https://github.com/bltlab/random-bpe.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision. (arXiv:2305.03047v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03047">
<div class="article-summary-box-inner">
<span><p>Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised
fine-tuning (SFT) with human annotations and reinforcement learning from human
feedback (RLHF) to align the output of large language models (LLMs) with human
intentions, ensuring they are helpful, ethical, and reliable. However, this
dependence can significantly constrain the true potential of AI-assistant
agents due to the high cost of obtaining human supervision and the related
issues on quality, reliability, diversity, self-consistency, and undesirable
biases. To address these challenges, we propose a novel approach called
SELF-ALIGN, which combines principle-driven reasoning and the generative power
of LLMs for the self-alignment of AI agents with minimal human supervision. Our
approach encompasses four stages: first, we use an LLM to generate synthetic
prompts, and a topic-guided method to augment the prompt diversity; second, we
use a small set of human-written principles for AI models to follow, and guide
the LLM through in-context learning from demonstrations (of principles
application) to produce helpful, ethical, and reliable responses to user's
queries; third, we fine-tune the original LLM with the high-quality
self-aligned responses so that the resulting model can generate desirable
responses for each query directly without the principle set and the
demonstrations anymore; and finally, we offer a refinement step to address the
issues of overly-brief or indirect responses. Applying SELF-ALIGN to the
LLaMA-65b base language model, we develop an AI assistant named Dromedary. With
fewer than 300 lines of human annotations (including &lt; 200 seed prompts, 16
generic principles, and 5 exemplars for in-context learning). Dromedary
significantly surpasses the performance of several state-of-the-art AI systems,
including Text-Davinci-003 and Alpaca, on benchmark datasets with various
settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Personalize Segment Anything Model with One Shot. (arXiv:2305.03048v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03048">
<div class="article-summary-box-inner">
<span><p>Driven by large-data pre-training, Segment Anything Model (SAM) has been
demonstrated as a powerful and promptable framework, revolutionizing the
segmentation models. Despite the generality, customizing SAM for specific
visual concepts without man-powered prompting is under explored, e.g.,
automatically segmenting your pet dog in different images. In this paper, we
propose a training-free Personalization approach for SAM, termed as PerSAM.
Given only a single image with a reference mask, PerSAM first localizes the
target concept by a location prior, and segments it within other images or
videos via three techniques: target-guided attention, target-semantic
prompting, and cascaded post-refinement. In this way, we effectively adapt SAM
for private use without any training. To further alleviate the mask ambiguity,
we present an efficient one-shot fine-tuning variant, PerSAM-F. Freezing the
entire SAM, we introduce two learnable weights for multi-scale masks, only
training 2 parameters within 10 seconds for improved performance. To
demonstrate our efficacy, we construct a new segmentation dataset, PerSeg, for
personalized evaluation, and test our methods on video object segmentation with
competitive performance. Besides, our approach can also enhance DreamBooth to
personalize Stable Diffusion for text-to-image generation, which discards the
background disturbance for better target appearance learning. Code is released
at https://github.com/ZrrSkywalker/Personalize-SAM
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QNLP in Practice: Running Compositional Models of Meaning on a Quantum Computer. (arXiv:2102.12846v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12846">
<div class="article-summary-box-inner">
<span><p>Quantum Natural Language Processing (QNLP) deals with the design and
implementation of NLP models intended to be run on quantum hardware. In this
paper, we present results on the first NLP experiments conducted on Noisy
Intermediate-Scale Quantum (NISQ) computers for datasets of size greater than
100 sentences. Exploiting the formal similarity of the compositional model of
meaning by Coecke, Sadrzadeh and Clark (2010) with quantum theory, we create
representations for sentences that have a natural mapping to quantum circuits.
We use these representations to implement and successfully train NLP models
that solve simple sentence classification tasks on quantum hardware. We conduct
quantum simulations that compare the syntax-sensitive model of Coecke et al.
with two baselines that use less or no syntax; specifically, we implement the
quantum analogues of a "bag-of-words" model, where syntax is not taken into
account at all, and of a word-sequence model, where only word order is
respected. We demonstrate that all models converge smoothly both in simulations
and when run on quantum hardware, and that the results are the expected ones
based on the nature of the tasks and the datasets used. Another important goal
of this paper is to describe in a way accessible to AI and NLP researchers the
main principles, process and challenges of experiments on quantum hardware. Our
aim in doing this is to take the first small steps in this unexplored research
territory and pave the way for practical Quantum Natural Language Processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ECOLA: Enhanced Temporal Knowledge Embeddings with Contextualized Language Representations. (arXiv:2203.09590v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.09590">
<div class="article-summary-box-inner">
<span><p>Since conventional knowledge embedding models cannot take full advantage of
the abundant textual information, there have been extensive research efforts in
enhancing knowledge embedding using texts. However, existing enhancement
approaches cannot apply to temporal knowledge graphs (tKGs), which contain
time-dependent event knowledge with complex temporal dynamics. Specifically,
existing enhancement approaches often assume knowledge embedding is
time-independent. In contrast, the entity embedding in tKG models usually
evolves, which poses the challenge of aligning temporally relevant texts with
entities. To this end, we propose to study enhancing temporal knowledge
embedding with textual data in this paper. As an approach to this task, we
propose Enhanced Temporal Knowledge Embeddings with Contextualized Language
Representations (ECOLA), which takes the temporal aspect into account and
injects textual information into temporal knowledge embedding. To evaluate
ECOLA, we introduce three new datasets for training and evaluating ECOLA.
Extensive experiments show that ECOLA significantly enhances temporal KG
embedding models with up to 287% relative improvements regarding Hits@1 on the
link prediction task. The code and models are publicly available on
https://anonymous.4open.science/r/ECOLA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MiniDisc: Minimal Distillation Schedule for Language Model Compression. (arXiv:2205.14570v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.14570">
<div class="article-summary-box-inner">
<span><p>Recent studies have uncovered that language model distillation is less
effective when facing a large capacity gap between the teacher and the student,
and introduced teacher assistant-based distillation to bridge the gap. As a
connection, the scale and the performance of the teacher assistant is of vital
importance to bring the knowledge from the teacher to the student. However,
existing teacher assistant-based methods require maximally many trials before
scheduling an optimal teacher assistant. To this end, we propose a minimal
distillation schedule (MiniDisc) for scheduling the optimal teacher assistant
in minimally one trial. In particular, motivated by the finding that the
performance of the student is positively correlated to the scale-performance
tradeoff of the teacher assistant, MiniDisc is designed with a
$\lambda$-tradeoff to measure the optimality of the teacher assistant without
trial distillation to the student. MiniDisc then can schedule the optimal
teacher assistant with the best $\lambda$-tradeoff in a sandwich framework.
MiniDisc is evaluated with an extensive set of experiments on GLUE.
Experimental results demonstrate the improved efficiency our MiniDisc compared
to several state-of-the-art baselines. We further apply MiniDisc to a language
model with billions of parameters and show its scalability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modular and On-demand Bias Mitigation with Attribute-Removal Subnetworks. (arXiv:2205.15171v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.15171">
<div class="article-summary-box-inner">
<span><p>Societal biases are reflected in large pre-trained language models and their
fine-tuned versions on downstream tasks. Common in-processing bias mitigation
approaches, such as adversarial training and mutual information removal,
introduce additional optimization criteria, and update the model to reach a new
debiased state. However, in practice, end-users and practitioners might prefer
to switch back to the original model, or apply debiasing only on a specific
subset of protected attributes. To enable this, we propose a novel modular bias
mitigation approach, consisting of stand-alone highly sparse debiasing
subnetworks, where each debiasing module can be integrated into the core model
on-demand at inference time. Our approach draws from the concept of \emph{diff}
pruning, and proposes a novel training regime adaptable to various
representation disentanglement optimizations. We conduct experiments on three
classification tasks with gender, race, and age as protected attributes. The
results show that our modular approach, while maintaining task performance,
improves (or at least remains on-par with) the effectiveness of bias mitigation
in comparison with baseline finetuning. Particularly on a two-attribute
dataset, our approach with separately learned debiasing subnetworks shows
effective utilization of either or both the subnetworks for selective bias
mitigation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-shot Incremental Event Detection. (arXiv:2209.01979v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.01979">
<div class="article-summary-box-inner">
<span><p>Event detection tasks can enable the quick detection of events from texts and
provide powerful support for downstream natural language processing tasks. Most
such methods can only detect a fixed set of predefined event classes. To extend
them to detect a new class without losing the ability to detect old classes
requires costly retraining of the model from scratch. Incremental learning can
effectively solve this problem, but it requires abundant data of new classes.
In practice, however, the lack of high-quality labeled data of new event
classes makes it difficult to obtain enough data for model training. To address
the above mentioned issues, we define a new task, few-shot incremental event
detection, which focuses on learning to detect a new event class with limited
data, while retaining the ability to detect old classes to the extent possible.
We created a benchmark dataset IFSED for the few-shot incremental event
detection task based on FewEvent and propose two benchmarks, IFSED-K and
IFSED-KP. Experimental results show that our approach has a higher F1-score
than baseline methods and is more stable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is It Worth the (Environmental) Cost? Limited Evidence for Temporal Adaptation via Continuous Training. (arXiv:2210.07365v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07365">
<div class="article-summary-box-inner">
<span><p>Language is constantly changing and evolving, leaving language models to
become quickly outdated. Consequently, we should continuously update our models
with new data to expose them to new events and facts. However, that requires
additional computing, which means new carbon emissions. Do any measurable
benefits justify this cost? This paper looks for empirical evidence to support
continuous training. We reproduce existing benchmarks and extend them to
include additional time periods, models, and tasks. Our results show that the
downstream task performance of temporally adapted English models for social
media data do not improve over time. Pretrained models without temporal
adaptation are actually significantly more effective and efficient. However, we
also note a lack of suitable temporal benchmarks. Our findings invite a
critical reflection on when and how to temporally adapt language models,
accounting for sustainability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Solving Math Word Problems via Cooperative Reasoning induced Language Models. (arXiv:2210.16257v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.16257">
<div class="article-summary-box-inner">
<span><p>Large-scale pre-trained language models (PLMs) bring new opportunities to
challenging problems, especially those that need high-level intelligence, such
as the math word problem (MWPs). However, directly applying existing PLMs to
MWPs can fail as the generation process lacks sufficient supervision and thus
lacks fast adaptivity as humans. We notice that human reasoning has a dual
reasoning framework that consists of an immediate reaction system (system 1)
and a delicate reasoning system (system 2), where the entire reasoning is
determined by their interaction. This inspires us to develop a cooperative
reasoning-induced PLM for solving MWPs, called Cooperative Reasoning (CoRe),
resulting in a human-like reasoning architecture with system 1 as the generator
and system 2 as the verifier. In our approach, the generator is responsible for
generating reasoning paths, and the verifiers are used to supervise the
evaluation in order to obtain reliable feedback for the generator. We evaluate
our CoRe framework on several mathematical reasoning datasets and achieve
decent improvement over state-of-the-art methods, up to 9.6% increase over best
baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Summary-Oriented Vision Modeling for Multimodal Abstractive Summarization. (arXiv:2212.07672v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.07672">
<div class="article-summary-box-inner">
<span><p>Multimodal abstractive summarization (MAS) aims to produce a concise summary
given the multimodal data (text and vision). Existing studies mainly focus on
how to effectively use the visual features from the perspective of an article,
having achieved impressive success on the high-resource English dataset.
However, less attention has been paid to the visual features from the
perspective of the summary, which may limit the model performance, especially
in the low- and zero-resource scenarios. In this paper, we propose to improve
the summary quality through summary-oriented visual features. To this end, we
devise two auxiliary tasks including vision to summary task and masked image
modeling task. Together with the main summarization task, we optimize the MAS
model via the training objectives of all these tasks. By these means, the MAS
model can be enhanced by capturing the summary-oriented visual features,
thereby yielding more accurate summaries. Experiments on 44 languages, covering
mid-high-, low-, and zero-resource scenarios, verify the effectiveness and
superiority of the proposed approach, which achieves state-of-the-art
performance under all scenarios. Additionally, we will contribute a large-scale
multilingual multimodal abstractive summarization (MM-Sum) dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation. (arXiv:2212.09246v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09246">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models, despite their rapid advancements powered by
scale, still fall short of robust commonsense capabilities. And yet, scale
appears to be the winning recipe; after all, the largest models seem to have
acquired the largest amount of commonsense capabilities. Or is it?
</p>
<p>In this paper, we investigate the possibility of a seemingly impossible
match: can smaller language models with dismal commonsense capabilities (i.e.,
GPT-2), ever win over models that are orders of magnitude larger and better
(i.e., GPT-3), if the smaller models are powered with novel commonsense
distillation algorithms? The key intellectual question we ask here is whether
it is possible, if at all, to design a learning algorithm that does not benefit
from scale, yet leads to a competitive level of commonsense acquisition. In
this work, we study the generative models of commonsense knowledge, focusing on
the task of generating generics, statements of commonsense facts about everyday
concepts, e.g., birds can fly.
</p>
<p>We introduce a novel commonsense distillation framework, I2D2, that loosely
follows the Symbolic Knowledge Distillation of West et al. but breaks the
dependence on the extreme-scale models as the teacher model by two innovations:
(1) the novel adaptation of NeuroLogic Decoding to enhance the generation
quality of the weak, off-the-shelf language models, and (2) self-imitation
learning to iteratively learn from the model's own enhanced commonsense
acquisition capabilities. Empirical results suggest that scale is not the only
way, as novel algorithms can be a promising alternative. Moreover, our study
leads to a new corpus of generics, Gen-A-Tomic, that is of the largest and
highest quality available to date.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09597">
<div class="article-summary-box-inner">
<span><p>Reasoning, as an essential ability for complex problem-solving, can provide
back-end support for various real-world applications, such as medical
diagnosis, negotiation, etc. This paper provides a comprehensive survey of
cutting-edge research on reasoning with language model prompting. We introduce
research works with comparisons and summaries and provide systematic resources
to help beginners. We also discuss the potential reasons for emerging such
reasoning abilities and highlight future research directions. Resources are
available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated
periodically).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SeqDiffuSeq: Text Diffusion with Encoder-Decoder Transformers. (arXiv:2212.10325v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10325">
<div class="article-summary-box-inner">
<span><p>Diffusion model, a new generative modelling paradigm, has achieved great
success in image, audio, and video generation. However, considering the
discrete categorical nature of text, it is not trivial to extend continuous
diffusion models to natural language, and text diffusion models are less
studied. Sequence-to-sequence text generation is one of the essential natural
language processing topics. In this work, we apply diffusion models to approach
sequence-to-sequence text generation, and explore whether the superiority
generation performance of diffusion model can transfer to natural language
domain. We propose SeqDiffuSeq, a text diffusion model for sequence-to-sequence
generation. SeqDiffuSeq uses an encoder-decoder Transformers architecture to
model denoising function. In order to improve generation quality, SeqDiffuSeq
combines the self-conditioning technique and a newly proposed adaptive noise
schedule technique. The adaptive noise schedule has the difficulty of denoising
evenly distributed across time steps, and considers exclusive noise schedules
for tokens at different positional order. Experiment results illustrate the
good performance on sequence-to-sequence generation in terms of text quality
and inference time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning. (arXiv:2301.11916v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.11916">
<div class="article-summary-box-inner">
<span><p>In recent years, pre-trained large language models have demonstrated
remarkable efficiency in achieving an inference-time few-shot learning
capability known as in-context learning. However, existing literature has
highlighted the sensitivity of this capability to the selection of few-shot
demonstrations. The underlying mechanisms by which this capability arises from
regular language model pretraining objectives remain poorly understood. In this
study, we aim to examine the in-context learning phenomenon through a Bayesian
lens, viewing large language models as topic models that implicitly infer
task-related information from demonstrations. On this premise, we propose an
algorithm for selecting optimal demonstrations from a set of annotated data and
demonstrate a significant 12.5% improvement relative to the random selection
baseline, averaged over eight GPT2 and GPT3 models on eight different
real-world text classification datasets. Our empirical findings support our
hypothesis that large language models implicitly infer a latent concept
variable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Few-Shot Generalization by Exploring and Exploiting Auxiliary Data. (arXiv:2302.00674v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00674">
<div class="article-summary-box-inner">
<span><p>Few-shot learning is valuable in many real-world applications, but learning a
generalizable model without overfitting to the few labeled datapoints is
challenging. In this work, we focus on Few-shot Learning with Auxiliary Data
(FLAD), a training paradigm that assumes access to auxiliary data during
few-shot learning in hopes of improving generalization. Previous works have
proposed automated methods for mixing auxiliary and target data, but these
methods typically scale linearly (or worse) with the number of auxiliary
datasets, limiting their practicality. In this work we relate FLAD to the
explore-exploit dilemma that is central to the multi-armed bandit setting and
derive algorithms whose computational complexity is independent of the number
of auxiliary datasets, allowing us to scale to 100x more auxiliary datasets
than prior methods. We propose two algorithms -- EXP3-FLAD and UCB1-FLAD -- and
compare them with prior FLAD methods that either explore or exploit, finding
that the combination of exploration and exploitation is crucial. Through
extensive experimentation we find that our methods outperform all pre-existing
FLAD methods by 4% and lead to the first 3 billion parameter language models
that outperform the 175 billion parameter GPT-3. Overall, our work suggests
that the discovery of better, more efficient mixing strategies for FLAD may
provide a viable path towards substantially improving generalization in
few-shot learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Large Language Models. (arXiv:2303.18223v9 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.18223">
<div class="article-summary-box-inner">
<span><p>Language is essentially a complex, intricate system of human expressions
governed by grammatical rules. It poses a significant challenge to develop
capable AI algorithms for comprehending and grasping a language. As a major
approach, language modeling has been widely studied for language understanding
and generation in the past two decades, evolving from statistical language
models to neural language models. Recently, pre-trained language models (PLMs)
have been proposed by pre-training Transformer models over large-scale corpora,
showing strong capabilities in solving various NLP tasks. Since researchers
have found that model scaling can lead to performance improvement, they further
study the scaling effect by increasing the model size to an even larger size.
Interestingly, when the parameter scale exceeds a certain level, these enlarged
language models not only achieve a significant performance improvement but also
show some special abilities that are not present in small-scale language
models. To discriminate the difference in parameter scale, the research
community has coined the term large language models (LLM) for the PLMs of
significant size. Recently, the research on LLMs has been largely advanced by
both academia and industry, and a remarkable progress is the launch of ChatGPT,
which has attracted widespread attention from society. The technical evolution
of LLMs has been making an important impact on the entire AI community, which
would revolutionize the way how we develop and use AI algorithms. In this
survey, we review the recent advances of LLMs by introducing the background,
key findings, and mainstream techniques. In particular, we focus on four major
aspects of LLMs, namely pre-training, adaptation tuning, utilization, and
capacity evaluation. Besides, we also summarize the available resources for
developing LLMs and discuss the remaining issues for future directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Story Discovery from Continuous News Streams via Scalable Thematic Embedding. (arXiv:2304.04099v3 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.04099">
<div class="article-summary-box-inner">
<span><p>Unsupervised discovery of stories with correlated news articles in real-time
helps people digest massive news streams without expensive human annotations. A
common approach of the existing studies for unsupervised online story discovery
is to represent news articles with symbolic- or graph-based embedding and
incrementally cluster them into stories. Recent large language models are
expected to improve the embedding further, but a straightforward adoption of
the models by indiscriminately encoding all information in articles is
ineffective to deal with text-rich and evolving news streams. In this work, we
propose a novel thematic embedding with an off-the-shelf pretrained sentence
encoder to dynamically represent articles and stories by considering their
shared temporal themes. To realize the idea for unsupervised online story
discovery, a scalable framework USTORY is introduced with two main techniques,
theme- and time-aware dynamic embedding and novelty-aware adaptive clustering,
fueled by lightweight story summaries. A thorough evaluation with real news
data sets demonstrates that USTORY achieves higher story discovery performances
than baselines while being robust and scalable to various streaming settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The language of sounds unheard: Exploring musical timbre semantics of large language models. (arXiv:2304.07830v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.07830">
<div class="article-summary-box-inner">
<span><p>Semantic dimensions of sound have been playing a central role in
understanding the nature of auditory sensory experience as well as the broader
relation between perception, language, and meaning. Accordingly, and given the
recent proliferation of large language models (LLMs), here we asked whether
such models exhibit an organisation of perceptual semantics similar to those
observed in humans. Specifically, we prompted ChatGPT, a chatbot based on a
state-of-the-art LLM, to rate musical instrument sounds on a set of 20 semantic
scales. We elicited multiple responses in separate chats, analogous to having
multiple human raters. ChatGPT generated semantic profiles that only partially
correlated with human ratings, yet showed robust agreement along well-known
psychophysical dimensions of musical sounds such as brightness (bright-dark)
and pitch height (deep-high). Exploratory factor analysis suggested the same
dimensionality but different spatial configuration of a latent factor space
between the chatbot and human ratings. Unexpectedly, the chatbot showed degrees
of internal variability that were comparable in magnitude to that of human
ratings. Our work highlights the potential of LLMs to capture salient
dimensions of human sensory experience.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers. (arXiv:2304.09116v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.09116">
<div class="article-summary-box-inner">
<span><p>Scaling text-to-speech (TTS) to large-scale, multi-speaker, and in-the-wild
datasets is important to capture the diversity in human speech such as speaker
identities, prosodies, and styles (e.g., singing). Current large TTS systems
usually quantize speech into discrete tokens and use language models to
generate these tokens one by one, which suffer from unstable prosody, word
skipping/repeating issue, and poor voice quality. In this paper, we develop
NaturalSpeech 2, a TTS system that leverages a neural audio codec with residual
vector quantizers to get the quantized latent vectors and uses a diffusion
model to generate these latent vectors conditioned on text input. To enhance
the zero-shot capability that is important to achieve diverse speech synthesis,
we design a speech prompting mechanism to facilitate in-context learning in the
diffusion model and the duration/pitch predictor. We scale NaturalSpeech 2 to
large-scale datasets with 44K hours of speech and singing data and evaluate its
voice quality on unseen speakers. NaturalSpeech 2 outperforms previous TTS
systems by a large margin in terms of prosody/timbre similarity, robustness,
and voice quality in a zero-shot setting, and performs novel zero-shot singing
synthesis with only a speech prompt. Audio samples are available at
https://speechresearch.github.io/naturalspeech2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DataComp: In search of the next generation of multimodal datasets. (arXiv:2304.14108v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.14108">
<div class="article-summary-box-inner">
<span><p>Large multimodal datasets have been instrumental in recent breakthroughs such
as CLIP, Stable Diffusion, and GPT-4. At the same time, datasets rarely receive
the same research attention as model architectures or training algorithms. To
address this shortcoming in the machine learning ecosystem, we introduce
DataComp, a benchmark where the training code is fixed and researchers innovate
by proposing new training sets. We provide a testbed for dataset experiments
centered around a new candidate pool of 12.8B image-text pairs from Common
Crawl. Participants in our benchmark design new filtering techniques or curate
new data sources and then evaluate their new dataset by running our
standardized CLIP training code and testing on 38 downstream test sets. Our
benchmark consists of multiple scales, with four candidate pool sizes and
associated compute budgets ranging from 12.8M to 12.8B samples seen during
training. This multi-scale design facilitates the study of scaling trends and
makes the benchmark accessible to researchers with varying resources.
</p>
<p>Our baseline experiments show that the DataComp workflow is a promising way
of improving multimodal datasets. We introduce DataComp-1B, a dataset created
by applying a simple filtering algorithm to the 12.8B candidate pool. The
resulting 1.4B subset enables training a CLIP ViT-L/14 from scratch to 79.2%
zero-shot accuracy on ImageNet. Our new ViT-L/14 model outperforms a larger
ViT-g/14 trained on LAION-2B by 0.7 percentage points while requiring 9x less
training compute. We also outperform OpenAI's CLIP ViT-L/14 by 3.7 percentage
points, which is trained with the same compute budget as our model. These gains
highlight the potential for improving model performance by carefully curating
training sets. We view DataComp-1B as only the first step and hope that
DataComp paves the way toward the next generation of multimodal datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpreting Vision and Language Generative Models with Semantic Visual Priors. (arXiv:2304.14986v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.14986">
<div class="article-summary-box-inner">
<span><p>When applied to Image-to-text models, interpretability methods often provide
token-by-token explanations namely, they compute a visual explanation for each
token of the generated sequence. Those explanations are expensive to compute
and unable to comprehensively explain the model's output. Therefore, these
models often require some sort of approximation that eventually leads to
misleading explanations. We develop a framework based on SHAP, that allows for
generating comprehensive, meaningful explanations leveraging the meaning
representation of the output sequence as a whole. Moreover, by exploiting
semantic priors in the visual backbone, we extract an arbitrary number of
features that allows the efficient computation of Shapley values on large-scale
models, generating at the same time highly meaningful visual explanations. We
demonstrate that our method generates semantically more expressive explanations
than traditional methods at a lower compute cost and that it can be generalized
over other explainability methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-shot In-context Learning for Knowledge Base Question Answering. (arXiv:2305.01750v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01750">
<div class="article-summary-box-inner">
<span><p>Question answering over knowledge bases is considered a difficult problem due
to the challenge of generalizing to a wide variety of possible natural language
questions. Additionally, the heterogeneity of knowledge base schema items
between different knowledge bases often necessitates specialized training for
different knowledge base question-answering (KBQA) datasets. To handle
questions over diverse KBQA datasets with a unified training-free framework, we
propose KB-BINDER, which for the first time enables few-shot in-context
learning over KBQA tasks. Firstly, KB-BINDER leverages large language models
like Codex to generate logical forms as the draft for a specific question by
imitating a few demonstrations. Secondly, KB-BINDER grounds on the knowledge
base to bind the generated draft to an executable one with BM25 score matching.
The experimental results on four public heterogeneous KBQA datasets show that
KB-BINDER can achieve a strong performance with only a few in-context
demonstrations. Especially on GraphQA and 3-hop MetaQA, KB-BINDER can even
outperform the state-of-the-art trained models. On GrailQA and WebQSP, our
model is also on par with other fully-trained models. We believe KB-BINDER can
serve as an important baseline for future research. Our code is available at
https://github.com/ltl3A87/KB-BINDER.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causality-aware Concept Extraction based on Knowledge-guided Prompting. (arXiv:2305.01876v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01876">
<div class="article-summary-box-inner">
<span><p>Concepts benefit natural language understanding but are far from complete in
existing knowledge graphs (KGs). Recently, pre-trained language models (PLMs)
have been widely used in text-based concept extraction (CE). However, PLMs tend
to mine the co-occurrence associations from massive corpus as pre-trained
knowledge rather than the real causal effect between tokens. As a result, the
pre-trained knowledge confounds PLMs to extract biased concepts based on
spurious co-occurrence correlations, inevitably resulting in low precision. In
this paper, through the lens of a Structural Causal Model (SCM), we propose
equipping the PLM-based extractor with a knowledge-guided prompt as an
intervention to alleviate concept bias. The prompt adopts the topic of the
given entity from the existing knowledge in KGs to mitigate the spurious
co-occurrence correlations between entities and biased concepts. Our extensive
experiments on representative multilingual KG datasets justify that our
proposed prompt can effectively alleviate concept bias and improve the
performance of PLM-based CE models.The code has been released on
https://github.com/siyuyuan/KPCE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Contrastive Learning of Sentence Embeddings from AI Feedback. (arXiv:2305.01918v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01918">
<div class="article-summary-box-inner">
<span><p>Contrastive learning has become a popular approach in natural language
processing, particularly for the learning of sentence embeddings. However, the
discrete nature of natural language makes it difficult to ensure the quality of
positive and negative sample pairs generated through data augmentation methods.
Although supervised contrastive learning can produce more accurate sample pairs
with human feedback labels, it still lacks fine-grained training signals. In
this paper, we propose to improve \textbf{C}ontrastive \textbf{L}earning of
sentence embeddings from \textbf{AI} \textbf{F}eedback \textbf{(CLAIF)}. Our
method utilizes AI feedback from large pre-trained language models (LLMs) to
construct sample pairs with fine-grained sample similarity scores to improve
contrastive learning. Besides, we combine human feedback and AI feedback to
provide better supervision signals for supervised contrastive learning of
sentence embeddings. Experimental results show that our method achieves
state-of-the-art performance on several semantic textual similarity (STS) and
transfer learning tasks compared to other unsupervised and supervised
contrastive learning methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text Documents with Semantic-Oriented Hierarchical Graphs. (arXiv:2305.01938v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01938">
<div class="article-summary-box-inner">
<span><p>Discrete reasoning over table-text documents (e.g., financial reports) gains
increasing attention in recent two years. Existing works mostly simplify this
challenge by manually selecting and transforming document pages to structured
tables and paragraphs, hindering their practical application. In this work, we
explore a more realistic problem setting in the form of TAT-DQA, i.e. to answer
the question over a visually-rich table-text document. Specifically, we propose
a novel Doc2SoarGraph framework with enhanced discrete reasoning capability by
harnessing the differences and correlations among different elements (e.g.,
quantities, dates) of the given question and document with Semantic-oriented
hierarchical Graph structures. We conduct extensive experiments on TAT-DQA
dataset, and the results show that our proposed framework outperforms the best
baseline model by 17.73% and 16.91% in terms of Exact Match (EM) and F1 score
respectively on the test set, achieving the new state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Statistical Exploration of Text Partition Into Constituents: The Case of the Priestly Source in the Books of Genesis and Exodus. (arXiv:2305.02170v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.02170">
<div class="article-summary-box-inner">
<span><p>We present a pipeline for a statistical textual exploration, offering a
stylometry-based explanation and statistical validation of a hypothesized
partition of a text. Given a parameterization of the text, our pipeline: (1)
detects literary features yielding the optimal overlap between the hypothesized
and unsupervised partitions, (2) performs a hypothesis-testing analysis to
quantify the statistical significance of the optimal overlap, while conserving
implicit correlations between units of text that are more likely to be grouped,
and (3) extracts and quantifies the importance of features most responsible for
the classification, estimates their statistical stability and cluster-wise
abundance.
</p>
<p>We apply our pipeline to the first two books in the Bible, where one
stylistic component stands out in the eyes of biblical scholars, namely, the
Priestly component. We identify and explore statistically significant stylistic
differences between the Priestly and non-Priestly components.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simplified TinyBERT: Knowledge Distillation for Document Retrieval. (arXiv:2009.07531v2 [cs.IR] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07531">
<div class="article-summary-box-inner">
<span><p>Despite the effectiveness of utilizing the BERT model for document ranking,
the high computational cost of such approaches limits their uses. To this end,
this paper first empirically investigates the effectiveness of two knowledge
distillation models on the document ranking task. In addition, on top of the
recently proposed TinyBERT model, two simplifications are proposed. Evaluations
on two different and widely-used benchmarks demonstrate that Simplified
TinyBERT with the proposed simplifications not only boosts TinyBERT, but also
significantly outperforms BERT-Base when providing 15$\times$ speedup.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">xTrimoABFold: De novo Antibody Structure Prediction without MSA. (arXiv:2212.00735v2 [q-bio.QM] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.00735">
<div class="article-summary-box-inner">
<span><p>In the field of antibody engineering, an essential task is to design a novel
antibody whose paratopes bind to a specific antigen with correct epitopes.
Understanding antibody structure and its paratope can facilitate a mechanistic
understanding of its function. Therefore, antibody structure prediction from
its sequence alone has always been a highly valuable problem for de novo
antibody design. AlphaFold2, a breakthrough in the field of structural biology,
provides a solution to predict protein structure based on protein sequences and
computationally expensive coevolutionary multiple sequence alignments (MSAs).
However, the computational efficiency and undesirable prediction accuracy of
antibodies, especially on the complementarity-determining regions (CDRs) of
antibodies limit their applications in the industrially high-throughput drug
design. To learn an informative representation of antibodies, we employed a
deep antibody language model (ALM) on curated sequences from the observed
antibody space database via a transformer model. We also developed a novel
model named xTrimoABFold to predict antibody structure from antibody sequence
based on the pretrained ALM as well as efficient evoformers and structural
modules. The model was trained end-to-end on the antibody structures in PDB by
minimizing the ensemble loss of domain-specific focal loss on CDR and the
frame-aligned point loss. xTrimoABFold outperforms AlphaFold2 and other protein
language model based SOTAs, e.g., OmegaFold, HelixFold-Single, and IgFold with
a large significant margin (30+\% improvement on RMSD) while performing 151
times faster than AlphaFold2. To the best of our knowledge, xTrimoABFold
achieved state-of-the-art antibody structure prediction. Its improvement in
both accuracy and efficiency makes it a valuable tool for de novo antibody
design and could make further improvements in immuno-theory.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Imperceptible Document Manipulations against Neural Ranking Models. (arXiv:2305.01860v1 [cs.IR] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01860">
<div class="article-summary-box-inner">
<span><p>Adversarial attacks have gained traction in order to identify potential
vulnerabilities in neural ranking models (NRMs), but current attack methods
often introduce grammatical errors, nonsensical expressions, or incoherent text
fragments, which can be easily detected. Additionally, current methods rely
heavily on the use of a well-imitated surrogate NRM to guarantee the attack
effect, which makes them difficult to use in practice. To address these issues,
we propose a framework called Imperceptible DocumEnt Manipulation (IDEM) to
produce adversarial documents that are less noticeable to both algorithms and
humans. IDEM instructs a well-established generative language model, such as
BART, to generate connection sentences without introducing easy-to-detect
errors, and employs a separate position-wise merging strategy to balance
relevance and coherence of the perturbed text. Experimental results on the
popular MS MARCO benchmark demonstrate that IDEM can outperform strong
baselines while preserving fluency and correctness of the target documents as
evidenced by automatic and human evaluations. Furthermore, the separation of
adversarial text generation from the surrogate NRM makes IDEM more robust and
less affected by the quality of the surrogate NRM.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-05-07 23:10:56.698585548 UTC">2023-05-07 23:10:56 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>