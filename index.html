<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-03-17T01:30:00Z">03-17</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">ROSE: A Neurocomputational Architecture for Syntax. (arXiv:2303.08877v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08877">
<div class="article-summary-box-inner">
<span><p>A comprehensive model of natural language processing in the brain must
accommodate four components: representations, operations, structures and
encoding. It further requires a principled account of how these components
mechanistically, and causally, relate to each another. While previous models
have isolated regions of interest for structure-building and lexical access,
many gaps remain with respect to bridging distinct scales of neural complexity.
By expanding existing accounts of how neural oscillations can index various
linguistic processes, this article proposes a neurocomputational architecture
for syntax, termed the ROSE model (Representation, Operation, Structure,
Encoding). Under ROSE, the basic data structures of syntax are atomic features,
types of mental representations (R), and are coded at the single-unit and
ensemble level. Elementary computations (O) that transform these units into
manipulable objects accessible to subsequent structure-building levels are
coded via high frequency gamma activity. Low frequency synchronization and
cross-frequency coupling code for recursive categorial inferences (S). Distinct
forms of low frequency coupling and phase-amplitude coupling (delta-theta
coupling via pSTS-IFG; theta-gamma coupling via IFG to conceptual hubs) then
encode these structures onto distinct workspaces (E). Causally connecting R to
O is spike-phase/LFP coupling; connecting O to S is phase-amplitude coupling;
connecting S to E is a system of frontotemporal traveling oscillations;
connecting E to lower levels is low-frequency phase resetting of spike-LFP
coupling. ROSE is reliant on neurophysiologically plausible mechanisms, is
supported at all four levels by a range of recent empirical research, and
provides an anatomically precise and falsifiable grounding for the basic
property of natural language syntax: hierarchical, recursive
structure-building.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Formalization of Operads in Coq. (arXiv:2303.08894v1 [math.CT])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08894">
<div class="article-summary-box-inner">
<span><p>What provides the highest level of assurance for correctness of execution
within a programming language? One answer, and our solution in particular, to
this problem is to provide a formalization for, if it exists, the denotational
semantics of a programming language. Achieving such a formalization provides a
gold standard for ensuring a programming language is correct-by-construction.
In our effort on the DARPA V-SPELLS program, we worked to provide a foundation
for the denotational semantics of a meta-language using a mathematical object
known as an operad. This object has compositional properties which are vital to
building languages from smaller pieces. In this paper, we discuss our
formalization of an operad in the proof assistant Coq. Moreover, our definition
within Coq is capable of providing proofs that objects specified within Coq are
operads. This work within Coq provides a formal mathematical basis for our
meta-language development within V-SPELLS. Our work also provides, to our
knowledge, the first known formalization of operads within a proof assistant
that has significant automation, as well as a model that can be replicated
without knowledge of Homotopy Type Theory.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models. (arXiv:2303.08896v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08896">
<div class="article-summary-box-inner">
<span><p>Generative Large Language Models (LLMs) such as GPT-3 are capable of
generating highly fluent responses to a wide variety of user prompts. However,
LLMs are known to hallucinate facts and make non-factual statements which can
undermine trust in their output. Existing fact-checking approaches either
require access to token-level output probability distribution (which may not be
available for systems such as ChatGPT) or external databases that are
interfaced via separate, often complex, modules. In this work, we propose
"SelfCheckGPT", a simple sampling-based approach that can be used to fact-check
black-box models in a zero-resource fashion, i.e. without an external database.
SelfCheckGPT leverages the simple idea that if a LLM has knowledge of a given
concept, sampled responses are likely to be similar and contain consistent
facts. However, for hallucinated facts, stochastically sampled responses are
likely to diverge and contradict one another. We investigate this approach by
using GPT-3 to generate passages about individuals from the WikiBio dataset,
and manually annotate the factuality of the generated passages. We demonstrate
that SelfCheckGPT can: i) detect non-factual and factual sentences; and ii)
rank passages in terms of factuality. We compare our approach to several
existing baselines and show that in sentence hallucination detection, our
approach has AUC-PR scores comparable to grey-box methods, while SelfCheckGPT
is best at passage factuality assessment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Applying unsupervised keyphrase methods on concepts extracted from discharge sheets. (arXiv:2303.08928v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08928">
<div class="article-summary-box-inner">
<span><p>Clinical notes containing valuable patient information are written by
different health care providers with various scientific levels and writing
styles. It might be helpful for clinicians and researchers to understand what
information is essential when dealing with extensive electronic medical
records. Entities recognizing and mapping them to standard terminologies is
crucial in reducing ambiguity in processing clinical notes. Although named
entity recognition and entity linking are critical steps in clinical natural
language processing, they can also result in the production of repetitive and
low-value concepts. In other hand, all parts of a clinical text do not share
the same importance or content in predicting the patient's condition. As a
result, it is necessary to identify the section in which each content is
recorded and also to identify key concepts to extract meaning from clinical
texts. In this study, these challenges have been addressed by using clinical
natural language processing techniques. In addition, in order to identify key
concepts, a set of popular unsupervised key phrase extraction methods has been
verified and evaluated. Considering that most of the clinical concepts are in
the form of multi-word expressions and their accurate identification requires
the user to specify n-gram range, we have proposed a shortcut method to
preserve the structure of the expression based on TF-IDF. In order to evaluate
the pre-processing method and select the concepts, we have designed two types
of downstream tasks (multiple and binary classification) using the capabilities
of transformer-based models. The obtained results show the superiority of
proposed method in combination with SciBERT model, also offer an insight into
the efficacy of general extracting essential phrase methods for clinical notes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PRESTO: A Multilingual Dataset for Parsing Realistic Task-Oriented Dialogs. (arXiv:2303.08954v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08954">
<div class="article-summary-box-inner">
<span><p>Research interest in task-oriented dialogs has increased as systems such as
Google Assistant, Alexa and Siri have become ubiquitous in everyday life.
However, the impact of academic research in this area has been limited by the
lack of datasets that realistically capture the wide array of user pain points.
To enable research on some of the more challenging aspects of parsing realistic
conversations, we introduce PRESTO, a public dataset of over 550K contextual
multilingual conversations between humans and virtual assistants. PRESTO
contains a diverse array of challenges that occur in real-world NLU tasks such
as disfluencies, code-switching, and revisions. It is the only large scale
human generated conversational parsing dataset that provides structured context
such as a user's contacts and lists for each example. Our mT5 model based
baselines demonstrate that the conversational phenomenon present in PRESTO are
challenging to model, which is further pronounced in a low-resource setup.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-domain Sentiment Classification in Spanish. (arXiv:2303.08985v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08985">
<div class="article-summary-box-inner">
<span><p>Sentiment Classification is a fundamental task in the field of Natural
Language Processing, and has very important academic and commercial
applications. It aims to automatically predict the degree of sentiment present
in a text that contains opinions and subjectivity at some level, like product
and movie reviews, or tweets. This can be really difficult to accomplish, in
part, because different domains of text contains different words and
expressions. In addition, this difficulty increases when text is written in a
non-English language due to the lack of databases and resources. As a
consequence, several cross-domain and cross-language techniques are often
applied to this task in order to improve the results. In this work we perform a
study on the ability of a classification system trained with a large database
of product reviews to generalize to different Spanish domains. Reviews were
collected from the MercadoLibre website from seven Latin American countries,
allowing the creation of a large and balanced dataset. Results suggest that
generalization across domains is feasible though very challenging when trained
with these product reviews, and can be improved by pre-training and fine-tuning
the classification model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeltaScore: Evaluating Story Generation with Differentiating Perturbations. (arXiv:2303.08991v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08991">
<div class="article-summary-box-inner">
<span><p>Various evaluation metrics exist for natural language generation tasks, but
they have limited utility for story generation since they generally do not
correlate well with human judgments and do not measure fine-grained story
aspects, such as fluency versus relatedness, as they are intended to assess
overall generation quality. In this paper, we propose deltascore, an approach
that utilizes perturbation to evaluate fine-grained story aspects. Our core
idea is based on the hypothesis that the better the story performs in a
specific aspect (e.g., fluency), the more it will be affected by a particular
perturbation (e.g., introducing typos). To measure the impact, we calculate the
likelihood difference between the pre- and post-perturbation stories using a
language model. We evaluate deltascore against state-of-the-art model-based and
traditional similarity-based metrics across multiple story domains, and
investigate its correlation with human judgments on five fine-grained story
aspects: fluency, coherence, relatedness, logicality, and interestingness. Our
results demonstrate that deltascore performs impressively in evaluating
fine-grained story aspects, and we discovered a striking outcome where a
specific perturbation appears to be highly effective in measuring most aspects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ART: Automatic multi-step reasoning and tool-use for large language models. (arXiv:2303.09014v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09014">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) can perform complex reasoning in few- and
zero-shot settings by generating intermediate chain of thought (CoT) reasoning
steps. Further, each reasoning step can rely on external tools to support
computation beyond the core LLM capabilities (e.g. search/running code). Prior
work on CoT prompting and tool use typically requires hand-crafting
task-specific demonstrations and carefully scripted interleaving of model
generations with tool use. We introduce Automatic Reasoning and Tool-use (ART),
a framework that uses frozen LLMs to automatically generate intermediate
reasoning steps as a program. Given a new task to solve, ART selects
demonstrations of multi-step reasoning and tool use from a task library. At
test time, ART seamlessly pauses generation whenever external tools are called,
and integrates their output before resuming generation. ART achieves a
substantial improvement over few-shot prompting and automatic CoT on unseen
tasks in the BigBench and MMLU benchmarks, and matches performance of
hand-crafted CoT prompts on a majority of these tasks. ART is also extensible,
and makes it easy for humans to improve performance by correcting errors in
task-specific programs or incorporating new tools, which we demonstrate by
drastically improving performance on select tasks with minimal human
intervention.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Picture is Worth a Thousand Words: Language Models Plan from Pixels. (arXiv:2303.09031v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09031">
<div class="article-summary-box-inner">
<span><p>Planning is an important capability of artificial agents that perform
long-horizon tasks in real-world environments. In this work, we explore the use
of pre-trained language models (PLMs) to reason about plan sequences from text
instructions in embodied visual environments. Prior PLM based approaches for
planning either assume observations are available in the form of text (e.g.,
provided by a captioning model), reason about plans from the instruction alone,
or incorporate information about the visual environment in limited ways (such
as a pre-trained affordance function). In contrast, we show that PLMs can
accurately plan even when observations are directly encoded as input prompts
for the PLM. We show that this simple approach outperforms prior approaches in
experiments on the ALFWorld and VirtualHome benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Translating Radiology Reports into Plain Language using ChatGPT and GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential. (arXiv:2303.09038v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09038">
<div class="article-summary-box-inner">
<span><p>The large language model called ChatGPT has drawn extensively attention
because of its human-like expression and reasoning abilities. In this study, we
investigate the feasibility of using ChatGPT in experiments on using ChatGPT to
translate radiology reports into plain language for patients and healthcare
providers so that they are educated for improved healthcare. Radiology reports
from 62 low-dose chest CT lung cancer screening scans and 76 brain MRI
metastases screening scans were collected in the first half of February for
this study. According to the evaluation by radiologists, ChatGPT can
successfully translate radiology reports into plain language with an average
score of 4.1 in the five-point system with 0.07 places of information missing
and 0.11 places of misinformation. In terms of the suggestions provided by
ChatGPT, they are general relevant such as keeping following-up with doctors
and closely monitoring any symptoms, and for about 37% of 138 cases in total
ChatGPT offers specific suggestions based on findings in the report. ChatGPT
also presents some randomness in its responses with occasionally
over-simplified or neglected information, which can be mitigated using a more
detailed prompt. Furthermore, ChatGPT results are compared with a newly
released large model GPT-4, showing that GPT-4 can significantly improve the
quality of translated reports. Our results show that it is feasible to utilize
large language models in clinical education, and further efforts are needed to
address limitations and maximize their potential.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Secret-Keeping in Question Answering. (arXiv:2303.09067v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09067">
<div class="article-summary-box-inner">
<span><p>Existing question-answering research focuses on unanswerable questions in the
context of always providing an answer when a system can\dots but what about
cases where a system {\bf should not} answer a question. This can either be to
protect sensitive users or sensitive information. Many models expose sensitive
information under interrogation by an adversarial user. We seek to determine if
it is possible to teach a question-answering system to keep a specific fact
secret. We design and implement a proof-of-concept architecture and through our
evaluation determine that while possible, there are numerous directions for
future research to reduce system paranoia (false positives), information
leakage (false negatives) and extend the implementation of the work to more
complex problems with preserving secrecy in the presence of information
aggregation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Consistent Learning: Cooperation between Generators and Discriminators. (arXiv:2303.09075v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09075">
<div class="article-summary-box-inner">
<span><p>Using generated data to improve the performance of downstream discriminative
models has recently gained popularity due to the great development of
pre-trained language models. In most previous studies, generative models and
discriminative models are trained separately and thus could not adapt to any
changes in each other. As a result, the generated samples can easily deviate
from the real data distribution, while the improvement of the discriminative
model quickly reaches saturation. Generative adversarial networks (GANs) train
generative models via an adversarial process with discriminative models to
achieve joint training. However, the training of standard GANs is notoriously
unstable and often falls short of convergence. In this paper, to address these
issues, we propose a $\textit{self-consistent learning}$ framework, in which a
discriminator and a generator are cooperatively trained in a closed-loop form.
The discriminator and the generator enhance each other during multiple rounds
of alternating training until a scoring consensus is reached. This framework
proves to be easy to train and free from instabilities such as mode collapse
and non-convergence. Extensive experiments on sentence semantic matching
demonstrate the effectiveness of the proposed framework: the discriminator
achieves 10+ AP of improvement on the zero-shot setting and new
state-of-the-art performance on the full-data setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Failures to Generalize for Coreference Resolution Models. (arXiv:2303.09092v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09092">
<div class="article-summary-box-inner">
<span><p>Coreference resolution models are often evaluated on multiple datasets.
Datasets vary, however, in how coreference is realized -- i.e., how the
theoretical concept of coreference is operationalized in the dataset -- due to
factors such as the choice of corpora and annotation guidelines. We investigate
the extent to which errors of current coreference resolution models are
associated with existing differences in operationalization across datasets
(OntoNotes, PreCo, and Winogrande). Specifically, we distinguish between and
break down model performance into categories corresponding to several types of
coreference, including coreferring generic mentions, compound modifiers, and
copula predicates, among others. This break down helps us investigate how
state-of-the-art models might vary in their ability to generalize across
different coreference types. In our experiments, for example, models trained on
OntoNotes perform poorly on generic mentions and copula predicates in PreCo.
Our findings help calibrate expectations of current coreference resolution
models; and, future work can explicitly account for those types of coreference
that are empirically associated with poor generalization when developing
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GLEN: General-Purpose Event Detection for Thousands of Types. (arXiv:2303.09093v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09093">
<div class="article-summary-box-inner">
<span><p>The development of event extraction systems has been hindered by the absence
of wide-coverage, large-scale datasets. To make event extraction systems more
accessible, we build a general-purpose event detection dataset GLEN, which
covers 3,465 different event types, making it over 20x larger in ontology than
any current dataset. GLEN is created by utilizing the DWD Overlay, which
provides a mapping between Wikidata Qnodes and PropBank rolesets. This enables
us to use the abundant existing annotation for PropBank as distant supervision.
In addition, we also propose a new multi-stage event detection model
specifically designed to handle the large ontology size and partial labels in
GLEN. We show that our model exhibits superior performance (~10% F1 gain)
compared to both conventional classification baselines and newer
definition-based models. Finally, we perform error analysis and show that label
noise is still the largest challenge for improving performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Patch-Token Aligned Bayesian Prompt Learning for Vision-Language Models. (arXiv:2303.09100v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09100">
<div class="article-summary-box-inner">
<span><p>For downstream applications of vision-language pre-trained models, there has
been significant interest in constructing effective prompts. Existing works on
prompt engineering, which either require laborious manual designs or optimize
the prompt tuning as a point estimation problem, may fail to describe diverse
characteristics of categories and limit their applications. We introduce a
Bayesian probabilistic resolution to prompt learning, where the label-specific
stochastic prompts are generated hierarchically by first sampling a latent
vector from an underlying distribution and then employing a lightweight
generative model. Importantly, we semantically regularize prompt learning with
the visual knowledge and view images and the corresponding prompts as patch and
token sets under optimal transport, which pushes the prompt tokens to
faithfully capture the label-specific visual concepts, instead of overfitting
the training categories. Moreover, the proposed model can also be
straightforwardly extended to the conditional case where the
instance-conditional prompts are generated to improve the generalizability.
Extensive experiments on 15 datasets show promising transferability and
generalization performance of our proposed model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Distributional Shifts in Large Language Models for Code Analysis. (arXiv:2303.09128v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09128">
<div class="article-summary-box-inner">
<span><p>We systematically study the capacity of two large language models for code -
CodeT5 and Codex - to generalize to out-of-domain data. In this study, we
consider two fundamental applications - code summarization, and code
generation. We split data into domains following its natural boundaries - by an
organization, by a project, and by a module within the software project. This
makes recognition of in-domain vs out-of-domain data at the time of deployment
trivial. We establish that samples from each new domain present both models
with a significant challenge of distribution shift. We study how well different
established methods can adapt models to better generalize to new domains. Our
experiments show that while multitask learning alone is a reasonable baseline,
combining it with few-shot finetuning on examples retrieved from training data
can achieve very strong performance. In fact, according to our experiments,
this solution can outperform direct finetuning for very low-data scenarios.
Finally, we consider variations of this approach to create a more broadly
applicable method to adapt to multiple domains at once. We find that in the
case of code generation, a model adapted to multiple domains simultaneously
performs on par with those adapted to each domain individually.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Short Survey of Viewing Large Language Models in Legal Aspect. (arXiv:2303.09136v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09136">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have transformed many fields, including natural
language processing, computer vision, and reinforcement learning. These models
have also made a significant impact in the field of law, where they are being
increasingly utilized to automate various legal tasks, such as legal judgement
prediction, legal document analysis, and legal document writing. However, the
integration of LLMs into the legal field has also raised several legal
problems, including privacy concerns, bias, and explainability. In this survey,
we explore the integration of LLMs into the field of law. We discuss the
various applications of LLMs in legal tasks, examine the legal challenges that
arise from their use, and explore the data resources that can be used to
specialize LLMs in the legal domain. Finally, we discuss several promising
directions and conclude this paper. By doing so, we hope to provide an overview
of the current state of LLMs in law and highlight the potential benefits and
challenges of their integration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Block-wise Bit-Compression of Transformer-based Models. (arXiv:2303.09184v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09184">
<div class="article-summary-box-inner">
<span><p>With the popularity of the recent Transformer-based models represented by
BERT, GPT-3 and ChatGPT, there has been state-of-the-art performance in a range
of natural language processing tasks. However, the massive computations, huge
memory footprint, and thus high latency of Transformer-based models is an
inevitable challenge for the cloud with high real-time requirement. To tackle
the issue, we propose BBCT, a method of block-wise bit-compression for
transformer without retraining. Our method achieves more fine-grained
compression of the whole transformer, including embedding, matrix
multiplication, GELU, softmax, layer normalization, and all the intermediate
results. As a case, we compress an efficient BERT with the method of BBCT. Our
benchmark test results on General Language Understanding Evaluation (GLUE) show
that BBCT can achieve less than 1% accuracy drop in most tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SmartBERT: A Promotion of Dynamic Early Exiting Mechanism for Accelerating BERT Inference. (arXiv:2303.09266v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09266">
<div class="article-summary-box-inner">
<span><p>Dynamic early exiting has been proven to improve the inference speed of the
pre-trained language model like BERT. However, all samples must go through all
consecutive layers before early exiting and more complex samples usually go
through more layers, which still exists redundant computation. In this paper,
we propose a novel dynamic early exiting combined with layer skipping for BERT
inference named SmartBERT, which adds a skipping gate and an exiting operator
into each layer of BERT. SmartBERT can adaptively skip some layers and
adaptively choose whether to exit. Besides, we propose cross-layer contrastive
learning and combine it into our training phases to boost the intermediate
layers and classifiers which would be beneficial for early exiting. To keep the
consistent usage of skipping gates between training and inference phases, we
propose a hard weight mechanism during training phase. We conduct experiments
on eight classification datasets of the GLUE benchmark. Experimental results
show that SmartBERT achieves 2-3x computation reduction with minimal accuracy
drops compared with BERT and our method outperforms previous methods in both
efficiency and accuracy. Moreover, in some complex datasets like RTE and WNLI,
we prove that the early exiting based on entropy hardly works, and the skipping
mechanism is essential for reducing computation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Robust Bangla Complex Named Entity Recognition. (arXiv:2303.09306v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09306">
<div class="article-summary-box-inner">
<span><p>Named Entity Recognition (NER) is a fundamental task in natural language
processing that involves identifying and classifying named entities in text.
But much work hasn't been done for complex named entity recognition in Bangla,
despite being the seventh most spoken language globally. CNER is a more
challenging task than traditional NER as it involves identifying and
classifying complex and compound entities, which are not common in Bangla
language. In this paper, we present the winning solution of Bangla Complex
Named Entity Recognition Challenge - addressing the CNER task on BanglaCoNER
dataset using two different approaches, namely Conditional Random Fields (CRF)
and finetuning transformer based Deep Learning models such as BanglaBERT.
</p>
<p>The dataset consisted of 15300 sentences for training and 800 sentences for
validation, in the .conll format. Exploratory Data Analysis (EDA) on the
dataset revealed that the dataset had 7 different NER tags, with notable
presence of English words, suggesting that the dataset is synthetic and likely
a product of translation.
</p>
<p>We experimented with a variety of feature combinations including Part of
Speech (POS) tags, word suffixes, Gazetteers, and cluster information from
embeddings, while also finetuning the BanglaBERT (large) model for NER. We
found that not all linguistic patterns are immediately apparent or even
intuitive to humans, which is why Deep Learning based models has proved to be
the more effective model in NLP, including CNER task. Our fine tuned BanglaBERT
(large) model achieves an F1 Score of 0.79 on the validation set. Overall, our
study highlights the importance of Bangla Complex Named Entity Recognition,
particularly in the context of synthetic datasets. Our findings also
demonstrate the efficacy of Deep Learning models such as BanglaBERT for NER in
Bangla language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TOT: Topology-Aware Optimal Transport For Multimodal Hate Detection. (arXiv:2303.09314v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09314">
<div class="article-summary-box-inner">
<span><p>Multimodal hate detection, which aims to identify harmful content online such
as memes, is crucial for building a wholesome internet environment. Previous
work has made enlightening exploration in detecting explicit hate remarks.
However, most of their approaches neglect the analysis of implicit harm, which
is particularly challenging as explicit text markers and demographic visual
cues are often twisted or missing. The leveraged cross-modal attention
mechanisms also suffer from the distributional modality gap and lack logical
interpretability. To address these semantic gaps issues, we propose TOT: a
topology-aware optimal transport framework to decipher the implicit harm in
memes scenario, which formulates the cross-modal aligning problem as solutions
for optimal transportation plans. Specifically, we leverage an optimal
transport kernel method to capture complementary information from multiple
modalities. The kernel embedding provides a non-linear transformation ability
to reproduce a kernel Hilbert space (RKHS), which reflects significance for
eliminating the distributional modality gap. Moreover, we perceive the topology
information based on aligned representations to conduct bipartite graph path
reasoning. The newly achieved state-of-the-art performance on two publicly
available benchmark datasets, together with further visual analysis,
demonstrate the superiority of TOT in capturing implicit cross-modal alignment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses?. (arXiv:2303.09325v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09325">
<div class="article-summary-box-inner">
<span><p>We evaluated the capability of generative pre-trained transformers (GPT), to
pass assessments in introductory and intermediate Python programming courses at
the postsecondary level. Discussions of potential uses (e.g., exercise
generation, code explanation) and misuses (e.g., cheating) of this emerging
technology in programming education have intensified, but to date there has not
been a rigorous analysis of the models' capabilities in the realistic context
of a full-fledged programming course with diverse set of assessment
instruments. We evaluated GPT on three Python courses that employ assessments
ranging from simple multiple-choice questions (no code involved) to complex
programming projects with code bases distributed into multiple files (599
exercises overall). Further, we studied if and how successfully GPT models
leverage feedback provided by an auto-grader. We found that the current models
are not capable of passing the full spectrum of assessments typically involved
in a Python programming course (&lt;70% on even entry-level modules). Yet, it is
clear that a straightforward application of these easily accessible models
could enable a learner to obtain a non-trivial portion of the overall available
score (&gt;55%) in introductory and intermediate courses alike. While the models
exhibit remarkable capabilities, including correcting solutions based on
auto-grader's feedback, some limitations exist (e.g., poor handling of
exercises requiring complex chains of reasoning steps). These findings can be
leveraged by instructors wishing to adapt their assessments so that GPT becomes
a valuable assistant for a learner as opposed to an end-to-end solution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tollywood Emotions: Annotation of Valence-Arousal in Telugu Song Lyrics. (arXiv:2303.09364v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09364">
<div class="article-summary-box-inner">
<span><p>Emotion recognition from a given music track has heavily relied on acoustic
features, social tags, and metadata but is seldom focused on lyrics. There are
no datasets of Indian language songs that contain both valence and arousal
manual ratings of lyrics. We present a new manually annotated dataset of Telugu
songs' lyrics collected from Spotify with valence and arousal annotated on a
discrete scale. A fairly high inter-annotator agreement was observed for both
valence and arousal. Subsequently, we create two music emotion recognition
models by using two classification techniques to identify valence, arousal and
respective emotion quadrant from lyrics. Support vector machine (SVM) with term
frequency-inverse document frequency (TF-IDF) features and fine-tuning the
pre-trained XLMRoBERTa (XLM-R) model were used for valence, arousal and
quadrant classification tasks. Fine-tuned XLMRoBERTa performs better than the
SVM by improving macro-averaged F1-scores of 54.69%, 67.61%, 34.13% to 77.90%,
80.71% and 58.33% for valence, arousal and quadrant classifications,
respectively, on 10-fold cross-validation. In addition, we compare our lyrics
annotations with Spotify's annotations of valence and energy (same as arousal),
which are based on entire music tracks. The implications of our findings are
discussed. Finally, we make the dataset publicly available with lyrics,
annotations and Spotify IDs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Scope of In-Context Learning for the Extraction of Medical Temporal Constraints. (arXiv:2303.09366v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09366">
<div class="article-summary-box-inner">
<span><p>Medications often impose temporal constraints on everyday patient activity.
Violations of such medical temporal constraints (MTCs) lead to a lack of
treatment adherence, in addition to poor health outcomes and increased
healthcare expenses. These MTCs are found in drug usage guidelines (DUGs) in
both patient education materials and clinical texts. Computationally
representing MTCs in DUGs will advance patient-centric healthcare applications
by helping to define safe patient activity patterns. We define a novel taxonomy
of MTCs found in DUGs and develop a novel context-free grammar (CFG) based
model to computationally represent MTCs from unstructured DUGs. Additionally,
we release three new datasets with a combined total of N = 836 DUGs labeled
with normalized MTCs. We develop an in-context learning (ICL) solution for
automatically extracting and normalizing MTCs found in DUGs, achieving an
average F1 score of 0.62 across all datasets. Finally, we rigorously
investigate ICL model performance against a baseline model, across datasets and
MTC types, and through in-depth error analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text-to-ECG: 12-Lead Electrocardiogram Synthesis conditioned on Clinical Text Reports. (arXiv:2303.09395v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09395">
<div class="article-summary-box-inner">
<span><p>Electrocardiogram (ECG) synthesis is the area of research focused on
generating realistic synthetic ECG signals for medical use without concerns
over annotation costs or clinical data privacy restrictions. Traditional ECG
generation models consider a single ECG lead and utilize GAN-based generative
models. These models can only generate single lead samples and require separate
training for each diagnosis class. The diagnosis classes of ECGs are
insufficient to capture the intricate differences between ECGs depending on
various features (e.g. patient demographic details, co-existing diagnosis
classes, etc.). To alleviate these challenges, we present a text-to-ECG task,
in which textual inputs are used to produce ECG outputs. Then we propose
Auto-TTE, an autoregressive generative model conditioned on clinical text
reports to synthesize 12-lead ECGs, for the first time to our knowledge. We
compare the performance of our model with other representative models in
text-to-speech and text-to-image. Experimental results show the superiority of
our model in various quantitative evaluations and qualitative analysis.
Finally, we conduct a user study with three board-certified cardiologists to
confirm the fidelity and semantic alignment of generated samples. our code will
be available at https://github.com/TClife/text_to_ecg
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cryptocurrency Price Prediction using Twitter Sentiment Analysis. (arXiv:2303.09397v1 [q-fin.ST])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09397">
<div class="article-summary-box-inner">
<span><p>The cryptocurrency ecosystem has been the centre of discussion on many social
media platforms, following its noted volatility and varied opinions. Twitter is
rapidly being utilised as a news source and a medium for bitcoin discussion.
Our algorithm seeks to use historical prices and sentiment of tweets to
forecast the price of Bitcoin. In this study, we develop an end-to-end model
that can forecast the sentiment of a set of tweets (using a Bidirectional
Encoder Representations from Transformers - based Neural Network Model) and
forecast the price of Bitcoin (using Gated Recurrent Unit) using the predicted
sentiment and other metrics like historical cryptocurrency price data, tweet
volume, a user's following, and whether or not a user is verified. The
sentiment prediction gave a Mean Absolute Percentage Error of 9.45%, an average
of real-time data, and test data. The mean absolute percent error for the price
prediction was 3.6%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ToxVis: Enabling Interpretability of Implicit vs. Explicit Toxicity Detection Models with Interactive Visualization. (arXiv:2303.09402v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09402">
<div class="article-summary-box-inner">
<span><p>The rise of hate speech on online platforms has led to an urgent need for
effective content moderation. However, the subjective and multi-faceted nature
of hateful online content, including implicit hate speech, poses significant
challenges to human moderators and content moderation systems. To address this
issue, we developed ToxVis, a visually interactive and explainable tool for
classifying hate speech into three categories: implicit, explicit, and
non-hateful. We fine-tuned two transformer-based models using RoBERTa, XLNET,
and GPT-3 and used deep learning interpretation techniques to provide
explanations for the classification results. ToxVis enables users to input
potentially hateful text and receive a classification result along with a
visual explanation of which words contributed most to the decision. By making
the classification process explainable, ToxVis provides a valuable tool for
understanding the nuances of hateful content and supporting more effective
content moderation. Our research contributes to the growing body of work aimed
at mitigating the harms caused by online hate speech and demonstrates the
potential for combining state-of-the-art natural language processing models
with interpretable deep learning techniques to address this critical issue.
Finally, ToxVis can serve as a resource for content moderators, social media
platforms, and researchers working to combat the spread of hate speech online.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Team SheffieldVeraAI at SemEval-2023 Task 3: Mono and multilingual approaches for news genre, topic and persuasion technique classification. (arXiv:2303.09421v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09421">
<div class="article-summary-box-inner">
<span><p>This paper describes our approach for SemEval-2023 Task 3: Detecting the
category, the framing, and the persuasion techniques in online news in a
multi-lingual setup. For Subtask 1 (News Genre), we propose an ensemble of
fully trained and adapter mBERT models which was ranked joint-first for German,
and had the highest mean rank of multi-language teams. For Subtask 2 (Framing),
we achieved first place in 3 languages, and the best average rank across all
the languages, by using two separate ensembles: a monolingual
RoBERTa-MUPPETLARGE and an ensemble of XLM-RoBERTaLARGE with adapters and task
adaptive pretraining. For Subtask 3 (Persuasion Techniques), we train a
monolingual RoBERTa-Base model for English and a multilingual mBERT model for
the remaining languages, which achieved top 10 for all languages, including 2nd
for English. For each subtask, we compare monolingual and multilingual
approaches, and consider class imbalance techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Jump to Conclusions: Short-Cutting Transformers With Linear Transformations. (arXiv:2303.09435v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09435">
<div class="article-summary-box-inner">
<span><p>Transformer-based language models (LMs) create hidden representations of
their inputs at every layer, but only use final-layer representations for
prediction. This obscures the internal decision-making process of the model and
the utility of its intermediate representations. One way to elucidate this is
to cast the hidden representations as final representations, bypassing the
transformer computation in-between. In this work, we suggest a simple method
for such casting, by using linear transformations. We show that our approach
produces more accurate approximations than the prevailing practice of
inspecting hidden representations from all layers in the space of the final
layer. Moreover, in the context of language modeling, our method allows
"peeking" into early layer representations of GPT-2 and BERT, showing that
often LMs already predict the final output in early layers. We then demonstrate
the practicality of our method to recent early exit strategies, showing that
when aiming, for example, at retention of 95% accuracy, our approach saves
additional 7.9% layers for GPT-2 and 5.4% layers for BERT, on top of the
savings of the original approach. Last, we extend our method to linearly
approximate sub-modules, finding that attention is most tolerant to this
change.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trustera: A Live Conversation Redaction System. (arXiv:2303.09438v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09438">
<div class="article-summary-box-inner">
<span><p>Trustera, the first functional system that redacts personally identifiable
information (PII) in real-time spoken conversations to remove agents' need to
hear sensitive information while preserving the naturalness of live
customer-agent conversations. As opposed to post-call redaction, audio masking
starts as soon as the customer begins speaking to a PII entity. This
significantly reduces the risk of PII being intercepted or stored in insecure
data storage. Trustera's architecture consists of a pipeline of automatic
speech recognition, natural language understanding, and a live audio redactor
module. The system's goal is three-fold: redact entities that are PII, mask the
audio that goes to the agent, and at the same time capture the entity, so that
the captured PII can be used for a payment transaction or caller
identification. Trustera is currently being used by thousands of agents to
secure customers' sensitive information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controlling High-Dimensional Data With Sparse Input. (arXiv:2303.09446v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09446">
<div class="article-summary-box-inner">
<span><p>We address the problem of human-in-the-loop control for generating
highly-structured data. This task is challenging because existing generative
models lack an efficient interface through which users can modify the output.
Users have the option to either manually explore a non-interpretable latent
space, or to laboriously annotate the data with conditioning labels. To solve
this, we introduce a novel framework whereby an encoder maps a sparse, human
interpretable control space onto the latent space of a generative model. We
apply this framework to the task of controlling prosody in text-to-speech
synthesis. We propose a model, called Multiple-Instance CVAE (MICVAE), that is
specifically designed to encode sparse prosodic features and output complete
waveforms. We show empirically that MICVAE displays desirable qualities of a
sparse human-in-the-loop control mechanism: efficiency, robustness, and
faithfulness. With even a very small number of input values (~4), MICVAE
enables users to improve the quality of the output significantly, in terms of
listener preference (4:1).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Cross-lingual Visual Speech Representations. (arXiv:2303.09455v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09455">
<div class="article-summary-box-inner">
<span><p>Cross-lingual self-supervised learning has been a growing research topic in
the last few years. However, current works only explored the use of audio
signals to create representations. In this work, we study cross-lingual
self-supervised visual representation learning. We use the recently-proposed
Raw Audio-Visual Speech Encoders (RAVEn) framework to pre-train an audio-visual
model with unlabelled multilingual data, and then fine-tune the visual model on
labelled transcriptions. Our experiments show that: (1) multi-lingual models
with more data outperform monolingual ones, but, when keeping the amount of
data fixed, monolingual models tend to reach better performance; (2)
multi-lingual outperforms English-only pre-training; (3) using languages which
are more similar yields better results; and (4) fine-tuning on unseen languages
is competitive to using the target language in the pre-training set. We hope
our study inspires future research on non-English-only speech representation
learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT Participates in a Computer Science Exam. (arXiv:2303.09461v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09461">
<div class="article-summary-box-inner">
<span><p>We asked ChatGPT to participate in an undergraduate computer science exam on
''Algorithms and Data Structures''. We evaluated the program on the entire exam
as posed to the students. We hand-copied its answers onto an exam sheet, which
was subsequently graded in a blind setup alongside those of 200 participating
students. We find that ChatGPT narrowly passed the exam, obtaining 20.5 out of
40 points. This impressive performance indicates that ChatGPT can indeed
succeed in challenging tasks like university exams. At the same time, the tasks
in our exam are structurally similar to those on other exams, solved homework
problems, and teaching materials that can be found online. Therefore, it would
be premature to conclude from this experiment that ChatGPT has any
understanding of computer science. The transcript of our conversation with
ChatGPT is available at
\url{https://github.com/tml-tuebingen/chatgpt-algorithm-exam}, and the entire
graded exam is in the appendix of this paper.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">$P+$: Extended Textual Conditioning in Text-to-Image Generation. (arXiv:2303.09522v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09522">
<div class="article-summary-box-inner">
<span><p>We introduce an Extended Textual Conditioning space in text-to-image models,
referred to as $P+$. This space consists of multiple textual conditions,
derived from per-layer prompts, each corresponding to a layer of the denoising
U-net of the diffusion model.
</p>
<p>We show that the extended space provides greater disentangling and control
over image synthesis. We further introduce Extended Textual Inversion (XTI),
where the images are inverted into $P+$, and represented by per-layer tokens.
</p>
<p>We show that XTI is more expressive and precise, and converges faster than
the original Textual Inversion (TI) space. The extended inversion method does
not involve any noticeable trade-off between reconstruction and editability and
induces more regular inversions.
</p>
<p>We conduct a series of extensive experiments to analyze and understand the
properties of the new space, and to showcase the effectiveness of our method
for personalizing text-to-image models. Furthermore, we utilize the unique
properties of this space to achieve previously unattainable results in
object-style mixing using text-to-image models. Project page:
https://prompt-plus.github.io
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UNIQORN: Unified Question Answering over RDF Knowledge Graphs and Natural Language Text. (arXiv:2108.08614v5 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08614">
<div class="article-summary-box-inner">
<span><p>Question answering over knowledge graphs and other RDF data has been greatly
advanced, with a number of good systems providing crisp answers for natural
language questions or telegraphic queries. Some of these systems incorporate
textual sources as additional evidence for the answering process, but cannot
compute answers that are present in text alone. Conversely, systems from the IR
and NLP communities have addressed QA over text, but such systems barely
utilize semantic data and knowledge. This paper presents the first system for
complex questions that can seamlessly operate over a mixture of RDF datasets
and text corpora, or individual sources, in a unified framework. Our method,
called UNIQORN, builds a context graph on-the-fly, by retrieving
question-relevant evidences from the RDF data and/or a text corpus, using
fine-tuned BERT models. The resulting graph is typically rich but highly noisy.
UNIQORN copes with this input by a graph algorithm for Group Steiner Trees,
that identifies the best answer candidates in the context graph. Experimental
results on several benchmarks of complex questions with multiple entities and
relations, show that \uniqorn significantly outperforms state-of-the-art
methods for QA over heterogeneous sources. The graph-based methodology provides
user-interpretable evidence for the complete answering process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Empirical Study of Named Entity Recognition Performance Using Distribution-aware Word Embedding. (arXiv:2109.01636v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01636">
<div class="article-summary-box-inner">
<span><p>With the fast development of Deep Learning techniques, Named Entity
Recognition (NER) is becoming more and more important in the information
extraction task. The greatest difficulty that the NER task faces is to keep the
detectability even when types of NE and documents are unfamiliar. Realizing
that the specificity information may contain potential meanings of a word and
generate semantic-related features for word embedding, we develop a
distribution-aware word embedding and implement three different methods to make
use of the distribution information in a NER framework. And the result shows
that the performance of NER will be improved if the word specificity is
incorporated into existing NER methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-linguistic differences in gender congruency effects: Evidence from meta-analyses. (arXiv:2109.03490v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03490">
<div class="article-summary-box-inner">
<span><p>It has been proposed that the order in which words are prepared for
production depends on the speaker's language. When producing the translation
equivalent of the small cat, speakers of German or Dutch select the
gender-marked determiner at a relatively early stage of production. Speakers of
French or Italian postpone the encoding of a determiner or adjective until the
phonological form of the noun is available. Hence, even though the words are
produced in the same order (e.g., die kleine Katze in German, le petit chat in
French), they are not planned in the same order and might require different
amounts of advanced planning prior to production onset. This distinction
between early and late selection languages was proposed to account for the
observation that speakers of Germanic and Slavic languages, but not of Romance
languages, are slower to name pictures in the context of a distractor word of a
different gender. Meta-analyses are conducted to provide the first direct test
of this cross-linguistic difference and to test a prediction of the late
selection hypothesis. They confirm the existence of the gender congruency
effect in German/Slavic languages and its absence in Romance languages when
target and distractor words are presented simultaneously. They do not allow
confirming the hypothesis that in the latter languages, a similar effect
emerges when the presentation of the distractor is delayed. Overall, these
analyses confirm the cross-linguistic difference but show that the evidence
available to date is not sufficient to confirm or reject the late selection
hypothesis as an explanation of this difference. We highlight specific
directions for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Well-classified Examples are Underestimated in Classification with Deep Neural Networks. (arXiv:2110.06537v6 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06537">
<div class="article-summary-box-inner">
<span><p>The conventional wisdom behind learning deep classification models is to
focus on bad-classified examples and ignore well-classified examples that are
far from the decision boundary. For instance, when training with cross-entropy
loss, examples with higher likelihoods (i.e., well-classified examples)
contribute smaller gradients in back-propagation. However, we theoretically
show that this common practice hinders representation learning, energy
optimization, and margin growth. To counteract this deficiency, we propose to
reward well-classified examples with additive bonuses to revive their
contribution to the learning process. This counterexample theoretically
addresses these three issues. We empirically support this claim by directly
verifying the theoretical results or significant performance improvement with
our counterexample on diverse tasks, including image classification, graph
classification, and machine translation. Furthermore, this paper shows that we
can deal with complex scenarios, such as imbalanced classification, OOD
detection, and applications under adversarial attacks because our idea can
solve these three issues. Code is available at:
https://github.com/lancopku/well-classified-examples-are-underestimated.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Adults Understand What Young Children Say. (arXiv:2206.07807v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.07807">
<div class="article-summary-box-inner">
<span><p>Children's early speech often bears little resemblance to that of adults, and
yet parents and other caregivers are able to interpret that speech and react
accordingly. Here we investigate how these adult inferences as listeners
reflect sophisticated beliefs about what children are trying to communicate, as
well as how children are likely to pronounce words. Using a Bayesian framework
for modeling spoken word recognition, we find that computational models can
replicate adult interpretations of children's speech only when they include
strong, context-specific prior expectations about the messages that children
will want to communicate. This points to a critical role of adult cognitive
processes in supporting early communication and reveals how children can
actively prompt adults to take actions on their behalf even when they have only
a nascent understanding of the adult language. We discuss the wide-ranging
implications of the powerful listening capabilities of adults for theories of
first language acquisition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chain of Explanation: New Prompting Method to Generate Higher Quality Natural Language Explanation for Implicit Hate Speech. (arXiv:2209.04889v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.04889">
<div class="article-summary-box-inner">
<span><p>Recent studies have exploited advanced generative language models to generate
Natural Language Explanations (NLE) for why a certain text could be hateful. We
propose the Chain of Explanation (CoE) Prompting method, using the heuristic
words and target group, to generate high-quality NLE for implicit hate speech.
We improved the BLUE score from 44.0 to 62.3 for NLE generation by providing
accurate target information. We then evaluate the quality of generated NLE
using various automatic metrics and human annotations of informativeness and
clarity scores.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Natural Language Processing Methods to Identify Oncology Patients at High Risk for Acute Care with Clinical Notes. (arXiv:2209.13860v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.13860">
<div class="article-summary-box-inner">
<span><p>Clinical notes are an essential component of a health record. This paper
evaluates how natural language processing (NLP) can be used to identify the
risk of acute care use (ACU) in oncology patients, once chemotherapy starts.
Risk prediction using structured health data (SHD) is now standard, but
predictions using free-text formats are complex. This paper explores the use of
free-text notes for the prediction of ACU instead of SHD. Deep Learning models
were compared to manually engineered language features. Results show that SHD
models minimally outperform NLP models; an l1-penalised logistic regression
with SHD achieved a C-statistic of 0.748 (95%-CI: 0.735, 0.762), while the same
model with language features achieved 0.730 (95%-CI: 0.717, 0.745) and a
transformer-based model achieved 0.702 (95%-CI: 0.688, 0.717). This paper shows
how language models can be used in clinical applications and underlines how
risk bias is different for diverse patient groups, even using only free-text
data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Model Decoding as Likelihood-Utility Alignment. (arXiv:2210.07228v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07228">
<div class="article-summary-box-inner">
<span><p>A critical component of a successful language generation pipeline is the
decoding algorithm. However, the general principles that should guide the
choice of a decoding algorithm remain unclear. Previous works only compare
decoding algorithms in narrow scenarios, and their findings do not generalize
across tasks. We argue that the misalignment between the model's likelihood and
the task-specific notion of utility is the key factor to understanding the
effectiveness of decoding algorithms. To structure the discussion, we introduce
a taxonomy of misalignment mitigation strategies (MMSs), providing a unifying
view of decoding as a tool for alignment. The MMS taxonomy groups decoding
algorithms based on their implicit assumptions about likelihood--utility
misalignment, yielding general statements about their applicability across
tasks. Specifically, by analyzing the correlation between the likelihood and
the utility of predictions across a diverse set of tasks, we provide empirical
evidence supporting the proposed taxonomy and a set of principles to structure
reasoning when choosing a decoding algorithm. Crucially, our analysis is the
first to relate likelihood-based decoding algorithms with algorithms that rely
on external information, such as value-guided methods and prompting, and covers
the most diverse set of tasks to date. Code, data, and models are available at
https://github.com/epfl-dlab/understanding-decoding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DreamArtist: Towards Controllable One-Shot Text-to-Image Generation via Contrastive Prompt-Tuning. (arXiv:2211.11337v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.11337">
<div class="article-summary-box-inner">
<span><p>Large-scale text-to-image generation models have achieved remarkable progress
in synthesizing high-quality, feature-rich images with high resolution guided
by texts. However, these models often struggle with novel concepts, eg, new
styles, object entities, etc. Although recent attempts have employed
fine-tuning or prompt-tuning strategies to teach the pre-trained diffusion
model novel concepts from a reference image set,they have the drawback of
overfitting to the given reference images, particularly in one-shot
applications, which is harmful to generate diverse and high-quality images
while maintaining generation controllability.
</p>
<p>To tackle this challenge, we present a simple yet effective method called
DreamArtist, which employs a positive-negative prompt-tuning learning strategy.
Specifically, DreamArtist incorporates both positive and negative embeddings
and jointly trains them. The positive embedding aggressively captures the
salient characteristics of the reference image to drive diversified generation
and the negative embedding rectifies inadequacies from the positive embedding.
It learns not only what is correct, but also what can be avoided or improved.
We have conducted extensive experiments and evaluated the proposed method from
image similarity and diversity, generation controllability, and style cloning.
And our DreamArtist has achieved a superior generation performance over
existing methods. Besides, our additional evaluation on extended tasks,
including concept compositions and prompt-guided image editing, demonstrates
its effectiveness for more applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automaton-Based Representations of Task Knowledge from Generative Language Models. (arXiv:2212.01944v3 [cs.FL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01944">
<div class="article-summary-box-inner">
<span><p>Automaton-based representations of task knowledge play an important role in
control and planning for sequential decision-making problems. However,
obtaining the high-level task knowledge required to build such automata is
often difficult. Meanwhile, large-scale generative language models (GLMs) can
automatically generate relevant task knowledge. However, the textual outputs
from GLMs cannot be formally verified or used for sequential decision-making.
We propose a novel algorithm named GLM2FSA, which constructs a finite state
automaton (FSA) encoding high-level task knowledge from a brief
natural-language description of the task goal. GLM2FSA first sends queries to a
GLM to extract task knowledge in textual form, and then it builds an FSA to
represent this text-based knowledge. The proposed algorithm thus fills the gap
between natural-language task descriptions and automaton-based representations,
and the constructed FSA can be formally verified against user-defined
specifications. We accordingly propose a method to iteratively refine the
queries to the GLM based on the outcomes, e.g., counter-examples, from
verification. We demonstrate GLM2FSA's ability to build and refine
automaton-based representations of everyday tasks (e.g., crossing a road or
making a phone call), and also of tasks that require highly-specialized
knowledge (e.g., executing secure multi-party computation).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LUNA: Language Understanding with Number Augmentations on Transformers via Number Plugins and Pre-training. (arXiv:2212.02691v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02691">
<div class="article-summary-box-inner">
<span><p>Transformers are widely used in NLP tasks. However, current approaches to
leveraging transformers to understand language expose one weak spot: Number
understanding. In some scenarios, numbers frequently occur, especially in
semi-structured data like tables. But current approaches to rich-number tasks
with transformer-based language models abandon or lose some of the numeracy
information - e.g., breaking numbers into sub-word tokens - which leads to many
number-related errors. In this paper, we propose the LUNA framework which
improves the numerical reasoning and calculation capabilities of
transformer-based language models. With the number plugin of NumTok and NumBed,
LUNA represents each number as a whole to model input. With number
pre-training, including regression loss and model distillation, LUNA bridges
the gap between number and vocabulary embeddings. To the best of our knowledge,
this is the first work that explicitly injects numeracy capability into
language models using Number Plugins. Besides evaluating toy models on toy
tasks, we evaluate LUNA on three large-scale transformer models (RoBERTa, BERT,
TabBERT) over three different downstream tasks (TATQA, TabFact, CrediTrans),
and observe the performances of language models are constantly improved by
LUNA. The augmented models also improve the official baseline of TAT-QA (EM:
50.15 -&gt; 59.58) and achieve SOTA performance on CrediTrans (F1 = 86.17).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human-Guided Fair Classification for Natural Language Processing. (arXiv:2212.10154v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10154">
<div class="article-summary-box-inner">
<span><p>Text classifiers have promising applications in high-stake tasks such as
resume screening and content moderation. These classifiers must be fair and
avoid discriminatory decisions by being invariant to perturbations of sensitive
attributes such as gender or ethnicity. However, there is a gap between human
intuition about these perturbations and the formal similarity specifications
capturing them. While existing research has started to address this gap,
current methods are based on hardcoded word replacements, resulting in
specifications with limited expressivity or ones that fail to fully align with
human intuition (e.g., in cases of asymmetric counterfactuals). This work
proposes novel methods for bridging this gap by discovering expressive and
intuitive individual fairness specifications. We show how to leverage
unsupervised style transfer and GPT-3's zero-shot capabilities to automatically
generate expressive candidate pairs of semantically similar sentences that
differ along sensitive attributes. We then validate the generated pairs via an
extensive crowdsourcing study, which confirms that a lot of these pairs align
with human intuition about fairness in the context of toxicity classification.
Finally, we show how limited amounts of human feedback can be leveraged to
learn a similarity specification that can be used to train downstream
fairness-aware models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Exploit Temporal Structure for Biomedical Vision-Language Processing. (arXiv:2301.04558v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.04558">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning in vision-language processing exploits semantic
alignment between imaging and text modalities. Prior work in biomedical VLP has
mostly relied on the alignment of single image and report pairs even though
clinical notes commonly refer to prior images. This does not only introduce
poor alignment between the modalities but also a missed opportunity to exploit
rich self-supervision through existing temporal content in the data. In this
work, we explicitly account for prior images and reports when available during
both training and fine-tuning. Our approach, named BioViL-T, uses a
CNN-Transformer hybrid multi-image encoder trained jointly with a text model.
It is designed to be versatile to arising challenges such as pose variations
and missing input images across time. The resulting model excels on downstream
tasks both in single- and multi-image setups, achieving state-of-the-art
performance on (I) progression classification, (II) phrase grounding, and (III)
report generation, whilst offering consistent improvements on disease
classification and sentence-similarity tasks. We release a novel multi-modal
temporal benchmark dataset, MS-CXR-T, to quantify the quality of
vision-language representations in terms of temporal semantics. Our
experimental results show the advantages of incorporating prior images and
reports to make most use of the data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Encoders for Streaming Sequence Tagging. (arXiv:2301.09244v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09244">
<div class="article-summary-box-inner">
<span><p>A naive application of state-of-the-art bidirectional encoders for streaming
sequence tagging would require encoding each token from scratch for each new
token in an incremental streaming input (like transcribed speech). The lack of
re-usability of previous computation leads to a higher number of Floating Point
Operations (or FLOPs) and higher number of unnecessary label flips. Increased
FLOPs consequently lead to higher wall-clock time and increased label flipping
leads to poorer streaming performance. In this work, we present a Hybrid
Encoder with Adaptive Restart (HEAR) that addresses these issues while
maintaining the performance of bidirectional encoders over the offline (or
complete) inputs while improving performance on streaming (or incomplete)
inputs. HEAR has a Hybrid unidirectional-bidirectional encoder architecture to
perform sequence tagging, along with an Adaptive Restart Module (ARM) to
selectively guide the restart of bidirectional portion of the encoder. Across
four sequence tagging tasks, HEAR offers FLOP savings in streaming settings
upto 71.1% and also outperforms bidirectional encoders for streaming
predictions by upto +10% streaming exact match.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Very Large Pretrained Language Models Learn Storytelling With A Few Examples?. (arXiv:2301.09790v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09790">
<div class="article-summary-box-inner">
<span><p>While pre-trained language models can generate individually fluent sentences
for automatic story generation, they struggle to generate stories that are
coherent, sensible and interesting. Current state-of-the-art (SOTA) story
generation models explore using higher-level features such as plots or
commonsense knowledge to improve the quality of generated stories. Prompt-based
learning using very large pre-trained language models (VLPLMs) such as GPT3 has
demonstrated impressive performance even across various NLP tasks. In this
paper, we present an extensive study using automatic and human evaluation to
compare the story generation capability of VLPLMs to those SOTA models in three
different datasets where stories differ in style, register and length. Our
results show that VLPLMs generate much higher quality stories than other story
generation models, and to a certain extent rival human authors, although
preliminary investigation also reveals that they tend to ``plagiarise'' real
stories in scenarios that involve world knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-Learning Siamese Network for Few-Shot Text Classification. (arXiv:2302.03507v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03507">
<div class="article-summary-box-inner">
<span><p>Few-shot learning has been used to tackle the problem of label scarcity in
text classification, of which meta-learning based methods have shown to be
effective, such as the prototypical networks (PROTO). Despite the success of
PROTO, there still exist three main problems: (1) ignore the randomness of the
sampled support sets when computing prototype vectors; (2) disregard the
importance of labeled samples; (3) construct meta-tasks in a purely random
manner. In this paper, we propose a Meta-Learning Siamese Network, namely,
Meta-SN, to address these issues. Specifically, instead of computing prototype
vectors from the sampled support sets, Meta-SN utilizes external knowledge
(e.g. class names and descriptive texts) for class labels, which is encoded as
the low-dimensional embeddings of prototype vectors. In addition, Meta-SN
presents a novel sampling strategy for constructing meta-tasks, which gives
higher sampling probabilities to hard-to-classify samples. Extensive
experiments are conducted on six benchmark datasets to show the clear
superiority of Meta-SN over other state-of-the-art models. For reproducibility,
all the datasets and codes are provided at https://github.com/hccngu/Meta-SN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI Chat Assistants can Improve Conversations about Divisive Topics. (arXiv:2302.07268v4 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07268">
<div class="article-summary-box-inner">
<span><p>A rapidly increasing amount of human conversation occurs online. But
divisiveness and conflict can fester in text-based interactions on social media
platforms, in messaging apps, and on other digital forums. Such toxicity
increases polarization and, importantly, corrodes the capacity of diverse
societies to develop efficient solutions to complex social problems that impact
everyone. Scholars and civil society groups promote interventions that can make
interpersonal conversations less divisive or more productive in offline
settings, but scaling these efforts to the amount of discourse that occurs
online is extremely challenging. We present results of a large-scale experiment
that demonstrates how online conversations about divisive topics can be
improved with artificial intelligence tools. Specifically, we employ a large
language model to make real-time, evidence-based recommendations intended to
improve participants' perception of feeling understood in conversations. We
find that these interventions improve the reported quality of the conversation,
reduce political divisiveness, and improve the tone, without systematically
changing the content of the conversation or moving people's policy attitudes.
These findings have important implications for future research on social media,
political deliberation, and the growing community of scholars interested in the
place of artificial intelligence within computational social science.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is ChatGPT better than Human Annotators? Potential and Limitations of ChatGPT in Explaining Implicit Hate Speech. (arXiv:2302.07736v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07736">
<div class="article-summary-box-inner">
<span><p>Recent studies have alarmed that many online hate speeches are implicit. With
its subtle nature, the explainability of the detection of such hateful speech
has been a challenging problem. In this work, we examine whether ChatGPT can be
used for providing natural language explanations (NLEs) for implicit hateful
speech detection. We design our prompt to elicit concise ChatGPT-generated NLEs
and conduct user studies to evaluate their qualities by comparison with
human-written NLEs. We discuss the potential and limitations of ChatGPT in the
context of implicit hateful speech research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">See Your Heart: Psychological states Interpretation through Visual Creations. (arXiv:2302.10276v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10276">
<div class="article-summary-box-inner">
<span><p>In psychoanalysis, generating interpretations to one's psychological state
through visual creations is facing significant demands. The two main tasks of
existing studies in the field of computer vision, sentiment/emotion
classification and affective captioning, can hardly satisfy the requirement of
psychological interpreting. To meet the demands for psychoanalysis, we
introduce a challenging task, \textbf{V}isual \textbf{E}motion
\textbf{I}nterpretation \textbf{T}ask (VEIT). VEIT requires AI to generate
reasonable interpretations of creator's psychological state through visual
creations. To support the task, we present a multimodal dataset termed SpyIn
(\textbf{S}and\textbf{p}la\textbf{y} \textbf{In}terpretation Dataset), which is
psychological theory supported and professional annotated. Dataset analysis
illustrates that SpyIn is not only able to support VEIT, but also more
challenging compared with other captioning datasets. Building on SpyIn, we
conduct experiments of several image captioning method, and propose a
visual-semantic combined model which obtains a SOTA result on SpyIn. The
results indicate that VEIT is a more challenging task requiring scene graph
information and psychological knowledge. Our work also show a promise for AI to
analyze and explain inner world of humanity through visual creations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering. (arXiv:2303.01903v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.01903">
<div class="article-summary-box-inner">
<span><p>Knowledge-based visual question answering (VQA) requires external knowledge
beyond the image to answer the question. Early studies retrieve required
knowledge from explicit knowledge bases (KBs), which often introduces
irrelevant information to the question, hence restricting the performance of
their models. Recent works have sought to use a large language model (i.e.,
GPT-3) as an implicit knowledge engine to acquire the necessary knowledge for
answering. Despite the encouraging results achieved by these methods, we argue
that they have not fully activated the capacity of GPT-3 as the provided input
information is insufficient. In this paper, we present Prophet -- a
conceptually simple framework designed to prompt GPT-3 with answer heuristics
for knowledge-based VQA. Specifically, we first train a vanilla VQA model on a
specific knowledge-based VQA dataset without external knowledge. After that, we
extract two types of complementary answer heuristics from the model: answer
candidates and answer-aware examples. Finally, the two types of answer
heuristics are encoded into the prompts to enable GPT-3 to better comprehend
the task thus enhancing its capacity. Prophet significantly outperforms all
existing state-of-the-art methods on two challenging knowledge-based VQA
datasets, OK-VQA and A-OKVQA, delivering 61.1% and 55.7% accuracies on their
testing sets, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FinXABSA: Explainable Finance through Aspect-Based Sentiment Analysis. (arXiv:2303.02563v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.02563">
<div class="article-summary-box-inner">
<span><p>This paper presents a novel approach for explainability in financial analysis
by utilizing the Pearson correlation coefficient to establish a relationship
between aspect-based sentiment analysis and stock prices. The proposed
methodology involves constructing an aspect list from financial news articles
and analyzing sentiment intensity scores for each aspect. These scores are then
compared to the stock prices for the relevant companies using the Pearson
coefficient to determine any significant correlations. The results indicate
that the proposed approach provides a more detailed and accurate understanding
of the relationship between sentiment analysis and stock prices, which can be
useful for investors and financial analysts in making informed decisions.
Additionally, this methodology offers a transparent and interpretable way to
explain the sentiment analysis results and their impact on stock prices.
Overall, the findings of this paper demonstrate the importance of
explainability in financial analysis and highlight the potential benefits of
utilizing the Pearson coefficient for analyzing aspect-based sentiment analysis
and stock prices. The proposed approach offers a valuable tool for
understanding the complex relationships between financial news sentiment and
stock prices, providing a new perspective on the financial market and aiding in
making informed investment decisions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Study on Post-Training Quantization for Large Language Models. (arXiv:2303.08302v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08302">
<div class="article-summary-box-inner">
<span><p>Post-training quantization (\ptq) had been recently shown as a compromising
method to reduce memory consumption and/or compute cost for large language
models. However, a comprehensive study about the effect of different
quantization schemes, different model families, different \ptq methods,
different quantization bit precision, etc, is still missing. In this work, we
provide an extensive study of those components over tens of thousands of
zero-shot experiments. Our results show that (1) Fine-grained quantization and
\ptq methods (instead of naive round-to-nearest quantization) are necessary to
achieve good accuracy and (2) Higher bits (e.g., 5 bits) with coarse-grained
quantization is more powerful than lower bits (e.g., 4 bits) with very
fine-grained quantization (whose effective bit precision is similar to 5 bits).
We also present recommendations about how to utilize quantization for \llms
with different sizes, and leave suggestions of future opportunities and system
work that are not resolved in this work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FactReranker: Fact-guided Reranker for Faithful Radiology Report Summarization. (arXiv:2303.08335v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08335">
<div class="article-summary-box-inner">
<span><p>Automatic radiology report summarization is a crucial clinical task, whose
key challenge is to maintain factual accuracy between produced summaries and
ground truth radiology findings. Existing research adopts reinforcement
learning to directly optimize factual consistency metrics such as CheXBert or
RadGraph score. However, their decoding method using greedy search or beam
search considers no factual consistency when picking the optimal candidate,
leading to limited factual consistency improvement. To address it, we propose a
novel second-stage summarizing approach FactReranker, the first attempt that
learns to choose the best summary from all candidates based on their estimated
factual consistency score. We propose to extract medical facts of the input
medical report, its gold summary, and candidate summaries based on the RadGraph
schema and design the fact-guided reranker to efficiently incorporate the
extracted medical facts for selecting the optimal summary. We decompose the
fact-guided reranker into the factual knowledge graph generation and the
factual scorer, which allows the reranker to model the mapping between the
medical facts of the input text and its gold summary, thus can select the
optimal summary even the gold summary can't be observed during inference. We
also present a fact-based ranking metric (RadMRR) for measuring the ability of
the reranker on selecting factual consistent candidates. Experimental results
on two benchmark datasets demonstrate the superiority of our method in
generating summaries with higher factual consistency scores when compared with
existing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPT-4 Technical Report. (arXiv:2303.08774v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08774">
<div class="article-summary-box-inner">
<span><p>We report the development of GPT-4, a large-scale, multimodal model which can
accept image and text inputs and produce text outputs. While less capable than
humans in many real-world scenarios, GPT-4 exhibits human-level performance on
various professional and academic benchmarks, including passing a simulated bar
exam with a score around the top 10% of test takers. GPT-4 is a
Transformer-based model pre-trained to predict the next token in a document.
The post-training alignment process results in improved performance on measures
of factuality and adherence to desired behavior. A core component of this
project was developing infrastructure and optimization methods that behave
predictably across a wide range of scales. This allowed us to accurately
predict some aspects of GPT-4's performance based on models trained with no
more than 1/1,000th the compute of GPT-4.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Sea of Words: An In-Depth Analysis of Anchors for Text Data. (arXiv:2205.13789v2 [stat.ML] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.13789">
<div class="article-summary-box-inner">
<span><p>Anchors (Ribeiro et al., 2018) is a post-hoc, rule-based interpretability
method. For text data, it proposes to explain a decision by highlighting a
small set of words (an anchor) such that the model to explain has similar
outputs when they are present in a document. In this paper, we present the
first theoretical analysis of Anchors, considering that the search for the best
anchor is exhaustive. After formalizing the algorithm for text classification,
we present explicit results on different classes of models when the
vectorization step is TF-IDF, and words are replaced by a fixed
out-of-dictionary token when removed. Our inquiry covers models such as
elementary if-then rules and linear classifiers. We then leverage this analysis
to gain insights on the behavior of Anchors for any differentiable classifiers.
For neural networks, we empirically show that the words corresponding to the
highest partial derivatives of the model with respect to the input, reweighted
by the inverse document frequencies, are selected by Anchors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparing Feature Importance and Rule Extraction for Interpretability on Text Data. (arXiv:2207.01420v1 [cs.LG] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.01420">
<div class="article-summary-box-inner">
<span><p>Complex machine learning algorithms are used more and more often in critical
tasks involving text data, leading to the development of interpretability
methods. Among local methods, two families have emerged: those computing
importance scores for each feature and those extracting simple logical rules.
In this paper we show that using different methods can lead to unexpectedly
different explanations, even when applied to simple models for which we would
expect qualitative coincidence. To quantify this effect, we propose a new
approach to compare explanations produced by different methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Formal Algebraic Framework for DSL Composition. (arXiv:2302.00744v1 [math.CT] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00744">
<div class="article-summary-box-inner">
<span><p>We discuss a formal framework for using algebraic structures to model a
meta-language that can write, compose, and provide interoperability between
abstractions of DSLs. The purpose of this formal framework is to provide a
verification of compositional properties of the meta-language. Throughout our
paper we discuss the construction of this formal framework, as well its
relation to our team's work on the DARPA V-SPELLS program via the pipeline we
have developed for completing our verification tasking on V-SPELLS. We aim to
give a broad overview of this verification pipeline in our paper. The pipeline
can be split into four main components: the first is providing a formal model
of the meta-language in Coq; the second is to give a specification in Coq of
our chosen algebraic structures; third, we need to implement specific instances
of our algebraic structures in Coq, as well as give a proof in Coq that this
implementation is an algebraic structure according to our specification in the
second step; and lastly, we need to give a proof in Coq that the formal model
for the meta-language in the first step is an instance of the implementation in
the third step.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Post-hoc Explainers: The Case of Anchors. (arXiv:2303.08806v1 [stat.ML] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08806">
<div class="article-summary-box-inner">
<span><p>In many scenarios, the interpretability of machine learning models is a
highly required but difficult task. To explain the individual predictions of
such models, local model-agnostic approaches have been proposed. However, the
process generating the explanations can be, for a user, as mysterious as the
prediction to be explained. Furthermore, interpretability methods frequently
lack theoretical guarantees, and their behavior on simple models is frequently
unknown. While it is difficult, if not impossible, to ensure that an explainer
behaves as expected on a cutting-edge model, we can at least ensure that
everything works on simple, already interpretable models. In this paper, we
present a theoretical analysis of Anchors (Ribeiro et al., 2018): a popular
rule-based interpretability method that highlights a small set of words to
explain a text classifier's decision. After formalizing its algorithm and
providing useful insights, we demonstrate mathematically that Anchors produces
meaningful results when used with linear text classifiers on top of a TF-IDF
vectorization. We believe that our analysis framework can aid in the
development of new explainability methods based on solid theoretical
foundations.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-03-19 23:12:08.758617134 UTC">2023-03-19 23:12:08 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>