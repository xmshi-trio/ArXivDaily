<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-10-09T01:30:00Z">10-09</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Alternative Feature Extraction Pipelines For Clinical Note Phenotyping. (arXiv:2310.03772v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03772">
<div class="article-summary-box-inner">
<span><p>A common practice in the medical industry is the use of clinical notes, which
consist of detailed patient observations. However, electronic health record
systems frequently do not contain these observations in a structured format,
rendering patient information challenging to assess and evaluate automatically.
Using computational systems for the extraction of medical attributes offers
many applications, including longitudinal analysis of patients, risk
assessment, and hospital evaluation. Recent work has constructed successful
methods for phenotyping: extracting medical attributes from clinical notes.
BERT-based models can be used to transform clinical notes into a series of
representations, which are then condensed into a single document representation
based on their CLS embeddings and passed into an LSTM (Mulyar et al., 2020).
Though this pipeline yields a considerable performance improvement over
previous results, it requires extensive convergence time. This method also does
not allow for predicting attributes not yet identified in clinical notes.
</p>
<p>Considering the wide variety of medical attributes that may be present in a
clinical note, we propose an alternative pipeline utilizing ScispaCy (Neumann
et al., 2019) for the extraction of common diseases. We then train various
supervised learning models to associate the presence of these conditions with
patient attributes. Finally, we replicate a ClinicalBERT (Alsentzer et al.,
2019) and LSTM-based approach for purposes of comparison. We find that
alternative methods moderately underperform the replicated LSTM approach. Yet,
considering a complex tradeoff between accuracy and runtime, in addition to the
fact that the alternative approach also allows for the detection of medical
conditions that are not already present in a clinical note, its usage may be
considered as a supplement to established methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PrIeD-KIE: Towards Privacy Preserved Document Key Information Extraction. (arXiv:2310.03777v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03777">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce strategies for developing private Key Information
Extraction (KIE) systems by leveraging large pretrained document foundation
models in conjunction with differential privacy (DP), federated learning (FL),
and Differentially Private Federated Learning (DP-FL). Through extensive
experimentation on six benchmark datasets (FUNSD, CORD, SROIE, WildReceipts,
XFUND, and DOCILE), we demonstrate that large document foundation models can be
effectively fine-tuned for the KIE task under private settings to achieve
adequate performance while maintaining strong privacy guarantees. Moreover, by
thoroughly analyzing the impact of various training and model parameters on
model performance, we propose simple yet effective guidelines for achieving an
optimal privacy-utility trade-off for the KIE task under global DP. Finally, we
introduce FeAm-DP, a novel DP-FL algorithm that enables efficiently upscaling
global DP from a standalone context to a multi-client federated environment. We
conduct a comprehensive evaluation of the algorithm across various client and
privacy settings, and demonstrate its capability to achieve comparable
performance and privacy guarantees to standalone DP, even when accommodating an
increasing number of participating clients. Overall, our study offers valuable
insights into the development of private KIE systems, and highlights the
potential of document foundation models for privacy-preserved Document AI
applications. To the best of authors' knowledge, this is the first work that
explores privacy preserved document KIE using document foundation models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HandMeThat: Human-Robot Communication in Physical and Social Environments. (arXiv:2310.03779v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03779">
<div class="article-summary-box-inner">
<span><p>We introduce HandMeThat, a benchmark for a holistic evaluation of instruction
understanding and following in physical and social environments. While previous
datasets primarily focused on language grounding and planning, HandMeThat
considers the resolution of human instructions with ambiguities based on the
physical (object states and relations) and social (human actions and goals)
information. HandMeThat contains 10,000 episodes of human-robot interactions.
In each episode, the robot first observes a trajectory of human actions towards
her internal goal. Next, the robot receives a human instruction and should take
actions to accomplish the subgoal set through the instruction. In this paper,
we present a textual interface for our benchmark, where the robot interacts
with a virtual environment through textual commands. We evaluate several
baseline models on HandMeThat, and show that both offline and online
reinforcement learning algorithms perform poorly on HandMeThat, suggesting
significant room for future work on physical and social human-robot
communications and interactions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextualized Structural Self-supervised Learning for Ontology Matching. (arXiv:2310.03840v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03840">
<div class="article-summary-box-inner">
<span><p>Ontology matching (OM) entails the identification of semantic relationships
between concepts within two or more knowledge graphs (KGs) and serves as a
critical step in integrating KGs from various sources. Recent advancements in
deep OM models have harnessed the power of transformer-based language models
and the advantages of knowledge graph embedding. Nevertheless, these OM models
still face persistent challenges, such as a lack of reference alignments,
runtime latency, and unexplored different graph structures within an end-to-end
framework. In this study, we introduce a novel self-supervised learning OM
framework with input ontologies, called LaKERMap. This framework capitalizes on
the contextual and structural information of concepts by integrating implicit
knowledge into transformers. Specifically, we aim to capture multiple
structural contexts, encompassing both local and global interactions, by
employing distinct training objectives. To assess our methods, we utilize the
Bio-ML datasets and tasks. The findings from our innovative approach reveal
that LaKERMap surpasses state-of-the-art systems in terms of alignment quality
and inference time. Our models and codes are available here:
https://github.com/ellenzhuwang/lakermap.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmarking a foundation LLM on its ability to re-label structure names in accordance with the AAPM TG-263 report. (arXiv:2310.03874v1 [physics.med-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03874">
<div class="article-summary-box-inner">
<span><p>Purpose: To introduce the concept of using large language models (LLMs) to
re-label structure names in accordance with the American Association of
Physicists in Medicine (AAPM) Task Group (TG)-263 standard, and to establish a
benchmark for future studies to reference.
</p>
<p>Methods and Materials: The Generative Pre-trained Transformer (GPT)-4
application programming interface (API) was implemented as a Digital Imaging
and Communications in Medicine (DICOM) storage server, which upon receiving a
structure set DICOM file, prompts GPT-4 to re-label the structure names of both
target volumes and normal tissues according to the AAPM TG-263. Three disease
sites, prostate, head and neck, and thorax were selected for evaluation. For
each disease site category, 150 patients were randomly selected for manually
tuning the instructions prompt (in batches of 50) and 50 patients were randomly
selected for evaluation. Structure names that were considered were those that
were most likely to be relevant for studies utilizing structure contours for
many patients.
</p>
<p>Results: The overall re-labeling accuracy of both target volumes and normal
tissues for prostate, head and neck, and thorax cases was 96.0%, 98.5%, and
96.9% respectively. Re-labeling of target volumes was less accurate on average
except for prostate - 100%, 93.1%, and 91.1% respectively.
</p>
<p>Conclusions: Given the accuracy of GPT-4 in re-labeling structure names of
both target volumes and normal tissues as presented in this work, LLMs are
poised to be the preferred method for standardizing structure names in
radiation oncology, especially considering the rapid advancements in LLM
capabilities that are likely to continue.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic and Human-AI Interactive Text Generation. (arXiv:2310.03878v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03878">
<div class="article-summary-box-inner">
<span><p>In this tutorial, we focus on text-to-text generation, a class of natural
language generation (NLG) tasks, that takes a piece of text as input and then
generates a revision that is improved according to some specific criteria
(e.g., readability or linguistic styles), while largely retaining the original
meaning and the length of the text. This includes many useful applications,
such as text simplification, paraphrase generation, style transfer, etc. In
contrast to text summarization and open-ended text completion (e.g., story),
the text-to-text generation tasks we discuss in this tutorial are more
constrained in terms of semantic consistency and targeted language styles. This
level of control makes these tasks ideal testbeds for studying the ability of
models to generate text that is both semantically adequate and stylistically
appropriate. Moreover, these tasks are interesting from a technical standpoint,
as they require complex combinations of lexical and syntactical
transformations, stylistic control, and adherence to factual knowledge, -- all
at once. With a special focus on text simplification and revision, this
tutorial aims to provide an overview of the state-of-the-art natural language
generation research from four major aspects -- Data, Models, Human-AI
Collaboration, and Evaluation -- and to discuss and showcase a few significant
and recent advances: (1) the use of non-retrogressive approaches; (2) the shift
from fine-tuning to prompting with large language models; (3) the development
of new learnable metric and fine-grained human evaluation framework; (4) a
growing body of studies and datasets on non-English languages; (5) the rise of
HCI+NLP+Accessibility interdisciplinary research to create real-world writing
assistant systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trustworthy Formal Natural Language Specifications. (arXiv:2310.03885v1 [cs.PL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03885">
<div class="article-summary-box-inner">
<span><p>Interactive proof assistants are computer programs carefully constructed to
check a human-designed proof of a mathematical claim with high confidence in
the implementation. However, this only validates truth of a formal claim, which
may have been mistranslated from a claim made in natural language. This is
especially problematic when using proof assistants to formally verify the
correctness of software with respect to a natural language specification. The
translation from informal to formal remains a challenging, time-consuming
process that is difficult to audit for correctness.
</p>
<p>This paper shows that it is possible to build support for specifications
written in expressive subsets of natural language, within existing proof
assistants, consistent with the principles used to establish trust and
auditability in proof assistants themselves. We implement a means to provide
specifications in a modularly extensible formal subset of English, and have
them automatically translated into formal claims, entirely within the Lean
proof assistant. Our approach is extensible (placing no permanent restrictions
on grammatical structure), modular (allowing information about new words to be
distributed alongside libraries), and produces proof certificates explaining
how each word was interpreted and how the sentence's structure was used to
compute the meaning.
</p>
<p>We apply our prototype to the translation of various English descriptions of
formal specifications from a popular textbook into Lean formalizations; all can
be translated correctly with a modest lexicon with only minor modifications
related to lexicon size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Multi-Agent Coordination Abilities in Large Language Models. (arXiv:2310.03903v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03903">
<div class="article-summary-box-inner">
<span><p>A pivotal aim in contemporary AI research is to develop agents proficient in
multi-agent coordination, enabling effective collaboration with both humans and
other systems. Large Language Models (LLMs), with their notable ability to
understand, generate, and interpret language in a human-like manner, stand out
as promising candidates for the development of such agents. In this study, we
build and assess the effectiveness of agents crafted using LLMs in various
coordination scenarios. We introduce the LLM-Coordination (LLM-Co) Framework,
specifically designed to enable LLMs to play coordination games. With the
LLM-Co framework, we conduct our evaluation with three game environments and
organize the evaluation into five aspects: Theory of Mind, Situated Reasoning,
Sustained Coordination, Robustness to Partners, and Explicit Assistance. First,
the evaluation of the Theory of Mind and Situated Reasoning reveals the
capabilities of LLM to infer the partner's intention and reason actions
accordingly. Then, the evaluation around Sustained Coordination and Robustness
to Partners further showcases the ability of LLMs to coordinate with an unknown
partner in complex long-horizon tasks, outperforming Reinforcement Learning
baselines. Lastly, to test Explicit Assistance, which refers to the ability of
an agent to offer help proactively, we introduce two novel layouts into the
Overcooked-AI benchmark, examining if agents can prioritize helping their
partners, sacrificing time that could have been spent on their tasks. This
research underscores the promising capabilities of LLMs in sophisticated
coordination environments and reveals the potential of LLMs in building strong
real-world agents for multi-agent coordination.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the evolution of research topics during the COVID-19 pandemic. (arXiv:2310.03928v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03928">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic has changed the research agendas of most scientific
communities, resulting in an overwhelming production of research articles in a
variety of domains, including medicine, virology, epidemiology, economy,
psychology, and so on. Several open-access corpora and literature hubs were
established; among them, the COVID-19 Open Research Dataset (CORD-19) has
systematically gathered scientific contributions for 2.5 years, by collecting
and indexing over one million articles. Here, we present the CORD-19 Topic
Visualizer (CORToViz), a method and associated visualization tool for
inspecting the CORD-19 textual corpus of scientific abstracts. Our method is
based upon a careful selection of up-to-date technologies (including large
language models), resulting in an architecture for clustering articles along
orthogonal dimensions and extraction techniques for temporal topic mining.
Topic inspection is supported by an interactive dashboard, providing fast,
one-click visualization of topic contents as word clouds and topic trends as
time series, equipped with easy-to-drive statistical testing for analyzing the
significance of topic emergence along arbitrarily selected time windows. The
processes of data preparation and results visualization are completely general
and virtually applicable to any corpus of textual documents - thus suited for
effective adaptation to other contexts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chain of Natural Language Inference for Reducing Large Language Model Ungrounded Hallucinations. (arXiv:2310.03951v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03951">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) can generate fluent natural language texts when
given relevant documents as background context. This ability has attracted
considerable interest in developing industry applications of LLMs. However,
LLMs are prone to generate hallucinations that are not supported by the
provided sources. In this paper, we propose a hierarchical framework to detect
and mitigate such ungrounded hallucination. Our framework uses Chain of Natural
Language Inference (CoNLI) for hallucination detection and hallucination
reduction via post-editing. Our approach achieves state-of-the-art performance
on hallucination detection and enhances text quality through rewrite, using
LLMs without any fine-tuning or domain-specific prompt engineering. We show
that this simple plug-and-play framework can serve as an effective choice for
hallucination detection and reduction, achieving competitive performance across
various contexts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models. (arXiv:2310.03965v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03965">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have achieved remarkable success in reasoning
tasks with the development of prompting methods. However, existing prompting
approaches cannot reuse insights of solving similar problems and suffer from
accumulated errors in multi-step reasoning, since they prompt LLMs to reason
\textit{from scratch}. To address these issues, we propose
\textbf{\textit{Thought Propagation} (TP)}, which explores the analogous
problems and leverages their solutions to enhance the complex reasoning ability
of LLMs. These analogous problems are related to the input one, with reusable
solutions and problem-solving strategies. Thus, it is promising to propagate
insights of solving previous analogous problems to inspire new problem-solving.
To achieve this, TP first prompts LLMs to propose and solve a set of analogous
problems that are related to the input one. Then, TP reuses the results of
analogous problems to directly yield a new solution or derive a
knowledge-intensive plan for execution to amend the initial solution obtained
from scratch. TP is compatible with existing prompting approaches, allowing
plug-and-play generalization and enhancement in a wide range of tasks without
much labor in task-specific prompt engineering. Experiments across three
challenging tasks demonstrate TP enjoys a substantial improvement over the
baselines by an average of 12\% absolute increase in finding the optimal
solutions in Shortest-path Reasoning, 13\% improvement of human preference in
Creative Writing, and 15\% enhancement in the task completion rate of LLM-Agent
Planning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantized Transformer Language Model Implementations on Edge Devices. (arXiv:2310.03971v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03971">
<div class="article-summary-box-inner">
<span><p>Large-scale transformer-based models like the Bidirectional Encoder
Representations from Transformers (BERT) are widely used for Natural Language
Processing (NLP) applications, wherein these models are initially pre-trained
with a large corpus with millions of parameters and then fine-tuned for a
downstream NLP task. One of the major limitations of these large-scale models
is that they cannot be deployed on resource-constrained devices due to their
large model size and increased inference latency. In order to overcome these
limitations, such large-scale models can be converted to an optimized
FlatBuffer format, tailored for deployment on resource-constrained edge
devices. Herein, we evaluate the performance of such FlatBuffer transformed
MobileBERT models on three different edge devices, fine-tuned for Reputation
analysis of English language tweets in the RepLab 2013 dataset. In addition,
this study encompassed an evaluation of the deployed models, wherein their
latency, performance, and resource efficiency were meticulously assessed. Our
experiment results show that, compared to the original BERT large model, the
converted and quantized MobileBERT models have 160$\times$ smaller footprints
for a 4.1% drop in accuracy while analyzing at least one tweet per second on
edge devices. Furthermore, our study highlights the privacy-preserving aspect
of TinyML systems as all data is processed locally within a serverless
environment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HuBERTopic: Enhancing Semantic Representation of HuBERT through Self-supervision Utilizing Topic Model. (arXiv:2310.03975v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03975">
<div class="article-summary-box-inner">
<span><p>Recently, the usefulness of self-supervised representation learning (SSRL)
methods has been confirmed in various downstream tasks. Many of these models,
as exemplified by HuBERT and WavLM, use pseudo-labels generated from spectral
features or the model's own representation features. From previous studies, it
is known that the pseudo-labels contain semantic information. However, the
masked prediction task, the learning criterion of HuBERT, focuses on local
contextual information and may not make effective use of global semantic
information such as speaker, theme of speech, and so on. In this paper, we
propose a new approach to enrich the semantic representation of HuBERT. We
apply topic model to pseudo-labels to generate a topic label for each
utterance. An auxiliary topic classification task is added to HuBERT by using
topic labels as teachers. This allows additional global semantic information to
be incorporated in an unsupervised manner. Experimental results demonstrate
that our method achieves comparable or better performance than the baseline in
most tasks, including automatic speech recognition and five out of the eight
SUPERB tasks. Moreover, we find that topic labels include various information
about utterance, such as gender, speaker, and its theme. This highlights the
effectiveness of our approach in capturing multifaceted semantic nuances.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dementia Assessment Using Mandarin Speech with an Attention-based Speech Recognition Encoder. (arXiv:2310.03985v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03985">
<div class="article-summary-box-inner">
<span><p>Dementia diagnosis requires a series of different testing methods, which is
complex and time-consuming. Early detection of dementia is crucial as it can
prevent further deterioration of the condition. This paper utilizes a speech
recognition model to construct a dementia assessment system tailored for
Mandarin speakers during the picture description task. By training an
attention-based speech recognition model on voice data closely resembling
real-world scenarios, we have significantly enhanced the model's recognition
capabilities. Subsequently, we extracted the encoder from the speech
recognition model and added a linear layer for dementia assessment. We
collected Mandarin speech data from 99 subjects and acquired their clinical
assessments from a local hospital. We achieved an accuracy of 92.04% in
Alzheimer's disease detection and a mean absolute error of 9% in clinical
dementia rating score prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation. (arXiv:2310.03991v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03991">
<div class="article-summary-box-inner">
<span><p>Existing watermarking algorithms are vulnerable to paraphrase attacks because
of their token-level design. To address this issue, we propose SemStamp, a
robust sentence-level semantic watermarking algorithm based on
locality-sensitive hashing (LSH), which partitions the semantic space of
sentences. The algorithm encodes and LSH-hashes a candidate sentence generated
by an LLM, and conducts sentence-level rejection sampling until the sampled
sentence falls in watermarked partitions in the semantic embedding space. A
margin-based constraint is used to enhance its robustness. To show the
advantages of our algorithm, we propose a "bigram" paraphrase attack using the
paraphrase that has the fewest bigram overlaps with the original sentence. This
attack is shown to be effective against the existing token-level watermarking
method. Experimental results show that our novel semantic watermark algorithm
is not only more robust than the previous state-of-the-art method on both
common and bigram paraphrase attacks, but also is better at preserving the
quality of generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models. (arXiv:2310.04027v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04027">
<div class="article-summary-box-inner">
<span><p>Financial sentiment analysis is critical for valuation and investment
decision-making. Traditional NLP models, however, are limited by their
parameter size and the scope of their training datasets, which hampers their
generalization capabilities and effectiveness in this field. Recently, Large
Language Models (LLMs) pre-trained on extensive corpora have demonstrated
superior performance across various NLP tasks due to their commendable
zero-shot abilities. Yet, directly applying LLMs to financial sentiment
analysis presents challenges: The discrepancy between the pre-training
objective of LLMs and predicting the sentiment label can compromise their
predictive performance. Furthermore, the succinct nature of financial news,
often devoid of sufficient context, can significantly diminish the reliability
of LLMs' sentiment analysis. To address these challenges, we introduce a
retrieval-augmented LLMs framework for financial sentiment analysis. This
framework includes an instruction-tuned LLMs module, which ensures LLMs behave
as predictors of sentiment labels, and a retrieval-augmentation module which
retrieves additional context from reliable external sources. Benchmarked
against traditional models and LLMs like ChatGPT and LLaMA, our approach
achieves 15\% to 48\% performance gain in accuracy and F1 score.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analysis of the Reasoning with Redundant Information Provided Ability of Large Language Models. (arXiv:2310.04039v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04039">
<div class="article-summary-box-inner">
<span><p>Recent advancements in Large Language Models (LLMs) have demonstrated
impressive capabilities across a range of natural language processing tasks,
especially in reasoning, a cornerstone for achieving Artificial General
Intelligence (AGI). However, commonly used benchmarks may not fully encapsulate
the inferential abilities of these models in real-world scenarios. To address
this gap, a new form of Question-Answering (QA) task, termed Reasoning with
Redundant Information Provided (RRIP), is introduced. The study designed a
modified version of the grade school math 8K (GSM-8K) dataset which has several
variants focusing on different attributes of redundant information. This
investigation evaluates two popular LLMs, LlaMA2-13B-chat and generative
pre-trained transformer 3.5 (GPT-3.5), contrasting their performance on
traditional QA tasks against the RRIP tasks. Findings indicate that while these
models achieved moderate success on standard QA benchmarks, their performance
notably declines when assessed on RRIP tasks. The study not only highlights the
limitations of current LLMs in handling redundant information but also suggests
that future training of these models should focus on incorporating redundant
information into the training data to increase the performance on RRIP tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to Capture Higher-order Correlations? Generalizing Matrix Softmax Attention to Kronecker Computation. (arXiv:2310.04064v1 [cs.DS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04064">
<div class="article-summary-box-inner">
<span><p>In the classical transformer attention scheme, we are given three $n \times
d$ size matrices $Q, K, V$ (the query, key, and value tokens), and the goal is
to compute a new $n \times d$ size matrix $D^{-1} \exp(QK^\top) V$ where $D =
\mathrm{diag}( \exp(QK^\top) {\bf 1}_n )$. In this work, we study a
generalization of attention which captures triple-wise correlations. This
generalization is able to solve problems about detecting triple-wise
connections that were shown to be impossible for transformers. The potential
downside of this generalization is that it appears as though computations are
even more difficult, since the straightforward algorithm requires cubic time in
$n$. However, we show that in the bounded-entry setting (which arises in
practice, and which is well-studied in both theory and practice), there is
actually a near-linear time algorithm. More precisely, we show that bounded
entries are both necessary and sufficient for quickly performing generalized
computations:
</p>
<p>$\bullet$ On the positive side, if all entries of the input matrices are
bounded above by $o(\sqrt[3]{\log n})$ then we show how to approximate the
``tensor-type'' attention matrix in $n^{1+o(1)}$ time.
</p>
<p>$\bullet$ On the negative side, we show that if the entries of the input
matrices may be as large as $\Omega(\sqrt[3]{\log n})$, then there is no
algorithm that runs faster than $n^{3-o(1)}$ (assuming the Strong Exponential
Time Hypothesis from fine-grained complexity theory).
</p>
<p>We also show that our construction, algorithms, and lower bounds naturally
generalize to higher-order tensors and correlations. Interestingly, the higher
the order of the tensors, the lower the bound on the entries needs to be for an
efficient algorithm. Our results thus yield a natural tradeoff between the
boundedness of the entries, and order of the tensor one may use for more
expressive, efficient attention computation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Aspect Extraction from Scientific Texts. (arXiv:2310.04074v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04074">
<div class="article-summary-box-inner">
<span><p>Being able to extract from scientific papers their main points, key insights,
and other important information, referred to here as aspects, might facilitate
the process of conducting a scientific literature review. Therefore, the aim of
our research is to create a tool for automatic aspect extraction from
Russian-language scientific texts of any domain. In this paper, we present a
cross-domain dataset of scientific texts in Russian, annotated with such
aspects as Task, Contribution, Method, and Conclusion, as well as a baseline
algorithm for aspect extraction, based on the multilingual BERT model
fine-tuned on our data. We show that there are some differences in aspect
representation in different domains, but even though our model was trained on a
limited number of scientific domains, it is still able to generalize to new
domains, as was proved by cross-domain experiments. The code and the dataset
are available at
\url{https://github.com/anna-marshalova/automatic-aspect-extraction-from-scientific-texts}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">mlirSynth: Automatic, Retargetable Program Raising in Multi-Level IR using Program Synthesis. (arXiv:2310.04196v1 [cs.PL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04196">
<div class="article-summary-box-inner">
<span><p>MLIR is an emerging compiler infrastructure for modern hardware, but existing
programs cannot take advantage of MLIR's high-performance compilation if they
are described in lower-level general purpose languages. Consequently, to avoid
programs needing to be rewritten manually, this has led to efforts to
automatically raise lower-level to higher-level dialects in MLIR. However,
current methods rely on manually-defined raising rules, which limit their
applicability and make them challenging to maintain as MLIR dialects evolve.
</p>
<p>We present mlirSynth -- a novel approach which translates programs from
lower-level MLIR dialects to high-level ones without manually defined rules.
Instead, it uses available dialect definitions to construct a program space and
searches it effectively using type constraints and equivalences. We demonstrate
its effectiveness \revi{by raising C programs} to two distinct high-level MLIR
dialects, which enables us to use existing high-level dialect specific
compilation flows. On Polybench, we show a greater coverage than previous
approaches, resulting in geomean speedups of 2.5x (Intel) and 3.4x (AMD) over
state-of-the-art compilation flows for the C programming language. mlirSynth
also enables retargetability to domain-specific accelerators, resulting in a
geomean speedup of 21.6x on a TPU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Keyword Augmented Retrieval: Novel framework for Information Retrieval integrated with speech interface. (arXiv:2310.04205v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04205">
<div class="article-summary-box-inner">
<span><p>Retrieving answers in a quick and low cost manner without hallucinations from
a combination of structured and unstructured data using Language models is a
major hurdle which prevents employment of Language models in knowledge
retrieval automation. This becomes accentuated when one wants to integrate a
speech interface. Besides, for commercial search and chatbot applications,
complete reliance on commercial large language models (LLMs) like GPT 3.5 etc.
can be very costly. In this work, authors have addressed this problem by first
developing a keyword based search framework which augments discovery of the
context to be provided to the large language model. The keywords in turn are
generated by LLM and cached for comparison with keywords generated by LLM
against the query raised. This significantly reduces time and cost to find the
context within documents. Once the context is set, LLM uses that to provide
answers based on a prompt tailored for Q&amp;A. This research work demonstrates
that use of keywords in context identification reduces the overall inference
time and cost of information retrieval. Given this reduction in inference time
and cost with the keyword augmented retrieval framework, a speech based
interface for user input and response readout was integrated. This allowed a
seamless interaction with the language model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Written and spoken corpus of real and fake social media postings about COVID-19. (arXiv:2310.04237v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04237">
<div class="article-summary-box-inner">
<span><p>This study investigates the linguistic traits of fake news and real news.
There are two parts to this study: text data and speech data. The text data for
this study consisted of 6420 COVID-19 related tweets re-filtered from Patwa et
al. (2021). After cleaning, the dataset contained 3049 tweets, with 2161
labeled as 'real' and 888 as 'fake'. The speech data for this study was
collected from TikTok, focusing on COVID-19 related videos. Research assistants
fact-checked each video's content using credible sources and labeled them as
'Real', 'Fake', or 'Questionable', resulting in a dataset of 91 real entries
and 109 fake entries from 200 TikTok videos with a total word count of 53,710
words. The data was analysed using the Linguistic Inquiry and Word Count (LIWC)
software to detect patterns in linguistic data. The results indicate a set of
linguistic features that distinguish fake news from real news in both written
and speech data. This offers valuable insights into the role of language in
shaping trust, social media interactions, and the propagation of fake news.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Evaluation of Large Language Models on Benchmark Biomedical Text Processing Tasks. (arXiv:2310.04270v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04270">
<div class="article-summary-box-inner">
<span><p>Recently, Large Language Models (LLM) have demonstrated impressive capability
to solve a wide range of tasks. However, despite their success across various
tasks, no prior work has investigated their capability in the biomedical domain
yet. To this end, this paper aims to evaluate the performance of LLMs on
benchmark biomedical tasks. For this purpose, we conduct a comprehensive
evaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets.
To the best of our knowledge, this is the first work that conducts an extensive
evaluation and comparison of various LLMs in the biomedical domain.
Interestingly, we find based on our evaluation that in biomedical datasets that
have smaller training sets, zero-shot LLMs even outperform the current
state-of-the-art fine-tuned biomedical models. This suggests that pretraining
on large text corpora makes LLMs quite specialized even in the biomedical
domain. We also find that not a single LLM can outperform other LLMs in all
tasks, with the performance of different LLMs may vary depending on the task.
While their performance is still quite poor in comparison to the biomedical
models that were fine-tuned on large training sets, our findings demonstrate
that LLMs have the potential to be a valuable tool for various biomedical tasks
that lack large annotated data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large-Scale Korean Text Dataset for Classifying Biased Speech in Real-World Online Services. (arXiv:2310.04313v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04313">
<div class="article-summary-box-inner">
<span><p>With the growth of online services, the need for advanced text classification
algorithms, such as sentiment analysis and biased text detection, has become
increasingly evident. The anonymous nature of online services often leads to
the presence of biased and harmful language, posing challenges to maintaining
the health of online communities. This phenomenon is especially relevant in
South Korea, where large-scale hate speech detection algorithms have not yet
been broadly explored. In this paper, we introduce a new comprehensive,
large-scale dataset collected from a well-known South Korean SNS platform. Our
proposed dataset provides annotations including (1) Preferences, (2)
Profanities, and (3) Nine types of Bias for the text samples, enabling
multi-task learning for simultaneous classification of user-generated texts.
Leveraging state-of-the-art BERT-based language models, our approach surpasses
human-level accuracy across diverse classification tasks, as measured by
various metrics. Beyond academic contributions, our work can provide practical
solutions for real-world hate speech and bias mitigation, contributing directly
to the improvement of online community health. Our work provides a robust
foundation for future research aiming to improve the quality of online
discourse and foster societal well-being. All source codes and datasets are
publicly accessible at https://github.com/Dasol-Choi/KoMultiText.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transferring speech-generic and depression-specific knowledge for Alzheimer's disease detection. (arXiv:2310.04358v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04358">
<div class="article-summary-box-inner">
<span><p>The detection of Alzheimer's disease (AD) from spontaneous speech has
attracted increasing attention while the sparsity of training data remains an
important issue. This paper handles the issue by knowledge transfer,
specifically from both speech-generic and depression-specific knowledge. The
paper first studies sequential knowledge transfer from generic foundation
models pretrained on large amounts of speech and text data. A block-wise
analysis is performed for AD diagnosis based on the representations extracted
from different intermediate blocks of different foundation models. Apart from
the knowledge from speech-generic representations, this paper also proposes to
simultaneously transfer the knowledge from a speech depression detection task
based on the high comorbidity rates of depression and AD. A parallel knowledge
transfer framework is studied that jointly learns the information shared
between these two tasks. Experimental results show that the proposed method
improves AD and depression detection, and produces a state-of-the-art F1 score
of 0.928 for AD diagnosis on the commonly used ADReSSo dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Amortizing intractable inference in large language models. (arXiv:2310.04363v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04363">
<div class="article-summary-box-inner">
<span><p>Autoregressive large language models (LLMs) compress knowledge from their
training data through next-token conditional distributions. This limits
tractable querying of this knowledge to start-to-end autoregressive sampling.
However, many tasks of interest -- including sequence continuation, infilling,
and other forms of constrained generation -- involve sampling from intractable
posterior distributions. We address this limitation by using amortized Bayesian
inference to sample from these intractable posteriors. Such amortization is
algorithmically achieved by fine-tuning LLMs via diversity-seeking
reinforcement learning algorithms: generative flow networks (GFlowNets). We
empirically demonstrate that this distribution-matching paradigm of LLM
fine-tuning can serve as an effective alternative to maximum-likelihood
training and reward-maximizing policy optimization. As an important
application, we interpret chain-of-thought reasoning as a latent variable
modeling problem and demonstrate that our approach enables data-efficient
adaptation of LLMs to tasks that require multi-step rationalization and tool
use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hermes: Unlocking Security Analysis of Cellular Network Protocols by Synthesizing Finite State Machines from Natural Language Specifications. (arXiv:2310.04381v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04381">
<div class="article-summary-box-inner">
<span><p>In this paper, we present Hermes, an end-to-end framework to automatically
generate formal representations from natural language cellular specifications.
We first develop a neural constituency parser, NEUTREX, to process
transition-relevant texts and extract transition components (i.e., states,
conditions, and actions). We also design a domain-specific language to
translate these transition components to logical formulas by leveraging
dependency parse trees. Finally, we compile these logical formulas to generate
transitions and create the formal model as finite state machines. To
demonstrate the effectiveness of Hermes, we evaluate it on 4G NAS, 5G NAS, and
5G RRC specifications and obtain an overall accuracy of 81-87%, which is a
substantial improvement over the state-of-the-art. Our security analysis of the
extracted models uncovers 3 new vulnerabilities and identifies 19 previous
attacks in 4G and 5G specifications, and 7 deviations in commercial 4G
basebands.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Stability in Simultaneous Speech Translation: A Revision-Controllable Decoding Approach. (arXiv:2310.04399v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04399">
<div class="article-summary-box-inner">
<span><p>Simultaneous Speech-to-Text translation serves a critical role in real-time
crosslingual communication. Despite the advancements in recent years,
challenges remain in achieving stability in the translation process, a concern
primarily manifested in the flickering of partial results. In this paper, we
propose a novel revision-controllable method designed to address this issue.
Our method introduces an allowed revision window within the beam search pruning
process to screen out candidate translations likely to cause extensive
revisions, leading to a substantial reduction in flickering and, crucially,
providing the capability to completely eliminate flickering. The experiments
demonstrate the proposed method can significantly improve the decoding
stability without compromising substantially on the translation quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models. (arXiv:2310.04406v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04406">
<div class="article-summary-box-inner">
<span><p>While large language models (LLMs) have demonstrated impressive performance
on a range of decision-making tasks, they rely on simple acting processes and
fall short of broad deployment as autonomous agents. We introduce LATS
(Language Agent Tree Search), a general framework that synergizes the
capabilities of LLMs in planning, acting, and reasoning. Drawing inspiration
from Monte Carlo tree search in model-based reinforcement learning, LATS
employs LLMs as agents, value functions, and optimizers, repurposing their
latent strengths for enhanced decision-making. What is crucial in this method
is the use of an environment for external feedback, which offers a more
deliberate and adaptive problem-solving mechanism that moves beyond the
limitations of existing techniques. Our experimental evaluation across diverse
domains, such as programming, HotPotQA, and WebShop, illustrates the
applicability of LATS for both reasoning and acting. In particular, LATS
achieves 94.4\% for programming on HumanEval with GPT-4 and an average score of
75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectiveness
and generality of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Policy-Gradient Training of Language Models for Ranking. (arXiv:2310.04407v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04407">
<div class="article-summary-box-inner">
<span><p>Text retrieval plays a crucial role in incorporating factual knowledge for
decision making into language processing pipelines, ranging from chat-based web
search to question answering systems. Current state-of-the-art text retrieval
models leverage pre-trained large language models (LLMs) to achieve competitive
performance, but training LLM-based retrievers via typical contrastive losses
requires intricate heuristics, including selecting hard negatives and using
additional supervision as learning signals. This reliance on heuristics stems
from the fact that the contrastive loss itself is heuristic and does not
directly optimize the downstream metrics of decision quality at the end of the
processing pipeline. To address this issue, we introduce Neural PG-RANK, a
novel training algorithm that learns to rank by instantiating a LLM as a
Plackett-Luce ranking policy. Neural PG-RANK provides a principled method for
end-to-end training of retrieval models as part of larger decision systems via
policy gradient, with little reliance on complex heuristics, and it effectively
unifies the training objective with downstream decision-making quality. We
conduct extensive experiments on various text retrieval benchmarks. The results
demonstrate that when the training objective aligns with the evaluation setup,
Neural PG-RANK yields remarkable in-domain performance improvement, with
substantial out-of-domain generalization to some critical datasets employed in
downstream question answering tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective Augmentation. (arXiv:2310.04408v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.04408">
<div class="article-summary-box-inner">
<span><p>Retrieving documents and prepending them in-context at inference time
improves performance of language model (LMs) on a wide range of tasks. However,
these documents, often spanning hundreds of words, make inference substantially
more expensive. We propose compressing the retrieved documents into textual
summaries prior to in-context integration. This not only reduces the
computational costs but also relieves the burden of LMs to identify relevant
information in long retrieved documents. We present two compressors -- an
extractive compressor which selects useful sentences from retrieved documents
and an abstractive compressor which generates summaries by synthesizing
information from multiple documents. Both compressors are trained to improve
LMs' performance on end tasks when the generated summaries are prepended to the
LMs' input, while keeping the summary concise.If the retrieved documents are
irrelevant to the input or offer no additional information to LM, our
compressor can return an empty string, implementing selective augmentation.We
evaluate our approach on language modeling task and open domain question
answering task. We achieve a compression rate of as low as 6% with minimal loss
in performance for both tasks, significantly outperforming the off-the-shelf
summarization models. We show that our compressors trained for one LM can
transfer to other LMs on the language modeling task and provide summaries
largely faithful to the retrieved documents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vector Space Semantics for Lambek Calculus with Soft Subexponentials. (arXiv:2111.11331v3 [cs.LO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.11331">
<div class="article-summary-box-inner">
<span><p>We develop a vector space semantics for Lambek Calculus with Soft
Subexponentials, apply the calculus to construct compositional vector
interpretations for parasitic gap noun phrases and discourse units with
anaphora and ellipsis, and experiment with the constructions in a
distributional sentence similarity task. As opposed to previous work, which
used Lambek Calculus with a Relevant Modality the calculus used in this paper
uses a bounded version of the modality and is decidable. The vector space
semantics of this new modality allows us to meaningfully define contraction as
projection and provide a linear theory behind what we could previously only
achieve via nonlinear maps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AdaptivePaste: Code Adaptation through Learning Semantics-aware Variable Usage Representations. (arXiv:2205.11023v3 [cs.SE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11023">
<div class="article-summary-box-inner">
<span><p>In software development, it is common for programmers to copy-paste or port
code snippets and then adapt them to their use case. This scenario motivates
the code adaptation task -- a variant of program repair which aims to adapt
variable identifiers in a pasted snippet of code to the surrounding,
preexisting source code. However, no existing approach has been shown to
effectively address this task. In this paper, we introduce AdaptivePaste, a
learning-based approach to source code adaptation, based on transformers and a
dedicated dataflow-aware deobfuscation pre-training task to learn meaningful
representations of variable usage patterns. We evaluate AdaptivePaste on a
dataset of code snippets in Python. Results suggest that our model can learn to
adapt source code with 79.8% accuracy. To evaluate how valuable is
AdaptivePaste in practice, we perform a user study with 10 Python developers on
a hundred real-world copy-paste instances. The results show that AdaptivePaste
reduces the dwell time to nearly half the time it takes for manual code
adaptation, and helps to avoid bugs. In addition, we utilize the participant
feedback to identify potential avenues for improvement of AdaptivePaste.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TwiRGCN: Temporally Weighted Graph Convolution for Question Answering over Temporal Knowledge Graphs. (arXiv:2210.06281v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06281">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed much interest in temporal reasoning over
knowledge graphs (KG) for complex question answering (QA), but there remains a
substantial gap in human capabilities. We explore how to generalize relational
graph convolutional networks (RGCN) for temporal KGQA. Specifically, we propose
a novel, intuitive and interpretable scheme to modulate the messages passed
through a KG edge during convolution, based on the relevance of its associated
time period to the question. We also introduce a gating device to predict if
the answer to a complex temporal question is likely to be a KG entity or time
and use this prediction to guide our scoring mechanism. We evaluate the
resulting system, which we call TwiRGCN, on TimeQuestions, a recently released,
challenging dataset for multi-hop complex temporal QA. We show that TwiRGCN
significantly outperforms state-of-the-art systems on this dataset across
diverse question types. Notably, TwiRGCN improves accuracy by 9--10 percentage
points for the most difficult ordinal and implicit question types.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Preserving Semantics in Textual Adversarial Attacks. (arXiv:2211.04205v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.04205">
<div class="article-summary-box-inner">
<span><p>The growth of hateful online content, or hate speech, has been associated
with a global increase in violent crimes against minorities [23]. Harmful
online content can be produced easily, automatically and anonymously. Even
though, some form of auto-detection is already achieved through text
classifiers in NLP, they can be fooled by adversarial attacks. To strengthen
existing systems and stay ahead of attackers, we need better adversarial
attacks. In this paper, we show that up to 70% of adversarial examples
generated by adversarial attacks should be discarded because they do not
preserve semantics. We address this core weakness and propose a new, fully
supervised sentence embedding technique called Semantics-Preserving-Encoder
(SPE). Our method outperforms existing sentence encoders used in adversarial
attacks by achieving 1.2x - 5.1x better real attack success rate. We release
our code as a plugin that can be used in any existing adversarial attack to
improve its quality and speed up its execution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner. (arXiv:2305.01711v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.01711">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) trained on vast quantities of unlabelled data have
greatly advanced the field of natural language processing (NLP). In this study,
we re-visit the widely accepted notion in NLP that continued pre-training LMs
on task-related texts improves the performance of fine-tuning (FT) in
downstream tasks. Through experiments on eight single-sentence tasks and eight
sentence-pair tasks in both semi-supervised and fully-supervised settings, we
find that conventional continued pre-training does not consistently provide
benefits and can even be detrimental for sentence-pair tasks or when
prompt-based FT is used. To tackle these issues, we propose Prompt-based
Continued Pre-training (PCP), which combines the idea of instruction tuning
with conventional continued pre-training. Our approach aims to improve the
performance of prompt-based FT by presenting both task-related texts and prompt
templates to LMs through unsupervised pre-training objectives before
fine-tuning for the target task. Our empirical evaluations on 21 benchmarks
demonstrate that the PCP consistently improves the performance of
state-of-the-art prompt-based FT approaches (up to 20.1% absolute) in both
semi-supervised and fully-supervised settings, even with only hundreds of
unlabelled examples. Additionally, prompt-based FT with the PCP outperforms
state-of-the-art semi-supervised approaches with greater simplicity,
eliminating the need for an iterative process and extra data augmentation. Our
further analysis explores the performance lower bound of the PCP and reveals
that the advantages of PCP persist across different sizes of models and
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Now It Sounds Like You: Learning Personalized Vocabulary On Device. (arXiv:2305.03584v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.03584">
<div class="article-summary-box-inner">
<span><p>In recent years, Federated Learning (FL) has shown significant advancements
in its ability to perform various natural language processing (NLP) tasks. This
work focuses on applying personalized FL for on-device language modeling. Due
to limitations of memory and latency, these models cannot support the
complexity of sub-word tokenization or beam search decoding, resulting in the
decision to deploy a closed-vocabulary language model. However,
closed-vocabulary models are unable to handle out-of-vocabulary (OOV) words
belonging to specific users. To address this issue, We propose a novel
technique called "OOV expansion" that improves OOV coverage and increases model
accuracy while minimizing the impact on memory and latency. This method
introduces a personalized "OOV adapter" that effectively transfers knowledge
from a central model and learns word embedding for personalized vocabulary. OOV
expansion significantly outperforms standard FL personalization methods on a
set of common FL benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Simple and Effective Pruning Approach for Large Language Models. (arXiv:2306.11695v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.11695">
<div class="article-summary-box-inner">
<span><p>As their size increases, Large Languages Models (LLMs) are natural candidates
for network pruning methods: approaches that drop a subset of network weights
while striving to preserve performance. Existing methods, however, require
either retraining, which is rarely affordable for billion-scale LLMs, or
solving a weight reconstruction problem reliant on second-order information,
which may also be computationally expensive. In this paper, we introduce a
novel, straightforward yet effective pruning method, termed Wanda (Pruning by
Weights and activations), designed to induce sparsity in pretrained LLMs.
Motivated by the recent observation of emergent large magnitude features in
LLMs, our approach prunes weights with the smallest magnitudes multiplied by
the corresponding input activations, on a per-output basis. Notably, Wanda
requires no retraining or weight update, and the pruned LLM can be used as is.
We conduct a thorough evaluation of our method Wanda on LLaMA and LLaMA-2
across various language benchmarks. Wanda significantly outperforms the
established baseline of magnitude pruning and performs competitively against
recent method involving intensive weight update. Code is available at
https://github.com/locuslab/wanda.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models. (arXiv:2307.05782v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.05782">
<div class="article-summary-box-inner">
<span><p>Artificial intelligence is making spectacular progress, and one of the best
examples is the development of large language models (LLMs) such as OpenAI's
GPT series. In these lectures, written for readers with a background in
mathematics or physics, we give a brief history and survey of the state of the
art, and describe the underlying transformer architecture in detail. We then
explore some current ideas on how LLMs work and how models trained to predict
the next word in a text are able to perform other tasks displaying
intelligence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-shot Domain-sensitive Speech Recognition with Prompt-conditioning Fine-tuning. (arXiv:2307.10274v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.10274">
<div class="article-summary-box-inner">
<span><p>In this work, we propose a method to create domain-sensitive speech
recognition models that utilize textual domain information by conditioning its
generation on a given text prompt. This is accomplished by fine-tuning a
pre-trained, end-to-end model (Whisper) to learn from demonstrations with
prompt examples. We show that this ability can be generalized to different
domains and even various prompt contexts, with our model gaining a Word Error
Rate (WER) reduction of up to 33% on unseen datasets from various domains, such
as medical conversation, air traffic control communication, and financial
meetings. Considering the limited availability of audio-transcript pair data,
we further extend our method to text-only fine-tuning to achieve domain
sensitivity as well as domain adaptation. We demonstrate that our text-only
fine-tuned model can also attend to various prompt contexts, with the model
reaching the most WER reduction of 29% on the medical conversation dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction Execution for Robots. (arXiv:2307.11865v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.11865">
<div class="article-summary-box-inner">
<span><p>This work explores the capacity of large language models (LLMs) to address
problems at the intersection of spatial planning and natural language
interfaces for navigation.Our focus is on following relatively complex
instructions that are more akin to natural conversation than traditional
explicit procedural directives seen in robotics. Unlike most prior work, where
navigation directives are provided as imperative commands (e.g., go to the
fridge), we examine implicit directives within conversational interactions. We
leverage the 3D simulator AI2Thor to create complex and repeatable scenarios at
scale, and augment it by adding complex language queries for 40 object types.
We demonstrate that a robot can better parse descriptive language queries than
existing methods by using an LLM to interpret the user interaction in the
context of a list of the objects in the scene.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection. (arXiv:2307.16888v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.16888">
<div class="article-summary-box-inner">
<span><p>Instruction-tuned Large Language Models (LLMs) have demonstrated remarkable
abilities to modulate their responses based on human instructions. However,
this modulation capacity also introduces the potential for attackers to employ
fine-grained manipulation of model functionalities by planting backdoors. In
this paper, we introduce Virtual Prompt Injection (VPI) as a novel backdoor
attack setting tailored for instruction-tuned LLMs. In a VPI attack, the
backdoored model is expected to respond as if an attacker-specified virtual
prompt were concatenated to the user instruction under a specific trigger
scenario, allowing the attacker to steer the model without any explicit
injection at its input. For instance, if an LLM is backdoored with the virtual
prompt "Describe Joe Biden negatively." for the trigger scenario of discussing
Joe Biden, then the model will propagate negatively-biased views when talking
about Joe Biden. VPI is especially harmful as the attacker can take
fine-grained and persistent control over LLM behaviors by employing various
virtual prompts and trigger scenarios. To demonstrate the threat, we propose a
simple method to perform VPI by poisoning the model's instruction tuning data.
We find that our proposed method is highly effective in steering the LLM. For
example, by poisoning only 52 instruction tuning examples (0.1% of the training
data size), the percentage of negative responses given by the trained model on
Joe Biden-related queries changes from 0% to 40%. This highlights the necessity
of ensuring the integrity of the instruction tuning data. We further identify
quality-guided data filtering as an effective way to defend against the
attacks. Our project page is available at https://poison-llm.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Are Not Robust Multiple Choice Selectors. (arXiv:2309.03882v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.03882">
<div class="article-summary-box-inner">
<span><p>Multiple choice questions (MCQs) serve as a common yet important task format
in the research of large language models (LLMs). This work shows that LLMs are
vulnerable to option position changes in MCQs due to their inherent "selection
bias", namely, they prefer to select specific option IDs as answers (like
"Option A"). Through extensive empirical analyses with 20 LLMs on three
benchmarks, we pinpoint that this behavioral bias primarily stems from LLMs'
token bias, where the model a priori assigns more probabilistic mass to
specific option ID tokens (e.g., A/B/C/D) when predicting answers from the
option IDs. To mitigate selection bias, we propose a label-free, inference-time
debiasing method, called PriDe, which separates the model's prior bias for
option IDs from the overall prediction distribution. PriDe first estimates the
prior by permutating option contents on a small number of test samples, which
is then applied to debias the subsequent samples. We demonstrate that PriDe
achieves superior debiasing effectiveness and computational efficiency to
strong baselines. Furthermore, the prior estimated by PriDe is interpretable
and can generalize well across different domains, highlighting its practical
potential in broader scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Answering Subjective Induction Questions on Products by Summarizing Multi-sources Multi-viewpoints Knowledge. (arXiv:2309.05938v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.05938">
<div class="article-summary-box-inner">
<span><p>This paper proposes a new task in the field of Answering Subjective Induction
Question on Products (SUBJPQA). The answer to this kind of question is
non-unique, but can be interpreted from many perspectives. For example, the
answer to 'whether the phone is heavy' has a variety of different viewpoints. A
satisfied answer should be able to summarize these subjective opinions from
multiple sources and provide objective knowledge, such as the weight of a
phone. That is quite different from the traditional QA task, in which the
answer to a factoid question is unique and can be found from a single data
source. To address this new task, we propose a three-steps method. We first
retrieve all answer-related clues from multiple knowledge sources on facts and
opinions. The implicit commonsense facts are also collected to supplement the
necessary but missing contexts. We then capture their relevance with the
questions by interactive attention. Next, we design a reinforcement-based
summarizer to aggregate all these knowledgeable clues. Based on a
template-controlled decoder, we can output a comprehensive and
multi-perspective answer. Due to the lack of a relevant evaluated benchmark set
for the new task, we construct a large-scale dataset, named SupQA, consisting
of 48,352 samples across 15 product domains. Evaluation results show the
effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Avoidance of Vulnerabilities in Auto-completed Smart Contract Code Using Vulnerability-constrained Decoding. (arXiv:2309.09826v2 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.09826">
<div class="article-summary-box-inner">
<span><p>Auto-completing code enables developers to speed up coding significantly.
Recent advances in transformer-based large language model (LLM) technologies
have been applied to code synthesis. However, studies show that many of such
synthesized codes contain vulnerabilities. We propose a novel
vulnerability-constrained decoding approach to reduce the amount of vulnerable
code generated by such models. Using a small dataset of labeled vulnerable
lines of code, we fine-tune an LLM to include vulnerability labels when
generating code, acting as an embedded classifier. Then, during decoding, we
deny the model to generate these labels to avoid generating vulnerable code. To
evaluate the method, we chose to automatically complete Ethereum Blockchain
smart contracts (SCs) as the case study due to the strict requirements of SC
security. We first fine-tuned the 6-billion-parameter GPT-J model using 186,397
Ethereum SCs after removing the duplication from 2,217,692 SCs. The fine-tuning
took more than one week using ten GPUs. The results showed that our fine-tuned
model could synthesize SCs with an average BLEU (BiLingual Evaluation
Understudy) score of 0.557. However, many codes in the auto-completed SCs were
vulnerable. Using the code before the vulnerable line of 176 SCs containing
different types of vulnerabilities to auto-complete the code, we found that
more than 70% of the auto-completed codes were insecure. Thus, we further
fine-tuned the model on other 941 vulnerable SCs containing the same types of
vulnerabilities and applied vulnerability-constrained decoding. The fine-tuning
took only one hour with four GPUs. We then auto-completed the 176 SCs again and
found that our approach could identify 62% of the code to be generated as
vulnerable and avoid generating 67% of them, indicating the approach could
efficiently and effectively avoid vulnerabilities in the auto-completed code.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical attention interpretation: an interpretable speech-level transformer for bi-modal depression detection. (arXiv:2309.13476v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13476">
<div class="article-summary-box-inner">
<span><p>Depression is a common mental disorder. Automatic depression detection tools
using speech, enabled by machine learning, help early screening of depression.
This paper addresses two limitations that may hinder the clinical
implementations of such tools: noise resulting from segment-level labelling and
a lack of model interpretability. We propose a bi-modal speech-level
transformer to avoid segment-level labelling and introduce a hierarchical
interpretation approach to provide both speech-level and sentence-level
interpretations, based on gradient-weighted attention maps derived from all
attention layers to track interactions between input features. We show that the
proposed model outperforms a model that learns at a segment level ($p$=0.854,
$r$=0.947, $F1$=0.897 compared to $p$=0.732, $r$=0.808, $F1$=0.768). For model
interpretation, using one true positive sample, we show which sentences within
a given speech are most relevant to depression detection; and which text tokens
and Mel-spectrogram regions within these sentences are most relevant to
depression detection. These interpretations allow clinicians to verify the
validity of predictions made by depression detection tools, promoting their
clinical implementations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Graphs for the Life Sciences: Recent Developments, Challenges and Opportunities. (arXiv:2309.17255v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.17255">
<div class="article-summary-box-inner">
<span><p>The term life sciences refers to the disciplines that study living organisms
and life processes, and include chemistry, biology, medicine, and a range of
other related disciplines. Research efforts in life sciences are heavily
data-driven, as they produce and consume vast amounts of scientific data, much
of which is intrinsically relational and graph-structured.
</p>
<p>The volume of data and the complexity of scientific concepts and relations
referred to therein promote the application of advanced knowledge-driven
technologies for managing and interpreting data, with the ultimate aim to
advance scientific discovery.
</p>
<p>In this survey and position paper, we discuss recent developments and
advances in the use of graph-based technologies in life sciences and set out a
vision for how these technologies will impact these fields into the future. We
focus on three broad topics: the construction and management of Knowledge
Graphs (KGs), the use of KGs and associated technologies in the discovery of
new knowledge, and the use of KGs in artificial intelligence applications to
support explanations (explainable AI). We select a few exemplary use cases for
each topic, discuss the challenges and open research questions within these
topics, and conclude with a perspective and outlook that summarizes the
overarching challenges and their potential solutions as a guide for future
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Natural Language Processing Model for Radiology Reports -- The Summary is all you need!. (arXiv:2310.00100v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.00100">
<div class="article-summary-box-inner">
<span><p>The impression section of a radiology report summarizes important radiology
findings and plays a critical role in communicating these findings to
physicians. However, the preparation of these summaries is time-consuming and
error-prone for radiologists. Recently, numerous models for radiology report
summarization have been developed. Nevertheless, there is currently no model
that can summarize these reports in multiple languages. Such a model could
greatly improve future research and the development of Deep Learning models
that incorporate data from patients with different ethnic backgrounds. In this
study, the generation of radiology impressions in different languages was
automated by fine-tuning a model, publicly available, based on a multilingual
text-to-text Transformer to summarize findings available in English,
Portuguese, and German radiology reports. In a blind test, two board-certified
radiologists indicated that for at least 70% of the system-generated summaries,
the quality matched or exceeded the corresponding human-written summaries,
suggesting substantial clinical reliability. Furthermore, this study showed
that the multilingual model outperformed other models that specialized in
summarizing radiology reports in only one language, as well as models that were
not specifically designed for summarizing radiology reports, such as ChatGPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BooookScore: A systematic exploration of book-length summarization in the era of LLMs. (arXiv:2310.00785v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.00785">
<div class="article-summary-box-inner">
<span><p>Summarizing book-length documents (&gt;100K tokens) that exceed the context
window size of large language models (LLMs) requires first breaking the input
document into smaller chunks and then prompting an LLM to merge, update, and
compress chunk-level summaries. Despite the complexity and importance of this
task, it has yet to be meaningfully studied due to the challenges of
evaluation: existing book-length summarization datasets (e.g., BookSum) are in
the pretraining data of most public LLMs, and existing evaluation methods
struggle to capture errors made by modern LLM summarizers. In this paper, we
present the first study of the coherence of LLM-based book-length summarizers
implemented via two prompting workflows: (1) hierarchically merging chunk-level
summaries, and (2) incrementally updating a running summary. We obtain 1193
fine-grained human annotations on GPT-4 generated summaries of 100
recently-published books and identify eight common types of coherence errors
made by LLMs. Because human evaluation is expensive and time-consuming, we
develop an automatic metric, BooookScore, that measures the proportion of
sentences in a summary that do not contain any of the identified error types.
BooookScore has high agreement with human annotations and allows us to
systematically evaluate the impact of many other critical parameters (e.g.,
chunk size, base LLM) while saving $15K and 500 hours in human evaluation
costs. We find that closed-source LLMs such as GPT-4 and Claude 2 produce
summaries with higher BooookScore than the oft-repetitive ones generated by
LLaMA 2. Incremental updating yields lower BooookScore but higher level of
detail than hierarchical merging, a trade-off sometimes preferred by human
annotators. We release code and annotations after blind review to spur more
principled research on book-length summarization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enable Language Models to Implicitly Learn Self-Improvement From Data. (arXiv:2310.00898v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.00898">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have demonstrated remarkable capabilities in
open-ended text generation tasks. However, the inherent open-ended nature of
these tasks implies that there is always room for improvement in the quality of
model responses. To address this challenge, various approaches have been
proposed to enhance the performance of LLMs. There has been a growing focus on
enabling LLMs to self-improve their response quality, thereby reducing the
reliance on extensive human annotation efforts for collecting diverse and
high-quality training data. Recently, prompting-based methods have been widely
explored among self-improvement methods owing to their effectiveness,
efficiency, and convenience. However, those methods usually require explicitly
and thoroughly written rubrics as inputs to LLMs. It is expensive and
challenging to manually derive and provide all necessary rubrics with a
real-world complex goal for improvement (e.g., being more helpful and less
harmful). To this end, we propose an ImPlicit Self-ImprovemenT (PIT) framework
that implicitly learns the improvement goal from human preference data. PIT
only requires preference data that are used to train reward models without
extra human efforts. Specifically, we reformulate the training objective of
reinforcement learning from human feedback (RLHF) -- instead of maximizing
response quality for a given input, we maximize the quality gap of the response
conditioned on a reference response. In this way, PIT is implicitly trained
with the improvement goal of better aligning with human preferences.
Experiments on two real-world datasets and one synthetic dataset show that our
method significantly outperforms prompting-based methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation. (arXiv:2310.01320v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.01320">
<div class="article-summary-box-inner">
<span><p>Recent breakthroughs in large language models (LLMs) have brought remarkable
success in the field of LLM-as-Agent. Nevertheless, a prevalent assumption is
that the information processed by LLMs is consistently honest, neglecting the
pervasive deceptive or misleading information in human society and AI-generated
content. This oversight makes LLMs susceptible to malicious manipulations,
potentially resulting in detrimental outcomes. This study utilizes the
intricate Avalon game as a testbed to explore LLMs' potential in deceptive
environments. Avalon, full of misinformation and requiring sophisticated logic,
manifests as a "Game-of-Thoughts". Inspired by the efficacy of humans'
recursive thinking and perspective-taking in the Avalon game, we introduce a
novel framework, Recursive Contemplation (ReCon), to enhance LLMs' ability to
identify and counteract deceptive information. ReCon combines formulation and
refinement contemplation processes; formulation contemplation produces initial
thoughts and speech, while refinement contemplation further polishes them.
Additionally, we incorporate first-order and second-order perspective
transitions into these processes respectively. Specifically, the first-order
allows an LLM agent to infer others' mental states, and the second-order
involves understanding how others perceive the agent's mental state. After
integrating ReCon with different LLMs, extensive experiment results from the
Avalon game indicate its efficacy in aiding LLMs to discern and maneuver around
deceptive information without extra fine-tuning and data. Finally, we offer a
possible explanation for the efficacy of ReCon and explore the current
limitations of LLMs in terms of safety, reasoning, speaking style, and format,
potentially furnishing insights for subsequent research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Instance Needs More Care: Rewriting Prompts for Instances Yields Better Zero-Shot Performance. (arXiv:2310.02107v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.02107">
<div class="article-summary-box-inner">
<span><p>Enabling large language models (LLMs) to perform tasks in zero-shot has been
an appealing goal owing to its labor-saving (i.e., requiring no task-specific
annotations); as such, zero-shot prompting approaches also enjoy better task
generalizability. To improve LLMs' zero-shot performance, prior work has
focused on devising more effective task instructions (e.g., ``let's think step
by step'' ). However, we argue that, in order for an LLM to solve them
correctly in zero-shot, individual test instances need more carefully designed
and customized instructions. To this end, we propose PRoMPTd, an approach that
rewrites the task prompt for each individual test input to be more specific,
unambiguous, and complete, so as to provide better guidance to the task LLM. We
evaluated PRoMPTd on eight datasets covering tasks including arithmetics,
logical reasoning, and code generation, using GPT-4 as the task LLM. Notably,
PRoMPTd achieves an absolute improvement of around 10% on the complex MATH
dataset and 5% on the code generation task on HumanEval, outperforming
conventional zero-shot methods. In addition, we also showed that the rewritten
prompt can provide better interpretability of how the LLM resolves each test
instance, which can potentially be leveraged as a defense mechanism against
adversarial prompting. The source code and dataset can be obtained from
https://github.com/salokr/PRoMPTd
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sweeping Heterogeneity with Smart MoPs: Mixture of Prompts for LLM Task Adaptation. (arXiv:2310.02842v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.02842">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have the ability to solve a variety of tasks,
such as text summarization and mathematical questions, just out of the box, but
they are often trained with a single task in mind. Due to high computational
costs, the current trend is to use prompt instruction tuning to better adjust
monolithic, pretrained LLMs for new -- but often individual -- downstream
tasks. Thus, how one would expand prompt tuning to handle -- concomitantly --
heterogeneous tasks and data distributions is a widely open question. To
address this gap, we suggest the use of \emph{Mixture of Prompts}, or MoPs,
associated with smart gating functionality: the latter -- whose design is one
of the contributions of this paper -- can identify relevant skills embedded in
different groups of prompts and dynamically assign combined experts (i.e.,
collection of prompts), based on the target task. Additionally, MoPs are
empirically agnostic to any model compression technique applied -- for
efficiency reasons -- as well as instruction data source and task composition.
In practice, MoPs can simultaneously mitigate prompt training "interference" in
multi-task, multi-source scenarios (e.g., task and data heterogeneity across
sources), as well as possible implications from model approximations. As a
highlight, MoPs manage to decrease final perplexity from $\sim20\%$ up to
$\sim70\%$, as compared to baselines, in the federated scenario, and from $\sim
3\%$ up to $\sim30\%$ in the centralized scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Personalized Story Evaluation. (arXiv:2310.03304v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03304">
<div class="article-summary-box-inner">
<span><p>While large language models (LLMs) have shown impressive results for more
objective tasks such as QA and retrieval, it remains nontrivial to evaluate
their performance on open-ended text generation for reasons including (1) data
contamination; (2) multi-dimensional evaluation criteria; and (3)
subjectiveness stemming from reviewers' personal preferences. To address such
issues, we propose to model personalization in an uncontaminated open-ended
generation assessment. We create two new datasets Per-MPST and Per-DOC for
personalized story evaluation, by re-purposing existing datasets with proper
anonymization and new personalized labels. We further develop a personalized
story evaluation model PERSE to infer reviewer preferences and provide a
personalized evaluation. Specifically, given a few exemplary reviews from a
particular reviewer, PERSE predicts either a detailed review or fine-grained
comparison in several aspects (such as interestingness and surprise) for that
reviewer on a new text input. Experimental results show that PERSE outperforms
GPT-4 by 15.8% on Kendall correlation of story ratings, and by 13.7% on
pairwise preference prediction accuracy. Both datasets and code will be
released at https://github.com/dqwang122/PerSE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The North System for Formosa Speech Recognition Challenge 2023. (arXiv:2310.03443v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03443">
<div class="article-summary-box-inner">
<span><p>This report provides a concise overview of the proposed North system, which
aims to achieve automatic word/syllable recognition for Taiwanese Hakka
(Sixian). The report outlines three key components of the system: the
acquisition, composition, and utilization of the training data; the
architecture of the model; and the hardware specifications and operational
statistics. The demonstration of the system has been made public at
https://asrvm.iis.sinica.edu.tw/hakka_sixian.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction. (arXiv:2310.03668v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.03668">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) combined with instruction tuning have made
significant progress when generalizing to unseen tasks. However, they have been
less successful in Information Extraction (IE), lagging behind task-specific
models. Typically, IE tasks are characterized by complex annotation guidelines
which describe the task and give examples to humans. Previous attempts to
leverage such information have failed, even with the largest models, as they
are not able to follow the guidelines out-of-the-box. In this paper we propose
GoLLIE (Guideline-following Large Language Model for IE), a model able to
improve zero-shot results on unseen IE tasks by virtue of being fine-tuned to
comply with annotation guidelines. Comprehensive evaluation empirically
demonstrates that GoLLIE is able to generalize to and follow unseen guidelines,
outperforming previous attempts at zero-shot information extraction. The
ablation study shows that detailed guidelines is key for good results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Differentiable Outlier Detection Enable Robust Deep Multimodal Analysis. (arXiv:2302.05608v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05608">
<div class="article-summary-box-inner">
<span><p>Often, deep network models are purely inductive during training and while
performing inference on unseen data. Thus, when such models are used for
predictions, it is well known that they often fail to capture the semantic
information and implicit dependencies that exist among objects (or concepts) on
a population level. Moreover, it is still unclear how domain or prior modal
knowledge can be specified in a backpropagation friendly manner, especially in
large-scale and noisy settings. In this work, we propose an end-to-end vision
and language model incorporating explicit knowledge graphs. We also introduce
an interactive out-of-distribution (OOD) layer using implicit network operator.
The layer is used to filter noise that is brought by external knowledge base.
In practice, we apply our model on several vision and language downstream tasks
including visual question answering, visual reasoning, and image-text retrieval
on different datasets. Our experiments show that it is possible to design
models that perform similarly to state-of-art results but with significantly
fewer samples and training time.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-10-09 23:11:24.151626552 UTC">2023-10-09 23:11:24 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>