<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-02-14T01:30:00Z">02-14</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Distillation of encoder-decoder transformers for sequence labelling. (arXiv:2302.05454v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05454">
<div class="article-summary-box-inner">
<span><p>Driven by encouraging results on a wide range of tasks, the field of NLP is
experiencing an accelerated race to develop bigger language models. This race
for bigger models has also underscored the need to continue the pursuit of
practical distillation approaches that can leverage the knowledge acquired by
these big models in a compute-efficient manner. Having this goal in mind, we
build on recent work to propose a hallucination-free framework for sequence
tagging that is especially suited for distillation. We show empirical results
of new state-of-the-art performance across multiple sequence labelling datasets
and validate the usefulness of this framework for distilling a large model in a
few-shot learning scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Long-Context Language Decision Transformers and Exponential Tilt for Interactive Text Environments. (arXiv:2302.05507v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05507">
<div class="article-summary-box-inner">
<span><p>Text-based game environments are challenging because agents must deal with
long sequences of text, execute compositional actions using text and learn from
sparse rewards. We address these challenges by proposing Long-Context Language
Decision Transformers (LLDTs), a framework that is based on long transformer
language models and decision transformers (DTs). LLDTs extend DTs with 3
components: (1) exponential tilt to guide the agent towards high obtainable
goals, (2) novel goal conditioning methods yielding significantly better
results than the traditional return-to-go (sum of all future rewards), and (3)
a model of future observations. Our ablation results show that predicting
future observations improves agent performance. To the best of our knowledge,
LLDTs are the first to address offline RL with DTs on these challenging games.
Our experiments show that LLDTs achieve the highest scores among many different
types of agents on some of the most challenging Jericho games, such as
Enchanter.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FairPy: A Toolkit for Evaluation of Social Biases and their Mitigation in Large Language Models. (arXiv:2302.05508v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05508">
<div class="article-summary-box-inner">
<span><p>Studies have shown that large pretrained language models exhibit biases
against social groups based on race, gender etc, which they inherit from the
datasets they are trained on. Various researchers have proposed mathematical
tools for quantifying and identifying these biases. There have been methods
proposed to mitigate such biases. In this paper, we present a comprehensive
quantitative evaluation of different kinds of biases such as race, gender,
ethnicity, age etc. exhibited by popular pretrained language models such as
BERT, GPT-2 etc. and also present a toolkit that provides plug-and-play
interfaces to connect mathematical tools to identify biases with large
pretrained language models such as BERT, GPT-2 etc. and also present users with
the opportunity to test custom models against these metrics. The toolkit also
allows users to debias existing and custom models using the debiasing
techniques proposed so far. The toolkit is available at
https://github.com/HrishikeshVish/Fairpy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NapSS: Paragraph-level Medical Text Simplification via Narrative Prompting and Sentence-matching Summarization. (arXiv:2302.05574v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05574">
<div class="article-summary-box-inner">
<span><p>Accessing medical literature is difficult for laypeople as the content is
written for specialists and contains medical jargon. Automated text
simplification methods offer a potential means to address this issue. In this
work, we propose a summarize-then-simplify two-stage strategy, which we call
NapSS, identifying the relevant content to simplify while ensuring that the
original narrative flow is preserved. In this approach, we first generate
reference summaries via sentence matching between the original and the
simplified abstracts. These summaries are then used to train an extractive
summarizer, learning the most relevant content to be simplified. Then, to
ensure the narrative consistency of the simplified text, we synthesize
auxiliary narrative prompts combining key phrases derived from the syntactical
analyses of the original text. Our model achieves results significantly better
than the seq2seq baseline on an English medical corpus, yielding 3%~4% absolute
improvements in terms of lexical similarity, and providing a further 1.1%
improvement of SARI score when combined with the baseline. We also highlight
shortcomings of existing evaluation methods, and introduce new metrics that
take into account both lexical and high-level semantic similarity. A human
evaluation conducted on a random sample of the test set further establishes the
effectiveness of the proposed approach. Codes and models are released here:
https://github.com/LuJunru/NapSS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Characterizing Attribution and Fluency Tradeoffs for Retrieval-Augmented Large Language Models. (arXiv:2302.05578v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05578">
<div class="article-summary-box-inner">
<span><p>Despite recent progress, it has been difficult to prevent semantic
hallucinations in generative Large Language Models. One common solution to this
is augmenting LLMs with a retrieval system and making sure that the generated
output is attributable to the retrieved information. Given this new added
constraint, it is plausible to expect that the overall quality of the output
will be affected, for example, in terms of fluency. Can scaling language models
help?
</p>
<p>Here we examine the relationship between fluency and attribution in LLMs
prompted with retrieved evidence in knowledge-heavy dialog settings. Our
experiments were implemented with a set of auto-metrics that are aligned with
human preferences. They were used to evaluate a large set of generations,
produced under varying parameters of LLMs and supplied context.
</p>
<p>We show that larger models tend to do much better in both fluency and
attribution, and that (naively) using top-k retrieval versus top-1 retrieval
improves attribution but hurts fluency. We next propose a recipe that could
allow smaller models to both close the gap with larger models and preserve the
benefits of top-k retrieval while avoiding its drawbacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ASDF: A Differential Testing Framework for Automatic Speech Recognition Systems. (arXiv:2302.05582v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05582">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed wider adoption of Automated Speech Recognition
(ASR) techniques in various domains. Consequently, evaluating and enhancing the
quality of ASR systems is of great importance. This paper proposes ASDF, an
Automated Speech Recognition Differential Testing Framework for testing ASR
systems. ASDF extends an existing ASR testing tool, the CrossASR++, which
synthesizes test cases from a text corpus. However, CrossASR++ fails to make
use of the text corpus efficiently and provides limited information on how the
failed test cases can improve ASR systems. To address these limitations, our
tool incorporates two novel features: (1) a text transformation module to boost
the number of generated test cases and uncover more errors in ASR systems and
(2) a phonetic analysis module to identify on which phonemes the ASR system
tend to produce errors. ASDF generates more high-quality test cases by applying
various text transformation methods (e.g., change tense) to the texts in failed
test cases. By doing so, ASDF can utilize a small text corpus to generate a
large number of audio test cases, something which CrossASR++ is not capable of.
In addition, ASDF implements more metrics to evaluate the performance of ASR
systems from multiple perspectives. ASDF performs phonetic analysis on the
identified failed test cases to identify the phonemes that ASR systems tend to
transcribe incorrectly, providing useful information for developers to improve
ASR systems. The demonstration video of our tool is made online at
https://www.youtube.com/watch?v=DzVwfc3h9As. The implementation is available at
https://github.com/danielyuenhx/asdf-differential-testing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MatKB: Semantic Search for Polycrystalline Materials Synthesis Procedures. (arXiv:2302.05597v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05597">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a novel approach to knowledge extraction and
retrieval using Natural Language Processing (NLP) techniques for material
science. Our goal is to automatically mine structured knowledge from millions
of research articles in the field of polycrystalline materials and make it
easily accessible to the broader community. The proposed method leverages NLP
techniques such as entity recognition and document classification to extract
relevant information and build an extensive knowledge base, from a collection
of 9.5 Million publications. The resulting knowledge base is integrated into a
search engine, which enables users to search for information about specific
materials, properties, and experiments with greater precision than traditional
search engines like Google. We hope our results can enable material scientists
quickly locate desired experimental procedures, compare their differences, and
even inspire them to design new experiments. Our website will be available at
Github \footnote{https://github.com/Xianjun-Yang/PcMSP.git} soon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emotion Detection From Social Media Posts. (arXiv:2302.05610v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05610">
<div class="article-summary-box-inner">
<span><p>Over the last few years, social media has evolved into a medium for
expressing personal views, emotions, and even business and political proposals,
recommendations, and advertisements. We address the topic of identifying
emotions from text data obtained from social media posts like Twitter in this
research. We have deployed different traditional machine learning techniques
such as Support Vector Machines (SVM), Naive Bayes, Decision Trees, and Random
Forest, as well as deep neural network models such as LSTM, CNN, GRU, BiLSTM,
BiGRU to classify these tweets into four emotion categories (Fear, Anger, Joy,
and Sadness). Furthermore, we have constructed a BiLSTM and BiGRU ensemble
model. The evaluation result shows that the deep neural network models(BiGRU,
to be specific) produce the most promising results compared to traditional
machine learning models, with an 87.53 % accuracy rate. The ensemble model
performs even better (87.66 %), albeit the difference is not significant. This
result will aid in the development of a decision-making tool that visualizes
emotional fluctuations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Metaphor Detection with Effective Context Denoising. (arXiv:2302.05611v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05611">
<div class="article-summary-box-inner">
<span><p>We propose a novel RoBERTa-based model, RoPPT, which introduces a
target-oriented parse tree structure in metaphor detection. Compared to
existing models, RoPPT focuses on semantically relevant information and
achieves the state-of-the-art on several main metaphor datasets. We also
compare our approach against several popular denoising and pruning methods,
demonstrating the effectiveness of our approach in context denoising. Our code
and dataset can be found at https://github.com/MajiBear000/RoPPT
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating the Robustness of Discrete Prompts. (arXiv:2302.05619v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05619">
<div class="article-summary-box-inner">
<span><p>Discrete prompts have been used for fine-tuning Pre-trained Language Models
for diverse NLP tasks. In particular, automatic methods that generate discrete
prompts from a small set of training instances have reported superior
performance. However, a closer look at the learnt prompts reveals that they
contain noisy and counter-intuitive lexical constructs that would not be
encountered in manually-written prompts. This raises an important yet
understudied question regarding the robustness of automatically learnt discrete
prompts when used in downstream tasks. To address this question, we conduct a
systematic study of the robustness of discrete prompts by applying carefully
designed perturbations into an application using AutoPrompt and then measure
their performance in two Natural Language Inference (NLI) datasets. Our
experimental results show that although the discrete prompt-based method
remains relatively robust against perturbations to NLI inputs, they are highly
sensitive to other types of perturbations such as shuffling and deletion of
prompt tokens. Moreover, they generalize poorly across different NLI datasets.
We hope our findings will inspire future work on robust discrete prompt
learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dialectograms: Machine Learning Differences between Discursive Communities. (arXiv:2302.05657v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05657">
<div class="article-summary-box-inner">
<span><p>Word embeddings provide an unsupervised way to understand differences in word
usage between discursive communities. A number of recent papers have focused on
identifying words that are used differently by two or more communities. But
word embeddings are complex, high-dimensional spaces and a focus on identifying
differences only captures a fraction of their richness. Here, we take a step
towards leveraging the richness of the full embedding space, by using word
embeddings to map out how words are used differently. Specifically, we describe
the construction of dialectograms, an unsupervised way to visually explore the
characteristic ways in which each community use a focal word. Based on these
dialectograms, we provide a new measure of the degree to which words are used
differently that overcomes the tendency for existing measures to pick out low
frequent or polysemous words. We apply our methods to explore the discourses of
two US political subreddits and show how our methods identify stark affective
polarisation of politicians and political entities, differences in the
assessment of proper political action as well as disagreement about whether
certain issues require political intervention at all.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DocILE Benchmark for Document Information Localization and Extraction. (arXiv:2302.05658v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05658">
<div class="article-summary-box-inner">
<span><p>This paper introduces the DocILE benchmark with the largest dataset of
business documents for the tasks of Key Information Localization and Extraction
and Line Item Recognition. It contains 6.7k annotated business documents, 100k
synthetically generated documents, and nearly~1M unlabeled documents for
unsupervised pre-training. The dataset has been built with knowledge of domain-
and task-specific aspects, resulting in the following key features: (i)
annotations in 55 classes, which surpasses the granularity of previously
published key information extraction datasets by a large margin; (ii) Line Item
Recognition represents a highly practical information extraction task, where
key information has to be assigned to items in a table; (iii) documents come
from numerous layouts and the test set includes zero- and few-shot cases as
well as layouts commonly seen in the training set. The benchmark comes with
several baselines, including RoBERTa, LayoutLMv3 and DETR-based Table
Transformer. These baseline models were applied to both tasks of the DocILE
benchmark, with results shared in this paper, offering a quick starting point
for future work. The dataset and baselines are available at
https://github.com/rossumai/docile.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counter-GAP: Counterfactual Bias Evaluation through Gendered Ambiguous Pronouns. (arXiv:2302.05674v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05674">
<div class="article-summary-box-inner">
<span><p>Bias-measuring datasets play a critical role in detecting biased behavior of
language models and in evaluating progress of bias mitigation methods. In this
work, we focus on evaluating gender bias through coreference resolution, where
previous datasets are either hand-crafted or fail to reliably measure an
explicitly defined bias. To overcome these shortcomings, we propose a novel
method to collect diverse, natural, and minimally distant text pairs via
counterfactual generation, and construct Counter-GAP, an annotated dataset
consisting of 4008 instances grouped into 1002 quadruples. We further identify
a bias cancellation problem in previous group-level metrics on Counter-GAP, and
propose to use the difference between inconsistency across genders and within
genders to measure bias at a quadruple level. Our results show that four
pre-trained language models are significantly more inconsistent across
different gender groups than within each group, and that a name-based
counterfactual data augmentation method is more effective to mitigate such bias
than an anonymization-based method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Compositional Exemplars for In-context Learning. (arXiv:2302.05698v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05698">
<div class="article-summary-box-inner">
<span><p>Large pretrained language models (LMs) have shown impressive In-Context
Learning (ICL) ability, where the model learns to do an unseen task via a
prompt consisting of input-output examples as the demonstration, without any
parameter updates. The performance of ICL is highly dominated by the quality of
the selected in-context examples. However, previous selection methods are
mostly based on simple heuristics, leading to sub-optimal performance. In this
work, we formulate in-context example selection as a subset selection problem.
We propose CEIL(Compositional Exemplars for In-context Learning), which is
instantiated by Determinantal Point Processes (DPPs) to model the interaction
between the given input and in-context examples, and optimized through a
carefully-designed contrastive learning objective to obtain preference from
LMs. We validate CEIL on 12 classification and generation datasets from 7
distinct NLP tasks, including sentiment analysis, paraphrase detection, natural
language inference, commonsense reasoning, open-domain question answering, code
generation, and semantic parsing. Extensive experiments demonstrate not only
the state-of-the-art performance but also the transferability and
compositionality of CEIL, shedding new light on effective and efficient
in-context learning. Our code is released at
https://github.com/HKUNLP/icl-ceil.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HateProof: Are Hateful Meme Detection Systems really Robust?. (arXiv:2302.05703v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05703">
<div class="article-summary-box-inner">
<span><p>Exploiting social media to spread hate has tremendously increased over the
years. Lately, multi-modal hateful content such as memes has drawn relatively
more traction than uni-modal content. Moreover, the availability of implicit
content payloads makes them fairly challenging to be detected by existing
hateful meme detection systems. In this paper, we present a use case study to
analyze such systems' vulnerabilities against external adversarial attacks. We
find that even very simple perturbations in uni-modal and multi-modal settings
performed by humans with little knowledge about the model can make the existing
detection models highly vulnerable. Empirically, we find a noticeable
performance drop of as high as 10% in the macro-F1 score for certain attacks.
As a remedy, we attempt to boost the model's robustness using contrastive
learning as well as an adversarial training-based method - VILLA. Using an
ensemble of the above two approaches, in two of our high resolution datasets,
we are able to (re)gain back the performance to a large extent for certain
attacks. We believe that ours is a first step toward addressing this crucial
problem in an adversarial setting and would inspire more such investigations in
the future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MTTM: Metamorphic Testing for Textual Content Moderation Software. (arXiv:2302.05706v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05706">
<div class="article-summary-box-inner">
<span><p>The exponential growth of social media platforms such as Twitter and Facebook
has revolutionized textual communication and textual content publication in
human society. However, they have been increasingly exploited to propagate
toxic content, such as hate speech, malicious advertisement, and pornography,
which can lead to highly negative impacts (e.g., harmful effects on teen mental
health). Researchers and practitioners have been enthusiastically developing
and extensively deploying textual content moderation software to address this
problem. However, we find that malicious users can evade moderation by changing
only a few words in the toxic content. Moreover, modern content moderation
software performance against malicious inputs remains underexplored. To this
end, we propose MTTM, a Metamorphic Testing framework for Textual content
Moderation software. Specifically, we conduct a pilot study on 2,000 text
messages collected from real users and summarize eleven metamorphic relations
across three perturbation levels: character, word, and sentence. MTTM employs
these metamorphic relations on toxic textual contents to generate test cases,
which are still toxic yet likely to evade moderation. In our evaluation, we
employ MTTM to test three commercial textual content moderation software and
two state-of-the-art moderation algorithms against three kinds of toxic
content. The results show that MTTM achieves up to 83.9%, 51%, and 82.5% error
finding rates (EFR) when testing commercial moderation software provided by
Google, Baidu, and Huawei, respectively, and it obtains up to 91.2% EFR when
testing the state-of-the-art algorithms from the academy. In addition, we
leverage the test cases generated by MTTM to retrain the model we explored,
which largely improves model robustness (0% to 5.9% EFR) while maintaining the
accuracy on the original test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fair Enough: Standardizing Evaluation and Model Selection for Fairness Research in NLP. (arXiv:2302.05711v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05711">
<div class="article-summary-box-inner">
<span><p>Modern NLP systems exhibit a range of biases, which a growing literature on
model debiasing attempts to correct. However current progress is hampered by a
plurality of definitions of bias, means of quantification, and oftentimes vague
relation between debiasing algorithms and theoretical measures of bias. This
paper seeks to clarify the current situation and plot a course for meaningful
progress in fair learning, with two key contributions: (1) making clear
inter-relations among the current gamut of methods, and their relation to
fairness theory; and (2) addressing the practical problem of model selection,
which involves a trade-off between fairness and accuracy and has led to
systemic issues in fairness research. Putting them together, we make several
recommendations to help shape future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning by Applying: A General Framework for Mathematical Reasoning via Enhancing Explicit Knowledge Learning. (arXiv:2302.05717v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05717">
<div class="article-summary-box-inner">
<span><p>Mathematical reasoning is one of the crucial abilities of general artificial
intelligence, which requires machines to master mathematical logic and
knowledge from solving problems. However, existing approaches are not
transparent (thus not interpretable) in terms of what knowledge has been
learned and applied in the reasoning process. In this paper, we propose a
general Learning by Applying (LeAp) framework to enhance existing models
(backbones) in a principled way by explicit knowledge learning. In LeAp, we
perform knowledge learning in a novel problem-knowledge-expression paradigm,
with a Knowledge Encoder to acquire knowledge from problem data and a Knowledge
Decoder to apply knowledge for expression reasoning. The learned mathematical
knowledge, including word-word relations and word-operator relations, forms an
explicit knowledge graph, which bridges the knowledge "learning" and "applying"
organically. Moreover, for problem solving, we design a semantics-enhanced
module and a reasoning-enhanced module that apply knowledge to improve the
problem comprehension and symbol reasoning abilities of any backbone,
respectively. We theoretically prove the superiority of LeAp's autonomous
learning mechanism. Experiments on three real-world datasets show that LeAp
improves all backbones' performances, learns accurate knowledge, and achieves a
more interpretable reasoning process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Synthesizing Human Gaze Feedback for Improved NLP Performance. (arXiv:2302.05721v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05721">
<div class="article-summary-box-inner">
<span><p>Integrating human feedback in models can improve the performance of natural
language processing (NLP) models. Feedback can be either explicit (e.g. ranking
used in training language models) or implicit (e.g. using human cognitive
signals in the form of eyetracking). Prior eye tracking and NLP research reveal
that cognitive processes, such as human scanpaths, gleaned from human gaze
patterns aid in the understanding and performance of NLP models. However, the
collection of real eyetracking data for NLP tasks is challenging due to the
requirement of expensive and precise equipment coupled with privacy invasion
issues. To address this challenge, we propose ScanTextGAN, a novel model for
generating human scanpaths over text. We show that ScanTextGAN-generated
scanpaths can approximate meaningful cognitive signals in human gaze patterns.
We include synthetically generated scanpaths in four popular NLP tasks spanning
six different datasets as proof of concept and show that the models augmented
with generated scanpaths improve the performance of all downstream NLP tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Brief Report on LawGPT 1.0: A Virtual Legal Assistant Based on GPT-3. (arXiv:2302.05729v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05729">
<div class="article-summary-box-inner">
<span><p>LawGPT 1.0 is a virtual legal assistant built on the state-of-the-art
language model GPT-3, fine-tuned for the legal domain. The system is designed
to provide legal assistance to users in a conversational manner, helping them
with tasks such as answering legal questions, generating legal documents, and
providing legal advice. In this paper, we provide a brief overview of LawGPT
1.0, its architecture, and its performance on a set of legal benchmark tasks.
Please note that the detailed information about the model is protected by a
non-disclosure agreement (NDA) and cannot be disclosed in this report.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Divergence-Based Domain Transferability for Zero-Shot Classification. (arXiv:2302.05735v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05735">
<div class="article-summary-box-inner">
<span><p>Transferring learned patterns from pretrained neural language models has been
shown to significantly improve effectiveness across a variety of language-based
tasks, meanwhile further tuning on intermediate tasks has been demonstrated to
provide additional performance benefits, provided the intermediate task is
sufficiently related to the target task. However, how to identify related tasks
is an open problem, and brute-force searching effective task combinations is
prohibitively expensive. Hence, the question arises, are we able to improve the
effectiveness and efficiency of tasks with no training examples through
selective fine-tuning? In this paper, we explore statistical measures that
approximate the divergence between domain representations as a means to
estimate whether tuning using one task pair will exhibit performance benefits
over tuning another. This estimation can then be used to reduce the number of
task pairs that need to be tested by eliminating pairs that are unlikely to
provide benefits. Through experimentation over 58 tasks and over 6,600 task
pair combinations, we demonstrate that statistical measures can distinguish
effective task pairs, and the resulting estimates can reduce end-to-end runtime
by up to 40%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Reparameterized Discrete Diffusion Model for Text Generation. (arXiv:2302.05737v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05737">
<div class="article-summary-box-inner">
<span><p>This work studies discrete diffusion probabilistic models with applications
to natural language generation. We derive an alternative yet equivalent
formulation of the sampling from discrete diffusion processes and leverage this
insight to develop a family of reparameterized discrete diffusion models. The
derived generic framework is highly flexible, offers a fresh perspective of the
generation process in discrete diffusion models, and features more effective
training and decoding techniques. We conduct extensive experiments to evaluate
the text generation capability of our model, demonstrating significant
improvements over existing diffusion models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Sign Recognition with Phonology. (arXiv:2302.05759v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05759">
<div class="article-summary-box-inner">
<span><p>We use insights from research on American Sign Language (ASL) phonology to
train models for isolated sign language recognition (ISLR), a step towards
automatic sign language understanding. Our key insight is to explicitly
recognize the role of phonology in sign production to achieve more accurate
ISLR than existing work which does not consider sign language phonology. We
train ISLR models that take in pose estimations of a signer producing a single
sign to predict not only the sign but additionally its phonological
characteristics, such as the handshape. These auxiliary predictions lead to a
nearly 9% absolute gain in sign recognition accuracy on the WLASL benchmark,
with consistent improvements in ISLR regardless of the underlying prediction
model architecture. This work has the potential to accelerate linguistic
research in the domain of signed languages and reduce communication barriers
between deaf and hearing people.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Level Generation Through Large Language Models. (arXiv:2302.05817v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05817">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) are powerful tools, capable of leveraging their
training on natural language to write stories, generate code, and answer
questions. But can they generate functional video game levels? Game levels,
with their complex functional constraints and spatial relationships in more
than one dimension, are very different from the kinds of data an LLM typically
sees during training. Datasets of game levels are also hard to come by,
potentially taxing the abilities of these data-hungry models. We investigate
the use of LLMs to generate levels for the game Sokoban, finding that LLMs are
indeed capable of doing so, and that their performance scales dramatically with
dataset size. We also perform preliminary experiments on controlling LLM level
generators and discuss promising areas for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"Why is this misleading?": Detecting News Headline Hallucinations with Explanations. (arXiv:2302.05852v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05852">
<div class="article-summary-box-inner">
<span><p>Automatic headline generation enables users to comprehend ongoing news events
promptly and has recently become an important task in web mining and natural
language processing. With the growing need for news headline generation, we
argue that the hallucination issue, namely the generated headlines being not
supported by the original news stories, is a critical challenge for the
deployment of this feature in web-scale systems Meanwhile, due to the
infrequency of hallucination cases and the requirement of careful reading for
raters to reach the correct consensus, it is difficult to acquire a large
dataset for training a model to detect such hallucinations through human
curation. In this work, we present a new framework named ExHalder to address
this challenge for headline hallucination detection. ExHalder adapts the
knowledge from public natural language inference datasets into the news domain
and learns to generate natural language sentences to explain the hallucination
detection results. To evaluate the model performance, we carefully collect a
dataset with more than six thousand labeled &lt;article, headline&gt; pairs.
Extensive experiments on this dataset and another six public ones demonstrate
that ExHalder can identify hallucinated headlines accurately and justifies its
predictions with human-readable natural language explanations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Position Matters! Empirical Study of Order Effect in Knowledge-grounded Dialogue. (arXiv:2302.05888v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05888">
<div class="article-summary-box-inner">
<span><p>With the power of large pretrained language models, various research works
have integrated knowledge into dialogue systems. The traditional techniques
treat knowledge as part of the input sequence for the dialogue system,
prepending a set of knowledge statements in front of dialogue history. However,
such a mechanism forces knowledge sets to be concatenated in an ordered manner,
making models implicitly pay imbalanced attention to the sets during training.
In this paper, we first investigate how the order of the knowledge set can
influence autoregressive dialogue systems' responses. We conduct experiments on
two commonly used dialogue datasets with two types of transformer-based models
and find that models view the input knowledge unequally. To this end, we
propose a simple and novel technique to alleviate the order effect by modifying
the position embeddings of knowledge input in these models. With the proposed
position embedding method, the experimental results show that each knowledge
statement is uniformly considered to generate responses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TextDefense: Adversarial Text Detection based on Word Importance Entropy. (arXiv:2302.05892v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05892">
<div class="article-summary-box-inner">
<span><p>Currently, natural language processing (NLP) models are wildly used in
various scenarios. However, NLP models, like all deep models, are vulnerable to
adversarially generated text. Numerous works have been working on mitigating
the vulnerability from adversarial attacks. Nevertheless, there is no
comprehensive defense in existing works where each work targets a specific
attack category or suffers from the limitation of computation overhead,
irresistible to adaptive attack, etc.
</p>
<p>In this paper, we exhaustively investigate the adversarial attack algorithms
in NLP, and our empirical studies have discovered that the attack algorithms
mainly disrupt the importance distribution of words in a text. A well-trained
model can distinguish subtle importance distribution differences between clean
and adversarial texts. Based on this intuition, we propose TextDefense, a new
adversarial example detection framework that utilizes the target model's
capability to defend against adversarial attacks while requiring no prior
knowledge. TextDefense differs from previous approaches, where it utilizes the
target model for detection and thus is attack type agnostic. Our extensive
experiments show that TextDefense can be applied to different architectures,
datasets, and attack methods and outperforms existing methods. We also discover
that the leading factor influencing the performance of TextDefense is the
target model's generalizability. By analyzing the property of the target model
and the property of the adversarial example, we provide our insights into the
adversarial attacks in NLP and the principles of our defense method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discourse Structure Extraction from Pre-Trained and Fine-Tuned Language Models in Dialogues. (arXiv:2302.05895v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05895">
<div class="article-summary-box-inner">
<span><p>Discourse processing suffers from data sparsity, especially for dialogues. As
a result, we explore approaches to build discourse structures for dialogues,
based on attention matrices from Pre-trained Language Models (PLMs). We
investigate multiple tasks for fine-tuning and show that the dialogue-tailored
Sentence Ordering task performs best. To locate and exploit discourse
information in PLMs, we propose an unsupervised and a semi-supervised method.
Our proposals achieve encouraging results on the STAC corpus, with F1 scores of
57.2 and 59.3 for unsupervised and semi-supervised methods, respectively. When
restricted to projective trees, our scores improved to 63.3 and 68.1.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Entanglement as a Method to Reduce Uncertainty. (arXiv:2302.05898v1 [q-bio.NC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05898">
<div class="article-summary-box-inner">
<span><p>In physics, entanglement 'reduces' the entropy of an entity, because the (von
Neumann) entropy of, e.g., a composite bipartite entity in a pure entangled
state is systematically lower than the entropy of the component sub-entities.
We show here that this 'genuinely non-classical reduction of entropy as a
result of composition' also holds whenever two concepts combine in human
cognition and, more generally, it is valid in human culture. We exploit these
results and make a 'new hypothesis' on the nature of entanglement, namely, the
production of entanglement in the preparation of a composite entity can be seen
as a 'dynamical process of collaboration between its sub-entities to reduce
uncertainty', because the composite entity is in a pure state while its
sub-entities are in a non-pure, or density, state, as a result of the
preparation. We identify within the nature of this entanglement a mechanism of
contextual updating and illustrate the mechanism in the example we analyze. Our
hypothesis naturally explains the 'non-classical nature' of some quantum
logical connectives, as due to Bell-type correlations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating the Effect of Relative Positional Embeddings on AMR-to-Text Generation with Structural Adapters. (arXiv:2302.05900v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05900">
<div class="article-summary-box-inner">
<span><p>Text generation from Abstract Meaning Representation (AMR) has substantially
benefited from the popularized Pretrained Language Models (PLMs). Myriad
approaches have linearized the input graph as a sequence of tokens to fit the
PLM tokenization requirements. Nevertheless, this transformation jeopardizes
the structural integrity of the graph and is therefore detrimental to its
resulting representation. To overcome this issue, Ribeiro et al. have recently
proposed StructAdapt, a structure-aware adapter which injects the input graph
connectivity within PLMs using Graph Neural Networks (GNNs). In this paper, we
investigate the influence of Relative Position Embeddings (RPE) on AMR-to-Text,
and, in parallel, we examine the robustness of StructAdapt. Through ablation
studies, graph attack and link prediction, we reveal that RPE might be
partially encoding input graphs. We suggest further research regarding the role
of RPE will provide valuable insights for Graph-to-Text generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Extended Sequence Tagging Vocabulary for Grammatical Error Correction. (arXiv:2302.05913v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05913">
<div class="article-summary-box-inner">
<span><p>We extend a current sequence-tagging approach to Grammatical Error Correction
(GEC) by introducing specialised tags for spelling correction and morphological
inflection using the SymSpell and LemmInflect algorithms. Our approach improves
generalisation: the proposed new tagset allows a smaller number of tags to
correct a larger range of errors. Our results show a performance improvement
both overall and in the targeted error categories. We further show that
ensembles trained with our new tagset outperform those trained with the
baseline tagset on the public BEA benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stabilized In-Context Learning with Pre-trained Language Models for Few Shot Dialogue State Tracking. (arXiv:2302.05932v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05932">
<div class="article-summary-box-inner">
<span><p>Prompt-based methods with large pre-trained language models (PLMs) have shown
impressive unaided performance across many NLP tasks. These models improve even
further with the addition of a few labeled in-context exemplars to guide output
generation. However, for more complex tasks such as dialogue state tracking
(DST), designing prompts that reliably convey the desired intent is nontrivial,
leading to unstable results. Furthermore, building in-context exemplars for
dialogue tasks is difficult because conversational contexts are long while
model input lengths are relatively short. To overcome these issues we first
adapt a meta-learning scheme to the dialogue domain which stabilizes the
ability of the model to perform well under various prompts. We additionally
design a novel training method to improve upon vanilla retrieval mechanisms to
find ideal in-context examples. Finally, we introduce a saliency model to limit
dialogue text length, allowing us to include more exemplars per query. In
effect, we are able to achieve highly competitive results for few-shot DST on
MultiWOZ.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analyzing the Effectiveness of the Underlying Reasoning Tasks in Multi-hop Question Answering. (arXiv:2302.05963v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05963">
<div class="article-summary-box-inner">
<span><p>To explain the predicted answers and evaluate the reasoning abilities of
models, several studies have utilized underlying reasoning (UR) tasks in
multi-hop question answering (QA) datasets. However, it remains an open
question as to how effective UR tasks are for the QA task when training models
on both tasks in an end-to-end manner. In this study, we address this question
by analyzing the effectiveness of UR tasks (including both sentence-level and
entity-level tasks) in three aspects: (1) QA performance, (2) reasoning
shortcuts, and (3) robustness. While the previous models have not been
explicitly trained on an entity-level reasoning prediction task, we build a
multi-task model that performs three tasks together: sentence-level supporting
facts prediction, entity-level reasoning prediction, and answer prediction.
Experimental results on 2WikiMultiHopQA and HotpotQA-small datasets reveal that
(1) UR tasks can improve QA performance. Using four debiased datasets that are
newly created, we demonstrate that (2) UR tasks are helpful in preventing
reasoning shortcuts in the multi-hop QA task. However, we find that (3) UR
tasks do not contribute to improving the robustness of the model on adversarial
questions, such as sub-questions and inverted questions. We encourage future
studies to investigate the effectiveness of entity-level reasoning in the form
of natural language questions (e.g., sub-question forms).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decoupling the Skeleton Parsing and Schema Linking for Text-to-SQL. (arXiv:2302.05965v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05965">
<div class="article-summary-box-inner">
<span><p>One of the recent best attempts at Text-to-SQL is the pre-trained language
model. Due to the structural property of the SQL queries, the seq2seq model
takes the responsibility of parsing both the schema items (i.e., tables and
columns) and the skeleton (i.e., SQL keywords). Such coupled targets increase
the difficulty of parsing the correct SQL queries especially when they involve
many schema items and logic operators. This paper proposes a ranking-enhanced
encoding and skeleton-aware decoding framework to decouple the schema linking
and the skeleton parsing. Specifically, for a seq2seq encoder-decode model, its
encoder is injected by the most relevant schema items instead of the whole
unordered ones, which could alleviate the schema linking effort during SQL
parsing, and its decoder first generates the skeleton and then the actual SQL
query, which could implicitly constrain the SQL parsing. We evaluate our
proposed framework on Spider and its three robustness variants: Spider-DK,
Spider-Syn, and Spider-Realistic. The experimental results show that our
framework delivers promising performance and robustness. Our code is available
at https://github.com/RUCKBReasoning/RESDSQL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MarioGPT: Open-Ended Text2Level Generation through Large Language Models. (arXiv:2302.05981v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05981">
<div class="article-summary-box-inner">
<span><p>Procedural Content Generation (PCG) algorithms provide a technique to
generate complex and diverse environments in an automated way. However, while
generating content with PCG methods is often straightforward, generating
meaningful content that reflects specific intentions and constraints remains
challenging. Furthermore, many PCG algorithms lack the ability to generate
content in an open-ended manner. Recently, Large Language Models (LLMs) have
shown to be incredibly effective in many diverse domains. These trained LLMs
can be fine-tuned, re-using information and accelerating training for new
tasks. In this work, we introduce MarioGPT, a fine-tuned GPT2 model trained to
generate tile-based game levels, in our case Super Mario Bros levels. We show
that MarioGPT can not only generate diverse levels, but can be text-prompted
for controllable level generation, addressing one of the key challenges of
current PCG techniques. As far as we know, MarioGPT is the first text-to-level
model. We also combine MarioGPT with novelty search, enabling it to generate
diverse levels with varying play-style dynamics (i.e. player paths). This
combination allows for the open-ended generation of an increasingly diverse
range of content.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ASR Bundestag: A Large-Scale political debate dataset in German. (arXiv:2302.06008v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.06008">
<div class="article-summary-box-inner">
<span><p>We present ASR Bundestag, a dataset for automatic speech recognition in
German, consisting of 610 hours of aligned audio-transcript pairs for
supervised training as well as 1,038 hours of unlabeled audio snippets for
self-supervised learning, based on raw audio data and transcriptions from
plenary sessions and committee meetings of the German parliament. In addition,
we discuss utilized approaches for the automated creation of speech datasets
and assess the quality of the resulting dataset based on evaluations and
finetuning of a pre-trained state of the art model. We make the dataset
publicly available, including all subsets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey on Publicly Available Sinhala Natural Language Processing Tools and Research. (arXiv:1906.02358v17 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.02358">
<div class="article-summary-box-inner">
<span><p>Sinhala is the native language of the Sinhalese people who make up the
largest ethnic group of Sri Lanka. The language belongs to the globe-spanning
language tree, Indo-European. However, due to poverty in both linguistic and
economic capital, Sinhala, in the perspective of Natural Language Processing
tools and research, remains a resource-poor language which has neither the
economic drive its cousin English has nor the sheer push of the law of numbers
a language such as Chinese has. A number of research groups from Sri Lanka have
noticed this dearth and the resultant dire need for proper tools and research
for Sinhala natural language processing. However, due to various reasons, these
attempts seem to lack coordination and awareness of each other. The objective
of this paper is to fill that gap of a comprehensive literature survey of the
publicly available Sinhala natural language tools and research so that the
researchers working in this field can better utilize contributions of their
peers. As such, we shall be uploading this paper to arXiv and perpetually
update it periodically to reflect the advances made in the field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The emojification of sentiment on social media: Collection and analysis of a longitudinal Twitter sentiment dataset. (arXiv:2108.13898v2 [cs.SI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13898">
<div class="article-summary-box-inner">
<span><p>Social media, as a means for computer-mediated communication, has been
extensively used to study the sentiment expressed by users around events or
topics. There is however a gap in the longitudinal study of how sentiment
evolved in social media over the years. To fill this gap, we develop TM-Senti,
a new large-scale, distantly supervised Twitter sentiment dataset with over 184
million tweets and covering a time period of over seven years. We describe and
assess our methodology to put together a large-scale, emoticon- and emoji-based
labelled sentiment analysis dataset, along with an analysis of the resulting
dataset. Our analysis highlights interesting temporal changes, among others in
the increasing use of emojis over emoticons. We publicly release the dataset
for further research in tasks including sentiment analysis and text
classification of tweets. The dataset can be fully rehydrated including tweet
metadata and without missing tweets thanks to the archive of tweets publicly
available on the Internet Archive, which the dataset is based on.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Multi-modal Summarization. (arXiv:2109.05199v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05199">
<div class="article-summary-box-inner">
<span><p>The new era of technology has brought us to the point where it is convenient
for people to share their opinions over an abundance of platforms. These
platforms have a provision for the users to express themselves in multiple
forms of representations, including text, images, videos, and audio. This,
however, makes it difficult for users to obtain all the key information about a
topic, making the task of automatic multi-modal summarization (MMS) essential.
In this paper, we present a comprehensive survey of the existing research in
the area of MMS, covering various modalities like text, image, audio, and
video. Apart from highlighting the different evaluation metrics and datasets
used for the MMS task, our work also discusses the current challenges and
future directions in this field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PECO: Examining Single Sentence Label Leakage in Natural Language Inference Datasets through Progressive Evaluation of Cluster Outliers. (arXiv:2112.09237v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.09237">
<div class="article-summary-box-inner">
<span><p>Building natural language inference (NLI) benchmarks that are both
challenging for modern techniques, and free from shortcut biases is difficult.
Chief among these biases is "single sentence label leakage," where
annotator-introduced spurious correlations yield datasets where the logical
relation between (premise, hypothesis) pairs can be accurately predicted from
only a single sentence, something that should in principle be impossible. We
demonstrate that despite efforts to reduce this leakage, it persists in modern
datasets that have been introduced since its 2018 discovery. To enable future
amelioration efforts, introduce a novel model-driven technique, the progressive
evaluation of cluster outliers (PECO) which enables both the objective
measurement of leakage, and the automated detection of subpopulations in the
data which maximally exhibit it.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The NLP Task Effectiveness of Long-Range Transformers. (arXiv:2202.07856v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.07856">
<div class="article-summary-box-inner">
<span><p>Transformer models cannot easily scale to long sequences due to their O(N^2)
time and space complexity. This has led to Transformer variants seeking to
lower computational complexity, such as Longformer and Performer. While such
models have theoretically greater efficiency, their effectiveness on real NLP
tasks has not been well studied. We benchmark 7 variants of Transformer models
on 5 difficult NLP tasks and 7 datasets. We design experiments to isolate the
effect of pretraining and hyperparameter settings, to focus on their capacity
for long-range attention. Moreover, we present various methods to investigate
attention behaviors to illuminate model details beyond metric scores. We find
that the modified attention in long-range transformers has advantages on
content selection and query-guided decoding, but they come with previously
unrecognized drawbacks such as insufficient attention to distant tokens and
accumulated approximation error.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">USCORE: An Effective Approach to Fully Unsupervised Evaluation Metrics for Machine Translation. (arXiv:2202.10062v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.10062">
<div class="article-summary-box-inner">
<span><p>The vast majority of evaluation metrics for machine translation are
supervised, i.e., (i) are trained on human scores, (ii) assume the existence of
reference translations, or (iii) leverage parallel data. This hinders their
applicability to cases where such supervision signals are not available. In
this work, we develop fully unsupervised evaluation metrics. To do so, we
leverage similarities and synergies between evaluation metric induction,
parallel corpus mining, and MT systems. In particular, we use an unsupervised
evaluation metric to mine pseudo-parallel data, which we use to remap deficient
underlying vector spaces (in an iterative manner) and to induce an unsupervised
MT system, which then provides pseudo-references as an additional component in
the metric. Finally, we also induce unsupervised multilingual sentence
embeddings from pseudo-parallel data. We show that our fully unsupervised
metrics are effective, i.e., they beat supervised competitors on 4 out of our 5
evaluation datasets. We make our code publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A survey in Adversarial Defences and Robustness in NLP. (arXiv:2203.06414v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.06414">
<div class="article-summary-box-inner">
<span><p>In recent years, it has been seen that deep neural networks are lacking
robustness and are vulnerable in case of adversarial perturbations in input
data. Strong adversarial attacks are proposed by various authors for tasks
under computer vision and Natural Language Processing (NLP). As a
counter-effort, several defense mechanisms are also proposed to save these
networks from failing. Defending the neural networks from adversarial attacks
has its own importance, where the goal is to ensure that the model's prediction
doesn't change if input data is perturbed. Numerous methods for adversarial
defense in NLP are proposed of late, for different NLP tasks such as text
classification, named entity recognition, natural language inferencing, etc.
Some of these methods are not just used for defending neural networks from
adversarial attacks, but also used as a regularization mechanism during
training, saving the model from overfitting. The proposed survey is an attempt
to review different methods proposed for adversarial defenses in NLP in recent
years by proposing a novel taxonomy. This survey also highlights the fragility
of the advanced deep neural networks in NLP and the challenges in defending
them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluation of Fake News Detection with Knowledge-Enhanced Language Models. (arXiv:2204.00458v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.00458">
<div class="article-summary-box-inner">
<span><p>Recent advances in fake news detection have exploited the success of
large-scale pre-trained language models (PLMs). The predominant
state-of-the-art approaches are based on fine-tuning PLMs on labelled fake news
datasets. However, large-scale PLMs are generally not trained on structured
factual data and hence may not possess priors that are grounded in factually
accurate knowledge. The use of existing knowledge bases (KBs) with rich
human-curated factual information has thus the potential to make fake news
detection more effective and robust. In this paper, we investigate the impact
of knowledge integration into PLMs for fake news detection. We study several
state-of-the-art approaches for knowledge integration, mostly using Wikidata as
KB, on two popular fake news datasets - LIAR, a politics-based dataset, and
COVID-19, a dataset of messages posted on social media relating to the COVID-19
pandemic. Our experiments show that knowledge-enhanced models can significantly
improve fake news detection on LIAR where the KB is relevant and up-to-date.
The mixed results on COVID-19 highlight the reliance on stylistic features and
the importance of domain-specific and current KBs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task-specific Compression for Multi-task Language Models using Attribution-based Pruning. (arXiv:2205.04157v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.04157">
<div class="article-summary-box-inner">
<span><p>Multi-task language models show outstanding performance for various natural
language understanding tasks with only a single model. However, these language
models utilize an unnecessarily large number of model parameters, even when
used only for a specific task. This paper proposes a novel training-free
compression method for multi-task language models using a pruning method.
Specifically, we use an attribution method to determine which neurons are
essential for performing a specific task. We task-specifically prune
unimportant neurons and leave only task-specific parameters. Furthermore, we
extend our method to be applicable in low-resource and unsupervised settings.
Since our compression method is training-free, it uses few computing resources
and does not destroy the pre-trained knowledge of language models. Experimental
results on the six widely-used datasets show that our proposed pruning method
significantly outperforms baseline pruning methods. In addition, we demonstrate
that our method preserves performance even in an unseen domain setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BanglaNLG and BanglaT5: Benchmarks and Resources for Evaluating Low-Resource Natural Language Generation in Bangla. (arXiv:2205.11081v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11081">
<div class="article-summary-box-inner">
<span><p>This work presents BanglaNLG, a comprehensive benchmark for evaluating
natural language generation (NLG) models in Bangla, a widely spoken yet
low-resource language. We aggregate six challenging conditional text generation
tasks under the BanglaNLG benchmark, introducing a new dataset on dialogue
generation in the process. Furthermore, using a clean corpus of 27.5 GB of
Bangla data, we pretrain BanglaT5, a sequence-to-sequence Transformer language
model for Bangla. BanglaT5 achieves state-of-the-art performance in all of
these tasks, outperforming several multilingual models by up to 9% absolute
gain and 32% relative gain. We are making the new dialogue dataset and the
BanglaT5 model publicly available at https://github.com/csebuetnlp/BanglaNLG in
the hope of advancing future research on Bangla NLG.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Summarize and Generate to Back-translate: Unsupervised Translation of Programming Languages. (arXiv:2205.11116v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11116">
<div class="article-summary-box-inner">
<span><p>Back-translation is widely known for its effectiveness in neural machine
translation when there is little to no parallel data. In this approach, a
source-to-target model is coupled with a target-to-source model trained in
parallel. The target-to-source model generates noisy sources, while the
source-to-target model is trained to reconstruct the targets and vice versa.
Recent developments of multilingual pre-trained sequence-to-sequence models for
programming languages have been very effective for a broad spectrum of
downstream software engineering tasks. Hence, training them to build
programming language translation systems via back-translation is compelling.
However, these models cannot be further trained via back-translation since they
learn to output sequences in the same language as the inputs during
pre-training. As an alternative, we propose performing back-translation via
code summarization and generation. In code summarization, a model learns to
generate natural language (NL) summaries given code snippets. In code
generation, the model learns to do the opposite. Therefore, target-to-source
generation in back-translation can be viewed as a target-to-NL-to-source
generation. We show that our proposed approach performs competitively with
state-of-the-art methods. We have made the code publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Workflow Discovery from Dialogues in the Low Data Regime. (arXiv:2205.11690v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11690">
<div class="article-summary-box-inner">
<span><p>Text-based dialogues are now widely used to solve real-world problems. In
cases where solution strategies are already known, they can sometimes be
codified into workflows and used to guide humans or artificial agents through
the task of helping clients. We introduce a new problem formulation that we
call Workflow Discovery (WD) in which we are interested in the situation where
a formal workflow may not yet exist. Still, we wish to discover the set of
actions that have been taken to resolve a particular problem. We also examine a
sequence-to-sequence (Seq2Seq) approach for this novel task. We present
experiments where we extract workflows from dialogues in the Action-Based
Conversations Dataset (ABCD). Since the ABCD dialogues follow known workflows
to guide agents, we can evaluate our ability to extract such workflows using
ground truth sequences of actions. We propose and evaluate an approach that
conditions models on the set of possible actions, and we show that using this
strategy, we can improve WD performance. Our conditioning approach also
improves zero-shot and few-shot WD performance when transferring learned models
to unseen domains within and across datasets. Further, on ABCD a modified
variant of our Seq2Seq method achieves state-of-the-art performance on related
but different problems of Action State Tracking (AST) and Cascading Dialogue
Success (CDS) across many evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-shot Reranking for Multi-hop QA via Language Model Prompting. (arXiv:2205.12650v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12650">
<div class="article-summary-box-inner">
<span><p>We study few-shot reranking for multi-hop QA (MQA) with open-domain
questions. To alleviate the need for a large number of labeled
question-document pairs for retriever training, we propose PromptRank, which
relies on large language models prompting for multi-hop path reranking.
PromptRank first constructs an instruction-based prompt that includes a
candidate document path and then computes the relevance score between a given
question and the path based on the conditional likelihood of the question given
the path prompt according to a language model. PromptRank yields strong
retrieval performance on HotpotQA with only 128 training examples compared to
state-of-the-art methods trained on thousands of examples -- 73.6 recall@10 by
PromptRank vs. 77.8 by PathRetriever and 77.5 by multi-hop dense retrieval.
Code available at https://github.com/mukhal/PromptRank
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Task-Oriented Dialogue Systems with Response Selection as an Auxiliary Task. (arXiv:2208.07097v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.07097">
<div class="article-summary-box-inner">
<span><p>The adoption of pre-trained language models in task-oriented dialogue systems
has resulted in significant enhancements of their text generation abilities.
However, these architectures are slow to use because of the large number of
trainable parameters and can sometimes fail to generate diverse responses. To
address these limitations, we propose two models with auxiliary tasks for
response selection - (1) distinguishing distractors from ground truth responses
and (2) distinguishing synthetic responses from ground truth labels. They
achieve state-of-the-art results on the MultiWOZ 2.1 dataset with combined
scores of 107.5 and 108.3 and outperform a baseline with three times more
parameters. We publish reproducible code and checkpoints and discuss the
effects of applying auxiliary tasks to T5-based architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A new hazard event classification model via deep learning and multifractal. (arXiv:2209.05263v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.05263">
<div class="article-summary-box-inner">
<span><p>Hazard and operability analysis (HAZOP) is the paradigm of industrial safety
that can reveal the hazards of process from its node deviations, consequences,
causes, measures and suggestions, and such hazards can be considered as hazard
events (HaE). The classification research on HaE has much irreplaceable
pragmatic values. In this paper, we present a novel deep learning model termed
DLF through multifractal to explore HaE classification where the motivation is
that HaE can be naturally regarded as a kind of time series. Specifically,
first HaE is vectorized to get HaE time series by employing BERT. Then, a new
multifractal analysis method termed HmF-DFA is proposed to win HaE fractal
series by analyzing HaE time series. Finally, a new hierarchical gating neural
network (HGNN) is designed to process HaE fractal series to accomplish the
classification of HaE from three aspects: severity, possibility and risk. We
take HAZOP reports of 18 processes as cases, and launch the experiments on this
basis. Results demonstrate that compared with other classifiers, DLF classifier
performs better under metrics of precision, recall and F1-score, especially for
the severity aspect. Also, HmF-DFA and HGNN effectively promote HaE
classification. Our HaE classification system can serve application incentives
to experts, engineers, employees, and other enterprises. We hope our research
can contribute added support to the daily practice in industrial safety.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dimensions of Interpersonal Dynamics in Text: Group Membership and Fine-grained Interpersonal Emotion. (arXiv:2209.06687v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.06687">
<div class="article-summary-box-inner">
<span><p>Current studies of bias in NLP rely mainly on identifying (unwanted or
negative) bias towards a specific demographic group. While this has led to
progress recognizing and mitigating negative bias, and having a clear notion of
the targeted group is necessary, it is not always practical. In this work we
extrapolate to a broader notion of bias, rooted in social science and
psychology literature. We move towards predicting interpersonal group
relationship (IGR) - modeling the relationship between the speaker and the
target in an utterance - using fine-grained interpersonal emotions as an
anchor. We build and release a dataset of English tweets by US Congress members
annotated for interpersonal emotion -- the first of its kind, and 'found
supervision' for IGR labels; our analyses show that subtle emotional signals
are indicative of different biases. While humans can perform better than chance
at identifying IGR given an utterance, we show that neural models perform much
better; furthermore, a shared encoding between IGR and interpersonal perceived
emotion enabled performance gains in both tasks. Data and code for this paper
are available at https://github.com/venkatasg/interpersonal-bias
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Transformer Memorization Recall Through Idioms. (arXiv:2210.03588v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.03588">
<div class="article-summary-box-inner">
<span><p>To produce accurate predictions, language models (LMs) must balance between
generalization and memorization. Yet, little is known about the mechanism by
which transformer LMs employ their memorization capacity. When does a model
decide to output a memorized phrase, and how is this phrase then retrieved from
memory? In this work, we offer the first methodological framework for probing
and characterizing recall of memorized sequences in transformer LMs. First, we
lay out criteria for detecting model inputs that trigger memory recall, and
propose idioms as inputs that typically fulfill these criteria. Next, we
construct a dataset of English idioms and use it to compare model behavior on
memorized vs. non-memorized inputs. Specifically, we analyze the internal
prediction construction process by interpreting the model's hidden
representations as a gradual refinement of the output probability distribution.
We find that across different model sizes and architectures, memorized
predictions are a two-step process: early layers promote the predicted token to
the top of the output distribution, and upper layers increase model confidence.
This suggests that memorized information is stored and retrieved in the early
layers of the network. Last, we demonstrate the utility of our methodology
beyond idioms in memorized factual statements. Overall, our work makes a first
step towards understanding memory recall, and provides a methodological basis
for future studies of transformer memorization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CHARD: Clinical Health-Aware Reasoning Across Dimensions for Text Generation Models. (arXiv:2210.04191v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04191">
<div class="article-summary-box-inner">
<span><p>We motivate and introduce CHARD: Clinical Health-Aware Reasoning across
Dimensions, to investigate the capability of text generation models to act as
implicit clinical knowledge bases and generate free-flow textual explanations
about various health-related conditions across several dimensions. We collect
and present an associated dataset, CHARDat, consisting of explanations about 52
health conditions across three clinical dimensions. We conduct extensive
experiments using BART and T5 along with data augmentation, and perform
automatic, human, and qualitative analyses. We show that while our models can
perform decently, CHARD is very challenging with strong potential for further
exploration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robustification of Multilingual Language Models to Real-world Noise in Crosslingual Zero-shot Settings with Robust Contrastive Pretraining. (arXiv:2210.04782v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04782">
<div class="article-summary-box-inner">
<span><p>Advances in neural modeling have achieved state-of-the-art (SOTA) results on
public natural language processing (NLP) benchmarks, at times surpassing human
performance. However, there is a gap between public benchmarks and real-world
applications where noise, such as typographical or grammatical mistakes, is
abundant and can result in degraded performance. Unfortunately, works which
evaluate the robustness of neural models on noisy data and propose
improvements, are limited to the English language. Upon analyzing noise in
different languages, we observe that noise types vary greatly across languages.
Thus, existing investigations do not generalize trivially to multilingual
settings. To benchmark the performance of pretrained multilingual language
models, we construct noisy datasets covering five languages and four NLP tasks
and observe a clear gap in the performance between clean and noisy data in the
zero-shot cross-lingual setting. After investigating several ways to boost the
robustness of multilingual models in this setting, we propose Robust
Contrastive Pretraining (RCP). RCP combines data augmentation with a
contrastive loss term at the pretraining stage and achieves large improvements
on noisy (and original test data) across two sentence-level (+3.2%) and two
sequence-labeling (+10 F1-score) multilingual classification tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vote'n'Rank: Revision of Benchmarking with Social Choice Theory. (arXiv:2210.05769v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.05769">
<div class="article-summary-box-inner">
<span><p>The development of state-of-the-art systems in different applied areas of
machine learning (ML) is driven by benchmarks, which have shaped the paradigm
of evaluating generalisation capabilities from multiple perspectives. Although
the paradigm is shifting towards more fine-grained evaluation across diverse
tasks, the delicate question of how to aggregate the performances has received
particular interest in the community. In general, benchmarks follow the
unspoken utilitarian principles, where the systems are ranked based on their
mean average score over task-specific metrics. Such aggregation procedure has
been viewed as a sub-optimal evaluation protocol, which may have created the
illusion of progress. This paper proposes Vote'n'Rank, a framework for ranking
systems in multi-task benchmarks under the principles of the social choice
theory. We demonstrate that our approach can be efficiently utilised to draw
new insights on benchmarking in several ML sub-fields and identify the
best-performing systems in research and development case studies. The
Vote'n'Rank's procedures are more robust than the mean average while being able
to handle missing performance scores and determine conditions under which the
system becomes the winner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Federated Continual Learning for Text Classification via Selective Inter-client Transfer. (arXiv:2210.06101v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06101">
<div class="article-summary-box-inner">
<span><p>In this work, we combine the two paradigms: Federated Learning (FL) and
Continual Learning (CL) for text classification task in cloud-edge continuum.
The objective of Federated Continual Learning (FCL) is to improve deep learning
models over life time at each client by (relevant and efficient) knowledge
transfer without sharing data. Here, we address challenges in minimizing
inter-client interference while knowledge sharing due to heterogeneous tasks
across clients in FCL setup. In doing so, we propose a novel framework,
Federated Selective Inter-client Transfer (FedSeIT) which selectively combines
model parameters of foreign clients. To further maximize knowledge transfer, we
assess domain overlap and select informative tasks from the sequence of
historical tasks at each foreign client while preserving privacy. Evaluating
against the baselines, we show improved performance, a gain of (average) 12.4\%
in text classification over a sequence of tasks using five datasets from
diverse domains. To the best of our knowledge, this is the first work that
applies FCL to NLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Pretrained Language Models (Yet) Reason Deductively?. (arXiv:2210.06442v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06442">
<div class="article-summary-box-inner">
<span><p>Acquiring factual knowledge with Pretrained Language Models (PLMs) has
attracted increasing attention, showing promising performance in many
knowledge-intensive tasks. Their good performance has led the community to
believe that the models do possess a modicum of reasoning competence rather
than merely memorising the knowledge. In this paper, we conduct a comprehensive
evaluation of the learnable deductive (also known as explicit) reasoning
capability of PLMs. Through a series of controlled experiments, we posit two
main findings. (i) PLMs inadequately generalise learned logic rules and perform
inconsistently against simple adversarial surface form edits. (ii) While the
deductive reasoning fine-tuning of PLMs does improve their performance on
reasoning over unseen knowledge facts, it results in catastrophically
forgetting the previously learnt knowledge. Our main results suggest that PLMs
cannot yet perform reliable deductive reasoning, demonstrating the importance
of controlled examinations and probing of PLMs' reasoning abilities; we reach
beyond (misleading) task performance, revealing that PLMs are still far from
human-level reasoning capabilities, even for simple deductive tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Entity Tracking via Effective Use of Multi-Task Learning Model and Mention-guided Decoding. (arXiv:2210.06444v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06444">
<div class="article-summary-box-inner">
<span><p>Cross-task knowledge transfer via multi-task learning has recently made
remarkable progress in general NLP tasks. However, entity tracking on the
procedural text has not benefited from such knowledge transfer because of its
distinct formulation, i.e., tracking the event flow while following structural
constraints. State-of-the-art entity tracking approaches either design
complicated model architectures or rely on task-specific pre-training to
achieve good results. To this end, we propose MeeT, a Multi-task
learning-enabled entity Tracking approach, which utilizes knowledge gained from
general domain tasks to improve entity tracking. Specifically, MeeT first
fine-tunes T5, a pre-trained multi-task learning model, with entity
tracking-specialized QA formats, and then employs our customized decoding
strategy to satisfy the structural constraints. MeeT achieves state-of-the-art
performances on two popular entity tracking datasets, even though it does not
require any task-specific architecture design or pre-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Iterative Document-level Information Extraction via Imitation Learning. (arXiv:2210.06600v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06600">
<div class="article-summary-box-inner">
<span><p>We present a novel iterative extraction model, IterX, for extracting complex
relations, or templates, i.e., N-tuples representing a mapping from named slots
to spans of text within a document. Documents may feature zero or more
instances of a template of any given type, and the task of template extraction
entails identifying the templates in a document and extracting each template's
slot values. Our imitation learning approach casts the problem as a Markov
decision process (MDP), and relieves the need to use predefined template orders
to train an extractor. It leads to state-of-the-art results on two established
benchmarks -- 4-ary relation extraction on SciREX and template extraction on
MUC-4 -- as well as a strong baseline on the new BETTER Granular task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shortcomings of Question Answering Based Factuality Frameworks for Error Localization. (arXiv:2210.06748v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06748">
<div class="article-summary-box-inner">
<span><p>Despite recent progress in abstractive summarization, models often generate
summaries with factual errors. Numerous approaches to detect these errors have
been proposed, the most popular of which are question answering (QA)-based
factuality metrics. These have been shown to work well at predicting
summary-level factuality and have potential to localize errors within
summaries, but this latter capability has not been systematically evaluated in
past research. In this paper, we conduct the first such analysis and find that,
contrary to our expectations, QA-based frameworks fail to correctly identify
error spans in generated summaries and are outperformed by trivial exact match
baselines. Our analysis reveals a major reason for such poor localization:
questions generated by the QG module often inherit errors from non-factual
summaries which are then propagated further into downstream modules. Moreover,
even human-in-the-loop question generation cannot easily offset these problems.
Our experiments conclusively show that there exist fundamental issues with
localization using the QA framework which cannot be fixed solely by stronger QA
and QG models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Closed-book Question Generation via Contrastive Learning. (arXiv:2210.06781v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06781">
<div class="article-summary-box-inner">
<span><p>Question Generation (QG) is a fundamental NLP task for many downstream
applications. Recent studies on open-book QG, where supportive answer-context
pairs are provided to models, have achieved promising progress. However,
generating natural questions under a more practical closed-book setting that
lacks these supporting documents still remains a challenge. In this work, we
propose a new QG model for this closed-book setting that is designed to better
understand the semantics of long-form abstractive answers and store more
information in its parameters through contrastive learning and an answer
reconstruction module. Through experiments, we validate the proposed QG model
on both public datasets and a new WikiCQA dataset. Empirical results show that
the proposed QG model outperforms baselines in both automatic evaluation and
human evaluation. In addition, we show how to leverage the proposed model to
improve existing question-answering systems. These results further indicate the
effectiveness of our QG model for enhancing closed-book question-answering
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bootstrapping Multilingual Semantic Parsers using Large Language Models. (arXiv:2210.07313v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07313">
<div class="article-summary-box-inner">
<span><p>Despite cross-lingual generalization demonstrated by pre-trained multilingual
models, the translate-train paradigm of transferring English datasets across
multiple languages remains to be a key mechanism for training task-specific
multilingual models. However, for many low-resource languages, the availability
of a reliable translation service entails significant amounts of costly
human-annotated translation pairs. Further, translation services may continue
to be brittle due to domain mismatch between task-specific input text and
general-purpose text used for training translation models. For multilingual
semantic parsing, we demonstrate the effectiveness and flexibility offered by
large language models (LLMs) for translating English datasets into several
languages via few-shot prompting. Through extensive comparisons on two public
datasets, MTOP and MASSIVE, spanning 50 languages and several domains, we show
that our method of translating data using LLMs outperforms a strong
translate-train baseline on 41 out of 50 languages. We study the key design
choices that enable more effective multilingual data translation via prompted
LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mind the Labels: Describing Relations in Knowledge Graphs With Pretrained Models. (arXiv:2210.07373v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07373">
<div class="article-summary-box-inner">
<span><p>Pretrained language models (PLMs) for data-to-text (D2T) generation can use
human-readable data labels such as column headings, keys, or relation names to
generalize to out-of-domain examples. However, the models are well-known in
producing semantically inaccurate outputs if these labels are ambiguous or
incomplete, which is often the case in D2T datasets. In this paper, we expose
this issue on the task of descibing a relation between two entities. For our
experiments, we collect a novel dataset for verbalizing a diverse set of 1,522
unique relations from three large-scale knowledge graphs (Wikidata, DBPedia,
YAGO). We find that although PLMs for D2T generation expectedly fail on unclear
cases, models trained with a large variety of relation labels are surprisingly
robust in verbalizing novel, unseen relations. We argue that using data with a
diverse set of clear and meaningful labels is key to training D2T generation
systems capable of generalizing to novel domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Behavior Cloned Transformers are Neurosymbolic Reasoners. (arXiv:2210.07382v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07382">
<div class="article-summary-box-inner">
<span><p>In this work, we explore techniques for augmenting interactive agents with
information from symbolic modules, much like humans use tools like calculators
and GPS systems to assist with arithmetic and navigation. We test our agent's
abilities in text games -- challenging benchmarks for evaluating the multi-step
reasoning abilities of game agents in grounded, language-based environments.
Our experimental study indicates that injecting the actions from these symbolic
modules into the action space of a behavior cloned transformer agent increases
performance on four text game benchmarks that test arithmetic, navigation,
sorting, and common sense reasoning by an average of 22%, allowing an agent to
reach the highest possible performance on unseen games. This action injection
technique is easily extended to new agents, environments, and symbolic modules.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SQA3D: Situated Question Answering in 3D Scenes. (arXiv:2210.07474v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07474">
<div class="article-summary-box-inner">
<span><p>We propose a new task to benchmark scene understanding of embodied agents:
Situated Question Answering in 3D Scenes (SQA3D). Given a scene context (e.g.,
3D scan), SQA3D requires the tested agent to first understand its situation
(position, orientation, etc.) in the 3D scene as described by text, then reason
about its surrounding environment and answer a question under that situation.
Based upon 650 scenes from ScanNet, we provide a dataset centered around 6.8k
unique situations, along with 20.4k descriptions and 33.4k diverse reasoning
questions for these situations. These questions examine a wide spectrum of
reasoning capabilities for an intelligent agent, ranging from spatial relation
comprehension to commonsense understanding, navigation, and multi-hop
reasoning. SQA3D imposes a significant challenge to current multi-modal
especially 3D reasoning models. We evaluate various state-of-the-art approaches
and find that the best one only achieves an overall score of 47.20%, while
amateur human participants can reach 90.06%. We believe SQA3D could facilitate
future embodied AI research with stronger situation understanding and reasoning
capability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConEntail: An Entailment-based Framework for Universal Zero and Few Shot Classification with Supervised Contrastive Pretraining. (arXiv:2210.07587v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07587">
<div class="article-summary-box-inner">
<span><p>A universal classification model aims to generalize to diverse classification
tasks in both zero and few shot settings. A promising way toward universal
classification is to cast heterogeneous data formats into a dataset-agnostic
"meta-task" (e.g., textual entailment, question answering) then pretrain a
model on the combined meta dataset. The existing work is either pretrained on
specific subsets of classification tasks, or pretrained on both classification
and generation data but the model could not fulfill its potential in
universality and reliability. These also leave a massive amount of annotated
data under-exploited. To fill these gaps, we propose ConEntail, a new framework
for universal zero and few shot classification with supervised contrastive
pretraining. Our unified meta-task for classification is based on nested
entailment. It can be interpreted as "Does sentence a entails [sentence b
entails label c]". This formulation enables us to make better use of 57
annotated classification datasets for supervised contrastive pretraining and
universal evaluation. In this way, ConEntail helps the model (1) absorb
knowledge from different datasets, and (2) gain consistent performance gain
with more pretraining data. In experiments, we compare our model with
discriminative and generative models pretrained on the same dataset. The
results confirm that our framework effectively exploits existing annotated data
and consistently outperforms baselines in both zero (9.4% average improvement)
and few shot settings (3.5% average improvement).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extracting Cultural Commonsense Knowledge at Scale. (arXiv:2210.07763v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07763">
<div class="article-summary-box-inner">
<span><p>Structured knowledge is important for many AI applications. Commonsense
knowledge, which is crucial for robust human-centric AI, is covered by a small
number of structured knowledge projects. However, they lack knowledge about
human traits and behaviors conditioned on socio-cultural contexts, which is
crucial for situative AI. This paper presents CANDLE, an end-to-end methodology
for extracting high-quality cultural commonsense knowledge (CCSK) at scale.
CANDLE extracts CCSK assertions from a huge web corpus and organizes them into
coherent clusters, for 3 domains of subjects (geography, religion, occupation)
and several cultural facets (food, drinks, clothing, traditions, rituals,
behaviors). CANDLE includes judicious techniques for classification-based
filtering and scoring of interestingness. Experimental evaluations show the
superiority of the CANDLE CCSK collection over prior works, and an extrinsic
use case demonstrates the benefits of CCSK for the GPT-3 language model. Code
and data can be accessed at https://candle.mpi-inf.mpg.de/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EntityCS: Improving Zero-Shot Cross-lingual Transfer with Entity-Centric Code Switching. (arXiv:2210.12540v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12540">
<div class="article-summary-box-inner">
<span><p>Accurate alignment between languages is fundamental for improving
cross-lingual pre-trained language models (XLMs). Motivated by the natural
phenomenon of code-switching (CS) in multilingual speakers, CS has been used as
an effective data augmentation method that offers language alignment at the
word- or phrase-level, in contrast to sentence-level via parallel instances.
Existing approaches either use dictionaries or parallel sentences with word
alignment to generate CS data by randomly switching words in a sentence.
However, such methods can be suboptimal as dictionaries disregard semantics,
and syntax might become invalid after random word switching. In this work, we
propose EntityCS, a method that focuses on Entity-level Code-Switching to
capture fine-grained cross-lingual semantics without corrupting syntax. We use
Wikidata and English Wikipedia to construct an entity-centric CS corpus by
switching entities to their counterparts in other languages. We further propose
entity-oriented masking strategies during intermediate model training on the
EntityCS corpus for improving entity prediction. Evaluation of the trained
models on four entity-centric downstream tasks shows consistent improvements
over the baseline with a notable increase of 10% in Fact Retrieval. We release
the corpus and models to assist research on code-switching and enriching XLMs
with external knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Not Just Plain Text! Fuel Document-Level Relation Extraction with Explicit Syntax Refinement and Subsentence Modeling. (arXiv:2211.05343v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.05343">
<div class="article-summary-box-inner">
<span><p>Document-level relation extraction (DocRE) aims to identify semantic labels
among entities within a single document. One major challenge of DocRE is to dig
decisive details regarding a specific entity pair from long text. However, in
many cases, only a fraction of text carries required information, even in the
manually labeled supporting evidence. To better capture and exploit instructive
information, we propose a novel expLicit syntAx Refinement and Subsentence
mOdeliNg based framework (LARSON). By introducing extra syntactic information,
LARSON can model subsentences of arbitrary granularity and efficiently screen
instructive ones. Moreover, we incorporate refined syntax into text
representations which further improves the performance of LARSON. Experimental
results on three benchmark datasets (DocRED, CDR, and GDA) demonstrate that
LARSON significantly outperforms existing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Narrative Information and the Distillation of Stories. (arXiv:2211.12423v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.12423">
<div class="article-summary-box-inner">
<span><p>The act of telling stories is a fundamental part of what it means to be
human. This work introduces the concept of narrative information, which we
define to be the overlap in information space between a story and the items
that compose the story. Using contrastive learning methods, we show how modern
artificial neural networks can be leveraged to distill stories and extract a
representation of the narrative information. We then demonstrate how
evolutionary algorithms can leverage this to extract a set of narrative
templates and how these templates -- in tandem with a novel curve-fitting
algorithm we introduce -- can reorder music albums to automatically induce
stories in them. In the process of doing so, we give strong statistical
evidence that these narrative information templates are present in existing
albums. While we experiment only with music albums here, the premises of our
work extend to any form of (largely) independent media.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explicit Knowledge Transfer for Weakly-Supervised Code Generation. (arXiv:2211.16740v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.16740">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) can acquire strong code-generation capabilities
through few-shot learning. In contrast, supervised fine-tuning is still needed
for smaller models to achieve good performance. Such fine-tuning demands a
large number of task-specific NL-code pairs, which are expensive to obtain. In
this paper, we attempt to transfer the code generation ability of an LLM to a
smaller model with the aid of weakly-supervised data. More specifically, we
propose explicit knowledge transfer (EKT), which uses the few-shot capabilities
of a teacher LLM to create NL-code pairs that we then filter for correctness
and fine-tune the student on. We evaluate EKT on the task of generating code
solutions to math word problems from the GSM8k dataset. We find that EKT not
only yields better performance than training with expert iteration, but also
outperforms knowledge distillation, another form of knowledge transfer. A
GPT-Neo 1.3B model trained using EKT with a GPT-J teacher achieves a 12.4%
pass@100 on GSM8k, while the same student and teacher trained with knowledge
distillation yield only a 3.7% pass@100. We also show that it is possible for a
student model to outperform the teacher using EKT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">APOLLO: An Optimized Training Approach for Long-form Numerical Reasoning. (arXiv:2212.07249v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.07249">
<div class="article-summary-box-inner">
<span><p>Long-form numerical reasoning in financial analysis aims to generate a
reasoning program to calculate the correct answer for a given question.
Previous work followed a retriever-generator framework, where the retriever
selects key facts from a long-form document, and the generator generates a
reasoning program based on retrieved facts. However, they treated all facts
equally without considering the different contributions of facts with and
without numbers. Meanwhile, the program consistency were ignored under
supervised training, resulting in lower training accuracy and diversity. To
solve these problems, we proposed APOLLO to improve the long-form numerical
reasoning framework. For the retriever, we adopt a number-aware negative
sampling strategy to enable the retriever to be more discriminative on key
numerical facts. For the generator, we design consistency-based reinforcement
learning and target program augmentation strategy based on the consistency of
program execution results. Experimental results on the FinQA and ConvFinQA
leaderboard verify the effectiveness of our proposed method, achieving the new
state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attributed Question Answering: Evaluation and Modeling for Attributed Large Language Models. (arXiv:2212.08037v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.08037">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have shown impressive results while requiring
little or no direct supervision. Further, there is mounting evidence that LLMs
may have potential in information-seeking scenarios. We believe the ability of
an LLM to attribute the text that it generates is likely to be crucial in this
setting. We formulate and study Attributed QA as a key first step in the
development of attributed LLMs. We propose a reproducible evaluation framework
for the task and benchmark a broad set of architectures. We take human
annotations as a gold standard and show that a correlated automatic metric is
suitable for development. Our experimental work gives concrete answers to two
key questions (How to measure attribution?, and How well do current
state-of-the-art methods perform on attribution?), and give some hints as to
how to address a third (How to build LLMs with attribution?).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AnyTOD: A Programmable Task-Oriented Dialog System. (arXiv:2212.09939v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09939">
<div class="article-summary-box-inner">
<span><p>We propose AnyTOD, an end-to-end, zero-shot task-oriented dialog (TOD) system
capable of handling unseen tasks without task-specific training. We view TOD as
a program executed by a language model (LM), where program logic and ontology
is provided by a designer as a schema. To enable generalization to unseen
schemas and programs without prior training, AnyTOD adopts a neuro-symbolic
approach. A neural LM keeps track of events occurring during a conversation and
a symbolic program implementing the dialog policy is executed to recommend next
actions AnyTOD should take. This approach drastically reduces data annotation
and model training requirements, addressing the enduring challenge of rapidly
adapting a TOD system to unseen tasks and domains. We demonstrate
state-of-the-art results on STAR, ABCD and SGD benchmarks. We also demonstrate
strong zero-shot transfer ability in low-resource settings, such as zero-shot
on MultiWOZ. In addition, we release STARv2, an updated version of the STAR
dataset with richer annotations, for benchmarking zero-shot end-to-end TOD
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hungry Hungry Hippos: Towards Language Modeling with State Space Models. (arXiv:2212.14052v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.14052">
<div class="article-summary-box-inner">
<span><p>State space models (SSMs) have demonstrated state-of-the-art sequence
modeling performance in some modalities, but underperform attention in language
modeling. Moreover, despite scaling nearly linearly in sequence length instead
of quadratically, SSMs are still slower than Transformers due to poor hardware
utilization. In this paper, we make progress on understanding the expressivity
gap between SSMs and attention in language modeling, and on reducing the
hardware barrier between SSMs and attention. First, we use synthetic language
modeling tasks to understand the gap between SSMs and attention. We find that
existing SSMs struggle with two capabilities: recalling earlier tokens in the
sequence and comparing tokens across the sequence. To understand the impact on
language modeling, we propose a new SSM layer, H3, that is explicitly designed
for these abilities. H3 matches attention on the synthetic languages and comes
within 0.4 PPL of Transformers on OpenWebText. Furthermore, a hybrid
125M-parameter H3-attention model that retains two attention layers
surprisingly outperforms Transformers on OpenWebText by 1.0 PPL. Next, to
improve the efficiency of training SSMs on modern hardware, we propose
FlashConv. FlashConv uses a fused block FFT algorithm to improve efficiency on
sequences up to 8K, and introduces a novel state passing algorithm that
exploits the recurrent properties of SSMs to scale to longer sequences.
FlashConv yields 2$\times$ speedup on the long-range arena benchmark and allows
hybrid language models to generate text 2.4$\times$ faster than Transformers.
Using FlashConv, we scale hybrid H3-attention language models up to 2.7B
parameters on the Pile and find promising initial results, achieving lower
perplexity than Transformers and outperforming Transformers in zero- and
few-shot learning on a majority of tasks in the SuperGLUE benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Editing Language Model-based Knowledge Graph Embeddings. (arXiv:2301.10405v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10405">
<div class="article-summary-box-inner">
<span><p>Recently decades have witnessed the empirical success of framing Knowledge
Graph (KG) embeddings via language models. However, language model-based KG
embeddings are usually deployed as static artifacts, which are challenging to
modify without re-training after deployment. To address this issue, we propose
a new task of editing language model-based KG embeddings in this paper. The
proposed task aims to enable data-efficient and fast updates to KG embeddings
without damaging the performance of the rest. We build four new datasets:
E-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and evaluate several knowledge
editing baselines demonstrating the limited ability of previous models to
handle the proposed challenging task. We further propose a simple yet strong
baseline dubbed KGEditor, which utilizes additional parametric layers of the
hyper network to edit/add facts. Comprehensive experimental results demonstrate
that KGEditor can perform better when updating specific facts while not
affecting the rest with low training resources. Code and datasets will be
available in https://github.com/zjunlp/PromptKG/tree/main/deltaKG.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI vs. Human -- Differentiation Analysis of Scientific Content Generation. (arXiv:2301.10416v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10416">
<div class="article-summary-box-inner">
<span><p>Recent neural language models have taken a significant step forward in
producing remarkably controllable, fluent, and grammatical text. Although
studies have found that AI-generated text is not distinguishable from
human-written text for crowd-sourcing workers, there still exist errors in
AI-generated text which are even subtler and harder to spot. We primarily focus
on the scenario in which scientific AI writing assistant is deeply involved.
First, we construct a feature description framework to distinguish between
AI-generated text and human-written text from syntax, semantics, and pragmatics
based on the human evaluation. Then we utilize the features, i.e., writing
style, coherence, consistency, and argument logistics, from the proposed
framework to analyze two types of content. Finally, we adopt several publicly
available methods to investigate the gap of between AI-generated scientific
text and human-written scientific text by AI-generated scientific text
detection models. The results suggest that while AI has the potential to
generate scientific content that is as accurate as human-written content, there
is still a gap in terms of depth and overall quality. The AI-generated
scientific content is more likely to contain errors in factual issues. We find
that there exists a "writing style" gap between AI-generated scientific text
and human-written scientific text. Based on the analysis result, we summarize a
series of model-agnostic and distribution-agnostic features for detection tasks
in other domains. Findings in this paper contribute to guiding the optimization
of AI models to produce high-quality content and addressing related ethical and
security concerns.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards a Unified Model for Generating Answers and Explanations in Visual Question Answering. (arXiv:2301.10799v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10799">
<div class="article-summary-box-inner">
<span><p>The field of visual question answering (VQA) has recently seen a surge in
research focused on providing explanations for predicted answers. However,
current systems mostly rely on separate models to predict answers and generate
explanations, leading to less grounded and frequently inconsistent results. To
address this, we propose a multitask learning approach towards a Unified Model
for Answer and Explanation generation (UMAE). Our approach involves the
addition of artificial prompt tokens to training data and fine-tuning a
multimodal encoder-decoder model on a variety of VQA-related tasks. In our
experiments, UMAE models surpass the prior state-of-the-art answer accuracy on
A-OKVQA by 10~15%, show competitive results on OK-VQA, achieve new
state-of-the-art explanation scores on A-OKVQA and VCR, and demonstrate
promising out-of-domain performance on VQA-X.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextual Dynamic Prompting for Response Generation in Task-oriented Dialog Systems. (arXiv:2301.13268v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.13268">
<div class="article-summary-box-inner">
<span><p>Response generation is one of the critical components in task-oriented dialog
systems. Existing studies have shown that large pre-trained language models can
be adapted to this task. The typical paradigm of adapting such extremely large
language models would be by fine-tuning on the downstream tasks which is not
only time-consuming but also involves significant resources and access to
fine-tuning data. Prompting (Schick and Sch\"utze, 2020) has been an
alternative to fine-tuning in many NLP tasks. In our work, we explore the idea
of using prompting for response generation in task-oriented dialog systems.
Specifically, we propose an approach that performs contextual dynamic prompting
where the prompts are learnt from dialog contexts. We aim to distill useful
prompting signals from the dialog context. On experiments with MultiWOZ 2.2
dataset (Zang et al., 2020), we show that contextual dynamic prompts improve
response generation in terms of combined score (Mehri et al., 2019) by 3
absolute points, and a massive 20 points when dialog states are incorporated.
Furthermore, human annotation on these conversations found that agents which
incorporate context were preferred over agents with vanilla prefix-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases. (arXiv:2302.00609v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00609">
<div class="article-summary-box-inner">
<span><p>In this paper, we cast Legal Judgment Prediction on European Court of Human
Rights cases into an article-aware classification task, where the case outcome
is classified from a combined input of case facts and convention articles. This
configuration facilitates the model learning some legal reasoning ability in
mapping article text to specific case fact text. It also provides an
opportunity to evaluate the model's ability to generalize to zero-shot settings
when asked to classify the case outcome with respect to articles not seen
during training. We devise zero-shot experiments and apply domain adaptation
methods based on domain discrimination and Wasserstein distance. Our results
demonstrate that the article-aware architecture outperforms straightforward
fact classification. We also find that domain adaptation methods improve
zero-shot transfer performance, with article relatedness and encoder
pre-training influencing the effect.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases. (arXiv:2302.00768v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00768">
<div class="article-summary-box-inner">
<span><p>We report on an experiment in case outcome classification on European Court
of Human Rights cases where our model first learns to identify the convention
articles allegedly violated by the state from case facts descriptions, and
subsequently uses that information to classify whether the court finds a
violation of those articles. We assess the dependency between these two tasks
at the feature and outcome level. Furthermore, we leverage a hierarchical
contrastive loss to pull together article-specific representations of cases at
the higher level, leading to distinctive article clusters. The cases in each
article cluster are further pulled closer based on their outcome, leading to
sub-clusters of cases with similar outcomes. Our experiment results demonstrate
that, given a static pre-trained encoder, our models produce a small but
consistent improvement in classification performance over single-task and joint
models without contrastive loss.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CTE: A Dataset for Contextualized Table Extraction. (arXiv:2302.01451v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01451">
<div class="article-summary-box-inner">
<span><p>Relevant information in documents is often summarized in tables, helping the
reader to identify useful facts. Most benchmark datasets support either
document layout analysis or table understanding, but lack in providing data to
apply both tasks in a unified way. We define the task of Contextualized Table
Extraction (CTE), which aims to extract and define the structure of tables
considering the textual context of the document. The dataset comprises 75k
fully annotated pages of scientific papers, including more than 35k tables.
Data are gathered from PubMed Central, merging the information provided by
annotations in the PubTables-1M and PubLayNet datasets. The dataset can support
CTE and adds new classes to the original ones. The generated annotations can be
used to develop end-to-end pipelines for various tasks, including document
layout analysis, table detection, structure recognition, and functional
analysis. We formally define CTE and evaluation metrics, showing which subtasks
can be tackled, describing advantages, limitations, and future works of this
collection of data. Annotations and code will be accessible a
https://github.com/AILab-UniFI/cte-dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Theory of Mind May Have Spontaneously Emerged in Large Language Models. (arXiv:2302.02083v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.02083">
<div class="article-summary-box-inner">
<span><p>Theory of mind (ToM), or the ability to impute unobservable mental states to
others, is central to human social interactions, communication, empathy,
self-consciousness, and morality. We administer classic false-belief tasks,
widely used to test ToM in humans, to several language models, without any
examples or pre-training. Our results show that models published before 2022
show virtually no ability to solve ToM tasks. Yet, the January 2022 version of
GPT-3 (davinci-002) solved 70% of ToM tasks, a performance comparable with that
of seven-year-old children. Moreover, its November 2022 version (davinci-003),
solved 93% of ToM tasks, a performance comparable with that of nine-year-old
children. These findings suggest that ToM-like ability (thus far considered to
be uniquely human) may have spontaneously emerged as a byproduct of language
models' improving language skills.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Nationality Bias in Text Generation. (arXiv:2302.02463v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.02463">
<div class="article-summary-box-inner">
<span><p>Little attention is placed on analyzing nationality bias in language models,
especially when nationality is highly used as a factor in increasing the
performance of social NLP models. This paper examines how a text generation
model, GPT-2, accentuates pre-existing societal biases about country-based
demonyms. We generate stories using GPT-2 for various nationalities and use
sensitivity analysis to explore how the number of internet users and the
country's economic status impacts the sentiment of the stories. To reduce the
propagation of biases through large language models (LLM), we explore the
debiasing method of adversarial triggering. Our results show that GPT-2
demonstrates significant bias against countries with lower internet users, and
adversarial triggering effectively reduces the same.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Clinical BioBERT Hyperparameter Optimization using Genetic Algorithm. (arXiv:2302.03822v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03822">
<div class="article-summary-box-inner">
<span><p>Clinical factors account only for a small portion, about 10-30%, of the
controllable factors that affect an individual's health outcomes. The remaining
factors include where a person was born and raised, where he/she pursued their
education, what their work and family environment is like, etc. These factors
are collectively referred to as Social Determinants of Health (SDoH). The
majority of SDoH data is recorded in unstructured clinical notes by physicians
and practitioners. Recording SDoH data in a structured manner (in an EHR) could
greatly benefit from a dedicated ontology of SDoH terms. Our research focuses
on extracting sentences from clinical notes, making use of such an SDoH
ontology (called SOHO) to provide appropriate concepts. We utilize recent
advancements in Deep Learning to optimize the hyperparameters of a Clinical
BioBERT model for SDoH text. A genetic algorithm-based hyperparameter tuning
regimen was implemented to identify optimal parameter settings. To implement a
complete classifier, we pipelined Clinical BioBERT with two subsequent linear
layers and two dropout layers. The output predicts whether a text fragment
describes an SDoH issue of the patient. We compared the AdamW, Adafactor, and
LAMB optimizers. In our experiments, AdamW outperformed the others in terms of
accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPTScore: Evaluate as You Desire. (arXiv:2302.04166v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04166">
<div class="article-summary-box-inner">
<span><p>Generative Artificial Intelligence (AI) has enabled the development of
sophisticated models that are capable of producing high-caliber text, images,
and other outputs through the utilization of large pre-trained models.
Nevertheless, assessing the quality of the generation is an even more arduous
task than the generation itself, and this issue has not been given adequate
consideration recently. This paper proposes a novel evaluation framework,
GPTScore, which utilizes the emergent abilities (e.g., zero-shot instruction)
of generative pre-trained models to score generated texts. There are 19
pre-trained models explored in this paper, ranging in size from 80M (e.g.,
FLAN-T5-small) to 175B (e.g., GPT3). Experimental results on four text
generation tasks, 22 evaluation aspects, and corresponding 37 datasets
demonstrate that this approach can effectively allow us to achieve what one
desires to evaluate for texts simply by natural language instructions. This
nature helps us overcome several long-standing challenges in text
evaluation--how to achieve customized, multi-faceted evaluation without the
need for annotated samples. We make our code publicly available at
https://github.com/jinlanfu/GPTScore.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals. (arXiv:2302.04449v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04449">
<div class="article-summary-box-inner">
<span><p>High sample complexity has long been a challenge for RL. On the other hand,
humans learn to perform tasks not only from interaction or demonstrations, but
also by reading unstructured text documents, e.g., instruction manuals.
Instruction manuals and wiki pages are among the most abundant data that could
inform agents of valuable features and policies or task-specific environmental
dynamics and reward structures. Therefore, we hypothesize that the ability to
utilize human-written instruction manuals to assist learning policies for
specific tasks should lead to a more efficient and better-performing agent.
</p>
<p>We propose the Read and Reward framework. Read and Reward speeds up RL
algorithms on Atari games by reading manuals released by the Atari game
developers. Our framework consists of a QA Extraction module that extracts and
summarizes relevant information from the manual and a Reasoning module that
evaluates object-agent interactions based on information from the manual.
Auxiliary reward is then provided to a standard A2C RL agent, when interaction
is detected. When assisted by our design, A2C improves on 4 games in the Atari
environment with sparse rewards, and requires 1000x less training frames
compared to the previous SOTA Agent 57 on Skiing, the hardest game in Atari.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge is a Region in Weight Space for Fine-tuned Language Models. (arXiv:2302.04863v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.04863">
<div class="article-summary-box-inner">
<span><p>Research on neural networks has largely focused on understanding a single
model trained on a single dataset. However, relatively little is known about
the relationships between different models, especially those trained or tested
on different datasets. We address this by studying how the weight space and
underlying loss landscape of different models are interconnected.
</p>
<p>Specifically, we demonstrate that fine-tuned models that were optimized for
high performance, reside in well-defined regions in weight space, and vice
versa -- that any model that resides anywhere in those regions also has high
performance. Specifically, we show that language models that have been
fine-tuned on the same dataset form a tight cluster in the weight space and
that models fine-tuned on different datasets from the same underlying task form
a looser cluster. Moreover, traversing around the region between the models
reaches new models that perform comparably or even better than models found via
fine-tuning, even on tasks that the original models were not fine-tuned on.
</p>
<p>Our findings provide insight into the relationships between models,
demonstrating that a model positioned between two similar models can acquire
the knowledge of both. We leverage this finding and design a method to pick a
better model for efficient fine-tuning. Specifically, we show that starting
from the center of the region is as good or better than the pre-trained model
in 11 of 12 datasets and improves accuracy by 3.06 on average.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Song of Ice and Fire: Analyzing Textual Autotelic Agents in ScienceWorld. (arXiv:2302.05244v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05244">
<div class="article-summary-box-inner">
<span><p>Building open-ended agents that can autonomously discover a diversity of
behaviours is one of the long-standing goals of artificial intelligence. This
challenge can be studied in the framework of autotelic RL agents, i.e. agents
that learn by selecting and pursuing their own goals, self-organizing a
learning curriculum. Recent work identified language has a key dimension of
autotelic learning, in particular because it enables abstract goal sampling and
guidance from social peers for hindsight relabelling. Within this perspective,
we study the following open scientific questions: What is the impact of
hindsight feedback from a social peer (e.g. selective vs. exhaustive)? How can
the agent learn from very rare language goal examples in its experience replay?
How can multiple forms of exploration be combined, and take advantage of easier
goals as stepping stones to reach harder ones? To address these questions, we
use ScienceWorld, a textual environment with rich abstract and combinatorial
physics. We show the importance of selectivity from the social peer's feedback;
that experience replay needs to over-sample examples of rare goals; and that
following self-generated goal sequences where the agent's competence is
intermediate leads to significant improvements in final performance.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-02-14 23:13:01.070791995 UTC">2023-02-14 23:13:01 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>