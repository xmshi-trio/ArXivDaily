<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-12-07T01:30:00Z">12-07</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Domain Few-Shot Relation Extraction via Representation Learning and Domain Adaptation. (arXiv:2212.02560v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02560">
<div class="article-summary-box-inner">
<span><p>Cross-domain few-shot relation extraction poses a great challenge for the
existing few-shot learning methods and domain adaptation methods when the
source domain and target domain have large discrepancies. This paper proposes a
method by combining the idea of few-shot learning and domain adaptation to deal
with this problem. In the proposed method, an encoder, learned by optimizing a
representation loss and an adversarial loss, is used to extract the relation of
sentences in the source and target domain. The representation loss, including a
cross-entropy loss and a contrastive loss, makes the encoder extract the
relation of the source domain and keep the geometric structure of the classes
in the source domain. And the adversarial loss is used to merge the source
domain and target domain. The experimental results on the benchmark FewRel
dataset demonstrate that the proposed method can outperform some
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">INCLUSIFY: A benchmark and a model for gender-inclusive German. (arXiv:2212.02564v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02564">
<div class="article-summary-box-inner">
<span><p>Gender-inclusive language is important for achieving gender equality in
languages with gender inflections, such as German. While stirring some
controversy, it is increasingly adopted by companies and political
institutions. A handful of tools have been developed to help people use
gender-inclusive language by identifying instances of the generic masculine and
providing suggestions for more inclusive reformulations. In this report, we
define the underlying tasks in terms of natural language processing, and
present a dataset and measures for benchmarking them. We also present a model
that implements these tasks, by combining an inclusive language database with
an elaborate sequence of processing steps via standard pre-trained models. Our
model achieves a recall of 0.89 and a precision of 0.82 in our benchmark for
identifying exclusive language; and one of its top five suggestions is chosen
in real-world texts in 44% of cases. We sketch how the area could be further
advanced by training end-to-end models and using large language models; and we
urge the community to include more gender-inclusive texts in their training
data in order to not present an obstacle to the adoption of gender-inclusive
language. Through these efforts, we hope to contribute to restoring justice in
language and, to a small extent, in reality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-tuning a Subtle Parsing Distinction Using a Probabilistic Decision Tree: the Case of Postnominal "that" in Noun Complement Clauses vs. Relative Clauses. (arXiv:2212.02591v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02591">
<div class="article-summary-box-inner">
<span><p>In this paper we investigated two different methods to parse relative and
noun complement clauses in English and resorted to distinct tags for their
corresponding that as a relative pronoun and as a complementizer. We used an
algorithm to relabel a corpus parsed with the GUM Treebank using Universal
Dependency. Our second experiment consisted in using TreeTagger, a
Probabilistic Decision Tree, to learn the distinction between the two
complement and relative uses of postnominal "that". We investigated the effect
of the training set size on TreeTagger accuracy and how representative the GUM
Treebank files are for the two structures under scrutiny. We discussed some of
the linguistic and structural tenets of the learnability of this distinction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unifying Vision, Text, and Layout for Universal Document Processing. (arXiv:2212.02623v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02623">
<div class="article-summary-box-inner">
<span><p>We propose Universal Document Processing (UDOP), a foundation Document AI
model which unifies text, image, and layout modalities together with varied
task formats, including document understanding and generation. UDOP leverages
the spatial correlation between textual content and document image to model
image, text, and layout modalities with one uniform representation. With a
novel Vision-Text-Layout Transformer, UDOP unifies pretraining and multi-domain
downstream tasks into a prompt-based sequence generation scheme. UDOP is
pretrained on both large-scale unlabeled document corpora using innovative
self-supervised objectives and diverse labeled data. UDOP also learns to
generate document images from text and layout modalities via masked image
reconstruction. To the best of our knowledge, this is the first time in the
field of document AI that one model simultaneously achieves high-quality neural
document editing and content customization. Our method sets the
state-of-the-art on 9 Document AI tasks, e.g., document understanding and QA,
across diverse data domains like finance reports, academic papers, and
websites. UDOP ranks first on the leaderboard of the Document Understanding
Benchmark (DUE).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">POQue: Asking Participant-specific Outcome Questions for a Deeper Understanding of Complex Events. (arXiv:2212.02629v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02629">
<div class="article-summary-box-inner">
<span><p>Knowledge about outcomes is critical for complex event understanding but is
hard to acquire. We show that by pre-identifying a participant in a complex
event, crowd workers are able to (1) infer the collective impact of salient
events that make up the situation, (2) annotate the volitional engagement of
participants in causing the situation, and (3) ground the outcome of the
situation in state changes of the participants. By creating a multi-step
interface and a careful quality control strategy, we collect a high quality
annotated dataset of 8K short newswire narratives and ROCStories with high
inter-annotator agreement (0.74-0.96 weighted Fleiss Kappa). Our dataset, POQue
(Participant Outcome Questions), enables the exploration and development of
models that address multiple aspects of semantic understanding. Experimentally,
we show that current language models lag behind human performance in subtle
ways through our task formulations that target abstract and specific
comprehension of a complex event, its outcome, and a participant's influence
over the event culmination.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LUNA: Language Understanding with Number Augmentations on Transformers via Number Plugins and Pre-training. (arXiv:2212.02691v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02691">
<div class="article-summary-box-inner">
<span><p>Transformers are widely used in NLP tasks. However, current approaches to
leveraging transformers to understand language expose one weak spot: Number
understanding. In some scenarios, numbers frequently occur, especially in
semi-structured data like tables. But current approaches to rich-number tasks
with transformer-based language models abandon or lose some of the numeracy
information - e.g., breaking numbers into sub-word tokens - which leads to many
number-related errors. In this paper, we propose the LUNA framework which
improves the numerical reasoning and calculation capabilities of
transformer-based language models. With the number plugin of NumTok and NumBed,
LUNA represents each number as a whole to model input. With number
pre-training, including regression loss and model distillation, LUNA bridges
the gap between number and vocabulary embeddings. To the best of our knowledge,
this is the first work that explicitly injects numeracy capability into
language models using Number Plugins. Besides evaluating toy models on toy
tasks, we evaluate LUNA on three large-scale transformer models (RoBERTa, BERT,
TabBERT) over three different downstream tasks (TATQA, TabFact, CrediTrans),
and observe the performances of language models are constantly improved by
LUNA. The augmented models also improve the official baseline of TAT-QA (EM:
50.15 -&gt; 59.58) and achieve SOTA performance on CrediTrans (F1 = 86.17).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved Beam Search for Hallucination Mitigation in Abstractive Summarization. (arXiv:2212.02712v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02712">
<div class="article-summary-box-inner">
<span><p>Advancement in large pretrained language models has significantly improved
their performance for conditional language generation tasks including
summarization albeit with hallucinations. To reduce hallucinations,
conventional methods proposed improving beam search or using a fact checker as
a postprocessing step. In this paper, we investigate the use of the Natural
Language Inference (NLI) entailment metric to detect and prevent hallucinations
in summary generation. We propose an NLI-assisted beam re-ranking mechanism by
computing entailment probability scores between the input context and
summarization model-generated beams during saliency-enhanced greedy decoding.
Moreover, a diversity metric is introduced to compare its effectiveness against
vanilla beam search. Our proposed algorithm significantly outperforms vanilla
beam decoding on XSum and CNN/DM datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sources of Noise in Dialogue and How to Deal with Them. (arXiv:2212.02745v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02745">
<div class="article-summary-box-inner">
<span><p>Training dialogue systems often entails dealing with noisy training examples
and unexpected user inputs. Despite their prevalence, there currently lacks an
accurate survey of dialogue noise, nor is there a clear sense of the impact of
each noise type on task performance. This paper addresses this gap by first
constructing a taxonomy of noise encountered by dialogue systems. In addition,
we run a series of experiments to show how different models behave when
subjected to varying levels of noise and types of noise. Our results reveal
that models are quite robust to label errors commonly tackled by existing
denoising algorithms, but that performance suffers from dialogue-specific
noise. Driven by these observations, we design a data cleaning algorithm
specialized for conversational settings and apply it as a proof-of-concept for
targeted dialogue denoising.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Identification of Eviction Status from Electronic Health Record Notes. (arXiv:2212.02762v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02762">
<div class="article-summary-box-inner">
<span><p>Objective: Evictions are involved in a cascade of negative events that can
lead to unemployment, homelessness, long-term poverty, and mental health
problems. In this study, we developed a natural language processing system to
automatically detect eviction incidences and their attributes from electronic
health record (EHR) notes.
</p>
<p>Materials and Methods: We annotated eviction status in 5000 EHR notes from
the Veterans Health Administration. We developed a novel model, called
Knowledge Injection based on Ripple Effects of Social and Behavioral
Determinants of Health (KIRESH), that has shown to substantially outperform
other state-of-the-art models such as fine-tuning pre-trained language models
like BioBERT and Bio_ClinicalBERT. Moreover, we designed a prompt to further
improve the model performance by using the intrinsic connection between the two
sub-tasks of eviction presence and period prediction. Finally, we used the
Temperature Scaling-based Calibration on our KIRESH-Prompt method to avoid
over-confidence issues arising from the imbalance dataset.
</p>
<p>Results: KIRESH-Prompt achieved a Macro-F1 of 0.6273 (presence) and 0.7115
(period), which was significantly higher than 0.5382 (presence) and 0.67167
(period) for just fine-tuning Bio_ClinicalBERT model.
</p>
<p>Conclusion and Future Work: KIRESH-Prompt has substantially improved eviction
status classification. In future work, we will evaluate the generalizability of
the model framework to other applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Life-long Learning for Multilingual Neural Machine Translation with Knowledge Distillation. (arXiv:2212.02800v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02800">
<div class="article-summary-box-inner">
<span><p>A common scenario of Multilingual Neural Machine Translation (MNMT) is that
each translation task arrives in a sequential manner, and the training data of
previous tasks is unavailable. In this scenario, the current methods suffer
heavily from catastrophic forgetting (CF). To alleviate the CF, we investigate
knowledge distillation based life-long learning methods. Specifically, in
one-tomany scenario, we propose a multilingual distillation method to make the
new model (student) jointly learn multilingual output from old model (teacher)
and new task. In many-to one scenario, we find that direct distillation faces
the extreme partial distillation problem, and we propose two different methods
to address it: pseudo input distillation and reverse teacher distillation. The
experimental results on twelve translation tasks show that the proposed methods
can better consolidate the previous knowledge and sharply alleviate the CF.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiSTRICT: Dialogue State Tracking with Retriever Driven In-Context Tuning. (arXiv:2212.02851v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02851">
<div class="article-summary-box-inner">
<span><p>Dialogue State Tracking (DST), a key component of task-oriented conversation
systems, represents user intentions by determining the values of pre-defined
slots in an ongoing dialogue. Existing approaches use hand-crafted templates
and additional slot information to fine-tune and prompt large pre-trained
language models and elicit slot values from the dialogue context. Significant
manual effort and domain knowledge is required to design effective prompts,
limiting the generalizability of these approaches to new domains and tasks. In
this work, we propose DiSTRICT, a generalizable in-context tuning approach for
DST that retrieves highly relevant training examples for a given dialogue to
fine-tune the model without any hand-crafted templates. Experiments with the
MultiWOZ benchmark datasets show that DiSTRICT outperforms existing approaches
in various zero-shot and few-shot settings using a much smaller model, thereby
providing an important advantage for real-world deployments that often have
limited resource availability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Template-based Recruitment Email Generation For Job Recommendation. (arXiv:2212.02885v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02885">
<div class="article-summary-box-inner">
<span><p>Text generation has long been a popular research topic in NLP. However, the
task of generating recruitment emails from recruiters to candidates in the job
recommendation scenario has received little attention by the research
community. This work aims at defining the topic of automatic email generation
for job recommendation, identifying the challenges, and providing a baseline
template-based solution for Danish jobs. Evaluation by human experts shows that
our method is effective. We wrap up by discussing the future research
directions for better solving this task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emotion Conditioned Creative Dialog Generation. (arXiv:2212.02907v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02907">
<div class="article-summary-box-inner">
<span><p>We present a DialGPT based model for generating creative dialog responses
that are conditioned based on one of the following emotions: anger, disgust,
fear, happiness, pain, sadness and surprise. Our model is capable of producing
a contextually apt response given an input sentence and a desired emotion
label. Our model is capable of expressing the desired emotion with an accuracy
of 0.6. The best performing emotions are neutral, fear and disgust. When
measuring the strength of the expressed emotion, we find that anger, fear and
disgust are expressed in the most strong fashion by the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards human-compatible autonomous car: A study of non-verbal Turing test in automated driving with affective transition modelling. (arXiv:2212.02908v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02908">
<div class="article-summary-box-inner">
<span><p>Autonomous cars are indispensable when humans go further down the hands-free
route. Although existing literature highlights that the acceptance of the
autonomous car will increase if it drives in a human-like manner, sparse
research offers the naturalistic experience from a passenger's seat perspective
to examine the human likeness of current autonomous cars. The present study
tested whether the AI driver could create a human-like ride experience for
passengers based on 69 participants' feedback in a real-road scenario. We
designed a ride experience-based version of the non-verbal Turing test for
automated driving. Participants rode in autonomous cars (driven by either human
or AI drivers) as a passenger and judged whether the driver was human or AI.
The AI driver failed to pass our test because passengers detected the AI driver
above chance. In contrast, when the human driver drove the car, the passengers'
judgement was around chance. We further investigated how human passengers
ascribe humanness in our test. Based on Lewin's field theory, we advanced a
computational model combining signal detection theory with pre-trained language
models to predict passengers' humanness rating behaviour. We employed affective
transition between pre-study baseline emotions and corresponding post-stage
emotions as the signal strength of our model. Results showed that the
passengers' ascription of humanness would increase with the greater affective
transition. Our study suggested an important role of affective transition in
passengers' ascription of humanness, which might become a future direction for
autonomous driving.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modern French Poetry Generation with RoBERTa and GPT-2. (arXiv:2212.02911v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02911">
<div class="article-summary-box-inner">
<span><p>We present a novel neural model for modern poetry generation in French. The
model consists of two pretrained neural models that are fine-tuned for the poem
generation task. The encoder of the model is a RoBERTa based one while the
decoder is based on GPT-2. This way the model can benefit from the superior
natural language understanding performance of RoBERTa and the good natural
language generation performance of GPT-2. Our evaluation shows that the model
can create French poetry successfully. On a 5 point scale, the lowest score of
3.57 was given by human judges to typicality and emotionality of the output
poetry while the best score of 3.79 was given to understandability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controlled Text Generation using T5 based Encoder-Decoder Soft Prompt Tuning and Analysis of the Utility of Generated Text in AI. (arXiv:2212.02924v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02924">
<div class="article-summary-box-inner">
<span><p>Controlled text generation is a very important task in the arena of natural
language processing due to its promising applications. In order to achieve this
task we mainly introduce the novel soft prompt tuning method of using soft
prompts at both encoder and decoder levels together in a T5 model and
investigate the performance as the behaviour of an additional soft prompt
related to the decoder of a T5 model in controlled text generation remained
unexplored. Then we also investigate the feasibility of steering the output of
this extended soft prompted T5 model at decoder level and finally analyse the
utility of generated text to be used in AI related tasks such as training AI
models with an interpretability analysis of the classifier trained with
synthetic text, as there is a lack of proper analysis of methodologies in
generating properly labelled data to be utilized in AI tasks. Through the
performed in-depth intrinsic and extrinsic evaluations of this generation model
along with the artificially generated data, we found that this model produced
better results compared to the T5 model with a single soft prompt at encoder
level and the sentiment classifier trained using this artificially generated
data can produce comparable classification results to the results of a
classifier trained with real labelled data and also the classifier decision is
interpretable with respect to the input text content.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CySecBERT: A Domain-Adapted Language Model for the Cybersecurity Domain. (arXiv:2212.02974v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02974">
<div class="article-summary-box-inner">
<span><p>The field of cybersecurity is evolving fast. Experts need to be informed
about past, current and - in the best case - upcoming threats, because attacks
are becoming more advanced, targets bigger and systems more complex. As this
cannot be addressed manually, cybersecurity experts need to rely on machine
learning techniques. In the texutual domain, pre-trained language models like
BERT have shown to be helpful, by providing a good baseline for further
fine-tuning. However, due to the domain-knowledge and many technical terms in
cybersecurity general language models might miss the gist of textual
information, hence doing more harm than good. For this reason, we create a
high-quality dataset and present a language model specifically tailored to the
cybersecurity domain, which can serve as a basic building block for
cybersecurity systems that deal with natural language. The model is compared
with other models based on 15 different domain-dependent extrinsic and
intrinsic tasks as well as general tasks from the SuperGLUE benchmark. On the
one hand, the results of the intrinsic tasks show that our model improves the
internal representation space of words compared to the other models. On the
other hand, the extrinsic, domain-dependent tasks, consisting of sequence
tagging and classification, show that the model is best in specific application
scenarios, in contrast to the others. Furthermore, we show that our approach
against catastrophic forgetting works, as the model is able to retrieve the
previously trained domain-independent knowledge. The used dataset and trained
model are made publicly available
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-Bridged Causal Interaction Network for Causal Emotion Entailment. (arXiv:2212.02995v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02995">
<div class="article-summary-box-inner">
<span><p>Causal Emotion Entailment aims to identify causal utterances that are
responsible for the target utterance with a non-neutral emotion in
conversations. Previous works are limited in thorough understanding of the
conversational context and accurate reasoning of the emotion cause. To this
end, we propose Knowledge-Bridged Causal Interaction Network (KBCIN) with
commonsense knowledge (CSK) leveraged as three bridges. Specifically, we
construct a conversational graph for each conversation and leverage the
event-centered CSK as the semantics-level bridge (S-bridge) to capture the deep
inter-utterance dependencies in the conversational context via the CSK-Enhanced
Graph Attention module. Moreover, social-interaction CSK serves as
emotion-level bridge (E-bridge) and action-level bridge (A-bridge) to connect
candidate utterances with the target one, which provides explicit causal clues
for the Emotional Interaction module and Actional Interaction module to reason
the target emotion. Experimental results show that our model achieves better
performance over most baseline models. Our source code is publicly available at
https://github.com/circle-hit/KBCIN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SODA: A Natural Language Processing Package to Extract Social Determinants of Health for Cancer Studies. (arXiv:2212.03000v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03000">
<div class="article-summary-box-inner">
<span><p>Objective: We aim to develop an open-source natural language processing (NLP)
package, SODA (i.e., SOcial DeterminAnts), with pre-trained transformer models
to extract social determinants of health (SDoH) for cancer patients, examine
the generalizability of SODA to a new disease domain (i.e., opioid use), and
evaluate the extraction rate of SDoH using cancer populations.
</p>
<p>Methods: We identified SDoH categories and attributes and developed an SDoH
corpus using clinical notes from a general cancer cohort. We compared four
transformer-based NLP models to extract SDoH, examined the generalizability of
NLP models to a cohort of patients prescribed with opioids, and explored
customization strategies to improve performance. We applied the best NLP model
to extract 19 categories of SDoH from the breast (n=7,971), lung (n=11,804),
and colorectal cancer (n=6,240) cohorts.
</p>
<p>Results and Conclusion: We developed a corpus of 629 cancer patients notes
with annotations of 13,193 SDoH concepts/attributes from 19 categories of SDoH.
The Bidirectional Encoder Representations from Transformers (BERT) model
achieved the best strict/lenient F1 scores of 0.9216 and 0.9441 for SDoH
concept extraction, 0.9617 and 0.9626 for linking attributes to SDoH concepts.
Fine-tuning the NLP models using new annotations from opioid use patients
improved the strict/lenient F1 scores from 0.8172/0.8502 to 0.8312/0.8679. The
extraction rates among 19 categories of SDoH varied greatly, where 10 SDoH
could be extracted from &gt;70% of cancer patients, but 9 SDoH had a low
extraction rate (&lt;70% of cancer patients). The SODA package with pre-trained
transformer models is publicly available at
https://github.com/uf-hobiinformatics-lab/SDoH_SODA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Document-Level Abstractive Summarization. (arXiv:2212.03013v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03013">
<div class="article-summary-box-inner">
<span><p>The task of automatic text summarization produces a concise and fluent text
summary while preserving key information and overall meaning. Recent approaches
to document-level summarization have seen significant improvements in recent
years by using models based on the Transformer architecture. However, the
quadratic memory and time complexities with respect to the sequence length make
them very expensive to use, especially with long sequences, as required by
document-level summarization. Our work addresses the problem of document-level
summarization by studying how efficient Transformer techniques can be used to
improve the automatic summarization of very long texts. In particular, we will
use the arXiv dataset, consisting of several scientific papers and the
corresponding abstracts, as baselines for this work. Then, we propose a novel
retrieval-enhanced approach based on the architecture which reduces the cost of
generating a summary of the entire document by processing smaller chunks. The
results were below the baselines but suggest a more efficient memory a
consumption and truthfulness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Style transfer and classification in hebrew news items. (arXiv:2212.03019v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03019">
<div class="article-summary-box-inner">
<span><p>Hebrew is a Morphological rich language, making its modeling harder than
simpler language. Recent developments such as Transformers in general and Bert
in particular opened a path for Hebrew models that reach SOTA results, not
falling short from other non-MRL languages. We explore the cutting edge in this
field performing style transfer, text generation and classification over news
articles collected from online archives. Furthermore, the news portals that
feed our collective consciousness are an interesting corpus to study, as their
analysis and tracing might reveal insights about our society and discourse.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ZeroKBC: A Comprehensive Benchmark for Zero-Shot Knowledge Base Completion. (arXiv:2212.03091v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03091">
<div class="article-summary-box-inner">
<span><p>Knowledge base completion (KBC) aims to predict the missing links in
knowledge graphs. Previous KBC tasks and approaches mainly focus on the setting
where all test entities and relations have appeared in the training set.
However, there has been limited research on the zero-shot KBC settings, where
we need to deal with unseen entities and relations that emerge in a constantly
growing knowledge base. In this work, we systematically examine different
possible scenarios of zero-shot KBC and develop a comprehensive benchmark,
ZeroKBC, that covers these scenarios with diverse types of knowledge sources.
Our systematic analysis reveals several missing yet important zero-shot KBC
settings. Experimental results show that canonical and state-of-the-art KBC
systems cannot achieve satisfactory performance on this challenging benchmark.
By analyzing the strength and weaknesses of these systems on solving ZeroKBC,
we further present several important observations and promising future
directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic-Conditional Diffusion Networks for Image Captioning. (arXiv:2212.03099v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03099">
<div class="article-summary-box-inner">
<span><p>Recent advances on text-to-image generation have witnessed the rise of
diffusion models which act as powerful generative models. Nevertheless, it is
not trivial to exploit such latent variable models to capture the dependency
among discrete words and meanwhile pursue complex visual-language alignment in
image captioning. In this paper, we break the deeply rooted conventions in
learning Transformer-based encoder-decoder, and propose a new diffusion model
based paradigm tailored for image captioning, namely Semantic-Conditional
Diffusion Networks (SCD-Net). Technically, for each input image, we first
search the semantically relevant sentences via cross-modal retrieval model to
convey the comprehensive semantic information. The rich semantics are further
regarded as semantic prior to trigger the learning of Diffusion Transformer,
which produces the output sentence in a diffusion process. In SCD-Net, multiple
Diffusion Transformer structures are stacked to progressively strengthen the
output sentence with better visional-language alignment and linguistical
coherence in a cascaded manner. Furthermore, to stabilize the diffusion
process, a new self-critical sequence training strategy is designed to guide
the learning of SCD-Net with the knowledge of a standard autoregressive
Transformer model. Extensive experiments on COCO dataset demonstrate the
promising potential of using diffusion models in the challenging image
captioning task. Source code is available at
\url{https://github.com/YehLi/xmodaler/tree/master/configs/image_caption/scdnet}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Machine Translation with Contrastive Translation Memories. (arXiv:2212.03140v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03140">
<div class="article-summary-box-inner">
<span><p>Retrieval-augmented Neural Machine Translation models have been successful in
many translation scenarios. Different from previous works that make use of
mutually similar but redundant translation memories~(TMs), we propose a new
retrieval-augmented NMT to model contrastively retrieved translation memories
that are holistically similar to the source sentence while individually
contrastive to each other providing maximal information gains in three phases.
First, in TM retrieval phase, we adopt a contrastive retrieval algorithm to
avoid redundancy and uninformativeness of similar translation pieces. Second,
in memory encoding stage, given a set of TMs we propose a novel Hierarchical
Group Attention module to gather both local context of each TM and global
context of the whole TM set. Finally, in training phase, a Multi-TM contrastive
learning objective is introduced to learn salient feature of each TM with
respect to target sentence. Experimental results show that our framework
obtains improvements over strong baselines on the benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LawngNLI: A Long-Premise Benchmark for In-Domain Generalization from Short to Long Contexts and for Implication-Based Retrieval. (arXiv:2212.03222v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03222">
<div class="article-summary-box-inner">
<span><p>Natural language inference has trended toward studying contexts beyond the
sentence level. An important application area is law: past cases often do not
foretell how they apply to new situations and implications must be inferred.
This paper introduces LawngNLI, constructed from U.S. legal opinions with
automatic labels with high human-validated accuracy. Premises are long and
multigranular. Experiments show two use cases. First, LawngNLI can benchmark
for in-domain generalization from short to long contexts. It has remained
unclear if large-scale long-premise NLI datasets actually need to be
constructed: near-top performance on long premises could be achievable by
fine-tuning using short premises. Without multigranularity, benchmarks cannot
distinguish lack of fine-tuning on long premises versus domain shift between
short and long datasets. In contrast, our long and short premises share the
same examples and domain. Models fine-tuned using several past NLI datasets
and/or our short premises fall short of top performance on our long premises.
So for at least certain domains (such as ours), large-scale long-premise
datasets are needed. Second, LawngNLI can benchmark for implication-based
retrieval. Queries are entailed or contradicted by target documents, allowing
users to move between arguments and evidence. Leading retrieval models perform
reasonably zero shot on a LawngNLI-derived retrieval task. We compare different
systems for re-ranking, including lexical overlap and cross-encoders fine-tuned
using a modified LawngNLI or past NLI datasets. LawngNLI can train and test
systems for implication-based case retrieval and argumentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Switching to Discriminative Image Captioning by Relieving a Bottleneck of Reinforcement Learning. (arXiv:2212.03230v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03230">
<div class="article-summary-box-inner">
<span><p>Discriminativeness is a desirable feature of image captions: captions should
describe the characteristic details of input images. However, recent
high-performing captioning models, which are trained with reinforcement
learning (RL), tend to generate overly generic captions despite their high
performance in various other criteria. First, we investigate the cause of the
unexpectedly low discriminativeness and show that RL has a deeply rooted side
effect of limiting the output words to high-frequency words. The limited
vocabulary is a severe bottleneck for discriminativeness as it is difficult for
a model to describe the details beyond its vocabulary. Then, based on this
identification of the bottleneck, we drastically recast discriminative image
captioning as a much simpler task of encouraging low-frequency word generation.
Hinted by long-tail classification and debiasing methods, we propose methods
that easily switch off-the-shelf RL models to discriminativeness-aware models
with only a single-epoch fine-tuning on the part of the parameters. Extensive
experiments demonstrate that our methods significantly enhance the
discriminativeness of off-the-shelf RL models and even outperform previous
discriminativeness-aware methods with much smaller computational costs.
Detailed analysis and human evaluation also verify that our methods boost the
discriminativeness without sacrificing the overall quality of captions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sharpness-Aware Minimization with Dynamic Reweighting. (arXiv:2112.08772v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.08772">
<div class="article-summary-box-inner">
<span><p>Deep neural networks are often overparameterized and may not easily achieve
model generalization. Adversarial training has shown effectiveness in improving
generalization by regularizing the change of loss on top of adversarially
chosen perturbations. The recently proposed sharpness-aware minimization (SAM)
algorithm conducts adversarial weight perturbation, encouraging the model to
converge to a flat minima. SAM finds a common adversarial weight perturbation
per-batch. Although per-instance adversarial weight perturbations are stronger
adversaries and can potentially lead to better generalization performance,
their computational cost is very high and thus it is impossible to use
per-instance perturbations efficiently in SAM. In this paper, we tackle this
efficiency bottleneck and propose sharpness-aware minimization with dynamic
reweighting (delta-SAM). Our theoretical analysis motivates that it is possible
to approach the stronger, per-instance adversarial weight perturbations using
reweighted per-batch weight perturbations. delta-SAM dynamically reweights
perturbation within each batch according to the theoretically principled
weighting factors, serving as a good approximation to per-instance
perturbation. Experiments on various natural language understanding tasks
demonstrate the effectiveness of delta-SAM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ensemble Transformer for Efficient and Accurate Ranking Tasks: an Application to Question Answering Systems. (arXiv:2201.05767v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05767">
<div class="article-summary-box-inner">
<span><p>Large transformer models can highly improve Answer Sentence Selection (AS2)
tasks, but their high computational costs prevent their use in many real-world
applications. In this paper, we explore the following research question: How
can we make the AS2 models more accurate without significantly increasing their
model complexity? To address the question, we propose a Multiple Heads Student
architecture (named CERBERUS), an efficient neural network designed to distill
an ensemble of large transformers into a single smaller model. CERBERUS
consists of two components: a stack of transformer layers that is used to
encode inputs, and a set of ranking heads; unlike traditional distillation
technique, each of them is trained by distilling a different large transformer
architecture in a way that preserves the diversity of the ensemble members. The
resulting model captures the knowledge of heterogeneous transformer models by
using just a few extra parameters. We show the effectiveness of CERBERUS on
three English datasets for AS2; our proposed approach outperforms all
single-model distillations we consider, rivaling the state-of-the-art large AS2
models that have 2.7x more parameters and run 2.5x slower. Code for our model
is available at https://github.com/amazon-research/wqa-cerberus
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LISA: Learning Interpretable Skill Abstractions from Language. (arXiv:2203.00054v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.00054">
<div class="article-summary-box-inner">
<span><p>Learning policies that effectively utilize language instructions in complex,
multi-task environments is an important problem in sequential decision-making.
While it is possible to condition on the entire language instruction directly,
such an approach could suffer from generalization issues. In our work, we
propose \emph{Learning Interpretable Skill Abstractions (LISA)}, a hierarchical
imitation learning framework that can learn diverse, interpretable primitive
behaviors or skills from language-conditioned demonstrations to better
generalize to unseen instructions. LISA uses vector quantization to learn
discrete skill codes that are highly correlated with language instructions and
the behavior of the learned policy. In navigation and robotic manipulation
environments, LISA outperforms a strong non-hierarchical Decision Transformer
baseline in the low data regime and is able to compose learned skills to solve
tasks containing unseen long-range instructions. Our method demonstrates a more
natural way to condition on language in sequential decision-making problems and
achieve interpretable and controllable behavior with the learned skills.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer Grammars: Augmenting Transformer Language Models with Syntactic Inductive Biases at Scale. (arXiv:2203.00633v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.00633">
<div class="article-summary-box-inner">
<span><p>We introduce Transformer Grammars (TGs), a novel class of Transformer
language models that combine (i) the expressive power, scalability, and strong
performance of Transformers and (ii) recursive syntactic compositions, which
here are implemented through a special attention mask and deterministic
transformation of the linearized tree. We find that TGs outperform various
strong baselines on sentence-level language modeling perplexity, as well as on
multiple syntax-sensitive language modeling evaluation metrics. Additionally,
we find that the recursive syntactic composition bottleneck which represents
each sentence as a single vector harms perplexity on document-level language
modeling, providing evidence that a different kind of memory mechanism -- one
that is independent of composed syntactic representations -- plays an important
role in current successful models of long text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer Language Models without Positional Encodings Still Learn Positional Information. (arXiv:2203.16634v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.16634">
<div class="article-summary-box-inner">
<span><p>Causal transformer language models (LMs), such as GPT-3, typically require
some form of positional encoding, such as positional embeddings. However, we
show that LMs without any explicit positional encoding are still competitive
with standard models, and that this phenomenon is robust across different
datasets, model sizes, and sequence lengths. Probing experiments reveal that
such models acquire an implicit notion of absolute positions throughout the
network, effectively compensating for the missing information. We conjecture
that causal attention enables the model to infer the number of predecessors
that each token can attend to, thereby approximating its absolute position. Our
findings indicate that causal LMs might derive positional awareness not only
from the explicit positioning mechanism, but also from the effects of the
causal mask.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Budge: a programming language and a theorem prover. (arXiv:2205.07979v6 [cs.PL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.07979">
<div class="article-summary-box-inner">
<span><p>We present a simple programming language based on G\"odel numbering and prime
factorization, enhanced with explicit, scoped loops, allowing for easy program
composition. Further, we will present a theorem prover that allows expressing
and working with formal systems. The theorem prover is simple as it relies
merely on a substitution rule and set equality to derive theorems. Finally, we
will represent the programming language in the theorem prover. We will show the
syntax and semantics of both, and then provide a few example programs and their
evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CodeAttack: Code-based Adversarial Attacks for Pre-Trained Programming Language Models. (arXiv:2206.00052v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.00052">
<div class="article-summary-box-inner">
<span><p>Pre-trained programming language (PL) models (such as CodeT5, CodeBERT,
GraphCodeBERT, etc.,) have the potential to automate software engineering tasks
involving code understanding and code generation. However, these models operate
in the natural channel of code, i.e., they are primarily concerned with the
human understanding of the code. They are not robust to changes in the input
and thus, are potentially susceptible to adversarial attacks in the natural
channel. We propose, CodeAttack, a simple yet effective black-box attack model
that uses code structure to generate effective, efficient, and imperceptible
adversarial code samples and demonstrates the vulnerabilities of the
state-of-the-art PL models to code-specific adversarial attacks. We evaluate
the transferability of CodeAttack on several code-code (translation and repair)
and code-NL (summarization) tasks across different programming languages.
CodeAttack outperforms state-of-the-art adversarial NLP attack models to
achieve the best overall drop in performance while being more efficient,
imperceptible, consistent, and fluent. The code can be found at
https://github.com/reddy-lab-code-research/CodeAttack.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Jeopardy: An Invertible Functional Programming Language. (arXiv:2209.02422v2 [cs.PL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.02422">
<div class="article-summary-box-inner">
<span><p>Algorithms are ways of mapping problems to solutions. An algorithm is
invertible precisely when this mapping is injective, such that the initial
problem can be uniquely inferred from its solution.
</p>
<p>While invertible algorithms can be described in general-purpose languages, no
guarantees are generally made by such languages as regards invertibility, so
ensuring invertibility requires additional (and often non-trivial) proof. On
the other hand, while reversible programming languages guarantee that their
programs are invertible by restricting the permissible operations to those
which are locally invertible, writing programs in the reversible style can be
cumbersome, and may differ significantly from conventional implementations even
when the implemented algorithm is, in fact, invertible.
</p>
<p>In this paper we introduce Jeopardy, a functional programming language that
guarantees program invertibility without imposing local reversibility. In
particular, Jeopardy allows the limited use of uninvertible -- and even
nondeterministic! -- operations, provided that they are used in a way that can
be
</p>
<p>statically determined to be invertible. To this end, we outline an
\emph{implicitly available arguments analysis} and three further approaches
that can give a partial static guarantee to the (generally difficult) problem
of guaranteeing invertibility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Two-Tailed Averaging: Anytime Adaptive Once-in-a-while Optimal Iterate Averaging for Stochastic Optimization. (arXiv:2209.12581v2 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.12581">
<div class="article-summary-box-inner">
<span><p>Tail averaging improves on Polyak averaging's non-asymptotic behaviour by
excluding a number of leading iterates of stochastic optimization from its
calculations. In practice, with a finite number of optimization steps and a
learning rate that cannot be annealed to zero, tail averaging can get much
closer to a local minimum point of the training loss than either the individual
iterates or the Polyak average. However, the number of leading iterates to
ignore is an important hyperparameter, and starting averaging too early or too
late leads to inefficient use of resources or suboptimal solutions. Our work
focusses on improving generalization, which makes setting this hyperparameter
even more difficult, especially in the presence of other hyperparameters and
overfitting. Furthermore, before averaging starts, the loss is only weakly
informative of the final performance, which makes early stopping unreliable. To
alleviate these problems, we propose an anytime variant of tail averaging
intended for improving generalization not pure optimization, that has no
hyperparameters and approximates the optimal tail at all optimization steps.
Our algorithm is based on two running averages with adaptive lengths bounded in
terms of the optimal tail length, one of which achieves approximate optimality
with some regularity. Requiring only the additional storage for two sets of
weights and periodic evaluation of the loss, the proposed two-tailed averaging
algorithm is a practical and widely applicable method for improving
generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Reason With Relational Abstractions. (arXiv:2210.02615v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.02615">
<div class="article-summary-box-inner">
<span><p>Large language models have recently shown promising progress in mathematical
reasoning when fine-tuned with human-generated sequences walking through a
sequence of solution steps. However, the solution sequences are not formally
structured and the resulting model-generated sequences may not reflect the kind
of systematic reasoning we might expect an expert human to produce. In this
paper, we study how to build stronger reasoning capability in language models
using the idea of relational abstractions. We introduce new types of sequences
that more explicitly provide an abstract characterization of the transitions
through intermediate solution steps to the goal state. We find that models that
are supplied with such sequences as prompts can solve tasks with a
significantly higher accuracy, and models that are trained to produce such
sequences solve problems better than those that are trained with previously
used human-generated sequences and other baselines. Our work thus takes several
steps toward elucidating and improving how language models perform on tasks
requiring multi-step mathematical reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Streaming Punctuation for Long-form Dictation with Transformers. (arXiv:2210.05756v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.05756">
<div class="article-summary-box-inner">
<span><p>While speech recognition Word Error Rate (WER) has reached human parity for
English, long-form dictation scenarios still suffer from segmentation and
punctuation problems resulting from irregular pausing patterns or slow
speakers. Transformer sequence tagging models are effective at capturing long
bi-directional context, which is crucial for automatic punctuation. Automatic
Speech Recognition (ASR) production systems, however, are constrained by
real-time requirements, making it hard to incorporate the right context when
making punctuation decisions. In this paper, we propose a streaming approach
for punctuation or re-punctuation of ASR output using dynamic decoding windows
and measure its impact on punctuation and segmentation accuracy across
scenarios. The new system tackles over-segmentation issues, improving
segmentation F0.5-score by 13.9%. Streaming punctuation achieves an average
BLEU-score improvement of 0.66 for the downstream task of Machine Translation
(MT).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models of Code are Few-Shot Commonsense Learners. (arXiv:2210.07128v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07128">
<div class="article-summary-box-inner">
<span><p>We address the general task of structured commonsense reasoning: given a
natural language input, the goal is to generate a graph such as an event -- or
a reasoning-graph. To employ large language models (LMs) for this task,
existing approaches ``serialize'' the output graph as a flat list of nodes and
edges. Although feasible, these serialized graphs strongly deviate from the
natural language corpora that LMs were pre-trained on, hindering LMs from
generating them correctly. In this paper, we show that when we instead frame
structured commonsense reasoning tasks as code generation tasks, pre-trained
LMs of code are better structured commonsense reasoners than LMs of natural
language, even when the downstream task does not involve source code at all. We
demonstrate our approach across three diverse structured commonsense reasoning
tasks. In all these natural language tasks, we show that using our approach, a
code generation LM (CODEX) outperforms natural-LMs that are fine-tuned on the
target task (e.g., T5) and other strong LMs such as GPT-3 in the few-shot
setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ACES: Translation Accuracy Challenge Sets for Evaluating Machine Translation Metrics. (arXiv:2210.15615v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.15615">
<div class="article-summary-box-inner">
<span><p>As machine translation (MT) metrics improve their correlation with human
judgement every year, it is crucial to understand the limitations of such
metrics at the segment level. Specifically, it is important to investigate
metric behaviour when facing accuracy errors in MT because these can have
dangerous consequences in certain contexts (e.g., legal, medical). We curate
ACES, a translation accuracy challenge set, consisting of 68 phenomena ranging
from simple perturbations at the word/character level to more complex errors
based on discourse and real-world knowledge. We use ACES to evaluate a wide
range of MT metrics including the submissions to the WMT 2022 metrics shared
task and perform several analyses leading to general recommendations for metric
developers. We recommend: a) combining metrics with different strengths, b)
developing metrics that give more weight to the source and less to
surface-level overlap with the reference and c) explicitly modelling additional
language-specific information beyond what is available via multilingual
embeddings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Impact of Social Media Posts by Executives on Stock Prices. (arXiv:2211.01287v2 [q-fin.ST] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.01287">
<div class="article-summary-box-inner">
<span><p>Predicting stock market movements has always been of great interest to
investors and an active area of research. Research has proven that popularity
of products is highly influenced by what people talk about. Social media like
Twitter, Reddit have become hotspots of such influences. This paper
investigates the impact of social media posts on close price prediction of
stocks using Twitter and Reddit posts. Our objective is to integrate sentiment
of social media data with historical stock data and study its effect on closing
prices using time series models. We carried out rigorous experiments and deep
analysis using multiple deep learning based models on different datasets to
study the influence of posts by executives and general people on the close
price. Experimental results on multiple stocks (Apple and Tesla) and
decentralised currencies (Bitcoin and Ethereum) consistently show improvements
in prediction on including social media data and greater improvements on
including executive posts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">kogito: A Commonsense Knowledge Inference Toolkit. (arXiv:2211.08451v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.08451">
<div class="article-summary-box-inner">
<span><p>In this paper, we present kogito, an open-source tool for generating
commonsense inferences about situations described in text. kogito provides an
intuitive and extensible interface to interact with natural language generation
models that can be used for hypothesizing commonsense knowledge inference from
a textual input. In particular, kogito offers several features for targeted,
multi-granularity knowledge generation. These include a standardized API for
training and evaluating knowledge models, and generating and filtering
inferences from them. We also include helper functions for converting natural
language texts into a format ingestible by knowledge models - intermediate
pipeline stages such as knowledge head extraction from text, heuristic and
model-based knowledge head-relation matching, and an ability to define and use
custom knowledge relations. We make the code for kogito available at
https://github.com/epfl-nlp/kogito along with thorough documentation at
https://kogito.readthedocs.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast and Accurate FSA System Using ELBERT: An Efficient and Lightweight BERT. (arXiv:2211.08842v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.08842">
<div class="article-summary-box-inner">
<span><p>With the development of deep learning and Transformer-based pre-trained
models like BERT, the accuracy of many NLP tasks has been dramatically
improved. However, the large number of parameters and computations also pose
challenges for their deployment. For instance, using BERT can improve the
predictions in the financial sentiment analysis (FSA) task but slow it down,
where speed and accuracy are equally important in terms of profits. To address
these issues, we first propose an efficient and lightweight BERT (ELBERT) along
with a novel confidence-window-based (CWB) early exit mechanism. Based on
ELBERT, an innovative method to accelerate text processing on the GPU platform
is developed, solving the difficult problem of making the early exit mechanism
work more effectively with a large input batch size. Afterward, a fast and
high-accuracy FSA system is built. Experimental results show that the proposed
CWB early exit mechanism achieves significantly higher accuracy than existing
early exit methods on BERT under the same computation cost. By using this
acceleration method, our FSA system can boost the processing speed by nearly 40
times to over 1000 texts per second with sufficient accuracy, which is nearly
twice as fast as FastBERT, thus providing a more powerful text processing
capability for modern trading systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UniSumm: Unified Few-shot Summarization with Multi-Task Pre-Training and Prefix-Tuning. (arXiv:2211.09783v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.09783">
<div class="article-summary-box-inner">
<span><p>The diverse demands of different summarization tasks and their high
annotation costs are driving a need for few-shot summarization. However,
despite the emergence of many summarization tasks and datasets, the current
training paradigm for few-shot summarization systems ignores potentially
shareable knowledge in heterogeneous datasets. To this end, we propose
\textsc{UniSumm}, a unified few-shot summarization model pre-trained with
multiple summarization tasks and can be prefix-tuned to excel at any few-shot
summarization datasets. Meanwhile, to better evaluate few-shot summarization
systems, under the principles of diversity and robustness, we assemble and
publicize a new benchmark \textsc{SummZoo}. It consists of $8$ diverse
summarization tasks with multiple sets of few-shot samples for each task,
covering both monologue and dialogue domains. Experimental results and ablation
studies show that \textsc{UniSumm} outperforms strong baseline systems by a
large margin across all tasks in \textsc{SummZoo} under both automatic and
human evaluations. We release our code and benchmark at
\url{https://github.com/microsoft/UniSumm}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continuous diffusion for categorical data. (arXiv:2211.15089v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.15089">
<div class="article-summary-box-inner">
<span><p>Diffusion models have quickly become the go-to paradigm for generative
modelling of perceptual signals (such as images and sound) through iterative
refinement. Their success hinges on the fact that the underlying physical
phenomena are continuous. For inherently discrete and categorical data such as
language, various diffusion-inspired alternatives have been proposed. However,
the continuous nature of diffusion models conveys many benefits, and in this
work we endeavour to preserve it. We propose CDCD, a framework for modelling
categorical data with diffusion models that are continuous both in time and
input space. We demonstrate its efficacy on several language modelling tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformers are Short Text Classifiers: A Study of Inductive Short Text Classifiers on Benchmarks and Real-world Datasets. (arXiv:2211.16878v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.16878">
<div class="article-summary-box-inner">
<span><p>Short text classification is a crucial and challenging aspect of Natural
Language Processing. For this reason, there are numerous highly specialized
short text classifiers. However, in recent short text research, State of the
Art (SOTA) methods for traditional text classification, particularly the pure
use of Transformers, have been unexploited. In this work, we examine the
performance of a variety of short text classifiers as well as the top
performing traditional text classifier. We further investigate the effects on
two new real-world short text datasets in an effort to address the issue of
becoming overly dependent on benchmark datasets with a limited number of
characteristics. Our experiments unambiguously demonstrate that Transformers
achieve SOTA accuracy on short text classification tasks, raising the question
of whether specialized short text techniques are necessary.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Orders Are Unwanted: Dynamic Deep Graph Convolutional Network for Personality Detection. (arXiv:2212.01515v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01515">
<div class="article-summary-box-inner">
<span><p>Predicting personality traits based on online posts has emerged as an
important task in many fields such as social network analysis. One of the
challenges of this task is assembling information from various posts into an
overall profile for each user. While many previous solutions simply concatenate
the posts into a long document and then encode the document by sequential or
hierarchical models, they introduce unwarranted orders for the posts, which may
mislead the models. In this paper, we propose a dynamic deep graph
convolutional network (D-DGCN) to overcome the above limitation. Specifically,
we design a learn-to-connect approach that adopts a dynamic multi-hop structure
instead of a deterministic structure, and combine it with a DGCN module to
automatically learn the connections between posts. The modules of post encoder,
learn-to-connect, and DGCN are jointly trained in an end-to-end manner.
Experimental results on the Kaggle and Pandora datasets show the superior
performance of D-DGCN to state-of-the-art baselines. Our code is available at
https://github.com/djz233/D-DGCN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analysis of Utterance Embeddings and Clustering Methods Related to Intent Induction for Task-Oriented Dialogue. (arXiv:2212.02021v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02021">
<div class="article-summary-box-inner">
<span><p>This paper investigates unsupervised approaches to overcome quintessential
challenges in designing task-oriented dialog schema: assigning intent labels to
each dialog turn (intent clustering) and generating a set of intents based on
the intent clustering methods (intent induction). We postulate there are two
salient factors for automatic induction of intents: (1) clustering algorithm
for intent labeling and (2) user utterance embedding space. We compare existing
off-the-shelf clustering models and embeddings based on DSTC11 evaluation. Our
extensive experiments demonstrate that we sholud add two huge caveat that
selection of utterance embedding and clustering method in intent induction task
should be very careful. We also present that pretrained MiniLM with
Agglomerative clustering shows significant improvement in NMI, ARI, F1,
accuracy and example coverage in intent induction tasks. The source code for
reimplementation will be available at Github.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-12-07 23:12:40.847948288 UTC">2022-12-07 23:12:40 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>