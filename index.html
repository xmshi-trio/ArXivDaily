<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-12-12T01:30:00Z">12-12</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing the Capacity of Transformer to Abstract Syntactic Representations: A Contrastive Analysis Based on Long-distance Agreement. (arXiv:2212.04523v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04523">
<div class="article-summary-box-inner">
<span><p>The long-distance agreement, evidence for syntactic structure, is
increasingly used to assess the syntactic generalization of Neural Language
Models. Much work has shown that transformers are capable of high accuracy in
varied agreement tasks, but the mechanisms by which the models accomplish this
behavior are still not well understood. To better understand transformers'
internal working, this work contrasts how they handle two superficially similar
but theoretically distinct agreement phenomena: subject-verb and object-past
participle agreement in French. Using probing and counterfactual analysis
methods, our experiments show that i) the agreement task suffers from several
confounders which partially question the conclusions drawn so far and ii)
transformers handle subject-verb and object-past participle agreements in a way
that is consistent with their modeling in theoretical linguistics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VASR: Visual Analogies of Situation Recognition. (arXiv:2212.04542v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04542">
<div class="article-summary-box-inner">
<span><p>A core process in human cognition is analogical mapping: the ability to
identify a similar relational structure between different situations. We
introduce a novel task, Visual Analogies of Situation Recognition, adapting the
classical word-analogy task into the visual domain. Given a triplet of images,
the task is to select an image candidate B' that completes the analogy (A to A'
is like B to what?). Unlike previous work on visual analogy that focused on
simple image transformations, we tackle complex analogies requiring
understanding of scenes.
</p>
<p>We leverage situation recognition annotations and the CLIP model to generate
a large set of 500k candidate analogies. Crowdsourced annotations for a sample
of the data indicate that humans agree with the dataset label ~80% of the time
(chance level 25%). Furthermore, we use human annotations to create a
gold-standard dataset of 3,820 validated analogies. Our experiments demonstrate
that state-of-the-art models do well when distractors are chosen randomly
(~86%), but struggle with carefully chosen distractors (~53%, compared to 90%
human accuracy). We hope our dataset will encourage the development of new
analogy-making models. Website: https://vasr-dataset.github.io/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explain to me like I am five -- Sentence Simplification Using Transformers. (arXiv:2212.04595v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04595">
<div class="article-summary-box-inner">
<span><p>Sentence simplification aims at making the structure of text easier to read
and understand while maintaining its original meaning. This can be helpful for
people with disabilities, new language learners, or those with low literacy.
Simplification often involves removing difficult words and rephrasing the
sentence. Previous research have focused on tackling this task by either using
external linguistic databases for simplification or by using control tokens for
desired fine-tuning of sentences. However, in this paper we purely use
pre-trained transformer models. We experiment with a combination of GPT-2 and
BERT models, achieving the best SARI score of 46.80 on the Mechanical Turk
dataset, which is significantly better than previous state-of-the-art results.
The code can be found at https://github.com/amanbasu/sentence-simplification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multidimensional Service Quality Scoring System. (arXiv:2212.04611v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04611">
<div class="article-summary-box-inner">
<span><p>This supplementary paper aims to introduce the Multidimensional Service
Quality Scoring System (MSQs), a review-based method for quantifying host
service quality mentioned and employed in the paper Exit and transition:
Exploring the survival status of Airbnb listings in a time of
professionalization. MSQs is not an end-to-end implementation and is
essentially composed of three pipelines, namely Data Collection and
Preprocessing, Objects Recognition and Grouping, and Aspect-based Service
Scoring. Using the study mentioned above as a case, the technical details of
MSQs are explained in this article.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open-world Story Generation with Structured Knowledge Enhancement: A Comprehensive Survey. (arXiv:2212.04634v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04634">
<div class="article-summary-box-inner">
<span><p>Storytelling and narrative are fundamental to human experience, intertwined
with our social and cultural engagement. As such, researchers have long
attempted to create systems that can generate stories automatically. In recent
years, powered by deep learning and massive data resources, automatic story
generation has shown significant advances. However, considerable challenges,
like the need for global coherence in generated stories, still hamper
generative models from reaching the same storytelling ability as human
narrators. To tackle these challenges, many studies seek to inject structured
knowledge into the generation process, which is referred to as structure
knowledge-enhanced story generation. Incorporating external knowledge can
enhance the logical coherence among story events, achieve better knowledge
grounding, and alleviate over-generalization and repetition problems in
stories. This survey provides the latest and comprehensive review of this
research field: (i) we present a systematical taxonomy regarding how existing
methods integrate structured knowledge into story generation; (ii) we summarize
involved story corpora, structured knowledge datasets, and evaluation metrics;
(iii) we give multidimensional insights into the challenges of
knowledge-enhanced story generation and cast light on promising directions for
future study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparative Study of Sentiment Analysis for Multi-Sourced Social Media Platforms. (arXiv:2212.04688v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04688">
<div class="article-summary-box-inner">
<span><p>There is a vast amount of data generated every second due to the rapidly
growing technology in the current world. This area of research attempts to
determine the feelings or opinions of people on social media posts. The dataset
we used was a multi-source dataset from the comment section of various social
networking sites like Twitter, Reddit, etc. Natural Language Processing
Techniques were employed to perform sentiment analysis on the obtained dataset.
In this paper, we provide a comparative analysis using techniques of
lexicon-based, machine learning and deep learning approaches. The Machine
Learning algorithm used in this work is Naive Bayes, the Lexicon-based approach
used in this work is TextBlob, and the deep-learning algorithm used in this
work is LSTM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MED-SE: Medical Entity Definition-based Sentence Embedding. (arXiv:2212.04734v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04734">
<div class="article-summary-box-inner">
<span><p>We propose Medical Entity Definition-based Sentence Embedding (MED-SE), a
novel unsupervised contrastive learning framework designed for clinical texts,
which exploits the definitions of medical entities. To this end, we conduct an
extensive analysis of multiple sentence embedding techniques in clinical
semantic textual similarity (STS) settings. In the entity-centric setting that
we have designed, MED-SE achieves significantly better performance, while the
existing unsupervised methods including SimCSE show degraded performance. Our
experiments elucidate the inherent discrepancies between the general- and
clinical-domain texts, and suggest that entity-centric contrastive approaches
may help bridge this gap and lead to a better representation of clinical
sentences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Clozing to Comprehending: Retrofitting Pre-trained Language Model to Pre-trained Machine Reader. (arXiv:2212.04755v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04755">
<div class="article-summary-box-inner">
<span><p>We present Pre-trained Machine Reader (PMR), a novel method to retrofit
Pre-trained Language Models (PLMs) into Machine Reading Comprehension (MRC)
models without acquiring labeled data. PMR is capable of resolving the
discrepancy between model pre-training and downstream fine-tuning of existing
PLMs, and provides a unified solver for tackling various extraction tasks. To
achieve this, we construct a large volume of general-purpose and high-quality
MRC-style training data with the help of Wikipedia hyperlinks and design a Wiki
Anchor Extraction task to guide the MRC-style pre-training process. Although
conceptually simple, PMR is particularly effective in solving extraction tasks
including Extractive Question Answering and Named Entity Recognition, where it
shows tremendous improvements over previous approaches especially under
low-resource settings. Moreover, viewing sequence classification task as a
special case of extraction task in our MRC formulation, PMR is even capable to
extract high-quality rationales to explain the classification process,
providing more explainability of the predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Online Migration Decisions Following the Banning of Radical Communities. (arXiv:2212.04765v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04765">
<div class="article-summary-box-inner">
<span><p>The proliferation of radical online communities and their violent offshoots
has sparked great societal concern. However, the current practice of banning
such communities from mainstream platforms has unintended consequences: (I) the
further radicalization of their members in fringe platforms where they migrate;
and (ii) the spillover of harmful content from fringe back onto mainstream
platforms. Here, in a large observational study on two banned subreddits,
r/The\_Donald and r/fatpeoplehate, we examine how factors associated with the
RECRO radicalization framework relate to users' migration decisions.
Specifically, we quantify how these factors affect users' decisions to post on
fringe platforms and, for those who do, whether they continue posting on the
mainstream platform. Our results show that individual-level factors, those
relating to the behavior of users, are associated with the decision to post on
the fringe platform. Whereas social-level factors, users' connection with the
radical community, only affect the propensity to be coactive on both platforms.
Overall, our findings pave the way for evidence-based moderation policies, as
the decisions to migrate and remain coactive amplify unintended consequences of
community bans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AUC Maximization for Low-Resource Named Entity Recognition. (arXiv:2212.04800v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04800">
<div class="article-summary-box-inner">
<span><p>Current work in named entity recognition (NER) uses either cross entropy (CE)
or conditional random fields (CRF) as the objective/loss functions to optimize
the underlying NER model. Both of these traditional objective functions for the
NER problem generally produce adequate performance when the data distribution
is balanced and there are sufficient annotated training examples. But since NER
is inherently an imbalanced tagging problem, the model performance under the
low-resource settings could suffer using these standard objective functions.
Based on recent advances in area under the ROC curve (AUC) maximization, we
propose to optimize the NER model by maximizing the AUC score. We give evidence
that by simply combining two binary-classifiers that maximize the AUC score,
significant performance improvement over traditional loss functions is achieved
under low-resource NER settings. We also conduct extensive experiments to
demonstrate the advantages of our method under the low-resource and
highly-imbalanced data distribution settings. To the best of our knowledge,
this is the first work that brings AUC maximization to the NER setting.
Furthermore, we show that our method is agnostic to different types of NER
embeddings, models and domains. The code to replicate this work will be
provided upon request.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CKG: Dynamic Representation Based on Context and Knowledge Graph. (arXiv:2212.04909v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04909">
<div class="article-summary-box-inner">
<span><p>Recently, neural language representation models pre-trained on large corpus
can capture rich co-occurrence information and be fine-tuned in downstream
tasks to improve the performance. As a result, they have achieved
state-of-the-art results in a large range of language tasks. However, there
exists other valuable semantic information such as similar, opposite, or other
possible meanings in external knowledge graphs (KGs). We argue that entities in
KGs could be used to enhance the correct semantic meaning of language
sentences. In this paper, we propose a new method CKG: Dynamic Representation
Based on \textbf{C}ontext and \textbf{K}nowledge \textbf{G}raph. On the one
side, CKG can extract rich semantic information of large corpus. On the other
side, it can make full use of inside information such as co-occurrence in large
corpus and outside information such as similar entities in KGs. We conduct
extensive experiments on a wide range of tasks, including QQP, MRPC, SST-5,
SQuAD, CoNLL 2003, and SNLI. The experiment results show that CKG achieves SOTA
89.2 on SQuAD compared with SAN (84.4), ELMo (85.8), and BERT$_{Base}$ (88.5).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TRBLLmaker -- Transformer Reads Between Lyrics Lines maker. (arXiv:2212.04917v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04917">
<div class="article-summary-box-inner">
<span><p>Even for us, it can be challenging to comprehend the meaning of songs. As
part of this project, we explore the process of generating the meaning of
songs. Despite the widespread use of text-to-text models, few attempts have
been made to achieve a similar objective. Songs are primarily studied in the
context of sentiment analysis. This involves identifying opinions and emotions
in texts, evaluating them as positive or negative, and utilizing these
evaluations to make music recommendations. In this paper, we present a
generative model that offers implicit meanings for several lines of a song. Our
model uses a decoder Transformer architecture GPT-2, where the input is the
lyrics of a song. Furthermore, we compared the performance of this architecture
with that of the encoder-decoder Transformer architecture of the T5 model. We
also examined the effect of different prompt types with the option of appending
additional information, such as the name of the artist and the title of the
song. Moreover, we tested different decoding methods with different training
parameters and evaluated our results using ROUGE. In order to build our
dataset, we utilized the 'Genious' API, which allowed us to acquire the lyrics
of songs and their explanations, as well as their rich metadata.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MOPRD: A multidisciplinary open peer review dataset. (arXiv:2212.04972v1 [cs.DL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04972">
<div class="article-summary-box-inner">
<span><p>Open peer review is a growing trend in academic publications. Public access
to peer review data can benefit both the academic and publishing communities.
It also serves as a great support to studies on review comment generation and
further to the realization of automated scholarly paper review. However, most
of the existing peer review datasets do not provide data that cover the whole
peer review process. Apart from this, their data are not diversified enough as
they are mainly collected from the field of computer science. These two
drawbacks of the currently available peer review datasets need to be addressed
to unlock more opportunities for related studies. In response to this problem,
we construct MOPRD, a multidisciplinary open peer review dataset. This dataset
consists of paper metadata, multiple version manuscripts, review comments,
meta-reviews, author's rebuttal letters, and editorial decisions. Moreover, we
design a modular guided review comment generation method based on MOPRD.
Experiments show that our method delivers better performance indicated by both
automatic metrics and human evaluation. We also explore other potential
applications of MOPRD, including meta-review generation, editorial decision
prediction, author rebuttal generation, and scientometric analysis. MOPRD is a
strong endorsement for further studies in peer review-related research and
other applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LADIS: Language Disentanglement for 3D Shape Editing. (arXiv:2212.05011v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.05011">
<div class="article-summary-box-inner">
<span><p>Natural language interaction is a promising direction for democratizing 3D
shape design. However, existing methods for text-driven 3D shape editing face
challenges in producing decoupled, local edits to 3D shapes. We address this
problem by learning disentangled latent representations that ground language in
3D geometry. To this end, we propose a complementary tool set including a novel
network architecture, a disentanglement loss, and a new editing procedure.
Additionally, to measure edit locality, we define a new metric that we call
part-wise edit precision. We show that our method outperforms existing SOTA
methods by 20% in terms of edit locality, and up to 6.6% in terms of language
reference resolution accuracy. Our work suggests that by solely disentangling
language representations, downstream 3D shape editing can become more local to
relevant parts, even if the model was never given explicit part-based
supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis. (arXiv:2212.05032v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.05032">
<div class="article-summary-box-inner">
<span><p>Large-scale diffusion models have achieved state-of-the-art results on
text-to-image synthesis (T2I) tasks. Despite their ability to generate
high-quality yet creative images, we observe that attribution-binding and
compositional capabilities are still considered major challenging issues,
especially when involving multiple objects. In this work, we improve the
compositional skills of T2I models, specifically more accurate attribute
binding and better image compositions. To do this, we incorporate linguistic
structures with the diffusion guidance process based on the controllable
properties of manipulating cross-attention layers in diffusion-based T2I
models. We observe that keys and values in cross-attention layers have strong
semantic meanings associated with object layouts and content. Therefore, we can
better preserve the compositional semantics in the generated image by
manipulating the cross-attention representations based on linguistic insights.
Built upon Stable Diffusion, a SOTA T2I model, our structured cross-attention
design is efficient that requires no additional training samples. We achieve
better compositional skills in qualitative and quantitative results, leading to
a 5-8% advantage in head-to-head user comparison studies. Lastly, we conduct an
in-depth analysis to reveal potential causes of incorrect image compositions
and justify the properties of cross-attention layers in the generation process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incorporating Emotions into Health Mention Classification Task on Social Media. (arXiv:2212.05039v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.05039">
<div class="article-summary-box-inner">
<span><p>The health mention classification (HMC) task is the process of identifying
and classifying mentions of health-related concepts in text. This can be useful
for identifying and tracking the spread of diseases through social media posts.
However, this is a non-trivial task. Here we build on recent studies suggesting
that using emotional information may improve upon this task. Our study results
in a framework for health mention classification that incorporates affective
features. We present two methods, an intermediate task fine-tuning approach
(implicit) and a multi-feature fusion approach (explicit) to incorporate
emotions into our target task of HMC. We evaluated our approach on 5
HMC-related datasets from different social media platforms including three from
Twitter, one from Reddit and another from a combination of social media
sources. Extensive experiments demonstrate that our approach results in
statistically significant performance gains on HMC tasks. By using the
multi-feature fusion approach, we achieve at least a 3% improvement in F1 score
over BERT baselines across all datasets. We also show that considering only
negative emotions does not significantly affect performance on the HMC task.
Additionally, our results indicate that HMC models infused with emotional
knowledge are an effective alternative, especially when other HMC datasets are
unavailable for domain-specific fine-tuning. The source code for our models is
freely available at https://github.com/tahirlanre/Emotion_PHM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints. (arXiv:2212.05055v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.05055">
<div class="article-summary-box-inner">
<span><p>Training large, deep neural networks to convergence can be prohibitively
expensive. As a result, often only a small selection of popular, dense models
are reused across different contexts and tasks. Increasingly, sparsely
activated models, which seek to decouple model size from computation costs, are
becoming an attractive alternative to dense models. Although more efficient in
terms of quality and computation cost, sparse models remain data-hungry and
costly to train from scratch in the large scale regime. In this work, we
propose sparse upcycling -- a simple way to reuse sunk training costs by
initializing a sparsely activated Mixture-of-Experts model from a dense
checkpoint. We show that sparsely upcycled T5 Base, Large, and XL language
models and Vision Transformer Base and Large models, respectively,
significantly outperform their dense counterparts on SuperGLUE and ImageNet,
using only ~50% of the initial dense pretraining sunk cost. The upcycled models
also outperform sparse models trained from scratch on 100% of the initial dense
pretraining computation budget.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Effective and Imperceptible Adversarial Textual Attack via Multi-objectivization. (arXiv:2111.01528v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.01528">
<div class="article-summary-box-inner">
<span><p>The field of adversarial textual attack has significantly grown over the last
few years, where the commonly considered objective is to craft adversarial
examples (AEs) that can successfully fool the target model. However, the
imperceptibility of attacks, which is also essential for practical attackers,
is often left out by previous studies. In consequence, the crafted AEs tend to
have obvious structural and semantic differences from the original
human-written texts, making them easily perceptible. In this work, we advocate
leveraging multi-objectivization to address such issue. Specifically, we
formulate the problem of crafting AEs as a multi-objective optimization
problem, where the imperceptibility of attacks is considered as auxiliary
objectives. Then, we propose a simple yet effective evolutionary algorithm,
dubbed HydraText, to solve this problem. To the best of our knowledge,
HydraText is currently the only approach that can be effectively applied to
both score-based and decision-based attack settings. Exhaustive experiments
involving 44237 instances demonstrate that HydraText consistently achieves
competitive attack success rates and better attack imperceptibility than the
recently proposed attack approaches. A human evaluation study also shows that
the AEs crafted by HydraText are more indistinguishable from human-written
texts. Finally, these AEs exhibit good transferability and can bring notable
robustness improvement to the target model by adversarial training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Transpile AMR into SPARQL. (arXiv:2112.07877v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.07877">
<div class="article-summary-box-inner">
<span><p>We propose a transition-based system to transpile Abstract Meaning
Representation (AMR) into SPARQL for Knowledge Base Question Answering (KBQA).
This allows us to delegate part of the semantic representation to a strongly
pre-trained semantic parser, while learning transpiling with small amount of
paired data. We depart from recent work relating AMR and SPARQL constructs, but
rather than applying a set of rules, we teach a BART model to selectively use
these relations. Further, we avoid explicitly encoding AMR but rather encode
the parser state in the attention mechanism of BART, following recent semantic
parsing works. The resulting model is simple, provides supporting text for its
decisions, and outperforms recent approaches in KBQA across two knowledge
bases: DBPedia (LC-QuAD 1.0, QALD-9) and Wikidata (WebQSP, SWQ-WD).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Study of Indian English Pronunciation Variabilities relative to Received Pronunciation. (arXiv:2204.06502v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.06502">
<div class="article-summary-box-inner">
<span><p>Analysis of Indian English (IE) pronunciation variabilities are useful in
building systems for Automatic Speech Recognition (ASR) and Text-to-Speech
(TTS) synthesis in the Indian context. Typically, these pronunciation
variabilities have been explored by comparing IE pronunciation with Received
Pronunciation (RP). However, to explore these variabilities, it is required to
have labelled pronunciation data at the phonetic level, which is scarce for IE.
Moreover, versatility of IE stems from the influence of a large diversity of
the speakers' mother tongues and demographic region differences. Prior
linguistic works have characterised features of IE variabilities qualitatively
by reporting phonetic rules that represent such variations relative to RP. The
qualitative descriptions often lack quantitative descriptors and data-driven
analysis of diverse IE pronunciation data to characterise IE on the phonetic
level. To address these issues, in this work, we consider a corpus, Indic
TIMIT, containing a large set of IE varieties from 80 speakers from various
regions of India. We present an analysis to obtain the new set of phonetic
rules representing IE pronunciation variabilities relative to RP in a
data-driven manner. We do this using 15,974 phonetic transcriptions, of which
13,632 were obtained manually in addition to those part of the corpus.
Furthermore, we validate the rules obtained from the analysis against the
existing phonetic rules to identify the relevance of the obtained phonetic
rules and test the efficacy of Grapheme-to-Phoneme (G2P) conversion developed
based on the obtained rules considering Phoneme Error Rate (PER) as the metric
for performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mixed-effects transformers for hierarchical adaptation. (arXiv:2205.01749v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.01749">
<div class="article-summary-box-inner">
<span><p>Language use differs dramatically from context to context. To some degree,
modern language models like GPT-3 are able to account for such variance by
conditioning on a string of previous input text, or prompt. Yet prompting is
ineffective when contexts are sparse, out-of-sample, or extra-textual; for
instance, accounting for when and where the text was produced or who produced
it. In this paper, we introduce the mixed-effects transformer (MET), a novel
approach for learning hierarchically-structured prefixes -- lightweight modules
prepended to the input -- to account for structured variation. Specifically, we
show how the popular class of mixed-effects models may be extended to
transformer-based architectures using a regularized prefix-tuning procedure
with dropout. We evaluate this approach on several domain-adaptation
benchmarks, finding that it efficiently adapts to novel contexts with minimal
data while still effectively generalizing to unseen contexts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ProQA: Structural Prompt-based Pre-training for Unified Question Answering. (arXiv:2205.04040v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.04040">
<div class="article-summary-box-inner">
<span><p>Question Answering (QA) is a longstanding challenge in natural language
processing. Existing QA works mostly focus on specific question types,
knowledge domains, or reasoning skills. The specialty in QA research hinders
systems from modeling commonalities between tasks and generalization for wider
applications. To address this issue, we present ProQA, a unified QA paradigm
that solves various tasks through a single model. ProQA takes a unified
structural prompt as the bridge and improves the QA-centric ability by
structural prompt-based pre-training. Through a structurally designed
prompt-based input schema, ProQA concurrently models the knowledge
generalization for all QA tasks while keeping the knowledge customization for
every specific QA task. Furthermore, ProQA is pre-trained with structural
prompt-formatted large-scale synthesized corpus, which empowers the model with
the commonly-required QA ability. Experimental results on 11 QA benchmarks
demonstrate that ProQA consistently boosts performance on both full data
fine-tuning, few-shot learning, and zero-shot testing scenarios. Furthermore,
ProQA exhibits strong ability in both continual learning and transfer learning
by taking the advantages of the structural prompt.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LogiGAN: Learning Logical Reasoning via Adversarial Pre-training. (arXiv:2205.08794v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08794">
<div class="article-summary-box-inner">
<span><p>We present LogiGAN, an unsupervised adversarial pre-training framework for
improving logical reasoning abilities of language models. Upon automatic
identifying logical reasoning phenomena in massive text corpus via detection
heuristics, we train language models to predict the masked-out logical
statements. Inspired by the facilitation effect of reflective thinking in human
learning, we analogically simulate the learning-thinking process with an
adversarial Generator-Verifier architecture to assist logic learning. LogiGAN
implements a novel sequential GAN approach that (a) circumvents the
non-differentiable challenge of the sequential GAN by leveraging the Generator
as a sentence-level generative likelihood scorer with a learning objective of
reaching scoring consensus with the Verifier; (b) is computationally feasible
for large-scale pre-training with arbitrary target length. Both base and large
size language models pre-trained with LogiGAN demonstrate obvious performance
improvement on 12 datasets requiring general reasoning abilities, revealing the
fundamental role of logic in broad reasoning, as well as the effectiveness of
LogiGAN. Ablation studies on LogiGAN components reveal the relative
orthogonality between linguistic and logic abilities and suggest that
reflective thinking's facilitation effect might also generalize to machine
learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Spam Reviews on Vietnamese E-commerce Websites. (arXiv:2207.14636v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.14636">
<div class="article-summary-box-inner">
<span><p>The reviews of customers play an essential role in online shopping. People
often refer to reviews or comments of previous customers to decide whether to
buy a new product. Catching up with this behavior, some people create untruths
and illegitimate reviews to hoax customers about the fake quality of products.
These are called spam reviews, confusing consumers on online shopping platforms
and negatively affecting online shopping behaviors. We propose the dataset
called ViSpamReviews, which has a strict annotation procedure for detecting
spam reviews on e-commerce platforms. Our dataset consists of two tasks: the
binary classification task for detecting whether a review is spam or not and
the multi-class classification task for identifying the type of spam. The
PhoBERT obtained the highest results on both tasks, 86.89% and 72.17%,
respectively, by macro average F1 score.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GMP*: Well-Tuned Gradual Magnitude Pruning Can Outperform Most BERT-Pruning Methods. (arXiv:2210.06384v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06384">
<div class="article-summary-box-inner">
<span><p>We revisit the performance of the classic gradual magnitude pruning (GMP)
baseline for large language models, focusing on the classic BERT benchmark on
various popular tasks. Despite existing evidence in the literature that GMP
performs poorly, we show that a simple and general variant, which we call GMP*,
can match and sometimes outperform more complex state-of-the-art methods. Our
results provide a simple yet strong baseline for future work, highlight the
importance of parameter tuning for baselines, and even improve the performance
of the state-of-the-art second-order pruning method in this setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parameter-Efficient Tuning on Layer Normalization for Pre-trained Language Models. (arXiv:2211.08682v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.08682">
<div class="article-summary-box-inner">
<span><p>Conventional fine-tuning encounters increasing difficulties given the size of
current Pre-trained Language Models, which makes parameter-efficient tuning
become the focal point of frontier research. Previous methods in this field add
tunable adapters into MHA or/and FFN of Transformer blocks to enable PLMs
achieve transferability. However, as an important part of Transformer
architecture, the power of layer normalization for parameter-efficent tuning is
ignored. In this paper, we first propose LN-tuning, by tuning the gain and bias
term of Layer Normalization module with only 0.03\% parameters, which is of
high time-efficency and significantly superior to baselines which are less than
0.1\% tunable parameters. Further, we study the unified framework of combining
LN-tuning with previous ones and we find that: (1) the unified framework of
combining prefix-tuning, the adapter-based method working on MHA, and LN-tuning
achieves SOTA performance. (2) unified framework which tunes MHA and LayerNorm
simultaneously can get performance improvement but those which tune FFN and
LayerNorm simultaneous will cause performance decrease. Ablation study
validates LN-tuning is of no abundant parameters and gives a further
understanding of it.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AGRO: Adversarial Discovery of Error-prone groups for Robust Optimization. (arXiv:2212.00921v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.00921">
<div class="article-summary-box-inner">
<span><p>Models trained via empirical risk minimization (ERM) are known to rely on
spurious correlations between labels and task-independent input features,
resulting in poor generalization to distributional shifts. Group
distributionally robust optimization (G-DRO) can alleviate this problem by
minimizing the worst-case loss over a set of pre-defined groups over training
data. G-DRO successfully improves performance of the worst-group, where the
correlation does not hold. However, G-DRO assumes that the spurious
correlations and associated worst groups are known in advance, making it
challenging to apply it to new tasks with potentially multiple unknown spurious
correlations. We propose AGRO -- Adversarial Group discovery for
Distributionally Robust Optimization -- an end-to-end approach that jointly
identifies error-prone groups and improves accuracy on them. AGRO equips G-DRO
with an adversarial slicing model to find a group assignment for training
examples which maximizes worst-case loss over the discovered groups. On the
WILDS benchmark, AGRO results in 8% higher model performance on average on
known worst-groups, compared to prior group discovery approaches used with
G-DRO. AGRO also improves out-of-distribution performance on SST2, QQP, and
MS-COCO -- datasets where potential spurious correlations are as yet
uncharacterized. Human evaluation of ARGO groups shows that they contain
well-defined, yet previously unstudied spurious correlations that lead to model
errors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Legal Prompting: Teaching a Language Model to Think Like a Lawyer. (arXiv:2212.01326v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01326">
<div class="article-summary-box-inner">
<span><p>Large language models that are capable of zero or few-shot prompting
approaches have given rise to the new research area of prompt engineering.
Recent advances showed that for example Chain-of-Thought (CoT) prompts can
improve arithmetic or common sense tasks significantly. We explore how such
approaches fare with legal reasoning tasks and take the COLIEE entailment task
based on the Japanese Bar exam for testing zero-shot/few-shot and fine-tuning
approaches. Our findings show that while CoT prompting and fine-tuning with
explanations approaches show improvements, the best results are produced by
prompts that are derived from specific legal reasoning techniques such as IRAC
(Issue, Rule, Application, Conclusion). Based on our experiments we improve the
2021 best result from 0.7037 accuracy to 0.8148 accuracy and beat the 2022 best
system of 0.6789 accuracy with an accuracy of 0.7431.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Generative Approach for Script Event Prediction via Contrastive Fine-tuning. (arXiv:2212.03496v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03496">
<div class="article-summary-box-inner">
<span><p>Script event prediction aims to predict the subsequent event given the
context. This requires the capability to infer the correlations between events.
Recent works have attempted to improve event correlation reasoning by using
pretrained language models and incorporating external knowledge~(e.g.,
discourse relations). Though promising results have been achieved, some
challenges still remain. First, the pretrained language models adopted by
current works ignore event-level knowledge, resulting in an inability to
capture the correlations between events well. Second, modeling correlations
between events with discourse relations is limited because it can only capture
explicit correlations between events with discourse markers, and cannot capture
many implicit correlations. To this end, we propose a novel generative approach
for this task, in which a pretrained language model is fine-tuned with an
event-centric pretraining objective and predicts the next event within a
generative paradigm. Specifically, we first introduce a novel event-level blank
infilling strategy as the learning objective to inject event-level knowledge
into the pretrained language model, and then design a likelihood-based
contrastive loss for fine-tuning the generative model. Instead of using an
additional prediction layer, we perform prediction by using sequence
likelihoods generated by the generative model. Our approach models correlations
between events in a soft way without any external knowledge. The
likelihood-based prediction eliminates the need to use additional networks to
make predictions and is somewhat interpretable since it scores each word in the
event. Experimental results on the multi-choice narrative cloze~(MCNC) task
demonstrate that our approach achieves better results than other
state-of-the-art baselines. Our code will be available at
https://github.com/zhufq00/mcnc.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-12-12 23:13:52.306310689 UTC">2022-12-12 23:13:52 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>