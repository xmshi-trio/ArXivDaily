<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-02-02T01:30:00Z">02-02</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">The Power of External Memory in Increasing Predictive Model Capacity. (arXiv:2302.00003v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00003">
<div class="article-summary-box-inner">
<span><p>One way of introducing sparsity into deep networks is by attaching an
external table of parameters that is sparsely looked up at different layers of
the network. By storing the bulk of the parameters in the external table, one
can increase the capacity of the model without necessarily increasing the
inference time. Two crucial questions in this setting are then: what is the
lookup function for accessing the table and how are the contents of the table
consumed? Prominent methods for accessing the table include 1) using
words/wordpieces token-ids as table indices, 2) LSH hashing the token vector in
each layer into a table of buckets, and 3) learnable softmax style routing to a
table entry. The ways to consume the contents include adding/concatenating to
input representation, and using the contents as expert networks that specialize
to different inputs. In this work, we conduct rigorous experimental evaluations
of existing ideas and their combinations. We also introduce a new method,
alternating updates, that enables access to an increased token dimension
without increasing the computation time, and demonstrate its effectiveness in
language modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">In-Context Retrieval-Augmented Language Models. (arXiv:2302.00083v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00083">
<div class="article-summary-box-inner">
<span><p>Retrieval-Augmented Language Modeling (RALM) methods, that condition a
language model (LM) on relevant documents from a grounding corpus during
generation, have been shown to significantly improve language modeling while
also providing a natural source attribution mechanism. Existing RALM approaches
focus on modifying the LM architecture in order to facilitate the incorporation
of external information, significantly complicating deployment. This paper
proposes an under-explored alternative, which we dub In-Context RALM: leaving
the LM architecture unchanged and prepending grounding documents to the input.
We show that in-context RALM which uses off-the-shelf general purpose
retrievers provides surprisingly large LM gains across model sizes and diverse
corpora. We also demonstrate that the document retrieval and ranking mechanism
can be specialized to the RALM setting to further boost performance. We
conclude that in-context RALM has considerable potential to increase the
prevalence of LM grounding, particularly in settings where a pretrained LM must
be used without modification or even via API access. To that end, we make our
code publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models Can Be Easily Distracted by Irrelevant Context. (arXiv:2302.00093v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00093">
<div class="article-summary-box-inner">
<span><p>Large language models have achieved impressive performance on various natural
language processing tasks. However, so far they have been evaluated primarily
on benchmarks where all information in the input context is relevant for
solving the task. In this work, we investigate the distractibility of large
language models, i.e., how the model problem-solving accuracy can be influenced
by irrelevant context. In particular, we introduce Grade-School Math with
Irrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant
information in the problem description. We use this benchmark to measure the
distractibility of cutting-edge prompting techniques for large language models,
and find that the model performance is dramatically decreased when irrelevant
information is included. We also identify several approaches for mitigating
this deficiency, such as decoding with self-consistency and adding to the
prompt an instruction that tells the language model to ignore the irrelevant
information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Harmful Agendas in News Articles. (arXiv:2302.00102v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00102">
<div class="article-summary-box-inner">
<span><p>Manipulated news online is a growing problem which necessitates the use of
automated systems to curtail its spread. We argue that while misinformation and
disinformation detection have been studied, there has been a lack of investment
in the important open challenge of detecting harmful agendas in news articles;
identifying harmful agendas is critical to flag news campaigns with the
greatest potential for real world harm. Moreover, due to real concerns around
censorship, harmful agenda detectors must be interpretable to be effective. In
this work, we propose this new task and release a dataset, NewsAgendas, of
annotated news articles for agenda identification. We show how interpretable
systems can be effective on this task and demonstrate that they can perform
comparably to black-box models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Translation Impact in E-commerce Multilingual Search. (arXiv:2302.00119v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00119">
<div class="article-summary-box-inner">
<span><p>Previous work suggests that performance of cross-lingual information
retrieval correlates highly with the quality of Machine Translation. However,
there may be a threshold beyond which improving query translation quality
yields little or no benefit to further improve the retrieval performance. This
threshold may depend upon multiple factors including the source and target
languages, the existing MT system quality and the search pipeline. In order to
identify the benefit of improving an MT system for a given search pipeline, we
investigate the sensitivity of retrieval quality to the presence of different
levels of MT quality using experimental datasets collected from actual traffic.
We systematically improve the performance of our MT systems quality on language
pairs as measured by MT evaluation metrics including Bleu and Chrf to determine
their impact on search precision metrics and extract signals that help to guide
the improvement strategies. Using this information we develop techniques to
compare query translations for multiple language pairs and identify the most
promising language pairs to invest and improve.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Universal Topological Regularities of Syntactic Structures: Decoupling Efficiency from Optimization. (arXiv:2302.00129v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00129">
<div class="article-summary-box-inner">
<span><p>Human syntactic structures are usually represented as graphs. Much research
has focused on the mapping between such graphs and linguistic sequences, but
less attention has been paid to the shapes of the graphs themselves: their
topologies. This study investigates how the topologies of syntactic graphs
reveal traces of the processes that led to their emergence. I report a new
universal regularity in syntactic structures: Their topology is communicatively
efficient above chance. The pattern holds, without exception, for all 124
languages studied, across linguistic families and modalities (spoken, written,
and signed). This pattern can arise from a process optimizing for communicative
efficiency or, alternatively, by construction, as a by-effect of a sublinear
preferential attachment process reflecting language production mechanisms known
from psycholinguistics. This dual explanation shows how communicative
efficiency, per se, does not require optimization. Among the two options,
efficiency without optimization offers the better explanation for the new
pattern.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Program Generation from Diverse Video Demonstrations. (arXiv:2302.00178v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00178">
<div class="article-summary-box-inner">
<span><p>The ability to use inductive reasoning to extract general rules from multiple
observations is a vital indicator of intelligence. As humans, we use this
ability to not only interpret the world around us, but also to predict the
outcomes of the various interactions we experience. Generalising over multiple
observations is a task that has historically presented difficulties for
machines to grasp, especially when requiring computer vision. In this paper, we
propose a model that can extract general rules from video demonstrations by
simultaneously performing summarisation and translation. Our approach differs
from prior works by framing the problem as a multi-sequence-to-sequence task,
wherein summarisation is learnt by the model. This allows our model to utilise
edge cases that would otherwise be suppressed or discarded by traditional
summarisation techniques. Additionally, we show that our approach can handle
noisy specifications without the need for additional filtering methods. We
evaluate our model by synthesising programs from video demonstrations in the
Vizdoom environment achieving state-of-the-art results with a relative increase
of 11.75% program accuracy on prior works
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Lexical Borrowings from Dominant Languages in Multilingual Wordlists. (arXiv:2302.00189v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00189">
<div class="article-summary-box-inner">
<span><p>Language contact is a pervasive phenomenon reflected in the borrowing of
words from donor to recipient languages. Most computational approaches to
borrowing detection treat all languages under study as equally important, even
though dominant languages have a stronger impact on heritage languages than
vice versa. We test new methods for lexical borrowing detection in contact
situations where dominant languages play an important role, applying two
classical sequence comparison methods and one machine learning method to a
sample of seven Latin American languages which have all borrowed extensively
from Spanish. All methods perform well, with the supervised machine learning
system outperforming the classical systems. A review of detection errors shows
that borrowing detection could be substantially improved by taking into account
donor words with divergent meanings from recipient words.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Transaction Represented with Weighted Finite-State Transducers. (arXiv:2302.00200v1 [cs.FL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00200">
<div class="article-summary-box-inner">
<span><p>Not all contracts are good, but all good contracts can be expressed as a
finite-state transition system ("State-Transition Contracts"). Contracts that
can be represented as State-Transition Contracts discretize fat-tailed risk to
foreseeable, managed risk, define the boundary of relevant events governed by
the relationship, and eliminate the potential of inconsistent contractual
provisions. Additionally, State-Transition Contracts reap the substantial
benefit of being able to be analyzed under the rules governing the science of
the theory of computation. Simple State-Transition Contracts can be represented
as discrete finite automata; more complicated State-Transition Contracts, such
as those that have downstream effects on other agreements or complicated
pathways of performance, benefit from representation as weighted finite-state
transducers, with weights assigned as costs, penalties, or probabilities of
transitions. This research paper (the "Research" or "Paper") presents a complex
legal transaction represented as weighted finite-state transducers.
Furthermore, we show that the mathematics/algorithms permitted by the algebraic
structure of weighted finite-state transducers provides actionable, legal
insight into the transaction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Filtering Context Mitigates Scarcity and Selection Bias in Political Ideology Prediction. (arXiv:2302.00239v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00239">
<div class="article-summary-box-inner">
<span><p>We propose a novel supervised learning approach for political ideology
prediction (PIP) that is capable of predicting out-of-distribution inputs. This
problem is motivated by the fact that manual data-labeling is expensive, while
self-reported labels are often scarce and exhibit significant selection bias.
We propose a novel statistical model that decomposes the document embeddings
into a linear superposition of two vectors; a latent neutral \emph{context}
vector independent of ideology, and a latent \emph{position} vector aligned
with ideology. We train an end-to-end model that has intermediate contextual
and positional vectors as outputs. At deployment time, our model predicts
labels for input documents by exclusively leveraging the predicted positional
vectors. On two benchmark datasets we show that our model is capable of
outputting predictions even when trained with as little as 5\% biased data, and
is significantly more accurate than the state-of-the-art. Through
crowd-sourcing we validate the neutrality of contextual vectors, and show that
context filtering results in ideological concentration, allowing for prediction
on out-of-distribution examples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Evaluation of Persian-English Machine Translation Datasets with Transformers. (arXiv:2302.00321v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00321">
<div class="article-summary-box-inner">
<span><p>Nowadays, many researchers are focusing their attention on the subject of
machine translation (MT). However, Persian machine translation has remained
unexplored despite a vast amount of research being conducted in languages with
high resources, such as English. Moreover, while a substantial amount of
research has been undertaken in statistical machine translation for some
datasets in Persian, there is currently no standard baseline for
transformer-based text2text models on each corpus. This study collected and
analysed the most popular and valuable parallel corpora, which were used for
Persian-English translation. Furthermore, we fine-tuned and evaluated two
state-of-the-art attention-based seq2seq models on each dataset separately (48
results). We hope this paper will assist researchers in comparing their Persian
to English and vice versa machine translation results to a standard baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating TCFD Reporting: A New Application of Zero-Shot Analysis to Climate-Related Financial Disclosures. (arXiv:2302.00326v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00326">
<div class="article-summary-box-inner">
<span><p>We examine climate-related disclosures in a large sample of reports published
by banks that officially endorsed the recommendations of the Task Force for
Climate-related Financial Disclosures (TCFD). In doing so, we introduce a new
application of the zero-shot text classification. By developing a set of
fine-grained TCFD labels, we show that zero-shot analysis is a useful tool for
classifying climate-related disclosures without further model training.
Overall, our findings indicate that corporate climate-related disclosures grew
dynamically after the launch of the TCFD recommendations. However, there are
marked differences in the extent of reporting by recommended disclosure topic,
suggesting that some recommendations have not yet been fully met. Our findings
yield important conclusions for the design of climate-related disclosure
frameworks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention Link: An Efficient Attention-Based Low Resource Machine Translation Architecture. (arXiv:2302.00340v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00340">
<div class="article-summary-box-inner">
<span><p>Transformers have achieved great success in machine translation, but
transformer-based NMT models often require millions of bilingual parallel
corpus for training. In this paper, we propose a novel architecture named as
attention link (AL) to help improve transformer models' performance, especially
in low training resources. We theoretically demonstrate the superiority of our
attention link architecture in low training resources. Besides, we have done a
large number of experiments, including en-de, de-en, en-fr, en-it, it-en, en-ro
translation tasks on the IWSLT14 dataset as well as real low resources scene on
bn-gu and gu-ta translation tasks on the CVIT PIB dataset. All the experiment
results show our attention link is powerful and can lead to a significant
improvement. In addition, we achieve a 37.9 BLEU score, a new sota, on the
IWSLT14 de-en task by combining our attention link and other advanced methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Study on the Transferability of Transformer Modules in Parameter-Efficient Fine-Tuning. (arXiv:2302.00378v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00378">
<div class="article-summary-box-inner">
<span><p>Parameter-efficient fine-tuning approaches have recently garnered a lot of
attention. Having considerably lower number of trainable weights, these methods
can bring about scalability and computational effectiveness. In this paper, we
look for optimal sub-networks and investigate the capability of different
transformer modules in transferring knowledge from a pre-trained model to a
downstream task. Our empirical results suggest that every transformer module in
BERT can act as a winning ticket: fine-tuning each specific module while
keeping the rest of the network frozen can lead to comparable performance to
the full fine-tuning. Among different modules, LayerNorms exhibit the best
capacity for knowledge transfer with limited trainable weights, to the extent
that, with only 0.003% of all parameters in the layer-wise analysis, they show
acceptable performance on various target tasks. On the reasons behind their
effectiveness, we argue that their notable performance could be attributed to
their high-magnitude weights compared to that of the other modules in the
pre-trained BERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">mPLUG-2: A Modularized Multi-modal Foundation Model Across Text, Image and Video. (arXiv:2302.00402v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00402">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed a big convergence of language, vision, and
multi-modal pretraining. In this work, we present mPLUG-2, a new unified
paradigm with modularized design for multi-modal pretraining, which can benefit
from modality collaboration while addressing the problem of modality
entanglement. In contrast to predominant paradigms of solely relying on
sequence-to-sequence generation or encoder-based instance discrimination,
mPLUG-2 introduces a multi-module composition network by sharing common
universal modules for modality collaboration and disentangling different
modality modules to deal with modality entanglement. It is flexible to select
different modules for different understanding and generation tasks across all
modalities including text, image, and video. Empirical study shows that mPLUG-2
achieves state-of-the-art or competitive results on a broad range of over 30
downstream tasks, spanning multi-modal tasks of image-text and video-text
understanding and generation, and uni-modal tasks of text-only, image-only, and
video-only understanding. Notably, mPLUG-2 shows new state-of-the-art results
of 48.0 top-1 accuracy and 80.3 CIDEr on the challenging MSRVTT video QA and
video caption tasks with a far smaller model size and data scale. It also
demonstrates strong zero-shot transferability on vision-language and
video-language tasks. Code and models will be released in
https://github.com/alibaba/AliceMind.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Role of Morphological Information for Contextual Lemmatization. (arXiv:2302.00407v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00407">
<div class="article-summary-box-inner">
<span><p>Lemmatization is a Natural Language Processing (NLP) task which consists of
producing, from a given inflected word, its canonical form or lemma.
Lemmatization is one of the basic tasks that facilitate downstream NLP
applications, and is of particular importance for high-inflected languages.
Given that the process to obtain a lemma from an inflected word can be
explained by looking at its morphosyntactic category, including fine-grained
morphosyntactic information to train contextual lemmatizers has become common
practice, without analyzing whether that is the optimum in terms of downstream
performance. Thus, in this paper we empirically investigate the role of
morphological information to develop contextual lemmatizers in six languages
within a varied spectrum of morphological complexity: Basque, Turkish, Russian,
Czech, Spanish and English. Furthermore, and unlike the vast majority of
previous work, we also evaluate lemmatizers in out-of-domain settings, which
constitutes, after all, their most common application use. The results of our
study are rather surprising: (i) providing lemmatizers with fine-grained
morphological features during training is not that beneficial, not even for
agglutinative languages; (ii) in fact, modern contextual word representations
seem to implicitly encode enough morphological information to obtain good
contextual lemmatizers without seeing any explicit morphological signal; (iii)
the best lemmatizers out-of-domain are those using simple UPOS tags or those
trained without morphology; (iv) current evaluation practices for lemmatization
are not adequate to clearly discriminate between models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KNNs of Semantic Encodings for Rating Prediction. (arXiv:2302.00412v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00412">
<div class="article-summary-box-inner">
<span><p>This paper explores a novel application of textual semantic similarity to
user-preference representation for rating prediction. The approach represents a
user's preferences as a graph of textual snippets from review text, where the
edges are defined by semantic similarity. This textual, memory-based approach
to rating prediction enables review-based explanations for recommendations. The
method is evaluated quantitatively, highlighting that leveraging text in this
way outperforms both strong memory-based and model-based collaborative
filtering baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved Knowledge Distillation for Pre-trained Language Models via Knowledge Selection. (arXiv:2302.00444v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00444">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation addresses the problem of transferring knowledge from a
teacher model to a student model. In this process, we typically have multiple
types of knowledge extracted from the teacher model. The problem is to make
full use of them to train the student model. Our preliminary study shows that:
(1) not all of the knowledge is necessary for learning a good student model,
and (2) knowledge distillation can benefit from certain knowledge at different
training steps. In response to these, we propose an actor-critic approach to
selecting appropriate knowledge to transfer during the process of knowledge
distillation. In addition, we offer a refinement of the training algorithm to
ease the computational burden. Experimental results on the GLUE datasets show
that our method outperforms several strong knowledge distillation baselines
significantly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HunSum-1: an Abstractive Summarization Dataset for Hungarian. (arXiv:2302.00455v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00455">
<div class="article-summary-box-inner">
<span><p>We introduce HunSum-1: a dataset for Hungarian abstractive summarization,
consisting of 1.14M news articles. The dataset is built by collecting, cleaning
and deduplicating data from 9 major Hungarian news sites through CommonCrawl.
Using this dataset, we build abstractive summarizer models based on huBERT and
mT5. We demonstrate the value of the created dataset by performing a
quantitative and qualitative analysis on the models' results. The HunSum-1
dataset, all models used in our experiments and our code are available open
source.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feed-Forward Blocks Control Contextualization in Masked Language Models. (arXiv:2302.00456v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00456">
<div class="article-summary-box-inner">
<span><p>Understanding the inner workings of neural network models is a crucial step
for rationalizing their output and refining their architecture.
Transformer-based models are the core of recent natural language processing and
have been analyzed typically with attention patterns as their epoch-making
feature is contextualizing surrounding input words via attention mechanisms. In
this study, we analyze their inner contextualization by considering all the
components, including the feed-forward block (i.e., a feed-forward layer and
its surrounding residual and normalization layers) as well as the attention.
Our experiments with masked language models show that each of the previously
overlooked components did modify the degree of the contextualization in case of
processing special word-word pairs (e.g., consisting of named entities).
Furthermore, we find that some components cancel each other's effects. Our
results could update the typical view about each component's roles (e.g.,
attention performs contextualization, and the other components serve different
roles) in the Transformer layer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">You Are What You Talk About: Inducing Evaluative Topics for Personality Analysis. (arXiv:2302.00493v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00493">
<div class="article-summary-box-inner">
<span><p>Expressing attitude or stance toward entities and concepts is an integral
part of human behavior and personality. Recently, evaluative language data has
become more accessible with social media's rapid growth, enabling large-scale
opinion analysis. However, surprisingly little research examines the
relationship between personality and evaluative language. To bridge this gap,
we introduce the notion of evaluative topics, obtained by applying topic models
to pre-filtered evaluative text from social media. We then link evaluative
topics to individual text authors to build their evaluative profiles. We apply
evaluative profiling to Reddit comments labeled with personality scores and
conduct an exploratory study on the relationship between evaluative topics and
Big Five personality facets, aiming for a more interpretable, facet-level
analysis. Finally, we validate our approach by observing correlations
consistent with prior research in personality psychology.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Semantic Perturbations on Grover. (arXiv:2302.00509v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00509">
<div class="article-summary-box-inner">
<span><p>With news and information being as easy to access as they currently are, it
is more important than ever to ensure that people are not mislead by what they
read. Recently, the rise of neural fake news (AI-generated fake news) and its
demonstrated effectiveness at fooling humans has prompted the development of
models to detect it. One such model is the Grover model, which can both detect
neural fake news to prevent it, and generate it to demonstrate how a model
could be misused to fool human readers. In this work we explore the Grover
model's fake news detection capabilities by performing targeted attacks through
perturbations on input news articles. Through this we test Grover's resilience
to these adversarial attacks and expose some potential vulnerabilities which
should be addressed in further iterations to ensure it can detect all types of
fake news accurately.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Co-Writing with Opinionated Language Models Affects Users' Views. (arXiv:2302.00560v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00560">
<div class="article-summary-box-inner">
<span><p>If large language models like GPT-3 preferably produce a particular point of
view, they may influence people's opinions on an unknown scale. This study
investigates whether a language-model-powered writing assistant that generates
some opinions more often than others impacts what users write - and what they
think. In an online experiment, we asked participants (N=1,506) to write a post
discussing whether social media is good for society. Treatment group
participants used a language-model-powered writing assistant configured to
argue that social media is good or bad for society. Participants then completed
a social media attitude survey, and independent judges (N=500) evaluated the
opinions expressed in their writing. Using the opinionated language model
affected the opinions expressed in participants' writing and shifted their
opinions in the subsequent attitude survey. We discuss the wider implications
of our results and argue that the opinions built into AI language technologies
need to be monitored and engineered more carefully.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The RW3D: A multi-modal panel dataset to understand the psychological impact of the pandemic. (arXiv:2302.00606v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00606">
<div class="article-summary-box-inner">
<span><p>Besides far-reaching public health consequences, the COVID-19 pandemic had a
significant psychological impact on people around the world. To gain further
insight into this matter, we introduce the Real World Worry Waves Dataset
(RW3D). The dataset combines rich open-ended free-text responses with survey
data on emotions, significant life events, and psychological stressors in a
repeated-measures design in the UK over three years (2020: n=2441, 2021: n=1716
and 2022: n=1152). This paper provides background information on the data
collection procedure, the recorded variables, participants' demographics, and
higher-order psychological and text-based derived variables that emerged from
the data. The RW3D is a unique primary data resource that could inspire new
research questions on the psychological impact of the pandemic, especially
those that connect modalities (here: text data, psychological survey variables
and demographics) over time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero Shot Transfer of Legal Judgement Prediction as Article-aware Entailment for the European Court of Human Rights. (arXiv:2302.00609v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00609">
<div class="article-summary-box-inner">
<span><p>In this paper, we cast Legal Judgment Prediction (LJP) from text on European
Court of Human Rights cases as an entailment task, where the case outcome is
classified from a combined input of case facts and convention articles. This
configuration facilitates the model learning legal reasoning ability in mapping
article text to specific fact text. It also provides the opportunity to
evaluate the model's ability to generalize to zero-shot settings when asked to
classify the case outcome with respect to articles not seen during training. We
devise zero-shot LJP experiments and apply domain adaptation methods based on
domain discriminator and Wasserstein distance. Our results demonstrate that the
entailment architecture outperforms straightforward fact classification. We
also find that domain adaptation methods improve zero-shot transfer
performance, with article relatedness and encoder pre-training influencing the
effect.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models. (arXiv:2302.00618v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00618">
<div class="article-summary-box-inner">
<span><p>Large language models can perform various reasoning tasks by using
chain-of-thought prompting, which guides them to find answers through
step-by-step demonstrations. However, the quality of the prompts depends on the
demonstrations given to the models, and creating many of them by hand is
costly. We introduce Synthetic prompting, a method that leverages a few
handcrafted examples to prompt the model to generate more examples by itself,
and selects effective demonstrations to elicit better reasoning. Our method
alternates between a backward and forward process to generate new examples. The
backward process generates a question that match a sampled reasoning chain, so
that the question is solvable and clear. The forward process produces a more
detailed reasoning chain for the question, improving the quality of the
example. We evaluate our method on numerical, symbolic, and algorithmic
reasoning tasks, and show that it outperforms existing prompting techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are UD Treebanks Getting More Consistent? A Report Card for English UD. (arXiv:2302.00636v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00636">
<div class="article-summary-box-inner">
<span><p>Recent efforts to consolidate guidelines and treebanks in the Universal
Dependencies project raise the expectation that joint training and dataset
comparison is increasingly possible for high-resource languages such as
English, which have multiple corpora. Focusing on the two largest UD English
treebanks, we examine progress in data consolidation and answer several
questions: Are UD English treebanks becoming more internally consistent? Are
they becoming more like each other and to what extent? Is joint training a good
idea, and if so, since which UD version? Our results indicate that while
consolidation has made progress, joint models may still suffer from
inconsistencies, which hamper their ability to leverage a larger pool of
training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does Vision Accelerate Hierarchical Generalization of Neural Language Learners?. (arXiv:2302.00667v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00667">
<div class="article-summary-box-inner">
<span><p>Neural language models (LMs) are arguably less data-efficient than humans --
why does this gap occur? In this study, we hypothesize that this gap stems from
the learners' accessibility to modalities other than text, specifically,
vision. We conducted two complementary experiments (using noisy, realistic data
and a simplified, artificial one) toward the advantage of vision in the
syntactic generalization of LMs. Our results showed that vision accelerated a
proper linguistic generalization in the simplified, artificial setting, but LMs
struggled with the noisy, realistic setting. These mixed results indicate
several possibilities, e.g., vision can potentially boost language acquisition,
but learners' additional visual/linguistic prior knowledge should be needed to
robustly make use of raw images for efficient language acquisition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">'Generative CI' through Collective Response Systems. (arXiv:2302.00672v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00672">
<div class="article-summary-box-inner">
<span><p>How can many people (who may disagree) come together to answer a question or
make a decision? "Collective response systems" are a type of generative
collective intelligence (CI) facilitation process meant to address this
challenge. They enable a form of "generative voting", where both the votes, and
the choices of what to vote on, are provided by the group. Such systems
overcome the traditional limitations of polling, town halls, standard voting,
referendums, etc. The generative CI outputs of collective response systems can
also be chained together into iterative "collective dialogues", analogously to
some kinds of generative AI.
</p>
<p>Technical advances across domains including recommender systems, language
models, and human-computer interaction have led to the development of
innovative and scalable collective response systems. For example, Polis has
been used around the world to support policy-making at different levels of
government, and Remesh has been used by the UN to understand the challenges and
needs of ordinary people across war-torn countries. This paper aims to develop
a shared language by defining the structure, processes, properties, and
principles of such systems.
</p>
<p>Collective response systems allow non-confrontational exploration of divisive
issues, help identify common ground, and elicit insights from those closest to
the issues. As a result, they can help overcome gridlock around conflict and
governance challenges, increase trust, and develop mandates. Continued progress
toward their development and adoption could help revitalize democracies,
reimagine corporate governance, transform conflict, and govern powerful AI
systems -- both as a complement to deeper deliberative democratic processes and
as an option where deeper processes are not applicable or possible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Few-Shot Generalization by Exploring and Exploiting Auxiliary Data. (arXiv:2302.00674v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00674">
<div class="article-summary-box-inner">
<span><p>Few-shot learning involves learning an effective model from only a few
labeled datapoints. The use of a small training set makes it difficult to avoid
overfitting but also makes few-shot learning applicable to many important
real-world settings. In this work, we focus on Few-shot Learning with Auxiliary
Data (FLAD), a training paradigm that assumes access to auxiliary data during
few-shot learning in hopes of improving generalization. Introducing auxiliary
data during few-shot learning leads to essential design choices where
hand-designed heuristics can lead to sub-optimal performance. In this work, we
focus on automated sampling strategies for FLAD and relate them to the
explore-exploit dilemma that is central in multi-armed bandit settings. Based
on this connection we propose two algorithms -- EXP3-FLAD and UCB1-FLAD -- and
compare them with methods that either explore or exploit, finding that the
combination of exploration and exploitation is crucial. Using our proposed
algorithms to train T5 yields a 9% absolute improvement over the explicitly
multi-task pre-trained T0 model across 11 datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic generation of semantic corpora for improving intent estimation of taxonomy-driven search engines. (arXiv:2203.16230v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.16230">
<div class="article-summary-box-inner">
<span><p>With the increasing demand of intelligent systems capable of operating in
different user contexts (e.g. users on the move) the correct interpretation of
the user-need by such systems has become crucial to give a consistent answer to
the user query. The most effective techniques which are used to address such
task are in the fields of natural language processing and semantic expansion of
terms. Such systems are aimed at estimating the actual meaning of input
queries, addressing the concepts of the words which are expressed within the
user questions. The aim of this paper is to demonstrate which semantic relation
impacts the most in semantic expansion-based retrieval systems and to identify
the best tradeoff between accuracy and noise introduction when combining such
relations. The evaluations are made building a simple natural language
processing system capable of querying any taxonomy-driven domain, making use of
the combination of different semantic expansions as knowledge resources. The
proposed evaluation employs a wide and varied taxonomy as a use-case,
exploiting its labels as basis for the expansions. To build the knowledge
resources several corpora have been produced and integrated as gazetteers into
the NLP infrastructure with the purpose of estimating the pseudo-queries
corresponding to the taxonomy labels, considered as the possible intents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Answering Open-ended Ethical Quandary Questions. (arXiv:2205.05989v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.05989">
<div class="article-summary-box-inner">
<span><p>Considerable advancements have been made in various NLP tasks based on the
impressive power of large language models (LLMs) and many NLP applications are
deployed in our daily lives. In this work, we challenge the capability of LLMs
with the new task of Ethical Quandary Generative Question Answering. Ethical
quandary questions are more challenging to address because multiple conflicting
answers may exist to a single quandary. We explore the current capability of
LLMs in providing an answer with a deliberative exchange of different
perspectives to an ethical quandary, in the approach of Socratic philosophy,
instead of providing a closed answer like an oracle. We propose a model that
searches for different ethical principles applicable to the ethical quandary
and generates an answer conditioned on the chosen principles through
prompt-based few-shot learning. We also discuss the remaining challenges and
ethical issues involved in this task and suggest the direction toward
developing responsible NLP systems by incorporating human values explicitly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chain of Explanation: New Prompting Method to Generate Higher Quality Natural Language Explanation for Implicit Hate Speech. (arXiv:2209.04889v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.04889">
<div class="article-summary-box-inner">
<span><p>Recent studies have exploited advanced generative language models to generate
Natural Language Explanations (NLE) for why a certain text could be hateful. We
propose the Chain of Explanation (CoE) Prompting method, using the target group
and retrieved social norms, to generate high-quality NLE for implicit hate
speech. Providing accurate target information and high-quality related social
norms, we improved the BLUE score from 44.0 to 62.3 for NLE generation. We then
evaluate the quality of generated NLE from various automatic metrics and human
annotations of informativeness and clarity scores. The correlation analysis
between auto-metrics and human perceptions reveals insights into how to select
suitable automatic metrics for Natural Language Generation tasks. To showcase a
potential application of our proposed CoE method, we demonstrate the f1-score
improvements from 0.635 to 0.655 for the implicit hate speech classification
task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WISE: Wavelet Transformation for Boosting Transformers' Long Sequence Learning Ability. (arXiv:2210.01989v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.01989">
<div class="article-summary-box-inner">
<span><p>Transformer and its variants are fundamental neural architectures in deep
learning. Recent works show that learning attention in the Fourier space can
improve the long sequence learning capability of Transformers. We argue that
wavelet transform shall be a better choice because it captures both position
and frequency information with a linear time complexity. Therefore, in this
paper, we systematically study the synergy between wavelet transform and
Transformers. Specifically, we focus on a new paradigm WISE, which replaces the
attention in Transformers by (1) applying forward wavelet transform to project
the input sequences to multi-resolution bases, (2) conducting non-linear
transformations in the wavelet coefficient space, and (3) reconstructing the
representation in input space via backward wavelet transform. Extensive
experiments on the Long Range Arena benchmark demonstrate that learning
attention in the wavelet space using either fixed or adaptive wavelets can
consistently improve Transformer's performance and also significantly
outperform Fourier-based methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FADO: Feedback-Aware Double COntrolling Network for Emotional Support Conversation. (arXiv:2211.00250v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.00250">
<div class="article-summary-box-inner">
<span><p>Emotional Support Conversation (ESConv) aims to reduce help-seekers'emotional
distress with the supportive strategy and response. It is essential for the
supporter to select an appropriate strategy with the feedback of the
help-seeker (e.g., emotion change during dialog turns, etc) in ESConv. However,
previous methods mainly focus on the dialog history to select the strategy and
ignore the help-seeker's feedback, leading to the wrong and user-irrelevant
strategy prediction. In addition, these approaches only model the
context-to-strategy flow and pay less attention to the strategy-to-context flow
that can focus on the strategy-related context for generating the
strategy-constrain response. In this paper, we propose a Feedback-Aware Double
COntrolling Network (FADO) to make a strategy schedule and generate the
supportive response. The core module in FADO consists of a dual-level feedback
strategy selector and a double control reader. Specifically, the dual-level
feedback strategy selector leverages the turn-level and conversation-level
feedback to encourage or penalize strategies. The double control reader
constructs the novel strategy-to-context flow for generating the
strategy-constrain response. Furthermore, a strategy dictionary is designed to
enrich the semantic information of the strategy and improve the quality of
strategy-constrain response. Experimental results on ESConv show that the
proposed FADO has achieved the state-of-the-art performance in terms of both
strategy selection and response generation. Our code is available at
https://github/after/reviewing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Study of Slang Representation Methods. (arXiv:2212.05613v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.05613">
<div class="article-summary-box-inner">
<span><p>Considering the large amount of content created online by the minute,
slang-aware automatic tools are critically needed to promote social good, and
assist policymakers and moderators in restricting the spread of offensive
language, abuse, and hate speech. Despite the success of large language models
and the spontaneous emergence of slang dictionaries, it is unclear how far
their combination goes in terms of slang understanding for downstream social
good tasks. In this paper, we provide a framework to study different
combinations of representation learning models and knowledge resources for a
variety of downstream tasks that rely on slang understanding. Our experiments
show the superiority of models that have been pre-trained on social media data,
while the impact of dictionaries is positive only for static word embeddings.
Our error analysis identifies core challenges for slang representation
learning, including out-of-vocabulary words, polysemy, variance, and annotation
disagreements, which can be traced to characteristics of slang as a quickly
evolving and highly subjective language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental Health on Social Media. (arXiv:2301.11004v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.11004">
<div class="article-summary-box-inner">
<span><p>Interactions among humans on social media often convey intentions behind
their actions, yielding a psychological language resource for Mental Health
Analysis (MHA) of online users. The success of Computational Intelligence
Techniques (CIT) for inferring mental illness from such social media resources
points to NLP as a lens for causal analysis and perception mining. However, we
argue that more consequential and explainable research is required for optimal
impact on clinical psychology practice and personalized mental healthcare. To
bridge this gap, we posit two significant dimensions: (1) Causal analysis to
illustrate a cause and effect relationship in the user generated text; (2)
Perception mining to infer psychological perspectives of social effects on
online users intentions. Within the scope of Natural Language Processing (NLP),
we further explore critical areas of inquiry associated with these two
dimensions, specifically through recent advancements in discourse analysis.
This position paper guides the community to explore solutions in this space and
advance the state of practice in developing conversational agents for inferring
mental health from social media. We advocate for a more explainable approach
toward modeling computational psychology problems through the lens of language
as we observe an increased number of research contributions in dataset and
problem formulation for causal relation extraction and perception enhancements
while inferring mental states.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using novel data and ensemble models to improve automated labeling of Sustainable Development Goals. (arXiv:2301.11353v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.11353">
<div class="article-summary-box-inner">
<span><p>A number of labeling systems based on text have been proposed to help monitor
work on the United Nations (UN) Sustainable Development Goals (SDGs). Here, we
present a systematic comparison of systems using a variety of text sources and
show that systems differ considerably in their specificity (i.e., true-positive
rate) and sensitivity (i.e., true-negative rate), have systematic biases (e.g.,
are more sensitive to specific SDGs relative to others), and are susceptible to
the type and amount of text analyzed. We then show that an ensemble model that
pools labeling systems alleviates some of these limitations, exceeding the
labeling performance of all currently available systems. We conclude that
researchers and policymakers should care about the choice of labeling system
and that ensemble methods should be favored when drawing conclusions about the
absolute and relative prevalence of work on the SDGs based on automated
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">REPLUG: Retrieval-Augmented Black-Box Language Models. (arXiv:2301.12652v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.12652">
<div class="article-summary-box-inner">
<span><p>We introduce REPLUG, a retrieval-augmented language modeling framework that
treats the language model (LM) as a black box and augments it with a tuneable
retrieval model. Unlike prior retrieval-augmented LMs that train language
models with special cross attention mechanisms to encode the retrieved text,
REPLUG simply prepends retrieved documents to the input for the frozen
black-box LM. This simple design can be easily applied to any existing
retrieval and language models. Furthermore, we show that the LM can be used to
supervise the retrieval model, which can then find documents that help the LM
make better predictions. Our experiments demonstrate that REPLUG with the tuned
retriever significantly improves the performance of GPT-3 (175B) on language
modeling by 6.3%, as well as the performance of Codex on five-shot MMLU by
5.1%.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-02-02 23:13:14.606422974 UTC">2023-02-02 23:13:14 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>