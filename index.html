<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-03-16T01:30:00Z">03-16</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">MEDBERT.de: A Comprehensive German BERT Model for the Medical Domain. (arXiv:2303.08179v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08179">
<div class="article-summary-box-inner">
<span><p>This paper presents medBERT.de, a pre-trained German BERT model specifically
designed for the German medical domain. The model has been trained on a large
corpus of 4.7 Million German medical documents and has been shown to achieve
new state-of-the-art performance on eight different medical benchmarks covering
a wide range of disciplines and medical document types. In addition to
evaluating the overall performance of the model, this paper also conducts a
more in-depth analysis of its capabilities. We investigate the impact of data
deduplication on the model's performance, as well as the potential benefits of
using more efficient tokenization methods. Our results indicate that
domain-specific models such as medBERT.de are particularly useful for longer
texts, and that deduplication of training data does not necessarily lead to
improved performance. Furthermore, we found that efficient tokenization plays
only a minor role in improving model performance, and attribute most of the
improved performance to the large amount of training data. To encourage further
research, the pre-trained model weights and new benchmarks based on
radiological data are made publicly available for use by the scientific
community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NL4Opt Competition: Formulating Optimization Problems Based on Their Natural Language Descriptions. (arXiv:2303.08233v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08233">
<div class="article-summary-box-inner">
<span><p>The Natural Language for Optimization (NL4Opt) Competition was created to
investigate methods of extracting the meaning and formulation of an
optimization problem based on its text description. Specifically, the goal of
the competition is to increase the accessibility and usability of optimization
solvers by allowing non-experts to interface with them using natural language.
We separate this challenging goal into two sub-tasks: (1) recognize and label
the semantic entities that correspond to the components of the optimization
problem; (2) generate a meaning representation (i.e., a logical form) of the
problem from its detected problem entities. The first task aims to reduce
ambiguity by detecting and tagging the entities of the optimization problems.
The second task creates an intermediate representation of the linear
programming (LP) problem that is converted into a format that can be used by
commercial solvers. In this report, we present the LP word problem dataset and
shared tasks for the NeurIPS 2022 competition. Furthermore, we present the
winning solutions. Through this competition, we hope to bring interest towards
the development of novel machine learning applications and datasets for
optimization modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextualized Medication Information Extraction Using Transformer-based Deep Learning Architectures. (arXiv:2303.08259v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08259">
<div class="article-summary-box-inner">
<span><p>Objective: To develop a natural language processing (NLP) system to extract
medications and contextual information that help understand drug changes. This
project is part of the 2022 n2c2 challenge.
</p>
<p>Materials and methods: We developed NLP systems for medication mention
extraction, event classification (indicating medication changes discussed or
not), and context classification to classify medication changes context into 5
orthogonal dimensions related to drug changes. We explored 6 state-of-the-art
pretrained transformer models for the three subtasks, including GatorTron, a
large language model pretrained using &gt;90 billion words of text (including &gt;80
billion words from &gt;290 million clinical notes identified at the University of
Florida Health). We evaluated our NLP systems using annotated data and
evaluation scripts provided by the 2022 n2c2 organizers.
</p>
<p>Results:Our GatorTron models achieved the best F1-scores of 0.9828 for
medication extraction (ranked 3rd), 0.9379 for event classification (ranked
2nd), and the best micro-average accuracy of 0.9126 for context classification.
GatorTron outperformed existing transformer models pretrained using smaller
general English text and clinical text corpora, indicating the advantage of
large language models.
</p>
<p>Conclusion: This study demonstrated the advantage of using large transformer
models for contextual medication information extraction from clinical
narratives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Clinical Concept and Relation Extraction Using Prompt-based Machine Reading Comprehension. (arXiv:2303.08262v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08262">
<div class="article-summary-box-inner">
<span><p>Objective: To develop a natural language processing system that solves both
clinical concept extraction and relation extraction in a unified prompt-based
machine reading comprehension (MRC) architecture with good generalizability for
cross-institution applications.
</p>
<p>Methods: We formulate both clinical concept extraction and relation
extraction using a unified prompt-based MRC architecture and explore
state-of-the-art transformer models. We compare our MRC models with existing
deep learning models for concept extraction and end-to-end relation extraction
using two benchmark datasets developed by the 2018 National NLP Clinical
Challenges (n2c2) challenge (medications and adverse drug events) and the 2022
n2c2 challenge (relations of social determinants of health [SDoH]). We also
evaluate the transfer learning ability of the proposed MRC models in a
cross-institution setting. We perform error analyses and examine how different
prompting strategies affect the performance of MRC models.
</p>
<p>Results and Conclusion: The proposed MRC models achieve state-of-the-art
performance for clinical concept and relation extraction on the two benchmark
datasets, outperforming previous non-MRC transformer models. GatorTron-MRC
achieves the best strict and lenient F1-scores for concept extraction,
outperforming previous deep learning models on the two datasets by 1%~3% and
0.7%~1.3%, respectively. For end-to-end relation extraction, GatorTron-MRC and
BERT-MIMIC-MRC achieve the best F1-scores, outperforming previous deep learning
models by 0.9%~2.4% and 10%-11%, respectively. For cross-institution
evaluation, GatorTron-MRC outperforms traditional GatorTron by 6.4% and 16% for
the two datasets, respectively. The proposed method is better at handling
nested/overlapped concepts, extracting relations, and has good portability for
cross-institute applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Chat with the Environment: Interactive Multimodal Perception using Large Language Models. (arXiv:2303.08268v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08268">
<div class="article-summary-box-inner">
<span><p>Programming robot behaviour in a complex world faces challenges on multiple
levels, from dextrous low-level skills to high-level planning and reasoning.
Recent pre-trained Large Language Models (LLMs) have shown remarkable reasoning
ability in zero-shot robotic planning. However, it remains challenging to
ground LLMs in multimodal sensory input and continuous action output, while
enabling a robot to interact with its environment and acquire novel information
as its policies unfold. We develop a robot interaction scenario with a
partially observable state, which necessitates a robot to decide on a range of
epistemic actions in order to sample sensory information among multiple
modalities, before being able to execute the task correctly. An interactive
perception framework is therefore proposed with an LLM as its backbone, whose
ability is exploited to instruct epistemic actions and to reason over the
resulting multimodal sensations (vision, sound, haptics, proprioception), as
well as to plan an entire task execution based on the interactively acquired
information. Our study demonstrates that LLMs can provide high-level planning
and reasoning skills and control interactive robot behaviour in a multimodal
environment, while multimodal modules with the context of the environmental
state help ground the LLMs and extend their processing ability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention-likelihood relationship in transformers. (arXiv:2303.08288v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08288">
<div class="article-summary-box-inner">
<span><p>We analyze how large language models (LLMs) represent out-of-context words,
investigating their reliance on the given context to capture their semantics.
Our likelihood-guided text perturbations reveal a correlation between token
likelihood and attention values in transformer-based language models. Extensive
experiments reveal that unexpected tokens cause the model to attend less to the
information coming from themselves to compute their representations,
particularly at higher layers. These findings have valuable implications for
assessing the robustness of LLMs in real-world scenarios. Fully reproducible
codebase at https://github.com/Flegyas/AttentionLikelihood.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rediscovery of CNN's Versatility for Text-based Encoding of Raw Electronic Health Records. (arXiv:2303.08290v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08290">
<div class="article-summary-box-inner">
<span><p>Making the most use of abundant information in electronic health records
(EHR) is rapidly becoming an important topic in the medical domain. Recent work
presented a promising framework that embeds entire features in raw EHR data
regardless of its form and medical code standards. The framework, however, only
focuses on encoding EHR with minimal preprocessing and fails to consider how to
learn efficient EHR representation in terms of computation and memory usage. In
this paper, we search for a versatile encoder not only reducing the large data
into a manageable size but also well preserving the core information of
patients to perform diverse clinical tasks. We found that hierarchically
structured Convolutional Neural Network (CNN) often outperforms the
state-of-the-art model on diverse tasks such as reconstruction, prediction, and
generation, even with fewer parameters and less training time. Moreover, it
turns out that making use of the inherent hierarchy of EHR data can boost the
performance of any kind of backbone models and clinical tasks performed.
Through extensive experiments, we present concrete evidence to generalize our
research findings into real-world practice. We give a clear guideline on
building the encoder based on the research findings captured while exploring
numerous settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Study on Post-Training Quantization for Large Language Models. (arXiv:2303.08302v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08302">
<div class="article-summary-box-inner">
<span><p>Post-training quantization (\ptq) had been recently shown as a compromising
method to reduce the memory consumption and/or compute cost for large language
models. However, a comprehensive study about the effect of different
quantization schemes, different model families, different \ptq methods,
different quantization bit precision, etc, is still missing. In this work, we
provide an extensive study on those components over tens of thousands of
zero-shot experiments. Our results show that (1) Fine-grained quantization and
\ptq methods (instead of naive round-to-nearest quantization) are necessary to
achieve good accuracy and (2) Higher bits (e.g., 5 bits) with coarse-grained
quantization is more powerful than lower bits (e.g., 4 bits) with very
fine-grained quantization (whose effective bits is similar to 5-bits). We also
present recommendations about how to utilize quantization for \llms with
different sizes, and leave suggestions of future opportunities and system work
that are not resolved in this work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-speaker Emotion Transfer by Manipulating Speech Style Latents. (arXiv:2303.08329v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08329">
<div class="article-summary-box-inner">
<span><p>In recent years, emotional text-to-speech has shown considerable progress.
However, it requires a large amount of labeled data, which is not easily
accessible. Even if it is possible to acquire an emotional speech dataset,
there is still a limitation in controlling emotion intensity. In this work, we
propose a novel method for cross-speaker emotion transfer and manipulation
using vector arithmetic in latent style space. By leveraging only a few labeled
samples, we generate emotional speech from reading-style speech without losing
the speaker identity. Furthermore, emotion strength is readily controllable
using a scalar value, providing an intuitive way for users to manipulate
speech. Experimental results show the proposed method affords superior
performance in terms of expressiveness, naturalness, and controllability,
preserving speaker identity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FactReranker: Fact-guided Reranker for Faithful Radiology Report Summarization. (arXiv:2303.08335v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08335">
<div class="article-summary-box-inner">
<span><p>Automatic radiology report summarization is a crucial clinical task, whose
key challenge is to maintain factual accuracy between produced summaries and
ground truth radiology findings. Existing research adopts reinforcement
learning to directly optimize factual consistency metrics such as CheXBert or
RadGraph score. However, their decoding method using greedy search or beam
search considers no factual consistency when picking the optimal candidate,
leading to limited factual consistency improvement. To address it, we propose a
novel second-stage summarizing approach FactReranker, the first attempt that
learns to choose the best summary from all candidates based on their estimated
factual consistency score. We propose to extract medical facts of the input
medical report, its gold summary, and candidate summaries based on the RadGraph
schema and design the fact-guided reranker to efficiently incorporate the
extracted medical facts for selecting the optimal summary. We decompose the
fact-guided reranker into the factual knowledge graph generation and the
factual scorer, which allows the reranker to model the mapping between the
medical facts of the input text and its gold summary, thus can select the
optimal summary even the gold summary can't be observed during inference. We
also present a fact-based ranking metric (RadMRR) for measuring the ability of
the reranker on selecting factual consistent candidates. Experimental results
on two benchmark datasets demonstrate the superiority of our method in
generating summaries with higher factual consistency scores when compared with
existing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PR-MCS: Perturbation Robust Metric for MultiLingual Image Captioning. (arXiv:2303.08389v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08389">
<div class="article-summary-box-inner">
<span><p>Vulnerability to lexical perturbation is a critical weakness of automatic
evaluation metrics for image captioning. This paper proposes Perturbation
Robust Multi-Lingual CLIPScore(PR-MCS), which exhibits robustness to such
perturbations, as a novel reference-free image captioning metric applicable to
multiple languages. To achieve perturbation robustness, we fine-tune the text
encoder of CLIP with our language-agnostic method to distinguish the perturbed
text from the original text. To verify the robustness of PR-MCS, we introduce a
new fine-grained evaluation dataset consisting of detailed captions, critical
objects, and the relationships between the objects for 3, 000 images in five
languages. In our experiments, PR-MCS significantly outperforms baseline
metrics in capturing lexical noise of all various perturbation types in all
five languages, proving that PR-MCS is highly robust to lexical perturbations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Cross-institutional Evaluation on Breast Cancer Phenotyping NLP Algorithms on Electronic Health Records. (arXiv:2303.08448v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08448">
<div class="article-summary-box-inner">
<span><p>Objective: The generalizability of clinical large language models is usually
ignored during the model development process. This study evaluated the
generalizability of BERT-based clinical NLP models across different clinical
settings through a breast cancer phenotype extraction task.
</p>
<p>Materials and Methods: Two clinical corpora of breast cancer patients were
collected from the electronic health records from the University of Minnesota
and the Mayo Clinic, and annotated following the same guideline. We developed
three types of NLP models (i.e., conditional random field, bi-directional long
short-term memory and CancerBERT) to extract cancer phenotypes from clinical
texts. The models were evaluated for their generalizability on different test
sets with different learning strategies (model transfer vs. locally trained).
The entity coverage score was assessed with their association with the model
performances.
</p>
<p>Results: We manually annotated 200 and 161 clinical documents at UMN and MC,
respectively. The corpora of the two institutes were found to have higher
similarity between the target entities than the overall corpora. The CancerBERT
models obtained the best performances among the independent test sets from two
clinical institutes and the permutation test set. The CancerBERT model
developed in one institute and further fine-tuned in another institute achieved
reasonable performance compared to the model developed on local data (micro-F1:
0.925 vs 0.932).
</p>
<p>Conclusions: The results indicate the CancerBERT model has the best learning
ability and generalizability among the three types of clinical NLP models. The
generalizability of the models was found to be correlated with the similarity
of the target entities between the corpora.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation. (arXiv:2303.08518v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08518">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) are popular for their impressive abilities, but
the need for model-specific fine-tuning or task-specific prompt engineering can
hinder their generalization. We propose UPRISE (Universal Prompt Retrieval for
Improving zero-Shot Evaluation), which tunes a lightweight and versatile
retriever that automatically retrieves prompts for a given zero-shot task
input. Specifically, we demonstrate universality in a cross-task and
cross-model scenario: the retriever is tuned on a diverse set of tasks, but
tested on unseen task types; we use a small frozen LLM, GPT-Neo-2.7B, for
tuning the retriever, but test the retriever on different LLMs of much larger
scales, such as BLOOM-7.1B, OPT-66B and GPT3-175B. Additionally, we show that
UPRISE mitigates the hallucination problem in our experiments with ChatGPT,
suggesting its potential to improve even the strongest LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Image of the Process Interpretation of Regular Expressions is Not Closed under Bisimulation Collapse. (arXiv:2303.08553v1 [cs.LO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08553">
<div class="article-summary-box-inner">
<span><p>Axiomatization and expressibility problems for Milner's process semantics
(1984) of regular expressions modulo bisimilarity have turned out to be
difficult for the full class of expressions with deadlock 0 and empty step~1.
We report on a phenomenon that arises from the added presence of 1 when 0 is
available, and that brings a crucial reason for this difficulty into focus. To
wit, while interpretations of 1-free regular expressions are closed under
bisimulation collapse, this is not the case for the interpretations of
arbitrary regular expressions.
</p>
<p>Process graph interpretations of 1-free regular expressions satisfy the loop
existence and elimination property LEE, which is preserved under bisimulation
collapse. These features of LEE were applied for showing that an equational
proof system for 1-free regular expressions modulo bisimilarity is complete,
and that it is decidable in polynomial time whether a process graph is
bisimilar to the interpretation of a 1-free regular expression.
</p>
<p>While interpretations of regular expressions do not satisfy the property LEE
in general, we show that LEE can be recovered by refined interpretations as
graphs with 1-transitions refined interpretations with 1-transitions (which are
similar to silent steps for automata). This suggests that LEE can be expedient
also for the general axiomatization and expressibility problems. But a new
phenomenon emerges that needs to be addressed: the property of a process graph
`to can be refined into a process graph with 1-transitions and with LEE' is not
preserved under bisimulation collapse. We provide a 10-vertex graph with two
1-transitions that satisfies LEE, and in which a pair of bisimilar vertices
cannot be collapsed on to each other while preserving the refinement property.
This implies that the image of the process interpretation of regular
expressions is not closed under bisimulation collapse.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!. (arXiv:2303.08559v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08559">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have made remarkable strides in various tasks.
However, whether they are competitive few-shot solvers for information
extraction (IE) tasks and surpass fine-tuned small Pre-trained Language Models
(SLMs) remains an open problem. This paper aims to provide a thorough answer to
this problem, and moreover, to explore an approach towards effective and
economical IE systems that combine the strengths of LLMs and SLMs. Through
extensive experiments on eight datasets across three IE tasks, we show that
LLMs are not effective few-shot information extractors in general, given their
unsatisfactory performance in most settings and the high latency and budget
requirements. However, we demonstrate that LLMs can well complement SLMs and
effectively solve hard samples that SLMs struggle with. Building on these
findings, we propose an adaptive filter-then-rerank paradigm, in which SLMs act
as filters and LLMs act as rerankers. By utilizing LLMs to rerank a small
portion of difficult samples identified by SLMs, our preliminary system
consistently achieves promising improvements (2.1% F1-gain on average) on
various IE tasks, with acceptable cost of time and money.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distinguishing Cause from Effect on Categorical Data: The Uniform Channel Model. (arXiv:2303.08572v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08572">
<div class="article-summary-box-inner">
<span><p>Distinguishing cause from effect using observations of a pair of random
variables is a core problem in causal discovery. Most approaches proposed for
this task, namely additive noise models (ANM), are only adequate for
quantitative data. We propose a criterion to address the cause-effect problem
with categorical variables (living in sets with no meaningful order), inspired
by seeing a conditional probability mass function (pmf) as a discrete
memoryless channel. We select as the most likely causal direction the one in
which the conditional pmf is closer to a uniform channel (UC). The rationale is
that, in a UC, as in an ANM, the conditional entropy (of the effect given the
cause) is independent of the cause distribution, in agreement with the
principle of independence of cause and mechanism. Our approach, which we call
the uniform channel model (UCM), thus extends the ANM rationale to categorical
variables. To assess how close a conditional pmf (estimated from data) is to a
UC, we use statistical testing, supported by a closed-form estimate of a UC
channel. On the theoretical front, we prove identifiability of the UCM and show
its equivalence with a structural causal model with a low-cardinality exogenous
variable. Finally, the proposed method compares favorably with recent
state-of-the-art alternatives in experiments on synthetic, benchmark, and real
data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Uncertainty Estimation with Gaussian Process for Reliable Dialog Response Retrieval. (arXiv:2303.08599v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08599">
<div class="article-summary-box-inner">
<span><p>Deep neural networks have achieved remarkable performance in retrieval-based
dialogue systems, but they are shown to be ill calibrated. Though basic
calibration methods like Monte Carlo Dropout and Ensemble can calibrate well,
these methods are time-consuming in the training or inference stages. To tackle
these challenges, we propose an efficient uncertainty calibration framework
GPF-BERT for BERT-based conversational search, which employs a Gaussian Process
layer and the focal loss on top of the BERT architecture to achieve a
high-quality neural ranker. Extensive experiments are conducted to verify the
effectiveness of our method. In comparison with basic calibration methods,
GPF-BERT achieves the lowest empirical calibration error (ECE) in three
in-domain datasets and the distributional shift tasks, while yielding the
highest $R_{10}@1$ and MAP performance on most cases. In terms of time
consumption, our GPF-BERT has an 8$\times$ speedup.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GCRE-GPT: A Generative Model for Comparative Relation Extraction. (arXiv:2303.08601v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08601">
<div class="article-summary-box-inner">
<span><p>Given comparative text, comparative relation extraction aims to extract two
targets (\eg two cameras) in comparison and the aspect they are compared for
(\eg image quality). The extracted comparative relations form the basis of
further opinion analysis.Existing solutions formulate this task as a sequence
labeling task, to extract targets and aspects. However, they cannot directly
extract comparative relation(s) from text. In this paper, we show that
comparative relations can be directly extracted with high accuracy, by
generative model. Based on GPT-2, we propose a Generation-based Comparative
Relation Extractor (GCRE-GPT). Experiment results show that \modelname achieves
state-of-the-art accuracy on two datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Calibration and Uncertainty with P\'{o}lya-Gamma Augmentation for Dialog Retrieval Models. (arXiv:2303.08606v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08606">
<div class="article-summary-box-inner">
<span><p>Deep neural retrieval models have amply demonstrated their power but
estimating the reliability of their predictions remains challenging. Most
dialog response retrieval models output a single score for a response on how
relevant it is to a given question. However, the bad calibration of deep neural
network results in various uncertainty for the single score such that the
unreliable predictions always misinform user decisions. To investigate these
issues, we present an efficient calibration and uncertainty estimation
framework PG-DRR for dialog response retrieval models which adds a Gaussian
Process layer to a deterministic deep neural network and recovers conjugacy for
tractable posterior inference by P\'{o}lya-Gamma augmentation. Finally, PG-DRR
achieves the lowest empirical calibration error (ECE) in the in-domain datasets
and the distributional shift task while keeping $R_{10}@1$ and MAP performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Query Generation for Evidence Collection from Web Search Engines. (arXiv:2303.08652v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08652">
<div class="article-summary-box-inner">
<span><p>It is widely accepted that so-called facts can be checked by searching for
information on the Internet. This process requires a fact-checker to formulate
a search query based on the fact and to present it to a search engine. Then,
relevant and believable passages need to be identified in the search results
before a decision is made. This process is carried out by sub-editors at many
news and media organisations on a daily basis. Here, we ask the question as to
whether it is possible to automate the first step, that of query generation.
Can we automatically formulate search queries based on factual statements which
are similar to those formulated by human experts? Here, we consider similarity
both in terms of textual similarity and with respect to relevant documents
being returned by a search engine. First, we introduce a moderate-sized
evidence collection dataset which includes 390 factual statements together with
associated human-generated search queries and search results. Then, we
investigate generating queries using a number of rule-based and automatic text
generation methods based on pre-trained large language models (LLMs). We show
that these methods have different merits and propose a hybrid approach which
has superior performance in practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mirror: A Natural Language Interface for Data Querying, Summarization, and Visualization. (arXiv:2303.08697v1 [cs.DB])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08697">
<div class="article-summary-box-inner">
<span><p>We present Mirror, an open-source platform for data exploration and analysis
powered by large language models. Mirror offers an intuitive natural language
interface for querying databases, and automatically generates executable SQL
commands to retrieve relevant data and summarize it in natural language. In
addition, users can preview and manually edit the generated SQL commands to
ensure the accuracy of their queries. Mirror also generates visualizations to
facilitate understanding of the data. Designed with flexibility and human input
in mind, Mirror is suitable for both experienced data analysts and
non-technical professionals looking to gain insights from their data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Artificial Influence: An Analysis Of AI-Driven Persuasion. (arXiv:2303.08721v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08721">
<div class="article-summary-box-inner">
<span><p>Persuasion is a key aspect of what it means to be human, and is central to
business, politics, and other endeavors. Advancements in artificial
intelligence (AI) have produced AI systems that are capable of persuading
humans to buy products, watch videos, click on search results, and more. Even
systems that are not explicitly designed to persuade may do so in practice. In
the future, increasingly anthropomorphic AI systems may form ongoing
relationships with users, increasing their persuasive power. This paper
investigates the uncertain future of persuasive AI systems. We examine ways
that AI could qualitatively alter our relationship to and views regarding
persuasion by shifting the balance of persuasive power, allowing personalized
persuasion to be deployed at scale, powering misinformation campaigns, and
changing the way humans can shape their own discourse. We consider ways
AI-driven persuasion could differ from human-driven persuasion. We warn that
ubiquitous highlypersuasive AI systems could alter our information environment
so significantly so as to contribute to a loss of human control of our own
future. In response, we examine several potential responses to AI-driven
persuasion: prohibition, identification of AI agents, truthful AI, and legal
remedies. We conclude that none of these solutions will be airtight, and that
individuals and governments will need to take active steps to guard against the
most pernicious effects of persuasive AI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPT-4 Technical Report. (arXiv:2303.08774v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08774">
<div class="article-summary-box-inner">
<span><p>We report the development of GPT-4, a large-scale, multimodal model which can
accept image and text inputs and produce text outputs. While less capable than
humans in many real-world scenarios, GPT-4 exhibits human-level performance on
various professional and academic benchmarks, including passing a simulated bar
exam with a score around the top 10% of test takers. GPT-4 is a
Transformer-based model pre-trained to predict the next token in a document.
The post-training alignment process results in improved performance on measures
of factuality and adherence to desired behavior. A core component of this
project was developing infrastructure and optimization methods that behave
predictably across a wide range of scales. This allowed us to accurately
predict some aspects of GPT-4's performance based on models trained with no
more than 1/1,000th the compute of GPT-4.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cascading and Direct Approaches to Unsupervised Constituency Parsing on Spoken Sentences. (arXiv:2303.08809v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08809">
<div class="article-summary-box-inner">
<span><p>Past work on unsupervised parsing is constrained to written form. In this
paper, we present the first study on unsupervised spoken constituency parsing
given unlabeled spoken sentences and unpaired textual data. The goal is to
determine the spoken sentences' hierarchical syntactic structure in the form of
constituency parse trees, such that each node is a span of audio that
corresponds to a constituent. We compare two approaches: (1) cascading an
unsupervised automatic speech recognition (ASR) model and an unsupervised
parser to obtain parse trees on ASR transcripts, and (2) direct training an
unsupervised parser on continuous word-level speech representations. This is
done by first splitting utterances into sequences of word-level segments, and
aggregating self-supervised speech representations within segments to obtain
segment embeddings. We find that separately training a parser on the unpaired
text and directly applying it on ASR transcripts for inference produces better
results for unsupervised parsing. Additionally, our results suggest that
accurate segmentation alone may be sufficient to parse spoken sentences
accurately. Finally, we show the direct approach may learn head-directionality
correctly for both head-initial and head-final languages without any explicit
inductive bias.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Label prompt for multi-label text classification. (arXiv:2106.10076v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10076">
<div class="article-summary-box-inner">
<span><p>One of the key problems in multi-label text classification is how to take
advantage of the correlation among labels. However, it is very challenging to
directly model the correlations among labels in a complex and unknown label
space. In this paper, we propose a Label Mask multi-label text classification
model (LM-MTC), which is inspired by the idea of cloze questions of language
model. LM-MTC is able to capture implicit relationships among labels through
the powerful ability of pre-train language models. On the basis, we assign a
different token to each potential label, and randomly mask the token with a
certain probability to build a label based Masked Language Model (MLM). We
train the MTC and MLM together, further improving the generalization ability of
the model. A large number of experiments on multiple datasets demonstrate the
effectiveness of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Large and Diverse Arabic Corpus for Language Modeling. (arXiv:2201.09227v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.09227">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) have introduced a major paradigm shift in Natural
Language Processing (NLP) modeling where large pre-trained LMs became integral
to most of the NLP tasks. The LMs are intelligent enough to find useful and
relevant representations of the language without any supervision. Perhaps,
these models are used to fine-tune typical NLP tasks with significantly high
accuracy as compared to the traditional approaches. Conversely, the training of
these models requires a massively large corpus that is a good representation of
the language. English LMs generally perform better than their other language
counterparts, due to the availability of massive English corpora. This work
elaborates on the design and development of a large Arabic corpus. It consists
of over 500 GB of Arabic cleaned text targeted at improving cross-domain
knowledge and downstream generalization capability of large-scale language
models. Moreover, the corpus is utilized in the training of a large Arabic LM.
In order to evaluate the effectiveness of the LM, a number of typical NLP tasks
are fine-tuned. The tasks demonstrate a significant boost from 4.5 to 8.5% when
compared to tasks fine-tuned on multi-lingual BERT (mBERT). To the best of my
knowledge, this is currently the largest clean and diverse Arabic corpus ever
collected.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Masked Vision and Language Modeling for Multi-modal Representation Learning. (arXiv:2208.02131v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.02131">
<div class="article-summary-box-inner">
<span><p>In this paper, we study how to use masked signal modeling in vision and
language (V+L) representation learning. Instead of developing masked language
modeling (MLM) and masked image modeling (MIM) independently, we propose to
build joint masked vision and language modeling, where the masked signal of one
modality is reconstructed with the help from another modality. This is
motivated by the nature of image-text paired data that both of the image and
the text convey almost the same information but in different formats. The
masked signal reconstruction of one modality conditioned on another modality
can also implicitly learn cross-modal alignment between language tokens and
image patches. Our experiments on various V+L tasks show that the proposed
method, along with common V+L alignment losses, achieves state-of-the-art
performance in the regime of millions of pre-training data. Also, we
outperforms the other competitors by a significant margin in limited data
scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Opinion Summarization Using Approximate Geodesics. (arXiv:2209.07496v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.07496">
<div class="article-summary-box-inner">
<span><p>Opinion summarization is the task of creating summaries capturing popular
opinions from user reviews. In this paper, we introduce Geodesic Summarizer
(GeoSumm), a novel system to perform unsupervised extractive opinion
summarization. GeoSumm involves an encoder-decoder based representation
learning model, that generates representations of text as a distribution over
latent semantic units. GeoSumm generates these representations by performing
dictionary learning over pre-trained text representations at multiple decoder
layers. We then use these representations to quantify the relevance of review
sentences using a novel approximate geodesic distance based scoring mechanism.
We use the relevance scores to identify popular opinions in order to compose
general and aspect-specific summaries. Our proposed model, GeoSumm, achieves
state-of-the-art performance on three opinion summarization datasets. We
perform additional experiments to analyze the functioning of our model and
showcase the generalization ability of {\X} across different domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How GPT-3 responds to different publics on climate change and Black Lives Matter: A critical appraisal of equity in conversational AI. (arXiv:2209.13627v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.13627">
<div class="article-summary-box-inner">
<span><p>Autoregressive language models, which use deep learning to produce human-like
texts, have become increasingly widespread. Such models are powering popular
virtual assistants in areas like smart health, finance, and autonomous driving.
While the parameters of these large language models are improving, concerns
persist that these models might not work equally for all subgroups in society.
Despite growing discussions of AI fairness across disciplines, there lacks
systemic metrics to assess what equity means in dialogue systems and how to
engage different populations in the assessment loop. Grounded in theories of
deliberative democracy and science and technology studies, this paper proposes
an analytical framework for unpacking the meaning of equity in human-AI
dialogues. Using this framework, we conducted an auditing study to examine how
GPT-3 responded to different sub-populations on crucial science and social
topics: climate change and the Black Lives Matter (BLM) movement. Our corpus
consists of over 20,000 rounds of dialogues between GPT-3 and 3290 individuals
who vary in gender, race and ethnicity, education level, English as a first
language, and opinions toward the issues. We found a substantively worse user
experience with GPT-3 among the opinion and the education minority
subpopulations; however, these two groups achieved the largest knowledge gain,
changing attitudes toward supporting BLM and climate change efforts after the
chat. We traced these user experience divides to conversational differences and
found that GPT-3 used more negative expressions when it responded to the
education and opinion minority groups, compared to its responses to the
majority groups. We discuss the implications of our findings for a deliberative
conversational AI system that centralizes diversity, equity, and inclusion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DABERT: Dual Attention Enhanced BERT for Semantic Matching. (arXiv:2210.03454v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.03454">
<div class="article-summary-box-inner">
<span><p>Transformer-based pre-trained language models such as BERT have achieved
remarkable results in Semantic Sentence Matching. However, existing models
still suffer from insufficient ability to capture subtle differences. Minor
noise like word addition, deletion, and modification of sentences may cause
flipped predictions. To alleviate this problem, we propose a novel Dual
Attention Enhanced BERT (DABERT) to enhance the ability of BERT to capture
fine-grained differences in sentence pairs. DABERT comprises (1) Dual Attention
module, which measures soft word matches by introducing a new dual channel
alignment mechanism to model affinity and difference attention. (2) Adaptive
Fusion module, this module uses attention to learn the aggregation of
difference and affinity features, and generates a vector describing the
matching details of sentence pairs. We conduct extensive experiments on
well-studied semantic matching and robustness test datasets, and the
experimental results show the effectiveness of our proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Perplexity from PLM Is Unreliable for Evaluating Text Quality. (arXiv:2210.05892v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.05892">
<div class="article-summary-box-inner">
<span><p>Recently, amounts of works utilize perplexity~(PPL) to evaluate the quality
of the generated text. They suppose that if the value of PPL is smaller, the
quality(i.e. fluency) of the text to be evaluated is better. However, we find
that the PPL referee is unqualified and it cannot evaluate the generated text
fairly for the following reasons: (i) The PPL of short text is larger than long
text, which goes against common sense, (ii) The repeated text span could damage
the performance of PPL, and (iii) The punctuation marks could affect the
performance of PPL heavily. Experiments show that the PPL is unreliable for
evaluating the quality of given text. Last, we discuss the key problems with
evaluating text quality using language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MAPL: Parameter-Efficient Adaptation of Unimodal Pre-Trained Models for Vision-Language Few-Shot Prompting. (arXiv:2210.07179v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07179">
<div class="article-summary-box-inner">
<span><p>Large pre-trained models have proved to be remarkable zero- and
(prompt-based) few-shot learners in unimodal vision and language tasks. We
propose MAPL, a simple and parameter-efficient method that reuses frozen
pre-trained unimodal models and leverages their strong generalization
capabilities in multimodal vision-language (VL) settings. MAPL learns a
lightweight mapping between the representation spaces of unimodal models using
aligned image-text data, and can generalize to unseen VL tasks from just a few
in-context examples. The small number of trainable parameters makes MAPL
effective at low-data and in-domain learning. Moreover, MAPL's modularity
enables easy extension to other pre-trained models. Extensive experiments on
several visual question answering and image captioning benchmarks show that
MAPL achieves superior or competitive performance compared to similar methods
while training orders of magnitude fewer parameters. MAPL can be trained in
just a few hours using modest computational resources and public datasets. We
release our code and pre-trained model weights at
https://github.com/mair-lab/mapl.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Semantic Matching through Dependency-Enhanced Pre-trained Model with Adaptive Fusion. (arXiv:2210.08471v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08471">
<div class="article-summary-box-inner">
<span><p>Transformer-based pre-trained models like BERT have achieved great progress
on Semantic Sentence Matching. Meanwhile, dependency prior knowledge has also
shown general benefits in multiple NLP tasks. However, how to efficiently
integrate dependency prior structure into pre-trained models to better model
complex semantic matching relations is still unsettled. In this paper, we
propose the \textbf{D}ependency-Enhanced \textbf{A}daptive \textbf{F}usion
\textbf{A}ttention (\textbf{DAFA}), which explicitly introduces dependency
structure into pre-trained models and adaptively fuses it with semantic
information. Specifically, \textbf{\emph{(i)}} DAFA first proposes a
structure-sensitive paradigm to construct a dependency matrix for calibrating
attention weights. It adopts an adaptive fusion module to integrate the
obtained dependency information and the original semantic signals. Moreover,
DAFA reconstructs the attention calculation flow and provides better
interpretability. By applying it on BERT, our method achieves state-of-the-art
or competitive performance on 10 public datasets, demonstrating the benefits of
adaptively fusing dependency structure in semantic matching task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Virtuoso: Massive Multilingual Speech-Text Joint Semi-Supervised Learning for Text-To-Speech. (arXiv:2210.15447v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.15447">
<div class="article-summary-box-inner">
<span><p>This paper proposes Virtuoso, a massively multilingual speech-text joint
semi-supervised learning framework for text-to-speech synthesis (TTS) models.
Existing multilingual TTS typically supports tens of languages, which are a
small fraction of the thousands of languages in the world. One difficulty to
scale multilingual TTS to hundreds of languages is collecting high-quality
speech-text paired data in low-resource languages. This study extends Maestro,
a speech-text joint pretraining framework for automatic speech recognition
(ASR), to speech generation tasks. To train a TTS model from various types of
speech and text data, different training schemes are designed to handle
supervised (paired TTS and ASR data) and unsupervised (untranscribed speech and
unspoken text) datasets. Experimental evaluation shows that 1) multilingual TTS
models trained on Virtuoso can achieve significantly better naturalness and
intelligibility than baseline ones in seen languages, and 2) they can
synthesize reasonably intelligible and naturally sounding speech for unseen
languages where no high-quality paired TTS data is available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Terminology-aware Medical Dialogue Generation. (arXiv:2210.15551v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.15551">
<div class="article-summary-box-inner">
<span><p>Medical dialogue generation aims to generate responses according to a history
of dialogue turns between doctors and patients. Unlike open-domain dialogue
generation, this requires background knowledge specific to the medical domain.
Existing generative frameworks for medical dialogue generation fall short of
incorporating domain-specific knowledge, especially with regard to medical
terminology. In this paper, we propose a novel framework to improve medical
dialogue generation by considering features centered on domain-specific
terminology. We leverage an attention mechanism to incorporate terminologically
centred features, and fill in the semantic gap between medical background
knowledge and common utterances by enforcing language models to learn
terminology representations with an auxiliary terminology recognition task.
Experimental results demonstrate the effectiveness of our approach, in which
our proposed framework outperforms SOTA language models. Additionally, we
provide a new dataset with medical terminology annotations to support the
research on medical dialogue generation. Our dataset and code are available at
https://github.com/tangg555/meddialog.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analyzing Acoustic Word Embeddings from Pre-trained Self-supervised Speech Models. (arXiv:2210.16043v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.16043">
<div class="article-summary-box-inner">
<span><p>Given the strong results of self-supervised models on various tasks, there
have been surprisingly few studies exploring self-supervised representations
for acoustic word embeddings (AWE), fixed-dimensional vectors representing
variable-length spoken word segments. In this work, we study several
pre-trained models and pooling methods for constructing AWEs with
self-supervised representations. Owing to the contextualized nature of
self-supervised representations, we hypothesize that simple pooling methods,
such as averaging, might already be useful for constructing AWEs. When
evaluating on a standard word discrimination task, we find that HuBERT
representations with mean-pooling rival the state of the art on English AWEs.
More surprisingly, despite being trained only on English, HuBERT
representations evaluated on Xitsonga, Mandarin, and French consistently
outperform the multilingual model XLSR-53 (as well as Wav2Vec 2.0 trained on
English).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-end Spoken Language Understanding with Tree-constrained Pointer Generator. (arXiv:2210.16554v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.16554">
<div class="article-summary-box-inner">
<span><p>End-to-end spoken language understanding (SLU) suffers from the long-tail
word problem. This paper exploits contextual biasing, a technique to improve
the speech recognition of rare words, in end-to-end SLU systems. Specifically,
a tree-constrained pointer generator (TCPGen), a powerful and efficient biasing
model component, is studied, which leverages a slot shortlist with
corresponding entities to extract biasing lists. Meanwhile, to bias the SLU
model output slot distribution, a slot probability biasing (SPB) mechanism is
proposed to calculate a slot distribution from TCPGen. Experiments on the SLURP
dataset showed consistent SLU-F1 improvements using TCPGen and SPB, especially
on unseen entities. On a new split by holding out 5 slot types for the test,
TCPGen with SPB achieved zero-shot learning with an SLU-F1 score over 50%
compared to baselines which can not deal with it. In addition to slot filling,
the intent classification accuracy was also improved.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Once-for-All Sequence Compression for Self-Supervised Speech Models. (arXiv:2211.02332v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.02332">
<div class="article-summary-box-inner">
<span><p>The sequence length along the time axis is often the dominant factor of the
computation in speech processing. Works have been proposed to reduce the
sequence length for lowering the computational cost in self-supervised speech
models. However, different downstream tasks have different tolerance of
sequence compressing, so a model that produces a fixed compressing rate may not
fit all tasks. In this work, we introduce a once-for-all (OFA) sequence
compression framework for self-supervised speech models that supports a
continuous range of operating compressing rates. The framework is evaluated on
various tasks, showing marginal degradation compared to the fixed compressing
rate variants with a smooth performance-efficiency trade-off. We further
explore adaptive compressing rate learning, demonstrating the ability to select
task-specific preferred frame periods without needing a grid search.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding BLOOM: An empirical study on diverse NLP tasks. (arXiv:2211.14865v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.14865">
<div class="article-summary-box-inner">
<span><p>We view the landscape of large language models (LLMs) through the lens of the
recently released BLOOM model to understand the performance of BLOOM and other
decoder-only LLMs compared to BERT-style encoder-only models. We achieve this
by evaluating the smaller BLOOM model variants (\textit{350m/560m} and
\textit{1b3/1b7}) on several NLP benchmark datasets and popular leaderboards.
We make the following observations: (1) BLOOM performance does not scale with
parameter size, unlike other LLMs like GPT and BERT. Experiments fine-tuning
BLOOM models show that the 560m variant performs similarly to or better than
the 1b7 variant, (2) Zero-shot cross-lingual and multi-lingual fine-tuning
experiments show that BLOOM is at par or worse than monolingual GPT-2 models,
and (3) Toxicity analysis of prompt-based text generation using the
RealToxicityPrompts dataset shows that the text generated by BLOOM is at least
17\% less toxic than GPT-2 and GPT-3 models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalized Category Discovery with Decoupled Prototypical Network. (arXiv:2211.15115v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.15115">
<div class="article-summary-box-inner">
<span><p>Generalized Category Discovery (GCD) aims to recognize both known and novel
categories from a set of unlabeled data, based on another dataset labeled with
only known categories. Without considering differences between known and novel
categories, current methods learn about them in a coupled manner, which can
hurt model's generalization and discriminative ability. Furthermore, the
coupled training approach prevents these models transferring category-specific
knowledge explicitly from labeled data to unlabeled data, which can lose
high-level semantic information and impair model performance. To mitigate above
limitations, we present a novel model called Decoupled Prototypical Network
(DPN). By formulating a bipartite matching problem for category prototypes, DPN
can not only decouple known and novel categories to achieve different training
targets effectively, but also align known categories in labeled and unlabeled
data to transfer category-specific knowledge explicitly and capture high-level
semantics. Furthermore, DPN can learn more discriminative features for both
known and novel categories through our proposed Semantic-aware Prototypical
Learning (SPL). Besides capturing meaningful semantic information, SPL can also
alleviate the noise of hard pseudo labels through semantic-weighted soft
assignment. Extensive experiments show that DPN outperforms state-of-the-art
models by a large margin on all evaluation metrics across multiple benchmark
datasets. Code and data are available at https://github.com/Lackel/DPN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Author as Character and Narrator: Deconstructing Personal Narratives from the r/AmITheAsshole Reddit Community. (arXiv:2301.08104v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.08104">
<div class="article-summary-box-inner">
<span><p>In the r/AmITheAsshole subreddit, people anonymously share first person
narratives that contain some moral dilemma or conflict and ask the community to
judge who is at fault (i.e., who is "the asshole"). In general, first person
narratives are a unique storytelling domain where the author is the narrator
(the person telling the story) but can also be a character (the person living
the story) and, thus, the author has two distinct voices presented in the
story. In this study, we identify linguistic and narrative features associated
with the author as the character or as a narrator. We use these features to
answer the following questions: (1) what makes an asshole character and (2)
what makes an asshole narrator? We extract both Author-as-Character features
(e.g., demographics, narrative event chain, and emotional arc) and
Author-as-Narrator features (i.e., the style and emotion of the story as a
whole) in order to identify which aspects of the narrative are correlated with
the final moral judgment. Our work shows that "assholes" as Characters frame
themselves as lacking agency with a more positive personal arc, while
"assholes" as Narrators will tell emotional and opinionated stories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Measuring The Impact Of Programming Language Distribution. (arXiv:2302.01973v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01973">
<div class="article-summary-box-inner">
<span><p>Current benchmarks for evaluating neural code models focus on only a small
subset of programming languages, excluding many popular languages such as Go or
Rust. To ameliorate this issue, we present the BabelCode framework for
execution-based evaluation of any benchmark in any language. BabelCode enables
new investigations into the qualitative performance of models' memory, runtime,
and individual test case results. Additionally, we present a new code
translation dataset called Translating Python Programming Puzzles (TP3) from
the Python Programming Puzzles (Schuster et al. 2021) benchmark that involves
translating expert-level python functions to any language. With both BabelCode
and the TP3 benchmark, we investigate if balancing the distributions of 14
languages in a training dataset improves a large language model's performance
on low-resource languages. Training a model on a balanced corpus results in, on
average, 12.34% higher $pass@k$ across all tasks and languages compared to the
baseline. We find that this strategy achieves 66.48% better $pass@k$ on
low-resource languages at the cost of only a 12.94% decrease to high-resource
languages. In our three translation tasks, this strategy yields, on average,
30.77% better low-resource $pass@k$ while having 19.58% worse high-resource
$pass@k$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Theory of Mind May Have Spontaneously Emerged in Large Language Models. (arXiv:2302.02083v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.02083">
<div class="article-summary-box-inner">
<span><p>Theory of mind (ToM), or the ability to impute unobservable mental states to
others, is central to human social interactions, communication, empathy,
self-consciousness, and morality. We tested several language models using 40
classic false-belief tasks widely used to test ToM in humans. The models
published before 2020 showed virtually no ability to solve ToM tasks. Yet, the
first version of GPT-3 ("davinci-001"), published in May 2020, solved about 40%
of false-belief tasks-performance comparable with 3.5-year-old children. Its
second version ("davinci-002"; January 2022) solved 70% of false-belief tasks,
performance comparable with six-year-olds. Its most recent version, GPT-3.5
("davinci-003"; November 2022), solved 90% of false-belief tasks, at the level
of seven-year-olds. GPT-4 published in March 2023 solved nearly all the tasks
(95%). These findings suggest that ToM-like ability (thus far considered to be
uniquely human) may have spontaneously emerged as a byproduct of language
models' improving language skills.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TRESTLE: Toolkit for Reproducible Execution of Speech, Text and Language Experiments. (arXiv:2302.07322v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07322">
<div class="article-summary-box-inner">
<span><p>The evidence is growing that machine and deep learning methods can learn the
subtle differences between the language produced by people with various forms
of cognitive impairment such as dementia and cognitively healthy individuals.
Valuable public data repositories such as TalkBank have made it possible for
researchers in the computational community to join forces and learn from each
other to make significant advances in this area. However, due to variability in
approaches and data selection strategies used by various researchers, results
obtained by different groups have been difficult to compare directly. In this
paper, we present TRESTLE (\textbf{T}oolkit for \textbf{R}eproducible
\textbf{E}xecution of \textbf{S}peech \textbf{T}ext and \textbf{L}anguage
\textbf{E}xperiments), an open source platform that focuses on two datasets
from the TalkBank repository with dementia detection as an illustrative domain.
Successfully deployed in the hackallenge (Hackathon/Challenge) of the
International Workshop on Health Intelligence at AAAI 2022, TRESTLE provides a
precise digital blueprint of the data pre-processing and selection strategies
that can be reused via TRESTLE by other researchers seeking comparable results
with their peers and current state-of-the-art (SOTA) approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FiTs: Fine-grained Two-stage Training for Knowledge-aware Question Answering. (arXiv:2302.11799v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11799">
<div class="article-summary-box-inner">
<span><p>Knowledge-aware question answering (KAQA) requires the model to answer
questions over a knowledge base, which is essential for both open-domain QA and
domain-specific QA, especially when language models alone cannot provide all
the knowledge needed. Despite the promising result of recent KAQA systems which
tend to integrate linguistic knowledge from pre-trained language models (PLM)
and factual knowledge from knowledge graphs (KG) to answer complex questions, a
bottleneck exists in effectively fusing the representations from PLMs and KGs
because of (i) the semantic and distributional gaps between them, and (ii) the
difficulties in joint reasoning over the provided knowledge from both
modalities. To address the above two problems, we propose a Fine-grained
Two-stage training framework (FiTs) to boost the KAQA system performance: The
first stage aims at aligning representations from the PLM and the KG, thus
bridging the modality gaps between them, named knowledge adaptive
post-training. The second stage, called knowledge-aware fine-tuning, aims to
improve the model's joint reasoning ability based on the aligned
representations. In detail, we fine-tune the post-trained model via two
auxiliary self-supervised tasks in addition to the QA supervision. Extensive
experiments demonstrate that our approach achieves state-of-the-art performance
on three benchmarks in the commonsense reasoning (i.e., CommonsenseQA,
OpenbookQA) and medical question answering (i.e., MedQA-USMILE) domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Which One Are You Referring To? Multimodal Object Identification in Situated Dialogue. (arXiv:2302.14680v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.14680">
<div class="article-summary-box-inner">
<span><p>The demand for multimodal dialogue systems has been rising in various
domains, emphasizing the importance of interpreting multimodal inputs from
conversational and situational contexts. We explore three methods to tackle
this problem and evaluate them on the largest situated dialogue dataset, SIMMC
2.1. Our best method, scene-dialogue alignment, improves the performance by
~20% F1-score compared to the SIMMC 2.1 baselines. We provide analysis and
discussion regarding the limitation of our methods and the potential directions
for future works. Our code is publicly available at
https://github.com/holylovenia/multimodal-object-identification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images. (arXiv:2303.07274v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.07274">
<div class="article-summary-box-inner">
<span><p>Weird, unusual, and uncanny images pique the curiosity of observers because
they challenge commonsense. For example, an image released during the 2022
world cup depicts the famous soccer stars Lionel Messi and Cristiano Ronaldo
playing chess, which playfully violates our expectation that their competition
should occur on the football field. Humans can easily recognize and interpret
these unconventional images, but can AI models do the same? We introduce
WHOOPS!, a new dataset and benchmark for visual commonsense. The dataset is
comprised of purposefully commonsense-defying images created by designers using
publicly-available image generation tools like Midjourney. We consider several
tasks posed over the dataset. In addition to image captioning, cross-modal
matching, and visual question answering, we introduce a difficult explanation
generation task, where models must identify and explain why a given image is
unusual. Our results show that state-of-the-art models such as GPT3 and BLIP2
still lag behind human performance on WHOOPS!. We hope our dataset will inspire
the development of AI models with stronger visual commonsense reasoning
abilities. Data, models and code are available at the project website:
whoops-benchmark.github.io
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Architext: Language-Driven Generative Architecture Design. (arXiv:2303.07519v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.07519">
<div class="article-summary-box-inner">
<span><p>Architectural design is a highly complex practice that involves a wide
diversity of disciplines, technologies, proprietary design software, expertise,
and an almost infinite number of constraints, across a vast array of design
tasks. Enabling intuitive, accessible, and scalable design processes is an
important step towards performance-driven and sustainable design for all. To
that end, we introduce Architext, a novel semantic generation assistive tool.
Architext enables design generation with only natural language prompts, given
to large-scale Language Models, as input. We conduct a thorough quantitative
evaluation of Architext's downstream task performance, focusing on semantic
accuracy and diversity for a number of pre-trained language models ranging from
120 million to 6 billion parameters. Architext models are able to learn the
specific design task, generating valid residential layouts at a near 100% rate.
Accuracy shows great improvement when scaling the models, with the largest
model (GPT-J) yielding impressive accuracy ranging between 25% to over 80% for
different prompt categories. We open source the finetuned Architext models and
our synthetic dataset, hoping to inspire experimentation in this exciting area
of design research.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-03-16 23:12:40.869219933 UTC">2023-03-16 23:12:40 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>