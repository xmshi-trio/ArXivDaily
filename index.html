<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-07-10T01:30:00Z">07-10</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">PREADD: Prefix-Adaptive Decoding for Controlled Text Generation. (arXiv:2307.03214v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03214">
<div class="article-summary-box-inner">
<span><p>We propose Prefix-Adaptive Decoding (PREADD), a flexible method for
controlled text generation. Unlike existing methods that use auxiliary expert
models to control for attributes, PREADD does not require an external model,
instead relying on linearly combining output logits from multiple prompts.
Specifically, PREADD contrasts the output logits generated using a raw prompt
against those generated using a prefix-prepended prompt, enabling both positive
and negative control with respect to any attribute encapsulated by the prefix.
We evaluate PREADD on three tasks -- toxic output mitigation, gender bias
reduction, and sentiment control -- and find that PREADD outperforms not only
prompting baselines, but also an auxiliary-expert control method, by 12% or
more in relative gain on our main metrics for each task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision Language Transformers: A Survey. (arXiv:2307.03254v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03254">
<div class="article-summary-box-inner">
<span><p>Vision language tasks, such as answering questions about or generating
captions that describe an image, are difficult tasks for computers to perform.
A relatively recent body of research has adapted the pretrained transformer
architecture introduced in \citet{vaswani2017attention} to vision language
modeling. Transformer models have greatly improved performance and versatility
over previous vision language models. They do so by pretraining models on a
large generic datasets and transferring their learning to new tasks with minor
changes in architecture and parameter values. This type of transfer learning
has become the standard modeling practice in both natural language processing
and computer vision. Vision language transformers offer the promise of
producing similar advancements in tasks which require both vision and language.
In this paper, we provide a broad synthesis of the currently available research
on vision language transformer models and offer some analysis of their
strengths, limitations and some open questions that remain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">It is not Sexually Suggestive, It is Educative. Separating Sex Education from Suggestive Content on TikTok Videos. (arXiv:2307.03274v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03274">
<div class="article-summary-box-inner">
<span><p>We introduce SexTok, a multi-modal dataset composed of TikTok videos labeled
as sexually suggestive (from the annotator's point of view), sex-educational
content, or neither. Such a dataset is necessary to address the challenge of
distinguishing between sexually suggestive content and virtual sex education
videos on TikTok. Children's exposure to sexually suggestive videos has been
shown to have adversarial effects on their development. Meanwhile, virtual sex
education, especially on subjects that are more relevant to the LGBTQIA+
community, is very valuable. The platform's current system removes or penalizes
some of both types of videos, even though they serve different purposes. Our
dataset contains video URLs, and it is also audio transcribed. To validate its
importance, we explore two transformer-based models for classifying the videos.
Our preliminary results suggest that the task of distinguishing between these
types of videos is learnable but challenging. These experiments suggest that
this dataset is meaningful and invites further study on the subject.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gammatonegram Representation for End-to-End Dysarthric Speech Processing Tasks: Speech Recognition, Speaker Identification, and Intelligibility Assessment. (arXiv:2307.03296v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03296">
<div class="article-summary-box-inner">
<span><p>Dysarthria is a disability that causes a disturbance in the human speech
system and reduces the quality and intelligibility of a person's speech.
Because of this effect, the normal speech processing systems can not work
properly on impaired speech. This disability is usually associated with
physical disabilities. Therefore, designing a system that can perform some
tasks by receiving voice commands in the smart home can be a significant
achievement. In this work, we introduce gammatonegram as an effective method to
represent audio files with discriminative details, which is used as input for
the convolutional neural network. On the other word, we convert each speech
file into an image and propose image recognition system to classify speech in
different scenarios. Proposed CNN is based on the transfer learning method on
the pre-trained Alexnet. In this research, the efficiency of the proposed
system for speech recognition, speaker identification, and intelligibility
assessment is evaluated. According to the results on the UA dataset, the
proposed speech recognition system achieved 91.29% accuracy in
speaker-dependent mode, the speaker identification system acquired 87.74%
accuracy in text-dependent mode, and the intelligibility assessment system
achieved 96.47% accuracy in two-class mode. Finally, we propose a multi-network
speech recognition system that works fully automatically. This system is
located in a cascade arrangement with the two-class intelligibility assessment
system, and the output of this system activates each one of the speech
recognition networks. This architecture achieves an accuracy of 92.3% WRR. The
source code of this paper is available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InfoSync: Information Synchronization across Multilingual Semi-structured Tables. (arXiv:2307.03313v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03313">
<div class="article-summary-box-inner">
<span><p>Information Synchronization of semi-structured data across languages is
challenging. For instance, Wikipedia tables in one language should be
synchronized across languages. To address this problem, we introduce a new
dataset InfoSyncC and a two-step method for tabular synchronization. InfoSync
contains 100K entity-centric tables (Wikipedia Infoboxes) across 14 languages,
of which a subset (3.5K pairs) are manually annotated. The proposed method
includes 1) Information Alignment to map rows and 2) Information Update for
updating missing/outdated information for aligned tables across multilingual
tables. When evaluated on InfoSync, information alignment achieves an F1 score
of 87.91 (en &lt;-&gt; non-en). To evaluate information updation, we perform
human-assisted Wikipedia edits on Infoboxes for 603 table pairs. Our approach
obtains an acceptance rate of 77.28% on Wikipedia, showing the effectiveness of
the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Covering Uncommon Ground: Gap-Focused Question Generation for Answer Assessment. (arXiv:2307.03319v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03319">
<div class="article-summary-box-inner">
<span><p>Human communication often involves information gaps between the
interlocutors. For example, in an educational dialogue, a student often
provides an answer that is incomplete, and there is a gap between this answer
and the perfect one expected by the teacher. Successful dialogue then hinges on
the teacher asking about this gap in an effective manner, thus creating a rich
and interactive educational experience. We focus on the problem of generating
such gap-focused questions (GFQs) automatically. We define the task, highlight
key desired aspects of a good GFQ, and propose a model that satisfies these.
Finally, we provide an evaluation by human annotators of our generated
questions compared against human generated ones, demonstrating competitive
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BiPhone: Modeling Inter Language Phonetic Influences in Text. (arXiv:2307.03322v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03322">
<div class="article-summary-box-inner">
<span><p>A large number of people are forced to use the Web in a language they have
low literacy in due to technology asymmetries. Written text in the second
language (L2) from such users often contains a large number of errors that are
influenced by their native language (L1). We propose a method to mine phoneme
confusions (sounds in L2 that an L1 speaker is likely to conflate) for pairs of
L1 and L2. These confusions are then plugged into a generative model (Bi-Phone)
for synthetically producing corrupted L2 text. Through human evaluations, we
show that Bi-Phone generates plausible corruptions that differ across L1s and
also have widespread coverage on the Web. We also corrupt the popular language
understanding benchmark SuperGLUE with our technique (FunGLUE for Phonetically
Noised GLUE) and show that SoTA language understating models perform poorly. We
also introduce a new phoneme prediction pre-training task which helps byte
models to recover performance close to SuperGLUE. Finally, we also release the
FunGLUE benchmark to promote further research in phonetically robust language
models. To the best of our knowledge, FunGLUE is the first benchmark to
introduce L1-L2 interactions in text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Token-Level Serialized Output Training for Joint Streaming ASR and ST Leveraging Textual Alignments. (arXiv:2307.03354v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03354">
<div class="article-summary-box-inner">
<span><p>In real-world applications, users often require both translations and
transcriptions of speech to enhance their comprehension, particularly in
streaming scenarios where incremental generation is necessary. This paper
introduces a streaming Transformer-Transducer that jointly generates automatic
speech recognition (ASR) and speech translation (ST) outputs using a single
decoder. To produce ASR and ST content effectively with minimal latency, we
propose a joint token-level serialized output training method that interleaves
source and target words by leveraging an off-the-shelf textual aligner.
Experiments in monolingual (it-en) and multilingual (\{de,es,it\}-en) settings
demonstrate that our approach achieves the best quality-latency balance. With
an average ASR latency of 1s and ST latency of 1.3s, our model shows no
degradation or even improves output quality compared to separate ASR and ST
models, yielding an average improvement of 1.1 WER and 0.4 BLEU in the
multilingual case.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Biased Attitude Associations of Language Models in an Intersectional Context. (arXiv:2307.03360v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03360">
<div class="article-summary-box-inner">
<span><p>Language models are trained on large-scale corpora that embed implicit biases
documented in psychology. Valence associations (pleasantness/unpleasantness) of
social groups determine the biased attitudes towards groups and concepts in
social cognition. Building on this established literature, we quantify how
social groups are valenced in English language models using a sentence template
that provides an intersectional context. We study biases related to age,
education, gender, height, intelligence, literacy, race, religion, sex, sexual
orientation, social class, and weight. We present a concept projection approach
to capture the valence subspace through contextualized word embeddings of
language models. Adapting the projection-based approach to embedding
association tests that quantify bias, we find that language models exhibit the
most biased attitudes against gender identity, social class, and sexual
orientation signals in language. We find that the largest and better-performing
model that we study is also more biased as it effectively captures bias
embedded in sociocultural data. We validate the bias evaluation method by
overperforming on an intrinsic valence evaluation task. The approach enables us
to measure complex intersectional biases as they are known to manifest in the
outputs and applications of language models that perpetuate historical biases.
Moreover, our approach contributes to design justice as it studies the
associations of groups underrepresented in language such as transgender and
homosexual individuals.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mitigating Negative Transfer with Task Awareness for Sexism, Hate Speech, and Toxic Language Detection. (arXiv:2307.03377v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03377">
<div class="article-summary-box-inner">
<span><p>This paper proposes a novelty approach to mitigate the negative transfer
problem. In the field of machine learning, the common strategy is to apply the
Single-Task Learning approach in order to train a supervised model to solve a
specific task. Training a robust model requires a lot of data and a significant
amount of computational resources, making this solution unfeasible in cases
where data are unavailable or expensive to gather. Therefore another solution,
based on the sharing of information between tasks, has been developed:
Multi-Task Learning (MTL). Despite the recent developments regarding MTL, the
problem of negative transfer has still to be solved. Negative transfer is a
phenomenon that occurs when noisy information is shared between tasks,
resulting in a drop in performance. This paper proposes a new approach to
mitigate the negative transfer problem based on the task awareness concept. The
proposed approach results in diminishing the negative transfer together with an
improvement of performance over classic MTL solution. Moreover, the proposed
approach has been implemented in two unified architectures to detect Sexism,
Hate Speech, and Toxic Language in text comments. The proposed architectures
set a new state-of-the-art both in EXIST-2021 and HatEval-2019 benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Side-by-side Comparison of Transformers for English Implicit Discourse Relation Classification. (arXiv:2307.03378v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03378">
<div class="article-summary-box-inner">
<span><p>Though discourse parsing can help multiple NLP fields, there has been no wide
language model search done on implicit discourse relation classification. This
hinders researchers from fully utilizing public-available models in discourse
analysis. This work is a straightforward, fine-tuned discourse performance
comparison of seven pre-trained language models. We use PDTB-3, a popular
discourse relation annotated dataset. Through our model search, we raise SOTA
to 0.671 ACC and obtain novel observations. Some are contrary to what has been
reported before (Shi and Demberg, 2019b), that sentence-level pre-training
objectives (NSP, SBO, SOP) generally fail to produce the best performing model
for implicit discourse relation classification. Counterintuitively,
similar-sized PLMs with MLM and full attention led to better performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI-UPV at EXIST 2023 -- Sexism Characterization Using Large Language Models Under The Learning with Disagreements Regime. (arXiv:2307.03385v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03385">
<div class="article-summary-box-inner">
<span><p>With the increasing influence of social media platforms, it has become
crucial to develop automated systems capable of detecting instances of sexism
and other disrespectful and hateful behaviors to promote a more inclusive and
respectful online environment. Nevertheless, these tasks are considerably
challenging considering different hate categories and the author's intentions,
especially under the learning with disagreements regime. This paper describes
AI-UPV team's participation in the EXIST (sEXism Identification in Social
neTworks) Lab at CLEF 2023. The proposed approach aims at addressing the task
of sexism identification and characterization under the learning with
disagreements paradigm by training directly from the data with disagreements,
without using any aggregated label. Yet, performances considering both soft and
hard evaluations are reported. The proposed system uses large language models
(i.e., mBERT and XLM-RoBERTa) and ensemble strategies for sexism identification
and classification in English and Spanish. In particular, our system is
articulated in three different pipelines. The ensemble approach outperformed
the individual large language models obtaining the best performances both
adopting a soft and a hard label evaluation. This work describes the
participation in all the three EXIST tasks, considering a soft evaluation, it
obtained fourth place in Task 2 at EXIST and first place in Task 3, with the
highest ICM-Soft of -2.32 and a normalized ICM-Soft of 0.79. The source code of
our approaches is publicly available at
https://github.com/AngelFelipeMP/Sexism-LLM-Learning-With-Disagreement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Derivative Free Weight-space Ensembling. (arXiv:2307.03506v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03506">
<div class="article-summary-box-inner">
<span><p>Recent work suggests that interpolating between the weights of two
specialized language models can transfer knowledge between tasks in a way that
multi-task learning cannot. However, very few have explored interpolation
between more than two models, where each has a distinct knowledge base. In this
paper, we introduce Derivative Free Weight-space Ensembling (DFWE), a new
few-sample task transfer approach for open-domain dialogue. Our framework
creates a set of diverse expert language models trained using a predefined set
of source tasks. Next, we finetune each of the expert models on the target
task, approaching the target task from several distinct knowledge bases.
Finally, we linearly interpolate between the model weights using a
gradient-free-optimization algorithm, to efficiently find a good interpolation
weighting. We demonstrate the effectiveness of the method on FETA-Friends
outperforming the standard pretrain-finetune approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantifying the perceptual value of lexical and non-lexical channels in speech. (arXiv:2307.03534v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03534">
<div class="article-summary-box-inner">
<span><p>Speech is a fundamental means of communication that can be seen to provide
two channels for transmitting information: the lexical channel of which words
are said, and the non-lexical channel of how they are spoken. Both channels
shape listener expectations of upcoming communication; however, directly
quantifying their relative effect on expectations is challenging. Previous
attempts require spoken variations of lexically-equivalent dialogue turns or
conspicuous acoustic manipulations. This paper introduces a generalised
paradigm to study the value of non-lexical information in dialogue across
unconstrained lexical content. By quantifying the perceptual value of the
non-lexical channel with both accuracy and entropy reduction, we show that
non-lexical information produces a consistent effect on expectations of
upcoming dialogue: even when it leads to poorer discriminative turn judgements
than lexical content alone, it yields higher consensus among participants.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models as Batteries-Included Zero-Shot ESCO Skills Matchers. (arXiv:2307.03539v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03539">
<div class="article-summary-box-inner">
<span><p>Understanding labour market dynamics requires accurately identifying the
skills required for and possessed by the workforce. Automation techniques are
increasingly being developed to support this effort. However, automatically
extracting skills from job postings is challenging due to the vast number of
existing skills. The ESCO (European Skills, Competences, Qualifications and
Occupations) framework provides a useful reference, listing over 13,000
individual skills. However, skills extraction remains difficult and accurately
matching job posts to the ESCO taxonomy is an open problem. In this work, we
propose an end-to-end zero-shot system for skills extraction from job
descriptions based on large language models (LLMs). We generate synthetic
training data for the entirety of ESCO skills and train a classifier to extract
skill mentions from job posts. We also employ a similarity retriever to
generate skill candidates which are then re-ranked using a second LLM. Using
synthetic data achieves an RP@10 score 10 points higher than previous distant
supervision approaches. Adding GPT-4 re-ranking improves RP@10 by over 22
points over previous methods. We also show that Framing the task as mock
programming when prompting the LLM can lead to better performance than natural
language prompts, especially with weaker LLMs. We demonstrate the potential of
integrating large language models at both ends of skills matching pipelines.
Our approach requires no human annotations and achieve extremely promising
results on skills extraction against ESCO.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through Style-based Data Sampling. (arXiv:2307.03550v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03550">
<div class="article-summary-box-inner">
<span><p>This paper describes our submission for the subjectivity detection task at
the CheckThat! Lab. To tackle class imbalances in the task, we have generated
additional training materials with GPT-3 models using prompts of different
styles from a subjectivity checklist based on journalistic perspective. We used
the extended training set to fine-tune language-specific transformer models.
Our experiments in English, German and Turkish demonstrate that different
subjective styles are effective across all languages. In addition, we observe
that the style-based oversampling is better than paraphrasing in Turkish and
English. Lastly, the GPT-3 models sometimes produce lacklustre results when
generating style-based texts in non-English languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text Simplification of Scientific Texts for Non-Expert Readers. (arXiv:2307.03569v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03569">
<div class="article-summary-box-inner">
<span><p>Reading levels are highly individual and can depend on a text's language, a
person's cognitive abilities, or knowledge on a topic. Text simplification is
the task of rephrasing a text to better cater to the abilities of a specific
target reader group. Simplification of scientific abstracts helps non-experts
to access the core information by bypassing formulations that require domain or
expert knowledge. This is especially relevant for, e.g., cancer patients
reading about novel treatment options. The SimpleText lab hosts the
simplification of scientific abstracts for non-experts (Task 3) to advance this
field. We contribute three runs employing out-of-the-box summarization models
(two based on T5, one based on PEGASUS) and one run using ChatGPT with complex
phrase identification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The distribution of discourse relations within and across turns in spontaneous conversation. (arXiv:2307.03645v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03645">
<div class="article-summary-box-inner">
<span><p>Time pressure and topic negotiation may impose constraints on how people
leverage discourse relations (DRs) in spontaneous conversational contexts. In
this work, we adapt a system of DRs for written language to spontaneous
dialogue using crowdsourced annotations from novice annotators. We then test
whether discourse relations are used differently across several types of
multi-utterance contexts. We compare the patterns of DR annotation within and
across speakers and within and across turns. Ultimately, we find that different
discourse contexts produce distinct distributions of discourse relations, with
single-turn annotations creating the most uncertainty for annotators.
Additionally, we find that the discourse relation annotations are of sufficient
quality to predict from embeddings of discourse units.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Testing the Predictions of Surprisal Theory in 11 Languages. (arXiv:2307.03667v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03667">
<div class="article-summary-box-inner">
<span><p>A fundamental result in psycholinguistics is that less predictable words take
a longer time to process. One theoretical explanation for this finding is
Surprisal Theory (Hale, 2001; Levy, 2008), which quantifies a word's
predictability as its surprisal, i.e. its negative log-probability given a
context. While evidence supporting the predictions of Surprisal Theory have
been replicated widely, most have focused on a very narrow slice of data:
native English speakers reading English texts. Indeed, no comprehensive
multilingual analysis exists. We address this gap in the current literature by
investigating the relationship between surprisal and reading times in eleven
different languages, distributed across five language families. Deriving
estimates from language models trained on monolingual and multilingual corpora,
we test three predictions associated with surprisal theory: (i) whether
surprisal is predictive of reading times; (ii) whether expected surprisal, i.e.
contextual entropy, is predictive of reading times; (iii) and whether the
linking function between surprisal and reading times is linear. We find that
all three predictions are borne out crosslinguistically. By focusing on a more
diverse set of languages, we argue that these results offer the most robust
link to-date between information theory and incremental language processing
across languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating the Effectiveness of Large Language Models in Representing Textual Descriptions of Geometry and Spatial Relations. (arXiv:2307.03678v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03678">
<div class="article-summary-box-inner">
<span><p>This research focuses on assessing the ability of large language models
(LLMs) in representing geometries and their spatial relations. We utilize LLMs
including GPT-2 and BERT to encode the well-known text (WKT) format of
geometries and then feed their embeddings into classifiers and regressors to
evaluate the effectiveness of the LLMs-generated embeddings for geometric
attributes. The experiments demonstrate that while the LLMs-generated
embeddings can preserve geometry types and capture some spatial relations (up
to 73% accuracy), challenges remain in estimating numeric values and retrieving
spatially related objects. This research highlights the need for improvement in
terms of capturing the nuances and complexities of the underlying geospatial
data and integrating domain knowledge to support various GeoAI applications
using foundation models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Undecimated Wavelet Transform for Word Embedded Semantic Marginal Autoencoder in Security improvement and Denoising different Languages. (arXiv:2307.03679v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03679">
<div class="article-summary-box-inner">
<span><p>By combining the undecimated wavelet transform within a Word Embedded
Semantic Marginal Autoencoder (WESMA), this research study provides a novel
strategy for improving security measures and denoising multiple languages. The
incorporation of these strategies is intended to address the issues of
robustness, privacy, and multilingualism in data processing applications. The
undecimated wavelet transform is used as a feature extraction tool to identify
prominent language patterns and structural qualities in the input data. The
proposed system may successfully capture significant information while
preserving the temporal and geographical links within the data by employing
this transform. This improves security measures by increasing the system's
ability to detect abnormalities, discover hidden patterns, and distinguish
between legitimate content and dangerous threats. The Word Embedded Semantic
Marginal Autoencoder also functions as an intelligent framework for
dimensionality and noise reduction. The autoencoder effectively learns the
underlying semantics of the data and reduces noise components by exploiting
word embeddings and semantic context. As a result, data quality and accuracy
are increased in following processing stages. The suggested methodology is
tested using a diversified dataset that includes several languages and security
scenarios. The experimental results show that the proposed approach is
effective in attaining security enhancement and denoising capabilities across
multiple languages. The system is strong in dealing with linguistic variances,
producing consistent outcomes regardless of the language used. Furthermore,
incorporating the undecimated wavelet transform considerably improves the
system's ability to efficiently address complex security concerns
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging text data for causal inference using electronic health records. (arXiv:2307.03687v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03687">
<div class="article-summary-box-inner">
<span><p>Text is a ubiquitous component of medical data, containing valuable
information about patient characteristics and care that are often missing from
structured chart data. Despite this richness, it is rarely used in clinical
research, owing partly to its complexity. Using a large database of patient
records and treatment histories accompanied by extensive notes by attendant
physicians and nurses, we show how text data can be used to support causal
inference with electronic health data in all stages, from conception and design
to analysis and interpretation, with minimal additional effort. We focus on
studies using matching for causal inference. We augment a classic matching
analysis by incorporating text in three ways: by using text to supplement a
multiple imputation procedure, we improve the fidelity of imputed values to
handle missing data; by incorporating text in the matching stage, we strengthen
the plausibility of the matching procedure; and by conditioning on text, we can
estimate easily interpretable text-based heterogeneous treatment effects that
may be stronger than those found across categories of structured covariates.
Using these techniques, we hope to expand the scope of secondary analysis of
clinical data to domains where quantitative data is of poor quality or
nonexistent, but where text is available, such as in developing countries.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparing Apples to Apples: Generating Aspect-Aware Comparative Sentences from User Review. (arXiv:2307.03691v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03691">
<div class="article-summary-box-inner">
<span><p>It is time-consuming to find the best product among many similar
alternatives. Comparative sentences can help to contrast one item from others
in a way that highlights important features of an item that stand out. Given
reviews of one or multiple items and relevant item features, we generate
comparative review sentences to aid users to find the best fit. Specifically,
our model consists of three successive components in a transformer: (i) an item
encoding module to encode an item for comparison, (ii) a comparison generation
module that generates comparative sentences in an autoregressive manner, (iii)
a novel decoding method for user personalization. We show that our pipeline
generates fluent and diverse comparative sentences. We run experiments on the
relevance and fidelity of our generated sentences in a human evaluation study
and find that our algorithm creates comparative review sentences that are
relevant and truthful.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Becoming self-instruct: introducing early stopping criteria for minimal instruct tuning. (arXiv:2307.03692v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03692">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce the Instruction Following Score (IFS), a metric
that detects language models' ability to follow instructions. The metric has a
dual purpose. First, IFS can be used to distinguish between base and instruct
models. We benchmark publicly available base and instruct models, and show that
the ratio of well formatted responses to partial and full sentences can be an
effective measure between those two model classes. Secondly, the metric can be
used as an early stopping criteria for instruct tuning. We compute IFS for
Supervised Fine-Tuning (SFT) of 7B and 13B LLaMA models, showing that models
learn to follow instructions relatively early in the training process, and the
further finetuning can result in changes in the underlying base model
semantics. As an example of semantics change we show the objectivity of model
predictions, as defined by an auxiliary metric ObjecQA. We show that in this
particular case, semantic changes are the steepest when the IFS tends to
plateau. We hope that decomposing instruct tuning into IFS and semantic factors
starts a new trend in better controllable instruct tuning and opens
possibilities for designing minimal instruct interfaces querying foundation
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media. (arXiv:2307.03699v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03699">
<div class="article-summary-box-inner">
<span><p>Social media platforms such as Instagram and Twitter have emerged as critical
channels for drug marketing and illegal sale. Detecting and labeling online
illicit drug trafficking activities becomes important in addressing this issue.
However, the effectiveness of conventional supervised learning methods in
detecting drug trafficking heavily relies on having access to substantial
amounts of labeled data, while data annotation is time-consuming and
resource-intensive. Furthermore, these models often face challenges in
accurately identifying trafficking activities when drug dealers use deceptive
language and euphemisms to avoid detection. To overcome this limitation, we
conduct the first systematic study on leveraging large language models (LLMs),
such as ChatGPT, to detect illicit drug trafficking activities on social media.
We propose an analytical framework to compose \emph{knowledge-informed
prompts}, which serve as the interface that humans can interact with and use
LLMs to perform the detection task. Additionally, we design a Monte Carlo
dropout based prompt optimization method to further to improve performance and
interpretability. Our experimental findings demonstrate that the proposed
framework outperforms other baseline language models in terms of drug
trafficking detection accuracy, showing a remarkable improvement of nearly
12\%. By integrating prior knowledge and the proposed prompts, ChatGPT can
effectively identify and label drug trafficking activities on social networks,
even in the presence of deceptive language and euphemisms used by drug dealers
to evade detection. The implications of our research extend to social networks,
emphasizing the importance of incorporating prior knowledge and scenario-based
prompts into analytical tools to improve online security and public safety.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">INT-FP-QSim: Mixed Precision and Formats For Large Language Models and Vision Transformers. (arXiv:2307.03712v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03712">
<div class="article-summary-box-inner">
<span><p>The recent rise of large language models (LLMs) has resulted in increased
efforts towards running LLMs at reduced precision. Running LLMs at lower
precision supports resource constraints and furthers their democratization,
enabling users to run billion-parameter LLMs on their personal devices. To
supplement this ongoing effort, we propose INT-FP-QSim: an open-source
simulator that enables flexible evaluation of LLMs and vision transformers at
various numerical precisions and formats. INT-FP-QSim leverages existing
open-source repositories such as TensorRT, QPytorch and AIMET for a combined
simulator that supports various floating point and integer formats. With the
help of our simulator, we survey the impact of different numerical formats on
the performance of LLMs and vision transformers at 4-bit weights and 4-bit or
8-bit activations. We also compare recently proposed methods like Adaptive
Block Floating Point, SmoothQuant, GPTQ and RPTQ on the model performances. We
hope INT-FP-QSim will enable researchers to flexibly simulate models at various
precisions to support further research in quantization of LLMs and vision
transformers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Automatic Quotation Attribution in Literary Novels. (arXiv:2307.03734v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03734">
<div class="article-summary-box-inner">
<span><p>Current models for quotation attribution in literary novels assume varying
levels of available information in their training and test data, which poses a
challenge for in-the-wild inference. Here, we approach quotation attribution as
a set of four interconnected sub-tasks: character identification, coreference
resolution, quotation identification, and speaker attribution. We benchmark
state-of-the-art models on each of these sub-tasks independently, using a large
dataset of annotated coreferences and quotations in literary novels (the
Project Dialogism Novel Corpus). We also train and evaluate models for the
speaker attribution task in particular, showing that a simple sequential
prediction model achieves accuracy scores on par with state-of-the-art models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QIGen: Generating Efficient Kernels for Quantized Inference on Large Language Models. (arXiv:2307.03738v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03738">
<div class="article-summary-box-inner">
<span><p>We present ongoing work on a new automatic code generation approach for
supporting quantized generative inference on LLMs such as LLaMA or OPT on
off-the-shelf CPUs. Our approach is informed by the target architecture and a
performance model, including both hardware characteristics and method-specific
accuracy constraints. Results on CPU-based inference for LLaMA models show that
our approach can lead to high performance and high accuracy, comparing
favorably to the best existing open-source solution. A preliminary
implementation is available at https://github.com/IST-DASLab/QIGen.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Efficacy of Sampling Adapters. (arXiv:2307.03749v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03749">
<div class="article-summary-box-inner">
<span><p>Sampling is a common strategy for generating text from probabilistic models,
yet standard ancestral sampling often results in text that is incoherent or
ungrammatical. To alleviate this issue, various modifications to a model's
sampling distribution, such as nucleus or top-k sampling, have been introduced
and are now ubiquitously used in language generation systems. We propose a
unified framework for understanding these techniques, which we term sampling
adapters. Sampling adapters often lead to qualitatively better text, which
raises the question: From a formal perspective, how are they changing the
(sub)word-level distributions of language generation models? And why do these
local changes lead to higher-quality text? We argue that the shift they enforce
can be viewed as a trade-off between precision and recall: while the model
loses its ability to produce certain strings, its precision rate on desirable
text increases. While this trade-off is not reflected in standard metrics of
distribution quality (such as perplexity), we find that several
precision-emphasizing measures indeed indicate that sampling adapters can lead
to probability distributions more aligned with the true distribution. Further,
these measures correlate with higher sequence-level quality scores,
specifically, Mauve.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Multimodal Fact-Checking and Explanation Generation: A Challenging Dataset and Models. (arXiv:2205.12487v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12487">
<div class="article-summary-box-inner">
<span><p>We propose end-to-end multimodal fact-checking and explanation generation,
where the input is a claim and a large collection of web sources, including
articles, images, videos, and tweets, and the goal is to assess the
truthfulness of the claim by retrieving relevant evidence and predicting a
truthfulness label (e.g., support, refute or not enough information), and to
generate a statement to summarize and explain the reasoning and ruling process.
To support this research, we construct Mocheg, a large-scale dataset consisting
of 15,601 claims where each claim is annotated with a truthfulness label and a
ruling statement, and 33,880 textual paragraphs and 12,112 images in total as
evidence. To establish baseline performances on Mocheg, we experiment with
several state-of-the-art neural architectures on the three pipelined subtasks:
multimodal evidence retrieval, claim verification, and explanation generation,
and demonstrate that the performance of the state-of-the-art end-to-end
multimodal fact-checking does not provide satisfactory outcomes. To the best of
our knowledge, we are the first to build the benchmark dataset and solutions
for end-to-end multimodal fact-checking and explanation generation. The
dataset, source code and model checkpoints are available at
https://github.com/VT-NLP/Mocheg.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bridging the Gap Between Indexing and Retrieval for Differentiable Search Index with Query Generation. (arXiv:2206.10128v3 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.10128">
<div class="article-summary-box-inner">
<span><p>The Differentiable Search Index (DSI) is an emerging paradigm for information
retrieval. Unlike traditional retrieval architectures where index and retrieval
are two different and separate components, DSI uses a single transformer model
to perform both indexing and retrieval.
</p>
<p>In this paper, we identify and tackle an important issue of current DSI
models: the data distribution mismatch that occurs between the DSI indexing and
retrieval processes. Specifically, we argue that, at indexing, current DSI
methods learn to build connections between the text of long documents and the
identifier of the documents, but then retrieval of document identifiers is
based on queries that are commonly much shorter than the indexed documents.
This problem is further exacerbated when using DSI for cross-lingual retrieval,
where document text and query text are in different languages.
</p>
<p>To address this fundamental problem of current DSI models, we propose a
simple yet effective indexing framework for DSI, called DSI-QG. When indexing,
DSI-QG represents documents with a number of potentially relevant queries
generated by a query generation model and re-ranked and filtered by a
cross-encoder ranker. The presence of these queries at indexing allows the DSI
models to connect a document identifier to a set of queries, hence mitigating
data distribution mismatches present between the indexing and the retrieval
phases. Empirical results on popular mono-lingual and cross-lingual passage
retrieval datasets show that DSI-QG significantly outperforms the original DSI
model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Word to Sentence Visual Semantic Similarity for Caption Generation: Lessons Learned. (arXiv:2209.12817v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.12817">
<div class="article-summary-box-inner">
<span><p>This paper focuses on enhancing the captions generated by image-caption
generation systems. We propose an approach for improving caption generation
systems by choosing the most closely related output to the image rather than
the most likely output produced by the model. Our model revises the language
generation output beam search from a visual context perspective. We employ a
visual semantic measure in a word and sentence level manner to match the proper
caption to the related information in the image. The proposed approach can be
applied to any caption system as a post-processing based method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Breadth-First Pipeline Parallelism. (arXiv:2211.05953v2 [cs.DC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.05953">
<div class="article-summary-box-inner">
<span><p>We introduce Breadth-First Pipeline Parallelism, a novel training schedule
which optimizes the combination of pipeline and data parallelism. Breadth-First
Pipeline Parallelism lowers training time, cost and memory usage by combining a
high GPU utilization with a small batch size per GPU, and by making use of
fully sharded data parallelism. Experimentally, we observed an increase of up
to 43% in training throughput for a 52 billion-parameter model using a small
batch size per GPU compared to Megatron-LM, which would reduce the training
time and cost by the same amount on a large GPU cluster.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Calibrated Interpretation: Confidence Estimation in Semantic Parsing. (arXiv:2211.07443v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.07443">
<div class="article-summary-box-inner">
<span><p>Sequence generation models are increasingly being used to translate natural
language into programs, i.e. to perform executable semantic parsing. The fact
that semantic parsing aims to predict programs that can lead to executed
actions in the real world motivates developing safe systems. This in turn makes
measuring calibration -- a central component to safety -- particularly
important. We investigate the calibration of popular generation models across
four popular semantic parsing datasets, finding that it varies across models
and datasets. We then analyze factors associated with calibration error and
release new confidence-based challenge splits of two parsing datasets. To
facilitate the inclusion of calibration in semantic parsing evaluations, we
release a library for computing calibration metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ALERT: Adapting Language Models to Reasoning Tasks. (arXiv:2212.08286v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.08286">
<div class="article-summary-box-inner">
<span><p>Current large language models can perform reasonably well on complex tasks
that require step-by-step reasoning with few-shot learning. Are these models
applying reasoning skills they have learnt during pre-training and reason
outside of their training context, or are they simply memorizing their training
corpus at finer granularity and have learnt to better understand their context?
To tease apart these possibilities, we introduce ALERT, a benchmark and suite
of analyses for assessing language models' reasoning ability comparing
pre-trained and finetuned models on complex tasks that require reasoning skills
to solve. ALERT provides a test bed to asses any language model on fine-grained
reasoning skills, which spans over 20 datasets and covers 10 different
reasoning skills. We leverage ALERT to further investigate the role of
finetuning. With extensive empirical analysis we find that language models
learn more reasoning skills such as textual entailment, abductive reasoning,
and analogical reasoning during finetuning stage compared to pretraining state.
We also find that when language models are finetuned they tend to overfit to
the prompt template, which hurts the robustness of models causing
generalization problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SESCORE2: Learning Text Generation Evaluation via Synthesizing Realistic Mistakes. (arXiv:2212.09305v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09305">
<div class="article-summary-box-inner">
<span><p>Is it possible to train a general metric for evaluating text generation
quality without human annotated ratings? Existing learned metrics either
perform unsatisfactorily across text generation tasks or require human ratings
for training on specific tasks. In this paper, we propose SESCORE2, a
self-supervised approach for training a model-based metric for text generation
evaluation. The key concept is to synthesize realistic model mistakes by
perturbing sentences retrieved from a corpus. The primary advantage of the
SESCORE2 is its ease of extension to many other languages while providing
reliable severity estimation. We evaluate SESCORE2 and previous methods on four
text generation tasks across three languages. SESCORE2 outperforms unsupervised
metric PRISM on four text generation evaluation benchmarks, with a Kendall
improvement of 0.078. Surprisingly, SESCORE2 even outperforms the supervised
BLEURT and COMET on multiple text generation tasks. The code and data are
available at https://github.com/xu1998hz/SEScore2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WACO: Word-Aligned Contrastive Learning for Speech Translation. (arXiv:2212.09359v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09359">
<div class="article-summary-box-inner">
<span><p>End-to-end Speech Translation (E2E ST) aims to directly translate source
speech into target text. Existing ST methods perform poorly when only extremely
small speech-text data are available for training. We observe that an ST
model's performance closely correlates with its embedding similarity between
speech and source transcript. In this paper, we propose Word-Aligned
COntrastive learning (WACO), a simple and effective method for extremely
low-resource speech-to-text translation. Our key idea is bridging word-level
representations for both speech and text modalities via contrastive learning.
We evaluate WACO and other methods on the MuST-C dataset, a widely used ST
benchmark, and on a low-resource direction Maltese-English from IWSLT 2023. Our
experiments demonstrate that WACO outperforms the best baseline by 9+ BLEU
points with only 1-hour parallel ST data. Code is available at
https://github.com/owaski/WACO.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Memory-efficient NLLB-200: Language-specific Expert Pruning of a Massively Multilingual Machine Translation Model. (arXiv:2212.09811v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09811">
<div class="article-summary-box-inner">
<span><p>The recently released NLLB-200 is a set of multilingual Neural Machine
Translation models that cover 202 languages. The largest model is based on a
Mixture of Experts architecture and achieves SoTA results across many language
pairs. It contains 54.5B parameters and requires at least four 32GB GPUs just
for inference. In this work, we propose a pruning method that enables the
removal of up to 80% of experts without further finetuning and with a
negligible loss in translation quality, which makes it feasible to run the
model on a single 32GB GPU. Further analysis suggests that our pruning metrics
can identify language-specific experts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Guiding Large Language Models via Directional Stimulus Prompting. (arXiv:2302.11520v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11520">
<div class="article-summary-box-inner">
<span><p>We introduce a novel prompting framework called Directional Stimulus
Prompting for guiding black-box large language models (LLMs) toward desired
outputs. The framework introduces a new component called directional stimulus
into the prompt, providing more fine-grained guidance and control over LLMs.
The directional stimulus serves as hints or cues for each input query to guide
LLMs toward the desired output, such as keywords that the desired summary
should include for summarization. We utilize a small tunable model (e.g., T5)
to generate such directional stimulus for each query, allowing us to optimize
black-box LLMs by optimizing a small policy model. This policy model can be
trained through 1) supervised fine-tuning using labeled data and 2)
reinforcement learning from offline or online rewards to explore directional
stimulus that better aligns LLMs with desired behaviors. We evaluate our
framework on summarization and dialogue response generation tasks. Experimental
results show that our framework consistently improves ChatGPT's performance
over standard prompting with a small collection of training data, and
reinforcement learning further improves the performance. Notably, on the
MultWOZ dataset, our framework enables ChatGPT to achieve a remarkable 41.4%
improvement in its combined score with only 80 dialogues, matching or even
surpassing the performance of some fully trained state-of-the-art models. We
have made our code publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Federated Learning Based Multilingual Emoji Prediction In Clean and Attack Scenarios. (arXiv:2304.01005v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.01005">
<div class="article-summary-box-inner">
<span><p>Federated learning is a growing field in the machine learning community due
to its decentralized and private design. Model training in federated learning
is distributed over multiple clients giving access to lots of client data while
maintaining privacy. Then, a server aggregates the training done on these
multiple clients without access to their data, which could be emojis widely
used in any social media service and instant messaging platforms to express
users' sentiments. This paper proposes federated learning-based multilingual
emoji prediction in both clean and attack scenarios. Emoji prediction data have
been crawled from both Twitter and SemEval emoji datasets. This data is used to
train and evaluate different transformer model sizes including a sparsely
activated transformer with either the assumption of clean data in all clients
or poisoned data via label flipping attack in some clients. Experimental
results on these models show that federated learning in either clean or
attacked scenarios performs similarly to centralized training in multilingual
emoji prediction on seen and unseen languages under different data sources and
distributions. Our trained transformers perform better than other techniques on
the SemEval emoji dataset in addition to the privacy as well as distributed
benefits of federated learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit. (arXiv:2304.04596v3 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.04596">
<div class="article-summary-box-inner">
<span><p>ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by
the broadening interests of the spoken language translation community.
ESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2)
simultaneous speech-to-text translation (SST), and 3) offline speech-to-speech
translation (S2ST) -- each task is supported with a wide variety of approaches,
differentiating ESPnet-ST-v2 from other open source spoken language translation
toolkits. This toolkit offers state-of-the-art architectures such as
transducers, hybrid CTC/attention, multi-decoders with searchable
intermediates, time-synchronous blockwise CTC/attention, Translatotron models,
and direct discrete unit models. In this paper, we describe the overall design,
example models for each task, and performance benchmarking behind ESPnet-ST-v2,
which is publicly available at https://github.com/espnet/espnet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Embedding APIs for Information Retrieval. (arXiv:2305.06300v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.06300">
<div class="article-summary-box-inner">
<span><p>The ever-increasing size of language models curtails their widespread
availability to the community, thereby galvanizing many companies into offering
access to large language models through APIs. One particular type, suitable for
dense retrieval, is a semantic embedding service that builds vector
representations of input text. With a growing number of publicly available
APIs, our goal in this paper is to analyze existing offerings in realistic
retrieval scenarios, to assist practitioners and researchers in finding
suitable services according to their needs. Specifically, we investigate the
capabilities of existing semantic embedding APIs on domain generalization and
multilingual retrieval. For this purpose, we evaluate these services on two
standard benchmarks, BEIR and MIRACL. We find that re-ranking BM25 results
using the APIs is a budget-friendly approach and is most effective in English,
in contrast to the standard practice of employing them as first-stage
retrievers. For non-English retrieval, re-ranking still improves the results,
but a hybrid model with BM25 works best, albeit at a higher cost. We hope our
work lays the groundwork for evaluating semantic embedding APIs that are
critical in search and more broadly, for information access.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Open-Domain Question Answering in the Era of Large Language Models. (arXiv:2305.06984v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.06984">
<div class="article-summary-box-inner">
<span><p>Lexical matching remains the de facto evaluation method for open-domain
question answering (QA). Unfortunately, lexical matching fails completely when
a plausible candidate answer does not appear in the list of gold answers, which
is increasingly the case as we shift from extractive to generative models. The
recent success of large language models (LLMs) for QA aggravates lexical
matching failures since candidate answers become longer, thereby making
matching with the gold answers even more challenging. Without accurate
evaluation, the true progress in open-domain QA remains unknown. In this paper,
we conduct a thorough analysis of various open-domain QA models, including
LLMs, by manually evaluating their answers on a subset of NQ-open, a popular
benchmark. Our assessments reveal that while the true performance of all models
is significantly underestimated, the performance of the InstructGPT (zero-shot)
LLM increases by nearly +60%, making it on par with existing top models, and
the InstructGPT (few-shot) model actually achieves a new state-of-the-art on
NQ-open. We also find that more than 50% of lexical matching failures are
attributed to semantically equivalent answers. We further demonstrate that
regex matching ranks QA models consistent with human judgments, although still
suffering from unnecessary strictness. Finally, we demonstrate that automated
evaluation models are a reasonable surrogate for lexical matching in some
circumstances, but not for long-form answers generated by LLMs. The automated
models struggle in detecting hallucinations in LLM answers and are thus unable
to evaluate LLMs. At this time, there appears to be no substitute for human
evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Code-Switched Text Synthesis in Unseen Language Pairs. (arXiv:2305.16724v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16724">
<div class="article-summary-box-inner">
<span><p>Existing efforts on text synthesis for code-switching mostly require training
on code-switched texts in the target language pairs, limiting the deployment of
the models to cases lacking code-switched data. In this work, we study the
problem of synthesizing code-switched texts for language pairs absent from the
training data. We introduce GLOSS, a model built on top of a pre-trained
multilingual machine translation model (PMMTM) with an additional
code-switching module. This module, either an adapter or extra prefixes, learns
code-switching patterns from code-switched data during training, while the
primary component of GLOSS, i.e., the PMMTM, is frozen. The design of only
adjusting the code-switching module prevents our model from overfitting to the
constrained training data for code-switching. Hence, GLOSS exhibits the ability
to generalize and synthesize code-switched texts across a broader spectrum of
language pairs. Additionally, we develop a self-training algorithm on target
language pairs further to enhance the reliability of GLOSS. Automatic
evaluations on four language pairs show that GLOSS achieves at least 55%
relative BLEU and METEOR scores improvements compared to strong baselines.
Human evaluations on two language pairs further validate the success of GLOSS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weaker Than You Think: A Critical Look at Weakly Supervised Learning. (arXiv:2305.17442v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17442">
<div class="article-summary-box-inner">
<span><p>Weakly supervised learning is a popular approach for training machine
learning models in low-resource settings. Instead of requesting high-quality
yet costly human annotations, it allows training models with noisy annotations
obtained from various weak sources. Recently, many sophisticated approaches
have been proposed for robust training under label noise, reporting impressive
results. In this paper, we revisit the setup of these approaches and find that
the benefits brought by these approaches are significantly overestimated.
Specifically, we find that the success of existing weakly supervised learning
approaches heavily relies on the availability of clean validation samples
which, as we show, can be leveraged much more efficiently by simply training on
them. After using these clean labels in training, the advantages of using these
sophisticated approaches are mostly wiped out. This remains true even when
reducing the size of the available clean data to just five samples per class,
making these approaches impractical. To understand the true value of weakly
supervised learning, we thoroughly analyze diverse NLP datasets and tasks to
ascertain when and why weakly supervised approaches work. Based on our
findings, we provide recommendations for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models are Bounded Pragmatic Speakers: Understanding RLHF from a Bayesian Cognitive Modeling Perspective. (arXiv:2305.17760v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17760">
<div class="article-summary-box-inner">
<span><p>How do language models "think"? This paper formulates a probabilistic
cognitive model called the bounded pragmatic speaker, which can characterize
the operation of different variations of language models. Specifically, we
demonstrate that large language models fine-tuned with reinforcement learning
from human feedback (Ouyang et al., 2022) embody a model of thought that
conceptually resembles a fast-and-slow model (Kahneman, 2011), which
psychologists have attributed to humans. We discuss the limitations of
reinforcement learning from human feedback as a fast-and-slow model of thought
and propose avenues for expanding this framework. In essence, our research
highlights the value of adopting a cognitive probabilistic modeling approach to
gain insights into the comprehension, evaluation, and advancement of language
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BigTranslate: Augmenting Large Language Models with Multilingual Translation Capability over 100 Languages. (arXiv:2305.18098v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18098">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) demonstrate promising translation performance
among various natural languages. However, many LLMs especially the open-sourced
ones, such as BLOOM and LLaMA, are English-dominant and support only dozens of
natural languages, making the potential of LLMs on language translation less
explored. In this work, we present BigTranslate which adapts LLaMA that covers
only 20 languages and enhances it with multilingual translation capability on
more than 100 languages. BigTranslate is built upon LLaMA-13B and it is
optimized in three steps. First, we continue training LLaMA with massive
Chinese monolingual data. Second, we continue training the model with a
large-scale parallel dataset that covers 102 natural languages. Third, we
instruct-tune the foundation model with multilingual translation instructions,
leading to our BigTranslate model. The preliminary experiments on multilingual
translation show that BigTranslate performs comparably with ChatGPT and Google
Translate in many languages and even outperforms ChatGPT in 8 language pairs.
We release the BigTranslate model and hope it can advance the research
progress.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MISGENDERED: Limits of Large Language Models in Understanding Pronouns. (arXiv:2306.03950v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.03950">
<div class="article-summary-box-inner">
<span><p>Content Warning: This paper contains examples of misgendering and erasure
that could be offensive and potentially triggering.
</p>
<p>Gender bias in language technologies has been widely studied, but research
has mostly been restricted to a binary paradigm of gender. It is essential also
to consider non-binary gender identities, as excluding them can cause further
harm to an already marginalized group. In this paper, we comprehensively
evaluate popular language models for their ability to correctly use English
gender-neutral pronouns (e.g., singular they, them) and neo-pronouns (e.g., ze,
xe, thon) that are used by individuals whose gender identity is not represented
by binary pronouns. We introduce MISGENDERED, a framework for evaluating large
language models' ability to correctly use preferred pronouns, consisting of (i)
instances declaring an individual's pronoun, followed by a sentence with a
missing pronoun, and (ii) an experimental setup for evaluating masked and
auto-regressive language models using a unified method. When prompted
out-of-the-box, language models perform poorly at correctly predicting
neo-pronouns (averaging 7.7% accuracy) and gender-neutral pronouns (averaging
34.2% accuracy). This inability to generalize results from a lack of
representation of non-binary pronouns in training data and memorized
associations. Few-shot adaptation with explicit examples in the prompt improves
performance for neo-pronouns, but only to 64.7% even with 20 shots. We release
the full dataset, code, and demo at
https://tamannahossainkay.github.io/misgendered/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Labeling of German Chest X-Ray Radiology Reports using Deep Learning. (arXiv:2306.05997v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.05997">
<div class="article-summary-box-inner">
<span><p>Radiologists are in short supply globally, and deep learning models offer a
promising solution to address this shortage as part of clinical
decision-support systems. However, training such models often requires
expensive and time-consuming manual labeling of large datasets. Automatic label
extraction from radiology reports can reduce the time required to obtain
labeled datasets, but this task is challenging due to semantically similar
words and missing annotated data. In this work, we explore the potential of
weak supervision of a deep learning-based label prediction model, using a
rule-based labeler. We propose a deep learning-based CheXpert label prediction
model, pre-trained on reports labeled by a rule-based German CheXpert model and
fine-tuned on a small dataset of manually labeled reports. Our results
demonstrate the effectiveness of our approach, which significantly outperformed
the rule-based model on all three tasks. Our findings highlight the benefits of
employing deep learning-based models even in scenarios with sparse data and the
use of the rule-based labeler as a tool for weak supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KoLA: Carefully Benchmarking World Knowledge of Large Language Models. (arXiv:2306.09296v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.09296">
<div class="article-summary-box-inner">
<span><p>The unprecedented performance of large language models (LLMs) necessitates
improvements in evaluations. Rather than merely exploring the breadth of LLM
abilities, we believe meticulous and thoughtful designs are essential to
thorough, unbiased, and applicable evaluations. Given the importance of world
knowledge to LLMs, we construct a Knowledge-oriented LLM Assessment benchmark
(KoLA), in which we carefully design three crucial factors: (1) For ability
modeling, we mimic human cognition to form a four-level taxonomy of
knowledge-related abilities, covering $19$ tasks. (2) For data, to ensure fair
comparisons, we use both Wikipedia, a corpus prevalently pre-trained by LLMs,
along with continuously collected emerging corpora, aiming to evaluate the
capacity to handle unseen data and evolving knowledge. (3) For evaluation
criteria, we adopt a contrastive system, including overall standard scores for
better numerical comparability across tasks and models and a unique
self-contrast metric for automatically evaluating knowledge hallucination. We
evaluate $21$ open-source and commercial LLMs and obtain some intriguing
findings. The KoLA dataset and open-participation leaderboard are publicly
released at https://kola.xlore.cn and will be continuously updated to provide
references for developing LLMs and knowledge-related systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT. (arXiv:2306.17103v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.17103">
<div class="article-summary-box-inner">
<span><p>We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic
lyrics transcription method achieving state-of-the-art performance on various
lyrics transcription datasets, even in challenging genres such as rock and
metal. Our novel, training-free approach utilizes Whisper, a weakly supervised
robust speech recognition model, and GPT-4, today's most performant chat-based
large language model. In the proposed method, Whisper functions as the "ear" by
transcribing the audio, while GPT-4 serves as the "brain," acting as an
annotator with a strong performance for contextualized output selection and
correction. Our experiments show that LyricWhiz significantly reduces Word
Error Rate compared to existing methods in English and can effectively
transcribe lyrics across multiple languages. Furthermore, we use LyricWhiz to
create the first publicly available, large-scale, multilingual lyrics
transcription dataset with a CC-BY-NC-SA copyright license, based on
MTG-Jamendo, and offer a human-annotated subset for noise level estimation and
evaluation. We anticipate that our proposed method and dataset will advance the
development of multilingual lyrics transcription, a challenging and emerging
task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Performance Comparison of Large Language Models on VNHSGE English Dataset: OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard. (arXiv:2307.02288v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.02288">
<div class="article-summary-box-inner">
<span><p>This paper presents a performance comparison of three large language models
(LLMs), namely OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard, on the
VNHSGE English dataset. The results show that BingChat is better than ChatGPT
and Bard. Therefore, BingChat and Bard can replace ChatGPT while ChatGPT is not
yet officially available in Vietnam. The results also indicate that ChatGPT,
Bing Chat, and Bard outperform Vietnamese students in English language
proficiency. The findings of this study contribute to the understanding of the
potential of LLMs in English language education. The remarkable performance of
ChatGPT, Bing Chat, and Bard demonstrates their potential as effective tools
for teaching and learning English at the high school level.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What Should Data Science Education Do with Large Language Models?. (arXiv:2307.02792v2 [cs.CY] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.02792">
<div class="article-summary-box-inner">
<span><p>The rapid advances of large language models (LLMs), such as ChatGPT, are
revolutionizing data science and statistics. These state-of-the-art tools can
streamline complex processes. As a result, it reshapes the role of data
scientists. We argue that LLMs are transforming the responsibilities of data
scientists, shifting their focus from hands-on coding, data-wrangling and
conducting standard analyses to assessing and managing analyses performed by
these automated AIs. This evolution of roles is reminiscent of the transition
from a software engineer to a product manager. We illustrate this transition
with concrete data science case studies using LLMs in this paper. These
developments necessitate a meaningful evolution in data science education.
Pedagogy must now place greater emphasis on cultivating diverse skillsets among
students, such as LLM-informed creativity, critical thinking, AI-guided
programming. LLMs can also play a significant role in the classroom as
interactive teaching and learning tools, contributing to personalized
education. This paper discusses the opportunities, resources and open
challenges for each of these directions. As with any transformative technology,
integrating LLMs into education calls for careful consideration. While LLMs can
perform repetitive tasks efficiently, it's crucial to remember that their role
is to supplement human intelligence and creativity, not to replace it.
Therefore, the new era of data science education should balance the benefits of
LLMs while fostering complementary human expertise and innovations. In
conclusion, the rise of LLMs heralds a transformative period for data science
and its education. This paper seeks to shed light on the emerging trends,
potential opportunities, and challenges accompanying this paradigm shift,
hoping to spark further discourse and investigation into this exciting,
uncharted territory.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Relationship Between Speech Features Changes When You Get Depressed: Feature Correlations for Improving Speed and Performance of Depression Detection. (arXiv:2307.02892v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.02892">
<div class="article-summary-box-inner">
<span><p>This work shows that depression changes the correlation between features
extracted from speech. Furthermore, it shows that using such an insight can
improve the training speed and performance of depression detectors based on
SVMs and LSTMs. The experiments were performed over the Androids Corpus, a
publicly available dataset involving 112 speakers, including 58 people
diagnosed with depression by professional psychiatrists. The results show that
the models used in the experiments improve in terms of training speed and
performance when fed with feature correlation matrices rather than with feature
vectors. The relative reduction of the error rate ranges between 23.1% and
26.6% depending on the model. The probable explanation is that feature
correlation matrices appear to be more variable in the case of depressed
speakers. Correspondingly, such a phenomenon can be thought of as a depression
marker.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extracting Multi-valued Relations from Language Models. (arXiv:2307.03122v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.03122">
<div class="article-summary-box-inner">
<span><p>The widespread usage of latent language representations via pre-trained
language models (LMs) suggests that they are a promising source of structured
knowledge. However, existing methods focus only on a single object per
subject-relation pair, even though often multiple objects are correct. To
overcome this limitation, we analyze these representations for their potential
to yield materialized multi-object relational knowledge. We formulate the
problem as a rank-then-select task. For ranking candidate objects, we evaluate
existing prompting techniques and propose new ones incorporating domain
knowledge. Among the selection methods, we find that choosing objects with a
likelihood above a learned relation-specific threshold gives a 49.5% F1 score.
Our results highlight the difficulty of employing LMs for the multi-valued
slot-filling task and pave the way for further research on extracting
relational knowledge from latent language representations.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-07-10 23:12:31.908367367 UTC">2023-07-10 23:12:31 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>