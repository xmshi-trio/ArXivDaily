<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-12-09T01:30:00Z">12-09</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Offline Reinforcement Learning Help Natural Language Understanding?. (arXiv:2212.03864v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03864">
<div class="article-summary-box-inner">
<span><p>Pre-training has been a useful method for learning implicit transferable
knowledge and it shows the benefit of offering complementary features across
different modalities. Recent work mainly focuses on the modalities such as
image and text, for example, studies show that visual features learned from
images can help visual-grounded language understanding. In this paper, we
consider investigating the potential connection between offline reinforcement
learning (RL) and language modeling (LM). Intuitively, RL and LM are similar in
predicting the next states based on the current and previous states, which rely
on both local and long-range dependency across states. To validate such an
assumption, we pre-trained different offline RL tasks using Transformer and
then evaluate these models on various language-related tasks. Experimental
results show that our RL pre-trained models can give close performance compared
with the models using the LM training objective, showing that there exist
common useful features across these two modalities. To further explore the
potential relationship, we investigate some factors such as Markov property and
the sequential nature of RL trajectory.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-Training With Scientific Text Improves Educational Question Generation. (arXiv:2212.03869v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03869">
<div class="article-summary-box-inner">
<span><p>With the boom of digital educational materials and scalable e-learning
systems, the potential for realising AI-assisted personalised learning has
skyrocketed. In this landscape, the automatic generation of educational
questions will play a key role, enabling scalable self-assessment when a global
population is manoeuvring their personalised learning journeys. We develop
EduQG, a novel educational question generation model built by adapting a large
language model. Our initial experiments demonstrate that EduQG can produce
superior educational questions by pre-training on scientific text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TweetDrought: A Deep-Learning Drought Impacts Recognizer based on Twitter Data. (arXiv:2212.04001v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04001">
<div class="article-summary-box-inner">
<span><p>Acquiring a better understanding of drought impacts becomes increasingly
vital under a warming climate. Traditional drought indices describe mainly
biophysical variables and not impacts on social, economic, and environmental
systems. We utilized natural language processing and bidirectional encoder
representation from Transformers (BERT) based transfer learning to fine-tune
the model on the data from the news-based Drought Impact Report (DIR) and then
apply it to recognize seven types of drought impacts based on the filtered
Twitter data from the United States. Our model achieved a satisfying macro-F1
score of 0.89 on the DIR test set. The model was then applied to California
tweets and validated with keyword-based labels. The macro-F1 score was 0.58.
However, due to the limitation of keywords, we also spot-checked tweets with
controversial labels. 83.5% of BERT labels were correct compared to the keyword
labels. Overall, the fine-tuned BERT-based recognizer provided proper
predictions and valuable information on drought impacts. The interpretation and
analysis of the model were consistent with experiential domain expertise.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Demystifying Prompts in Language Models via Perplexity Estimation. (arXiv:2212.04037v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04037">
<div class="article-summary-box-inner">
<span><p>Language models can be prompted to perform a wide variety of zero- and
few-shot learning problems. However, performance varies significantly with the
choice of prompt, and we do not yet understand why this happens or how to pick
the best prompts. In this work, we analyze the factors that contribute to this
variance and establish a new empirical hypothesis: the performance of a prompt
is coupled with the extent to which the model is familiar with the language it
contains. Over a wide range of tasks, we show that the lower the perplexity of
the prompt is, the better the prompt is able to perform the task. As a result,
we devise a method for creating prompts: (1) automatically extend a small seed
set of manually written prompts by paraphrasing using GPT3 and backtranslation
and (2) choose the lowest perplexity prompts to get significant gains in
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Dub Movies via Hierarchical Prosody Models. (arXiv:2212.04054v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04054">
<div class="article-summary-box-inner">
<span><p>Given a piece of text, a video clip and a reference audio, the movie dubbing
(also known as visual voice clone V2C) task aims to generate speeches that
match the speaker's emotion presented in the video using the desired speaker
voice as reference. V2C is more challenging than conventional text-to-speech
tasks as it additionally requires the generated speech to exactly match the
varying emotions and speaking speed presented in the video. Unlike previous
works, we propose a novel movie dubbing architecture to tackle these problems
via hierarchical prosody modelling, which bridges the visual information to
corresponding speech prosody from three aspects: lip, face, and scene.
Specifically, we align lip movement to the speech duration, and convey facial
expression to speech energy and pitch via attention mechanism based on valence
and arousal representations inspired by recent psychology findings. Moreover,
we design an emotion booster to capture the atmosphere from global video
scenes. All these embeddings together are used to generate mel-spectrogram and
then convert to speech waves via existing vocoder. Extensive experimental
results on the Chem and V2C benchmark datasets demonstrate the favorable
performance of the proposed method. The source code and trained models will be
released to the public.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Glyph Phonetic Information for Chinese Spell Checking: What Works and What's Next. (arXiv:2212.04068v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04068">
<div class="article-summary-box-inner">
<span><p>While pre-trained Chinese language models have demonstrated impressive
performance on a wide range of NLP tasks, the Chinese Spell Checking (CSC) task
remains a challenge. Previous research has explored using information such as
glyphs and phonetics to improve the ability to distinguish misspelled
characters, with good results. However, the generalization ability of these
models is not well understood: it is unclear whether they incorporate
glyph-phonetic information and, if so, whether this information is fully
utilized. In this paper, we aim to better understand the role of glyph-phonetic
information in the CSC task and suggest directions for improvement.
Additionally, we propose a new, more challenging, and practical setting for
testing the generalizability of CSC models. All code is made publicly
available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Survey on Multi-hop Machine Reading Comprehension Datasets and Metrics. (arXiv:2212.04070v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04070">
<div class="article-summary-box-inner">
<span><p>Multi-hop Machine reading comprehension is a challenging task with aim of
answering a question based on disjoint pieces of information across the
different passages. The evaluation metrics and datasets are a vital part of
multi-hop MRC because it is not possible to train and evaluate models without
them, also, the proposed challenges by datasets often are an important
motivation for improving the existing models. Due to increasing attention to
this field, it is necessary and worth reviewing them in detail. This study aims
to present a comprehensive survey on recent advances in multi-hop MRC
evaluation metrics and datasets. In this regard, first, the multi-hop MRC
problem definition will be presented, then the evaluation metrics based on
their multi-hop aspect will be investigated. Also, 15 multi-hop datasets have
been reviewed in detail from 2017 to 2022, and a comprehensive analysis has
been prepared at the end. Finally, open issues in this field have been
discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Survey on Multi-hop Machine Reading Comprehension Approaches. (arXiv:2212.04072v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04072">
<div class="article-summary-box-inner">
<span><p>Machine reading comprehension (MRC) is a long-standing topic in natural
language processing (NLP). The MRC task aims to answer a question based on the
given context. Recently studies focus on multi-hop MRC which is a more
challenging extension of MRC, which to answer a question some disjoint pieces
of information across the context are required. Due to the complexity and
importance of multi-hop MRC, a large number of studies have been focused on
this topic in recent years, therefore, it is necessary and worth reviewing the
related literature. This study aims to investigate recent advances in the
multi-hop MRC approaches based on 31 studies from 2018 to 2022. In this regard,
first, the multi-hop MRC problem definition will be introduced, then 31 models
will be reviewed in detail with a strong focus on their multi-hop aspects. They
also will be categorized based on their main techniques. Finally, a fine-grain
comprehensive comparison of the models and techniques will be presented.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models. (arXiv:2212.04088v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04088">
<div class="article-summary-box-inner">
<span><p>This study focuses on embodied agents that can follow natural language
instructions to complete complex tasks in a visually-perceived environment.
Existing methods rely on a large amount of (instruction, gold trajectory) pairs
to learn a good policy. The high data cost and poor sample efficiency prevents
the development of versatile agents that are capable of many tasks and can
learn new tasks quickly. In this work, we propose a novel method, LLM-Planner,
that harnesses the power of large language models (LLMs) such as GPT-3 to do
few-shot planning for embodied agents. We further propose a simple but
effective way to enhance LLMs with physical grounding to generate plans that
are grounded in the current environment. Experiments on the ALFRED dataset show
that our method can achieve very competitive few-shot performance, even
outperforming several recent baselines that are trained using the full training
data despite using less than 0.5% of paired training data. Existing methods can
barely complete any task successfully under the same few-shot setting. Our work
opens the door for developing versatile and sample-efficient embodied agents
that can quickly learn many tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Editing Models with Task Arithmetic. (arXiv:2212.04089v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04089">
<div class="article-summary-box-inner">
<span><p>Changing how pre-trained models behave -- e.g., improving their performance
on a downstream task or mitigating biases learned during pre-training -- is a
common practice when developing machine learning systems. In this work, we
propose a new paradigm for steering the behavior of neural networks, centered
around \textit{task vectors}. A task vector specifies a direction in the weight
space of a pre-trained model, such that movement in that direction improves
performance on the task. We build task vectors by subtracting the weights of a
pre-trained model from the weights of the same model after fine-tuning on a
task. We show that these task vectors can be modified and combined together
through arithmetic operations such as negation and addition, and the behavior
of the resulting model is steered accordingly. Negating a task vector decreases
performance on the target task, with little change in model behavior on control
tasks. Moreover, adding task vectors together can improve performance on
multiple tasks at once. Finally, when tasks are linked by an analogy
relationship of the form ``A is to B as C is to D", combining task vectors from
three of the tasks can improve performance on the fourth, even when no data
from the fourth task is used for training. Overall, our experiments with
several models, modalities and tasks show that task arithmetic is a simple,
efficient and effective way of editing models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Successive Prompting for Decomposing Complex Questions. (arXiv:2212.04092v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04092">
<div class="article-summary-box-inner">
<span><p>Answering complex questions that require making latent decisions is a
challenging task, especially when limited supervision is available. Recent
works leverage the capabilities of large language models (LMs) to perform
complex question answering in a few-shot setting by demonstrating how to output
intermediate rationalizations while solving the complex question in a single
pass. We introduce ``Successive Prompting'', where we iteratively break down a
complex task into a simple task, solve it, and then repeat the process until we
get the final solution. Successive prompting decouples the supervision for
decomposing complex questions from the supervision for answering simple
questions, allowing us to (1) have multiple opportunities to query in-context
examples at each reasoning step (2) learn question decomposition separately
from question answering, including using synthetic data, and (3) use bespoke
(fine-tuned) components for reasoning steps where a large LM does not perform
well. The intermediate supervision is typically manually written, which can be
expensive to collect. We introduce a way to generate a synthetic dataset which
can be used to bootstrap a model's ability to decompose and answer intermediate
questions. Our best model (with successive prompting) achieves an improvement
of ~5% absolute F1 on a few-shot version of the DROP dataset when compared with
a state-of-the-art model with the same supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DialogCC: Large-Scale Multi-Modal Dialogue Dataset. (arXiv:2212.04119v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04119">
<div class="article-summary-box-inner">
<span><p>As sharing images in an instant message is a crucial factor, there has been
active research on learning a image-text multi-modal dialogue model. However,
training a well-generalized multi-modal dialogue model is challenging because
existing multi-modal dialogue datasets contain a small number of data, limited
topics, and a restricted variety of images per dialogue. In this paper, we
present a multi-modal dialogue dataset creation pipeline that involves matching
large-scale images to dialogues based on CLIP similarity. Using this automatic
pipeline, we propose a large-scale multi-modal dialogue dataset, DialogCC,
which covers diverse real-world topics and various images per dialogue. With
extensive experiments, we demonstrate that training a multi-modal dialogue
model with our dataset can improve generalization performance. Additionally,
existing models trained with our dataset achieve state-of-the-art performance
on image and text retrieval tasks. The source code and the dataset will be
released after publication.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Discrete Genres: Mapping News Items onto a Multidimensional Framework of Genre Cues. (arXiv:2212.04185v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04185">
<div class="article-summary-box-inner">
<span><p>In the contemporary media landscape, with the vast and diverse supply of
news, it is increasingly challenging to study such an enormous amount of items
without a standardized framework. Although attempts have been made to organize
and compare news items on the basis of news values, news genres receive little
attention, especially the genres in a news consumer's perception. Yet,
perceived news genres serve as an essential component in exploring how news has
developed, as well as a precondition for understanding media effects. We
approach this concept by conceptualizing and operationalizing a non-discrete
framework for mapping news items in terms of genre cues. As a starting point,
we propose a preliminary set of dimensions consisting of "factuality" and
"formality". To automatically analyze a large amount of news items, we deliver
two computational models for predicting news sentences in terms of the said two
dimensions. Such predictions could then be used for locating news items within
our framework. This proposed approach that positions news items upon a
multidimensional grid helps in deepening our insight into the evolving nature
of news genres.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DC-MBR: Distributional Cooling for Minimum Bayesian Risk Decoding. (arXiv:2212.04205v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04205">
<div class="article-summary-box-inner">
<span><p>Minimum Bayesian Risk Decoding (MBR) emerges as a promising decoding
algorithm in Neural Machine Translation. However, MBR performs poorly with
label smoothing, which is surprising as label smoothing provides decent
improvement with beam search and improves generality in various tasks. In this
work, we show that the issue arises from the un-consistency of label smoothing
on the token-level and sequence-level distributions. We demonstrate that even
though label smoothing only causes a slight change in the token-level, the
sequence-level distribution is highly skewed. We coin the issue
\emph{distributional over-smoothness}. To address this issue, we propose a
simple and effective method, Distributional Cooling MBR (DC-MBR), which
manipulates the entropy of output distributions by tuning down the Softmax
temperature. We theoretically prove the equivalence between pre-tuning label
smoothing factor and distributional cooling. Experiments on NMT benchmarks
validate that distributional cooling improves MBR's efficiency and
effectiveness in various settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scientific Paper Extractive Summarization Enhanced by Citation Graphs. (arXiv:2212.04214v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04214">
<div class="article-summary-box-inner">
<span><p>In a citation graph, adjacent paper nodes share related scientific terms and
topics. The graph thus conveys unique structure information of document-level
relatedness that can be utilized in the paper summarization task, for exploring
beyond the intra-document information. In this work, we focus on leveraging
citation graphs to improve scientific paper extractive summarization under
different settings. We first propose a Multi-granularity Unsupervised
Summarization model (MUS) as a simple and low-cost solution to the task. MUS
finetunes a pre-trained encoder model on the citation graph by link prediction
tasks. Then, the abstract sentences are extracted from the corresponding paper
considering multi-granularity information. Preliminary results demonstrate that
citation graph is helpful even in a simple unsupervised framework. Motivated by
this, we next propose a Graph-based Supervised Summarization model (GSS) to
achieve more accurate results on the task when large-scale labeled data are
available. Apart from employing the link prediction as an auxiliary task, GSS
introduces a gated sentence encoder and a graph information fusion module to
take advantage of the graph information to polish the sentence representation.
Experiments on a public benchmark dataset show that MUS and GSS bring
substantial improvements over the prior state-of-the-art model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Neural Correlates of Linguistic Structure Building: Comments on Kazanina & Tavano (2022). (arXiv:2212.04219v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04219">
<div class="article-summary-box-inner">
<span><p>A recent perspective paper by Kazanina &amp; Tavano (referred to as the KT
perspective in the following) argues how neural oscillations cannot provide a
potential neural correlate for syntactic structure building. The view that
neural oscillations can provide a potential neural correlate for syntactic
structure building is largely attributed to a study by Ding, Melloni, Zhang,
Tian, and Poeppel in 2016 (referred to as the DMZTP study).
</p>
<p>The KT perspective is thought provoking, but has severe misinterpretations
about the arguments in DMZTP and other studies, and contains contradictory
conclusions in different parts of the perspective, making it impossible to
understand the position of the authors. In the following, I summarize a few
misinterpretations and inconsistent arguments in the KT perspective, and put
forward a few suggestions for future studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Harnessing the Power of Multi-Task Pretraining for Ground-Truth Level Natural Language Explanations. (arXiv:2212.04231v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04231">
<div class="article-summary-box-inner">
<span><p>Natural language explanations promise to offer intuitively understandable
explanations of a neural network's decision process in complex vision-language
tasks, as pursued in recent VL-NLE models. While current models offer
impressive performance on task accuracy and explanation plausibility, they
suffer from a range of issues: Some models feature a modular design where the
explanation generation module is poorly integrated with a separate module for
task-answer prediction, employ backbone models trained on limited sets of
tasks, or incorporate ad hoc solutions to increase performance on single
datasets. We propose to evade these limitations by applying recent advances in
large-scale multi-task pretraining of generative Transformer models to the
problem of VL-NLE tasks. Our approach outperforms recent models by a large
margin, with human annotators preferring the generated explanations over the
ground truth in two out of three evaluated datasets. As a novel challenge in
VL-NLE research, we propose the problem of multi-task VL-NLE and show that
jointly training on multiple tasks can increase the explanation quality. We
discuss the ethical implications of high-quality NLE generation and other
issues in recent VL-NLE research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Momentum Calibration for Text Generation. (arXiv:2212.04257v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04257">
<div class="article-summary-box-inner">
<span><p>The input and output of most text generation tasks can be transformed to two
sequences of tokens and they can be modeled using sequence-to-sequence learning
modeling tools such as Transformers. These models are usually trained by
maximizing the likelihood the output text sequence and assumes the input
sequence and all gold preceding tokens are given during training, while during
inference the model suffers from the exposure bias problem (i.e., it only has
access to its previously predicted tokens rather gold tokens during beam
search). In this paper, we propose MoCa ({\bf Mo}mentum {\bf Ca}libration) for
text generation. MoCa is an online method that dynamically generates slowly
evolving (but consistent) samples using a momentum moving average generator
with beam search and MoCa learns to align its model scores of these samples
with their actual qualities. Experiments on four text generation datasets
(i.e., CNN/DailyMail, XSum, SAMSum and Gigaword) show MoCa consistently
improves strong pre-trained transformers using vanilla fine-tuning and we
achieve the state-of-the-art results on CNN/DailyMail and SAMSum datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConsistTL: Modeling Consistency in Transfer Learning for Low-Resource Neural Machine Translation. (arXiv:2212.04262v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04262">
<div class="article-summary-box-inner">
<span><p>Transfer learning is a simple and powerful method that can be used to boost
model performance of low-resource neural machine translation (NMT). Existing
transfer learning methods for NMT are static, which simply transfer knowledge
from a parent model to a child model once via parameter initialization. In this
paper, we propose a novel transfer learning method for NMT, namely ConsistTL,
which can continuously transfer knowledge from the parent model during the
training of the child model. Specifically, for each training instance of the
child model, ConsistTL constructs the semantically-equivalent instance for the
parent model and encourages prediction consistency between the parent and child
for this instance, which is equivalent to the child model learning each
instance under the guidance of the parent model. Experimental results on five
low-resource NMT tasks demonstrate that ConsistTL results in significant
improvements over strong transfer learning baselines, with a gain up to 1.7
BLEU over the existing back-translation model on the widely-used WMT17
Turkish-English benchmark. Further analysis reveals that ConsistTL can improve
the inference calibration of the child model. Code and scripts are freely
available at https://github.com/NLP2CT/ConsistTL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Modality-level Explainable Framework for Misinformation Checking in Social Networks. (arXiv:2212.04272v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04272">
<div class="article-summary-box-inner">
<span><p>The widespread of false information is a rising concern worldwide with
critical social impact, inspiring the emergence of fact-checking organizations
to mitigate misinformation dissemination. However, human-driven verification
leads to a time-consuming task and a bottleneck to have checked trustworthy
information at the same pace they emerge. Since misinformation relates not only
to the content itself but also to other social features, this paper addresses
automatic misinformation checking in social networks from a multimodal
perspective. Moreover, as simply naming a piece of news as incorrect may not
convince the citizen and, even worse, strengthen confirmation bias, the
proposal is a modality-level explainable-prone misinformation classifier
framework. Our framework comprises a misinformation classifier assisted by
explainable methods to generate modality-oriented explainable inferences.
Preliminary findings show that the misinformation classifier does benefit from
multimodal information encoding and the modality-oriented explainable mechanism
increases both inferences' interpretability and completeness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lie detection algorithms attract few users but vastly increase accusation rates. (arXiv:2212.04277v1 [econ.GN])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04277">
<div class="article-summary-box-inner">
<span><p>People are not very good at detecting lies, which may explain why they
refrain from accusing others of lying, given the social costs attached to false
accusations - both for the accuser and the accused. Here we consider how this
social balance might be disrupted by the availability of lie-detection
algorithms powered by Artificial Intelligence. Will people elect to use lie
detection algorithms that perform better than humans, and if so, will they show
less restraint in their accusations? We built a machine learning classifier
whose accuracy (67\%) was significantly better than human accuracy (50\%) in a
lie-detection task and conducted an incentivized lie-detection experiment in
which we measured participants' propensity to use the algorithm, as well as the
impact of that use on accusation rates. We find that the few people (33\%) who
elect to use the algorithm drastically increase their accusation rates (from
25\% in the baseline condition up to 86% when the algorithm flags a statement
as a lie). They make more false accusations (18pp increase), but at the same
time, the probability of a lie remaining undetected is much lower in this group
(36pp decrease). We consider individual motivations for using lie detection
algorithms and the social implications of these algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Montague semantics and modifier consistency measurement in neural language models. (arXiv:2212.04310v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04310">
<div class="article-summary-box-inner">
<span><p>The recent dominance of distributional language representation models has
elicited a variety of questions regarding their capabilities and intrinsic
properties, one of which is the manifestation of compositional phenomena in
natural language, which has significant implications towards explainability and
safety/fairness in the use of such models. While most current research on
compositionality has been directed towards improving performance of the
representations on similarity tasks, this work proposes a methodology for
measuring the presence of compositional behaviour in contemporary language
models related to adjectival modifier phenomena in adjective-noun phrases. Our
results show that current neural language models do not behave consistently
according to the linguistic theories with regard to the evaluated intersective
property, but on the other hand, the differences between adjective categories
are noticeable in single adjective interactions, indicating that such
differences are encoded in individual word representations, but they do not
transfer generally in the expected way to the compositions. This raises the
question of whether current language models are not capable of capturing the
true underlying distributional properties of language, or whether linguistic
theories from Montagovian tradition do not hold to distributional scrutiny.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lattice-Free Sequence Discriminative Training for Phoneme-Based Neural Transducers. (arXiv:2212.04325v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04325">
<div class="article-summary-box-inner">
<span><p>Recently, RNN-Transducers have achieved remarkable results on various
automatic speech recognition tasks. However, lattice-free sequence
discriminative training methods, which obtain superior performance in hybrid
modes, are rarely investigated in RNN-Transducers. In this work, we propose
three lattice-free training objectives, namely lattice-free maximum mutual
information, lattice-free segment-level minimum Bayes risk, and lattice-free
minimum Bayes risk, which are used for the final posterior output of the
phoneme-based neural transducer with a limited context dependency. Compared to
criteria using N-best lists, lattice-free methods eliminate the decoding step
for hypotheses generation during training, which leads to more efficient
training. Experimental results show that lattice-free methods gain up to 6.5%
relative improvement in word error rate compared to a sequence-level
cross-entropy trained model. Compared to the N-best-list based minimum Bayes
risk objectives, lattice-free methods gain 40% - 70% relative training time
speedup with a small degradation in performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Implicit causality in GPT-2: a case study. (arXiv:2212.04348v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04348">
<div class="article-summary-box-inner">
<span><p>This case study investigates the extent to which a language model (GPT-2) is
able to capture native speakers' intuitions about implicit causality in a
sentence completion task. We first reproduce earlier results (showing lower
surprisal values for pronouns that are congruent with either the subject or
object, depending on which one corresponds to the implicit causality bias of
the verb), and then examine the effects of gender and verb frequency on model
performance. Our second study examines the reasoning ability of GPT-2: is the
model able to produce more sensible motivations for why the subject VERBed the
object if the verbs have stronger causality biases? We also developed a
methodology to avoid human raters being biased by obscenities and disfluencies
generated by the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Speech Recognition via Large-Scale Weak Supervision. (arXiv:2212.04356v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04356">
<div class="article-summary-box-inner">
<span><p>We study the capabilities of speech processing systems trained simply to
predict large amounts of transcripts of audio on the internet. When scaled to
680,000 hours of multilingual and multitask supervision, the resulting models
generalize well to standard benchmarks and are often competitive with prior
fully supervised results but in a zero-shot transfer setting without the need
for any fine-tuning. When compared to humans, the models approach their
accuracy and robustness. We are releasing models and inference code to serve as
a foundation for further work on robust speech processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BEVBert: Topo-Metric Map Pre-training for Language-guided Navigation. (arXiv:2212.04385v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04385">
<div class="article-summary-box-inner">
<span><p>Existing approaches for vision-and-language navigation (VLN) are mainly based
on cross-modal reasoning over discrete views. However, this scheme may hamper
an agent's spatial and numerical reasoning because of incomplete objects within
a single view and duplicate observations across views. A potential solution is
mapping discrete views into a unified birds's-eye view, which can aggregate
partial and duplicate observations. Existing metric maps could achieve this
goal, but they suffer from less expressive semantics (e.g. usually predefined
labels) and limited map size, which weakens an agent's language grounding and
long-term planning ability. Inspired by the robotics community, we introduce
hybrid topo-metric maps into VLN, where a topological map is used for long-term
planning and a metric map for short-term reasoning. Beyond mapping with more
expressive deep features, we further design a pre-training framework via the
hybrid map to learn language-informed map representations, which enhances
cross-modal grounding and facilitates the final language-guided navigation
goal. Extensive experiments demonstrate the effectiveness of the map-based
route for VLN, and the proposed method sets the new state-of-the-art on three
VLN benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">OFASys: A Multi-Modal Multi-Task Learning System for Building Generalist Models. (arXiv:2212.04408v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04408">
<div class="article-summary-box-inner">
<span><p>Generalist models, which are capable of performing diverse multi-modal tasks
in a task-agnostic way within a single model, have been explored recently.
Being, hopefully, an alternative to approaching general-purpose AI, existing
generalist models are still at an early stage, where modality and task coverage
is limited. To empower multi-modal task-scaling and speed up this line of
research, we release a generalist model learning system, OFASys, built on top
of a declarative task interface named multi-modal instruction. At the core of
OFASys is the idea of decoupling multi-modal task representations from the
underlying model implementations. In OFASys, a task involving multiple
modalities can be defined declaratively even with just a single line of code.
The system automatically generates task plans from such instructions for
training and inference. It also facilitates multi-task training for diverse
multi-modal workloads. As a starting point, we provide presets of 7 different
modalities and 23 highly-diverse example tasks in OFASys, with which we also
develop a first-in-kind, single model, OFA+, that can handle text, image,
speech, video, and motion data. The single OFA+ model achieves 95% performance
in average with only 16% parameters of 15 task-finetuned models, showcasing the
performance reliability of multi-modal task-scaling provided by OFASys.
Available at https://github.com/OFA-Sys/OFASys
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning. (arXiv:2105.03654v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03654">
<div class="article-summary-box-inner">
<span><p>Recent advances in Named Entity Recognition (NER) show that document-level
contexts can significantly improve model performance. In many application
scenarios, however, such contexts are not available. In this paper, we propose
to find external contexts of a sentence by retrieving and selecting a set of
semantically relevant texts through a search engine, with the original sentence
as the query. We find empirically that the contextual representations computed
on the retrieval-based input view, constructed through the concatenation of a
sentence and its external contexts, can achieve significantly improved
performance compared to the original input view based only on the sentence.
Furthermore, we can improve the model performance of both input views by
Cooperative Learning, a training method that encourages the two input views to
produce similar contextual representations or output label distributions.
Experiments show that our approach can achieve new state-of-the-art performance
on 8 NER data sets across 5 domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Confounds and Overestimations in Fake Review Detection: Experimentally Controlling for Product-Ownership and Data-Origin. (arXiv:2110.15130v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15130">
<div class="article-summary-box-inner">
<span><p>The popularity of online shopping is steadily increasing. At the same time,
fake product reviewsare published widely and have the potential to affect
consumer purchasing behavior. In response,previous work has developed automated
methods for the detection of deceptive product reviews.However, studies vary
considerably in terms of classification performance, and many use data
thatcontain potential confounds, which makes it difficult to determine their
validity. Two possibleconfounds are data-origin (i.e., the dataset is composed
of more than one source) and productownership (i.e., reviews written by
individuals who own or do not own the reviewed product). Inthe present study,
we investigate the effect of both confounds for fake review detection. Using
anexperimental design, we manipulate data-origin, product ownership, review
polarity, and veracity.Supervised learning analysis suggests that review
veracity (60.26 - 69.87%) is somewhat detectablebut reviews additionally
confounded with product-ownership (66.19 - 74.17%), or with data-origin(84.44 -
86.94%) are easier to classify. Review veracity is most easily classified if
confounded withproduct-ownership and data-origin combined (87.78 - 88.12%),
suggesting overestimations of thetrue performance in other work. These findings
are moderated by review polarity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reinforcement Learning for Few-Shot Text Generation Adaptation. (arXiv:2111.11030v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.11030">
<div class="article-summary-box-inner">
<span><p>Controlling the generative model to adapt a new domain with limited samples
is a difficult challenge and it is receiving increasing attention. Recently,
methods based on meta-learning have shown promising results for few-shot domain
adaptation. However, meta-learning-based methods usually suffer from the
problem of overfitting, which results in a lack of diversity in the generated
texts. To avoid this problem, in this study, a novel framework based on
reinforcement learning (RL) is proposed. In this framework, to increase the
sample utilization of RL and decrease its sample requirement, maximum
likelihood estimation learning is incorporated into the RL process. When there
are only a few in-domain samples available, experimental results on five target
domains in two few-shot configurations show that this framework performs better
than baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Measuring Context-Word Biases in Lexical Semantic Datasets. (arXiv:2112.06733v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06733">
<div class="article-summary-box-inner">
<span><p>State-of-the-art pretrained contextualized models (PCM) eg. BERT use tasks
such as WiC and WSD to evaluate their word-in-context representations. This
inherently assumes that performance in these tasks reflect how well a model
represents the coupled word and context semantics. We question this assumption
by presenting the first quantitative analysis on the context-word interaction
being tested in major contextual lexical semantic tasks. To achieve this, we
run probing baselines on masked input, and propose measures to calculate and
visualize the degree of context or word biases in existing datasets. The
analysis was performed on both models and humans. Our findings demonstrate that
models are usually not being tested for word-in-context semantics in the same
way as humans are in these tasks, which helps us better understand the
model-human gap. Specifically, to PCMs, most existing datasets fall into the
extreme ends (the retrieval-based tasks exhibit strong target word bias while
WiC-style tasks and WSD show strong context bias); In comparison, humans are
less biased and achieve much better performance when both word and context are
available than with masked input. We recommend our framework for understanding
and controlling these biases for model interpretation and future task design.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Know Where You're Going: Meta-Learning for Parameter-Efficient Fine-Tuning. (arXiv:2205.12453v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12453">
<div class="article-summary-box-inner">
<span><p>A recent family of techniques, dubbed lightweight fine-tuning methods,
facilitates parameter-efficient transfer learning by updating only a small set
of additional parameters while keeping the parameters of the pretrained
language model frozen. While proven to be an effective method, there are no
existing studies on if and how such knowledge of the downstream fine-tuning
approach should affect the pretraining stage. In this work, we show that taking
the ultimate choice of fine-tuning method into consideration boosts the
performance of parameter-efficient fine-tuning. By relying on
optimization-based meta-learning using MAML with certain modifications for our
distinct purpose, we prime the pretrained model specifically for
parameter-efficient fine-tuning, resulting in gains of up to 1.7 points on
cross-lingual NER fine-tuning. Our ablation settings and analyses further
reveal that the tweaks we introduce in MAML are crucial for the attained gains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recurrent Memory Transformer. (arXiv:2207.06881v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.06881">
<div class="article-summary-box-inner">
<span><p>Transformer-based models show their effectiveness across multiple domains and
tasks. The self-attention allows to combine information from all sequence
elements into context-aware representations. However, global and local
information has to be stored mostly in the same element-wise representations.
Moreover, the length of an input sequence is limited by quadratic computational
complexity of self-attention.
</p>
<p>In this work, we propose and study a memory-augmented segment-level recurrent
Transformer (RMT). Memory allows to store and process local and global
information as well as to pass information between segments of the long
sequence with the help of recurrence.
</p>
<p>We implement a memory mechanism with no changes to Transformer model by
adding special memory tokens to the input or output sequence. Then the model is
trained to control both memory operations and sequence representations
processing.
</p>
<p>Results of experiments show that RMT performs on par with the Transformer-XL
on language modeling for smaller memory sizes and outperforms it for tasks that
require longer sequence processing. We show that adding memory tokens to Tr-XL
is able to improve its performance. This makes Recurrent Memory Transformer a
promising architecture for applications that require learning of long-term
dependencies and general purpose in memory processing, such as algorithmic
tasks and reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What the DAAM: Interpreting Stable Diffusion Using Cross Attention. (arXiv:2210.04885v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04885">
<div class="article-summary-box-inner">
<span><p>Large-scale diffusion neural networks represent a substantial milestone in
text-to-image generation, but they remain poorly understood, lacking
interpretability analyses. In this paper, we perform a text-image attribution
analysis on Stable Diffusion, a recently open-sourced model. To produce
pixel-level attribution maps, we upscale and aggregate cross-attention
word-pixel scores in the denoising subnetwork, naming our method DAAM. We
evaluate its correctness by testing its semantic segmentation ability on nouns,
as well as its generalized attribution quality on all parts of speech, rated by
humans. We then apply DAAM to study the role of syntax in the pixel space,
characterizing head--dependent heat map interaction patterns for ten common
dependency relations. Finally, we study several semantic phenomena using DAAM,
with a focus on feature entanglement, where we find that cohyponyms worsen
generation quality and descriptive adjectives attend too broadly. To our
knowledge, we are the first to interpret large diffusion models from a
visuolinguistic perspective, which enables future lines of research. Our code
is at https://github.com/castorini/daam.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPT-3-driven pedagogical agents for training children's curious question-asking skills. (arXiv:2211.14228v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.14228">
<div class="article-summary-box-inner">
<span><p>Students' ability to ask curious questions is a crucial skill that improves
their learning processes. To train this skill, previous research has used a
conversational agent that propose specific cues to prompt children's curiosity
during learning. Despite showing pedagogical efficiency, this method is still
limited since it relies on generating the said prompts by hand for each
educational resource, which can be a very long and costly process. In this
context, we leverage the advances in the natural language processing field and
explore using a large language model (GPT-3) to automate the generation of this
agent's curiosity-prompting cues to help children ask more and deeper
questions. We then used this study to investigate a different
curiosity-prompting behavior for the agent. The study was conducted with 75
students aged between 9 and 10. They either interacted with a hand-crafted
conversational agent that proposes "closed" manually-extracted cues leading to
predefined questions, a GPT-3-driven one that proposes the same type of cues,
or a GPT-3-driven one that proposes "open" cues that can lead to several
possible questions. Results showed a similar question-asking performance
between children who had the two "closed" agents, but a significantly better
one for participants with the "open" agent. Our first results suggest the
validity of using GPT-3 to facilitate the implementation of
curiosity-stimulating learning technologies. In a second step, we also show
that GPT-3 can be efficient in proposing the relevant open cues that leave
children with more autonomy to express their curiosity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Event knowledge in large language models: the gap between the impossible and the unlikely. (arXiv:2212.01488v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.01488">
<div class="article-summary-box-inner">
<span><p>People constantly use language to learn about the world. Computational
linguists have capitalized on this fact to build large language models (LLMs)
that acquire co-occurrence-based knowledge from language corpora. LLMs achieve
impressive performance on many tasks, but the robustness of their world
knowledge has been questioned. Here, we ask: do LLMs acquire generalized
knowledge about real-world events? Using curated sets of minimal sentence pairs
(n=1215), we tested whether LLMs are more likely to generate plausible event
descriptions compared to their implausible counterparts. We found that LLMs
systematically distinguish possible and impossible events (The teacher bought
the laptop vs. The laptop bought the teacher) but fall short of human
performance when distinguishing likely and unlikely events (The nanny tutored
the boy vs. The boy tutored the nanny). In follow-up analyses, we show that (i)
LLM scores are driven by both plausibility and surface-level sentence features,
(ii) LLMs generalize well across syntactic sentence variants (active vs
passive) but less well across semantic sentence variants (synonymous
sentences), (iii) some, but not all LLM deviations from ground-truth labels
align with crowdsourced human judgments, and (iv) explicit event plausibility
information emerges in middle LLM layers and remains high thereafter. Overall,
our analyses reveal a gap in LLMs' event knowledge, highlighting their
limitations as generalized knowledge bases. We conclude by speculating that the
differential performance on impossible vs. unlikely events is not a temporary
setback but an inherent property of LLMs, reflecting a fundamental difference
between linguistic knowledge and world knowledge in intelligent systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Generative Approach for Script Event Prediction via Contrastive Fine-tuning. (arXiv:2212.03496v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03496">
<div class="article-summary-box-inner">
<span><p>Script event prediction aims to predict the subsequent event given the
context. This requires the capability to infer the correlations between events.
Recent works have attempted to improve event correlation reasoning by using
pretrained language models and incorporating external knowledge~(e.g.,
discourse relations). Though promising results have been achieved, some
challenges still remain. First, the pretrained language models adopted by
current works ignore event-level knowledge, resulting in an inability to
capture the correlations between events well. Second, modeling correlations
between events with discourse relations is limited because it can only capture
explicit correlations between events with discourse markers, and cannot capture
many implicit correlations. To this end, we propose a novel generative approach
for this task, in which a pretrained language model is fine-tuned with an
event-centric pretraining objective and predicts the next event within a
generative paradigm. Specifically, we first introduce a novel event-level blank
infilling strategy as the learning objective to inject event-level knowledge
into the pretrained language model, and then design a likelihood-based
contrastive loss for fine-tuning the generative model. Instead of using an
additional prediction layer, we perform prediction by using sequence
likelihoods generated by the generative model. Our approach models correlations
between events in a soft way without any external knowledge. The
likelihood-based prediction eliminates the need to use additional networks to
make predictions and is somewhat interpretable since it scores each word in the
event. Experimental results on the multi-choice narrative cloze~(MCNC) task
demonstrate that our approach achieves better results than other
state-of-the-art baselines. Our code will be available at
https://github.com/zhufq00/mcnc.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">G-MAP: General Memory-Augmented Pre-trained Language Model for Domain Tasks. (arXiv:2212.03613v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.03613">
<div class="article-summary-box-inner">
<span><p>Recently, domain-specific PLMs have been proposed to boost the task
performance of specific domains (e.g., biomedical and computer science) by
continuing to pre-train general PLMs with domain-specific corpora. However,
this Domain-Adaptive Pre-Training (DAPT; Gururangan et al. (2020)) tends to
forget the previous general knowledge acquired by general PLMs, which leads to
a catastrophic forgetting phenomenon and sub-optimal performance. To alleviate
this problem, we propose a new framework of General Memory Augmented
Pre-trained Language Model (G-MAP), which augments the domain-specific PLM by a
memory representation built from the frozen general PLM without losing any
general knowledge. Specifically, we propose a new memory-augmented layer, and
based on it, different augmented strategies are explored to build the memory
representation and then adaptively fuse it into the domain-specific PLM. We
demonstrate the effectiveness of G-MAP on various domains (biomedical and
computer science publications, news, and reviews) and different kinds (text
classification, QA, NER) of tasks, and the extensive results show that the
proposed G-MAP can achieve SOTA results on all tasks.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-12-10 23:12:55.741394926 UTC">2022-12-10 23:12:55 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>