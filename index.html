<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-10-25T01:30:00Z">10-25</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Coreference Resolution for Zeros and non-Zeros in Arabic. (arXiv:2210.12169v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12169">
<div class="article-summary-box-inner">
<span><p>Most existing proposals about anaphoric zero pronoun (AZP) resolution regard
full mention coreference and AZP resolution as two independent tasks, even
though the two tasks are clearly related. The main issues that need tackling to
develop a joint model for zero and non-zero mentions are the difference between
the two types of arguments (zero pronouns, being null, provide no nominal
information) and the lack of annotated datasets of a suitable size in which
both types of arguments are annotated for languages other than Chinese and
Japanese. In this paper, we introduce two architectures for jointly resolving
AZPs and non-AZPs, and evaluate them on Arabic, a language for which, as far as
we know, there has been no prior work on joint resolution. Doing this also
required creating a new version of the Arabic subset of the standard
coreference resolution dataset used for the CoNLL-2012 shared task (Pradhan et
al.,2012) in which both zeros and non-zeros are included in a single dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discovering Differences in the Representation of People using Contextualized Semantic Axes. (arXiv:2210.12170v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12170">
<div class="article-summary-box-inner">
<span><p>A common paradigm for identifying semantic differences across social and
temporal contexts is the use of static word embeddings and their distances. In
particular, past work has compared embeddings against "semantic axes" that
represent two opposing concepts. We extend this paradigm to BERT embeddings,
and construct contextualized axes that mitigate the pitfall where antonyms have
neighboring representations. We validate and demonstrate these axes on two
people-centric datasets: occupations from Wikipedia, and multi-platform
discussions in extremist, men's communities over fourteen years. In both
studies, contextualized semantic axes can characterize differences among
instances of the same word type. In the latter study, we show that references
to women and the contexts around them have become more detestable over time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving the Factual Correctness of Radiology Report Generation with Semantic Rewards. (arXiv:2210.12186v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12186">
<div class="article-summary-box-inner">
<span><p>Neural image-to-text radiology report generation systems offer the potential
to improve radiology reporting by reducing the repetitive process of report
drafting and identifying possible medical errors. These systems have achieved
promising performance as measured by widely used NLG metrics such as BLEU and
CIDEr. However, the current systems face important limitations. First, they
present an increased complexity in architecture that offers only marginal
improvements on NLG metrics. Secondly, these systems that achieve high
performance on these metrics are not always factually complete or consistent
due to both inadequate training and evaluation. Recent studies have shown the
systems can be substantially improved by using new methods encouraging 1) the
generation of domain entities consistent with the reference and 2) describing
these entities in inferentially consistent ways. So far, these methods rely on
weakly-supervised approaches (rule-based) and named entity recognition systems
that are not specific to the chest X-ray domain. To overcome this limitation,
we propose a new method, the RadGraph reward, to further improve the factual
completeness and correctness of generated radiology reports. More precisely, we
leverage the RadGraph dataset containing annotated chest X-ray reports with
entities and relations between entities. On two open radiology report datasets,
our system substantially improves the scores up to 14.2% and 25.3% on metrics
evaluating the factual correctness and completeness of reports.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Syntactic Surprisal From Neural Models Predicts, But Underestimates, Human Processing Difficulty From Syntactic Ambiguities. (arXiv:2210.12187v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12187">
<div class="article-summary-box-inner">
<span><p>Humans exhibit garden path effects: When reading sentences that are
temporarily structurally ambiguous, they slow down when the structure is
disambiguated in favor of the less preferred alternative. Surprisal theory
(Hale, 2001; Levy, 2008), a prominent explanation of this finding, proposes
that these slowdowns are due to the unpredictability of each of the words that
occur in these sentences. Challenging this hypothesis, van Schijndel &amp; Linzen
(2021) find that estimates of the cost of word predictability derived from
language models severely underestimate the magnitude of human garden path
effects. In this work, we consider whether this underestimation is due to the
fact that humans weight syntactic factors in their predictions more highly than
language models do. We propose a method for estimating syntactic predictability
from a language model, allowing us to weigh the cost of lexical and syntactic
predictability independently. We find that treating syntactic predictability
independently from lexical predictability indeed results in larger estimates of
garden path. At the same time, even when syntactic predictability is
independently weighted, surprisal still greatly underestimate the magnitude of
human garden path effects. Our results support the hypothesis that
predictability is not the only factor responsible for the processing cost
associated with garden path sentences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Life is a Circus and We are the Clowns: Automatically Finding Analogies between Situations and Processes. (arXiv:2210.12197v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12197">
<div class="article-summary-box-inner">
<span><p>Analogy-making gives rise to reasoning, abstraction, flexible categorization
and counterfactual inference -- abilities lacking in even the best AI systems
today. Much research has suggested that analogies are key to non-brittle
systems that can adapt to new domains. Despite their importance, analogies
received little attention in the NLP community, with most research focusing on
simple word analogies. Work that tackled more complex analogies relied heavily
on manually constructed, hard-to-scale input representations. In this work, we
explore a more realistic, challenging setup: our input is a pair of natural
language procedural texts, describing a situation or a process (e.g., how the
heart works/how a pump works). Our goal is to automatically extract entities
and their relations from the text and find a mapping between the different
domains based on relational similarity (e.g., blood is mapped to water). We
develop an interpretable, scalable algorithm and demonstrate that it identifies
the correct mappings 87% of the time for procedural texts and 94% for stories
from cognitive-psychology literature. We show it can extract analogies from a
large dataset of procedural texts, achieving 79% precision (analogy prevalence
in data: 3%). Lastly, we demonstrate that our algorithm is robust to
paraphrasing the input texts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Probing with Noise: Unpicking the Warp and Weft of Embeddings. (arXiv:2210.12206v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12206">
<div class="article-summary-box-inner">
<span><p>Improving our understanding of how information is encoded in vector space can
yield valuable interpretability insights. Alongside vector dimensions, we argue
that it is possible for the vector norm to also carry linguistic information.
We develop a method to test this: an extension of the probing framework which
allows for relative intrinsic interpretations of probing results. It relies on
introducing noise that ablates information encoded in embeddings, grounded in
random baselines and confidence intervals. We apply the method to
well-established probing tasks and find evidence that confirms the existence of
separate information containers in English GloVe and BERT embeddings. Our
correlation analysis aligns with the experimental findings that different
encoders use the norm to encode different kinds of information: GloVe stores
syntactic and sentence length information in the vector norm, while BERT uses
it to encode contextual incongruity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SpaBERT: A Pretrained Language Model from Geographic Data for Geo-Entity Representation. (arXiv:2210.12213v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12213">
<div class="article-summary-box-inner">
<span><p>Named geographic entities (geo-entities for short) are the building blocks of
many geographic datasets. Characterizing geo-entities is integral to various
application domains, such as geo-intelligence and map comprehension, while a
key challenge is to capture the spatial-varying context of an entity. We
hypothesize that we shall know the characteristics of a geo-entity by its
surrounding entities, similar to knowing word meanings by their linguistic
context. Accordingly, we propose a novel spatial language model, SpaBERT, which
provides a general-purpose geo-entity representation based on neighboring
entities in geospatial data. SpaBERT extends BERT to capture linearized spatial
context, while incorporating a spatial coordinate embedding mechanism to
preserve spatial relations of entities in the 2-dimensional space. SpaBERT is
pretrained with masked language modeling and masked entity prediction tasks to
learn spatial dependencies. We apply SpaBERT to two downstream tasks:
geo-entity typing and geo-entity linking. Compared with the existing language
models that do not use spatial context, SpaBERT shows significant performance
improvement on both tasks. We also analyze the entity representation from
SpaBERT in various settings and the effect of spatial coordinate embedding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimizing Bilingual Neural Transducer with Synthetic Code-switching Text Generation. (arXiv:2210.12214v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12214">
<div class="article-summary-box-inner">
<span><p>Code-switching describes the practice of using more than one language in the
same sentence. In this study, we investigate how to optimize a neural
transducer based bilingual automatic speech recognition (ASR) model for
code-switching speech. Focusing on the scenario where the ASR model is trained
without supervised code-switching data, we found that semi-supervised training
and synthetic code-switched data can improve the bilingual ASR system on
code-switching speech. We analyze how each of the neural transducer's encoders
contributes towards code-switching performance by measuring encoder-specific
recall values, and evaluate our English/Mandarin system on the ASCEND data set.
Our final system achieves 25% mixed error rate (MER) on the ASCEND
English/Mandarin code-switching test set -- reducing the MER by 2.1% absolute
compared to the previous literature -- while maintaining good accuracy on the
monolingual test sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gui at MixMT 2022 : English-Hinglish: An MT approach for translation of code mixed data. (arXiv:2210.12215v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12215">
<div class="article-summary-box-inner">
<span><p>Code-mixed machine translation has become an important task in multilingual
communities and extending the task of machine translation to code mixed data
has become a common task for these languages. In the shared tasks of WMT 2022,
we try to tackle the same for both English + Hindi to Hinglish and Hinglish to
English. The first task dealt with both Roman and Devanagari script as we had
monolingual data in both English and Hindi whereas the second task only had
data in Roman script. To our knowledge, we achieved one of the top ROUGE-L and
WER scores for the first task of Monolingual to Code-Mixed machine translation.
In this paper, we discuss the use of mBART with some special pre-processing and
post-processing (transliteration from Devanagari to Roman) for the first task
in detail and the experiments that we performed for the second task of
translating code-mixed Hinglish to monolingual English.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Entailer: Answering Questions with Faithful and Truthful Chains of Reasoning. (arXiv:2210.12217v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12217">
<div class="article-summary-box-inner">
<span><p>Our goal is a question-answering (QA) system that can show how its answers
are implied by its own internal beliefs via a systematic chain of reasoning.
Such a capability would allow better understanding of why a model produced the
answer it did. Our approach is to recursively combine a trained
backward-chaining model, capable of generating a set of premises entailing an
answer hypothesis, with a verifier that checks that the model itself believes
those premises (and the entailment itself) through self-querying. To our
knowledge, this is the first system to generate multistep chains that are both
faithful (the answer follows from the reasoning) and truthful (the chain
reflects the system's own internal beliefs). In evaluation using two different
datasets, users judge that a majority (70%+) of generated chains clearly show
how an answer follows from a set of facts - substantially better than a
high-performance baseline - while preserving answer accuracy. By materializing
model beliefs that systematically support an answer, new opportunities arise
for understanding the model's system of belief, and diagnosing and correcting
its misunderstandings when an answer is wrong.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low-Resource Multilingual and Zero-Shot Multispeaker TTS. (arXiv:2210.12223v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12223">
<div class="article-summary-box-inner">
<span><p>While neural methods for text-to-speech (TTS) have shown great advances in
modeling multiple speakers, even in zero-shot settings, the amount of data
needed for those approaches is generally not feasible for the vast majority of
the world's over 6,000 spoken languages. In this work, we bring together the
tasks of zero-shot voice cloning and multilingual low-resource TTS. Using the
language agnostic meta learning (LAML) procedure and modifications to a TTS
encoder, we show that it is possible for a system to learn speaking a new
language using just 5 minutes of training data while retaining the ability to
infer the voice of even unseen speakers in the newly learned language. We show
the success of our proposed approach in terms of intelligibility, naturalness
and similarity to target speaker using objective metrics as well as human
studies and provide our code and trained models open source.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EDUKG: a Heterogeneous Sustainable K-12 Educational Knowledge Graph. (arXiv:2210.12228v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12228">
<div class="article-summary-box-inner">
<span><p>Web and artificial intelligence technologies, especially semantic web and
knowledge graph (KG), have recently raised significant attention in educational
scenarios. Nevertheless, subject-specific KGs for K-12 education still lack
sufficiency and sustainability from knowledge and data perspectives. To tackle
these issues, we propose EDUKG, a heterogeneous sustainable K-12 Educational
Knowledge Graph. We first design an interdisciplinary and fine-grained ontology
for uniformly modeling knowledge and resource in K-12 education, where we
define 635 classes, 445 object properties, and 1314 datatype properties in
total. Guided by this ontology, we propose a flexible methodology for
interactively extracting factual knowledge from textbooks. Furthermore, we
establish a general mechanism based on our proposed generalized entity linking
system for EDUKG's sustainable maintenance, which can dynamically index
numerous heterogeneous resources and data with knowledge topics in EDUKG. We
further evaluate EDUKG to illustrate its sufficiency, richness, and
variability. We publish EDUKG with more than 252 million entities and 3.86
billion triplets. Our code and data repository is now available at
https://github.com/THU-KEG/EDUKG.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Dataset for Plain Language Adaptation of Biomedical Abstracts. (arXiv:2210.12242v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12242">
<div class="article-summary-box-inner">
<span><p>Though exponentially growing health-related literature has been made
available to a broad audience online, the language of scientific articles can
be difficult for the general public to understand. Therefore, adapting this
expert-level language into plain language versions is necessary for the public
to reliably comprehend the vast health-related literature. Deep Learning
algorithms for automatic adaptation are a possible solution; however, gold
standard datasets are needed for proper evaluation. Proposed datasets thus far
consist of either pairs of comparable professional- and general public-facing
documents or pairs of semantically similar sentences mined from such documents.
This leads to a trade-off between imperfect alignments and small test sets. To
address this issue, we created the Plain Language Adaptation of Biomedical
Abstracts dataset. This dataset is the first manually adapted dataset that is
both document- and sentence-aligned. The dataset contains 750 adapted
abstracts, totaling 7643 sentence pairs. Along with describing the dataset, we
benchmark automatic adaptation on the dataset with state-of-the-art Deep
Learning approaches, setting baselines for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Tabular Reasoning with Pattern Exploiting Training. (arXiv:2210.12259v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12259">
<div class="article-summary-box-inner">
<span><p>Recent methods based on pre-trained language models have exhibited superior
performance over tabular tasks (e.g., tabular NLI), despite showing inherent
problems such as not using the right evidence and inconsistent predictions
across inputs while reasoning over the tabular data. In this work, we utilize
Pattern-Exploiting Training (PET) (i.e., strategic MLM) on pre-trained language
models to strengthen these tabular reasoning models' pre-existing knowledge and
reasoning abilities. Our upgraded model exhibits a superior understanding of
knowledge facts and tabular reasoning compared to current baselines.
Additionally, we demonstrate that such models are more effective for underlying
downstream tasks of tabular inference on InfoTabs. Furthermore, we show our
model's robustness against adversarial sets generated through various character
and word level perturbations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Z-LaVI: Zero-Shot Language Solver Fueled by Visual Imagination. (arXiv:2210.12261v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12261">
<div class="article-summary-box-inner">
<span><p>Large-scale pretrained language models have made significant advances in
solving downstream language understanding tasks. However, they generally suffer
from reporting bias, the phenomenon describing the lack of explicit commonsense
knowledge in written text, e.g., ''an orange is orange''. To overcome this
limitation, we develop a novel approach, Z-LaVI, to endow language models with
visual imagination capabilities. Specifically, we leverage two complementary
types of ''imaginations'': (i) recalling existing images through retrieval and
(ii) synthesizing nonexistent images via text-to-image generation. Jointly
exploiting the language inputs and the imagination, a pretrained
vision-language model (e.g., CLIP) eventually composes a zero-shot solution to
the original language tasks. Notably, fueling language models with imagination
can effectively leverage visual knowledge to solve plain language tasks. In
consequence, Z-LaVI consistently improves the zero-shot performance of existing
language models across a diverse set of language tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Calibration of Massively Multilingual Language Models. (arXiv:2210.12265v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12265">
<div class="article-summary-box-inner">
<span><p>Massively Multilingual Language Models (MMLMs) have recently gained
popularity due to their surprising effectiveness in cross-lingual transfer.
While there has been much work in evaluating these models for their performance
on a variety of tasks and languages, little attention has been paid on how well
calibrated these models are with respect to the confidence in their
predictions. We first investigate the calibration of MMLMs in the zero-shot
setting and observe a clear case of miscalibration in low-resource languages or
those which are typologically diverse from English. Next, we empirically show
that calibration methods like temperature scaling and label smoothing do
reasonably well towards improving calibration in the zero-shot scenario. We
also find that few-shot examples in the language can further help reduce the
calibration errors, often substantially. Overall, our work contributes towards
building more reliable multilingual models by highlighting the issue of their
miscalibration, understanding what language and model specific factors
influence it, and pointing out the strategies to improve the same.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graphemic Normalization of the Perso-Arabic Script. (arXiv:2210.12273v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12273">
<div class="article-summary-box-inner">
<span><p>Since its original appearance in 1991, the Perso-Arabic script representation
in Unicode has grown from 169 to over 440 atomic isolated characters spread
over several code pages representing standard letters, various diacritics and
punctuation for the original Arabic and numerous other regional orthographic
traditions. This paper documents the challenges that Perso-Arabic presents
beyond the best-documented languages, such as Arabic and Persian, building on
earlier work by the expert community. We particularly focus on the situation in
natural language processing (NLP), which is affected by multiple, often
neglected, issues such as the use of visually ambiguous yet canonically
nonequivalent letters and the mixing of letters from different orthographies.
Among the contributing conflating factors are the lack of input methods, the
instability of modern orthographies, insufficient literacy, and loss or lack of
orthographic tradition. We evaluate the effects of script normalization on
eight languages from diverse language families in the Perso-Arabic script
diaspora on machine translation and statistical language modeling tasks. Our
results indicate statistically significant improvements in performance in most
conditions for all the languages considered when normalization is applied. We
argue that better understanding and representation of Perso-Arabic script
variation within regional orthographic traditions, where those are present, is
crucial for further progress of modern computational NLP techniques especially
for languages with a paucity of resources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text Editing as Imitation Game. (arXiv:2210.12276v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12276">
<div class="article-summary-box-inner">
<span><p>Text editing, such as grammatical error correction, arises naturally from
imperfect textual data. Recent works frame text editing as a multi-round
sequence tagging task, where operations -- such as insertion and substitution
-- are represented as a sequence of tags. While achieving good results, this
encoding is limited in flexibility as all actions are bound to token-level
tags. In this work, we reformulate text editing as an imitation game using
behavioral cloning. Specifically, we convert conventional sequence-to-sequence
data into state-to-action demonstrations, where the action space can be as
flexible as needed. Instead of generating the actions one at a time, we
introduce a dual decoders structure to parallel the decoding while retaining
the dependencies between action tokens, coupled with trajectory augmentation to
alleviate the distribution shift that imitation learning often suffers. In
experiments on a suite of Arithmetic Equation benchmarks, our model
consistently outperforms the autoregressive baselines in terms of performance,
efficiency, and robustness. We hope our findings will shed light on future
studies in reinforcement learning applying sequence-level action generation to
natural language processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What do Large Language Models Learn beyond Language?. (arXiv:2210.12302v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12302">
<div class="article-summary-box-inner">
<span><p>Large language models (LMs) have rapidly become a mainstay in Natural
Language Processing. These models are known to acquire rich linguistic
knowledge from training on large amounts of text. In this paper, we investigate
if pre-training on text also confers these models with helpful `inductive
biases' for non-linguistic reasoning. On a set of 19 diverse non-linguistic
tasks involving quantitative computations, recognizing regular expressions and
reasoning over strings. We find that pretrained models significantly outperform
comparable non-pretrained neural models. This remains true also in experiments
with training non-pretrained models with fewer parameters to account for model
regularization effects. We further explore the effect of text domain on LMs by
pretraining models from text from different domains and provenances. Our
experiments surprisingly reveal that the positive effects of pre-training
persist even when pretraining on multi-lingual text or computer code, and even
for text generated from synthetic languages. Our findings suggest a hitherto
unexplored deep connection between pre-training and inductive learning
abilities of language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning a Grammar Inducer from Massive Uncurated Instructional Videos. (arXiv:2210.12309v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12309">
<div class="article-summary-box-inner">
<span><p>Video-aided grammar induction aims to leverage video information for finding
more accurate syntactic grammars for accompanying text. While previous work
focuses on building systems for inducing grammars on text that are well-aligned
with video content, we investigate the scenario, in which text and video are
only in loose correspondence. Such data can be found in abundance online, and
the weak correspondence is similar to the indeterminacy problem studied in
language acquisition. Furthermore, we build a new model that can better learn
video-span correlation without manually designed features adopted by previous
work. Experiments show that our model trained only on large-scale YouTube data
with no text-video alignment reports strong and robust performances across
three unseen datasets, despite domain shift and noisy label issues. Furthermore
our model yields higher F1 scores than the previous state-of-the-art systems
trained on in-domain data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Benchmark Study of Contrastive Learning for Arabic Social Meaning. (arXiv:2210.12314v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12314">
<div class="article-summary-box-inner">
<span><p>Contrastive learning (CL) brought significant progress to various NLP tasks.
Despite this progress, CL has not been applied to Arabic NLP to date. Nor is it
clear how much benefits it could bring to particular classes of tasks such as
those involved in Arabic social meaning (e.g., sentiment analysis, dialect
identification, hate speech detection). In this work, we present a
comprehensive benchmark study of state-of-the-art supervised CL methods on a
wide array of Arabic social meaning tasks. Through extensive empirical
analyses, we show that CL methods outperform vanilla finetuning on most tasks
we consider. We also show that CL can be data efficient and quantify this
efficiency. Overall, our work allows us to demonstrate the promise of CL
methods, including in low-resource settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Comparison of Neural Networks as Cognitive Models of Inflection. (arXiv:2210.12321v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12321">
<div class="article-summary-box-inner">
<span><p>Neural networks have long been at the center of a debate around the cognitive
mechanism by which humans process inflectional morphology. This debate has
gravitated into NLP by way of the question: Are neural networks a feasible
account for human behavior in morphological inflection? We address that
question by measuring the correlation between human judgments and neural
network probabilities for unknown word inflections. We test a larger range of
architectures than previously studied on two important tasks for the cognitive
processing debate: English past tense, and German number inflection. We find
evidence that the Transformer may be a better account of human behavior than
LSTMs on these datasets, and that LSTM features known to increase inflection
accuracy do not always result in more human-like behavior.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer-Based Conditioned Variational Autoencoder for Dialogue Generation. (arXiv:2210.12326v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12326">
<div class="article-summary-box-inner">
<span><p>In human dialogue, a single query may elicit numerous appropriate responses.
The Transformer-based dialogue model produces frequently occurring sentences in
the corpus since it is a one-to-one mapping function. CVAE is a technique for
reducing generic replies. In this paper, we create a new dialogue model
(CVAE-T) based on the Transformer with CVAE structure. We use a pre-trained MLM
model to rewrite some key n-grams in responses to obtain a series of negative
examples, and introduce a regularization term during training to explicitly
guide the latent variable in learning the semantic differences between each
pair of positive and negative examples. Experiments suggest that the method we
design is capable of producing more informative replies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">R$^2$F: A General Retrieval, Reading and Fusion Framework for Document-level Natural Language Inference. (arXiv:2210.12328v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12328">
<div class="article-summary-box-inner">
<span><p>Document-level natural language inference (DOCNLI) is a new challenging task
in natural language processing, aiming at judging the entailment relationship
between a pair of hypothesis and premise documents. Current datasets and
baselines largely follow sentence-level settings, but fail to address the
issues raised by longer documents. In this paper, we establish a general
solution, named Retrieval, Reading and Fusion (R2F) framework, and a new
setting, by analyzing the main challenges of DOCNLI: interpretability,
long-range dependency, and cross-sentence inference. The basic idea of the
framework is to simplify document-level task into a set of sentence-level
tasks, and improve both performance and interpretability with the power of
evidence. For each hypothesis sentence, the framework retrieves evidence
sentences from the premise, and reads to estimate its credibility. Then the
sentence-level results are fused to judge the relationship between the
documents. For the setting, we contribute complementary evidence and entailment
label annotation on hypothesis sentences, for interpretability study. Our
experimental results show that R2F framework can obtain state-of-the-art
performance and is robust for diverse evidence retrieval methods. Moreover, it
can give more interpretable prediction results. Our model and code are released
at https://github.com/phoenixsecularbird/R2F.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ProGen: Progressive Zero-shot Dataset Generation via In-context Feedback. (arXiv:2210.12329v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12329">
<div class="article-summary-box-inner">
<span><p>Recently, dataset-generation-based zero-shot learning has shown promising
results by training a task-specific model with a dataset synthesized from large
pre-trained language models (PLMs). The final task-specific model often
achieves compatible or even better performance than PLMs under the zero-shot
setting, with orders of magnitude fewer parameters. However, synthetic datasets
have their drawbacks. They have long been suffering from low-quality issues
(e.g., low informativeness and redundancy). This explains why the massive
synthetic data does not lead to better performance -- a scenario we would
expect in the human-labeled data. To improve the quality of dataset synthesis,
we propose a progressive zero-shot dataset generation framework, ProGen, which
leverages the feedback from the task-specific model to guide the generation of
new training data via in-context examples. Extensive experiments on five text
classification datasets demonstrate the effectiveness of the proposed approach.
We also show ProGen achieves on-par or superior performance with only 1\%
synthetic dataset size compared to baseline methods without in-context
feedback.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Salience Allocation as Guidance for Abstractive Summarization. (arXiv:2210.12330v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12330">
<div class="article-summary-box-inner">
<span><p>Abstractive summarization models typically learn to capture the salient
information from scratch implicitly. Recent literature adds extractive
summaries as guidance for abstractive summarization models to provide hints of
salient content and achieves better performance. However, extractive summaries
as guidance could be over strict, leading to information loss or noisy signals.
Furthermore, it cannot easily adapt to documents with various abstractiveness.
As the number and allocation of salience content pieces vary, it is hard to
find a fixed threshold deciding which content should be included in the
guidance. In this paper, we propose a novel summarization approach with a
flexible and reliable salience guidance, namely SEASON (SaliencE Allocation as
Guidance for Abstractive SummarizatiON). SEASON utilizes the allocation of
salience expectation to guide abstractive summarization and adapts well to
articles in different abstractiveness. Automatic and human evaluations on two
benchmark datasets show that the proposed method is effective and reliable.
Empirical results on more than one million news articles demonstrate a natural
fifteen-fifty salience split for news article sentences, providing a useful
insight for composing news articles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Guided contrastive self-supervised pre-training for automatic speech recognition. (arXiv:2210.12335v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12335">
<div class="article-summary-box-inner">
<span><p>Contrastive Predictive Coding (CPC) is a representation learning method that
maximizes the mutual information between intermediate latent representations
and the output of a given model. It can be used to effectively initialize the
encoder of an Automatic Speech Recognition (ASR) model. We present a novel
modification of CPC called Guided Contrastive Predictive Coding (GCPC). Our
proposed method maximizes the mutual information between representations from a
prior-knowledge model and the output of the model being pre-trained, allowing
prior knowledge injection during pre-training. We validate our method on 3 ASR
tasks: German, French and English. Our method outperforms CPC pre-training on
all three datasets, reducing the Word Error Rate (WER) by 4.44%, 6.55% and
15.43% relative on the German, French and English (Librispeech) tasks
respectively, compared to training from scratch, while CPC pre-training only
brings 2.96%, 1.01% and 14.39% relative WER reduction respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open-domain Question Answering via Chain of Reasoning over Heterogeneous Knowledge. (arXiv:2210.12338v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12338">
<div class="article-summary-box-inner">
<span><p>We propose a novel open-domain question answering (ODQA) framework for
answering single/multi-hop questions across heterogeneous knowledge sources.
The key novelty of our method is the introduction of the intermediary modules
into the current retriever-reader pipeline. Unlike previous methods that solely
rely on the retriever for gathering all evidence in isolation, our intermediary
performs a chain of reasoning over the retrieved set. Specifically, our method
links the retrieved evidence with its related global context into graphs and
organizes them into a candidate list of evidence chains. Built upon pretrained
language models, our system achieves competitive performance on two ODQA
datasets, OTT-QA and NQ, against tables and passages from Wikipedia. In
particular, our model substantially outperforms the previous state-of-the-art
on OTT-QA with an exact match score of 47.3 (45 % relative gain).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">P$^3$LM: Probabilistically Permuted Prophet Language Modeling for Generative Pre-Training. (arXiv:2210.12339v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12339">
<div class="article-summary-box-inner">
<span><p>Conventional autoregressive left-to-right (L2R) sequence generation faces two
issues during decoding: limited to unidirectional target sequence modeling, and
constrained on strong local dependencies. To address the aforementioned
problem, we propose P$^3$LM, a probabilistically permuted prophet language
model, which strengthens the modeling of bidirectional information and long
token dependencies for sequence generation. Specifically, P$^3$LM learns to
generate tokens in permuted order upon an order-aware transformer decoder, as
well as to generate the corresponding future $N$ tokens with a multi-stream
attention mechanism. Extensive experiments are conducted on the GLGE benchmark,
which includes four datasets for summarization, two for question generation,
one for conversational question answering, and one for dialog response
generation, where P$^3$LM achieves state-of-the-art results compared with
strong publicly available generative pre-training methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI-based Arabic Language and Speech Tutor. (arXiv:2210.12346v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12346">
<div class="article-summary-box-inner">
<span><p>In the past decade, we have observed a growing interest in using technologies
such as artificial intelligence (AI), machine learning, and chatbots to provide
assistance to language learners, especially in second language learning. By
using AI and natural language processing (NLP) and chatbots, we can create an
intelligent self-learning environment that goes beyond multiple-choice
questions and/or fill in the blank exercises. In addition, NLP allows for
learning to be adaptive in that it offers more than an indication that an error
has occurred. It also provides a description of the error, uses linguistic
analysis to isolate the source of the error, and then suggests additional
drills to achieve optimal individualized learning outcomes. In this paper, we
present our approach for developing an Artificial Intelligence-based Arabic
Language and Speech Tutor (AI-ALST) for teaching the Moroccan Arabic dialect.
The AI-ALST system is an intelligent tutor that provides analysis and
assessment of students learning the Moroccan dialect at University of Arizona
(UA). The AI-ALST provides a self-learned environment to practice each lesson
for pronunciation training. In this paper, we present our initial experimental
evaluation of the AI-ALST that is based on MFCC (Mel frequency cepstrum
coefficient) feature extraction, bidirectional LSTM (Long Short-Term Memory),
attention mechanism, and a cost-based strategy for dealing with class-imbalance
learning. We evaluated our tutor on the word pronunciation of lesson 1 of the
Moroccan Arabic dialect class. The experimental results show that the AI-ALST
can effectively and successfully detect pronunciation errors and evaluate its
performance by using F_1-score, accuracy, precision, and recall.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Large Language Models for Multiple Choice Question Answering. (arXiv:2210.12353v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12353">
<div class="article-summary-box-inner">
<span><p>While large language models (LLMs) like GPT-3 have achieved impressive
results on multiple choice question answering (MCQA) tasks in the zero, one,
and few-shot settings, they generally lag behind the MCQA state of the art
(SOTA). MCQA tasks have traditionally been presented to LLMs like cloze tasks.
An LLM is conditioned on a question (without the associated answer options) and
its chosen option is the one assigned the highest probability after
normalization (for length, etc.). A more natural prompting approach is to
present the question and answer options to the LLM jointly and have it output
the symbol (e.g., "A") associated with its chosen answer option. This approach
allows the model to explicitly compare answer options, reduces computational
costs, and mitigates the effects of tokenization scheme and answer option
representations on answer selection. For the natural approach to be effective
the LLM it is used with must be able to associate answer options with the
symbols that represent them. The LLM needs what we term multiple choice symbol
binding (MCSB) ability. This ability varies greatly by model. We show that a
model with high MCSB ability performs much better with the natural approach
than with the traditional approach across 20 diverse datasets and largely
closes the gap with the SOTA, suggesting that the MCQA ability of LLMs has been
previously underestimated.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Information-Transport-based Policy for Simultaneous Translation. (arXiv:2210.12357v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12357">
<div class="article-summary-box-inner">
<span><p>Simultaneous translation (ST) outputs translation while receiving the source
inputs, and hence requires a policy to determine whether to translate a target
token or wait for the next source token. The major challenge of ST is that each
target token can only be translated based on the current received source
tokens, where the received source information will directly affect the
translation quality. So naturally, how much source information is received for
the translation of the current target token is supposed to be the pivotal
evidence for the ST policy to decide between translating and waiting. In this
paper, we treat the translation as information transport from source to target
and accordingly propose an Information-Transport-based Simultaneous Translation
(ITST). ITST quantifies the transported information weight from each source
token to the current target token, and then decides whether to translate the
target token according to its accumulated received information. Experiments on
both text-to-text ST and speech-to-text ST (a.k.a., streaming speech
translation) tasks show that ITST outperforms strong baselines and achieves
state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompt-Tuning Can Be Much Better Than Fine-Tuning on Cross-lingual Understanding With Multilingual Language Models. (arXiv:2210.12360v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12360">
<div class="article-summary-box-inner">
<span><p>Pre-trained multilingual language models show significant performance gains
for zero-shot cross-lingual model transfer on a wide range of natural language
understanding (NLU) tasks. Previously, for zero-shot cross-lingual evaluation,
pre-trained models are only fine-tuned on English data and tested on a variety
of target languages. In this paper, we do cross-lingual evaluation on various
NLU tasks (sentence classification, sequence labeling, question answering)
using prompt-tuning and compare it with fine-tuning. The results show that
prompt tuning achieves much better cross-lingual transfer than fine-tuning
across datasets, with only 0.1% to 0.3% tuned parameters. Additionally, we
demonstrate through the analysis that prompt tuning can have better
cross-lingual transferability of representations on downstream tasks with
better aligned decision boundaries.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EnDex: Evaluation of Dialogue Engagingness at Scale. (arXiv:2210.12362v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12362">
<div class="article-summary-box-inner">
<span><p>We propose EnDex, the first human-reaction based model to evaluate dialogue
engagingness. EnDex is trained on 80k Reddit-based Engagement Dataset (RED)
curated using a novel distant-supervision framework. Engagingness is a key
measure that captures high-level quality of AI dialogue systems and closely
reflects actual user experience. However, data shortage, plus the abstract and
extensive definition of engagingness makes it challenging to develop an
automatic metric. Our work departs from mainstream approaches that use
synthetic negative examples to train binary classifiers, and instead, proposes
a solution using distant-supervision from human-reaction feedback. To support
the soundness of our EnDex metric, we offer a theoretical foundation for
engagement, an extensive ablation study, and empirical evidence of high
correlation on five engagingness related datasets. We will release code,
off-the-shelf EnDex model, and a large-scale dataset upon paper publication to
facilitate future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FCGEC: Fine-Grained Corpus for Chinese Grammatical Error Correction. (arXiv:2210.12364v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12364">
<div class="article-summary-box-inner">
<span><p>Grammatical Error Correction (GEC) has been broadly applied in automatic
correction and proofreading system recently. However, it is still immature in
Chinese GEC due to limited high-quality data from native speakers in terms of
category and scale. In this paper, we present FCGEC, a fine-grained corpus to
detect, identify and correct the grammatical errors. FCGEC is a human-annotated
corpus with multiple references, consisting of 41,340 sentences collected
mainly from multi-choice questions in public school Chinese examinations.
Furthermore, we propose a Switch-Tagger-Generator (STG) baseline model to
correct the grammatical errors in low-resource settings. Compared to other GEC
benchmark models, experimental results illustrate that STG outperforms them on
our FCGEC. However, there exists a significant gap between benchmark models and
humans that encourages future models to bridge it.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeuroCounterfactuals: Beyond Minimal-Edit Counterfactuals for Richer Data Augmentation. (arXiv:2210.12365v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12365">
<div class="article-summary-box-inner">
<span><p>While counterfactual data augmentation offers a promising step towards robust
generalization in natural language processing, producing a set of
counterfactuals that offer valuable inductive bias for models remains a
challenge. Most existing approaches for producing counterfactuals, manual or
automated, rely on small perturbations via minimal edits, resulting in
simplistic changes. We introduce NeuroCounterfactuals, designed as loose
counterfactuals, allowing for larger edits which result in naturalistic
generations containing linguistic diversity, while still bearing similarity to
the original document. Our novel generative approach bridges the benefits of
constrained decoding, with those of language model adaptation for sentiment
steering. Training data augmentation with our generations results in both
in-domain and out-of-domain improvements for sentiment classification,
outperforming even manually curated counterfactuals, under select settings. We
further present detailed analyses to show the advantages of
NeuroCounterfactuals over approaches involving simple, minimal edits.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Precisely the Point: Adversarial Augmentations for Faithful and Informative Text Generation. (arXiv:2210.12367v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12367">
<div class="article-summary-box-inner">
<span><p>Though model robustness has been extensively studied in language
understanding, the robustness of Seq2Seq generation remains understudied. In
this paper, we conduct the first quantitative analysis on the robustness of
pre-trained Seq2Seq models. We find that even current SOTA pre-trained Seq2Seq
model (BART) is still vulnerable, which leads to significant degeneration in
faithfulness and informativeness for text generation tasks. This motivated us
to further propose a novel adversarial augmentation framework, namely AdvSeq,
for generally improving faithfulness and informativeness of Seq2Seq models via
enhancing their robustness. AdvSeq automatically constructs two types of
adversarial augmentations during training, including implicit adversarial
samples by perturbing word representations and explicit adversarial samples by
word swapping, both of which effectively improve Seq2Seq robustness. Extensive
experiments on three popular text generation tasks demonstrate that AdvSeq
significantly improves both the faithfulness and informativeness of Seq2Seq
generation under both automatic and human evaluation settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ReasTAP: Injecting Table Reasoning Skills During Pre-training via Synthetic Reasoning Examples. (arXiv:2210.12374v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12374">
<div class="article-summary-box-inner">
<span><p>Reasoning over tabular data requires both table structure understanding and a
broad set of table reasoning skills. Current models with table-specific
architectures and pre-training methods perform well on understanding table
structures, but they still struggle with tasks that require various table
reasoning skills. In this work, we develop ReasTAP to show that high-level
table reasoning skills can be injected into models during pre-training without
a complex table-specific architecture design. We define 7 table reasoning
skills, such as numerical operation, temporal comparison, and conjunction. Each
reasoning skill is associated with one example generator, which synthesizes
questions over semi-structured tables according to the sampled templates. We
model the table pre-training task as a sequence generation task and pre-train
ReasTAP to generate precise answers to the synthetic examples. ReasTAP is
evaluated on four benchmarks covering three downstream tasks including: 1)
WikiSQL and WTQ for Table Question Answering; 2) TabFact for Table Fact
Verification; and 3) LogicNLG for Faithful Table-to-Text Generation.
Experimental results demonstrate that ReasTAP achieves new state-of-the-art
performance on all benchmarks and delivers a significant improvement on
low-resource setting. Our code is publicly available at
https://github.com/Yale-LILY/ReasTAP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Correcting Diverse Factual Errors in Abstractive Summarization via Post-Editing and Language Model Infilling. (arXiv:2210.12378v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12378">
<div class="article-summary-box-inner">
<span><p>Abstractive summarization models often generate inconsistent summaries
containing factual errors or hallucinated content. Recent works focus on
correcting factual errors in generated summaries via post-editing. Such
correction models are trained using adversarial non-factual summaries
constructed using heuristic rules for injecting errors. However, generating
non-factual summaries using heuristics often does not generalize well to actual
model errors. In this work, we propose to generate hard, representative
synthetic examples of non-factual summaries through infilling language models.
With this data, we train a more robust fact-correction model to post-edit the
summaries to improve factual consistency. Through quantitative and qualitative
experiments on two popular summarization datasets -- CNN/DM and XSum -- we show
that our approach vastly outperforms prior methods in correcting erroneous
summaries. Our model -- FactEdit -- improves factuality scores by over ~11
points on CNN/DM and over ~31 points on XSum on average across multiple
summarization models, producing more factual summaries while maintaining
competitive summarization quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stance Detection and Open Research Avenues. (arXiv:2210.12383v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12383">
<div class="article-summary-box-inner">
<span><p>This tutorial aims to cover the state-of-the-art on stance detection and
address open research avenues for interested researchers and practitioners.
Stance detection is a recent research topic where the stance towards a given
target or target set is determined based on the given content and there are
significant application opportunities of stance detection in various domains.
The tutorial comprises two parts where the first part outlines the fundamental
concepts, problems, approaches, and resources of stance detection, while the
second part covers open research avenues and application areas of stance
detection. The tutorial will be a useful guide for researchers and
practitioners of stance detection, social media analysis, information
retrieval, and natural language processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MasakhaNER 2.0: Africa-centric Transfer Learning for Named Entity Recognition. (arXiv:2210.12391v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12391">
<div class="article-summary-box-inner">
<span><p>African languages are spoken by over a billion people, but are
underrepresented in NLP research and development. The challenges impeding
progress include the limited availability of annotated datasets, as well as a
lack of understanding of the settings where current methods are effective. In
this paper, we make progress towards solutions for these challenges, focusing
on the task of named entity recognition (NER). We create the largest
human-annotated NER dataset for 20 African languages, and we study the behavior
of state-of-the-art cross-lingual transfer methods in an Africa-centric
setting, demonstrating that the choice of source language significantly affects
performance. We show that choosing the best transfer language improves
zero-shot F1 scores by an average of 14 points across 20 languages compared to
using English. Our results highlight the need for benchmark datasets and models
that cover typologically-diverse African languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ADDMU: Detection of Far-Boundary Adversarial Examples with Data and Model Uncertainty Estimation. (arXiv:2210.12396v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12396">
<div class="article-summary-box-inner">
<span><p>Adversarial Examples Detection (AED) is a crucial defense technique against
adversarial attacks and has drawn increasing attention from the Natural
Language Processing (NLP) community. Despite the surge of new AED methods, our
studies show that existing methods heavily rely on a shortcut to achieve good
performance. In other words, current search-based adversarial attacks in NLP
stop once model predictions change, and thus most adversarial examples
generated by those attacks are located near model decision boundaries. To
surpass this shortcut and fairly evaluate AED methods, we propose to test AED
methods with \textbf{F}ar \textbf{B}oundary (\textbf{FB}) adversarial examples.
Existing methods show worse than random guess performance under this scenario.
To overcome this limitation, we propose a new technique, \textbf{ADDMU},
\textbf{a}dversary \textbf{d}etection with \textbf{d}ata and \textbf{m}odel
\textbf{u}ncertainty, which combines two types of uncertainty estimation for
both regular and FB adversarial example detection. Our new method outperforms
previous methods by 3.6 and 6.0 \emph{AUC} points under each scenario. Finally,
our analysis shows that the two types of uncertainty provided by \textbf{ADDMU}
can be leveraged to characterize adversarial examples and identify the ones
that contribute most to model's robustness in adversarial training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MetaASSIST: Robust Dialogue State Tracking with Meta Learning. (arXiv:2210.12397v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12397">
<div class="article-summary-box-inner">
<span><p>Existing dialogue datasets contain lots of noise in their state annotations.
Such noise can hurt model training and ultimately lead to poor generalization
performance. A general framework named ASSIST has recently been proposed to
train robust dialogue state tracking (DST) models. It introduces an auxiliary
model to generate pseudo labels for the noisy training set. These pseudo labels
are combined with vanilla labels by a common fixed weighting parameter to train
the primary DST model. Notwithstanding the improvements of ASSIST on DST,
tuning the weighting parameter is challenging. Moreover, a single parameter
shared by all slots and all instances may be suboptimal. To overcome these
limitations, we propose a meta learning-based framework MetaASSIST to
adaptively learn the weighting parameter. Specifically, we propose three
schemes with varying degrees of flexibility, ranging from slot-wise to both
slot-wise and instance-wise, to convert the weighting parameter into learnable
functions. These functions are trained in a meta-learning manner by taking the
validation set as meta data. Experimental results demonstrate that all three
schemes can achieve competitive performance. Most impressively, we achieve a
state-of-the-art joint goal accuracy of 80.10% on MultiWOZ 2.4.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Varifocal Question Generation for Fact-checking. (arXiv:2210.12400v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12400">
<div class="article-summary-box-inner">
<span><p>Fact-checking requires retrieving evidence related to a claim under
investigation. The task can be formulated as question generation based on a
claim, followed by question answering. However, recent question generation
approaches assume that the answer is known and typically contained in a passage
given as input, whereas such passages are what is being sought when verifying a
claim. In this paper, we present {\it Varifocal}, a method that generates
questions based on different focal points within a given claim, i.e.\ different
spans of the claim and its metadata, such as its source and date. Our method
outperforms previous work on a fact-checking question generation dataset on a
wide range of automatic evaluation metrics. These results are corroborated by
our manual evaluation, which indicates that our method generates more relevant
and informative questions. We further demonstrate the potential of focal points
in generating sets of clarification questions for product descriptions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PcMSP: A Dataset for Scientific Action Graphs Extraction from Polycrystalline Materials Synthesis Procedure Text. (arXiv:2210.12401v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12401">
<div class="article-summary-box-inner">
<span><p>Scientific action graphs extraction from materials synthesis procedures is
important for reproducible research, machine automation, and material
prediction. But the lack of annotated data has hindered progress in this field.
We demonstrate an effort to annotate Polycrystalline Materials Synthesis
Procedures (PcMSP) from 305 open access scientific articles for the
construction of synthesis action graphs. This is a new dataset for material
science information extraction that simultaneously contains the synthesis
sentences extracted from the experimental paragraphs, as well as the entity
mentions and intra-sentence relations. A two-step human annotation and
inter-annotator agreement study guarantee the high quality of the PcMSP corpus.
We introduce four natural language processing tasks: sentence classification,
named entity recognition, relation classification, and joint extraction of
entities and relations. Comprehensive experiments validate the effectiveness of
several state-of-the-art models for these challenges while leaving large space
for improvement. We also perform the error analysis and point out some unique
challenges that require further investigation. We will release our annotation
scheme, the corpus, and codes to the research community to alleviate the
scarcity of labeled data in this domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PATS: Sensitivity-aware Noisy Learning for Pretrained Language Models. (arXiv:2210.12403v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12403">
<div class="article-summary-box-inner">
<span><p>A wide range of NLP tasks benefit from the fine-tuning of pretrained language
models (PLMs). However, a number of redundant parameters which contribute less
to the downstream task are observed in a directly fine-tuned model. We consider
the gap between pretraining and downstream tasks hinders the training of these
redundant parameters, and results in a suboptimal performance of the overall
model. In this paper, we present PATS (Perturbation According To Sensitivity),
a noisy training mechanism which considers each parameter's importance in the
downstream task to help fine-tune PLMs. The main idea of PATS is to add bigger
noise to parameters with lower sensitivity and vice versa, in order to activate
more parameters' contributions to downstream tasks without affecting the
sensitive ones much. Extensive experiments conducted on different tasks of the
GLUE benchmark show PATS can consistently empower the fine-tuning of different
sizes of PLMs, and the parameters in the well-performing models always have
more concentrated distributions of sensitivities, which experimentally proves
the effectiveness of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recurrence Boosts Diversity! Revisiting Recurrent Latent Variable in Transformer-Based Variational AutoEncoder for Diverse Text Generation. (arXiv:2210.12409v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12409">
<div class="article-summary-box-inner">
<span><p>Variational Auto-Encoder (VAE) has been widely adopted in text generation.
Among many variants, recurrent VAE learns token-wise latent variables with each
conditioned on the preceding ones, which captures sequential variability better
in the era of RNN. However, it is unclear how to incorporate such recurrent
dynamics into the recently dominant Transformer due to its parallelism. In this
work, we propose DELLA, a Transformer-based recurrent VAE structure. DELLA
imposes recurrence on segment-wise latent variables with arbitrarily separated
text segments and constructs the posterior distribution with residual
parameterization. Besides, we design an acceleration method by approximating
idempotent matrices, which allows parallelism while maintaining the conditional
dependence of latent variables. We demonstrate that DELLA could enhance the
entanglement of each segment and preceding latent variables and deduce a
non-zero lower bound of the KL term, providing a theoretical guarantee of
generation diversity. Experiments on two unconditional and one conditional
generation tasks show that DELLA achieves significantly improved diversity
while maintaining satisfactory generation quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Shared Task on Gender Rewriting. (arXiv:2210.12410v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12410">
<div class="article-summary-box-inner">
<span><p>In this paper, we present the results and findings of the Shared Task on
Gender Rewriting, which was organized as part of the Seventh Arabic Natural
Language Processing Workshop. The task of gender rewriting refers to generating
alternatives of a given sentence to match different target user gender contexts
(e.g., female speaker with a male listener, a male speaker with a male
listener, etc.). This requires changing the grammatical gender (masculine or
feminine) of certain words referring to the users. In this task, we focus on
Arabic, a gender-marking morphologically rich language. A total of five teams
from four countries participated in the shared task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hard Gate Knowledge Distillation -- Leverage Calibration for Robust and Reliable Language Model. (arXiv:2210.12427v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12427">
<div class="article-summary-box-inner">
<span><p>In knowledge distillation, a student model is trained with supervisions from
both knowledge from a teacher and observations drawn from a training data
distribution. Knowledge of a teacher is considered a subject that holds
inter-class relations which send a meaningful supervision to a student; hence,
much effort has been put to find such knowledge to be distilled. In this paper,
we explore a question that has been given little attention: "when to distill
such knowledge." The question is answered in our work with the concept of model
calibration; we view a teacher model not only as a source of knowledge but also
as a gauge to detect miscalibration of a student. This simple and yet novel
view leads to a hard gate knowledge distillation scheme that switches between
learning from a teacher model and training data. We verify the gating mechanism
in the context of natural language generation at both the token-level and the
sentence-level. Empirical comparisons with strong baselines show that hard gate
knowledge distillation not only improves model generalization, but also
significantly lowers model calibration error.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robots-Dont-Cry: Understanding Falsely Anthropomorphic Utterances in Dialog Systems. (arXiv:2210.12429v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12429">
<div class="article-summary-box-inner">
<span><p>Dialog systems are often designed or trained to output human-like responses.
However, some responses may be impossible for a machine to truthfully say (e.g.
"that movie made me cry"). Highly anthropomorphic responses might make users
uncomfortable or implicitly deceive them into thinking they are interacting
with a human. We collect human ratings on the feasibility of approximately 900
two-turn dialogs sampled from 9 diverse data sources. Ratings are for two
hypothetical machine embodiments: a futuristic humanoid robot and a digital
assistant. We find that for some data-sources commonly used to train dialog
systems, 20-30% of utterances are not viewed as possible for a machine. Rating
is marginally affected by machine embodiment. We explore qualitative and
quantitative reasons for these ratings. Finally, we build classifiers and
explore how modeling configuration might affect output permissibly, and discuss
implications for building less falsely anthropomorphic dialog systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structure-Unified M-Tree Coding Solver for MathWord Problem. (arXiv:2210.12432v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12432">
<div class="article-summary-box-inner">
<span><p>As one of the challenging NLP tasks, designing math word problem (MWP)
solvers has attracted increasing research attention for the past few years. In
previous work, models designed by taking into account the properties of the
binary tree structure of mathematical expressions at the output side have
achieved better performance. However, the expressions corresponding to a MWP
are often diverse (e.g., $n_1+n_2 \times n_3-n_4$, $n_3\times n_2-n_4+n_1$,
etc.), and so are the corresponding binary trees, which creates difficulties in
model learning due to the non-deterministic output space. In this paper, we
propose the Structure-Unified M-Tree Coding Solver (SUMC-Solver), which applies
a tree with any M branches (M-tree) to unify the output structures. To learn
the M-tree, we use a mapping to convert the M-tree into the M-tree codes, where
codes store the information of the paths from tree root to leaf nodes and the
information of leaf nodes themselves, and then devise a Sequence-to-Code
(seq2code) model to generate the codes. Experimental results on the widely used
MAWPS and Math23K datasets have demonstrated that SUMC-Solver not only
outperforms several state-of-the-art models under similar experimental settings
but also performs much better under low-resource conditions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Prompt Tuning for Relation Classification. (arXiv:2210.12435v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12435">
<div class="article-summary-box-inner">
<span><p>Using prompts to explore the knowledge contained within pre-trained language
models for downstream tasks has now become an active topic. Current prompt
tuning methods mostly convert the downstream tasks to masked language modeling
problems by adding cloze-style phrases and mapping all labels to verbalizations
with fixed length, which has proven effective for tasks with simple label
spaces. However, when applied to relation classification exhibiting complex
label spaces, vanilla prompt tuning methods may struggle with label
verbalizations with arbitrary lengths due to rigid prompt restrictions.
Inspired by the text infilling task for pre-training generative models that can
flexibly predict missing spans, we propose a novel generative prompt tuning
method to reformulate relation classification as an infilling problem, which
frees our approach from limitations of current prompt based approaches and thus
fully exploits rich semantics of entity and relation types. In addition, we
design entity-guided decoding and discriminative relation scoring to generate
and align relations effectively and efficiently during inference. Extensive
experiments under fully supervised settings and low-resource settings
demonstrate the effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extractive Summarization of Legal Decisions using Multi-task Learning and Maximal Marginal Relevance. (arXiv:2210.12437v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12437">
<div class="article-summary-box-inner">
<span><p>Summarizing legal decisions requires the expertise of law practitioners,
which is both time- and cost-intensive. This paper presents techniques for
extractive summarization of legal decisions in a low-resource setting using
limited expert annotated data. We test a set of models that locate relevant
content using a sequential model and tackle redundancy by leveraging maximal
marginal relevance to compose summaries. We also demonstrate an implicit
approach to help train our proposed models generate more informative summaries.
Our multi-task learning model variant leverages rhetorical role identification
as an auxiliary task to further improve the summarizer. We perform extensive
experiments on datasets containing legal decisions from the US Board of
Veterans' Appeals and conduct quantitative and expert-ranked evaluations of our
models. Our results show that the proposed approaches can achieve ROUGE scores
vis-\`a-vis expert extracted summaries that match those achieved by
inter-annotator comparison.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly-Supervised Temporal Article Grounding. (arXiv:2210.12444v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12444">
<div class="article-summary-box-inner">
<span><p>Given a long untrimmed video and natural language queries, video grounding
(VG) aims to temporally localize the semantically-aligned video segments.
Almost all existing VG work holds two simple but unrealistic assumptions: 1)
All query sentences can be grounded in the corresponding video. 2) All query
sentences for the same video are always at the same semantic scale.
Unfortunately, both assumptions make today's VG models fail to work in
practice. For example, in real-world multimodal assets (eg, news articles),
most of the sentences in the article can not be grounded in their affiliated
videos, and they typically have rich hierarchical relations (ie, at different
semantic scales). To this end, we propose a new challenging grounding task:
Weakly-Supervised temporal Article Grounding (WSAG). Specifically, given an
article and a relevant video, WSAG aims to localize all ``groundable''
sentences to the video, and these sentences are possibly at different semantic
scales. Accordingly, we collect the first WSAG dataset to facilitate this task:
YouwikiHow, which borrows the inherent multi-scale descriptions in wikiHow
articles and plentiful YouTube videos. In addition, we propose a simple but
effective method DualMIL for WSAG, which consists of a two-level MIL loss and a
single-/cross- sentence constraint loss. These training objectives are
carefully designed for these relaxed assumptions. Extensive ablations have
verified the effectiveness of DualMIL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-domain Generalization for AMR Parsing. (arXiv:2210.12445v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12445">
<div class="article-summary-box-inner">
<span><p>Abstract Meaning Representation (AMR) parsing aims to predict an AMR graph
from textual input. Recently, there has been notable growth in AMR parsing
performance. However, most existing work focuses on improving the performance
in the specific domain, ignoring the potential domain dependence of AMR parsing
systems. To address this, we extensively evaluate five representative AMR
parsers on five domains and analyze challenges to cross-domain AMR parsing. We
observe that challenges to cross-domain AMR parsing mainly arise from the
distribution shift of words and AMR concepts. Based on our observation, we
investigate two approaches to reduce the domain distribution divergence of text
and AMR features, respectively. Experimental results on two out-of-domain test
sets show the superiority of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">There Is No Standard Answer: Knowledge-Grounded Dialogue Generation with Adversarial Activated Multi-Reference Learning. (arXiv:2210.12459v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12459">
<div class="article-summary-box-inner">
<span><p>Knowledge-grounded conversation (KGC) shows excellent potential to deliver an
engaging and informative response. However, existing approaches emphasize
selecting one golden knowledge given a particular dialogue context, overlooking
the one-to-many phenomenon in dialogue. As a result, the existing paradigm
limits the diversity of knowledge selection and generation. To this end, we
establish a multi-reference KGC dataset and propose a series of metrics to
systematically assess the one-to-many efficacy of existing KGC models.
Furthermore, to extend the hypothesis space of knowledge selection to enhance
the mapping relationship between multiple knowledge and multiple responses, we
devise a span-based variational model and optimize the model in a wake-sleep
style with an ameliorated evidence lower bound objective to learn the
one-to-many generalization. Both automatic and human evaluations demonstrate
the efficacy of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Collaborative Reasoning on Multi-Modal Semantic Graphs for Video-Grounded Dialogue Generation. (arXiv:2210.12460v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12460">
<div class="article-summary-box-inner">
<span><p>We study video-grounded dialogue generation, where a response is generated
based on the dialogue context and the associated video. The primary challenges
of this task lie in (1) the difficulty of integrating video data into
pre-trained language models (PLMs) which presents obstacles to exploiting the
power of large-scale pre-training; and (2) the necessity of taking into account
the complementarity of various modalities throughout the reasoning process.
Although having made remarkable progress in video-grounded dialogue generation,
existing methods still fall short when it comes to integrating with PLMs in a
way that allows information from different modalities to complement each other.
To alleviate these issues, we first propose extracting pertinent information
from videos and turning it into reasoning paths that are acceptable to PLMs.
Additionally, we propose a multi-agent reinforcement learning method to
collaboratively perform reasoning on different modalities (i.e., video and
dialogue context). Empirical experiment results on two public datasets indicate
that the proposed model can significantly outperform state-of-the-art models by
large margins on both automatic and human evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Efficient Dialogue Pre-training with Transferable and Interpretable Latent Structure. (arXiv:2210.12461v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12461">
<div class="article-summary-box-inner">
<span><p>With the availability of massive general-domain dialogue data, pre-trained
dialogue generation appears to be super appealing to transfer knowledge from
the general domain to downstream applications. In most existing work, such
transferable ability is mainly obtained by fitting a large model with hundreds
of millions of parameters on massive data in an exhaustive way, leading to
inefficient running and poor interpretability. This paper proposes a novel
dialogue generation model with a latent structure that is easily transferable
from the general domain to downstream tasks in a lightweight and transparent
way. Experiments on two benchmarks validate the effectiveness of the proposed
model. Thanks to the transferable latent structure, our model is able to yield
better dialogue responses than four strong baselines in terms of both automatic
and human evaluations, and our model with about 22% parameters particularly
delivers a 5x speedup in running time compared with the strongest baseline.
Moreover, the proposed model is explainable by interpreting the discrete latent
variables.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EtriCA: Event-Triggered Context-Aware Story Generation Augmented by Cross Attention. (arXiv:2210.12463v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12463">
<div class="article-summary-box-inner">
<span><p>One of the key challenges of automatic story generation is how to generate a
long narrative that can maintain fluency, relevance, and coherence. Despite
recent progress, current story generation systems still face the challenge of
how to effectively capture contextual and event features, which has a profound
impact on a model's generation performance. To address these challenges, we
present EtriCA, a novel neural generation model, which improves the relevance
and coherence of the generated stories through residually mapping context
features to event sequences with a cross-attention mechanism. Such a feature
capturing mechanism allows our model to better exploit the logical relatedness
between events when generating stories. Extensive experiments based on both
automatic and human evaluations show that our model significantly outperforms
state-of-the-art baselines, demonstrating the effectiveness of our model in
leveraging context and event features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ECTSum: A New Benchmark Dataset For Bullet Point Summarization of Long Earnings Call Transcripts. (arXiv:2210.12467v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12467">
<div class="article-summary-box-inner">
<span><p>Despite tremendous progress in automatic summarization, state-of-the-art
methods are predominantly trained to excel in summarizing short newswire
articles, or documents with strong layout biases such as scientific articles or
government reports. Efficient techniques to summarize financial documents,
including facts and figures, have largely been unexplored, majorly due to the
unavailability of suitable datasets. In this work, we present ECTSum, a new
dataset with transcripts of earnings calls (ECTs), hosted by publicly traded
companies, as documents, and short experts-written telegram-style bullet point
summaries derived from corresponding Reuters articles. ECTs are long
unstructured documents without any prescribed length limit or format. We
benchmark our dataset with state-of-the-art summarizers across various metrics
evaluating the content quality and factual consistency of the generated
summaries. Finally, we present a simple-yet-effective approach, ECT-BPS, to
generate a set of bullet points that precisely capture the important facts
discussed in the calls.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiscoSense: Commonsense Reasoning with Discourse Connectives. (arXiv:2210.12478v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12478">
<div class="article-summary-box-inner">
<span><p>We present DiscoSense, a benchmark for commonsense reasoning via
understanding a wide variety of discourse connectives. We generate compelling
distractors in DiscoSense using Conditional Adversarial Filtering, an extension
of Adversarial Filtering that employs conditional generation. We show that
state-of-the-art pre-trained language models struggle to perform well on
DiscoSense, which makes this dataset ideal for evaluating next-generation
commonsense reasoning systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SynGEC: Syntax-Enhanced Grammatical Error Correction with a Tailored GEC-Oriented Parser. (arXiv:2210.12484v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12484">
<div class="article-summary-box-inner">
<span><p>This work proposes a syntax-enhanced grammatical error correction (GEC)
approach named SynGEC that effectively incorporates dependency syntactic
information into the encoder part of GEC models. The key challenge for this
idea is that off-the-shelf parsers are unreliable when processing ungrammatical
sentences. To confront this challenge, we propose to build a tailored
GEC-oriented parser (GOPar) using parallel GEC training data as a pivot. First,
we design an extended syntax representation scheme that allows us to represent
both grammatical errors and syntax in a unified tree structure. Then, we obtain
parse trees of the source incorrect sentences by projecting trees of the target
correct sentences. Finally, we train GOPar with such projected trees. For GEC,
we employ the graph convolution network to encode source-side syntactic
information produced by GOPar, and fuse them with the outputs of the
Transformer encoder. Experiments on mainstream English and Chinese GEC datasets
show that our proposed SynGEC approach consistently and substantially
outperforms strong baselines and achieves competitive performance. Our code and
data are all publicly available at https://github.com/HillZhang1999/SynGEC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DANLI: Deliberative Agent for Following Natural Language Instructions. (arXiv:2210.12485v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12485">
<div class="article-summary-box-inner">
<span><p>Recent years have seen an increasing amount of work on embodied AI agents
that can perform tasks by following human language instructions. However, most
of these agents are reactive, meaning that they simply learn and imitate
behaviors encountered in the training data. These reactive agents are
insufficient for long-horizon complex tasks. To address this limitation, we
propose a neuro-symbolic deliberative agent that, while following language
instructions, proactively applies reasoning and planning based on its neural
and symbolic representations acquired from past experience (e.g., natural
language and egocentric vision). We show that our deliberative agent achieves
greater than 70% improvement over reactive baselines on the challenging TEACh
benchmark. Moreover, the underlying reasoning and planning processes, together
with our modular framework, offer impressive transparency and explainability to
the behaviors of the agent. This enables an in-depth understanding of the
agent's capabilities, which shed light on challenges and opportunities for
future embodied agents for instruction following. The code is available at
https://github.com/sled-group/DANLI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MetaLogic: Logical Reasoning Explanations with Fine-Grained Structure. (arXiv:2210.12487v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12487">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a comprehensive benchmark to investigate models'
logical reasoning capabilities in complex real-life scenarios. Current
explanation datasets often employ synthetic data with simple reasoning
structures. Therefore, it cannot express more complex reasoning processes, such
as the rebuttal to a reasoning step and the degree of certainty of the
evidence. To this end, we propose a comprehensive logical reasoning explanation
form. Based on the multi-hop chain of reasoning, the explanation form includes
three main components: (1) The condition of rebuttal that the reasoning node
can be challenged; (2) Logical formulae that uncover the internal texture of
reasoning nodes; (3) Reasoning strength indicated by degrees of certainty. The
fine-grained structure conforms to the real logical reasoning scenario, better
fitting the human cognitive process but, simultaneously, is more challenging
for the current models. We evaluate the current best models' performance on
this new explanation form. The experimental results show that generating
reasoning graphs remains a challenging task for current models, even with the
help of giant pre-trained language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training Dynamics for Curriculum Learning: A Study on Monolingual and Cross-lingual NLU. (arXiv:2210.12499v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12499">
<div class="article-summary-box-inner">
<span><p>Curriculum Learning (CL) is a technique of training models via ranking
examples in a typically increasing difficulty trend with the aim of
accelerating convergence and improving generalisability. Current approaches for
Natural Language Understanding (NLU) tasks use CL to improve in-distribution
data performance often via heuristic-oriented or task-agnostic difficulties. In
this work, instead, we employ CL for NLU by taking advantage of training
dynamics as difficulty metrics, i.e., statistics that measure the behavior of
the model at hand on specific task-data instances during training and propose
modifications of existing CL schedulers based on these statistics. Differently
from existing works, we focus on evaluating models on in-distribution (ID),
out-of-distribution (OOD) as well as zero-shot (ZS) cross-lingual transfer
datasets. We show across several NLU tasks that CL with training dynamics can
result in better performance mostly on zero-shot cross-lingual transfer and OOD
settings with improvements up by 8.5% in certain cases. Overall, experiments
indicate that training dynamics can lead to better performing models with
smoother training compared to other difficulty metrics while being 20% faster
on average. In addition, through analysis we shed light on the correlations of
task-specific versus task-agnostic metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DOROTHIE: Spoken Dialogue for Handling Unexpected Situations in Interactive Autonomous Driving Agents. (arXiv:2210.12511v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12511">
<div class="article-summary-box-inner">
<span><p>In the real world, autonomous driving agents navigate in highly dynamic
environments full of unexpected situations where pre-trained models are
unreliable. In these situations, what is immediately available to vehicles is
often only human operators. Empowering autonomous driving agents with the
ability to navigate in a continuous and dynamic environment and to communicate
with humans through sensorimotor-grounded dialogue becomes critical. To this
end, we introduce Dialogue On the ROad To Handle Irregular Events (DOROTHIE), a
novel interactive simulation platform that enables the creation of unexpected
situations on the fly to support empirical studies on situated communication
with autonomous driving agents. Based on this platform, we created the Situated
Dialogue Navigation (SDN), a navigation benchmark of 183 trials with a total of
8415 utterances, around 18.7 hours of control streams, and 2.9 hours of trimmed
audio. SDN is developed to evaluate the agent's ability to predict dialogue
moves from humans as well as generate its own dialogue moves and physical
navigation actions. We further developed a transformer-based baseline model for
these SDN tasks. Our empirical results indicate that language guided-navigation
in a highly dynamic environment is an extremely difficult task for end-to-end
models. These results will provide insight towards future work on robust
autonomous driving agents. The DOROTHIE platform, SDN benchmark, and code for
the baseline model are available at https://github.com/sled-group/DOROTHIE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring The Landscape of Distributional Robustness for Question Answering Models. (arXiv:2210.12517v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12517">
<div class="article-summary-box-inner">
<span><p>We conduct a large empirical evaluation to investigate the landscape of
distributional robustness in question answering. Our investigation spans over
350 models and 16 question answering datasets, including a diverse set of
architectures, model sizes, and adaptation methods (e.g., fine-tuning, adapter
tuning, in-context learning, etc.). We find that, in many cases, model
variations do not affect robustness and in-distribution performance alone
determines out-of-distribution performance. Moreover, our findings indicate
that i) zero-shot and in-context learning methods are more robust to
distribution shifts than fully fine-tuned models; ii) few-shot prompt
fine-tuned models exhibit better robustness than few-shot fine-tuned span
prediction models; iii) parameter-efficient and robustness enhancing training
methods provide no significant robustness improvements. In addition, we
publicly release all evaluations to encourage researchers to further analyze
robustness trends for question answering models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LMPriors: Pre-Trained Language Models as Task-Specific Priors. (arXiv:2210.12530v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12530">
<div class="article-summary-box-inner">
<span><p>Particularly in low-data regimes, an outstanding challenge in machine
learning is developing principled techniques for augmenting our models with
suitable priors. This is to encourage them to learn in ways that are compatible
with our understanding of the world. But in contrast to generic priors such as
shrinkage or sparsity, we draw inspiration from the recent successes of
large-scale language models (LMs) to construct task-specific priors distilled
from the rich knowledge of LMs. Our method, Language Model Priors (LMPriors),
incorporates auxiliary natural language metadata about the task -- such as
variable names and descriptions -- to encourage downstream model outputs to be
consistent with the LM's common-sense reasoning based on the metadata.
Empirically, we demonstrate that LMPriors improve model performance in settings
where such natural language descriptions are available, and perform well on
several tasks that benefit from such prior knowledge, such as feature
selection, causal inference, and safe reinforcement learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Why Do You Feel This Way? Summarizing Triggers of Emotions in Social Media Posts. (arXiv:2210.12531v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12531">
<div class="article-summary-box-inner">
<span><p>Crises such as the COVID-19 pandemic continuously threaten our world and
emotionally affect billions of people worldwide in distinct ways. Understanding
the triggers leading to people's emotions is of crucial importance. Social
media posts can be a good source of such analysis, yet these texts tend to be
charged with multiple emotions, with triggers scattering across multiple
sentences. This paper takes a novel angle, namely, emotion detection and
trigger summarization, aiming to both detect perceived emotions in text, and
summarize events and their appraisals that trigger each emotion. To support
this goal, we introduce CovidET (Emotions and their Triggers during Covid-19),
a dataset of ~1,900 English Reddit posts related to COVID-19, which contains
manual annotations of perceived emotions and abstractive summaries of their
triggers described in the post. We develop strong baselines to jointly detect
emotions and summarize emotion triggers. Our analyses show that CovidET
presents new challenges in emotion-specific summarization, as well as
multi-emotion detection in long social media posts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EntityCS: Improving Zero-Shot Cross-lingual Transfer with Entity-Centric Code Switching. (arXiv:2210.12540v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12540">
<div class="article-summary-box-inner">
<span><p>Accurate alignment between languages is fundamental for improving
cross-lingual pre-trained language models (XLMs). Motivated by the natural
phenomenon of code-switching (CS) in multilingual speakers, CS has been used as
an effective data augmentation method that offers language alignment at word-
or phrase-level, in contrast to sentence-level via parallel instances. Existing
approaches either use dictionaries or parallel sentences with word-alignment to
generate CS data by randomly switching words in a sentence. However, such
methods can be suboptimal as dictionaries disregard semantics, and syntax might
become invalid after random word switching. In this work, we propose EntityCS,
a method that focuses on Entity-level Code-Switching to capture fine-grained
cross-lingual semantics without corrupting syntax. We use Wikidata and the
English Wikipedia to construct an entity-centric CS corpus by switching
entities to their counterparts in other languages. We further propose
entity-oriented masking strategies during intermediate model training on the
EntityCS corpus for improving entity prediction. Evaluation of the trained
models on four entity-centric downstream tasks shows consistent improvements
over the baseline with a notable increase of 10% in Fact Retrieval. We release
the corpus and models to assist research on code-switching and enriching XLMs
with external knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Refine and Imitate: Reducing Repetition and Inconsistency in Persuasion Dialogues via Reinforcement Learning and Human Demonstration. (arXiv:2012.15375v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15375">
<div class="article-summary-box-inner">
<span><p>Persuasion dialogue systems reflect the machine's ability to make strategic
moves beyond verbal communication, and therefore differentiate themselves from
task-oriented or open-domain dialogue systems and have their own unique values.
However, the repetition and inconsistency problems still persist in dialogue
response generation and could substantially impact user experience and impede
the persuasion outcome. Besides, although reinforcement learning (RL)
approaches have achieved big success in strategic tasks such as games, they
require a sophisticated user simulator to provide real-time feedback to the
dialogue system, which limits the application of RL on persuasion dialogues. To
address these issues towards a better persuasion dialogue system, we apply RL
to refine a language model baseline without user simulators, and distill
sentence-level information about repetition, inconsistency, and task relevance
through rewards. Moreover, to better accomplish the persuasion task, the model
learns from human demonstration to imitate human persuasion behavior and
selects the most persuasive responses. Experiments show that our model
outperforms previous state-of-the-art dialogue models on both automatic metrics
and human evaluation results on a donation persuasion task, and generates more
diverse, consistent and persuasive conversations according to the user
feedback.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Poolingformer: Long Document Modeling with Pooling Attention. (arXiv:2105.04371v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04371">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce a two-level attention schema, Poolingformer, for
long document modeling. Its first level uses a smaller sliding window pattern
to aggregate information from neighbors. Its second level employs a larger
window to increase receptive fields with pooling attention to reduce both
computational cost and memory consumption. We first evaluate Poolingformer on
two long sequence QA tasks: the monolingual NQ and the multilingual TyDi QA.
Experimental results show that Poolingformer sits atop three official
leaderboards measured by F1, outperforming previous state-of-the-art models by
1.9 points (79.8 vs. 77.9) on NQ long answer, 1.9 points (79.5 vs. 77.6) on
TyDi QA passage answer, and 1.6 points (67.6 vs. 66.0) on TyDi QA minimal
answer. We further evaluate Poolingformer on a long sequence summarization
task. Experimental results on the arXiv benchmark continue to demonstrate its
superior performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient (Soft) Q-Learning for Text Generation with Limited Good Data. (arXiv:2106.07704v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07704">
<div class="article-summary-box-inner">
<span><p>Maximum likelihood estimation (MLE) is the predominant algorithm for training
text generation models. This paradigm relies on direct supervision examples,
which is not applicable to many emerging applications, such as generating
adversarial attacks or generating prompts to control language models.
Reinforcement learning (RL) on the other hand offers a more flexible solution
by allowing users to plug in arbitrary task metrics as reward. Yet previous RL
algorithms for text generation, such as policy gradient (on-policy RL) and
Q-learning (off-policy RL), are often notoriously inefficient or unstable to
train due to the large sequence space and the sparse reward received only at
the end of sequences. In this paper, we introduce a new RL formulation for text
generation from the soft Q-learning (SQL) perspective. It enables us to draw
from the latest RL advances, such as path consistency learning, to combine the
best of on-/off-policy updates, and learn effectively from sparse reward. We
apply the approach to a wide range of novel text generation tasks, including
learning from noisy/negative examples, adversarial attacks, and prompt
generation. Experiments show our approach consistently outperforms both
task-specialized algorithms and the previous RL methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PicTalky: Augmentative and Alternative Communication Software for Language Developmental Disabilities. (arXiv:2109.12941v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.12941">
<div class="article-summary-box-inner">
<span><p>Augmentative and alternative communication (AAC) is a practical means of
communication for people with language disabilities. In this study, we propose
PicTalky, which is an AI-based AAC system that helps children with language
developmental disabilities to improve their communication skills and language
comprehension abilities. PicTalky can process both text and pictograms more
accurately by connecting a series of neural-based NLP modules. Moreover, we
perform quantitative and qualitative analyses on the essential features of
PicTalky. It is expected that those suffering from language problems will be
able to express their intentions or desires more easily and improve their
quality of life by using this service. We have made the models freely available
alongside a demonstration of the Web interface. Furthermore, we implemented
robotics AAC for the first time by applying PicTalky to the NAO robot.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EncT5: A Framework for Fine-tuning T5 as Non-autoregressive Models. (arXiv:2110.08426v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08426">
<div class="article-summary-box-inner">
<span><p>Pre-trained encoder-decoder transformer architectures have become
increasingly popular recently with the advent of T5 models. T5 has also become
more favorable over other architectures like BERT due to the amount of data
that it is pre-trained on, increased scale of model parameter sizes and easy
applicability to a diverse set of tasks due to the generative nature of the
model. While being able to generalize to a wide variety of tasks, it is not
clear that encoder-decoder architectures are the most efficient for fine-tuning
tasks that don't require auto-regressive decoding. In this work, we study
fine-tuning pre-trained encoder-decoder models for tasks such as
classification, multi-label classification, and structured prediction. We
propose \textbf{EncT5}, a framework for these problems, and illustrate
instantiations for these tasks. Our experiment results show that EncT5 has
advantages over T5 such as efficiency and usability out performs BERT when
evaluated on publicly available pre-trained checkpoints.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KPDrop: Improving Absent Keyphrase Generation. (arXiv:2112.01476v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.01476">
<div class="article-summary-box-inner">
<span><p>Keyphrase generation is the task of generating phrases (keyphrases) that
summarize the main topics of a given document. Keyphrases can be either present
or absent from the given document. While the extraction of present keyphrases
has received much attention in the past, only recently a stronger focus has
been placed on the generation of absent keyphrases. However, generating absent
keyphrases is challenging; even the best methods show only a modest degree of
success. In this paper, we propose a model-agnostic approach called keyphrase
dropout (or KPDrop) to improve absent keyphrase generation. In this approach,
we randomly drop present keyphrases from the document and turn them into
artificial absent keyphrases during training. We test our approach extensively
and show that it consistently improves the absent performance of strong
baselines in both supervised and resource-constrained semi-supervised settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KGE-CL: Contrastive Learning of Tensor Decomposition Based Knowledge Graph Embeddings. (arXiv:2112.04871v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.04871">
<div class="article-summary-box-inner">
<span><p>Learning the embeddings of knowledge graphs (KG) is vital in artificial
intelligence, and can benefit various downstream applications, such as
recommendation and question answering. In recent years, many research efforts
have been proposed for knowledge graph embedding (KGE). However, most previous
KGE methods ignore the semantic similarity between the related entities and
entity-relation couples in different triples since they separately optimize
each triple with the scoring function. To address this problem, we propose a
simple yet efficient contrastive learning framework for tensor decomposition
based (TDB) KGE, which can shorten the semantic distance of the related
entities and entity-relation couples in different triples and thus improve the
performance of KGE. We evaluate our proposed method on three standard KGE
datasets: WN18RR, FB15k-237 and YAGO3-10. Our method can yield some new
state-of-the-art results, achieving 51.2% MRR, 46.8% Hits@1 on the WN18RR
dataset, 37.8% MRR, 28.6% Hits@1 on FB15k-237 dataset, and 59.1% MRR, 51.8%
Hits@1 on the YAGO3-10 dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Out-of-Domain Transfer Learning of Natural Language Explanations in a Label-Abundant Setup. (arXiv:2112.06204v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06204">
<div class="article-summary-box-inner">
<span><p>Training a model to provide natural language explanations (NLEs) for its
predictions usually requires the acquisition of task-specific NLEs, which is
time- and resource-consuming. A potential solution is the few-shot
out-of-domain transfer of NLEs from a parent task with many NLEs to a child
task. In this work, we examine the setup in which the child task has few NLEs
but abundant labels. We establish four few-shot transfer learning methods that
cover the possible fine-tuning combinations of the labels and NLEs for the
parent and child tasks. We transfer explainability from a large natural
language inference dataset (e-SNLI) separately to two child tasks: (1) hard
cases of pronoun resolution, where we introduce the small-e-WinoGrande dataset
of NLEs on top of the WinoGrande dataset, and (2)~commonsense validation
(ComVE). Our results demonstrate that the parent task helps with NLE generation
and we establish the best methods for this setup.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simple Questions Generate Named Entity Recognition Datasets. (arXiv:2112.08808v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.08808">
<div class="article-summary-box-inner">
<span><p>Recent named entity recognition (NER) models often rely on human-annotated
datasets, requiring the significant engagement of professional knowledge on the
target domain and entities. This research introduces an ask-to-generate
approach that automatically generates NER datasets by asking questions in
simple natural language to an open-domain question answering system (e.g.,
"Which disease?"). Despite using fewer in-domain resources, our models, solely
trained on the generated datasets, largely outperform strong low-resource
models by an average F1 score of 19.5 for six popular NER benchmarks.
Furthermore, our models provide competitive performance with rich-resource
models that additionally leverage in-domain dictionaries provided by domain
experts. In few-shot NER, we outperform the previous best model by an F1 score
of 5.2 on three benchmarks and achieve new state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-shot Learning with Multilingual Language Models. (arXiv:2112.10668v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.10668">
<div class="article-summary-box-inner">
<span><p>Large-scale generative language models such as GPT-3 are competitive few-shot
learners. While these models are known to be able to jointly represent many
different languages, their training data is dominated by English, potentially
limiting their cross-lingual generalization. In this work, we train
multilingual generative language models on a corpus covering a diverse set of
languages, and study their few- and zero-shot learning capabilities in a wide
range of tasks. Our largest model with 7.5 billion parameters sets new state of
the art in few-shot learning in more than 20 representative languages,
outperforming GPT-3 of comparable size in multilingual commonsense reasoning
(with +7.4% absolute accuracy improvement in 0-shot settings and +9.4% in
4-shot settings) and natural language inference (+5.4% in each of 0-shot and
4-shot settings). On the FLORES-101 machine translation benchmark, our model
outperforms GPT-3 on 171 out of 182 directions with 32 training examples, while
surpassing the official supervised baseline in 45 directions. We conduct an
in-depth analysis of different multilingual prompting approaches, showing in
particular that strong few-shot learning performance across languages can be
achieved via cross-lingual transfer through both templates and demonstration
examples. Finally, we evaluate our models in social value tasks such as hate
speech detection in five languages and find it has limitations similar to
comparable sized GPT-3 models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PAEG: Phrase-level Adversarial Example Generation for Neural Machine Translation. (arXiv:2201.02009v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02009">
<div class="article-summary-box-inner">
<span><p>While end-to-end neural machine translation (NMT) has achieved impressive
progress, noisy input usually leads models to become fragile and unstable.
Generating adversarial examples as the augmented data has been proved to be
useful to alleviate this problem. Existing methods for adversarial example
generation (AEG) are word-level or character-level, which ignore the ubiquitous
phrase structure. In this paper, we propose a Phrase-level Adversarial Example
Generation (PAEG) framework to enhance the robustness of the translation model.
Our method further improves the gradient-based word-level AEG method by
adopting a phrase-level substitution strategy. We verify our method on three
benchmarks, including LDC Chinese-English, IWSLT14 German-English, and WMT14
English-German tasks. Experimental results demonstrate that our approach
significantly improves translation performance and robustness to noise compared
to previous strong baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unobserved Local Structures Make Compositional Generalization Hard. (arXiv:2201.05899v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05899">
<div class="article-summary-box-inner">
<span><p>While recent work has convincingly showed that sequence-to-sequence models
struggle to generalize to new compositions (termed compositional
generalization), little is known on what makes compositional generalization
hard on a particular test instance. In this work, we investigate what are the
factors that make generalization to certain test instances challenging. We
first substantiate that indeed some examples are more difficult than others by
showing that different models consistently fail or succeed on the same test
instances. Then, we propose a criterion for the difficulty of an example: a
test instance is hard if it contains a local structure that was not observed at
training time. We formulate a simple decision rule based on this criterion and
empirically show it predicts instance-level generalization well across 5
different semantic parsing datasets, substantially better than alternative
decision rules. Last, we show local structures can be leveraged for creating
difficult adversarial compositional splits and also to improve compositional
generalization under limited training budgets by strategically selecting
examples for the training set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation. (arXiv:2201.05955v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05955">
<div class="article-summary-box-inner">
<span><p>A recurring challenge of crowdsourcing NLP datasets at scale is that human
writers often rely on repetitive patterns when crafting examples, leading to a
lack of linguistic diversity. We introduce a novel approach for dataset
creation based on worker and AI collaboration, which brings together the
generative strength of language models and the evaluative strength of humans.
Starting with an existing dataset, MultiNLI for natural language inference
(NLI), our approach uses dataset cartography to automatically identify examples
that demonstrate challenging reasoning patterns, and instructs GPT-3 to compose
new examples with similar patterns. Machine generated examples are then
automatically filtered, and finally revised and labeled by human crowdworkers.
The resulting dataset, WANLI, consists of 107,885 NLI examples and presents
unique empirical strengths over existing NLI datasets. Remarkably, training a
model on WANLI improves performance on eight out-of-domain test sets we
consider, including by 11% on HANS and 9% on Adversarial NLI, compared to
training on the 4x larger MultiNLI. Moreover, it continues to be more effective
than MultiNLI augmented with other NLI datasets. Our results demonstrate the
promise of leveraging natural language generation techniques and re-imagining
the role of humans in the dataset creation process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Memory-assisted prompt editing to improve GPT-3 after deployment. (arXiv:2201.06009v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.06009">
<div class="article-summary-box-inner">
<span><p>Large LMs such as GPT-3 are powerful, but can commit mistakes that are
obvious to humans. For example, GPT-3 would mistakenly interpret "What word is
similar to good?" to mean a homophone, while the user intended a synonym. Our
goal is to effectively correct such errors via user interactions with the
system but without retraining, which will be prohibitively costly. We pair
GPT-3 with a growing memory of recorded cases where the model misunderstood the
user's intents, along with user feedback for clarification. Such a memory
allows our system to produce enhanced prompts for any new query based on the
user feedback for error correction on similar cases in the past. On four tasks
(two lexical tasks, two advanced ethical reasoning tasks), we show how a
(simulated) user can interactively teach a deployed GPT-3, substantially
increasing its accuracy over the queries with different kinds of
misunderstandings by the GPT-3. Our approach is a step towards the low-cost
utility enhancement for very large pre-trained LMs. Code, data, and
instructions to implement MEMPROMPT for a new task at
https://www.memprompt.com/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEMON: Language-Based Environment Manipulation via Execution-Guided Pre-training. (arXiv:2201.08081v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08081">
<div class="article-summary-box-inner">
<span><p>Language-based environment manipulation requires agents to manipulate the
environment following natural language instructions, which is challenging due
to the huge space of the environments. To address this challenge, various
approaches have been proposed in recent work. Although these approaches work
well for their intended environments, they are difficult to generalize across
environments. In this work, we propose LEMON, a general framework for
language-based environment manipulation tasks. Specifically, we first specify a
task-agnostic approach for language-based environment manipulation tasks, which
can deal with various environments using the same generative language model.
Then we propose an execution-guided pre-training strategy to inject prior
knowledge of environments to the language model with a pure synthetic
pre-training corpus. Experimental results on tasks including Alchemy, Scene,
Tangrams, ProPara and Recipes demonstrate the effectiveness of LEMON: it
achieves new state-of-the-art results on four of the tasks, and the
execution-guided pre-training strategy brings remarkable improvements on all
experimental tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TextHacker: Learning based Hybrid Local Search Algorithm for Text Hard-label Adversarial Attack. (arXiv:2201.08193v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.08193">
<div class="article-summary-box-inner">
<span><p>Existing textual adversarial attacks usually utilize the gradient or
prediction confidence to generate adversarial examples, making it hard to be
deployed in real-world applications. To this end, we consider a rarely
investigated but more rigorous setting, namely hard-label attack, in which the
attacker can only access the prediction label. In particular, we find we can
learn the importance of different words via the change on prediction label
caused by word substitutions on the adversarial examples. Based on this
observation, we propose a novel adversarial attack, termed Text Hard-label
attacker (TextHacker). TextHacker randomly perturbs lots of words to craft an
adversarial example. Then, TextHacker adopts a hybrid local search algorithm
with the estimation of word importance from the attack history to minimize the
adversarial perturbation. Extensive evaluations for text classification and
textual entailment show that TextHacker significantly outperforms existing
hard-label attacks regarding the attack performance as well as adversary
quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal data matters: language model pre-training over structured and unstructured electronic health records. (arXiv:2201.10113v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.10113">
<div class="article-summary-box-inner">
<span><p>As two important textual modalities in electronic health records (EHR), both
structured data (clinical codes) and unstructured data (clinical narratives)
have recently been increasingly applied to the healthcare domain. Most existing
EHR-oriented studies, however, either focus on a particular modality or
integrate data from different modalities in a straightforward manner, which
usually treats structured and unstructured data as two independent sources of
information about patient admission and ignore the intrinsic interactions
between them. In fact, the two modalities are documented during the same
encounter where structured data inform the documentation of unstructured data
and vice versa. In this paper, we proposed a Medical Multimodal Pre-trained
Language Model, named MedM-PLM, to learn enhanced EHR representations over
structured and unstructured data and explore the interaction of two modalities.
In MedM-PLM, two Transformer-based neural network components are firstly
adopted to learn representative characteristics from each modality. A
cross-modal module is then introduced to model their interactions. We
pre-trained MedM-PLM on the MIMIC-III dataset and verified the effectiveness of
the model on three downstream clinical tasks, i.e., medication recommendation,
30-day readmission prediction and ICD coding. Extensive experiments demonstrate
the power of MedM-PLM compared with state-of-the-art methods. Further analyses
and visualizations show the robustness of our model, which could potentially
provide more comprehensive interpretations for clinical decision-making.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reasoning Like Program Executors. (arXiv:2201.11473v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11473">
<div class="article-summary-box-inner">
<span><p>Reasoning over natural language is a long-standing goal for the research
community. However, studies have shown that existing language models are
inadequate in reasoning. To address the issue, we present POET, a novel
reasoning pre-training paradigm. Through pre-training language models with
programs and their execution results, POET empowers language models to harvest
the reasoning knowledge possessed by program executors via a data-driven
approach. POET is conceptually simple and can be instantiated by different
kinds of program executors. In this paper, we showcase two simple instances
POET-Math and POET-Logic, in addition to a complex instance, POET-SQL.
Experimental results on six benchmarks demonstrate that POET can significantly
boost model performance in natural language reasoning, such as numerical
reasoning, logical reasoning, and multi-hop reasoning. POET opens a new gate on
reasoning-enhancement pre-training, and we hope our analysis would shed light
on the future research of reasoning like program executors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Multi-Granularity Summarization. (arXiv:2201.12502v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12502">
<div class="article-summary-box-inner">
<span><p>Text summarization is a user-preference based task, i.e., for one document,
users often have different priorities for summary. As a key aspect of
customization in summarization, granularity is used to measure the semantic
coverage between the summary and source document. However, developing systems
that can generate summaries with customizable semantic coverage is still an
under-explored topic. In this paper, we propose the first unsupervised
multi-granularity summarization framework, GranuSum. We take events as the
basic semantic units of the source documents and propose to rank these events
by their salience. We also develop a model to summarize input documents with
given events as anchors and hints. By inputting different numbers of events,
GranuSum is capable of producing multi-granular summaries in an unsupervised
manner. Meanwhile, we annotate a new benchmark GranuDUC that contains multiple
summaries at different granularities for each document cluster. Experimental
results confirm the substantial superiority of GranuSum on multi-granularity
summarization over strong baselines. Further, by exploiting the event
information, GranuSum also exhibits state-of-the-art performance under the
conventional unsupervised abstractive setting. Dataset for this paper can be
found at: https://github.com/maszhongming/GranuDUC
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models. (arXiv:2202.04173v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04173">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (LMs) are shown to easily generate toxic
language. In this work, we systematically explore domain-adaptive training to
reduce the toxicity of language models. We conduct this study on three
dimensions: training corpus, model size, and parameter efficiency. For the
training corpus, we propose to leverage the generative power of LMs and
generate nontoxic datasets for domain-adaptive training, which mitigates the
exposure bias and is shown to be more data-efficient than using a curated
pre-training corpus. We demonstrate that the self-generation method
consistently outperforms the existing baselines across various model sizes on
both automatic and human evaluations, even when it uses a 1/3 smaller training
corpus. We then comprehensively study detoxifying LMs with parameter sizes
ranging from 126M up to 530B (3x larger than GPT-3), a scale that has never
been studied before. We find that i) large LMs have similar toxicity levels as
smaller ones given the same pre-training corpus, and ii) large LMs require more
endeavor to detoxify. We also explore parameter-efficient training methods for
detoxification. We demonstrate that adding and training adapter-only layers in
LMs not only saves a lot of parameters but also achieves a better trade-off
between toxicity and perplexity than whole model adaptation for the large-scale
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Locating and Editing Factual Associations in GPT. (arXiv:2202.05262v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.05262">
<div class="article-summary-box-inner">
<span><p>We analyze the storage and recall of factual associations in autoregressive
transformer language models, finding evidence that these associations
correspond to localized, directly-editable computations. We first develop a
causal intervention for identifying neuron activations that are decisive in a
model's factual predictions. This reveals a distinct set of steps in
middle-layer feed-forward modules that mediate factual predictions while
processing subject tokens. To test our hypothesis that these computations
correspond to factual association recall, we modify feed-forward weights to
update specific factual associations using Rank-One Model Editing (ROME). We
find that ROME is effective on a standard zero-shot relation extraction (zsRE)
model-editing task, comparable to existing methods. To perform a more sensitive
evaluation, we also evaluate ROME on a new dataset of counterfactual
assertions, on which it simultaneously maintains both specificity and
generalization, whereas other methods sacrifice one or another. Our results
confirm an important role for mid-layer feed-forward modules in storing factual
associations and suggest that direct manipulation of computational mechanisms
may be a feasible approach for model editing. The code, dataset,
visualizations, and an interactive demo notebook are available at
https://rome.baulab.info/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ZeroGen: Efficient Zero-shot Learning via Dataset Generation. (arXiv:2202.07922v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.07922">
<div class="article-summary-box-inner">
<span><p>There is a growing interest in dataset generation recently due to the
superior generative capacity of large pre-trained language models (PLMs). In
this paper, we study a flexible and efficient zero-short learning method,
\textsc{ZeroGen}. Given a zero-shot task, we first generate a dataset from
scratch using PLMs in an unsupervised manner. Then, we train a tiny task model
(e.g., LSTM) under the supervision of the synthesized dataset. This approach
allows highly efficient inference as the final task model only has orders of
magnitude fewer parameters comparing to PLMs (e.g., GPT2-XL). Apart from being
annotation-free and efficient, we argue that \textsc{ZeroGen} can also provide
useful insights from the perspective of data-free model-agnostic knowledge
distillation, and unreferenced text generation evaluation. Experiments and
analysis on different NLP tasks, namely, text classification, question
answering, and natural language inference, show the effectiveness of
\textsc{ZeroGen}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Parameter-Efficient Tuning: Are We Really There Yet?. (arXiv:2202.07962v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.07962">
<div class="article-summary-box-inner">
<span><p>Parameter-Efficient Tuning (PETuning) methods have been deemed by many as the
new paradigm for using pretrained language models (PLMs). By tuning just a
fraction amount of parameters comparing to full model finetuning, PETuning
methods claim to have achieved performance on par with or even better than
finetuning. In this work, we take a step back and re-examine these PETuning
methods by conducting the first comprehensive investigation into the training
and evaluation of them. We found the problematic validation and testing
practice in current studies, when accompanied by the instability nature of
PETuning methods, has led to unreliable conclusions. When being compared under
a truly fair evaluation protocol, PETuning cannot yield consistently
competitive performance while finetuning remains to be the best-performing
method in medium- and high-resource settings. We delve deeper into the cause of
the instability and observed that the number of trainable parameters and
training iterations are two main factors: reducing trainable parameters and
prolonging training iterations may lead to higher stability in PETuning
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">APEACH: Attacking Pejorative Expressions with Analysis on Crowd-Generated Hate Speech Evaluation Datasets. (arXiv:2202.12459v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.12459">
<div class="article-summary-box-inner">
<span><p>In hate speech detection, developing training and evaluation datasets across
various domains is the critical issue. Whereas, major approaches crawl social
media texts and hire crowd-workers to annotate the data. Following this
convention often restricts the scope of pejorative expressions to a single
domain lacking generalization. Sometimes domain overlap between training corpus
and evaluation set overestimate the prediction performance when pretraining
language models on low-data language. To alleviate these problems in Korean, we
propose APEACH that asks unspecified users to generate hate speech examples
followed by minimal post-labeling. We find that APEACH can collect useful
datasets that are less sensitive to the lexical overlaps between the
pretraining corpus and the evaluation set, thereby properly measuring the model
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Measuring the Mixing of Contextual Information in the Transformer. (arXiv:2203.04212v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.04212">
<div class="article-summary-box-inner">
<span><p>The Transformer architecture aggregates input information through the
self-attention mechanism, but there is no clear understanding of how this
information is mixed across the entire model. Additionally, recent works have
demonstrated that attention weights alone are not enough to describe the flow
of information. In this paper, we consider the whole attention block --
multi-head attention, residual connection, and layer normalization -- and
define a metric to measure token-to-token interactions within each layer. Then,
we aggregate layer-wise interpretations to provide input attribution scores for
model predictions. Experimentally, we show that our method, ALTI (Aggregation
of Layer-wise Token-to-token Interactions), provides more faithful explanations
and increased robustness than gradient-based methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Representation Learning for Resource-Constrained Keyphrase Generation. (arXiv:2203.08118v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08118">
<div class="article-summary-box-inner">
<span><p>State-of-the-art keyphrase generation methods generally depend on large
annotated datasets, limiting their performance in domains with limited
annotated data. To overcome this challenge, we design a data-oriented approach
that first identifies salient information using retrieval-based corpus-level
statistics, and then learns a task-specific intermediate representation based
on a pre-trained language model using large-scale unlabeled documents. We
introduce salient span recovery and salient span prediction as denoising
training objectives that condense the intra-article and inter-article knowledge
essential for keyphrase generation. Through experiments on multiple keyphrase
generation benchmarks, we show the effectiveness of the proposed approach for
facilitating low-resource keyphrase generation and zero-shot domain adaptation.
Our method especially benefits the generation of absent keyphrases, approaching
the performance of models trained with large training sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Iteratively Prompt Pre-trained Language Models for Chain of Thought. (arXiv:2203.08383v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08383">
<div class="article-summary-box-inner">
<span><p>While Pre-trained Language Models (PLMs) internalize a great amount of world
knowledge, they have been shown incapable of recalling these knowledge to solve
tasks requiring complex &amp; multi-step reasoning. Similar to how humans develop a
"chain of thought" for these tasks, how can we equip PLMs with such abilities?
In this work, we explore an iterative prompting framework, a new prompting
paradigm which progressively elicits relevant knowledge from PLMs for
multi-step inference. We identify key limitations of existing prompting
methods, namely they are either restricted to queries with a single
identifiable relation/predicate, or being agnostic to input contexts, which
makes it difficult to capture variabilities across different inference steps.
We propose an iterative context-aware prompter, which addresses these
limitations by learning to dynamically synthesize prompts conditioned on the
current step's contexts. Experiments on three datasets involving multi-step
reasoning show the effectiveness of the iterative scheme and the context-aware
prompter design.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Less is More: Summary of Long Instructions is Better for Program Synthesis. (arXiv:2203.08597v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08597">
<div class="article-summary-box-inner">
<span><p>Despite the success of large pre-trained language models (LMs) such as Codex,
they show below-par performance on the larger and more complicated programming
related questions. We show that LMs benefit from the summarized version of
complicated questions. Our findings show that superfluous information often
present in problem description such as human characters, background stories,
and names (which are included to help humans in understanding a task) does not
help models in understanding a task. To this extent, we create a meta-dataset
from the frequently used APPS dataset and the newly created CodeContests
dataset for the program synthesis task. Our meta-dataset consists of human and
synthesized summaries of the long and complicated programming questions.
Experimental results on Codex show that our proposed approach outperforms
baseline by 8.13% on the APPS dataset and 11.88% on the CodeContests dataset on
average in terms of strict accuracy. Our analysis shows that summaries
significantly improve performance for introductory (9.86%) and interview
(11.48%) programming questions. However, it shows improvement by a small margin
(~ 2%) for competitive programming questions, implying scope for future
research in this direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhanced Temporal Knowledge Embeddings with Contextualized Language Representations. (arXiv:2203.09590v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.09590">
<div class="article-summary-box-inner">
<span><p>World knowledge exists in both structured (tables, knowledge graphs) and
unstructured forms (texts). Recently, there have been extensive research
efforts in the integration of structured factual knowledge and unstructured
textual knowledge. However, most studies focus on incorporating static factual
knowledge into pre-trained language models, while there is less work on
enhancing temporal knowledge graph embedding using textual knowledge. Existing
integration approaches can not apply to temporal knowledge graphs (tKGs) since
they often assume knowledge embedding is time-invariant. In fact, the entity
embedding in tKG embedding models usually evolves over time, which poses the
challenge of aligning temporally relevant textual information with entities. To
this end, we propose Enhanced Temporal Knowledge Embeddings with Contextualized
Language Representations (ECOLA), which uses tKG quadruple as an implicit
measure to temporally align textual data and the time-evolving entity
representations and uses a novel knowledge-text prediction task to inject
textual information into temporal knowledge embedding. ECOLA jointly optimizes
the knowledge-text prediction objective and the temporal knowledge embedding
objective, and thus, can simultaneously take full advantage of textual and
structured knowledge. Since existing datasets do not provide tKGs with aligned
textual data, we introduce three new datasets for training and evaluating
ECOLA. Experimental results on the temporal knowledge graph completion task
show that ECOLA outperforms state-of-the-art tKG embedding models by a large
margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The SAME score: Improved cosine based bias score for word embeddings. (arXiv:2203.14603v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.14603">
<div class="article-summary-box-inner">
<span><p>Over the last years, word and sentence embeddings have established as text
preprocessing for all kinds of NLP tasks and improved performances in these
tasks significantly. Unfortunately, it has also been shown that these
embeddings inherit various kinds of biases from the training data and thereby
pass on biases present in society to NLP solutions. Many papers attempted to
quantify bias in word or sentence embeddings to evaluate debiasing methods or
compare different embedding models, often with cosine-based scores. However,
some works have raised doubts about these scores showing that even though they
report low biases, biases persist and can be shown with other tests. In fact,
there is a great variety of bias scores or tests proposed in the literature
without any consensus on the optimal solutions. We lack works that study the
behavior of bias scores and elaborate their advantages and disadvantages. In
this work, we will explore different cosine-based bias scores. We provide a
bias definition based on the ideas from the literature and derive novel
requirements for bias scores. Furthermore, we thoroughly investigate the
existing cosine-based scores and their limitations in order to show why these
scores fail to report biases in some situations. Finally, we propose a new bias
score, SAME, to address the shortcomings of existing bias scores and show
empirically that SAME is better suited to quantify biases in word embeddings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reproducibility Issues for BERT-based Evaluation Metrics. (arXiv:2204.00004v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.00004">
<div class="article-summary-box-inner">
<span><p>Reproducibility is of utmost concern in machine learning and natural language
processing (NLP). In the field of natural language generation (especially
machine translation), the seminal paper of Post (2018) has pointed out problems
of reproducibility of the dominant metric, BLEU, at the time of publication.
Nowadays, BERT-based evaluation metrics considerably outperform BLEU. In this
paper, we ask whether results and claims from four recent BERT-based metrics
can be reproduced. We find that reproduction of claims and results often fails
because of (i) heavy undocumented preprocessing involved in the metrics, (ii)
missing code and (iii) reporting weaker results for the baseline metrics. (iv)
In one case, the problem stems from correlating not to human scores but to a
wrong column in the csv file, inflating scores by 5 points. Motivated by the
impact of preprocessing, we then conduct a second study where we examine its
effects more closely (for one of the metrics). We find that preprocessing can
have large effects, especially for highly inflectional languages. In this case,
the effect of preprocessing may be larger than the effect of the aggregation
mechanism (e.g., greedy alignment vs. Word Mover Distance).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Tokenisation by Alternative Treatment of Spaces. (arXiv:2204.04058v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.04058">
<div class="article-summary-box-inner">
<span><p>Tokenisation is the first step in almost all NLP tasks, and state-of-the-art
transformer-based language models all use subword tokenisation algorithms to
process input text. Existing algorithms have problems, often producing
tokenisations of limited linguistic validity, and representing equivalent
strings differently depending on their position within a word. We hypothesise
that these problems hinder the ability of transformer-based models to handle
complex words, and suggest that these problems are a result of allowing tokens
to include spaces. We thus experiment with an alternative tokenisation approach
where spaces are always treated as individual tokens. Specifically, we apply
this modification to the BPE and Unigram algorithms. We find that our modified
algorithms lead to improved performance on downstream NLP tasks that involve
handling complex words, whilst having no detrimental effect on performance in
general natural language understanding tasks. Intrinsically, we find our
modified algorithms give more morphologically correct tokenisations, in
particular when handling prefixes. Given the results of our experiments, we
advocate for always treating spaces as individual tokens as an improved
tokenisation method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gaining Insights into Unrecognized User Utterances in Task-Oriented Dialog Systems. (arXiv:2204.05158v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.05158">
<div class="article-summary-box-inner">
<span><p>The rapidly growing market demand for automatic dialogue agents capable of
goal-oriented behavior has caused many tech-industry leaders to invest
considerable efforts into task-oriented dialog systems. The success of these
systems is highly dependent on the accuracy of their intent identification --
the process of deducing the goal or meaning of the user's request and mapping
it to one of the known intents for further processing. Gaining insights into
unrecognized utterances -- user requests the systems fail to attribute to a
known intent -- is therefore a key process in continuous improvement of
goal-oriented dialog systems.
</p>
<p>We present an end-to-end pipeline for processing unrecognized user
utterances, deployed in a real-world, commercial task-oriented dialog system,
including a specifically-tailored clustering algorithm, a novel approach to
cluster representative extraction, and cluster naming. We evaluated the
proposed components, demonstrating their benefits in the analysis of
unrecognized user requests.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Passage Retrieval with Zero-Shot Question Generation. (arXiv:2204.07496v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.07496">
<div class="article-summary-box-inner">
<span><p>We propose a simple and effective re-ranking method for improving passage
retrieval in open question answering. The re-ranker re-scores retrieved
passages with a zero-shot question generation model, which uses a pre-trained
language model to compute the probability of the input question conditioned on
a retrieved passage. This approach can be applied on top of any retrieval
method (e.g. neural or keyword-based), does not require any domain- or
task-specific training (and therefore is expected to generalize better to data
distribution shifts), and provides rich cross-attention between query and
passage (i.e. it must explain every token in the question). When evaluated on a
number of open-domain retrieval datasets, our re-ranker improves strong
unsupervised retrieval models by 6%-18% absolute and strong supervised models
by up to 12% in terms of top-20 passage retrieval accuracy. We also obtain new
state-of-the-art results on full open-domain question answering by simply
adding the new re-ranker to existing models with no further changes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Just Fine-tune Twice: Selective Differential Privacy for Large Language Models. (arXiv:2204.07667v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.07667">
<div class="article-summary-box-inner">
<span><p>Protecting large language models from privacy leakage is becoming
increasingly crucial with their wide adoption in real-world products. Yet
applying differential privacy (DP), a canonical notion with provable privacy
guarantees for machine learning models, to those models remains challenging due
to the trade-off between model utility and privacy loss. Utilizing the fact
that sensitive information in language data tends to be sparse, Shi et al.
(2021) formalized a DP notion extension called Selective Differential Privacy
(SDP) to protect only the sensitive tokens defined by a policy function.
However, their algorithm only works for RNN-based models. In this paper, we
develop a novel framework, Just Fine-tune Twice (JFT), that achieves SDP for
state-of-the-art large transformer-based models. Our method is easy to
implement: it first fine-tunes the model with redacted in-domain data, and then
fine-tunes it again with the original in-domain data using a private training
mechanism. Furthermore, we study the scenario of imperfect implementation of
policy functions that misses sensitive tokens and develop systematic methods to
handle it. Experiments show that our method achieves strong utility compared to
previous baselines. We also analyze the SDP privacy guarantee empirically with
the canary insertion attack.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks. (arXiv:2204.07705v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.07705">
<div class="article-summary-box-inner">
<span><p>How well can NLP models generalize to a variety of unseen tasks when provided
with task instructions? To address this question, we first introduce
Super-NaturalInstructions, a benchmark of 1,616 diverse NLP tasks and their
expert-written instructions. Our collection covers 76 distinct task types,
including but not limited to classification, extraction, infilling, sequence
tagging, text rewriting, and text composition. This large and diverse
collection of tasks enables rigorous benchmarking of cross-task generalization
under instructions -- training models to follow instructions on a subset of
tasks and evaluating them on the remaining unseen ones. Furthermore, we build
Tk-Instruct, a transformer model trained to follow a variety of in-context
instructions (plain language task definitions or k-shot examples). Our
experiments show that Tk-Instruct outperforms existing instruction-following
models such as InstructGPT by over 9% on our benchmark despite being an order
of magnitude smaller. We further analyze generalization as a function of
various scaling parameters, such as the number of observed tasks, the number of
instances per task, and model sizes. We hope our dataset and model facilitate
future progress towards more general-purpose NLP models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ArcaneQA: Dynamic Program Induction and Contextualized Encoding for Knowledge Base Question Answering. (arXiv:2204.08109v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.08109">
<div class="article-summary-box-inner">
<span><p>Question answering on knowledge bases (KBQA) poses a unique challenge for
semantic parsing research due to two intertwined challenges: large search space
and ambiguities in schema linking. Conventional ranking-based KBQA models,
which rely on a candidate enumeration step to reduce the search space, struggle
with flexibility in predicting complicated queries and have impractical running
time. In this paper, we present ArcaneQA, a novel generation-based model that
addresses both the large search space and the schema linking challenges in a
unified framework with two mutually boosting ingredients: dynamic program
induction for tackling the large search space and dynamic contextualized
encoding for schema linking. Experimental results on multiple popular KBQA
datasets demonstrate the highly competitive performance of ArcaneQA in both
effectiveness and efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Position Encoding for Transformers. (arXiv:2204.08142v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.08142">
<div class="article-summary-box-inner">
<span><p>Recurrent models have been dominating the field of neural machine translation
(NMT) for the past few years. Transformers \citep{vaswani2017attention}, have
radically changed it by proposing a novel architecture that relies on a
feed-forward backbone and self-attention mechanism. Although Transformers are
powerful, they could fail to properly encode sequential/positional information
due to their non-recurrent nature. To solve this problem, position embeddings
are defined exclusively for each time step to enrich word information. However,
such embeddings are fixed after training regardless of the task and the word
ordering system of the source or target language.
</p>
<p>In this paper, we propose a novel architecture with new position embeddings
depending on the input text to address this shortcoming by taking the order of
target words into consideration. Instead of using predefined position
embeddings, our solution generates new embeddings to refine each word's
position information. Since we do not dictate the position of source tokens and
learn them in an end-to-end fashion, we refer to our method as dynamic position
encoding (DPE). We evaluated the impact of our model on multiple datasets to
translate from English into German, French, and Italian and observed meaningful
improvements in comparison to the original Transformer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">K-LITE: Learning Transferable Visual Models with External Knowledge. (arXiv:2204.09222v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.09222">
<div class="article-summary-box-inner">
<span><p>The new generation of state-of-the-art computer vision systems are trained
from natural language supervision, ranging from simple object category names to
descriptive captions. This form of supervision ensures high generality and
usability of the learned visual models, due to the broad concept coverage
achieved via large-scale data collection process. Alternatively, we argue that
learning with external knowledge is a promising way which leverages a much more
structured source of supervision and offers sample efficiency. We propose
K-LITE, a simple strategy to leverage external knowledge for building
transferable visual systems: In training, it enriches entities in text with
WordNet and Wiktionary knowledge, leading to an efficient and scalable approach
to learning image representations that uses knowledge about the visual
concepts. In evaluation, the text is also augmented with external knowledge and
then used to reference learned visual concepts (or describe new ones) to enable
zero-shot and few-shot transfer of the pre-trained models. We study the
performance of K-LITE on two important computer vision problems, image
classification and object detection, benchmarking on 20 and 13 different
existing datasets, respectively. The proposed knowledge-augmented models show
significant improvement in transfer learning performance over existing methods.
Our code is available at https://github.com/microsoft/klite.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Hierarchical N-Gram Framework for Zero-Shot Link Prediction. (arXiv:2204.10293v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.10293">
<div class="article-summary-box-inner">
<span><p>Due to the incompleteness of knowledge graphs (KGs), zero-shot link
prediction (ZSLP) which aims to predict unobserved relations in KGs has
attracted recent interest from researchers. A common solution is to use textual
features of relations (e.g., surface name or textual descriptions) as auxiliary
information to bridge the gap between seen and unseen relations. Current
approaches learn an embedding for each word token in the text. These methods
lack robustness as they suffer from the out-of-vocabulary (OOV) problem.
Meanwhile, models built on character n-grams have the capability of generating
expressive representations for OOV words. Thus, in this paper, we propose a
Hierarchical N-Gram framework for Zero-Shot Link Prediction (HNZSLP), which
considers the dependencies among character n-grams of the relation surface name
for ZSLP. Our approach works by first constructing a hierarchical n-gram graph
on the surface name to model the organizational structure of n-grams that leads
to the surface name. A GramTransformer, based on the Transformer is then
presented to model the hierarchical n-gram graph to construct the relation
embedding for ZSLP. Experimental results show the proposed HNZSLP achieved
state-of-the-art performance on two ZSLP datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FaithDial: A Faithful Benchmark for Information-Seeking Dialogue. (arXiv:2204.10757v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.10757">
<div class="article-summary-box-inner">
<span><p>The goal of information-seeking dialogue is to respond to seeker queries with
natural language utterances that are grounded on knowledge sources. However,
dialogue systems often produce unsupported utterances, a phenomenon known as
hallucination. To mitigate this behavior, we adopt a data-centric solution and
create FaithDial, a new benchmark for hallucination-free dialogues, by editing
hallucinated responses in the Wizard of Wikipedia (WoW) benchmark. We observe
that FaithDial is more faithful than WoW while also maintaining engaging
conversations. We show that FaithDial can serve as training signal for: i) a
hallucination critic, which discriminates whether an utterance is faithful or
not, and boosts the performance by 12.8 F1 score on the BEGIN benchmark
compared to existing datasets for dialogue coherence; ii) high-quality dialogue
generation. We benchmark a series of state-of-the-art models and propose an
auxiliary contrastive objective that achieves the highest level of faithfulness
and abstractiveness based on several automated metrics. Further, we find that
the benefits of FaithDial generalize to zero-shot transfer on other datasets,
such as CMU-Dog and TopicalChat. Finally, human evaluation reveals that
responses generated by models trained on FaithDial are perceived as more
interpretable, cooperative, and engaging.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Teachable Reasoning Systems: Using a Dynamic Memory of User Feedback for Continual System Improvement. (arXiv:2204.13074v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.13074">
<div class="article-summary-box-inner">
<span><p>Our goal is a teachable reasoning system for question-answering (QA), where a
user can interact with faithful answer explanations, and correct its errors so
that the system improves over time. Our approach is to augment a QA model with
a dynamic memory of user feedback, containing user-supplied corrections to
erroneous model beliefs that users identify during interaction. Retrievals from
memory are used as additional context for QA, to help avoid previous mistakes
in similar new situations - a novel application of memory-based continuous
learning. With simulated feedback, we find that our system (called TeachMe)
continually improves with time, and without model retraining, requiring
feedback on only 25% of training examples to reach within 1% of the upper-bound
(feedback on all examples). Similarly, in experiments with real users, we
observe a similar trend, with performance improving by over 15% on a hidden
test set after teaching. This suggests new opportunities for using frozen
language models in an interactive setting where users can inspect, debug, and
correct the model's beliefs, leading to improved system's performance over
time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Backdoor Attacks in Federated Learning by Rare Embeddings and Gradient Ensembling. (arXiv:2204.14017v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.14017">
<div class="article-summary-box-inner">
<span><p>Recent advances in federated learning have demonstrated its promising
capability to learn on decentralized datasets. However, a considerable amount
of work has raised concerns due to the potential risks of adversaries
participating in the framework to poison the global model for an adversarial
purpose. This paper investigates the feasibility of model poisoning for
backdoor attacks through rare word embeddings of NLP models. In text
classification, less than 1% of adversary clients suffices to manipulate the
model output without any drop in the performance on clean sentences. For a less
complex dataset, a mere 0.1% of adversary clients is enough to poison the
global model effectively. We also propose a technique specialized in the
federated learning scheme called Gradient Ensemble, which enhances the backdoor
performance in all our experimental settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Not to Overfit or Underfit the Source Domains? An Empirical Study of Domain Generalization in Question Answering. (arXiv:2205.07257v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.07257">
<div class="article-summary-box-inner">
<span><p>Machine learning models are prone to overfitting their training (source)
domains, which is commonly believed to be the reason why they falter in novel
target domains. Here we examine the contrasting view that multi-source domain
generalization (DG) is first and foremost a problem of mitigating source domain
underfitting: models not adequately learning the signal already present in
their multi-domain training data. Experiments on a reading comprehension DG
benchmark show that as a model learns its source domains better -- using
familiar methods such as knowledge distillation (KD) from a bigger model -- its
zero-shot out-of-domain utility improves at an even faster pace. Improved
source domain learning also demonstrates superior out-of-domain generalization
over three popular existing DG approaches that aim to limit overfitting. Our
implementation of KD-based domain generalization is available via PrimeQA at:
https://ibm.biz/domain-generalization-with-kd.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CQR-SQL: Conversational Question Reformulation Enhanced Context-Dependent Text-to-SQL Parsers. (arXiv:2205.07686v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.07686">
<div class="article-summary-box-inner">
<span><p>Context-dependent text-to-SQL is the task of translating multi-turn questions
into database-related SQL queries. Existing methods typically focus on making
full use of history context or previously predicted SQL for currently SQL
parsing, while neglecting to explicitly comprehend the schema and
conversational dependency, such as co-reference, ellipsis and user focus
change. In this paper, we propose CQR-SQL, which uses auxiliary Conversational
Question Reformulation (CQR) learning to explicitly exploit schema and decouple
contextual dependency for SQL parsing. Specifically, we first present a schema
enhanced recursive CQR method to produce domain-relevant self-contained
questions. Secondly, we train CQR-SQL models to map the semantics of multi-turn
questions and auxiliary self-contained questions into the same latent space
through schema grounding consistency task and tree-structured SQL parsing
consistency task, which enhances the abilities of SQL parsing by adequately
contextual understanding. At the time of writing, our CQR-SQL achieves new
state-of-the-art results on two context-dependent text-to-SQL benchmarks SParC
and CoSQL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LogicSolver: Towards Interpretable Math Word Problem Solving with Logical Prompt-enhanced Learning. (arXiv:2205.08232v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08232">
<div class="article-summary-box-inner">
<span><p>Recently, deep learning models have made great progress in MWP solving on
answer accuracy. However, they are uninterpretable since they mainly rely on
shallow heuristics to achieve high performance without understanding and
reasoning the grounded math logic. To address this issue and make a step
towards interpretable MWP solving, we first construct a high-quality MWP
dataset named InterMWP which consists of 11,495 MWPs and annotates
interpretable logical formulas based on algebraic knowledge as the grounded
linguistic logic of each solution equation. Different from existing MWP
datasets, our InterMWP benchmark asks for a solver to not only output the
solution expressions but also predict the corresponding logical formulas. We
further propose a novel approach with logical prompt and interpretation
generation, called LogicSolver. For each MWP, our LogicSolver first retrieves
some highly-correlated algebraic knowledge and then passes them to the backbone
model as prompts to improve the semantic representations of MWPs. With these
improved semantic representations, our LogicSolver generates corresponding
solution expressions and interpretable knowledge formulas in accord with the
generated solution expressions, simultaneously. Experimental results show that
our LogicSolver has stronger logical formula-based interpretability than
baselines while achieving higher answer accuracy with the help of logical
prompts, simultaneously. The source code and dataset is available at
https://github.com/yangzhch6/InterMWP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Acceptability Judgements via Examining the Topology of Attention Maps. (arXiv:2205.09630v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09630">
<div class="article-summary-box-inner">
<span><p>The role of the attention mechanism in encoding linguistic knowledge has
received special interest in NLP. However, the ability of the attention heads
to judge the grammatical acceptability of a sentence has been underexplored.
This paper approaches the paradigm of acceptability judgments with topological
data analysis (TDA), showing that the geometric properties of the attention
graph can be efficiently exploited for two standard practices in linguistics:
binary judgments and linguistic minimal pairs. Topological features enhance the
BERT-based acceptability classifier scores by $8$%-$24$% on CoLA in three
languages (English, Italian, and Swedish). By revealing the topological
discrepancy between attention maps of minimal pairs, we achieve the human-level
performance on the BLiMP benchmark, outperforming nine statistical and
Transformer LM baselines. At the same time, TDA provides the foundation for
analyzing the linguistic functions of attention heads and interpreting the
correspondence between the graph features and grammatical phenomena.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Commonsense Knowledge Salience Evaluation with a Benchmark Dataset in E-commerce. (arXiv:2205.10843v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10843">
<div class="article-summary-box-inner">
<span><p>In e-commerce, the salience of commonsense knowledge (CSK) is beneficial for
widespread applications such as product search and recommendation. For example,
when users search for ``running'' in e-commerce, they would like to find
products highly related to running, such as ``running shoes'' rather than
``shoes''. Nevertheless, many existing CSK collections rank statements solely
by confidence scores, and there is no information about which ones are salient
from a human perspective. In this work, we define the task of supervised
salience evaluation, where given a CSK triple, the model is required to learn
whether the triple is salient or not. In addition to formulating the new task,
we also release a new Benchmark dataset of Salience Evaluation in E-commerce
(BSEE) and hope to promote related research on commonsense knowledge salience
evaluation. We conduct experiments in the dataset with several representative
baseline models. The experimental results show that salience evaluation is a
challenging task where models perform poorly on our evaluation set. We further
propose a simple but effective approach, PMI-tuning, which shows promise for
solving this novel problem. Code is available in
\url{https://github.com/OpenBGBenchmark/OpenBG-CSK.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Geometry of Multilingual Language Model Representations. (arXiv:2205.10964v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10964">
<div class="article-summary-box-inner">
<span><p>We assess how multilingual language models maintain a shared multilingual
representation space while still encoding language-sensitive information in
each language. Using XLM-R as a case study, we show that languages occupy
similar linear subspaces after mean-centering, evaluated based on causal
effects on language modeling performance and direct comparisons between
subspaces for 88 languages. The subspace means differ along language-sensitive
axes that are relatively stable throughout middle layers, and these axes encode
information such as token vocabularies. Shifting representations by language
means is sufficient to induce token predictions in different languages.
However, we also identify stable language-neutral axes that encode information
such as token positions and part-of-speech. We visualize representations
projected onto language-sensitive and language-neutral axes, identifying
language family and part-of-speech clusters, along with spirals, toruses, and
curves representing token position information. These results demonstrate that
multilingual language models encode information along orthogonal
language-sensitive and language-neutral axes, allowing the models to extract a
variety of features for downstream tasks and cross-lingual transfer learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding. (arXiv:2205.11024v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11024">
<div class="article-summary-box-inner">
<span><p>Prompt Tuning has been largely successful as a parameter-efficient method of
conditioning large-scale pre-trained language models to perform downstream
tasks. Thus far, soft prompt tuning learns a fixed set of task-specific
continuous vectors, i.e., soft tokens that remain static across the task
samples. A fixed prompt, however, may not generalize well to the diverse kinds
of inputs the task comprises. In order to address this, we propose
Vector-quantized Input-contextualized Prompts (VIP) as an extension to the soft
prompt tuning framework. VIP particularly focuses on two aspects -- contextual
prompts that learns input-specific contextualization of the soft prompt tokens
through a small-scale sentence encoder and quantized prompts that maps the
contextualized prompts to a set of learnable codebook vectors through a Vector
quantization network. On various language understanding tasks like SuperGLUE,
QA, Relation classification, NER and NLI, VIP outperforms the soft prompt
tuning (PT) baseline by an average margin of 1.19%. Further, our generalization
studies show that VIP learns more robust prompt representations, surpassing PT
by a margin of 0.6% - 5.3% on Out-of-domain QA and NLI tasks respectively, and
by 0.75% on Multi-Task setup over 4 tasks spanning across 12 domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When does Parameter-Efficient Transfer Learning Work for Machine Translation?. (arXiv:2205.11277v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11277">
<div class="article-summary-box-inner">
<span><p>Parameter-efficient fine-tuning methods (PEFTs) offer the promise of adapting
large pre-trained models while only tuning a small number of parameters. They
have been shown to be competitive with full model fine-tuning for many
downstream tasks. However, prior work indicates that PEFTs may not work as well
for machine translation (MT), and there is no comprehensive study showing when
PEFTs work for MT. We conduct a comprehensive empirical study of PEFTs for MT,
considering (1) various parameter budgets, (2) a diverse set of language-pairs,
and (3) different pre-trained models. We find that 'adapters', in which small
feed-forward networks are added after every layer, are indeed on par with full
model fine-tuning when the parameter budget corresponds to 10% of total model
parameters. Nevertheless, as the number of tuned parameters decreases, the
performance of PEFTs decreases. The magnitude of this decrease depends on the
language pair, with PEFTs particularly struggling for distantly related
language-pairs. We find that using PEFTs with a larger pre-trained model
outperforms full fine-tuning with a smaller model, and for smaller training
data sizes, PEFTs outperform full fine-tuning for the same pre-trained model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Outliers Dimensions that Disrupt Transformers Are Driven by Frequency. (arXiv:2205.11380v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11380">
<div class="article-summary-box-inner">
<span><p>While Transformer-based language models are generally very robust to pruning,
there is the recently discovered outlier phenomenon: disabling only 48 out of
110M parameters in BERT-base drops its performance by nearly 30% on MNLI. We
replicate the original evidence for the outlier phenomenon and we link it to
the geometry of the embedding space. We find that in both BERT and RoBERTa the
magnitude of hidden state coefficients corresponding to outlier dimensions
correlates with the frequency of encoded tokens in pre-training data, and it
also contributes to the "vertical" self-attention pattern enabling the model to
focus on the special tokens. This explains the drop in performance from
disabling the outliers, and it suggests that to decrease anisotropicity in
future models we need pre-training schemas that would better take into account
the skewed token distributions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Importance of Being Parameters: An Intra-Distillation Method for Serious Gains. (arXiv:2205.11416v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11416">
<div class="article-summary-box-inner">
<span><p>Recent model pruning methods have demonstrated the ability to remove
redundant parameters without sacrificing model performance. Common methods
remove redundant parameters according to the parameter sensitivity, a
gradient-based measure reflecting the contribution of the parameters. In this
paper, however, we argue that redundant parameters can be trained to make
beneficial contributions. We first highlight the large sensitivity
(contribution) gap among high-sensitivity and low-sensitivity parameters and
show that the model generalization performance can be significantly improved
after balancing the contribution of all parameters. Our goal is to balance the
sensitivity of all parameters and encourage all of them to contribute equally.
We propose a general task-agnostic method, namely intra-distillation, appended
to the regular training loss to balance parameter sensitivity. Moreover, we
also design a novel adaptive learning method to control the strength of
intra-distillation loss for faster convergence. Our experiments show the strong
effectiveness of our methods on machine translation, natural language
understanding, and zero-shot cross-lingual transfer across up to 48 languages,
e.g., a gain of 3.54 BLEU on average across 8 language pairs from the IWSLT'14
translation dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Advances in Text Generation from Images Beyond Captioning: A Case Study in Self-Rationalization. (arXiv:2205.11686v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11686">
<div class="article-summary-box-inner">
<span><p>Combining the visual modality with pretrained language models has been
surprisingly effective for simple descriptive tasks such as image captioning.
More general text generation however remains elusive. We take a step back and
ask: How do these models work for more complex generative tasks, i.e.
conditioning on both text and images? Are multimodal models simply visually
adapted language models, or do they combine they reason jointly over
modalities?
</p>
<p>We investigate these questions in the context of self-rationalization
(jointly generating task labels/answers and free-text explanations) of three
tasks: (i) visual question answering in VQA-X, (ii) visual commonsense
reasoning in VCR, and (iii) visual-textual entailment in e-SNLI-VE. We show
that recent unimodal advances, CLIP image representations and scaling of
language models, do not consistently improve self-rationalization in multimodal
tasks. We find that no single model type works universally best across tasks,
datasets, and finetuning data sizes. Our findings motivate the need for novel
general backbones approach that move text generation from images and text
beyond image captioning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analyzing the Mono- and Cross-Lingual Pretraining Dynamics of Multilingual Language Models. (arXiv:2205.11758v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11758">
<div class="article-summary-box-inner">
<span><p>The emergent cross-lingual transfer seen in multilingual pretrained models
has sparked significant interest in studying their behavior. However, because
these analyses have focused on fully trained multilingual models, little is
known about the dynamics of the multilingual pretraining process. We
investigate when these models acquire their in-language and cross-lingual
abilities by probing checkpoints taken from throughout XLM-R pretraining, using
a suite of linguistic tasks. Our analysis shows that the model achieves high
in-language performance early on, with lower-level linguistic skills acquired
before more complex ones. In contrast, the point in pretraining when the model
learns to transfer cross-lingually differs across language pairs.
Interestingly, we also observe that, across many languages and tasks, the final
model layer exhibits significant performance degradation over time, while
linguistic knowledge propagates to lower layers of the network. Taken together,
these insights highlight the complexity of multilingual pretraining and the
resulting varied behavior for different languages over time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">D4: a Chinese Dialogue Dataset for Depression-Diagnosis-Oriented Chat. (arXiv:2205.11764v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11764">
<div class="article-summary-box-inner">
<span><p>In a depression-diagnosis-directed clinical session, doctors initiate a
conversation with ample emotional support that guides the patients to expose
their symptoms based on clinical diagnosis criteria. Such a dialogue system is
distinguished from existing single-purpose human-machine dialog systems, as it
combines task-oriented and chit-chats with uniqueness in dialogue topics and
procedures. However, due to the social stigma associated with mental illness,
the dialogue data related to depression consultation and diagnosis are rarely
disclosed. Based on clinical depression diagnostic criteria ICD-11 and DSM-5,
we designed a 3-phase procedure to construct D$^4$: a Chinese Dialogue Dataset
for Depression-Diagnosis-Oriented Chat, which simulates the dialogue between
doctors and patients during the diagnosis of depression, including diagnosis
results and symptom summary given by professional psychiatrists for each
conversation. Upon the newly-constructed dataset, four tasks mirroring the
depression diagnosis process are established: response generation, topic
prediction, dialog summary, and severity classification of depressive episode
and suicide risk. Multi-scale evaluation results demonstrate that a more
empathy-driven and diagnostic-accurate consultation dialogue system trained on
our dataset can be achieved compared to rule-based bots.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hyper-X: A Unified Hypernetwork for Multi-Task Multilingual Transfer. (arXiv:2205.12148v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12148">
<div class="article-summary-box-inner">
<span><p>Massively multilingual models are promising for transfer learning across
tasks and languages. However, existing methods are unable to fully leverage
training data when it is available in different task-language combinations. To
exploit such heterogeneous supervision, we propose Hyper-X, a single
hypernetwork that unifies multi-task and multilingual learning with efficient
adaptation. This model generates weights for adapter modules conditioned on
both tasks and language embeddings. By learning to combine task and
language-specific knowledge, our model enables zero-shot transfer for unseen
languages and task-language combinations. Our experiments on a diverse set of
languages demonstrate that Hyper-X achieves the best or competitive gain when a
mixture of multiple resources is available, while being on par with strong
baselines in the standard scenario. Hyper-X is also considerably more efficient
in terms of parameters and resources compared to methods that train separate
adapters. Finally, Hyper-X consistently produces strong results in few-shot
scenarios for new languages, showing the versatility of our approach beyond
zero-shot transfer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Natural Language Proofs with Verifier-Guided Search. (arXiv:2205.12443v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12443">
<div class="article-summary-box-inner">
<span><p>Reasoning over natural language is a challenging problem in NLP. In this
work, we focus on proof generation: Given a hypothesis and a set of supporting
facts, the model generates a proof tree indicating how to derive the hypothesis
from supporting facts. Compared to generating the entire proof in one shot,
stepwise generation can better exploit the compositionality and generalize to
longer proofs but has achieved limited success on real-world data. Existing
stepwise methods struggle to generate proof steps that are both logically valid
and relevant to the hypothesis. Instead, they tend to hallucinate invalid steps
given the hypothesis. In this paper, we present a novel stepwise method,
NLProofS (Natural Language Proof Search), which learns to generate relevant
steps conditioning on the hypothesis. At the core of our approach, we train an
independent verifier to check the validity of the proof steps to prevent
hallucination. Instead of generating steps greedily, we search for proofs
maximizing a global proof score judged by the verifier. NLProofS achieves
state-of-the-art performance on EntailmentBank and RuleTaker. Specifically, it
improves the correctness of predicted proofs from 27.7% to 33.3% in the
distractor setting of EntailmentBank, demonstrating the effectiveness of
NLProofS in generating challenging human-authored proofs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conditional set generation using Seq2seq models. (arXiv:2205.12485v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12485">
<div class="article-summary-box-inner">
<span><p>Conditional set generation learns a mapping from an input sequence of tokens
to a set. Several NLP tasks, such as entity typing and dialogue emotion
tagging, are instances of set generation. Seq2Seq models, a popular choice for
set generation, treat a set as a sequence and do not fully leverage its key
properties, namely order-invariance and cardinality. We propose a novel
algorithm for effectively sampling informative orders over the combinatorial
space of label orders. We jointly model the set cardinality and output by
prepending the set size and taking advantage of the autoregressive
factorization used by Seq2Seq models. Our method is a model-independent data
augmentation approach that endows any Seq2Seq model with the signals of
order-invariance and cardinality. Training a Seq2Seq model on this augmented
data (without any additional annotations) gets an average relative improvement
of 20% on four benchmark datasets across various models: BART, T5, and GPT-3.
Code to use SETAUG available at: https://setgen.structgen.com.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Re-Examining Calibration: The Case of Question Answering. (arXiv:2205.12507v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12507">
<div class="article-summary-box-inner">
<span><p>For users to trust model predictions, they need to understand model outputs,
particularly their confidence - calibration aims to adjust (calibrate) models'
confidence to match expected accuracy. We argue that the traditional
calibration evaluation does not promote effective calibrations: for example, it
can encourage always assigning a mediocre confidence score to all predictions,
which does not help users distinguish correct predictions from wrong ones.
Building on those observations, we propose a new calibration metric, MacroCE,
that better captures whether the model assigns low confidence to wrong
predictions and high confidence to correct predictions. Focusing on the
practical application of open-domain question answering, we examine
conventional calibration methods applied on the widely-used retriever-reader
pipeline, all of which do not bring significant gains under our new MacroCE
metric. Toward better calibration, we propose a new calibration method
(ConsCal) that uses not just final model predictions but whether multiple model
checkpoints make consistent predictions. Altogether, we provide an alternative
view of calibration along with a new metric, re-evaluation of existing
calibration methods on our metric, and proposal of a more effective calibration
method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning. (arXiv:2205.12548v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12548">
<div class="article-summary-box-inner">
<span><p>Prompting has shown impressive success in enabling large pretrained language
models (LMs) to perform diverse NLP tasks, especially when only few downstream
data are available. Automatically finding the optimal prompt for each task,
however, is challenging. Most existing work resorts to tuning soft prompt
(e.g., embeddings) which falls short of interpretability, reusability across
LMs, and applicability when gradients are not accessible. Discrete prompt, on
the other hand, is difficult to optimize, and is often created by "enumeration
(e.g., paraphrasing)-then-selection" heuristics that do not explore the prompt
space systematically. This paper proposes RLPrompt, an efficient discrete
prompt optimization approach with reinforcement learning (RL). RLPrompt
formulates a parameter-efficient policy network that generates the desired
discrete prompt after training with reward. To overcome the complexity and
stochasticity of reward signals by the large LM environment, we incorporate
effective reward stabilization that substantially enhances the training
efficiency. RLPrompt is flexibly applicable to different types of LMs, such as
masked (e.g., BERT) and left-to-right models (e.g., GPTs), for both
classification and generation tasks. Experiments on few-shot classification and
unsupervised text style transfer show superior performance over a wide range of
existing finetuning or prompting methods. Interestingly, the resulting
optimized prompts are often ungrammatical gibberish text; and surprisingly,
those gibberish prompts are transferrable between different LMs to retain
significant performance, indicating LM prompting may not follow human language
patterns.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Information-Seeking Conversations from Unlabeled Documents. (arXiv:2205.12609v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12609">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce a novel framework, SIMSEEK, (Simulating
information-Seeking conversation from unlabeled documents), and compare its two
variants. In our baseline SIMSEEK-SYM, a questioner generates follow-up
questions upon the predetermined answer by an answerer. On the contrary,
SIMSEEK-ASYM first generates the question and then finds its corresponding
answer under the conversational context. Our experiments show that they can
synthesize effective training resources for CQA and conversational search
tasks. As a result, conversations from SIMSEEK-ASYM not only make more
improvements in our experiments but also are favorably reviewed in a human
evaluation. We finally release a large-scale resource of synthetic
conversations, WIKI-SIMSEEK, containing 2 million CQA pairs built upon
Wikipedia documents. With the dataset, our CQA model achieves state-of-the-art
performance on a recent CQA benchmark, QuAC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Overcoming Catastrophic Forgetting in Zero-Shot Cross-Lingual Generation. (arXiv:2205.12647v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12647">
<div class="article-summary-box-inner">
<span><p>In this paper, we explore the challenging problem of performing a generative
task in a target language when labeled data is only available in English, using
summarization as a case study. We assume a strict setting with no access to
parallel data or machine translation and find that common transfer learning
approaches struggle in this setting, as a generative multilingual model
fine-tuned purely on English catastrophically forgets how to generate
non-English. Given the recent rise of parameter-efficient adaptation
techniques, we conduct the first investigation into how one such method, prompt
tuning (Lester et al., 2021), can overcome catastrophic forgetting to enable
zero-shot cross-lingual generation. Our experiments show that
parameter-efficient prompt tuning provides gains over standard fine-tuning when
transferring between less-related languages, e.g., from English to Thai.
However, a significant gap still remains between these methods and
fully-supervised baselines. To improve cross-lingual transfer further, we
explore several approaches, including: (1) mixing in unlabeled multilingual
data, and (2) explicitly factoring prompts into recombinable language and task
components. Our approaches can provide further quality gains, suggesting that
robust zero-shot cross-lingual generation is within reach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations. (arXiv:2205.12685v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12685">
<div class="article-summary-box-inner">
<span><p>Despite recent explosion of interests in in-context learning, the underlying
mechanism and the precise impact of the quality of demonstrations remain
elusive. Intuitively, ground-truth labels should have as much impact in
in-context learning (ICL) as supervised learning, but recent work reported that
the input-label correspondence is significantly less important than previously
thought. Intrigued by this counter-intuitive observation, we re-examine the
importance of ground-truth labels in in-context learning. With the introduction
of two novel metrics, namely Label-Correctness Sensitivity and Ground-truth
Label Effect Ratio (GLER), we were able to conduct quantifiable analysis on the
impact of ground-truth label demonstrations. Through extensive analyses, we
find that the correct input-label mappings can have varying impacts on the
downstream in-context learning performances, depending on the experimental
configuration. Through additional studies, we identify key components, such as
the verbosity of prompt templates and the language model size, as the
controlling factor to achieve more noise-resilient ICL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Train Flat, Then Compress: Sharpness-Aware Minimization Learns More Compressible Models. (arXiv:2205.12694v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12694">
<div class="article-summary-box-inner">
<span><p>Model compression by way of parameter pruning, quantization, or distillation
has recently gained popularity as an approach for reducing the computational
requirements of modern deep neural network models for NLP. Inspired by prior
works suggesting a connection between simpler, more generalizable models and
those that lie within wider loss basins, we hypothesize that optimizing for
flat minima should lead to simpler parameterizations and thus more compressible
models. We propose to combine sharpness-aware minimization (SAM) with various
task-specific model compression methods, including iterative magnitude pruning
(IMP), structured pruning with a distillation objective, and post-training
dynamic quantization. Empirically, we show that optimizing for flatter minima
consistently leads to greater compressibility of parameters compared to vanilla
Adam when fine-tuning BERT models, with little to no loss in accuracy on the
GLUE text classification and SQuAD question answering benchmarks. Moreover, SAM
finds superior winning tickets during IMP that 1) are amenable to vanilla Adam
optimization, and 2) transfer more effectively across tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Factuality Enhanced Language Models for Open-Ended Text Generation. (arXiv:2206.04624v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.04624">
<div class="article-summary-box-inner">
<span><p>Pretrained language models (LMs) are susceptible to generate text with
nonfactual information. In this work, we measure and improve the factual
accuracy of large-scale LMs for open-ended text generation. We design the
FactualityPrompts test set and metrics to measure the factuality of LM
generations. Based on that, we study the factual accuracy of LMs with parameter
sizes ranging from 126M to 530B. Interestingly, we find that larger LMs are
more factual than smaller ones, although a previous study suggests that larger
LMs can be less truthful in terms of misconceptions. In addition, popular
sampling algorithms (e.g., top-p) in open-ended text generation can harm the
factuality due to the ''uniform randomness'' introduced at every sampling step.
We propose the factual-nucleus sampling algorithm that dynamically adapts the
randomness to improve the factuality of generation while maintaining quality.
Furthermore, we analyze the inefficiencies of the standard training method in
learning correct associations between entities from factual text corpus (e.g.,
Wikipedia). We propose a factuality-enhanced training method that uses
TopicPrefix for better awareness of facts and sentence completion as the
training objective, which can vastly reduce the factual errors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exact Prosody Cloning in Zero-Shot Multispeaker Text-to-Speech. (arXiv:2206.12229v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12229">
<div class="article-summary-box-inner">
<span><p>The cloning of a speaker's voice using an untranscribed reference sample is
one of the great advances of modern neural text-to-speech (TTS) methods.
Approaches for mimicking the prosody of a transcribed reference audio have also
been proposed recently. In this work, we bring these two tasks together for the
first time through utterance level normalization in conjunction with an
utterance level speaker embedding. We further introduce a lightweight aligner
for extracting fine-grained prosodic features, that can be finetuned on
individual samples within seconds. We show that it is possible to clone the
voice of a speaker as well as the prosody of a spoken reference independently
without any degradation in quality and high similarity to both original voice
and prosody, as our objective evaluation and human study show. All of our code
and trained models are available, alongside static and interactive demos.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DailyTalk: Spoken Dialogue Dataset for Conversational Text-to-Speech. (arXiv:2207.01063v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.01063">
<div class="article-summary-box-inner">
<span><p>The majority of current Text-to-Speech (TTS) datasets, which are collections
of individual utterances, contain few conversational aspects. In this paper, we
introduce DailyTalk, a high-quality conversational speech dataset designed for
conversational TTS. We sampled, modified, and recorded 2,541 dialogues from the
open-domain dialogue dataset DailyDialog inheriting its annotated attributes.
On top of our dataset, we extend prior work as our baseline, where a
non-autoregressive TTS is conditioned on historical information in a dialogue.
From the baseline experiment with both general and our novel metrics, we show
that DailyTalk can be used as a general TTS dataset, and more than that, our
baseline can represent contextual information from DailyTalk. The DailyTalk
dataset and baseline code are freely available for academic use with CC-BY-SA
4.0 license.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Where's the Learning in Representation Learning for Compositional Semantics and the Case of Thematic Fit. (arXiv:2208.04749v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.04749">
<div class="article-summary-box-inner">
<span><p>Observing that for certain NLP tasks, such as semantic role prediction or
thematic fit estimation, random embeddings perform as well as pretrained
embeddings, we explore what settings allow for this and examine where most of
the learning is encoded: the word embeddings, the semantic role embeddings, or
``the network''. We find nuanced answers, depending on the task and its
relation to the training objective. We examine these representation learning
aspects in multi-task learning, where role prediction and role-filling are
supervised tasks, while several thematic fit tasks are outside the models'
direct supervision. We observe a non-monotonous relation between some tasks'
quality score and the training data size. In order to better understand this
observation, we analyze these results using easier, per-verb versions of these
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SPOT: Knowledge-Enhanced Language Representations for Information Extraction. (arXiv:2208.09625v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.09625">
<div class="article-summary-box-inner">
<span><p>Knowledge-enhanced pre-trained models for language representation have been
shown to be more effective in knowledge base construction tasks (i.e.,~relation
extraction) than language models such as BERT. These knowledge-enhanced
language models incorporate knowledge into pre-training to generate
representations of entities or relationships. However, existing methods
typically represent each entity with a separate embedding. As a result, these
methods struggle to represent out-of-vocabulary entities and a large amount of
parameters, on top of their underlying token models (i.e.,~the transformer),
must be used and the number of entities that can be handled is limited in
practice due to memory constraints. Moreover, existing models still struggle to
represent entities and relationships simultaneously. To address these problems,
we propose a new pre-trained model that learns representations of both entities
and relationships from token spans and span pairs in the text respectively. By
encoding spans efficiently with span modules, our model can represent both
entities and their relationships but requires fewer parameters than existing
models. We pre-trained our model with the knowledge graph extracted from
Wikipedia and test it on a broad range of supervised and unsupervised
information extraction tasks. Results show that our model learns better
representations for both entities and relationships than baselines, while in
supervised settings, fine-tuning our model outperforms RoBERTa consistently and
achieves competitive results on information extraction tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continuous QA Learning with Structured Prompts. (arXiv:2208.14602v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.14602">
<div class="article-summary-box-inner">
<span><p>QA models with lifelong learning (LL) abilities are important for practical
QA applications, and architecture-based LL methods are reported to be an
effective implementation for these models. However, it is non-trivial to extend
previous approaches to QA tasks since they either require access to task
identities in the testing phase or do not explicitly model samples from unseen
tasks. In this paper, we propose Diana: a dynamic architecture-based lifelong
QA model that tries to learn a sequence of QA tasks with a prompt enhanced
language model. Four types of hierarchically organized prompts are used in
Diana to capture QA knowledge from different granularities. Specifically, we
dedicate task-level prompts to capture task-specific knowledge to retain high
LL performances and maintain instance-level prompts to learn knowledge shared
across different input samples to improve the model's generalization
performance. Moreover, we dedicate separate prompts to explicitly model unseen
tasks and introduce a set of prompt key vectors to facilitate knowledge sharing
between tasks. Extensive experiments demonstrate that Diana outperforms
state-of-the-art lifelong QA models, especially in handling unseen tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transfer Learning of Lexical Semantic Families for Argumentative Discourse Units Identification. (arXiv:2209.02495v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.02495">
<div class="article-summary-box-inner">
<span><p>Argument mining tasks require an informed range of low to high complexity
linguistic phenomena and commonsense knowledge. Previous work has shown that
pre-trained language models are highly effective at encoding syntactic and
semantic linguistic phenomena when applied with transfer learning techniques
and built on different pre-training objectives. It remains an issue of how much
the existing pre-trained language models encompass the complexity of argument
mining tasks. We rely on experimentation to shed light on how language models
obtained from different lexical semantic families leverage the performance of
the identification of argumentative discourse units task. Experimental results
show that transfer learning techniques are beneficial to the task and that
current methods may be insufficient to leverage commonsense knowledge from
different lexical semantic families.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Base Question Answering: A Semantic Parsing Perspective. (arXiv:2209.04994v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.04994">
<div class="article-summary-box-inner">
<span><p>Recent advances in deep learning have greatly propelled the research on
semantic parsing. Improvement has since been made in many downstream tasks,
including natural language interface to web APIs, text-to-SQL generation, among
others. However, despite the close connection shared with these tasks, research
on question answering over knowledge bases (KBQA) has comparatively been
progressing slowly. We identify and attribute this to two unique challenges of
KBQA, schema-level complexity and fact-level complexity. In this survey, we
situate KBQA in the broader literature of semantic parsing and give a
comprehensive account of how existing KBQA approaches attempt to address the
unique challenges. Regardless of the unique challenges, we argue that we can
still take much inspiration from the literature of semantic parsing, which has
been overlooked by existing research on KBQA. Based on our discussion, we can
better understand the bottleneck of current KBQA research and shed light on
promising directions for KBQA to keep up with the literature of semantic
parsing, particularly in the era of pre-trained language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">U3E: Unsupervised and Erasure-based Evidence Extraction for Machine Reading Comprehension. (arXiv:2210.02621v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.02621">
<div class="article-summary-box-inner">
<span><p>More tasks in Machine Reading Comprehension(MRC) require, in addition to
answer prediction, the extraction of evidence sentences that support the
answer. However, the annotation of supporting evidence sentences is usually
time-consuming and labor-intensive. In this paper, to address this issue and
considering that most of the existing extraction methods are semi-supervised,
we propose an unsupervised evidence extraction method (U3E). U3E takes the
changes after sentence-level feature erasure in the document as input,
simulating the decline in problem-solving ability caused by human memory
decline. In order to make selections on the basis of fully understanding the
semantics of the original text, we also propose metrics to quickly select the
optimal memory model for this input changes. To compare U3E with typical
evidence extraction methods and investigate its effectiveness in evidence
extraction, we conduct experiments on different datasets. Experimental results
show that U3E is simple but effective, not only extracting evidence more
accurately, but also significantly improving model performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Join-Chain Network: A Logical Reasoning View of the Multi-head Attention in Transformer. (arXiv:2210.02729v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.02729">
<div class="article-summary-box-inner">
<span><p>Developing neural architectures that are capable of logical reasoning has
become increasingly important for a wide range of applications (e.g., natural
language processing). Towards this grand objective, we propose a symbolic
reasoning architecture that chains many join operators together to model output
logical expressions. In particular, we demonstrate that such an ensemble of
join-chains can express a broad subset of ''tree-structured'' first-order
logical expressions, named FOET, which is particularly useful for modeling
natural languages. To endow it with differentiable learning capability, we
closely examine various neural operators for approximating the symbolic
join-chains. Interestingly, we find that the widely used multi-head
self-attention module in transformer can be understood as a special neural
operator that implements the union bound of the join operator in probabilistic
predicate space. Our analysis not only provides a new perspective on the
mechanism of the pretrained models such as BERT for natural language
understanding but also suggests several important future improvement
directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rainier: Reinforced Knowledge Introspector for Commonsense Question Answering. (arXiv:2210.03078v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.03078">
<div class="article-summary-box-inner">
<span><p>Knowledge underpins reasoning. Recent research demonstrates that when
relevant knowledge is provided as additional context to commonsense question
answering (QA), it can substantially enhance the performance even on top of
state-of-the-art. The fundamental challenge is where and how to find such
knowledge that is high quality and on point with respect to the question;
knowledge retrieved from knowledge bases are incomplete and knowledge generated
from language models are inconsistent. We present Rainier, or Reinforced
Knowledge Introspector, that learns to generate contextually relevant knowledge
in response to given questions. Our approach starts by imitating knowledge
generated by GPT-3, then learns to generate its own knowledge via reinforcement
learning where rewards are shaped based on the increased performance on the
resulting question answering. Rainier demonstrates substantial and consistent
performance gains when tested over 9 different commonsense benchmarks:
including 5 datasets that are seen during model training, as well as 4 datasets
that are kept unseen. Our work is the first to report that knowledge generated
by models that are orders of magnitude smaller than GPT-3, even without direct
supervision on the knowledge itself, can exceed the quality of commonsense
knowledge elicited from GPT-3.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PQLM -- Multilingual Decentralized Portable Quantum Language Model for Privacy Protection. (arXiv:2210.03221v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.03221">
<div class="article-summary-box-inner">
<span><p>With careful manipulation, malicious agents can reverse engineer private
information encoded in pre-trained language models. Security concerns motivate
the development of quantum pre-training. In this work, we propose a highly
portable quantum language model (PQLM) that can be easily transferred to
downstream tasks on classical machines. The framework consists of a cloud PQLM
built with random Variational Quantum Classifiers (VQC) and local models for
downstream applications. We demonstrate the portability of the quantum model by
extracting only the word embeddings and effectively applying them to downstream
tasks on classical machines. Our PQLM exhibits comparable performance to its
classical counterpart on both intrinsic evaluation (loss, perplexity) and
extrinsic evaluation (multilingual sentiment analysis accuracy) metrics and
achieves an accuracy of 93.4%, outperforming the classical model. We also
perform ablation studies on the factors affecting PQLM performance to analyze
model stability. Our work establishes a theoretical foundation for a portable
quantum pre-trained language model that could be trained on private data and
made available for public use with privacy protection guarantees.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Large-scale Paraphrase Acquisition and Generation. (arXiv:2210.03235v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.03235">
<div class="article-summary-box-inner">
<span><p>This paper addresses the quality issues in existing Twitter-based paraphrase
datasets, and discusses the necessity of using two separate definitions of
paraphrase for identification and generation tasks. We present a new
Multi-Topic Paraphrase in Twitter (MultiPIT) corpus that consists of a total of
130k sentence pairs with crowdsoursing (MultiPIT_crowd) and expert
(MultiPIT_expert) annotations using two different paraphrase definitions for
paraphrase identification, in addition to a multi-reference test set
(MultiPIT_NMR) and a large automatically constructed training set
(MultiPIT_Auto) for paraphrase generation. With improved data annotation
quality and task-specific paraphrase definition, the best pre-trained language
model fine-tuned on our dataset achieves the state-of-the-art performance of
84.2 F1 for automatic paraphrase identification. Furthermore, our empirical
results also demonstrate that the paraphrase generation models trained on
MultiPIT_Auto generate more diverse and high-quality paraphrases compared to
their counterparts fine-tuned on other corpora such as Quora, MSCOCO, and
ParaNMT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distillation-Resistant Watermarking for Model Protection in NLP. (arXiv:2210.03312v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.03312">
<div class="article-summary-box-inner">
<span><p>How can we protect the intellectual property of trained NLP models? Modern
NLP models are prone to stealing by querying and distilling from their publicly
exposed APIs. However, existing protection methods such as watermarking only
work for images but are not applicable to text. We propose
Distillation-Resistant Watermarking (DRW), a novel technique to protect NLP
models from being stolen via distillation. DRW protects a model by injecting
watermarks into the victim's prediction probability corresponding to a secret
key and is able to detect such a key by probing a suspect model. We prove that
a protected model still retains the original accuracy within a certain bound.
We evaluate DRW on a diverse set of NLP tasks including text classification,
part-of-speech tagging, and named entity recognition. Experiments show that DRW
protects the original model and detects stealing suspects at 100% mean average
precision for all four tasks while the prior method fails on two.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are Representations Built from the Ground Up? An Empirical Examination of Local Composition in Language Models. (arXiv:2210.03575v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.03575">
<div class="article-summary-box-inner">
<span><p>Compositionality, the phenomenon where the meaning of a phrase can be derived
from its constituent parts, is a hallmark of human language. At the same time,
many phrases are non-compositional, carrying a meaning beyond that of each part
in isolation. Representing both of these types of phrases is critical for
language understanding, but it is an open question whether modern language
models (LMs) learn to do so; in this work we examine this question. We first
formulate a problem of predicting the LM-internal representations of longer
phrases given those of their constituents. We find that the representation of a
parent phrase can be predicted with some accuracy given an affine
transformation of its children. While we would expect the predictive accuracy
to correlate with human judgments of semantic compositionality, we find this is
largely not the case, indicating that LMs may not accurately distinguish
between compositional and non-compositional phrases. We perform a variety of
analyses, shedding light on when different varieties of LMs do and do not
generate compositional representations, and discuss implications for future
modeling work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Artificial Intelligence and Natural Language Processing and Understanding in Space: A Methodological Framework and Four ESA Case Studies. (arXiv:2210.03640v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.03640">
<div class="article-summary-box-inner">
<span><p>The European Space Agency is well known as a powerful force for scientific
discovery in numerous areas related to Space. The amount and depth of the
knowledge produced throughout the different missions carried out by ESA and
their contribution to scientific progress is enormous, involving large
collections of documents like scientific publications, feasibility studies,
technical reports, and quality management procedures, among many others.
Through initiatives like the Open Space Innovation Platform, ESA also acts as a
hub for new ideas coming from the wider community across different challenges,
contributing to a virtuous circle of scientific discovery and innovation.
Handling such wealth of information, of which large part is unstructured text,
is a colossal task that goes beyond human capabilities, hence requiring
automation. In this paper, we present a methodological framework based on
artificial intelligence and natural language processing and understanding to
automatically extract information from Space documents, generating value from
it, and illustrate such framework through several case studies implemented
across different functional areas of ESA, including Mission Design, Quality
Assurance, Long-Term Data Preservation, and the Open Space Innovation Platform.
In doing so, we demonstrate the value of these technologies in several tasks
ranging from effortlessly searching and recommending Space information to
automatically determining how innovative an idea can be, answering questions
about Space, and generating quizzes regarding quality procedures. Each of these
accomplishments represents a step forward in the application of increasingly
intelligent AI systems in Space, from structuring and facilitating information
access to intelligent systems capable to understand and reason with such
information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models. (arXiv:2210.04325v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04325">
<div class="article-summary-box-inner">
<span><p>Data-to-text generation is challenging due to the great variety of the input
data in terms of domains (e.g., finance vs sports) or schemata (e.g., diverse
predicates). Recent end-to-end neural methods thus require substantial training
examples to learn to disambiguate and describe the data. Yet, real-world
data-to-text problems often suffer from various data-scarce issues: one may
have access to only a handful of or no training examples, and/or have to rely
on examples in a different domain or schema. To fill this gap, we propose
Any-Shot Data-to-Text (ASDOT), a new approach flexibly applicable to diverse
settings by making efficient use of any given (or no) examples. ASDOT consists
of two steps, data disambiguation and sentence fusion, both of which are
amenable to be solved with off-the-shelf pretrained language models (LMs) with
optional finetuning. In the data disambiguation stage, we employ the prompted
GPT-3 model to understand possibly ambiguous triples from the input data and
convert each into a short sentence with reduced ambiguity. The sentence fusion
stage then uses an LM like T5 to fuse all the resulting sentences into a
coherent paragraph as the final description. We evaluate extensively on various
datasets in different scenarios, including the zero-/few-/full-shot settings,
and generalization to unseen predicates and out-of-domain data. Experimental
results show that ASDOT consistently achieves significant improvement over
baselines, e.g., a 30.81 BLEU gain on the DART dataset under the zero-shot
setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge Graph Link Prediction. (arXiv:2210.04870v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04870">
<div class="article-summary-box-inner">
<span><p>Link prediction is the task of inferring missing links between entities in
knowledge graphs. Embedding-based methods have shown effectiveness in
addressing this problem by modeling relational patterns in triples. However,
the link prediction task often requires contextual information in entity
neighborhoods, while most existing embedding-based methods fail to capture it.
Additionally, little attention is paid to the diversity of entity
representations in different contexts, which often leads to false prediction
results. In this situation, we consider that the schema of knowledge graph
contains the specific contextual information, and it is beneficial for
preserving the consistency of entities across contexts. In this paper, we
propose a novel Schema-augmented Multi-level contrastive LEarning framework
(SMiLE) to conduct knowledge graph link prediction. Specifically, we first
exploit network schema as the prior constraint to sample negatives and
pre-train our model by employing a multi-level contrastive learning method to
yield both prior schema and contextual information. Then we fine-tune our model
under the supervision of individual triples to learn subtler representations
for link prediction. Extensive experimental results on four knowledge graph
datasets with thorough analysis of each component demonstrate the effectiveness
of our proposed framework against state-of-the-art baselines. The
implementation of SMiLE is available at https://github.com/GKNL/SMiLE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Measuring and Improving Semantic Diversity of Dialogue Generation. (arXiv:2210.05725v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.05725">
<div class="article-summary-box-inner">
<span><p>Response diversity has become an important criterion for evaluating the
quality of open-domain dialogue generation models. However, current evaluation
metrics for response diversity often fail to capture the semantic diversity of
generated responses, as they mainly consider lexical aspects of the generated
responses. In this paper, we introduce a new automatic evaluation metric to
measure the semantic diversity of generated responses. Through human
evaluation, we demonstrate that our proposed metric captures human judgments on
response diversity better than existing lexical-level diversity metrics.
Furthermore, motivated by analyzing an existing dialogue dataset, we propose a
simple yet effective learning method that improves the semantic diversity of
generated responses. Our learning method weights training samples based on the
semantic distribution of the training set. We show that our learning method
improves response diversity and coherency better than other baseline methods
through automatic and human evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Re3: Generating Longer Stories With Recursive Reprompting and Revision. (arXiv:2210.06774v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.06774">
<div class="article-summary-box-inner">
<span><p>We consider the problem of automatically generating longer stories of over
two thousand words. Compared to prior work on shorter stories, long-range plot
coherence and relevance are more central challenges here. We propose the
Recursive Reprompting and Revision framework (Re3) to address these challenges
by (a) prompting a general-purpose language model to construct a structured
overarching plan, and (b) generating story passages by repeatedly injecting
contextual information from both the plan and current story state into a
language model prompt. We then revise by (c) reranking different continuations
for plot coherence and premise relevance, and finally (d) editing the best
continuation for factual consistency. Compared to similar-length stories
generated directly from the same base model, human evaluators judged
substantially more of Re3's stories as having a coherent overarching plot (by
14% absolute increase), and relevant to the given initial premise (by 20%).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models of Code are Few-Shot Commonsense Learners. (arXiv:2210.07128v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07128">
<div class="article-summary-box-inner">
<span><p>We address the general task of structured commonsense reasoning: given a
natural language input, the goal is to generate a graph such as an event -- or
a reasoning-graph. To employ large language models (LMs) for this task,
existing approaches ``serialize'' the output graph as a flat list of nodes and
edges. Although feasible, these serialized graphs strongly deviate from the
natural language corpora that LMs were pre-trained on, hindering LMs from
generating them correctly. In this paper, we show that when we instead frame
structured commonsense reasoning tasks as code generation tasks, pre-trained
LMs of code are better structured commonsense reasoners than LMs of natural
language, even when the downstream task does not involve source code at all. We
demonstrate our approach across three diverse structured commonsense reasoning
tasks. In all these natural language tasks, we show that using our approach, a
code generation LM (CODEX) outperforms natural-LMs that are fine-tuned on the
target task (e.g., T5) and other strong LMs such as GPT-3 in the few-shot
setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controlling Bias Exposure for Fair Interpretable Predictions. (arXiv:2210.07455v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07455">
<div class="article-summary-box-inner">
<span><p>Recent work on reducing bias in NLP models usually focuses on protecting or
isolating information related to a sensitive attribute (like gender or race).
However, when sensitive information is semantically entangled with the task
information of the input, e.g., gender information is predictive for a
profession, a fair trade-off between task performance and bias mitigation is
difficult to achieve. Existing approaches perform this trade-off by eliminating
bias information from the latent space, lacking control over how much bias is
necessarily required to be removed. We argue that a favorable debiasing method
should use sensitive information 'fairly', rather than blindly eliminating it
(Caliskan et al., 2017; Sun et al., 2019; Bogen et al., 2020). In this work, we
provide a novel debiasing algorithm by adjusting the predictive model's belief
to (1) ignore the sensitive information if it is not useful for the task; (2)
use sensitive information minimally as necessary for the prediction (while also
incurring a penalty). Experimental results on two text classification tasks
(influenced by gender) and an open-ended generation task (influenced by race)
indicate that our model achieves a desirable trade-off between debiasing and
task performance along with producing debiased rationales as evidence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SQA3D: Situated Question Answering in 3D Scenes. (arXiv:2210.07474v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07474">
<div class="article-summary-box-inner">
<span><p>We propose a new task to benchmark scene understanding of embodied agents:
Situated Question Answering in 3D Scenes (SQA3D). Given a scene context (e.g.,
3D scan), SQA3D requires the tested agent to first understand its situation
(position, orientation, etc.) in the 3D scene as described by text, then reason
about its surrounding environment and answer a question under that situation.
Based upon 650 scenes from ScanNet, we provide a dataset centered around 6.8k
unique situations, along with 20.4k descriptions and 33.4k diverse reasoning
questions for these situations. These questions examine a wide spectrum of
reasoning capabilities for an intelligent agent, ranging from spatial relation
comprehension to commonsense understanding, navigation, and multi-hop
reasoning. SQA3D imposes a significant challenge to current multi-modal
especially 3D reasoning models. We evaluate various state-of-the-art approaches
and find that the best one only achieves an overall score of 47.20%, while
amateur human participants can reach 90.06%. We believe SQA3D could facilitate
future embodied AI research with stronger situation understanding and reasoning
capability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Task Pre-Training of Modular Prompt for Few-Shot Learning. (arXiv:2210.07565v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07565">
<div class="article-summary-box-inner">
<span><p>Prompt tuning is a parameter-efficient approach to adapting pre-trained
language models to downstream tasks. Although prompt tuning has been shown to
match the performance of full model tuning when training data is sufficient, it
tends to struggle in few-shot learning settings. In this paper, we present
Multi-task Pre-trained Modular Prompt (MP2) to boost prompt tuning for few-shot
learning. MP2 is a set of combinable prompts pre-trained on 38 Chinese tasks.
On downstream tasks, the pre-trained prompts are selectively activated and
combined, leading to strong compositional generalization to unseen tasks. To
bridge the gap between pre-training and fine-tuning, we formulate upstream and
downstream tasks into a unified machine reading comprehension task. Extensive
experiments under two learning paradigms, i.e., gradient descent and black-box
tuning, show that MP2 significantly outperforms prompt tuning, full model
tuning, and prior prompt pre-training methods in few-shot settings. In
addition, we demonstrate that MP2 can achieve surprisingly fast and strong
adaptation to downstream tasks by merely learning 8 parameters to combine the
pre-trained modular prompts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Character-Centric Story Visualization via Visual Planning and Token Alignment. (arXiv:2210.08465v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08465">
<div class="article-summary-box-inner">
<span><p>Story visualization advances the traditional text-to-image generation by
enabling multiple image generation based on a complete story. This task
requires machines to 1) understand long text inputs and 2) produce a globally
consistent image sequence that illustrates the contents of the story. A key
challenge of consistent story visualization is to preserve characters that are
essential in stories. To tackle the challenge, we propose to adapt a recent
work that augments Vector-Quantized Variational Autoencoders (VQ-VAE) with a
text-tovisual-token (transformer) architecture. Specifically, we modify the
text-to-visual-token module with a two-stage framework: 1) character token
planning model that predicts the visual tokens for characters only; 2) visual
token completion model that generates the remaining visual token sequence,
which is sent to VQ-VAE for finalizing image generations. To encourage
characters to appear in the images, we further train the two-stage framework
with a character-token alignment objective. Extensive experiments and
evaluations demonstrate that the proposed method excels at preserving
characters and can produce higher quality image sequences compared with the
strong baselines. Codes can be found in https://github.com/sairin1202/VP-CSV
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coordinated Topic Modeling. (arXiv:2210.08559v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08559">
<div class="article-summary-box-inner">
<span><p>We propose a new problem called coordinated topic modeling that imitates
human behavior while describing a text corpus. It considers a set of
well-defined topics like the axes of a semantic space with a reference
representation. It then uses the axes to model a corpus for easily
understandable representation. This new task helps represent a corpus more
interpretably by reusing existing knowledge and benefits the corpora comparison
task. We design ECTM, an embedding-based coordinated topic model that
effectively uses the reference representation to capture the target
corpus-specific aspects while maintaining each topic's global semantics. In
ECTM, we introduce the topic- and document-level supervision with a
self-training mechanism to solve the problem. Finally, extensive experiments on
multiple domains show the superiority of our model over other baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Unified Positive-Unlabeled Learning Framework for Document-Level Relation Extraction with Different Levels of Labeling. (arXiv:2210.08709v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08709">
<div class="article-summary-box-inner">
<span><p>Document-level relation extraction (RE) aims to identify relations between
entities across multiple sentences. Most previous methods focused on
document-level RE under full supervision. However, in real-world scenario, it
is expensive and difficult to completely label all relations in a document
because the number of entity pairs in document-level RE grows quadratically
with the number of entities. To solve the common incomplete labeling problem,
we propose a unified positive-unlabeled learning framework - shift and squared
ranking loss positive-unlabeled (SSR-PU) learning. We use positive-unlabeled
(PU) learning on document-level RE for the first time. Considering that labeled
data of a dataset may lead to prior shift of unlabeled data, we introduce a PU
learning under prior shift of training data. Also, using none-class score as an
adaptive threshold, we propose squared ranking loss and prove its Bayesian
consistency with multi-label ranking metrics. Extensive experiments demonstrate
that our method achieves an improvement of about 14 F1 points relative to the
previous baseline with incomplete labeling. In addition, it outperforms
previous state-of-the-art results under both fully supervised and extremely
unlabeled settings as well.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging a New Spanish Corpus for Multilingual and Crosslingual Metaphor Detection. (arXiv:2210.10358v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10358">
<div class="article-summary-box-inner">
<span><p>The lack of wide coverage datasets annotated with everyday metaphorical
expressions for languages other than English is striking. This means that most
research on supervised metaphor detection has been published only for that
language. In order to address this issue, this work presents the first corpus
annotated with naturally occurring metaphors in Spanish large enough to develop
systems to perform metaphor detection. The presented dataset, CoMeta, includes
texts from various domains, namely, news, political discourse, Wikipedia and
reviews. In order to label CoMeta, we apply the MIPVU method, the guidelines
most commonly used to systematically annotate metaphor on real data. We use our
newly created dataset to provide competitive baselines by fine-tuning several
multilingual and monolingual state-of-the-art large language models.
Furthermore, by leveraging the existing VUAM English data in addition to
CoMeta, we present the, to the best of our knowledge, first cross-lingual
experiments on supervised metaphor detection. Finally, we perform a detailed
error analysis that explores the seemingly high transfer of everyday metaphor
across these two languages and datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attribution and Obfuscation of Neural Text Authorship: A Data Mining Perspective. (arXiv:2210.10488v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10488">
<div class="article-summary-box-inner">
<span><p>Two interlocking research questions of growing interest and importance in
privacy research are Authorship Attribution (AA) and Authorship Obfuscation
(AO). Given an artifact, especially a text t in question, an AA solution aims
to accurately attribute t to its true author out of many candidate authors
while an AO solution aims to modify t to hide its true authorship.
Traditionally, the notion of authorship and its accompanying privacy concern is
only toward human authors. However, in recent years, due to the explosive
advancements in Neural Text Generation (NTG) techniques in NLP, capable of
synthesizing human-quality open-ended texts (so-called "neural texts"), one has
to now consider authorships by humans, machines, or their combination. Due to
the implications and potential threats of neural texts when used maliciously,
it has become critical to understand the limitations of traditional AA/AO
solutions and develop novel AA/AO solutions in dealing with neural texts. In
this survey, therefore, we make a comprehensive review of recent literature on
the attribution and obfuscation of neural text authorship from a Data Mining
perspective, and share our view on their limitations and promising research
directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Schema-aware Reference as Prompt Improves Data-Efficient Relational Triple and Event Extraction. (arXiv:2210.10709v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10709">
<div class="article-summary-box-inner">
<span><p>Information Extraction, which aims to extract structural relational triple or
event from unstructured texts, often suffers from data scarcity issues. With
the development of pre-trained language models, many prompt-based approaches to
data-efficient information extraction have been proposed and achieved
impressive performance. However, existing prompt learning methods for
information extraction are still susceptible to several potential limitations:
(i) semantic gap between natural language and output structure knowledge with
pre-defined schema; (ii) representation learning with locally individual
instances limits the performance given the insufficient features. In this
paper, we propose a novel approach of schema-aware Reference As Prompt (RAP),
which dynamically leverage schema and knowledge inherited from global
(few-shot) training data for each sample. Specifically, we propose a
schema-aware reference store, which unifies symbolic schema and relevant
textual instances. Then, we employ a dynamic reference integration module to
retrieve pertinent knowledge from the datastore as prompts during training and
inference. Experimental results demonstrate that RAP can be plugged into
various existing models and outperforms baselines in low-resource settings on
four datasets of relational triple extraction and event extraction. In
addition, we provide comprehensive empirical ablations and case analysis
regarding different types and scales of knowledge in order to better understand
the mechanisms of RAP. Code is available in https://github.com/zjunlp/RAP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Doc2Bot: Accessing Heterogeneous Documents via Conversational Bots. (arXiv:2210.11060v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11060">
<div class="article-summary-box-inner">
<span><p>This paper introduces Doc2Bot, a novel dataset for building machines that
help users seek information via conversations. This is of particular interest
for companies and organizations that own a large number of manuals or
instruction books. Despite its potential, the nature of our task poses several
challenges: (1) documents contain various structures that hinder the ability of
machines to comprehend, and (2) user information needs are often
underspecified. Compared to prior datasets that either focus on a single
structural type or overlook the role of questioning to uncover user needs, the
Doc2Bot dataset is developed to target such challenges systematically. Our
dataset contains over 100,000 turns based on Chinese documents from five
domains, larger than any prior document-grounded dialog dataset for information
seeking. We propose three tasks in Doc2Bot: (1) dialog state tracking to track
user intentions, (2) dialog policy learning to plan system actions and
contents, and (3) response generation which generates responses based on the
outputs of the dialog policy. Baseline methods based on the latest deep
learning models are presented, indicating that our proposed tasks are
challenging and worthy of further research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MovieCLIP: Visual Scene Recognition in Movies. (arXiv:2210.11065v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11065">
<div class="article-summary-box-inner">
<span><p>Longform media such as movies have complex narrative structures, with events
spanning a rich variety of ambient visual scenes. Domain specific challenges
associated with visual scenes in movies include transitions, person coverage,
and a wide array of real-life and fictional scenarios. Existing visual scene
datasets in movies have limited taxonomies and don't consider the visual scene
transition within movie clips. In this work, we address the problem of visual
scene recognition in movies by first automatically curating a new and extensive
movie-centric taxonomy of 179 scene labels derived from movie scripts and
auxiliary web-based video datasets. Instead of manual annotations which can be
expensive, we use CLIP to weakly label 1.12 million shots from 32K movie clips
based on our proposed taxonomy. We provide baseline visual models trained on
the weakly labeled dataset called MovieCLIP and evaluate them on an independent
dataset verified by human raters. We show that leveraging features from models
pretrained on MovieCLIP benefits downstream tasks such as multi-label scene and
genre classification of web videos and movie trailers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SimANS: Simple Ambiguous Negatives Sampling for Dense Text Retrieval. (arXiv:2210.11773v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11773">
<div class="article-summary-box-inner">
<span><p>Sampling proper negatives from a large document pool is vital to effectively
train a dense retrieval model. However, existing negative sampling strategies
suffer from the uninformative or false negative problem. In this work, we
empirically show that according to the measured relevance scores, the negatives
ranked around the positives are generally more informative and less likely to
be false negatives. Intuitively, these negatives are not too hard (\emph{may be
false negatives}) or too easy (\emph{uninformative}). They are the ambiguous
negatives and need more attention during training. Thus, we propose a simple
ambiguous negatives sampling method, SimANS, which incorporates a new sampling
probability distribution to sample more ambiguous negatives. Extensive
experiments on four public and one industry datasets show the effectiveness of
our approach. We made the code and models publicly available in
\url{https://github.com/microsoft/SimXNS}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models. (arXiv:2210.12023v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.12023">
<div class="article-summary-box-inner">
<span><p>We have recently witnessed a number of impressive results on hard
mathematical reasoning problems with language models. At the same time, the
robustness of these models has also been called into question; recent works
have shown that models can rely on shallow patterns in the problem description
when predicting a solution. Building on the idea of behavioral testing, we
propose a novel framework, which pins down the causal effect of various factors
in the input, e.g., the surface form of the problem text, the operands and math
operators on the output solution. By grounding the behavioral analysis in a
causal graph describing an intuitive reasoning process, we study the behavior
of language models in terms of robustness and sensitivity to direct
interventions in the input space. We apply our framework on a test bed of
bivariate math word problems. Our analysis shows that robustness does not
appear to continuously improve as a function of scale, but that the recent LLM,
GPT-3-Instruct (175B), achieves a dramatic improvement in both robustness and
sensitivity, compared to all other GPT variants.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-10-25 23:18:12.730100948 UTC">2022-10-25 23:18:12 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>