<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-02-23T01:30:00Z">02-23</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">GLUECons: A Generic Benchmark for Learning Under Constraints. (arXiv:2302.10914v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10914">
<div class="article-summary-box-inner">
<span><p>Recent research has shown that integrating domain knowledge into deep
learning architectures is effective -- it helps reduce the amount of required
data, improves the accuracy of the models' decisions, and improves the
interpretability of models. However, the research community is missing a
convened benchmark for systematically evaluating knowledge integration methods.
In this work, we create a benchmark that is a collection of nine tasks in the
domains of natural language processing and computer vision. In all cases, we
model external knowledge as constraints, specify the sources of the constraints
for each task, and implement various models that use these constraints. We
report the results of these models using a new set of extended evaluation
criteria in addition to the task performances for a more in-depth analysis.
This effort provides a framework for a more comprehensive and systematic
comparison of constraint integration techniques and for identifying related
research challenges. It will facilitate further research for alleviating some
problems of state-of-the-art neural models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conformers are All You Need for Visual Speech Recogntion. (arXiv:2302.10915v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10915">
<div class="article-summary-box-inner">
<span><p>Visual speech recognition models extract visual features in a hierarchical
manner. At the lower level, there is a visual front-end with a limited temporal
receptive field that processes the raw pixels depicting the lips or faces. At
the higher level, there is an encoder that attends to the embeddings produced
by the front-end over a large temporal receptive field. Previous work has
focused on improving the visual front-end of the model to extract more useful
features for speech recognition. Surprisingly, our work shows that complex
visual front-ends are not necessary. Instead of allocating resources to a
sophisticated visual front-end, we find that a linear visual front-end paired
with a larger Conformer encoder results in lower latency, more efficient memory
usage, and improved WER performance. We achieve a new state-of-the-art of
$12.8\%$ WER for visual speech recognition on the TED LRS3 dataset, which
rivals the performance of audio-only models from just four years ago.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Retrieve Engaging Follow-Up Queries. (arXiv:2302.10978v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10978">
<div class="article-summary-box-inner">
<span><p>Open domain conversational agents can answer a broad range of targeted
queries. However, the sequential nature of interaction with these systems makes
knowledge exploration a lengthy task which burdens the user with asking a chain
of well phrased questions. In this paper, we present a retrieval based system
and associated dataset for predicting the next questions that the user might
have. Such a system can proactively assist users in knowledge exploration
leading to a more engaging dialog. The retrieval system is trained on a dataset
which contains ~14K multi-turn information-seeking conversations with a valid
follow-up question and a set of invalid candidates. The invalid candidates are
generated to simulate various syntactic and semantic confounders such as
paraphrases, partial entity match, irrelevant entity, and ASR errors. We use
confounder specific techniques to simulate these negative examples on the
OR-QuAC dataset and develop a dataset called the Follow-up Query Bank
(FQ-Bank). Then, we train ranking models on FQ-Bank and present results
comparing supervised and unsupervised approaches. The results suggest that we
can retrieve the valid follow-ups by ranking them in higher positions compared
to confounders, but further knowledge grounding can improve ranking
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Orcas Have Semantic Language? Machine Learning to Predict Orca Behaviors Using Partially Labeled Vocalization Data. (arXiv:2302.10983v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10983">
<div class="article-summary-box-inner">
<span><p>Orcinus orca (killer whales) exhibit complex calls. They last about a second.
In a call, an orca typically uses multiple frequencies simultaneously, varies
the frequencies, and varies their volumes. Behavior data is hard to obtain
because orcas live under water and travel quickly. Sound data is relatively
easy to capture. As a science goal, we would like to know whether orca
vocalizations constitute a semantic language. We do this by studying whether
machine learning can predict behavior from vocalizations. Such prediction would
also help scientific research and safety applications because one would like to
predict behavior while only having to capture sound. A significant challenge in
this process is lack of labeled data. We work with recent recordings of McMurdo
Sound orcas [Wellard et al. 2020] where each recording is labeled with the
behaviors observed during the recording. This yields a dataset where sound
segments - continuous vocalizations that can be thought of as call sequences or
more general structures - within the recordings are labeled with superfluous
behaviors. Despite that, with a careful combination of recent machine learning
techniques, we achieve 96.4% classification accuracy. This suggests that orcas
do use a semantic language. It is also promising for research and applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">In-context Example Selection with Influences. (arXiv:2302.11042v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11042">
<div class="article-summary-box-inner">
<span><p>In-context learning (ICL) is a powerful paradigm emerged from large language
models (LLMs). Despite its promises, ICL performance is known to be highly
sensitive to input examples. In this work, we use in-context influences to
analyze few-shot ICL performance directly from the in-context examples. Our
proposed influence-based example selection method outperforms most baselines
when evaluated on 10 SuperGlue tasks and stably scales with increasing k-shot.
The analysis finds up to a 22.2% performance gap between the most positively
and negatively influential examples. In a case study, we apply our
influence-based framework to quantify the phenomena of recency bias in example
ordering for few-shot ICL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Edgeformers: Graph-Empowered Transformers for Representation Learning on Textual-Edge Networks. (arXiv:2302.11050v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11050">
<div class="article-summary-box-inner">
<span><p>Edges in many real-world social/information networks are associated with rich
text information (e.g., user-user communications or user-product reviews).
However, mainstream network representation learning models focus on propagating
and aggregating node attributes, lacking specific designs to utilize text
semantics on edges. While there exist edge-aware graph neural networks, they
directly initialize edge attributes as a feature vector, which cannot fully
capture the contextualized text semantics of edges. In this paper, we propose
Edgeformers, a framework built upon graph-enhanced Transformers, to perform
edge and node representation learning by modeling texts on edges in a
contextualized way. Specifically, in edge representation learning, we inject
network information into each Transformer layer when encoding edge texts; in
node representation learning, we aggregate edge representations through an
attention mechanism within each node's ego-graph. On five public datasets from
three different domains, Edgeformers consistently outperform state-of-the-art
baselines in edge classification and link prediction, demonstrating the
efficacy in learning edge and node representations, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conversational Text-to-SQL: An Odyssey into State-of-the-Art and Challenges Ahead. (arXiv:2302.11054v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11054">
<div class="article-summary-box-inner">
<span><p>Conversational, multi-turn, text-to-SQL (CoSQL) tasks map natural language
utterances in a dialogue to SQL queries. State-of-the-art (SOTA) systems use
large, pre-trained and finetuned language models, such as the T5-family, in
conjunction with constrained decoding. With multi-tasking (MT) over coherent
tasks with discrete prompts during training, we improve over specialized
text-to-SQL T5-family models. Based on Oracle analyses over n-best hypotheses,
we apply a query plan model and a schema linking algorithm as rerankers.
Combining MT and reranking, our results using T5-3B show absolute accuracy
improvements of 1.0% in exact match and 3.4% in execution match over a SOTA
baseline on CoSQL. While these gains consistently manifest at turn level,
context dependent turns are considerably harder. We conduct studies to tease
apart errors attributable to domain and compositional generalization, with the
latter remaining a challenge for multi-turn conversations, especially in
generating SQL with unseen parse trees.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Preventing Catastrophic Forgetting in Continual Learning of New Natural Language Tasks. (arXiv:2302.11074v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11074">
<div class="article-summary-box-inner">
<span><p>Multi-Task Learning (MTL) is widely-accepted in Natural Language Processing
as a standard technique for learning multiple related tasks in one model.
Training an MTL model requires having the training data for all tasks available
at the same time. As systems usually evolve over time, (e.g., to support new
functionalities), adding a new task to an existing MTL model usually requires
retraining the model from scratch on all the tasks and this can be
time-consuming and computationally expensive. Moreover, in some scenarios, the
data used to train the original training may be no longer available, for
example, due to storage or privacy concerns. In this paper, we approach the
problem of incrementally expanding MTL models' capability to solve new tasks
over time by distilling the knowledge of an already trained model on n tasks
into a new one for solving n+1 tasks. To avoid catastrophic forgetting, we
propose to exploit unlabeled data from the same distributions of the old tasks.
Our experiments on publicly available benchmarks show that such a technique
dramatically benefits the distillation by preserving the already acquired
knowledge (i.e., preventing up to 20% performance drops on old tasks) while
obtaining good performance on the incrementally added tasks. Further, we also
show that our approach is beneficial in practical settings by using data from a
leading voice assistant.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distribution Normalization: An "Effortless" Test-Time Augmentation for Contrastively Learned Visual-language Models. (arXiv:2302.11084v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11084">
<div class="article-summary-box-inner">
<span><p>Advances in the field of visual-language contrastive learning have made it
possible for many downstream applications to be carried out efficiently and
accurately by simply taking the dot product between image and text
representations. One of the most representative approaches proposed recently
known as CLIP has quickly garnered widespread adoption due to its
effectiveness. CLIP is trained with an InfoNCE loss that takes into account
both positive and negative samples to help learn a much more robust
representation space. This paper however reveals that the common downstream
practice of taking a dot product is only a zeroth-order approximation of the
optimization goal, resulting in a loss of information during test-time.
Intuitively, since the model has been optimized based on the InfoNCE loss,
test-time procedures should ideally also be in alignment. The question lies in
how one can retrieve any semblance of negative samples information during
inference. We propose Distribution Normalization (DN), where we approximate the
mean representation of a batch of test samples and use such a mean to represent
what would be analogous to negative samples in the InfoNCE loss. DN requires no
retraining or fine-tuning and can be effortlessly applied during inference.
Extensive experiments on a wide variety of downstream tasks exhibit a clear
advantage of DN over the dot product.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GTRL: An Entity Group-Aware Temporal Knowledge Graph Representation Learning Method. (arXiv:2302.11091v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11091">
<div class="article-summary-box-inner">
<span><p>Temporal Knowledge Graph (TKG) representation learning embeds entities and
event types into a continuous low-dimensional vector space by integrating the
temporal information, which is essential for downstream tasks, e.g., event
prediction and question answering. Existing methods stack multiple graph
convolution layers to model the influence of distant entities, leading to the
over-smoothing problem. To alleviate the problem, recent studies infuse
reinforcement learning to obtain paths that contribute to modeling the
influence of distant entities. However, due to the limited number of hops,
these studies fail to capture the correlation between entities that are far
apart and even unreachable. To this end, we propose GTRL, an entity Group-aware
Temporal knowledge graph Representation Learning method. GTRL is the first work
that incorporates the entity group modeling to capture the correlation between
entities by stacking only a finite number of layers. Specifically, the entity
group mapper is proposed to generate entity groups from entities in a learning
way. Based on entity groups, the implicit correlation encoder is introduced to
capture implicit correlations between any pairwise entity groups. In addition,
the hierarchical GCNs are exploited to accomplish the message aggregation and
representation updating on the entity group graph and the entity graph.
Finally, GRUs are employed to capture the temporal dependency in TKGs.
Extensive experiments on three real-world datasets demonstrate that GTRL
achieves the state-of-the-art performances on the event prediction task,
outperforming the best baseline by an average of 13.44%, 9.65%, 12.15%, and
15.12% in MRR, Hits@1, Hits@3, and Hits@10, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open-domain Visual Entity Recognition: Towards Recognizing Millions of Wikipedia Entities. (arXiv:2302.11154v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11154">
<div class="article-summary-box-inner">
<span><p>Large-scale multi-modal pre-training models such as CLIP and PaLI exhibit
strong generalization on various visual domains and tasks. However, existing
image classification benchmarks often evaluate recognition on a specific domain
(e.g., outdoor images) or a specific task (e.g., classifying plant species),
which falls short of evaluating whether pre-trained foundational models are
universal visual recognizers. To address this, we formally present the task of
Open-domain Visual Entity recognitioN (OVEN), where a model need to link an
image onto a Wikipedia entity with respect to a text query. We construct
OVEN-Wiki by re-purposing 14 existing datasets with all labels grounded onto
one single label space: Wikipedia entities. OVEN challenges models to select
among six million possible Wikipedia entities, making it a general visual
recognition benchmark with the largest number of labels. Our study on
state-of-the-art pre-trained models reveals large headroom in generalizing to
the massive-scale label space. We show that a PaLI-based auto-regressive visual
recognition model performs surprisingly well, even on Wikipedia entities that
have never been seen during fine-tuning. We also find existing pretrained
models yield different strengths: while PaLI-based models obtain higher overall
performance, CLIP-based models are better at recognizing tail entities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FiNER: Financial Named Entity Recognition Dataset and Weak-Supervision Model. (arXiv:2302.11157v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11157">
<div class="article-summary-box-inner">
<span><p>The development of annotated datasets over the 21st century has helped us
truly realize the power of deep learning. Most of the datasets created for the
named-entity-recognition (NER) task are not domain specific. Finance domain
presents specific challenges to the NER task and a domain specific dataset
would help push the boundaries of finance research. In our work, we develop the
first high-quality NER dataset for the finance domain. To set the benchmark for
the dataset, we develop and test a weak-supervision-based framework for the NER
task. We extend the current weak-supervision framework to make it employable
for span-level classification. Our weak-ner framework and the dataset are
publicly available on GitHub and Hugging Face.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UML: A Universal Monolingual Output Layer for Multilingual ASR. (arXiv:2302.11186v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11186">
<div class="article-summary-box-inner">
<span><p>Word-piece models (WPMs) are commonly used subword units in state-of-the-art
end-to-end automatic speech recognition (ASR) systems. For multilingual ASR,
due to the differences in written scripts across languages, multilingual WPMs
bring the challenges of having overly large output layers and scaling to more
languages. In this work, we propose a universal monolingual output layer (UML)
to address such problems. Instead of one output node for only one WPM, UML
re-associates each output node with multiple WPMs, one for each language, and
results in a smaller monolingual output layer shared across languages.
Consequently, the UML enables to switch in the interpretation of each output
node depending on the language of the input speech. Experimental results on an
11-language voice search task demonstrated the feasibility of using UML for
high-quality and high-efficiency multilingual streaming ASR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Contextual Spelling Correction by External Acoustics Attention and Semantic Aware Data Augmentation. (arXiv:2302.11192v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11192">
<div class="article-summary-box-inner">
<span><p>We previously proposed contextual spelling correction (CSC) to correct the
output of end-to-end (E2E) automatic speech recognition (ASR) models with
contextual information such as name, place, etc. Although CSC has achieved
reasonable improvement in the biasing problem, there are still two drawbacks
for further accuracy improvement. First, due to information limitation in text
only hypothesis or weak performance of ASR model on rare domains, the CSC model
may fail to correct phrases with similar pronunciation or anti-context cases
where all biasing phrases are not present in the utterance. Second, there is a
discrepancy between the training and inference of CSC. The bias list in
training is randomly selected but in inference there may be more similarity
between ground truth phrase and other phrases. To solve above limitations, in
this paper we propose an improved non-autoregressive (NAR) spelling correction
model for contextual biasing in E2E neural transducer-based ASR systems to
improve the previous CSC model from two perspectives: Firstly, we incorporate
acoustics information with an external attention as well as text hypotheses
into CSC to better distinguish target phrase from dissimilar or irrelevant
phrases. Secondly, we design a semantic aware data augmentation schema in
training phrase to reduce the mismatch between training and inference to
further boost the biasing accuracy. Experiments show that the improved method
outperforms the baseline ASR+Biasing system by as much as 20.3% relative name
recall gain and achieves stable improvement compared to the previous CSC method
over different bias list name coverage ratio.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Structured Policy Learning for Multi-Domain and Multi-Task Dialogues. (arXiv:2302.11199v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11199">
<div class="article-summary-box-inner">
<span><p>Reinforcement learning has been widely adopted to model dialogue managers in
task-oriented dialogues. However, the user simulator provided by
state-of-the-art dialogue frameworks are only rough approximations of human
behaviour. The ability to learn from a small number of human interactions is
hence crucial, especially on multi-domain and multi-task environments where the
action space is large. We therefore propose to use structured policies to
improve sample efficiency when learning on these kinds of environments. We also
evaluate the impact of learning from human vs simulated experts. Among the
different levels of structure that we tested, the graph neural networks (GNNs)
show a remarkable superiority by reaching a success rate above 80% with only 50
dialogues, when learning from simulated experts. They also show superiority
when learning from human experts, although a performance drop was observed,
indicating a possible difficulty in capturing the variability of human
strategies. We therefore suggest to concentrate future research efforts on
bridging the gap between human data, simulators and automatic evaluators in
dialogue frameworks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MADI: Inter-domain Matching and Intra-domain Discrimination for Cross-domain Speech Recognition. (arXiv:2302.11224v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11224">
<div class="article-summary-box-inner">
<span><p>End-to-end automatic speech recognition (ASR) usually suffers from
performance degradation when applied to a new domain due to domain shift.
Unsupervised domain adaptation (UDA) aims to improve the performance on the
unlabeled target domain by transferring knowledge from the source to the target
domain. To improve transferability, existing UDA approaches mainly focus on
matching the distributions of the source and target domains globally and/or
locally, while ignoring the model discriminability. In this paper, we propose a
novel UDA approach for ASR via inter-domain MAtching and intra-domain
DIscrimination (MADI), which improves the model transferability by fine-grained
inter-domain matching and discriminability by intra-domain contrastive
discrimination simultaneously. Evaluations on the Libri-Adapt dataset
demonstrate the effectiveness of our approach. MADI reduces the relative word
error rate (WER) on cross-device and cross-environment ASR by 17.7% and 22.8%,
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning from Multiple Sources for Data-to-Text and Text-to-Data. (arXiv:2302.11269v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11269">
<div class="article-summary-box-inner">
<span><p>Data-to-text (D2T) and text-to-data (T2D) are dual tasks that convert
structured data, such as graphs or tables into fluent text, and vice versa.
These tasks are usually handled separately and use corpora extracted from a
single source. Current systems leverage pre-trained language models fine-tuned
on D2T or T2D tasks. This approach has two main limitations: first, a separate
system has to be tuned for each task and source; second, learning is limited by
the scarcity of available corpora. This paper considers a more general scenario
where data are available from multiple heterogeneous sources. Each source, with
its specific data format and semantic domain, provides a non-parallel corpus of
text and structured data. We introduce a variational auto-encoder model with
disentangled style and content variables that allows us to represent the
diversity that stems from multiple sources of text and data. Our model is
designed to handle the tasks of D2T and T2D jointly. We evaluate our model on
several datasets, and show that by learning from multiple sources, our model
closes the performance gap with its supervised single-source counterpart and
outperforms it in some cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topic-switch adapted Japanese Dialogue System based on PLATO-2. (arXiv:2302.11280v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11280">
<div class="article-summary-box-inner">
<span><p>Large-scale open-domain dialogue systems such as PLATO-2 have achieved
state-of-the-art scores in both English and Chinese. However, little work
explores whether such dialogue systems also work well in the Japanese language.
In this work, we create a large-scale Japanese dialogue dataset,
Dialogue-Graph, which contains 1.656 million dialogue data in a tree structure
from News, TV subtitles, and Wikipedia corpus. Then, we train PLATO-2 using
Dialogue-Graph to build a large-scale Japanese dialogue system, PLATO-JDS. In
addition, to improve the PLATO-JDS in the topic switch issue, we introduce a
topic-switch algorithm composed of a topic discriminator to switch to a new
topic when user input differs from the previous topic. We evaluate the user
experience by using our model with respect to four metrics, namely, coherence,
informativeness, engagingness, and humanness. As a result, our proposed
PLATO-JDS achieves an average score of 1.500 for the human evaluation with
human-bot chat strategy, which is close to the maximum score of 2.000 and
suggests the high-quality dialogue generation capability of PLATO-2 in
Japanese. Furthermore, our proposed topic-switch algorithm achieves an average
score of 1.767 and outperforms PLATO-JDS by 0.267, indicating its effectiveness
in improving the user experience of our system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Impact of Subword Pooling Strategy for Cross-lingual Event Detection. (arXiv:2302.11365v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11365">
<div class="article-summary-box-inner">
<span><p>Pre-trained multilingual language models (e.g., mBERT, XLM-RoBERTa) have
significantly advanced the state-of-the-art for zero-shot cross-lingual
information extraction. These language models ubiquitously rely on word
segmentation techniques that break a word into smaller constituent subwords.
Therefore, all word labeling tasks (e.g. named entity recognition, event
detection, etc.), necessitate a pooling strategy that takes the subword
representations as input and outputs a representation for the entire word.
Taking the task of cross-lingual event detection as a motivating example, we
show that the choice of pooling strategy can have a significant impact on the
target language performance. For example, the performance varies by up to 16
absolute $f_{1}$ points depending on the pooling strategy when training in
English and testing in Arabic on the ACE task. We carry out our analysis with
five different pooling strategies across nine languages in diverse
multi-lingual datasets. Across configurations, we find that the canonical
strategy of taking just the first subword to represent the entire word is
usually sub-optimal. On the other hand, we show that attention pooling is
robust to language and dataset variations by being either the best or close to
the optimal strategy. For reproducibility, we make our code available at
https://github.com/isi-boston/ed-pooling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Augmentation for Neural NLP. (arXiv:2302.11412v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11412">
<div class="article-summary-box-inner">
<span><p>Data scarcity is a problem that occurs in languages and tasks where we do not
have large amounts of labeled data but want to use state-of-the-art models.
Such models are often deep learning models that require a significant amount of
data to train. Acquiring data for various machine learning problems is
accompanied by high labeling costs. Data augmentation is a low-cost approach
for tackling data scarcity. This paper gives an overview of current
state-of-the-art data augmentation methods used for natural language
processing, with an emphasis on methods for neural and transformer-based
models. Furthermore, it discusses the practical challenges of data
augmentation, possible mitigations, and directions for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Advancements in Federated Learning: Models, Methods, and Privacy. (arXiv:2302.11466v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11466">
<div class="article-summary-box-inner">
<span><p>Federated learning (FL) is a promising technique for addressing the rising
privacy and security issues. Its main ingredient is to cooperatively learn the
model among the distributed clients without uploading any sensitive data. In
this paper, we conducted a thorough review of the related works, following the
development context and deeply mining the key technologies behind FL from both
theoretical and practical perspectives. Specifically, we first classify the
existing works in FL architecture based on the network topology of FL systems
with detailed analysis and summarization. Next, we abstract the current
application problems, summarize the general techniques and frame the
application problems into the general paradigm of FL base models. Moreover, we
provide our proposed solutions for model training via FL. We have summarized
and analyzed the existing FedOpt algorithms, and deeply revealed the
algorithmic development principles of many first-order algorithms in depth,
proposing a more generalized algorithm design framework. Based on these
frameworks, we have instantiated FedOpt algorithms. As privacy and security is
the fundamental requirement in FL, we provide the existing attack scenarios and
the defense methods. To the best of our knowledge, we are among the first tier
to review the theoretical methodology and propose our strategies since there
are very few works surveying the theoretical approaches. Our survey targets
motivating the development of high-performance, privacy-preserving, and secure
methods to integrate FL into real-world applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Guiding Large Language Models via Directional Stimulus Prompting. (arXiv:2302.11520v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11520">
<div class="article-summary-box-inner">
<span><p>We introduce a new framework, Directional Stimulus Prompting, that uses a
tuneable language model (LM) to provide guidance for the black-box frozen large
language model (LLM) on downstream tasks. Unlike prior work that manually or
automatically finds the optimal prompt for each task, we train a policy LM to
generate discrete tokens as ``directional stimulus'' of each input, which is a
hint/cue such as keywords of an article for summarization. The directional
stimulus is then combined with the original input and fed into the LLM to guide
its generation toward the desired target. The policy LM can be trained through
1) supervised learning from annotated data and 2) reinforcement learning from
offline and online rewards to explore directional stimulus that better aligns
LLMs with human preferences. This framework is flexibly applicable to various
LMs and tasks. To verify its effectiveness, we apply our framework to
summarization and dialogue response generation tasks. Experimental results
demonstrate that it can significantly improve LLMs' performance with a small
collection of training data: a T5 (780M) trained with 2,000 samples from the
CNN/Daily Mail dataset improves Codex (175B)'s performance by 7.2% in ROUGE-Avg
scores; 500 dialogues boost the combined score by 52.5%, achieving comparable
or even better performance than fully trained models on the MultiWOZ dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Does In-Context Learning Help Prompt Tuning?. (arXiv:2302.11521v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11521">
<div class="article-summary-box-inner">
<span><p>Fine-tuning large language models is becoming ever more impractical due to
their rapidly-growing scale. This motivates the use of parameter-efficient
adaptation methods such as prompt tuning (PT), which adds a small number of
tunable embeddings to an otherwise frozen model, and in-context learning (ICL),
in which demonstrations of the task are provided to the model in natural
language without any additional training. Recently, Singhal et al. (2022)
propose ``instruction prompt tuning'' (IPT), which combines PT with ICL by
concatenating a natural language demonstration with learned prompt embeddings.
While all of these methods have proven effective on different tasks, how they
interact with each other remains unexplored. In this paper, we empirically
study when and how in-context examples improve prompt tuning by measuring the
effectiveness of ICL, PT, and IPT on five text generation tasks with multiple
base language models. We observe that (1) IPT does \emph{not} always outperform
PT, and in fact requires the in-context demonstration to be semantically
similar to the test input to yield improvements; (2) PT is unstable and
exhibits high variance, but combining PT and ICL (into IPT) consistently
reduces variance across all five tasks; and (3) prompts learned for a specific
source task via PT exhibit positive transfer when paired with in-context
examples of a different target task. Our results offer actionable insights on
choosing a suitable parameter-efficient adaptation method for a given task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scaling Robot Learning with Semantically Imagined Experience. (arXiv:2302.11550v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.11550">
<div class="article-summary-box-inner">
<span><p>Recent advances in robot learning have shown promise in enabling robots to
perform a variety of manipulation tasks and generalize to novel scenarios. One
of the key contributing factors to this progress is the scale of robot data
used to train the models. To obtain large-scale datasets, prior approaches have
relied on either demonstrations requiring high human involvement or
engineering-heavy autonomous data collection schemes, both of which are
challenging to scale. To mitigate this issue, we propose an alternative route
and leverage text-to-image foundation models widely used in computer vision and
natural language processing to obtain meaningful data for robot learning
without requiring additional robot data. We term our method Robot Learning with
Semantically Imagened Experience (ROSIE). Specifically, we make use of the
state of the art text-to-image diffusion models and perform aggressive data
augmentation on top of our existing robotic manipulation datasets via
inpainting various unseen objects for manipulation, backgrounds, and
distractors with text guidance. Through extensive real-world experiments, we
show that manipulation policies trained on data augmented this way are able to
solve completely unseen tasks with new objects and can behave more robustly
w.r.t. novel distractors. In addition, we find that we can improve the
robustness and generalization of high-level robot learning tasks such as
success detection through training with the diffusion-based data augmentation.
The project's website and videos can be found at diffusion-rosie.github.io
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structured Denoising Diffusion Models in Discrete State-Spaces. (arXiv:2107.03006v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03006">
<div class="article-summary-box-inner">
<span><p>Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown
impressive results on image and waveform generation in continuous state spaces.
Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs),
diffusion-like generative models for discrete data that generalize the
multinomial diffusion model of Hoogeboom et al. 2021, by going beyond
corruption processes with uniform transition probabilities. This includes
corruption with transition matrices that mimic Gaussian kernels in continuous
space, matrices based on nearest neighbors in embedding space, and matrices
that introduce absorbing states. The third allows us to draw a connection
between diffusion models and autoregressive and mask-based generative models.
We show that the choice of transition matrix is an important design decision
that leads to improved results in image and text domains. We also introduce a
new loss function that combines the variational lower bound with an auxiliary
cross entropy loss. For text, this model class achieves strong results on
character-level text generation while scaling to large vocabularies on LM1B. On
the image dataset CIFAR-10, our models approach the sample quality and exceed
the log-likelihood of the continuous-space DDPM model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Cognitive Architecture for Machine Consciousness and Artificial Superintelligence: Updating Working Memory Iteratively. (arXiv:2203.17255v3 [q-bio.NC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.17255">
<div class="article-summary-box-inner">
<span><p>This article examines how to construct human-like working memory and thought
processes within a computer. The focus is on simulating the mammalian working
memory system. There should be two interacting working memory stores, one
analogous to sustained firing lending the system a focus of attention, and
another analogous to synaptic potentiation lending the system a short-term
memory. These working memory stores retain and coactivate representations,
using them to search long-term memory for appropriate updates. The working
memory stores should be updated continuously, and in an iterative fashion,
meaning that, in the next state, some proportion of the coactive items should
always be retained. Thus, the set of concepts coactive in working memory will
evolve gradually and incrementally over time. This makes each state a revised
iteration of the preceding state and causes successive states to overlap and
blend with respect to the set of representations they contain. As new
representations are added and old ones are subtracted, some remain active for
several seconds over the course of these changes. This persistent activity,
similar to that used in contemporary artificial recurrent neural networks, is
used to spread activation energy throughout the global workspace to search for
the next associative update. The result is a chain of associatively linked
intermediate states that are capable of advancing toward a solution or goal.
Iterative updating is conceptualized here as an information processing
strategy, a computational and neurophysiological determinant of the stream of
thought, and an algorithm for designing and programming artificial general
intelligence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Faithful Model Explanation in NLP: A Survey. (arXiv:2209.11326v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.11326">
<div class="article-summary-box-inner">
<span><p>End-to-end neural Natural Language Processing (NLP) models are notoriously
difficult to understand. This has given rise to numerous efforts towards model
explainability in recent years. One desideratum of model explanation is
faithfulness, i.e. an explanation should accurately represent the reasoning
process behind the model's prediction. In this survey, we review over 110 model
explanation methods in NLP through the lens of faithfulness. We first discuss
the definition and evaluation of faithfulness, as well as its significance for
explainability. We then introduce recent advances in faithful explanation,
grouping existing approaches into five categories: similarity methods, analysis
of model-internal structures, backpropagation-based methods, counterfactual
intervention, and self-explanatory models. For each category, we synthesize its
representative studies, strengths, and weaknesses. Finally, we summarize their
common virtues and remaining challenges, and reflect on future work directions
towards faithful explainability in NLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Interdisciplinary Topic Detection Model for Research Proposal Classification. (arXiv:2209.13519v3 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.13519">
<div class="article-summary-box-inner">
<span><p>The peer merit review of research proposals has been the major mechanism for
deciding grant awards. However, research proposals have become increasingly
interdisciplinary. It has been a longstanding challenge to assign
interdisciplinary proposals to appropriate reviewers, so proposals are fairly
evaluated. One of the critical steps in reviewer assignment is to generate
accurate interdisciplinary topic labels for proposal-reviewer matching.
Existing systems mainly collect topic labels manually generated by principal
investigators. However, such human-reported labels can be non-accurate,
incomplete, labor intensive, and time costly. What role can AI play in
developing a fair and precise proposal reviewer assignment system? In this
study, we collaborate with the National Science Foundation of China to address
the task of automated interdisciplinary topic path detection. For this purpose,
we develop a deep Hierarchical Interdisciplinary Research Proposal
Classification Network (HIRPCN). Specifically, we first propose a hierarchical
transformer to extract the textual semantic information of proposals. We then
design an interdisciplinary graph and leverage GNNs for learning
representations of each discipline in order to extract interdisciplinary
knowledge. After extracting the semantic and interdisciplinary knowledge, we
design a level-wise prediction component to fuse the two types of knowledge
representations and detect interdisciplinary topic paths for each proposal. We
conduct extensive experiments and expert evaluations on three real-world
datasets to demonstrate the effectiveness of our proposed model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Methods for Addressing Class Imbalance in Deep-Learning Based Natural Language Processing. (arXiv:2210.04675v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.04675">
<div class="article-summary-box-inner">
<span><p>Many natural language processing (NLP) tasks are naturally imbalanced, as
some target categories occur much more frequently than others in the real
world. In such scenarios, current NLP models still tend to perform poorly on
less frequent classes. Addressing class imbalance in NLP is an active research
topic, yet, finding a good approach for a particular task and imbalance
scenario is difficult.
</p>
<p>With this survey, the first overview on class imbalance in deep-learning
based NLP, we provide guidance for NLP researchers and practitioners dealing
with imbalanced data. We first discuss various types of controlled and
real-world class imbalance. Our survey then covers approaches that have been
explicitly proposed for class-imbalanced NLP tasks or, originating in the
computer vision community, have been evaluated on them. We organize the methods
by whether they are based on sampling, data augmentation, choice of loss
function, staged learning, or model design. Finally, we discuss open problems
such as dealing with multi-label scenarios, and propose systematic benchmarking
and reporting in order to move forward on this problem as a community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SQA3D: Situated Question Answering in 3D Scenes. (arXiv:2210.07474v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07474">
<div class="article-summary-box-inner">
<span><p>We propose a new task to benchmark scene understanding of embodied agents:
Situated Question Answering in 3D Scenes (SQA3D). Given a scene context (e.g.,
3D scan), SQA3D requires the tested agent to first understand its situation
(position, orientation, etc.) in the 3D scene as described by text, then reason
about its surrounding environment and answer a question under that situation.
Based upon 650 scenes from ScanNet, we provide a dataset centered around 6.8k
unique situations, along with 20.4k descriptions and 33.4k diverse reasoning
questions for these situations. These questions examine a wide spectrum of
reasoning capabilities for an intelligent agent, ranging from spatial relation
comprehension to commonsense understanding, navigation, and multi-hop
reasoning. SQA3D imposes a significant challenge to current multi-modal
especially 3D reasoning models. We evaluate various state-of-the-art approaches
and find that the best one only achieves an overall score of 47.20%, while
amateur human participants can reach 90.06%. We believe SQA3D could facilitate
future embodied AI research with stronger situation understanding and reasoning
capability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Generation Models Can Cause Harm: So What Can We Do About It? An Actionable Survey. (arXiv:2210.07700v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07700">
<div class="article-summary-box-inner">
<span><p>Recent advances in the capacity of large language models to generate
human-like text have resulted in their increased adoption in user-facing
settings. In parallel, these improvements have prompted a heated discourse
around the risks of societal harms they introduce, whether inadvertent or
malicious. Several studies have explored these harms and called for their
mitigation via development of safer, fairer models. Going beyond enumerating
the risks of harms, this work provides a survey of practical methods for
addressing potential threats and societal harms from language generation
models. We draw on several prior works' taxonomies of language model risks to
present a structured overview of strategies for detecting and ameliorating
different kinds of risks/harms of language generators. Bridging diverse strands
of research, this survey aims to serve as a practical guide for both LM
researchers and practitioners, with explanations of different mitigation
strategies' motivations, their limitations, and open problems for future
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Effective Distillation of Self-Supervised Speech Models for Automatic Speech Recognition. (arXiv:2210.15631v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.15631">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed great strides in self-supervised learning (SSL)
on the speech processing. The SSL model is normally pre-trained on a great
variety of unlabelled data and a large model size is preferred to increase the
modeling capacity. However, this might limit its potential applications due to
the expensive computation and memory costs introduced by the oversize model.
Miniaturization for SSL models has become an important research direction of
practical value. To this end, we explore the effective distillation of
HuBERT-based SSL models for automatic speech recognition (ASR). First, in order
to establish a strong baseline, a comprehensive study on different student
model structures is conducted. On top of this, as a supplement to the
regression loss widely adopted in previous works, a discriminative loss is
introduced for HuBERT to enhance the distillation performance, especially in
low-resource scenarios. In addition, we design a simple and effective algorithm
to distill the front-end input from waveform to Fbank feature, resulting in 17%
parameter reduction and doubling inference speed, at marginal performance
degradation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PUnifiedNER: A Prompting-based Unified NER System for Diverse Datasets. (arXiv:2211.14838v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.14838">
<div class="article-summary-box-inner">
<span><p>Much of named entity recognition (NER) research focuses on developing
dataset-specific models based on data from the domain of interest, and a
limited set of related entity types. This is frustrating as each new dataset
requires a new model to be trained and stored. In this work, we present a
``versatile'' model -- the Prompting-based Unified NER system (PUnifiedNER) --
that works with data from different domains and can recognise up to 37 entity
types simultaneously, and theoretically it could be as many as possible. By
using prompt learning, PUnifiedNER is a novel approach that is able to jointly
train across multiple corpora, implementing intelligent on-demand entity
recognition. Experimental results show that PUnifiedNER leads to significant
prediction benefits compared to dataset-specific models with impressively
reduced model deployment costs. Furthermore, the performance of PUnifiedNER can
achieve competitive or even better performance than state-of-the-art
domain-specific methods for some datasets. We also perform comprehensive pilot
and ablation studies to support in-depth analysis of each component in
PUnifiedNER.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Bidirectional Action-Language Translation with Limited Supervision and Incongruent Input. (arXiv:2301.03353v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.03353">
<div class="article-summary-box-inner">
<span><p>Human infant learning happens during exploration of the environment, by
interaction with objects, and by listening to and repeating utterances
casually, which is analogous to unsupervised learning. Only occasionally, a
learning infant would receive a matching verbal description of an action it is
committing, which is similar to supervised learning. Such a learning mechanism
can be mimicked with deep learning. We model this weakly supervised learning
paradigm using our Paired Gated Autoencoders (PGAE) model, which combines an
action and a language autoencoder. After observing a performance drop when
reducing the proportion of supervised training, we introduce the Paired
Transformed Autoencoders (PTAE) model, using Transformer-based crossmodal
attention. PTAE achieves significantly higher accuracy in language-to-action
and action-to-language translations, particularly in realistic but difficult
cases when only few supervised training samples are available. We also test
whether the trained model behaves realistically with conflicting multimodal
input. In accordance with the concept of incongruence in psychology, conflict
deteriorates the model output. Conflicting action input has a more severe
impact than conflicting language input, and more conflicting features lead to
larger interference. PTAE can be trained on mostly unlabelled data where
labeled data is scarce, and it behaves plausibly when tested with incongruent
input.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring AI Ethics of ChatGPT: A Diagnostic Analysis. (arXiv:2301.12867v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.12867">
<div class="article-summary-box-inner">
<span><p>Recent breakthroughs in natural language processing (NLP) have permitted the
synthesis and comprehension of coherent text in an open-ended way, therefore
translating the theoretical algorithms into practical applications. The large
language-model (LLM) has significantly impacted businesses such as report
summarization softwares and copywriters. Observations indicate, however, that
LLMs may exhibit social prejudice and toxicity, posing ethical and societal
dangers of consequences resulting from irresponsibility. Large-scale benchmarks
for accountable LLMs should consequently be developed. Although several
empirical investigations reveal the existence of a few ethical difficulties in
advanced LLMs, there is no systematic examination and user study of the ethics
of current LLMs use. To further educate future efforts on constructing ethical
LLMs responsibly, we perform a qualitative research method on OpenAI's ChatGPT
to better understand the practical features of ethical dangers in recent LLMs.
We analyze ChatGPT comprehensively from four perspectives: 1) \textit{Bias} 2)
\textit{Reliability} 3) \textit{Robustness} 4) \textit{Toxicity}. In accordance
with our stated viewpoints, we empirically benchmark ChatGPT on multiple sample
datasets. We find that a significant number of ethical risks cannot be
addressed by existing benchmarks, and hence illustrate them via additional case
studies. In addition, we examine the implications of our findings on the AI
ethics of ChatGPT, as well as future problems and practical design
considerations for LLMs. We believe that our findings may give light on future
efforts to determine and mitigate the ethical hazards posed by machines in LLM
applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Study on the Transferability of Transformer Modules in Parameter-Efficient Fine-Tuning. (arXiv:2302.00378v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00378">
<div class="article-summary-box-inner">
<span><p>Parameter-efficient fine-tuning approaches have recently garnered a lot of
attention. Having considerably lower number of trainable weights, these methods
can bring about scalability and computational effectiveness. In this paper, we
look for optimal sub-networks and investigate the capability of different
transformer modules in transferring knowledge from a pre-trained model to a
downstream task. Our empirical results suggest that every transformer module in
BERT can act as a winning ticket: fine-tuning each specific module while
keeping the rest of the network frozen can lead to comparable performance to
the full fine-tuning. Among different modules, LayerNorms exhibit the best
capacity for knowledge transfer with limited trainable weights, to the extent
that, with only 0.003% of all parameters in the layer-wise analysis, they show
acceptable performance on various target tasks. On the reasons behind their
effectiveness, we argue that their notable performance could be attributed to
their high-magnitude weights compared to that of the other modules in the
pre-trained BERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CAB: Empathetic Dialogue Generation with Cognition, Affection and Behavior. (arXiv:2302.01935v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.01935">
<div class="article-summary-box-inner">
<span><p>Empathy is an important characteristic to be considered when building a more
intelligent and humanized dialogue agent. However, existing methods did not
fully comprehend empathy as a complex process involving three aspects:
cognition, affection and behavior. In this paper, we propose CAB, a novel
framework that takes a comprehensive perspective of cognition, affection and
behavior to generate empathetic responses. For cognition, we build paths
between critical keywords in the dialogue by leveraging external knowledge.
This is because keywords in a dialogue are the core of sentences. Building the
logic relationship between keywords, which is overlooked by the majority of
existing works, can improve the understanding of keywords and contextual logic,
thus enhance the cognitive ability. For affection, we capture the emotional
dependencies with dual latent variables that contain both interlocutors'
emotions. The reason is that considering both interlocutors' emotions
simultaneously helps to learn the emotional dependencies. For behavior, we use
appropriate dialogue acts to guide the dialogue generation to enhance the
empathy expression. Extensive experiments demonstrate that our
multi-perspective model outperforms the state-of-the-art models in both
automatic and manual evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Semantic Approach to Negation Detection and Word Disambiguation with Natural Language Processing. (arXiv:2302.02291v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.02291">
<div class="article-summary-box-inner">
<span><p>This study aims to demonstrate the methods for detecting negations in a
sentence by uniquely evaluating the lexical structure of the text via
word-sense disambiguation. The proposed framework examines all the unique
features in the various expressions within a text to resolve the contextual
usage of all tokens and decipher the effect of negation on sentiment analysis.
The application of popular expression detectors skips this important step,
thereby neglecting the root words caught in the web of negation and making text
classification difficult for machine learning and sentiment analysis. This
study adopts the Natural Language Processing (NLP) approach to discover and
antonimize words that were negated for better accuracy in text classification
using a knowledge base provided by an NLP library called WordHoard. Early
results show that our initial analysis improved on traditional sentiment
analysis, which sometimes neglects negations or assigns an inverse polarity
score. The SentiWordNet analyzer was improved by 35%, the Vader analyzer by 20%
and the TextBlob by 6%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RESDSQL: Decoupling Schema Linking and Skeleton Parsing for Text-to-SQL. (arXiv:2302.05965v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05965">
<div class="article-summary-box-inner">
<span><p>One of the recent best attempts at Text-to-SQL is the pre-trained language
model. Due to the structural property of the SQL queries, the seq2seq model
takes the responsibility of parsing both the schema items (i.e., tables and
columns) and the skeleton (i.e., SQL keywords). Such coupled targets increase
the difficulty of parsing the correct SQL queries especially when they involve
many schema items and logic operators. This paper proposes a ranking-enhanced
encoding and skeleton-aware decoding framework to decouple the schema linking
and the skeleton parsing. Specifically, for a seq2seq encoder-decode model, its
encoder is injected by the most relevant schema items instead of the whole
unordered ones, which could alleviate the schema linking effort during SQL
parsing, and its decoder first generates the skeleton and then the actual SQL
query, which could implicitly constrain the SQL parsing. We evaluate our
proposed framework on Spider and its three robustness variants: Spider-DK,
Spider-Syn, and Spider-Realistic. The experimental results show that our
framework delivers promising performance and robustness. Our code is available
at https://github.com/RUCKBReasoning/RESDSQL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What happens before and after: Multi-Event Commonsense in Event Coreference Resolution. (arXiv:2302.09715v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.09715">
<div class="article-summary-box-inner">
<span><p>Event coreference models cluster event mentions pertaining to the same
real-world event. Recent models rely on contextualized representations to
recognize coreference among lexically or contextually similar mentions.
However, models typically fail to leverage commonsense inferences, which is
particularly limiting for resolving lexically-divergent mentions. We propose a
model that extends event mentions with temporal commonsense inferences. Given a
complex sentence with multiple events, e.g., "The man killed his wife and got
arrested", with the target event "arrested", our model generates plausible
events that happen before the target event - such as "the police arrived", and
after it, such as "he was sentenced". We show that incorporating such
inferences into an existing event coreference model improves its performance,
and we analyze the coreferences in which such temporal knowledge is required.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-02-23 23:13:59.814439178 UTC">2023-02-23 23:13:59 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>