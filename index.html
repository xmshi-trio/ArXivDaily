<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-10-17T01:30:00Z">10-17</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding AI Cognition: A Neural Module for Inference Inspired by Human Memory Mechanisms. (arXiv:2310.09297v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09297">
<div class="article-summary-box-inner">
<span><p>How humans and machines make sense of current inputs for relation reasoning
and question-answering while putting the perceived information into context of
our past memories, has been a challenging conundrum in cognitive science and
artificial intelligence. Inspired by human brain's memory system and cognitive
architectures, we propose a PMI framework that consists of perception, memory
and inference components. Notably, the memory module comprises working and
long-term memory, with the latter endowed with a higher-order structure to
retain more accumulated knowledge and experiences. Through a differentiable
competitive write access, current perceptions update working memory, which is
later merged with long-term memory via outer product associations, averting
memory overflow and minimizing information conflicts. In the inference module,
relevant information is retrieved from two separate memory origins and
associatively integrated to attain a more comprehensive and precise
interpretation of current perceptions. We exploratively apply our PMI to
improve prevailing Transformers and CNN models on question-answering tasks like
bAbI-20k and Sort-of-CLEVR datasets, as well as relation calculation and image
classification tasks, and in each case, our PMI enhancements consistently
outshine their original counterparts significantly. Visualization analyses
reveal that memory consolidation, along with the interaction and integration of
information from diverse memory sources, substantially contributes to the model
effectiveness on inference tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ranking LLM-Generated Loop Invariants for Program Verification. (arXiv:2310.09342v1 [cs.PL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09342">
<div class="article-summary-box-inner">
<span><p>Synthesizing inductive loop invariants is fundamental to automating program
verification. In this work, we observe that Large Language Models (such as
gpt-3.5 or gpt-4) are capable of synthesizing loop invariants for a class of
programs in a 0-shot setting, yet require several samples to generate the
correct invariants. This can lead to a large number of calls to a program
verifier to establish an invariant. To address this issue, we propose a {\it
re-ranking} approach for the generated results of LLMs. We have designed a
ranker that can distinguish between correct inductive invariants and incorrect
attempts based on the problem definition. The ranker is optimized as a
contrastive ranker. Experimental results demonstrate that this re-ranking
mechanism significantly improves the ranking of correct invariants among the
generated candidates, leading to a notable reduction in the number of calls to
a verifier.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents. (arXiv:2310.09343v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09343">
<div class="article-summary-box-inner">
<span><p>Human-like chatbots necessitate the use of commonsense reasoning in order to
effectively comprehend and respond to implicit information present within
conversations. Achieving such coherence and informativeness in responses,
however, is a non-trivial task. Even for large language models (LLMs), the task
of identifying and aggregating key evidence within a single hop presents a
substantial challenge. This complexity arises because such evidence is
scattered across multiple turns in a conversation, thus necessitating
integration over multiple hops. Hence, our focus is to facilitate such
multi-hop reasoning over a dialogue context, namely dialogue chain-of-thought
(CoT) reasoning. To this end, we propose a knowledge distillation framework
that leverages LLMs as unreliable teachers and selectively distills consistent
and helpful rationales via alignment filters. We further present DOCTOR, a
DialOgue Chain-of-ThOught Reasoner that provides reliable CoT rationales for
response generation. We conduct extensive experiments to show that enhancing
dialogue agents with high-quality rationales from DOCTOR significantly improves
the quality of their responses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Domain Adaption for Neural Information Retrieval. (arXiv:2310.09350v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09350">
<div class="article-summary-box-inner">
<span><p>Neural information retrieval requires costly annotated data for each target
domain to be competitive. Synthetic annotation by query generation using Large
Language Models or rule-based string manipulation has been proposed as an
alternative, but their relative merits have not been analysed. In this paper,
we compare both methods head-to-head using the same neural IR architecture. We
focus on the BEIR benchmark, which includes test datasets from several domains
with no training data, and explore two scenarios: zero-shot, where the
supervised system is trained in a large out-of-domain dataset (MS-MARCO); and
unsupervised domain adaptation, where, in addition to MS-MARCO, the system is
fine-tuned in synthetic data from the target domain. Our results indicate that
Large Language Models outperform rule-based methods in all scenarios by a large
margin, and, more importantly, that unsupervised domain adaptation is effective
compared to applying a supervised IR system in a zero-shot fashion. In addition
we explore several sizes of open Large Language Models to generate synthetic
data and find that a medium-sized model suffices. Code and models are publicly
available for reproducibility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Computational Approach to Style in American Poetry. (arXiv:2310.09357v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09357">
<div class="article-summary-box-inner">
<span><p>We develop a quantitative method to assess the style of American poems and to
visualize a collection of poems in relation to one another. Qualitative poetry
criticism helped guide our development of metrics that analyze various
orthographic, syntactic, and phonemic features. These features are used to
discover comprehensive stylistic information from a poem's multi-layered latent
structure, and to compute distances between poems in this space. Visualizations
provide ready access to the analytical components. We demonstrate our method on
several collections of poetry, showing that it better delineates poetry style
than the traditional word-occurrence features that are used in typical text
analysis algorithms. Our method has potential applications to academic research
of texts, to research of the intuitive personal response to poetry, and to
making recommendations to readers based on their favorite poems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Surveying the Landscape of Text Summarization with Deep Learning: A Comprehensive Review. (arXiv:2310.09411v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09411">
<div class="article-summary-box-inner">
<span><p>In recent years, deep learning has revolutionized natural language processing
(NLP) by enabling the development of models that can learn complex
representations of language data, leading to significant improvements in
performance across a wide range of NLP tasks. Deep learning models for NLP
typically use large amounts of data to train deep neural networks, allowing
them to learn the patterns and relationships in language data. This is in
contrast to traditional NLP approaches, which rely on hand-engineered features
and rules to perform NLP tasks. The ability of deep neural networks to learn
hierarchical representations of language data, handle variable-length input
sequences, and perform well on large datasets makes them well-suited for NLP
applications. Driven by the exponential growth of textual data and the
increasing demand for condensed, coherent, and informative summaries, text
summarization has been a critical research area in the field of NLP. Applying
deep learning to text summarization refers to the use of deep neural networks
to perform text summarization tasks. In this survey, we begin with a review of
fashionable text summarization tasks in recent years, including extractive,
abstractive, multi-document, and so on. Next, we discuss most deep
learning-based models and their experimental results on these tasks. The paper
also covers datasets and data representation for summarization tasks. Finally,
we delve into the opportunities and challenges associated with summarization
tasks and their corresponding methodologies, aiming to inspire future research
efforts to advance the field further. A goal of our survey is to explain how
these methods differ in their requirements as understanding them is essential
for choosing a technique suited for a specific setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SALM: Speech-augmented Language Model with In-context Learning for Speech Recognition and Translation. (arXiv:2310.09424v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09424">
<div class="article-summary-box-inner">
<span><p>We present a novel Speech Augmented Language Model (SALM) with {\em
multitask} and {\em in-context} learning capabilities. SALM comprises a frozen
text LLM, a audio encoder, a modality adapter module, and LoRA layers to
accommodate speech input and associated task instructions. The unified SALM not
only achieves performance on par with task-specific Conformer baselines for
Automatic Speech Recognition (ASR) and Speech Translation (AST), but also
exhibits zero-shot in-context learning capabilities, demonstrated through
keyword-boosting task for ASR and AST. Moreover, {\em speech supervised
in-context training} is proposed to bridge the gap between LLM training and
downstream speech tasks, which further boosts the in-context learning ability
of speech-to-text models. Proposed model is open-sourced via NeMo toolkit.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Systematic Evaluation of Large Language Models on Out-of-Distribution Logical Reasoning Tasks. (arXiv:2310.09430v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09430">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs), such as GPT-3.5 and GPT-4, have greatly
advanced the performance of artificial systems on various natural language
processing tasks to human-like levels. However, their generalisation and
robustness to perform logical reasoning remain under-evaluated. To probe this
ability, we propose three new logical reasoning datasets named "ReClor-plus",
"LogiQA-plus" and "LogiQAv2-plus", each featuring three subsets: the first with
randomly shuffled options, the second with the correct choices replaced by
"none of the other options are correct", and a combination of the previous two
subsets. We carry out experiments on these datasets with both discriminative
and generative LLMs and show that these simple tricks greatly hinder the
performance of the language models. Despite their superior performance on the
original publicly available datasets, we find that all models struggle to
answer our newly constructed datasets. We show that introducing task variations
by perturbing a sizable training set can markedly improve the model's
generalisation and robustness in logical reasoning tasks. Moreover, applying
logic-driven data augmentation for fine-tuning, combined with prompting can
enhance the generalisation performance of both discriminative large language
models and generative large language models. These results offer insights into
assessing and improving the generalisation and robustness of large language
models for logical reasoning tasks. We make our source code and data publicly
available
\url{https://github.com/Strong-AI-Lab/Logical-and-abstract-reasoning}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing BERT-Based Visual Question Answering through Keyword-Driven Sentence Selection. (arXiv:2310.09432v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09432">
<div class="article-summary-box-inner">
<span><p>The Document-based Visual Question Answering competition addresses the
automatic detection of parent-child relationships between elements in
multi-page documents. The goal is to identify the document elements that answer
a specific question posed in natural language. This paper describes the
PoliTo's approach to addressing this task, in particular, our best solution
explores a text-only approach, leveraging an ad hoc sampling strategy.
Specifically, our approach leverages the Masked Language Modeling technique to
fine-tune a BERT model, focusing on sentences containing sensitive keywords
that also occur in the questions, such as references to tables or images.
Thanks to the effectiveness of this approach, we are able to achieve high
performance compared to baselines, demonstrating how our solution contributes
positively to this task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sub-network Discovery and Soft-masking for Continual Learning of Mixed Tasks. (arXiv:2310.09436v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09436">
<div class="article-summary-box-inner">
<span><p>Continual learning (CL) has two main objectives: preventing catastrophic
forgetting (CF) and encouraging knowledge transfer (KT). The existing
literature mainly focused on overcoming CF. Some work has also been done on KT
when the tasks are similar. To our knowledge, only one method has been proposed
to learn a sequence of mixed tasks. However, these techniques still suffer from
CF and/or limited KT. This paper proposes a new CL method to achieve both. It
overcomes CF by isolating the knowledge of each task via discovering a
subnetwork for it. A soft-masking mechanism is also proposed to preserve the
previous knowledge and to enable the new task to leverage the past knowledge to
achieve KT. Experiments using classification, generation, information
extraction, and their mixture (i.e., heterogeneous tasks) show that the
proposed method consistently outperforms strong baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Computational analyses of linguistic features with schizophrenic and autistic traits along with formal thought disorders. (arXiv:2310.09494v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09494">
<div class="article-summary-box-inner">
<span><p>[See full abstract in the pdf] Formal Thought Disorder (FTD), which is a
group of symptoms in cognition that affects language and thought, can be
observed through language. FTD is seen across such developmental or psychiatric
disorders as Autism Spectrum Disorder (ASD) or Schizophrenia, and its related
Schizotypal Personality Disorder (SPD). This paper collected a Japanese
audio-report dataset with score labels related to ASD and SPD through a
crowd-sourcing service from the general population. We measured language
characteristics with the 2nd edition of the Social Responsiveness Scale (SRS2)
and the Schizotypal Personality Questionnaire (SPQ), including an odd speech
subscale from SPQ to quantify the FTD symptoms. We investigated the following
four research questions through machine-learning-based score predictions: (RQ1)
How are schizotypal and autistic measures correlated? (RQ2) What is the most
suitable task to elicit FTD symptoms? (RQ3) Does the length of speech affect
the elicitation of FTD symptoms? (RQ4) Which features are critical for
capturing FTD symptoms? We confirmed that an FTD-related subscale, odd speech,
was significantly correlated with both the total SPQ and SRS scores, although
they themselves were not correlated significantly. Our regression analysis
indicated that longer speech about a negative memory elicited more FTD
symptoms. The ablation study confirmed the importance of function words and
both the abstract and temporal features for FTD-related odd speech estimation.
In contrast, content words were effective only in the SRS predictions, and
content words were effective only in the SPQ predictions, a result that implies
the differences between SPD-like and ASD-like symptoms. Data and programs used
in this paper can be found here:
https://sites.google.com/view/sagatake/resource.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models. (arXiv:2310.09499v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09499">
<div class="article-summary-box-inner">
<span><p>Various Large Language Models(LLMs) from the Generative Pretrained
Transformer~(GPT) family have achieved outstanding performances in a wide range
of text generation tasks. However, the enormous model sizes have hindered their
practical use in real-world applications due to high inference latency.
Therefore, improving the efficiencies of LLMs through quantization, pruning,
and other means has been a key issue in LLM studies. In this work, we propose a
method based on Hessian sensitivity-aware mixed sparsity pruning to prune LLMs
to at least 50\% sparsity without the need of any retraining. It allocates
sparsity adaptively based on sensitivity, allowing us to reduce pruning-induced
error while maintaining the overall sparsity level. The advantages of the
proposed method exhibit even more when the sparsity is extremely high.
Furthermore, our method is compatible with quantization, enabling further
compression of LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DepNeCTI: Dependency-based Nested Compound Type Identification for Sanskrit. (arXiv:2310.09501v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09501">
<div class="article-summary-box-inner">
<span><p>Multi-component compounding is a prevalent phenomenon in Sanskrit, and
understanding the implicit structure of a compound's components is crucial for
deciphering its meaning. Earlier approaches in Sanskrit have focused on binary
compounds and neglected the multi-component compound setting. This work
introduces the novel task of nested compound type identification (NeCTI), which
aims to identify nested spans of a multi-component compound and decode the
implicit semantic relations between them. To the best of our knowledge, this is
the first attempt in the field of lexical semantics to propose this task.
</p>
<p>We present 2 newly annotated datasets including an out-of-domain dataset for
this task. We also benchmark these datasets by exploring the efficacy of the
standard problem formulations such as nested named entity recognition,
constituency parsing and seq2seq, etc. We present a novel framework named
DepNeCTI: Dependency-based Nested Compound Type Identifier that surpasses the
performance of the best baseline with an average absolute improvement of 13.1
points F1-score in terms of Labeled Span Score (LSS) and a 5-fold enhancement
in inference efficiency. In line with the previous findings in the binary
Sanskrit compound identification task, context provides benefits for the NeCTI
task. The codebase and datasets are publicly available at:
https://github.com/yaswanth-iitkgp/DepNeCTI
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attentive Multi-Layer Perceptron for Non-autoregressive Generation. (arXiv:2310.09512v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09512">
<div class="article-summary-box-inner">
<span><p>Autoregressive~(AR) generation almost dominates sequence generation for its
efficacy. Recently, non-autoregressive~(NAR) generation gains increasing
popularity for its efficiency and growing efficacy. However, its efficiency is
still bottlenecked by quadratic complexity in sequence lengths, which is
prohibitive for scaling to long sequence generation and few works have been
done to mitigate this problem. In this paper, we propose a novel MLP variant,
\textbf{A}ttentive \textbf{M}ulti-\textbf{L}ayer \textbf{P}erceptron~(AMLP), to
produce a generation model with linear time and space complexity. Different
from classic MLP with static and learnable projection matrices, AMLP leverages
adaptive projections computed from inputs in an attentive mode. The
sample-aware adaptive projections enable communications among tokens in a
sequence, and model the measurement between the query and key space.
Furthermore, we marry AMLP with popular NAR models, deriving a highly efficient
NAR-AMLP architecture with linear time and space complexity. Empirical results
show that such marriage architecture surpasses competitive efficient NAR
models, by a significant margin on text-to-speech synthesis and machine
translation. We also test AMLP's self- and cross-attention ability separately
with extensive ablation experiments, and find them comparable or even superior
to the other efficient models. The efficiency analysis further shows that AMLP
extremely reduces the memory cost against vanilla non-autoregressive models for
long sequences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Instruction Tuning with Human Curriculum. (arXiv:2310.09518v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.09518">
<div class="article-summary-box-inner">
<span><p>The dominant paradigm for instruction tuning is the random-shuffled training
of maximally diverse instruction-response pairs. This paper explores the
potential benefits of applying a structured cognitive learning approach to
instruction tuning in contemporary large language models like ChatGPT and
GPT-4. Unlike the previous conventional randomized instruction dataset, we
propose a highly structured synthetic dataset that mimics the progressive and
organized nature of human education. We curate our dataset by aligning it with
educational frameworks, incorporating meta information including its topic and
cognitive rigor level for each sample. Our dataset covers comprehensive
fine-grained topics spanning diverse educational stages (from middle school to
graduate school) with various questions for each topic to enhance conceptual
depth using Bloom's taxonomy-a classification framework distinguishing various
levels of human cognition for each concept. The results demonstrate that this
cognitive rigorous training approach yields significant performance
enhancements - +3.06 on the MMLU benchmark and an additional +1.28 on AI2
Reasoning Challenge (hard set) - compared to conventional randomized training,
all while avoiding additional computational costs. This research highlights the
potential of leveraging human learning principles to enhance the capabilities
of language models in comprehending and responding to complex instructions and
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentiment Analysis Using Averaged Weighted Word Vector Features. (arXiv:2002.05606v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.05606">
<div class="article-summary-box-inner">
<span><p>People use the world wide web heavily to share their experience with entities
such as products, services, or travel destinations. Texts that provide online
feedback in the form of reviews and comments are essential to make consumer
decisions. These comments create a valuable source that may be used to measure
satisfaction related to products or services. Sentiment analysis is the task of
identifying opinions expressed in such text fragments. In this work, we develop
two methods that combine different types of word vectors to learn and estimate
polarity of reviews. We develop average review vectors from word vectors and
add weights to this review vectors using word frequencies in positive and
negative sensitivity-tagged reviews. We applied the methods to several datasets
from different domains that are used as standard benchmarks for sentiment
analysis. We ensemble the techniques with each other and existing methods, and
we make a comparison with the approaches in the literature. The results show
that the performances of our approaches outperform the state-of-the-art success
rates.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Temporal Convolutional Attention-based Network For Sequence Modeling. (arXiv:2002.12530v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.12530">
<div class="article-summary-box-inner">
<span><p>With the development of feed-forward models, the default model for sequence
modeling has gradually evolved to replace recurrent networks. Many powerful
feed-forward models based on convolutional networks and attention mechanism
were proposed and show more potential to handle sequence modeling tasks. We
wonder that is there an architecture that can not only achieve an approximate
substitution of recurrent network, but also absorb the advantages of
feed-forward models. So we propose an exploratory architecture referred to
Temporal Convolutional Attention-based Network (TCAN) which combines temporal
convolutional network and attention mechanism. TCAN includes two parts, one is
Temporal Attention (TA) which captures relevant features inside the sequence,
the other is Enhanced Residual (ER) which extracts shallow layer's important
information and transfers to deep layers. We improve the state-of-the-art
results of bpc/perplexity to 30.28 on word-level PTB, 1.092 on character-level
PTB, and 9.20 on WikiText-2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graphmax for Text Generation. (arXiv:2101.00153v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00153">
<div class="article-summary-box-inner">
<span><p>In text generation, a large language model (LM) makes a choice of each new
word based only on the former selection of its context using the softmax
function. Nevertheless, the link statistics information of concurrent words
based on a scene-specific corpus is valuable in choosing the next word, which
can help to ensure the topic of the generated text to be aligned with the
current task. To fully explore the co-occurrence information,we propose a
graphmax function for task-specific text generation. Using the graph-based
regularization, graphmax enables the final word choice to be determined by both
the global knowledge from the LM and the local knowledge from the
scene-specific corpus. The traditional softmax function is regularized with a
graph total variation (GTV) term, which incorporates the local knowledge into
the LM and encourages the model to consider the statistical relationships
between words in a scene-specific corpus. The proposed graphmax is versatile
and can be readily plugged into any large pre-trained LM for text generation
and machine translation. Through extensive experiments, we demonstrate that the
new GTV-based regularization can improve performances in various natural
language processing tasks in comparison with existing methods. Moreover,
through human experiments, we observe that participants can easily distinguish
the text generated by graphmax or softmax.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counterfactual Memorization in Neural Language Models. (arXiv:2112.12938v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12938">
<div class="article-summary-box-inner">
<span><p>Modern neural language models that are widely used in various NLP tasks risk
memorizing sensitive information from their training data. Understanding this
memorization is important in real world applications and also from a
learning-theoretical perspective. An open question in previous studies of
language model memorization is how to filter out "common" memorization. In
fact, most memorization criteria strongly correlate with the number of
occurrences in the training set, capturing memorized familiar phrases, public
knowledge, templated texts, or other repeated data. We formulate a notion of
counterfactual memorization which characterizes how a model's predictions
change if a particular document is omitted during training. We identify and
study counterfactually-memorized training examples in standard text datasets.
We estimate the influence of each memorized training example on the validation
set and on generated texts, showing how this can provide direct evidence of the
source of memorization at test time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speculative Decoding: Lossless Speedup of Autoregressive Translation. (arXiv:2203.16487v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.16487">
<div class="article-summary-box-inner">
<span><p>Different from some previous work accelerating autoregressive translation
(AT) at the sacrifice of quality, we propose Speculative Decoding (SpecDec) --
a novel decoding paradigm inspired by speculative execution in computer
architecture, which combines respective advantages of AT and non-autoregressive
translation (NAT) for lossless speedup of translation. At each decoding step,
SpecDec first speculatively drafts (i.e. decodes) next $k$ tokens with an NAT
model and then verifies them with an AT model, where only the drafted tokens
passing the verification are accepted as decoded tokens for guaranteeing its
translation result is exactly the same as AT. The collaboration of NAT drafting
and AT verification leads to a much higher decoding speed without quality loss
due to parallel computing enabled by speculative decoding.
</p>
<p>We conduct experiments in 4 standard WMT translation benchmarks and confirm
the vanilla SpecDec yields exactly the same results as AT greedy decoding with
an around $3\times$ speedup, and that its variant (SpecDec++) with an advanced
verification strategy not only outperforms AT greedy decoding, but also further
improves the decoding speed, resulting in an around $5\times$ speedup over AT.
Moreover, SpecDec can be easily generalized for speeding up other seq2seq tasks
like Abstractive Summarization, and benefit more from stronger computing
devices, demonstrating its potential to become a \textit{de facto} decoding
standard in the future for efficient and lossless seq2seq generation. We will
release all our codes and checkpoints to facilitate reproducing our results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Labeling Programs with Non-Programmers Indirectly via Active Examples: A Case Study with Text-to-SQL. (arXiv:2205.12422v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12422">
<div class="article-summary-box-inner">
<span><p>Can non-programmers annotate natural language utterances with complex
programs that represent their meaning? We introduce APEL, a framework in which
non-programmers select among candidate programs generated by a seed semantic
parser (e.g., Codex). Since they cannot understand the candidate programs, we
ask them to select indirectly by examining the programs' input-ouput examples.
For each utterance, APEL actively searches for a simple input on which the
candidate programs tend to produce different outputs. It then asks the
non-programmers only to choose the appropriate output, thus allowing us to
infer which program is correct and could be used to fine-tune the parser. As a
first case study, we recruited human non-programmers to use APEL to re-annotate
SPIDER, a text-to-SQL dataset. Our approach achieved the same annotation
accuracy as the original expert annotators (75%) and exposed many subtle errors
in the original annotations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">5q032e@SMM4H'22: Transformer-based classification of premise in tweets related to COVID-19. (arXiv:2209.03851v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.03851">
<div class="article-summary-box-inner">
<span><p>Automation of social network data assessment is one of the classic challenges
of natural language processing. During the COVID-19 pandemic, mining people's
stances from public messages have become crucial regarding understanding
attitudes towards health orders. In this paper, the authors propose the
predictive model based on transformer architecture to classify the presence of
premise in Twitter texts. This work is completed as part of the Social Media
Mining for Health (SMM4H) Workshop 2022. We explored modern transformer-based
classifiers in order to construct the pipeline efficiently capturing tweets
semantics. Our experiments on a Twitter dataset showed that RoBERTa is superior
to the other transformer models in the case of the premise prediction task. The
model achieved competitive performance with respect to ROC AUC value 0.807, and
0.7648 for the F1 score.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficiently Enhancing Zero-Shot Performance of Instruction Following Model via Retrieval of Soft Prompt. (arXiv:2210.03029v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.03029">
<div class="article-summary-box-inner">
<span><p>Enhancing the zero-shot performance of instruction-following models requires
heavy computation, either by scaling the total number of training datasets or
the model size. In this work, we explore how retrieval of soft prompts obtained
through prompt tuning can efficiently assist hard prompts in zero-shot task
generalization. Specifically, we train soft prompt embeddings for each prompt
through prompt tuning, store the samples of the training instances mapped with
the prompt embeddings, and retrieve the corresponding prompt embedding of the
training instance closest to the query instance during inference. While only
adding 0.007% additional parameters, retrieval of soft prompt enhances the
performance of T0 on unseen tasks by outperforming it on 10 out of 11 datasets
as well as improving the mean accuracy of T0 on BIG-bench benchmark by 2.39%
points. Also, we report an interesting finding that retrieving source
embeddings trained on similar answer choice formats is more important than
those on similar task types.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mind the Labels: Describing Relations in Knowledge Graphs With Pretrained Models. (arXiv:2210.07373v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07373">
<div class="article-summary-box-inner">
<span><p>Pretrained language models (PLMs) for data-to-text (D2T) generation can use
human-readable data labels such as column headings, keys, or relation names to
generalize to out-of-domain examples. However, the models are well-known in
producing semantically inaccurate outputs if these labels are ambiguous or
incomplete, which is often the case in D2T datasets. In this paper, we expose
this issue on the task of descibing a relation between two entities. For our
experiments, we collect a novel dataset for verbalizing a diverse set of 1,522
unique relations from three large-scale knowledge graphs (Wikidata, DBPedia,
YAGO). We find that although PLMs for D2T generation expectedly fail on unclear
cases, models trained with a large variety of relation labels are surprisingly
robust in verbalizing novel, unseen relations. We argue that using data with a
diverse set of clear and meaningful labels is key to training D2T generation
systems capable of generalizing to novel domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Graph Embedding: A Survey from the Perspective of Representation Spaces. (arXiv:2211.03536v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.03536">
<div class="article-summary-box-inner">
<span><p>Knowledge graph embedding (KGE) is an increasingly popular technique that
aims to represent entities and relations of knowledge graphs into
low-dimensional semantic spaces for a wide spectrum of applications such as
link prediction, knowledge reasoning and knowledge completion. In this paper,
we provide a systematic review of existing KGE techniques based on
representation spaces. Particularly, we build a fine-grained classification to
categorise the models based on three mathematical perspectives of the
representation spaces: (1) Algebraic perspective, (2) Geometric perspective,
and (3) Analytical perspective. We introduce the rigorous definitions of
fundamental mathematical spaces before diving into KGE models and their
mathematical properties. We further discuss different KGE methods over the
three categories, as well as summarise how spatial advantages work over
different embedding needs. By collating the experimental results from
downstream tasks, we also explore the advantages of mathematical space in
different scenarios and the reasons behind them. We further state some
promising research directions from a representation space perspective, with
which we hope to inspire researchers to design their KGE models as well as
their related applications with more consideration of their mathematical space
properties.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bidirectional Representations for Low Resource Spoken Language Understanding. (arXiv:2211.14320v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.14320">
<div class="article-summary-box-inner">
<span><p>Most spoken language understanding systems use a pipeline approach composed
of an automatic speech recognition interface and a natural language
understanding module. This approach forces hard decisions when converting
continuous inputs into discrete language symbols. Instead, we propose a
representation model to encode speech in rich bidirectional encodings that can
be used for downstream tasks such as intent prediction. The approach uses a
masked language modelling objective to learn the representations, and thus
benefits from both the left and right contexts. We show that the performance of
the resulting encodings before fine-tuning is better than comparable models on
multiple datasets, and that fine-tuning the top layers of the representation
model improves the current state of the art on the Fluent Speech Command
dataset, also in a low-data regime, when a limited amount of labelled data is
used for training. Furthermore, we propose class attention as a spoken language
understanding module, efficient both in terms of speed and number of
parameters. Class attention can be used to visually explain the predictions of
our model, which goes a long way in understanding how the model makes
predictions. We perform experiments in English and in Dutch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Cloze to Comprehension: Retrofitting Pre-trained Masked Language Model to Pre-trained Machine Reader. (arXiv:2212.04755v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.04755">
<div class="article-summary-box-inner">
<span><p>We present Pre-trained Machine Reader (PMR), a novel method for retrofitting
pre-trained masked language models (MLMs) to pre-trained machine reading
comprehension (MRC) models without acquiring labeled data. PMR can resolve the
discrepancy between model pre-training and downstream fine-tuning of existing
MLMs. To build the proposed PMR, we constructed a large volume of
general-purpose and high-quality MRC-style training data by using Wikipedia
hyperlinks and designed a Wiki Anchor Extraction task to guide the MRC-style
pre-training. Apart from its simplicity, PMR effectively solves extraction
tasks, such as Extractive Question Answering and Named Entity Recognition. PMR
shows tremendous improvements over existing approaches, especially in
low-resource scenarios. When applied to the sequence classification task in the
MRC formulation, PMR enables the extraction of high-quality rationales to
explain the classification process, thereby providing greater prediction
explainability. PMR also has the potential to serve as a unified model for
tackling various extraction and classification tasks in the MRC formulation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extending TrOCR for Text Localization-Free OCR of Full-Page Scanned Receipt Images. (arXiv:2212.05525v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.05525">
<div class="article-summary-box-inner">
<span><p>Digitization of scanned receipts aims to extract text from receipt images and
save it into structured documents. This is usually split into two sub-tasks:
text localization and optical character recognition (OCR). Most existing OCR
models only focus on the cropped text instance images, which require the
bounding box information provided by a text region detection model. Introducing
an additional detector to identify the text instance images in advance adds
complexity, however instance-level OCR models have very low accuracy when
processing the whole image for the document-level OCR, such as receipt images
containing multiple text lines arranged in various layouts. To this end, we
propose a localization-free document-level OCR model for transcribing all the
characters in a receipt image into an ordered sequence end-to-end.
Specifically, we finetune the pretrained instance-level model TrOCR with
randomly cropped image chunks, and gradually increase the image chunk size to
generalize the recognition ability from instance images to full-page images. In
our experiments on the SROIE receipt OCR dataset, the model finetuned with our
strategy achieved 64.4 F1-score and a 22.8% character error rate (CER),
respectively, which outperforms the baseline results with 48.5 F1-score and
50.6% CER. The best model, which splits the full image into 15 equally sized
chunks, gives 87.8 F1-score and 4.98% CER with minimal additional pre or
post-processing of the output. Moreover, the characters in the generated
document-level sequences are arranged in the reading order, which is practical
for real-world applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Momentum Contrastive Pre-training for Question Answering. (arXiv:2212.05762v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.05762">
<div class="article-summary-box-inner">
<span><p>Existing pre-training methods for extractive Question Answering (QA) generate
cloze-like queries different from natural questions in syntax structure, which
could overfit pre-trained models to simple keyword matching. In order to
address this problem, we propose a novel Momentum Contrastive pRe-training fOr
queStion anSwering (MCROSS) method for extractive QA. Specifically, MCROSS
introduces a momentum contrastive learning framework to align the answer
probability between cloze-like and natural query-passage sample pairs. Hence,
the pre-trained models can better transfer the knowledge learned in cloze-like
samples to answering natural questions. Experimental results on three
benchmarking QA datasets show that our method achieves noticeable improvement
compared with all baselines in both supervised and zero-shot scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Improving Summarization Factual Consistency from Natural Language Feedback. (arXiv:2212.09968v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09968">
<div class="article-summary-box-inner">
<span><p>Despite the recent progress in language generation models, their outputs may
not always meet user expectations. In this work, we study whether informational
feedback in natural language can be leveraged to improve generation quality and
user preference alignment. To this end, we consider factual consistency in
summarization, the quality that the summary should only contain information
supported by the input documents, as the user-expected preference. We collect a
high-quality dataset, DeFacto, containing human demonstrations and
informational natural language feedback consisting of corrective instructions,
edited summaries, and explanations with respect to the factual consistency of
the summary. Using our dataset, we study three natural language generation
tasks: (1) editing a summary by following the human feedback, (2) generating
human feedback for editing the original summary, and (3) revising the initial
summary to correct factual errors by generating both the human feedback and
edited summary. We show that DeFacto can provide factually consistent
human-edited summaries and further insights into summarization factual
consistency thanks to its informational natural language feedback. We further
demonstrate that fine-tuned language models can leverage our dataset to improve
the summary factual consistency, while large language models lack the zero-shot
learning ability in our proposed tasks that require controllable text
generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does Localization Inform Editing? Surprising Differences in Causality-Based Localization vs. Knowledge Editing in Language Models. (arXiv:2301.04213v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.04213">
<div class="article-summary-box-inner">
<span><p>Language models learn a great quantity of factual information during
pretraining, and recent work localizes this information to specific model
weights like mid-layer MLP weights. In this paper, we find that we can change
how a fact is stored in a model by editing weights that are in a different
location than where existing methods suggest that the fact is stored. This is
surprising because we would expect that localizing facts to specific model
parameters would tell us where to manipulate knowledge in models, and this
assumption has motivated past work on model editing methods. Specifically, we
show that localization conclusions from representation denoising (also known as
Causal Tracing) do not provide any insight into which model MLP layer would be
best to edit in order to override an existing stored fact with a new one. This
finding raises questions about how past work relies on Causal Tracing to select
which model layers to edit. Next, we consider several variants of the editing
problem, including erasing and amplifying facts. For one of our editing
problems, editing performance does relate to localization results from
representation denoising, but we find that which layer we edit is a far better
predictor of performance. Our results suggest, counterintuitively, that better
mechanistic understanding of how pretrained language models work may not always
translate to insights about how to best change their behavior. Our code is
available at https://github.com/google/belief-localization
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models. (arXiv:2301.10472v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10472">
<div class="article-summary-box-inner">
<span><p>Large multilingual language models typically rely on a single vocabulary
shared across 100+ languages. As these models have increased in parameter count
and depth, vocabulary size has remained largely unchanged. This
\textit{vocabulary bottleneck} limits the representational capabilities of
multilingual models like XLM-R. In this paper, we introduce a new approach for
scaling to very large multilingual vocabularies by de-emphasizing token sharing
between languages with little lexical overlap and assigning vocabulary capacity
to achieve sufficient coverage for each individual language. Tokenizations
using our vocabulary are typically more semantically meaningful and shorter
compared to XLM-R. Leveraging this improved vocabulary, we train XLM-V, a
multilingual language model with a one million token vocabulary. XLM-V
outperforms XLM-R on every task we tested on ranging from natural language
inference (XNLI), question answering (MLQA, XQuAD, TyDiQA), to named entity
recognition (WikiAnn). XLM-V is particularly effective on low-resource language
tasks and outperforms XLM-R by 11.2% and 5.8% absolute on MasakhaNER and
Americas NLI, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Type-Aware Decomposed Framework for Few-Shot Named Entity Recognition. (arXiv:2302.06397v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.06397">
<div class="article-summary-box-inner">
<span><p>Despite the recent success achieved by several two-stage prototypical
networks in few-shot named entity recognition (NER) task, the overdetected
false spans at the span detection stage and the inaccurate and unstable
prototypes at the type classification stage remain to be challenging problems.
In this paper, we propose a novel Type-Aware Decomposed framework, namely
TadNER, to solve these problems. We first present a type-aware span filtering
strategy to filter out false spans by removing those semantically far away from
type names. We then present a type-aware contrastive learning strategy to
construct more accurate and stable prototypes by jointly exploiting support
samples and type names as references. Extensive experiments on various
benchmarks prove that our proposed TadNER framework yields a new
state-of-the-art performance. Our code and data will be available at
https://github.com/NLPWM-WHU/TadNER.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FinXABSA: Explainable Finance through Aspect-Based Sentiment Analysis. (arXiv:2303.02563v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.02563">
<div class="article-summary-box-inner">
<span><p>This paper presents a novel approach for explainability in financial analysis
by deriving financially-explainable statistical relationships through
aspect-based sentiment analysis, Pearson correlation, Granger causality &amp;
uncertainty coefficient. The proposed methodology involves constructing an
aspect list from financial literature and applying aspect-based sentiment
analysis on social media text to compute sentiment scores for each aspect.
Pearson correlation is then applied to uncover financially explainable
relationships between aspect sentiment scores and stock prices. Findings for
derived relationships are made robust by applying Granger causality to
determine the forecasting ability of each aspect sentiment score for stock
prices. Finally, an added layer of interpretability is added by evaluating
uncertainty coefficient scores between aspect sentiment scores and stock
prices. This allows us to determine the aspects whose sentiment scores are most
statistically significant for stock prices. Relative to other methods, our
approach provides a more informative and accurate understanding of the
relationship between sentiment analysis and stock prices. Specifically, this
methodology enables an interpretation of the statistical relationship between
aspect-based sentiment scores and stock prices, which offers explainability to
AI-driven financial decision-making.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Transformers Parse while Predicting the Masked Word?. (arXiv:2303.08117v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.08117">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models have been shown to encode linguistic structures,
e.g. dependency and constituency parse trees, in their embeddings while being
trained on unsupervised loss functions like masked language modeling. Some
doubts have been raised whether the models actually are doing parsing or only
some computation weakly correlated with it. We study questions: (a) Is it
possible to explicitly describe transformers with realistic embedding
dimension, number of heads, etc. that are capable of doing parsing -- or even
approximate parsing? (b) Why do pre-trained models capture parsing structure?
This paper takes a step toward answering these questions in the context of
generative modeling with PCFGs. We show that masked language models like BERT
or RoBERTa of moderate sizes can approximately execute the Inside-Outside
algorithm for the English PCFG [Marcus et al, 1993]. We also show that the
Inside-Outside algorithm is optimal for masked language modeling loss on the
PCFG-generated data. We also give a construction of transformers with $50$
layers, $15$ attention heads, and $1275$ dimensional embeddings in average such
that using its embeddings it is possible to do constituency parsing with
$&gt;70\%$ F1 score on PTB dataset. We conduct probing experiments on models
pre-trained on PCFG-generated data to show that this not only allows recovery
of approximate parse tree, but also recovers marginal span probabilities
computed by the Inside-Outside algorithm, which suggests an implicit bias of
masked language modeling towards this algorithm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Scope of In-Context Learning for the Extraction of Medical Temporal Constraints. (arXiv:2303.09366v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09366">
<div class="article-summary-box-inner">
<span><p>Medications often impose temporal constraints on everyday patient activity.
Violations of such medical temporal constraints (MTCs) lead to a lack of
treatment adherence, in addition to poor health outcomes and increased
healthcare expenses. These MTCs are found in drug usage guidelines (DUGs) in
both patient education materials and clinical texts. Computationally
representing MTCs in DUGs will advance patient-centric healthcare applications
by helping to define safe patient activity patterns. We define a novel taxonomy
of MTCs found in DUGs and develop a novel context-free grammar (CFG) based
model to computationally represent MTCs from unstructured DUGs. Additionally,
we release three new datasets with a combined total of N = 836 DUGs labeled
with normalized MTCs. We develop an in-context learning (ICL) solution for
automatically extracting and normalizing MTCs found in DUGs, achieving an
average F1 score of 0.62 across all datasets. Finally, we rigorously
investigate ICL model performance against a baseline model, across datasets and
MTC types, and through in-depth error analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Architecture Search for Effective Teacher-Student Knowledge Transfer in Language Models. (arXiv:2303.09639v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.09639">
<div class="article-summary-box-inner">
<span><p>Large pretrained language models have achieved state-of-the-art results on a
variety of downstream tasks. Knowledge Distillation (KD) into a smaller student
model addresses their inefficiency, allowing for deployment in
resource-constrained environments. However, KD can be ineffective when the
student is manually selected from a set of existing options, since it can be a
sub-optimal choice within the space of all possible student architectures. We
develop multilingual KD-NAS, the use of Neural Architecture Search (NAS) guided
by KD to find the optimal student architecture for task agnostic distillation
from a multilingual teacher. In each episode of the search process, a NAS
controller predicts a reward based on the distillation loss and latency of
inference. The top candidate architectures are then distilled from the teacher
on a small proxy set. Finally the architecture(s) with the highest reward is
selected, and distilled on the full training corpus. KD-NAS can automatically
trade off efficiency and effectiveness, and recommends architectures suitable
to various latency budgets. Using our multi-layer hidden state distillation
process, our KD-NAS student model achieves a 7x speedup on CPU inference (2x on
GPU) compared to a XLM-Roberta Base Teacher, while maintaining 90% performance,
and has been deployed in 3 software offerings requiring large throughput, low
latency and deployment on CPU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Making the Most of ChatGPT for Machine Translation. (arXiv:2303.13780v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.13780">
<div class="article-summary-box-inner">
<span><p>ChatGPT shows remarkable capabilities for machine translation (MT). Several
prior studies have shown that it achieves comparable results to commercial
systems for high-resource languages, but lags behind in complex tasks, e.g.,
low-resource and distant-language-pairs translation. However, they usually
adopt simple prompts which can not fully elicit the capability of ChatGPT. In
this paper, we aim to further mine ChatGPT's translation ability by revisiting
several aspects: temperature, task information, and domain information, and
correspondingly propose an optimal temperature setting and two (simple but
effective) prompts: Task-Specific Prompts (TSP) and Domain-Specific Prompts
(DSP). We show that: 1) The performance of ChatGPT depends largely on
temperature, and a lower temperature usually can achieve better performance; 2)
Emphasizing the task information can further improve ChatGPT's performance,
particularly in complex MT tasks; 3) Introducing domain information can elicit
ChatGPT's generalization ability and improve its performance in the specific
domain; 4) ChatGPT tends to generate hallucinations for non-English-centric MT
tasks, which can be partially addressed by our proposed prompts but still need
to be highlighted for the MT/NLP community. We also explore the effects of
advanced in-context learning strategies and find a (negative but interesting)
observation: the powerful chain-of-thought prompt leads to word-by-word
translation behavior, thus bringing significant translation degradation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Manifold Learning for Reading Comprehension and Logical Reasoning Tasks with Polytuplet Loss. (arXiv:2304.01046v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.01046">
<div class="article-summary-box-inner">
<span><p>The current trend in developing machine learning models for reading
comprehension and logical reasoning tasks is focused on improving the models'
abilities to understand and utilize logical rules. This work focuses on
providing a novel loss function and accompanying model architecture that has
more interpretable components than some other models by representing a common
strategy employed by humans when given reading comprehension and logical
reasoning tasks. Our strategy involves emphasizing relative accuracy over
absolute accuracy and can theoretically produce the correct answer with
incomplete knowledge. We examine the effectiveness of this strategy to solve
reading comprehension and logical reasoning questions. The models were
evaluated on the ReClor dataset, a challenging reading comprehension and
logical reasoning benchmark. We propose the polytuplet loss function, which
forces prioritization of learning the relative correctness of answer choices
over learning the true accuracy of each choice. Our results indicate that
models employing polytuplet loss outperform existing baseline models, though
further research is required to quantify the benefits it may present.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Unified Contrastive Transfer Framework with Propagation Structure for Boosting Low-Resource Rumor Detection. (arXiv:2304.01492v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.01492">
<div class="article-summary-box-inner">
<span><p>The truth is significantly hampered by massive rumors that spread along with
breaking news or popular topics. Since there is sufficient corpus gathered from
the same domain for model training, existing rumor detection algorithms show
promising performance on yesterday's news. However, due to a lack of
substantial training data and prior expert knowledge, they are poor at spotting
rumors concerning unforeseen events, especially those propagated in different
languages (i.e., low-resource regimes). In this paper, we propose a unified
contrastive transfer framework to detect rumors by adapting the features
learned from well-resourced rumor data to that of the low-resourced with only
few-shot annotations. More specifically, we first represent rumor circulated on
social media as an undirected topology for enhancing the interaction of user
opinions, and then train a Multi-scale Graph Convolutional Network via a
unified contrastive paradigm to mine effective clues simultaneously from post
semantics and propagation structure. Our model explicitly breaks the barriers
of the domain and/or language issues, via language alignment and a novel
domain-adaptive contrastive learning mechanism. To well-generalize the
representation learning using a small set of annotated target events, we reveal
that rumor-indicative signal is closely correlated with the uniformity of the
distribution of these events. We design a target-wise contrastive training
mechanism with three event-level data augmentation strategies, capable of
unifying the representations by distinguishing target events. Extensive
experiments conducted on four low-resource datasets collected from real-world
microblog platforms demonstrate that our framework achieves much better
performance than state-of-the-art methods and exhibits a superior capacity for
detecting rumors at early stages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bridging Discrete and Backpropagation: Straight-Through and Beyond. (arXiv:2304.08612v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.08612">
<div class="article-summary-box-inner">
<span><p>Backpropagation, the cornerstone of deep learning, is limited to computing
gradients for continuous variables. This limitation poses challenges for
problems involving discrete latent variables. To address this issue, we propose
a novel approach to approximate the gradient of parameters involved in
generating discrete latent variables. First, we examine the widely used
Straight-Through (ST) heuristic and demonstrate that it works as a first-order
approximation of the gradient. Guided by our findings, we propose ReinMax,
which achieves second-order accuracy by integrating Heun's method, a
second-order numerical method for solving ODEs. ReinMax does not require
Hessian or other second-order derivatives, thus having negligible computation
overheads. Extensive experimental results on various tasks demonstrate the
superiority of ReinMax over the state of the art. Implementations are released
at https://github.com/microsoft/ReinMax.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dissecting Recall of Factual Associations in Auto-Regressive Language Models. (arXiv:2304.14767v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.14767">
<div class="article-summary-box-inner">
<span><p>Transformer-based language models (LMs) are known to capture factual
knowledge in their parameters. While previous work looked into where factual
associations are stored, only little is known about how they are retrieved
internally during inference. We investigate this question through the lens of
information flow. Given a subject-relation query, we study how the model
aggregates information about the subject and relation to predict the correct
attribute. With interventions on attention edges, we first identify two
critical points where information propagates to the prediction: one from the
relation positions followed by another from the subject positions. Next, by
analyzing the information at these points, we unveil a three-step internal
mechanism for attribute extraction. First, the representation at the
last-subject position goes through an enrichment process, driven by the early
MLP sublayers, to encode many subject-related attributes. Second, information
from the relation propagates to the prediction. Third, the prediction
representation "queries" the enriched subject to extract the attribute. Perhaps
surprisingly, this extraction is typically done via attention heads, which
often encode subject-attribute mappings in their parameters. Overall, our
findings introduce a comprehensive view of how factual associations are stored
and extracted internally in LMs, facilitating future research on knowledge
localization and editing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Previously Fact-Checked Claim Retrieval. (arXiv:2305.07991v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07991">
<div class="article-summary-box-inner">
<span><p>Fact-checkers are often hampered by the sheer amount of online content that
needs to be fact-checked. NLP can help them by retrieving already existing
fact-checks relevant to the content being investigated. This paper introduces a
new multilingual dataset -- MultiClaim -- for previously fact-checked claim
retrieval. We collected 28k posts in 27 languages from social media, 206k
fact-checks in 39 languages written by professional fact-checkers, as well as
31k connections between these two groups. This is the most extensive and the
most linguistically diverse dataset of this kind to date. We evaluated how
different unsupervised methods fare on this dataset and its various dimensions.
We show that evaluating such a diverse dataset has its complexities and proper
care needs to be taken before interpreting the results. We also evaluated a
supervised fine-tuning approach, improving upon the unsupervised method
significantly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SuperDialseg: A Large-scale Dataset for Supervised Dialogue Segmentation. (arXiv:2305.08371v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.08371">
<div class="article-summary-box-inner">
<span><p>Dialogue segmentation is a crucial task for dialogue systems allowing a
better understanding of conversational texts. Despite recent progress in
unsupervised dialogue segmentation methods, their performances are limited by
the lack of explicit supervised signals for training. Furthermore, the precise
definition of segmentation points in conversations still remains as a
challenging problem, increasing the difficulty of collecting manual
annotations. In this paper, we provide a feasible definition of dialogue
segmentation points with the help of document-grounded dialogues and release a
large-scale supervised dataset called SuperDialseg, containing 9,478 dialogues
based on two prevalent document-grounded dialogue corpora, and also inherit
their useful dialogue-related annotations. Moreover, we provide a benchmark
including 18 models across five categories for the dialogue segmentation task
with several proper evaluation metrics. Empirical studies show that supervised
learning is extremely effective in in-domain datasets and models trained on
SuperDialseg can achieve good generalization ability on out-of-domain data.
Additionally, we also conducted human verification on the test set and the
Kappa score confirmed the quality of our automatically constructed dataset. We
believe our work is an important step forward in the field of dialogue
segmentation. Our codes and data can be found from:
https://github.com/Coldog2333/SuperDialseg.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Memorization for Good: Encryption with Autoregressive Language Models. (arXiv:2305.10445v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10445">
<div class="article-summary-box-inner">
<span><p>Over-parameterized neural language models (LMs) can memorize and recite long
sequences of training data. While such memorization is normally associated with
undesired properties such as overfitting and information leaking, our work
casts memorization as an unexplored capability of LMs. We propose the first
symmetric encryption algorithm with autoregressive language models (SELM). We
show that autoregressive LMs can encode arbitrary data into a compact
real-valued vector (i.e., encryption) and then losslessly decode the vector to
the original message (i.e., decryption) via random subspace optimization and
greedy decoding. While SELM is not amenable to conventional cryptanalysis, we
investigate its security through a novel empirical variant of the classic
IND-CPA (indistinguishability under chosen-plaintext attack) game and show
promising results on security. Our code and datasets are available at
https://github.com/OSU-NLP-Group/SELM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HaSa: Hardness and Structure-Aware Contrastive Knowledge Graph Embedding. (arXiv:2305.10563v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10563">
<div class="article-summary-box-inner">
<span><p>We consider a contrastive learning approach to knowledge graph embedding
(KGE) via InfoNCE. For KGE, efficient learning relies on augmenting the
training data with negative triples. However, most KGE works overlook the bias
from generating the negative triples-false negative triples (factual triples
missing from the knowledge graph). We argue that the generation of high-quality
(i.e., hard) negative triples might lead to an increase in false negative
triples. To mitigate the impact of false negative triples during the generation
of hard negative triples, we propose the Hardness and Structure-aware
(\textbf{HaSa}) contrastive KGE method, which alleviates the effect of false
negative triples while generating the hard negative triples. Experiments show
that HaSa improves the performance of InfoNCE-based KGE approaches and achieves
state-of-the-art results in several metrics for WN18RR datasets and competitive
results for FB15k-237 datasets compared to both classic and pre-trained
LM-based KGE methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and Generation. (arXiv:2305.11490v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11490">
<div class="article-summary-box-inner">
<span><p>Following the impressive development of LLMs, vision-language alignment in
LLMs is actively being researched to enable multimodal reasoning and visual IO.
This direction of research is particularly relevant to medical imaging because
medical image analysis and generation consist of reasoning based on a
combination of visual features and prior knowledge. Many recent works have
focused on training adapter networks that serve as an information bridge
between image processing networks and LLMs; but presumably, in order to achieve
maximum reasoning potential of LLMs on visual information as well, visual and
language features should be allowed to interact more freely. This is especially
important in the medical domain because understanding and generating medical
images such as chest X-rays (CXR) require not only accurate visual and
language-based reasoning but also a more intimate mapping between the two
modalities. Thus, taking inspiration from previous work on the transformer and
VQ-GAN combination for bidirectional image and text generation, we build upon
this approach and develop a method for instruction-tuning an LLM pre-trained
only on text to gain vision-language capabilities for medical images.
Specifically, we leverage a pretrained LLM's existing question-answering and
instruction-following abilities to teach it to understand visual inputs by
instructing it to answer questions about image inputs and, symmetrically,
output both text and image responses appropriate to a given query by tuning the
LLM with diverse tasks that encompass image-based text-generation and
text-based image-generation. We show that our model, LLM-CXR, trained in this
approach shows better image-text alignment in both CXR understanding and
generation tasks while being smaller in size compared to previously developed
models that perform a narrower range of tasks. The code is at
https://github.com/hyn2028/llm-cxr.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering. (arXiv:2305.11541v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11541">
<div class="article-summary-box-inner">
<span><p>Large Language Model (LLM) has gained popularity and achieved remarkable
results in open-domain tasks, but its performance in real industrial
domain-specific scenarios is average due to its lack of specific domain
knowledge. This issue has attracted widespread attention, but there are few
relevant benchmarks available. In this paper, we provide a benchmark Question
Answering (QA) dataset named MSQA, centered around Microsoft products and IT
technical problems encountered by customers. This dataset contains industry
cloud-specific QA knowledge, an area not extensively covered in general LLMs,
making it well-suited for evaluating methods aiming to enhance LLMs'
domain-specific capabilities. In addition, we propose a new model interaction
paradigm that can empower LLM to achieve better performance on domain-specific
tasks where it is not proficient. Extensive experiments demonstrate that the
approach following our method outperforms the commonly used LLM with retrieval
methods. We make our source code and sample data available at:
https://aka.ms/Microsoft_QA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cue-CoT: Chain-of-thought Prompting for Responding to In-depth Dialogue Questions with LLMs. (arXiv:2305.11792v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11792">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs), such as \texttt{ChatGPT}, greatly empower
dialogue systems with strong language understanding and generation
capabilities. However, most of the previous works prompt the LLMs to directly
generate a response based on the dialogue context, overlooking the underlying
linguistic cues about the user status exhibited in the context. Such in-depth
dialogue scenarios are challenging for existing LLMs to figure out the user's
hidden needs and respond satisfactorily through a single-step inference. To
this end, we propose a novel linguistic cue-based chain-of-thoughts
(\textit{Cue}-CoT), which enhances the LLMs inference with an intermediate
reasoning step to find cues exhibited in the dialogue, aiming to provide a more
personalized and engaging response. To evaluate the approach, we build a
benchmark with in-depth dialogue questions, consisting of 6 datasets in both
Chinese and English, targeting 3 major linguistic cues during the conversation:
\textit{personality}, \textit{emotion}, and \textit{psychology}. We conduct
extensive experiments on the proposed benchmark with 5 LLMs under both
zero-shot and one-shot settings. Empirical results demonstrate our proposed
\textit{Cue}-CoT method outperforms standard prompting methods in terms of both
\textit{helpfulness} and \textit{acceptability} on all datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DisCo: Distilled Student Models Co-training for Semi-supervised Text Mining. (arXiv:2305.12074v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.12074">
<div class="article-summary-box-inner">
<span><p>Many text mining models are constructed by fine-tuning a large deep
pre-trained language model (PLM) in downstream tasks. However, a significant
challenge nowadays is maintaining performance when we use a lightweight model
with limited labelled samples. We present DisCo, a semi-supervised learning
(SSL) framework for fine-tuning a cohort of small student models generated from
a large PLM using knowledge distillation. Our key insight is to share
complementary knowledge among distilled student cohorts to promote their SSL
effectiveness. DisCo employs a novel co-training technique to optimize a cohort
of multiple small student models by promoting knowledge sharing among students
under diversified views: model views produced by different distillation
strategies and data views produced by various input augmentations. We evaluate
DisCo on both semi-supervised text classification and extractive summarization
tasks. Experimental results show that DisCo can produce student models that are
7.6 times smaller and 4.8 times faster in inference than the baseline PLMs
while maintaining comparable performance. We also show that DisCo-generated
student models outperform the similar-sized models elaborately tuned in
distinct tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are Your Explanations Reliable? Investigating the Stability of LIME in Explaining Text Classifiers by Marrying XAI and Adversarial Attack. (arXiv:2305.12351v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.12351">
<div class="article-summary-box-inner">
<span><p>LIME has emerged as one of the most commonly referenced tools in explainable
AI (XAI) frameworks that is integrated into critical machine learning
applications--e.g., healthcare and finance. However, its stability remains
little explored, especially in the context of text data, due to the unique
text-space constraints. To address these challenges, in this paper, we first
evaluate the inherent instability of LIME on text data to establish a baseline,
and then propose a novel algorithm XAIFooler to perturb text inputs and
manipulate explanations that casts investigation on the stability of LIME as a
text perturbation optimization problem. XAIFooler conforms to the constraints
to preserve text semantics and original prediction with small perturbations,
and introduces Rank-biased Overlap (RBO) as a key part to guide the
optimization of XAIFooler that satisfies all the requirements for explanation
similarity measure. Extensive experiments on real-world text datasets
demonstrate that XAIFooler significantly outperforms all baselines by large
margins in its ability to manipulate LIME's explanations with high semantic
preservability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Logical Reasoning of Large Language Models through Logic-Driven Data Augmentation. (arXiv:2305.12599v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.12599">
<div class="article-summary-box-inner">
<span><p>Combining large language models with logical reasoning enhance their capacity
to address problems in a robust and reliable manner. Nevertheless, the
intricate nature of logical reasoning poses challenges to gathering reliable
data from web for building comprehensive training datasets, subsequently
affecting the performance on downstream tasks. To address this, we introduce a
novel logic-driven data augmentation approach, AMR-LDA. AMR-LDA converts the
original text into an Abstract Meaning Representation (AMR) graph, a structured
semantic representation that encapsulates the logic structure of the sentence,
upon which operations are performed to generate logically modified AMR graphs.
The modified AMR graphs are subsequently converted back into texts to create
augmented data. Notably, our methodology is architecture-agnostic and enhances
generative large language models, such as GPT-3.5 and GPT-4, through prompt
augmentation, and fine-tuning discriminative large language models through
contrastive learning with logic-driven data augmentation. Empirical evidence
underscores the efficacy of our proposed method with improvement in performance
across seven downstream tasks, such as logical reasoning reading comprehension,
textual entailment, and natural language inference. Furthermore, our method
ranked first on the ReClor leaderboard
\url{https://eval.ai/web/challenges/challenge-page/503/leaderboard/1347}. The
source code and data are publicly available
\url{https://github.com/Strong-AI-Lab/Logical-Equivalence-driven-AMR-Data-Augmentation-for-Representation-Learning}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">D$^2$TV: Dual Knowledge Distillation and Target-oriented Vision Modeling for Many-to-Many Multimodal Summarization. (arXiv:2305.12767v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.12767">
<div class="article-summary-box-inner">
<span><p>Many-to-many multimodal summarization (M$^3$S) task aims to generate
summaries in any language with document inputs in any language and the
corresponding image sequence, which essentially comprises multimodal
monolingual summarization (MMS) and multimodal cross-lingual summarization
(MXLS) tasks. Although much work has been devoted to either MMS or MXLS and has
obtained increasing attention in recent years, little research pays attention
to the M$^3$S task. Besides, existing studies mainly focus on 1) utilizing MMS
to enhance MXLS via knowledge distillation without considering the performance
of MMS or 2) improving MMS models by filtering summary-unrelated visual
features with implicit learning or explicitly complex training objectives. In
this paper, we first introduce a general and practical task, i.e., M$^3$S.
Further, we propose a dual knowledge distillation and target-oriented vision
modeling framework for the M$^3$S task. Specifically, the dual knowledge
distillation method guarantees that the knowledge of MMS and MXLS can be
transferred to each other and thus mutually prompt both of them. To offer
target-oriented visual features, a simple yet effective target-oriented
contrastive objective is designed and responsible for discarding needless
visual information. Extensive experiments on the many-to-many setting show the
effectiveness of the proposed approach. Additionally, we will contribute a
many-to-many multimodal summarization (M$^3$Sum) dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lion: Adversarial Distillation of Proprietary Large Language Models. (arXiv:2305.12870v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.12870">
<div class="article-summary-box-inner">
<span><p>The practice of transferring knowledge from a sophisticated, proprietary
large language model (LLM) to a compact, open-source LLM has garnered
considerable attention. Previous works have focused on a unidirectional
knowledge distillation way by aligning the responses of the student model with
those of the teacher model to a set of instructions. Nevertheless, they
overlooked the possibility of incorporating any reciprocal
"feedback"--identifying challenging instructions where the student model's
performance falls short--to boost the student model's proficiency iteratively.
To this end, we propose a novel adversarial distillation framework for a more
efficient knowledge transfer. Leveraging the versatile role adaptability of
LLMs, we prompt the teacher model to identify "hard" instructions and generate
new "hard" instructions for the student model, creating a three-stage
adversarial loop of imitation, discrimination, and generation. By applying this
adversarial framework, we successfully transfer knowledge from ChatGPT to a
student model (named Lion), using a mere 70k training data. Our results show
that Lion-13B not only achieves comparable open-ended generation capabilities
to ChatGPT but surpasses conventional state-of-the-art (SOTA) instruction-tuned
models like Vicuna-13B by 55.4% in challenging zero-shot reasoning benchmarks
such as BIG-Bench Hard (BBH) and 16.7% on AGIEval. Code and model can be found
at https://github.com/YJiangcm/Lion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Easily Updated General Purpose Text Representations with Adaptable Task-Specific Prefixes. (arXiv:2305.13499v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.13499">
<div class="article-summary-box-inner">
<span><p>Many real-world applications require making multiple predictions from the
same text. Fine-tuning a large pre-trained language model for each downstream
task causes computational burdens in the inference time due to several times of
forward passes. To amortize the computational cost, freezing the language model
and building lightweight models for downstream tasks based on fixed text
representations are common solutions. Accordingly, how to learn fixed but
general text representations that can generalize well to unseen downstream
tasks becomes a challenge. Previous works have shown that the generalizability
of representations can be improved by fine-tuning the pre-trained language
model with some source tasks in a multi-tasking way. In this work, we propose a
prefix-based method to learn the fixed text representations with source tasks.
We learn a task-specific prefix for each source task independently and combine
them to get the final representations. Our experimental results show that
prefix-based training performs better than multi-tasking training and can
update the text representations at a smaller computational cost than
multi-tasking training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration. (arXiv:2305.13626v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.13626">
<div class="article-summary-box-inner">
<span><p>Conversational systems based on Large Language Models (LLMs), such as
ChatGPT, show exceptional proficiency in context understanding and response
generation. However, despite their impressive capabilities, they still possess
limitations, such as providing randomly-guessed answers to ambiguous queries or
failing to refuse users' requests, both of which are considered aspects of a
conversational agent's proactivity. This raises the question of whether
LLM-based conversational systems are equipped to handle proactive dialogue
problems. In this work, we conduct a comprehensive analysis of LLM-based
conversational systems, specifically focusing on three aspects of proactive
dialogue systems: clarification, target-guided, and non-collaborative
dialogues. To trigger the proactivity of LLMs, we propose the Proactive
Chain-of-Thought prompting scheme, which augments LLMs with the goal planning
capability over descriptive reasoning chains. Empirical findings are discussed
to promote future studies on LLM-based proactive dialogue systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Prompt Optimization for Large Language Models Against Distribution Shifts. (arXiv:2305.13954v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.13954">
<div class="article-summary-box-inner">
<span><p>Large Language Model (LLM) has demonstrated significant ability in various
Natural Language Processing tasks. However, their effectiveness is highly
dependent on the phrasing of the task prompt, leading to research on automatic
prompt optimization using labeled task data. We reveal that these prompt
optimization techniques are vulnerable to distribution shifts such as
subpopulation shifts, which are common for LLMs in real-world scenarios such as
customer reviews analysis. In this light, we propose a new problem of robust
prompt optimization for LLMs against distribution shifts, which requires the
prompt optimized over the labeled source group can simultaneously generalize to
an unlabeled target group. To solve this problem, we propose Generalized Prompt
Optimization framework, which incorporates the unlabeled data from the target
group into prompt optimization. Extensive experimental results demonstrate the
effectiveness of the proposed framework with significant performance
improvement on the target group and comparable performance on the source group.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning. (arXiv:2305.14045v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14045">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) with less than 100B parameters are known to perform
poorly on chain-of-thought (CoT) reasoning in contrast to large LMs when
solving unseen tasks. In this work, we aim to equip smaller LMs with the
step-by-step reasoning capability by instruction tuning with CoT rationales. In
order to achieve this goal, we first introduce a new instruction-tuning dataset
called the CoT Collection, which augments the existing Flan Collection
(including only 9 CoT tasks) with additional 1.84 million rationales across
1,060 tasks. We show that CoT fine-tuning Flan-T5 (3B &amp; 11B) with CoT
Collection enables smaller LMs to have better CoT capabilities on unseen tasks.
On the BIG-Bench-Hard (BBH) benchmark, we report an average improvement of
+4.34% (Flan-T5 3B) and +2.60% (Flan-T5 11B), in terms of zero-shot task
accuracy. Furthermore, we show that instruction tuning with CoT Collection
allows LMs to possess stronger few-shot learning capabilities on 4
domain-specific tasks, resulting in an improvement of +2.24% (Flan-T5 3B) and
+2.37% (Flan-T5 11B), even outperforming ChatGPT utilizing demonstrations until
the max length by a +13.98% margin. Our code, the CoT Collection data, and
model checkpoints are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding. (arXiv:2305.14196v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14196">
<div class="article-summary-box-inner">
<span><p>We introduce ZeroSCROLLS, a zero-shot benchmark for natural language
understanding over long texts, which contains only test and small validation
sets, without training data. We adapt six tasks from the SCROLLS benchmark, and
add four new datasets, including two novel information fusing tasks, such as
aggregating the percentage of positive reviews. Using ZeroSCROLLS, we conduct a
comprehensive evaluation of both open-source and closed large language models,
finding that Claude outperforms ChatGPT, and that GPT-4 achieves the highest
average score. However, there is still room for improvement on multiple open
challenges in ZeroSCROLLS, such as aggregation tasks, where models struggle to
pass the naive baseline. As the state of the art is a moving target, we invite
researchers to evaluate their ideas on the live ZeroSCROLLS leaderboard.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Finding the Pillars of Strength for Multi-Head Attention. (arXiv:2305.14380v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14380">
<div class="article-summary-box-inner">
<span><p>Recent studies have revealed some issues of Multi-Head Attention (MHA), e.g.,
redundancy and over-parameterization. Specifically, the heads of MHA were
originally designed to attend to information from different representation
subspaces, whereas prior studies found that some attention heads likely learn
similar features and can be pruned without harming performance. Inspired by the
minimum-redundancy feature selection, we assume that focusing on the most
representative and distinctive features with minimum resources can mitigate the
above issues and lead to more effective and efficient MHAs. In particular, we
propose Grouped Head Attention, trained with a self-supervised group constraint
that group attention heads, where each group focuses on an essential but
distinctive feature subset. We additionally propose a Voting-to-Stay procedure
to remove redundant heads, thus achieving a transformer with lighter weights.
Moreover, our method achieves significant performance gains on three
well-established tasks while considerably compressing parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BAND: Biomedical Alert News Dataset. (arXiv:2305.14480v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14480">
<div class="article-summary-box-inner">
<span><p>Infectious disease outbreaks continue to pose a significant threat to human
health and well-being. To improve disease surveillance and understanding of
disease spread, several surveillance systems have been developed to monitor
daily news alerts and social media. However, existing systems lack thorough
epidemiological analysis in relation to corresponding alerts or news, largely
due to the scarcity of well-annotated reports data. To address this gap, we
introduce the Biomedical Alert News Dataset (BAND), which includes 1,508
samples from existing reported news articles, open emails, and alerts, as well
as 30 epidemiology-related questions. These questions necessitate the model's
expert reasoning abilities, thereby offering valuable insights into the
outbreak of the disease. The BAND dataset brings new challenges to the NLP
world, requiring better disguise capability of the content and the ability to
infer important information. We provide several benchmark tasks, including
Named Entity Recognition (NER), Question Answering (QA), and Event Extraction
(EE), to show how existing models are capable of handling these tasks in the
epidemiology domain. To the best of our knowledge, the BAND corpus is the
largest corpus of well-annotated biomedical outbreak alert news with
elaborately designed questions, making it a valuable resource for
epidemiologists and NLP researchers alike.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ComSL: A Composite Speech-Language Model for End-to-End Speech-to-Text Translation. (arXiv:2305.14838v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14838">
<div class="article-summary-box-inner">
<span><p>Joint speech-language training is challenging due to the large demand for
training data and GPU consumption, as well as the modality gap between speech
and language. We present ComSL, a speech-language model built atop a composite
architecture of public pretrained speech-only and language-only models and
optimized data-efficiently for spoken language tasks. Particularly, we propose
to incorporate cross-modality learning into transfer learning and conduct them
simultaneously for downstream tasks in a multi-task learning manner. Our
approach has demonstrated effectiveness in end-to-end speech-to-text
translation tasks, achieving a new state-of-the-art average BLEU score of 31.5
on the multilingual speech to English text translation task for 21 languages,
as measured on the public CoVoST2 evaluation set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Words to Wires: Generating Functioning Electronic Devices from Natural Language Descriptions. (arXiv:2305.14874v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14874">
<div class="article-summary-box-inner">
<span><p>In this work, we show that contemporary language models have a previously
unknown skill -- the capacity for electronic circuit design from high-level
textual descriptions, akin to code generation. We introduce two benchmarks:
Pins100, assessing model knowledge of electrical components, and Micro25,
evaluating a model's capability to design common microcontroller circuits and
code in the Arduino ecosystem that involve input, output, sensors, motors,
protocols, and logic -- with models such as GPT-4 and Claude-V1 achieving
between 60% to 96% Pass@1 on generating full devices. We include six case
studies of using language models as a design assistant for moderately complex
devices, such as a radiation-powered random number generator, an emoji
keyboard, a visible spectrometer, and several assistive devices, while offering
a qualitative analysis performance, outlining evaluation challenges, and
suggesting areas of development to improve complex circuit design and practical
utility. With this work, we aim to spur research at the juncture of natural
language processing and electronic design.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Demonstration Attacks on Large Language Models. (arXiv:2305.14950v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14950">
<div class="article-summary-box-inner">
<span><p>With the emergence of more powerful large language models (LLMs), such as
ChatGPT and GPT-4, in-context learning (ICL) has gained significant prominence
in leveraging these models for specific tasks by utilizing data-label pairs as
precondition prompts. While incorporating demonstrations can greatly enhance
the performance of LLMs across various tasks, it may introduce a new security
concern: attackers can manipulate only the demonstrations without changing the
input to perform an attack. In this paper, we investigate the security concern
of ICL from an adversarial perspective, focusing on the impact of
demonstrations. We propose a novel attack method named advICL, which aims to
manipulate only the demonstration without changing the input to mislead the
models. Our results demonstrate that as the number of demonstrations increases,
the robustness of in-context learning would decrease. Additionally, we also
identify the intrinsic property of the demonstrations is that they can be used
(prepended) with different inputs. As a result, it introduces a more practical
threat model in which an attacker can attack the test input example even
without knowing and manipulating it. To achieve it, we propose the transferable
version of advICL, named Transferable-advICL. Our experiment shows that the
adversarial demonstration generated by Transferable-advICL can successfully
attack the unseen test input examples. We hope that our study reveals the
critical security risks associated with ICL and underscores the need for
extensive research on the robustness of ICL, particularly given its increasing
significance in the advancement of LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lawyer LLaMA Technical Report. (arXiv:2305.15062v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15062">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs), like LLaMA, have exhibited remarkable
performance across various tasks. Nevertheless, when deployed to specific
domains such as law or medicine, the models still confront the challenge of a
deficiency in domain-specific knowledge and an inadequate capability to
leverage that knowledge to resolve domain-related problems. In this paper, we
propose a new framework to adapt LLMs to specific domains and build Lawyer
LLaMA, a legal domain LLM, based on this framework. Specifically, we inject
domain knowledge during the continual training stage and teach the model to
learn professional skills using properly designed supervised fine-tuning tasks.
Moreover, to alleviate the hallucination problem during the model's generation,
we add a retrieval module and extract relevant legal articles before the model
answers any queries. When learning domain-specific skills, we find that
experts' experience is much more useful than experiences distilled from
ChatGPT, where hundreds of expert-written data outperform tens of thousands of
ChatGPT-generated ones. We will release our model and data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena. (arXiv:2306.05685v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.05685">
<div class="article-summary-box-inner">
<span><p>Evaluating large language model (LLM) based chat assistants is challenging
due to their broad capabilities and the inadequacy of existing benchmarks in
measuring human preferences. To address this, we explore using strong LLMs as
judges to evaluate these models on more open-ended questions. We examine the
usage and limitations of LLM-as-a-judge, including position, verbosity, and
self-enhancement biases, as well as limited reasoning ability, and propose
solutions to mitigate some of them. We then verify the agreement between LLM
judges and human preferences by introducing two benchmarks: MT-bench, a
multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our
results reveal that strong LLM judges like GPT-4 can match both controlled and
crowdsourced human preferences well, achieving over 80% agreement, the same
level of agreement between humans. Hence, LLM-as-a-judge is a scalable and
explainable way to approximate human preferences, which are otherwise very
expensive to obtain. Additionally, we show our benchmark and traditional
benchmarks complement each other by evaluating several variants of LLaMA and
Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with
human preferences are publicly available at
https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Clickbait Detection via Large Language Models. (arXiv:2306.09597v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.09597">
<div class="article-summary-box-inner">
<span><p>Clickbait, which aims to induce users with some surprising and even thrilling
headlines for increasing click-through rates, permeates almost all online
content publishers, such as news portals and social media. Recently, Large
Language Models (LLMs) have emerged as a powerful instrument and achieved
tremendous success in a serious of NLP downstream tasks. However, it is not yet
known whether LLMs can be served as a high-quality clickbait detection system.
In this paper, we analyze the performance of LLMs in the few-shot scenarios on
a number of English and Chinese benchmark datasets. Experimental results show
that LLMs cannot achieve the best results compared to the state-of-the-art deep
and fine-tuning PLMs methods. Different from the human intuition, the
experiments demonstrated that LLMs cannot make satisfied clickbait detection
just by the headlines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analysis of the Cambridge Multiple-Choice Questions Reading Dataset with a Focus on Candidate Response Distribution. (arXiv:2306.13047v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13047">
<div class="article-summary-box-inner">
<span><p>Multiple choice exams are widely used to assess candidates across a diverse
range of domains and tasks. To moderate question quality, newly proposed
questions often pass through pre-test evaluation stages before being deployed
into real-world exams. Currently, this evaluation process is manually
intensive, which can lead to time lags in the question development cycle.
Streamlining this process via automation can significantly enhance efficiency,
however, there's a current lack of datasets with adequate pre-test analysis
information. In this paper we analyse a subset of the public Cambridge
Multiple-Choice Questions Reading Database released by Cambridge University
Press &amp; Assessment; a multiple-choice comprehension dataset of questions at
different target levels, with corresponding candidate selection distributions.
We introduce the task of candidate distribution matching, propose several
evaluation metrics for the task, and demonstrate that automatic systems trained
on RACE++ can be leveraged as baselines for our task. We further demonstrate
that these automatic systems can be used for practical pre-test evaluation
tasks such as detecting underperforming distractors, where our detection
systems can automatically identify poor distractors that few candidates select.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Med-HALT: Medical Domain Hallucination Test for Large Language Models. (arXiv:2307.15343v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2307.15343">
<div class="article-summary-box-inner">
<span><p>This research paper focuses on the challenges posed by hallucinations in
large language models (LLMs), particularly in the context of the medical
domain. Hallucination, wherein these models generate plausible yet unverified
or incorrect information, can have serious consequences in healthcare
applications. We propose a new benchmark and dataset, Med-HALT (Medical Domain
Hallucination Test), designed specifically to evaluate and reduce
hallucinations. Med-HALT provides a diverse multinational dataset derived from
medical examinations across various countries and includes multiple innovative
testing modalities. Med-HALT includes two categories of tests reasoning and
memory-based hallucination tests, designed to assess LLMs's problem-solving and
information retrieval abilities.
</p>
<p>Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2,
MPT, and Falcon, revealing significant differences in their performance. The
paper provides detailed insights into the dataset, promoting transparency and
reproducibility. Through this work, we aim to contribute to the development of
safer and more reliable language models in healthcare. Our benchmark can be
found at medhalt.github.io
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Science and engineering for what? A large-scale analysis of students' projects in science fairs. (arXiv:2308.02962v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.02962">
<div class="article-summary-box-inner">
<span><p>Science and Engineering fairs offer K-12 students opportunities to engage
with authentic STEM practices. Particularly, students are given the chance to
experience authentic and open inquiry processes, by defining which themes,
questions and approaches will guide their scientific endeavors. In this study,
we analyzed data from over 5,000 projects presented at a nationwide science
fair in Brazil over the past 20 years using topic modeling to identify the main
topics that have driven students' inquiry and design. Our analysis identified a
broad range of topics being explored, with significant variations over time,
region, and school setting. We argue those results and proposed methodology can
not only support further research in the context of science fairs, but also
inform instruction and design of contexts-specific resources to support
students in open inquiry experiences in different settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SynJax: Structured Probability Distributions for JAX. (arXiv:2308.03291v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.03291">
<div class="article-summary-box-inner">
<span><p>The development of deep learning software libraries enabled significant
progress in the field by allowing users to focus on modeling, while letting the
library to take care of the tedious and time-consuming task of optimizing
execution for modern hardware accelerators. However, this has benefited only
particular types of deep learning models, such as Transformers, whose
primitives map easily to the vectorized computation. The models that explicitly
account for structured objects, such as trees and segmentations, did not
benefit equally because they require custom algorithms that are difficult to
implement in a vectorized form.
</p>
<p>SynJax directly addresses this problem by providing an efficient vectorized
implementation of inference algorithms for structured distributions covering
alignment, tagging, segmentation, constituency trees and spanning trees. This
is done by exploiting the connection between algorithms for automatic
differentiation and probabilistic inference. With SynJax we can build
large-scale differentiable models that explicitly model structure in the data.
The code is available at https://github.com/google-deepmind/synjax
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLEVA: Chinese Language Models EVAluation Platform. (arXiv:2308.04813v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.04813">
<div class="article-summary-box-inner">
<span><p>With the continuous emergence of Chinese Large Language Models (LLMs), how to
evaluate a model's capabilities has become an increasingly significant issue.
The absence of a comprehensive Chinese benchmark that thoroughly assesses a
model's performance, the unstandardized and incomparable prompting procedure,
and the prevalent risk of contamination pose major challenges in the current
evaluation of Chinese LLMs. We present CLEVA, a user-friendly platform crafted
to holistically evaluate Chinese LLMs. Our platform employs a standardized
workflow to assess LLMs' performance across various dimensions, regularly
updating a competitive leaderboard. To alleviate contamination, CLEVA curates a
significant proportion of new data and develops a sampling strategy that
guarantees a unique subset for each leaderboard round. Empowered by an
easy-to-use interface that requires just a few mouse clicks and a model API,
users can conduct a thorough evaluation with minimal coding. Large-scale
experiments featuring 23 Chinese LLMs have validated CLEVA's efficacy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Thresh: A Unified, Customizable and Deployable Platform for Fine-Grained Text Evaluation. (arXiv:2308.06953v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.06953">
<div class="article-summary-box-inner">
<span><p>Fine-grained, span-level human evaluation has emerged as a reliable and
robust method for evaluating text generation tasks such as summarization,
simplification, machine translation and news generation, and the derived
annotations have been useful for training automatic metrics and improving
language models. However, existing annotation tools implemented for these
evaluation frameworks lack the adaptability to be extended to different domains
or languages, or modify annotation settings according to user needs; and, the
absence of a unified annotated data format inhibits the research in multi-task
learning. In this paper, we introduce Thresh, a unified, customizable and
deployable platform for fine-grained evaluation. With a single YAML
configuration file, users can build and test an annotation interface for any
framework within minutes -- all in one web browser window. To facilitate
collaboration and sharing, Thresh provides a community hub that hosts a
collection of fine-grained frameworks and corresponding annotations made and
collected by the community, covering a wide range of NLP tasks. For deployment,
Thresh offers multiple options for any scale of annotation projects from small
manual inspections to large crowdsourcing ones. Additionally, we introduce a
Python library to streamline the entire process from typology design and
deployment to annotation processing. Thresh is publicly accessible at
https://thresh.tools.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SummHelper: Collaborative Human-Computer Summarization. (arXiv:2308.08363v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.08363">
<div class="article-summary-box-inner">
<span><p>Current approaches for text summarization are predominantly automatic, with
rather limited space for human intervention and control over the process. In
this paper, we introduce SummHelper, a 2-phase summarization assistant designed
to foster human-machine collaboration. The initial phase involves content
selection, where the system recommends potential content, allowing users to
accept, modify, or introduce additional selections. The subsequent phase,
content consolidation, involves SummHelper generating a coherent summary from
these selections, which users can then refine using visual mappings between the
summary and the source text. Small-scale user studies reveal the effectiveness
of our application, with participants being especially appreciative of the
balance between automated guidance and opportunities for personal input.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Study on Robustness and Reliability of Large Language Model Code Generation. (arXiv:2308.10335v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.10335">
<div class="article-summary-box-inner">
<span><p>Recently, the large language models (LLMs) have shown extraordinary ability
in understanding natural language and generating programming code. It has been
a common practice of software engineers to consult LLMs when encountering
coding questions. Although efforts have been made to avoid syntax errors and
align the code with the intended semantics, the reliability and robustness of
the code generationfrom LLMs have not yet been thoroughly studied. The
executable code is not equivalent to the reliable and robust code, especially
in the context of real-world software development. The misuse of APIs in the
generated code could lead to severe problem, such as resource leaks, program
crashes. To make things worse, the users of LLM code generation services are
actually the developers that are most vulnerable to these code that seems right
-- They are always novice developers that are not familiar with the APIs that
LLMs generate code for them. Therefore, they could hardly tell the misuse in
the code generated by LLMs, which further facilitates the incorrect code
applied in real-world software. Existing code evaluation benchmark and datasets
focus on crafting small tasks such as programming questions in coding
interviews, which however deviates from the problem that developers would ask
LLM for real-world coding help. To fill the missing piece, in this work, we
propose a dataset RobustAPI for evaluating the reliability and robustness of
code generated by LLMs. We collect 1208 coding questions from StackOverflow on
24 representative Java APIs. We summarize thecommon misuse patterns of these
APIs and evaluate them oncurrent popular LLMs. The evaluation results show that
evenfor GPT-4, 62% of the generated code contains API misuses,which would cause
unexpected consequences if the code isintroduced into real-world software.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models. (arXiv:2308.10633v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.10633">
<div class="article-summary-box-inner">
<span><p>Retrieval-augmented large language models (R-LLMs) combine pre-trained large
language models (LLMs) with information retrieval systems to improve the
accuracy of factual question-answering. However, current libraries for building
R-LLMs provide high-level abstractions without sufficient transparency for
evaluating and optimizing prompts within specific inference processes such as
retrieval and generation. To address this gap, we present RaLLe, an open-source
framework designed to facilitate the development, evaluation, and optimization
of R-LLMs for knowledge-intensive tasks. With RaLLe, developers can easily
develop and evaluate R-LLMs, improving hand-crafted prompts, assessing
individual inference processes, and objectively measuring overall system
performance quantitatively. By leveraging these features, developers can
enhance the performance and accuracy of their R-LLMs in knowledge-intensive
generation tasks. We open-source our code at https://github.com/yhoshi3/RaLLe.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors. (arXiv:2308.13904v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2308.13904">
<div class="article-summary-box-inner">
<span><p>Prompt-tuning has emerged as an attractive paradigm for deploying large-scale
language models due to its strong downstream task performance and efficient
multitask serving ability. Despite its wide adoption, we empirically show that
prompt-tuning is vulnerable to downstream task-agnostic backdoors, which reside
in the pretrained models and can affect arbitrary downstream tasks. The
state-of-the-art backdoor detection approaches cannot defend against
task-agnostic backdoors since they hardly converge in reversing the backdoor
triggers. To address this issue, we propose LMSanitator, a novel approach for
detecting and removing task-agnostic backdoors on Transformer models. Instead
of directly inverting the triggers, LMSanitator aims to invert the predefined
attack vectors (pretrained models' output when the input is embedded with
triggers) of the task-agnostic backdoors, which achieves much better
convergence performance and backdoor detection accuracy. LMSanitator further
leverages prompt-tuning's property of freezing the pretrained model to perform
accurate and fast output monitoring and input purging during the inference
phase. Extensive experiments on multiple language models and NLP tasks
illustrate the effectiveness of LMSanitator. For instance, LMSanitator achieves
92.8% backdoor detection accuracy on 960 models and decreases the attack
success rate to less than 1% in most scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Code Generation by Dynamic Temperature Sampling. (arXiv:2309.02772v2 [cs.SE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.02772">
<div class="article-summary-box-inner">
<span><p>Recently, Large Language Models (LLMs) have shown impressive results in code
generation. However, existing decoding strategies are designed for Natural
Language (NL) generation, overlooking the differences between NL and
programming languages (PL). Due to this oversight, a better decoding strategy
for code generation remains an open question. In this paper, we conduct the
first systematic study to explore a decoding strategy specialized in code
generation. With an analysis of loss distributions of code tokens, we find that
code tokens can be divided into two categories: challenging tokens that are
difficult to predict and confident tokens that can be easily inferred. Among
them, the challenging tokens mainly appear at the beginning of a code block.
Inspired by the above findings, we propose a simple yet effective method:
Adaptive Temperature (AdapT) sampling, which dynamically adjusts the
temperature coefficient when decoding different tokens. We apply a larger
temperature when sampling for challenging tokens, allowing LLMs to explore
diverse choices. We employ a smaller temperature for confident tokens avoiding
the influence of tail randomness noises. We apply AdapT sampling to LLMs with
different sizes and conduct evaluations on two popular datasets. Results show
that AdapT sampling significantly outperforms state-of-the-art decoding
strategy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. How good are AI chatbots at scientific writing?. (arXiv:2309.08636v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.08636">
<div class="article-summary-box-inner">
<span><p>Historical emphasis on writing mastery has shifted with advances in
generative AI, especially in scientific writing. This study analysed six AI
chatbots for scholarly writing in humanities and archaeology. Using methods
that assessed factual correctness and scientific contribution, ChatGPT-4 showed
the highest quantitative accuracy, closely followed by ChatGPT-3.5, Bing, and
Bard. However, Claude 2 and Aria scored considerably lower. Qualitatively, all
AIs exhibited proficiency in merging existing knowledge, but none produced
original scientific content. Inter-estingly, our findings suggest ChatGPT-4
might represent a plateau in large language model size. This research
emphasizes the unique, intricate nature of human research, suggesting that AI's
emulation of human originality in scientific writing is challenging. As of
2023, while AI has transformed content generation, it struggles with original
contributions in humanities. This may change as AI chatbots continue to evolve
into LLM-powered software.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models. (arXiv:2309.13567v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.13567">
<div class="article-summary-box-inner">
<span><p>With the development of web technology, social media texts are becoming a
rich source for automatic mental health analysis. As traditional discriminative
methods bear the problem of low interpretability, the recent large language
models have been explored for interpretable mental health analysis on social
media, which aims to provide detailed explanations along with predictions. The
results show that ChatGPT can generate approaching-human explanations for its
correct classifications. However, LLMs still achieve unsatisfactory
classification performance in a zero-shot/few-shot manner. Domain-specific
finetuning is an effective solution, but faces 2 challenges: 1) lack of
high-quality training data. 2) no open-source LLMs for interpretable mental
health analysis were released to lower the finetuning cost. To alleviate these
problems, we build the first multi-task and multi-source interpretable mental
health instruction (IMHI) dataset on social media, with 105K data samples. The
raw social media data are collected from 10 existing sources covering 8 mental
health analysis tasks. We use expert-written few-shot prompts and collected
labels to prompt ChatGPT and obtain explanations from its responses. To ensure
the reliability of the explanations, we perform strict automatic and human
evaluations on the correctness, consistency, and quality of generated data.
Based on the IMHI dataset and LLaMA2 foundation models, we train MentalLLaMA,
the first open-source LLM series for interpretable mental health analysis with
instruction-following capability. We also evaluate the performance of
MentalLLaMA on the IMHI evaluation benchmark with 10 test sets, where their
correctness for making predictions and the quality of explanations are
examined. The results show that MentalLLaMA approaches state-of-the-art
discriminative methods in correctness and generates high-quality explanations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Legal Question-Answering in the Indian Context: Efficacy, Challenges, and Potential of Modern AI Models. (arXiv:2309.14735v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.14735">
<div class="article-summary-box-inner">
<span><p>Legal QA platforms bear the promise to metamorphose the manner in which legal
experts engage with jurisprudential documents. In this exposition, we embark on
a comparative exploration of contemporary AI frameworks, gauging their
adeptness in catering to the unique demands of the Indian legal milieu, with a
keen emphasis on Indian Legal Question Answering (AILQA). Our discourse zeroes
in on an array of retrieval and QA mechanisms, positioning the OpenAI GPT model
as a reference point. The findings underscore the proficiency of prevailing
AILQA paradigms in decoding natural language prompts and churning out precise
responses. The ambit of this study is tethered to the Indian criminal legal
landscape, distinguished by its intricate nature and associated logistical
constraints. To ensure a holistic evaluation, we juxtapose empirical metrics
with insights garnered from seasoned legal practitioners, thereby painting a
comprehensive picture of AI's potential and challenges within the realm of
Indian legal QA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future. (arXiv:2309.15402v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15402">
<div class="article-summary-box-inner">
<span><p>Chain-of-thought reasoning, a cognitive process fundamental to human
intelligence, has garnered significant attention in the realm of artificial
intelligence and natural language processing. However, there still remains a
lack of a comprehensive survey for this arena. To this end, we take the first
step and present a thorough survey of this research field carefully and widely.
We use X-of-Thought to refer to Chain-of-Thought in a broad sense. In detail,
we systematically organize the current research according to the taxonomies of
methods, including XoT construction, XoT structure variants, and enhanced XoT.
Additionally, we describe XoT with frontier applications, covering planning,
tool use, and distillation. Furthermore, we address challenges and discuss some
future directions, including faithfulness, multi-modal, and theory. We hope
this survey serves as a valuable resource for researchers seeking to innovate
within the domain of chain-of-thought reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HyPoradise: An Open Baseline for Generative Speech Recognition with Large Language Models. (arXiv:2309.15701v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2309.15701">
<div class="article-summary-box-inner">
<span><p>Advancements in deep neural networks have allowed automatic speech
recognition (ASR) systems to attain human parity on several publicly available
clean speech datasets. However, even state-of-the-art ASR systems experience
performance degradation when confronted with adverse conditions, as a
well-trained acoustic model is sensitive to variations in the speech domain,
e.g., background noise. Intuitively, humans address this issue by relying on
their linguistic knowledge: the meaning of ambiguous spoken terms is usually
inferred from contextual cues thereby reducing the dependency on the auditory
system. Inspired by this observation, we introduce the first open-source
benchmark to utilize external large language models (LLMs) for ASR error
correction, where N-best decoding hypotheses provide informative elements for
true transcription prediction. This approach is a paradigm shift from the
traditional language model rescoring strategy that can only select one
candidate hypothesis as the output transcription. The proposed benchmark
contains a novel dataset, HyPoradise (HP), encompassing more than 334,000 pairs
of N-best hypotheses and corresponding accurate transcriptions across prevalent
speech domains. Given this dataset, we examine three types of error correction
techniques based on LLMs with varying amounts of labeled
hypotheses-transcription pairs, which gains a significant word error rate (WER)
reduction. Experimental evidence demonstrates the proposed technique achieves a
breakthrough by surpassing the upper bound of traditional re-ranking based
methods. More surprisingly, LLM with reasonable prompt and its generative
capability can even correct those tokens that are missing in N-best list. We
make our results publicly accessible for reproducible pipelines with released
pre-trained models, thus providing a new evaluation paradigm for ASR error
correction with LLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unlocking Bias Detection: Leveraging Transformer-Based Models for Content Analysis. (arXiv:2310.00347v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.00347">
<div class="article-summary-box-inner">
<span><p>Bias detection in text is imperative due to its role in reinforcing negative
stereotypes, disseminating misinformation, and influencing decisions. Current
language models often fall short in generalizing beyond their training sets. In
response, we introduce the Contextualized Bi-Directional Dual Transformer
(CBDT) Classifier. This novel architecture utilizes two synergistic transformer
networks: the Context Transformer and the Entity Transformer, aiming for
enhanced bias detection. Our dataset preparation follows the FAIR principles,
ensuring ethical data usage. Through rigorous testing on various datasets, CBDT
showcases its ability in distinguishing biased from neutral statements, while
also pinpointing exact biased lexemes. Our approach outperforms existing
methods, achieving a 2-4\% increase over benchmark performances. This opens
avenues for adapting the CBDT model across diverse linguistic and cultural
landscapes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">(Dynamic) Prompting might be all you need to repair Compressed LLMs. (arXiv:2310.00867v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.00867">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs), while transformative for NLP, come with
significant computational demands, underlining the need for efficient,
training-free compression. Notably, despite the marked improvement in
training-free compression for the largest of LLMs, our tests using LLaMA-7B and
OPT-6.7b highlight a significant performance drop in several realistic
downstream tasks. Investigation into the trade-off between resource-intensive
post-compression re-training highlights the prospect of prompt-driven recovery
as a lightweight adaption tool. However, existing studies, confined mainly to
perplexity evaluations and simple tasks, fail to offer unequivocal confidence
in the scalability and generalizability of prompting. We tackle this
uncertainty in two key ways. First, we uncover the vulnerability of naive
prompts in LLM compression as an over-reliance on a singular prompt per input.
In response, we propose inference-time dynamic prompting (IDP), a mechanism
that autonomously chooses from a set of curated prompts based on the context of
each individual input. Second, we delve into a scientific understanding of why
"prompting might be all you need post-LLM compression." Our findings suggest
that compression does not irretrievably erase LLM model knowledge but displace
it, necessitating a new inference path. IDP effectively redirects this path,
enabling the model to tap into its inherent yet displaced knowledge and thereby
recover performance. Empirical tests affirm the value of IDP, demonstrating an
average performance improvement of 1.24% across nine varied tasks spanning
multiple knowledge domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving. (arXiv:2310.01957v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.01957">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have shown promise in the autonomous driving
sector, particularly in generalization and interpretability. We introduce a
unique object-level multimodal LLM architecture that merges vectorized numeric
modalities with a pre-trained LLM to improve context understanding in driving
situations. We also present a new dataset of 160k QA pairs derived from 10k
driving scenarios, paired with high quality control commands collected with RL
agent and question answer pairs generated by teacher LLM (GPT-3.5). A distinct
pretraining strategy is devised to align numeric vector modalities with static
LLM representations using vector captioning language data. We also introduce an
evaluation metric for Driving QA and demonstrate our LLM-driver's proficiency
in interpreting driving scenarios, answering questions, and decision-making.
Our findings highlight the potential of LLM-based driving action generation in
comparison to traditional behavioral cloning. We make our benchmark, datasets,
and model available for further exploration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond. (arXiv:2310.02071v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.02071">
<div class="article-summary-box-inner">
<span><p>In this study, we explore the potential of Multimodal Large Language Models
(MLLMs) in improving embodied decision-making processes for agents. While Large
Language Models (LLMs) have been widely used due to their advanced reasoning
skills and vast world knowledge, MLLMs like GPT4-Vision offer enhanced visual
understanding and reasoning capabilities. We investigate whether
state-of-the-art MLLMs can handle embodied decision-making in an end-to-end
manner and whether collaborations between LLMs and MLLMs can enhance
decision-making. To address these questions, we introduce a new benchmark
called PCA-EVAL, which evaluates embodied decision-making from the perspectives
of Perception, Cognition, and Action. Additionally, we propose HOLMES, a
multi-agent cooperation framework that allows LLMs to leverage MLLMs and APIs
to gather multimodal information for informed decision-making. We compare
end-to-end embodied decision-making and HOLMES on our benchmark and find that
the GPT4-Vision model demonstrates strong end-to-end embodied decision-making
abilities, outperforming GPT4-HOLMES in terms of average decision accuracy
(+3%). However, this performance is exclusive to the latest GPT4-Vision model,
surpassing the open-source state-of-the-art MLLM by 26%. Our results indicate
that powerful MLLMs like GPT4-Vision hold promise for decision-making in
embodied agents, offering new avenues for MLLM research. Code and data are open
at https://github.com/pkunlp-icler/PCA-EVAL/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Instances and Labels: Hierarchy-aware Joint Supervised Contrastive Learning for Hierarchical Multi-Label Text Classification. (arXiv:2310.05128v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.05128">
<div class="article-summary-box-inner">
<span><p>Hierarchical multi-label text classification (HMTC) aims at utilizing a label
hierarchy in multi-label classification. Recent approaches to HMTC deal with
the problem of imposing an over-constrained premise on the output space by
using contrastive learning on generated samples in a semi-supervised manner to
bring text and label embeddings closer. However, the generation of samples
tends to introduce noise as it ignores the correlation between similar samples
in the same batch. One solution to this issue is supervised contrastive
learning, but it remains an underexplored topic in HMTC due to its complex
structured labels. To overcome this challenge, we propose $\textbf{HJCL}$, a
$\textbf{H}$ierarchy-aware $\textbf{J}$oint Supervised $\textbf{C}$ontrastive
$\textbf{L}$earning method that bridges the gap between supervised contrastive
learning and HMTC. Specifically, we employ both instance-wise and label-wise
contrastive learning techniques and carefully construct batches to fulfill the
contrastive learning objective. Extensive experiments on four multi-path HMTC
datasets demonstrate that HJCL achieves promising results and the effectiveness
of Contrastive Learning on HMTC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Long-form Text Generation in Mental Health with Task-adaptive Tokenization. (arXiv:2310.05317v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.05317">
<div class="article-summary-box-inner">
<span><p>We propose task-adaptive tokenization as a way to adapt the generation
pipeline to the specifics of a downstream task and enhance long-form generation
in mental health. Inspired by insights from cognitive science, our
task-adaptive tokenizer samples variable segmentations from multiple outcomes,
with sampling probabilities optimized based on task-specific data. We introduce
a strategy for building a specialized vocabulary and introduce a vocabulary
merging protocol that allows for the integration of task-specific tokens into
the pre-trained model's tokenization step. Through extensive experiments on
psychological question-answering tasks in both Chinese and English, we find
that our task-adaptive tokenization approach brings a significant improvement
in generation performance while using up to 60% fewer tokens. Preliminary
experiments point to promising results when using our tokenization approach
with very large language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Resolving the Imbalance Issue in Hierarchical Disciplinary Topic Inference via LLM-based Data Augmentation. (arXiv:2310.05318v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.05318">
<div class="article-summary-box-inner">
<span><p>In addressing the imbalanced issue of data within the realm of Natural
Language Processing, text data augmentation methods have emerged as pivotal
solutions. This data imbalance is prevalent in the research proposals submitted
during the funding application process. Such imbalances, resulting from the
varying popularity of disciplines or the emergence of interdisciplinary
studies, significantly impede the precision of downstream topic models that
deduce the affiliated disciplines of these proposals. At the data level,
proposals penned by experts and scientists are inherently complex technological
texts, replete with intricate terminologies, which augmenting such specialized
text data poses unique challenges. At the system level, this, in turn,
compromises the fairness of AI-assisted reviewer assignment systems, which
raises a spotlight on solving this issue. This study leverages large language
models (Llama V1) as data generators to augment research proposals categorized
within intricate disciplinary hierarchies, aiming to rectify data imbalances
and enhance the equity of expert assignments. We first sample within the
hierarchical structure to find the under-represented class. Then we designed a
prompt for keyword-based research proposal generation. Our experiments attests
to the efficacy of the generated data, demonstrating that research proposals
produced using the prompts can effectively address the aforementioned issues
and generate high quality scientific text data, thus help the model overcome
the imbalanced issue.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving End-to-End Speech Processing by Efficient Text Data Utilization with Latent Synthesis. (arXiv:2310.05374v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.05374">
<div class="article-summary-box-inner">
<span><p>Training a high performance end-to-end speech (E2E) processing model requires
an enormous amount of labeled speech data, especially in the era of
data-centric artificial intelligence. However, labeled speech data are usually
scarcer and more expensive for collection, compared to textual data. We propose
Latent Synthesis (LaSyn), an efficient textual data utilization framework for
E2E speech processing models. We train a latent synthesizer to convert textual
data into an intermediate latent representation of a pre-trained speech model.
These pseudo acoustic representations of textual data augment acoustic data for
model training. We evaluate LaSyn on low-resource automatic speech recognition
(ASR) and spoken language understanding (SLU) tasks. For ASR, LaSyn improves an
E2E baseline trained on LibriSpeech train-clean-100, with relative word error
rate reductions over 22.3% on different test sets. For SLU, LaSyn improves our
E2E baseline by absolute 4.1% for intent classification accuracy and 3.8% for
slot filling SLU-F1 on SLURP, and absolute 4.49% and 2.25% for exact match (EM)
and EM-Tree accuracies on STOP respectively. With fewer parameters, the results
of LaSyn are competitive to published state-of-the-art works. The results
demonstrate the quality of the augmented training data. The source code will be
available to the community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiffuSeq-v2: Bridging Discrete and Continuous Text Spaces for Accelerated Seq2Seq Diffusion Models. (arXiv:2310.05793v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.05793">
<div class="article-summary-box-inner">
<span><p>Diffusion models have gained prominence in generating high-quality sequences
of text. Nevertheless, current approaches predominantly represent discrete text
within a continuous diffusion space, which incurs substantial computational
overhead during training and results in slower sampling speeds. In this paper,
we introduce a soft absorbing state that facilitates the diffusion model in
learning to reconstruct discrete mutations based on the underlying Gaussian
space, thereby enhancing its capacity to recover conditional signals. During
the sampling phase, we employ state-of-the-art ODE solvers within the
continuous space to expedite the sampling process. Comprehensive experimental
evaluations reveal that our proposed method effectively accelerates the
training convergence by 4x and generates samples of similar quality 800x
faster, rendering it significantly closer to practical application.
\footnote{The code is released at \url{https://github.com/Shark-NLP/DiffuSeq}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Typing to Listen at the Cocktail Party: Text-Guided Target Speaker Extraction. (arXiv:2310.07284v3 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.07284">
<div class="article-summary-box-inner">
<span><p>Humans possess an extraordinary ability to selectively focus on the sound
source of interest amidst complex acoustic environments, commonly referred to
as cocktail party scenarios. In an attempt to replicate this remarkable
auditory attention capability in machines, target speaker extraction (TSE)
models have been developed. These models leverage the pre-registered cues of
the target speaker to extract the sound source of interest. However, the
effectiveness of these models is hindered in real-world scenarios due to the
unreliable or even absence of pre-registered cues. To address this limitation,
this study investigates the integration of natural language description to
enhance the feasibility, controllability, and performance of existing TSE
models. Specifically, we propose a model named LLM-TSE, wherein a large
language model (LLM) extracts useful semantic cues from the user's typed text
input. These cues can serve as independent extraction cues, task selectors to
control the TSE process or complement the pre-registered cues. Our experimental
results demonstrate competitive performance when only text-based cues are
presented, the effectiveness of using input text as a task selector, and a new
state-of-the-art when combining text-based cues with pre-registered cues. To
our knowledge, this is the first study to successfully incorporate LLMs to
guide target speaker extraction, which can be a cornerstone for cocktail party
problem research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LLM4Vis: Explainable Visualization Recommendation using ChatGPT. (arXiv:2310.07652v2 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.07652">
<div class="article-summary-box-inner">
<span><p>Data visualization is a powerful tool for exploring and communicating
insights in various domains. To automate visualization choice for datasets, a
task known as visualization recommendation has been proposed. Various
machine-learning-based approaches have been developed for this purpose, but
they often require a large corpus of dataset-visualization pairs for training
and lack natural explanations for their results. To address this research gap,
we propose LLM4Vis, a novel ChatGPT-based prompting approach to perform
visualization recommendation and return human-like explanations using very few
demonstration examples. Our approach involves feature description,
demonstration example selection, explanation generation, demonstration example
construction, and inference steps. To obtain demonstration examples with
high-quality explanations, we propose a new explanation generation
bootstrapping to iteratively refine generated explanations by considering the
previous generation and template-based hint. Evaluations on the VizML dataset
show that LLM4Vis outperforms or performs similarly to supervised learning
models like Random Forest, Decision Tree, and MLP in both few-shot and
zero-shot settings. The qualitative evaluation also shows the effectiveness of
explanations generated by LLM4Vis. We make our code publicly available at
\href{https://github.com/demoleiwang/LLM4Vis}{https://github.com/demoleiwang/LLM4Vis}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the Relationship between Analogy Identification and Sentence Structure Encoding in Large Language Models. (arXiv:2310.07818v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.07818">
<div class="article-summary-box-inner">
<span><p>Identifying analogies plays a pivotal role in human cognition and language
proficiency. In the last decade, there has been extensive research on word
analogies in the form of ``A is to B as C is to D.'' However, there is a
growing interest in analogies that involve longer text, such as sentences and
collections of sentences, which convey analogous meanings. While the current
NLP research community evaluates the ability of Large Language Models (LLMs) to
identify such analogies, the underlying reasons behind these abilities warrant
deeper investigation. Furthermore, the capability of LLMs to encode both
syntactic and semantic structures of language within their embeddings has
garnered significant attention with the surge in their utilization. In this
work, we examine the relationship between the abilities of multiple LLMs to
identify sentence analogies, and their capacity to encode syntactic and
semantic structures. Through our analysis, we find that analogy identification
ability of LLMs is positively correlated with their ability to encode syntactic
and semantic structures of sentences. Specifically, we find that the LLMs which
capture syntactic structures better, also have higher abilities in identifying
sentence analogies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Expresssive Power of Transformers with Chain of Thought. (arXiv:2310.07923v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.07923">
<div class="article-summary-box-inner">
<span><p>Recent theoretical work has identified surprisingly simple reasoning
problems, such as checking if two nodes in a graph are connected or simulating
finite-state machines, that are provably unsolvable by standard transformers
that answer immediately after reading their input. However, in practice,
transformers' reasoning can be improved by allowing them to use a "chain of
thought" or "scratchpad", i.e., generate and condition on a sequence of
intermediate tokens before answering. Motivated by this, we ask: Does such
intermediate generation fundamentally extend the computational power of a
decoder-only transformer? We show that the answer is yes, but the amount of
increase depends crucially on the amount of intermediate generation. For
instance, we find that transformer decoders with a logarithmic number of
decoding steps (w.r.t. the input length) push the limits of standard
transformers only slightly, while a linear number of decoding steps adds a
clear new ability (under standard complexity conjectures): recognizing all
regular languages. Our results also imply that linear steps keep transformer
decoders within context-sensitive languages, and polynomial steps make them
recognize exactly the class of polynomial-time solvable problems -- the first
exact characterization of a type of transformers in terms of standard
complexity classes. Together, our results provide a nuanced framework for
understanding how the length of a transformer's chain of thought or scratchpad
impacts its reasoning power.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Promptor: A Conversational and Autonomous Prompt Generation Agent for Intelligent Text Entry Techniques. (arXiv:2310.08101v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.08101">
<div class="article-summary-box-inner">
<span><p>Text entry is an essential task in our day-to-day digital interactions.
Numerous intelligent features have been developed to streamline this process,
making text entry more effective, efficient, and fluid. These improvements
include sentence prediction and user personalization. However, as deep
learning-based language models become the norm for these advanced features, the
necessity for data collection and model fine-tuning increases. These challenges
can be mitigated by harnessing the in-context learning capability of large
language models such as GPT-3.5. This unique feature allows the language model
to acquire new skills through prompts, eliminating the need for data collection
and fine-tuning. Consequently, large language models can learn various text
prediction techniques. We initially showed that, for a sentence prediction
task, merely prompting GPT-3.5 surpassed a GPT-2 backed system and is
comparable with a fine-tuned GPT-3.5 model, with the latter two methods
requiring costly data collection, fine-tuning and post-processing. However, the
task of prompting large language models to specialize in specific text
prediction tasks can be challenging, particularly for designers without
expertise in prompt engineering. To address this, we introduce Promptor, a
conversational prompt generation agent designed to engage proactively with
designers. Promptor can automatically generate complex prompts tailored to meet
specific needs, thus offering a solution to this challenge. We conducted a user
study involving 24 participants creating prompts for three intelligent text
entry tasks, half of the participants used Promptor while the other half
designed prompts themselves. The results show that Promptor-designed prompts
result in a 35% increase in similarity and 22% in coherence over those by
designers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Context Compression for Auto-regressive Transformers with Sentinel Tokens. (arXiv:2310.08152v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.08152">
<div class="article-summary-box-inner">
<span><p>The quadratic complexity of the attention module makes it gradually become
the bulk of compute in Transformer-based LLMs during generation. Moreover, the
excessive key-value cache that arises when dealing with long inputs also brings
severe issues on memory footprint and inference latency. In this work, we
propose a plug-and-play approach that is able to incrementally compress the
intermediate activation of a specified span of tokens into compact ones,
thereby reducing both memory and computational cost when processing subsequent
context. Experiments on both in-domain language modeling and zero-shot
open-ended document generation demonstrate the advantage of our approach over
sparse attention baselines in terms of fluency, n-gram matching, and semantic
similarity. At last, we comprehensively profile the benefit of context
compression on improving the system throughout. Code is available at
https://github.com/DRSY/KV_Compression.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Factual Consistency for Knowledge-Grounded Dialogue Systems via Knowledge Enhancement and Alignment. (arXiv:2310.08372v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.08372">
<div class="article-summary-box-inner">
<span><p>Pretrained language models (PLMs) based knowledge-grounded dialogue systems
are prone to generate responses that are factually inconsistent with the
provided knowledge source. In such inconsistent responses, the dialogue models
fail to accurately express the external knowledge they rely upon. Inspired by
previous work which identified that feed-forward networks (FFNs) within
Transformers are responsible for factual knowledge expressions, we investigate
two methods to efficiently improve the factual expression capability {of FFNs}
by knowledge enhancement and alignment respectively. We first propose
\textsc{K-Dial}, which {explicitly} introduces {extended FFNs in Transformers
to enhance factual knowledge expressions} given the specific patterns of
knowledge-grounded dialogue inputs. Additionally, we apply the reinforcement
learning for factual consistency (RLFC) method to implicitly adjust FFNs'
expressions in responses by aligning with gold knowledge for the factual
consistency preference. To comprehensively assess the factual consistency and
dialogue quality of responses, we employ extensive automatic measures and human
evaluations including sophisticated fine-grained NLI-based metrics.
Experimental results on WoW and CMU\_DoG datasets demonstrate that our methods
efficiently enhance the ability of the FFN module to convey factual knowledge,
validating the efficacy of improving factual consistency for knowledge-grounded
dialogue systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Data-Type Understanding does not emerge from Scaling Vision-Language Models. (arXiv:2310.08577v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.08577">
<div class="article-summary-box-inner">
<span><p>Recent advances in the development of vision-language models (VLMs) are
yielding remarkable success in recognizing visual semantic content, including
impressive instances of compositional image understanding. Here, we introduce
the novel task of Visual Data-Type Identification, a basic perceptual skill
with implications for data curation (e.g., noisy data-removal from large
datasets, domain-specific retrieval) and autonomous vision (e.g.,
distinguishing changing weather conditions from camera lens staining). We
develop two datasets consisting of animal images altered across a diverse set
of 27 visual data-types, spanning four broad categories. An extensive zero-shot
evaluation of 39 VLMs, ranging from 100M to 80B parameters, shows a nuanced
performance landscape. While VLMs are reasonably good at identifying certain
stylistic \textit{data-types}, such as cartoons and sketches, they struggle
with simpler data-types arising from basic manipulations like image rotations
or additive noise. Our findings reveal that (i) model scaling alone yields
marginal gains for contrastively-trained models like CLIP, and (ii) there is a
pronounced drop in performance for the largest auto-regressively trained VLMs
like OpenFlamingo. This finding points to a blind spot in current frontier
VLMs: they excel in recognizing semantic content but fail to acquire an
understanding of visual data-types through scaling. By analyzing the
pre-training distributions of these models and incorporating data-type
information into the captions during fine-tuning, we achieve a significant
enhancement in performance. By exploring this previously uncharted task, we aim
to set the stage for further advancing VLMs to equip them with visual data-type
understanding. Code and datasets are released at
https://github.com/bethgelab/DataTypeIdentification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Out-of-Distribution Detection by Leveraging Between-Layer Transformation Smoothness. (arXiv:2310.02832v1 [cs.LG] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2310.02832">
<div class="article-summary-box-inner">
<span><p>Effective OOD detection is crucial for reliable machine learning models, yet
most current methods are limited in practical use due to requirements like
access to training data or intervention in training. We present a novel method
for detecting OOD data in deep neural networks based on transformation
smoothness between intermediate layers of a network (BLOOD), which is
applicable to pre-trained models without access to training data. BLOOD
utilizes the tendency of between-layer representation transformations of
in-distribution (ID) data to be smoother than the corresponding transformations
of OOD data, a property that we also demonstrate empirically for Transformer
networks. We evaluate BLOOD on several text classification tasks with
Transformer networks and demonstrate that it outperforms methods with
comparable resource requirements. Our analysis also suggests that when learning
simpler tasks, OOD data transformations maintain their original sharpness,
whereas sharpness increases with more complex tasks.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-10-17 23:11:05.385995736 UTC">2023-10-17 23:11:05 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>