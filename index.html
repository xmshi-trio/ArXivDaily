<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-02-22T01:30:00Z">02-22</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Spoken Entity Extraction for Virtual Agents. (arXiv:2302.10186v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10186">
<div class="article-summary-box-inner">
<span><p>This paper reimagines some aspects of speech processing using speech
encoders, specifically about extracting entities directly from speech, with no
intermediate textual representation. In human-computer conversations,
extracting entities such as names, postal addresses and email addresses from
speech is a challenging task. In this paper, we study the impact of fine-tuning
pre-trained speech encoders on extracting spoken entities in human-readable
form directly from speech without the need for text transcription. We
illustrate that such a direct approach optimizes the encoder to transcribe only
the entity relevant portions of speech, ignoring the superfluous portions such
as carrier phrases and spellings of entities. In the context of dialogs from an
enterprise virtual agent, we demonstrate that the 1-step approach outperforms
the typical 2-step cascade of first generating lexical transcriptions followed
by text-based entity extraction for identifying spoken entities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty-Aware Reward-based Deep Reinforcement Learning for Intent Analysis of Social Media Information. (arXiv:2302.10195v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10195">
<div class="article-summary-box-inner">
<span><p>Due to various and serious adverse impacts of spreading fake news, it is
often known that only people with malicious intent would propagate fake news.
However, it is not necessarily true based on social science studies.
Distinguishing the types of fake news spreaders based on their intent is
critical because it will effectively guide how to intervene to mitigate the
spread of fake news with different approaches. To this end, we propose an
intent classification framework that can best identify the correct intent of
fake news. We will leverage deep reinforcement learning (DRL) that can optimize
the structural representation of each tweet by removing noisy words from the
input sequence when appending an actor to the long short-term memory (LSTM)
intent classifier. Policy gradient DRL model (e.g., REINFORCE) can lead the
actor to a higher delayed reward. We also devise a new uncertainty-aware
immediate reward using a subjective opinion that can explicitly deal with
multidimensional uncertainty for effective decision-making. Via 600K training
episodes from a fake news tweets dataset with an annotated intent class, we
evaluate the performance of uncertainty-aware reward in DRL. Evaluation results
demonstrate that our proposed framework efficiently reduces the number of
selected words to maintain a high 95\% multi-class accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT. (arXiv:2302.10198v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10198">
<div class="article-summary-box-inner">
<span><p>Recently, ChatGPT has attracted great attention, as it can generate fluent
and high-quality responses to human inquiries. Several prior studies have shown
that ChatGPT attains remarkable generation ability compared with existing
models. However, the quantitative analysis of ChatGPT's understanding ability
has been given little attention. In this report, we explore the understanding
ability of ChatGPT by evaluating it on the most popular GLUE benchmark, and
comparing it with 4 representative fine-tuned BERT-style models. We find that:
1) ChatGPT falls short in handling paraphrase and similarity tasks; 2) ChatGPT
outperforms all BERT models on inference tasks by a large margin; 3) ChatGPT
achieves comparable performance compared with BERT on sentiment analysis and
question answering tasks. Additionally, several bad cases from inference tasks
show the potential limitation of ChatGPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating the Effectiveness of Pre-trained Language Models in Predicting the Helpfulness of Online Product Reviews. (arXiv:2302.10199v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10199">
<div class="article-summary-box-inner">
<span><p>Businesses and customers can gain valuable information from product reviews.
The sheer number of reviews often necessitates ranking them based on their
potential helpfulness. However, only a few reviews ever receive any helpfulness
votes on online marketplaces. Sorting all reviews based on the few existing
votes can cause helpful reviews to go unnoticed because of the limited
attention span of readers. The problem of review helpfulness prediction is even
more important for higher review volumes, and newly written reviews or launched
products. In this work we compare the use of RoBERTa and XLM-R language models
to predict the helpfulness of online product reviews. The contributions of our
work in relation to literature include extensively investigating the efficacy
of state-of-the-art language models -- both monolingual and multilingual --
against a robust baseline, taking ranking metrics into account when assessing
these approaches, and assessing multilingual models for the first time. We
employ the Amazon review dataset for our experiments. According to our study on
several product categories, multilingual and monolingual pre-trained language
models outperform the baseline that utilizes random forest with handcrafted
features as much as 23% in RMSE. Pre-trained language models reduce the need
for complex text feature engineering. However, our results suggest that
pre-trained multilingual models may not be used for fine-tuning only one
language. We assess the performance of language models with and without
additional features. Our results show that including additional features like
product rating by the reviewer can further help the predictive methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-Shot Information Extraction via Chatting with ChatGPT. (arXiv:2302.10205v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10205">
<div class="article-summary-box-inner">
<span><p>Zero-shot information extraction (IE) aims to build IE systems from the
unannotated text. It is challenging due to involving little human intervention.
Challenging but worthwhile, zero-shot IE reduces the time and effort that data
labeling takes. Recent efforts on large language models (LLMs, e.g., GPT-3,
ChatGPT) show promising performance on zero-shot settings, thus inspiring us to
explore prompt-based methods. In this work, we ask whether strong IE models can
be constructed by directly prompting LLMs. Specifically, we transform the
zero-shot IE task into a multi-turn question-answering problem with a two-stage
framework (ChatIE). With the power of ChatGPT, we extensively evaluate our
framework on three IE tasks: entity-relation triple extract, named entity
recognition, and event extraction. Empirical results on six datasets across two
languages show that ChatIE achieves impressive performance and even surpasses
some full-shot models on several datasets (e.g., NYT11-HRL). We believe that
our work could shed light on building IE models with limited resources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">See Your Heart: Psychological states Interpretation through Visual Creations. (arXiv:2302.10276v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10276">
<div class="article-summary-box-inner">
<span><p>In psychoanalysis, generating interpretations to one's psychological state
through visual creations is facing significant demands. The two main tasks of
existing studies in the field of computer vision, sentiment/emotion
classification and affective captioning, can hardly satisfy the requirement of
psychological interpreting. To meet the demands for psychoanalysis, we
introduce a challenging task, \textbf{V}isual \textbf{E}motion
\textbf{I}nterpretation \textbf{T}ask (VEIT). VEIT requires AI to generate
reasonable interpretations of creator's psychological state through visual
creations. To support the task, we present a multimodal dataset termed SpyIn
(\textbf{S}and\textbf{p}la\textbf{y} \textbf{In}terpretation Dataset), which is
psychological theory supported and professional annotated. Dataset analysis
illustrates that SpyIn is not only able to support VEIT, but also more
challenging compared with other captioning datasets. Building on SpyIn, we
conduct experiments of several image captioning method, and propose a
visual-semantic combined model which obtains a SOTA result on SpyIn. The
results indicate that VEIT is a more challenging task requiring scene graph
information and psychological knowledge. Our work also show a promise for AI to
analyze and explain inner world of humanity through visual creations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LiT Tuned Models for Efficient Species Detection. (arXiv:2302.10281v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10281">
<div class="article-summary-box-inner">
<span><p>Recent advances in training vision-language models have demonstrated
unprecedented robustness and transfer learning effectiveness; however, standard
computer vision datasets are image-only, and therefore not well adapted to such
training methods. Our paper introduces a simple methodology for adapting any
fine-grained image classification dataset for distributed vision-language
pretraining. We implement this methodology on the challenging iNaturalist-2021
dataset, comprised of approximately 2.7 million images of macro-organisms
across 10,000 classes, and achieve a new state-of-the art model in terms of
zero-shot classification accuracy. Somewhat surprisingly, our model (trained
using a new method called locked-image text tuning) uses a pre-trained, frozen
vision representation, proving that language alignment alone can attain strong
transfer learning performance, even on fractious, long-tailed datasets. Our
approach opens the door for utilizing high quality vision-language pretrained
models in agriculturally relevant applications involving species detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Paparazzi: A Deep Dive into the Capabilities of Language and Vision Models for Grounding Viewpoint Descriptions. (arXiv:2302.10282v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10282">
<div class="article-summary-box-inner">
<span><p>Existing language and vision models achieve impressive performance in
image-text understanding. Yet, it is an open question to what extent they can
be used for language understanding in 3D environments and whether they
implicitly acquire 3D object knowledge, e.g. about different views of an
object. In this paper, we investigate whether a state-of-the-art language and
vision model, CLIP, is able to ground perspective descriptions of a 3D object
and identify canonical views of common objects based on text queries. We
present an evaluation framework that uses a circling camera around a 3D object
to generate images from different viewpoints and evaluate them in terms of
their similarity to natural language descriptions. We find that a pre-trained
CLIP model performs poorly on most canonical views and that fine-tuning using
hard negative sampling and random contrasting yields good results even under
conditions with little available training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Large Language Models Change User Preference Adversarially?. (arXiv:2302.10291v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10291">
<div class="article-summary-box-inner">
<span><p>Pretrained large language models (LLMs) are becoming increasingly powerful
and ubiquitous in mainstream applications such as being a personal assistant, a
dialogue model, etc. As these models become proficient in deducing user
preferences and offering tailored assistance, there is an increasing concern
about the ability of these models to influence, modify and in the extreme case
manipulate user preference adversarially. The issue of lack of interpretability
in these models in adversarial settings remains largely unsolved. This work
tries to study adversarial behavior in user preferences from the lens of
attention probing, red teaming and white-box analysis. Specifically, it
provides a bird's eye view of existing literature, offers red teaming samples
for dialogue models like ChatGPT and GODEL and probes the attention mechanism
in the latter for non-adversarial and adversarial settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ViewCo: Discovering Text-Supervised Segmentation Masks via Multi-View Semantic Consistency. (arXiv:2302.10307v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10307">
<div class="article-summary-box-inner">
<span><p>Recently, great success has been made in learning visual representations from
text supervision, facilitating the emergence of text-supervised semantic
segmentation. However, existing works focus on pixel grouping and cross-modal
semantic alignment, while ignoring the correspondence among multiple augmented
views of the same image. To overcome such limitation, we propose
multi-\textbf{View} \textbf{Co}nsistent learning (ViewCo) for text-supervised
semantic segmentation. Specifically, we first propose text-to-views consistency
modeling to learn correspondence for multiple views of the same input image.
Additionally, we propose cross-view segmentation consistency modeling to
address the ambiguity issue of text supervision by contrasting the segment
features of Siamese visual encoders. The text-to-views consistency benefits the
dense assignment of the visual features by encouraging different crops to align
with the same text, while the cross-view segmentation consistency modeling
provides additional self-supervision, overcoming the limitation of ambiguous
text supervision for segmentation masks. Trained with large-scale image-text
data, our model can directly segment objects of arbitrary categories in a
zero-shot manner. Extensive experiments show that ViewCo outperforms
state-of-the-art methods on average by up to 2.9\%, 1.6\%, and 2.4\% mIoU on
PASCAL VOC2012, PASCAL Context, and COCO, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Named Entity Recognition. (arXiv:2302.10314v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10314">
<div class="article-summary-box-inner">
<span><p>Named Entity Recognition (NER) is a challenging and widely studied task that
involves detecting and typing entities in text. So far,NER still approaches
entity typing as a task of classification into universal classes (e.g. date,
person, or location). Recent advances innatural language processing focus on
architectures of increasing complexity that may lead to overfitting and
memorization, and thus, underuse of context. Our work targets situations where
the type of entities depends on the context and cannot be solved solely by
memorization. We hence introduce a new task: Dynamic Named Entity Recognition
(DNER), providing a framework to better evaluate the ability of algorithms to
extract entities by exploiting the context. The DNER benchmark is based on two
datasets, DNER-RotoWire and DNER-IMDb. We evaluate baseline models and present
experiments reflecting issues and research axes related to this novel task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalization algorithm of multimodal pre-training model based on graph-text self-supervised training. (arXiv:2302.10315v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10315">
<div class="article-summary-box-inner">
<span><p>Recently, a large number of studies have shown that the introduction of
visual information can effectively improve the effect of neural machine
translation (NMT). Its effectiveness largely depends on the availability of a
large number of bilingual parallel sentence pairs and manual image annotation.
The lack of images and the effectiveness of images have been difficult to
solve. In this paper, a multimodal pre-training generalization algorithm for
self-supervised training is proposed, which overcomes the lack of visual
information and inaccuracy, and thus extends the applicability of images on
NMT. Specifically, we will search for many pictures from the existing sentences
through the search engine, and then through the relationship between visual
information and text, do the self-supervised training task of graphics and text
to obtain more effective visual information for text. We show that when the
filtered information is used as multimodal machine translation for fine-tuning,
the effect of translation in the global voice dataset is 0.5 BLEU higher than
the baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Transformers without Shortcuts: Modifying Self-attention for Faithful Signal Propagation. (arXiv:2302.10322v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10322">
<div class="article-summary-box-inner">
<span><p>Skip connections and normalisation layers form two standard architectural
components that are ubiquitous for the training of Deep Neural Networks (DNNs),
but whose precise roles are poorly understood. Recent approaches such as Deep
Kernel Shaping have made progress towards reducing our reliance on them, using
insights from wide NN kernel theory to improve signal propagation in vanilla
DNNs (which we define as networks without skips or normalisation). However,
these approaches are incompatible with the self-attention layers present in
transformers, whose kernels are intrinsically more complicated to analyse and
control. And so the question remains: is it possible to train deep vanilla
transformers? We answer this question in the affirmative by designing several
approaches that use combinations of parameter initialisations, bias matrices
and location-dependent rescaling to achieve faithful signal propagation in
vanilla transformers. Our methods address various intricacies specific to
signal propagation in transformers, including the interaction with positional
encoding and causal masking. In experiments on WikiText-103 and C4, our
approaches enable deep transformers without normalisation to train at speeds
matching their standard counterparts, and deep vanilla transformers to reach
the same performance as standard ones after about 5 times more iterations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fantastic Rewards and How to Tame Them: A Case Study on Reward Learning for Task-oriented Dialogue Systems. (arXiv:2302.10342v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10342">
<div class="article-summary-box-inner">
<span><p>When learning task-oriented dialogue (ToD) agents, reinforcement learning
(RL) techniques can naturally be utilized to train dialogue strategies to
achieve user-specific goals. Prior works mainly focus on adopting advanced RL
techniques to train the ToD agents, while the design of the reward function is
not well studied. This paper aims at answering the question of how to
efficiently learn and leverage a reward function for training end-to-end (E2E)
ToD agents. Specifically, we introduce two generalized objectives for
reward-function learning, inspired by the classical learning-to-rank
literature. Further, we utilize the learned reward function to guide the
training of the E2E ToD agent. With the proposed techniques, we achieve
competitive results on the E2E response-generation task on the Multiwoz 2.0
dataset. Source code and checkpoints are publicly released at
https://github.com/Shentao-YANG/Fantastic_Reward_ICLR2023.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the Limits of Transfer Learning with Unified Model in the Cybersecurity Domain. (arXiv:2302.10346v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10346">
<div class="article-summary-box-inner">
<span><p>With the increase in cybersecurity vulnerabilities of software systems, the
ways to exploit them are also increasing. Besides these, malware threats,
irregular network interactions, and discussions about exploits in public forums
are also on the rise. To identify these threats faster, to detect potentially
relevant entities from any texts, and to be aware of software vulnerabilities,
automated approaches are necessary. Application of natural language processing
(NLP) techniques in the Cybersecurity domain can help in achieving this.
However, there are challenges such as the diverse nature of texts involved in
the cybersecurity domain, the unavailability of large-scale publicly available
datasets, and the significant cost of hiring subject matter experts for
annotations. One of the solutions is building multi-task models that can be
trained jointly with limited data. In this work, we introduce a generative
multi-task model, Unified Text-to-Text Cybersecurity (UTS), trained on malware
reports, phishing site URLs, programming code constructs, social media data,
blogs, news articles, and public forum posts. We show UTS improves the
performance of some cybersecurity datasets. We also show that with a few
examples, UTS can be adapted to novel unseen tasks and the nature of data
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Time to Embrace Natural Language Processing (NLP)-based Digital Pathology: Benchmarking NLP- and Convolutional Neural Network-based Deep Learning Pipelines. (arXiv:2302.10406v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10406">
<div class="article-summary-box-inner">
<span><p>NLP-based computer vision models, particularly vision transformers, have been
shown to outperform CNN models in many imaging tasks. However, most digital
pathology artificial-intelligence models are based on CNN architectures,
probably owing to a lack of data regarding NLP models for pathology images. In
this study, we developed digital pathology pipelines to benchmark the five most
recently proposed NLP models (vision transformer (ViT), Swin Transformer,
MobileViT, CMT, and Sequencer2D) and four popular CNN models (ResNet18,
ResNet50, MobileNetV2, and EfficientNet) to predict biomarkers in colorectal
cancer (microsatellite instability, CpG island methylator phenotype, and BRAF
mutation). Hematoxylin and eosin-stained whole-slide images from Molecular and
Cellular Oncology and The Cancer Genome Atlas were used as training and
external validation datasets, respectively. Cross-study external validations
revealed that the NLP-based models significantly outperformed the CNN-based
models in biomarker prediction tasks, improving the overall prediction and
precision up to approximately 10% and 26%, respectively. Notably, compared with
existing models in the current literature using large training datasets, our
NLP models achieved state-of-the-art predictions for all three biomarkers using
a relatively small training dataset, suggesting that large training datasets
are not a prerequisite for NLP models or transformers, and NLP may be more
suitable for clinical studies in which small training datasets are commonly
collected. The superior performance of Sequencer2D suggests that further
research and innovation on both transformer and bidirectional long short-term
memory architectures are warranted in the field of digital pathology. NLP
models can replace classic CNN architectures and become the new workhorse
backbone in the field of digital pathology.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mask-guided BERT for Few Shot Text Classification. (arXiv:2302.10447v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10447">
<div class="article-summary-box-inner">
<span><p>Transformer-based language models have achieved significant success in
various domains. However, the data-intensive nature of the transformer
architecture requires much labeled data, which is challenging in low-resource
scenarios (i.e., few-shot learning (FSL)). The main challenge of FSL is the
difficulty of training robust models on small amounts of samples, which
frequently leads to overfitting. Here we present Mask-BERT, a simple and
modular framework to help BERT-based architectures tackle FSL. The proposed
approach fundamentally differs from existing FSL strategies such as prompt
tuning and meta-learning. The core idea is to selectively apply masks on text
inputs and filter out irrelevant information, which guides the model to focus
on discriminative tokens that influence prediction results. In addition, to
make the text representations from different categories more separable and the
text representations from the same category more compact, we introduce a
contrastive learning loss function. Experimental results on public-domain
benchmark datasets demonstrate the effectiveness of Mask-BERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KG-ECO: Knowledge Graph Enhanced Entity Correction for Query Rewriting. (arXiv:2302.10454v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10454">
<div class="article-summary-box-inner">
<span><p>Query Rewriting (QR) plays a critical role in large-scale dialogue systems
for reducing frictions. When there is an entity error, it imposes extra
challenges for a dialogue system to produce satisfactory responses. In this
work, we propose KG-ECO: Knowledge Graph enhanced Entity COrrection for query
rewriting, an entity correction system with corrupt entity span detection and
entity retrieval/re-ranking functionalities.To boost the model performance, we
incorporate Knowledge Graph (KG) to provide entity structural information
(neighboring entities encoded by graph neural networks) and textual information
(KG entity descriptions encoded by RoBERTa). Experimental results show that our
approach yields a clear performance gain over two baselines: utterance level QR
and entity correction without utilizing KG information. The proposed system is
particularly effective for few-shot learning cases where target entities are
rarely seen in training or there is a KG relation between the target entity and
other contextual entities in the query.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tell Model Where to Attend: Improving Interpretability of Aspect-Based Sentiment Classification via Small Explanation Annotations. (arXiv:2302.10479v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10479">
<div class="article-summary-box-inner">
<span><p>Gradient-based explanation methods play an important role in the field of
interpreting complex deep neural networks for NLP models. However, the existing
work has shown that the gradients of a model are unstable and easily
manipulable, which impacts the model's reliability largely. According to our
preliminary analyses, we also find the interpretability of gradient-based
methods is limited for complex tasks, such as aspect-based sentiment
classification (ABSC). In this paper, we propose an
\textbf{I}nterpretation-\textbf{E}nhanced \textbf{G}radient-based framework for
\textbf{A}BSC via a small number of explanation annotations, namely
\texttt{{IEGA}}. Particularly, we first calculate the word-level saliency map
based on gradients to measure the importance of the words in the sentence
towards the given aspect. Then, we design a gradient correction module to
enhance the model's attention on the correct parts (e.g., opinion words). Our
model is model agnostic and task agnostic so that it can be integrated into the
existing ABSC methods or other tasks. Comprehensive experimental results on
four benchmark datasets show that our \texttt{IEGA} can improve not only the
interpretability of the model but also the performance and robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Co-Driven Recognition of Semantic Consistency via the Fusion of Transformer and HowNet Sememes Knowledge. (arXiv:2302.10570v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10570">
<div class="article-summary-box-inner">
<span><p>Semantic consistency recognition aims to detect and judge whether the
semantics of two text sentences are consistent with each other. However, the
existing methods usually encounter the challenges of synonyms, polysemy and
difficulty to understand long text. To solve the above problems, this paper
proposes a co-driven semantic consistency recognition method based on the
fusion of Transformer and HowNet sememes knowledge. Multi-level encoding of
internal sentence structures via data-driven is carried out firstly by
Transformer, sememes knowledge base HowNet is introduced for knowledge-driven
to model the semantic knowledge association among sentence pairs. Then,
interactive attention calculation is carried out utilizing soft-attention and
fusion the knowledge with sememes matrix. Finally, bidirectional long
short-term memory network (BiLSTM) is exploited to encode the conceptual
semantic information and infer the semantic consistency. Experiments are
conducted on two financial text matching datasets (BQ, AFQMC) and a
cross-lingual adversarial dataset (PAWSX) for paraphrase identification.
Compared with lightweight models including DSSM, MwAN, DRCN, and pre-training
models such as ERNIE etc., the proposed model can not only improve the accuracy
of semantic consistency recognition effectively (by 2.19%, 5.57% and 6.51%
compared with the DSSM, MWAN and DRCN models on the BQ dataset), but also
reduce the number of model parameters (to about 16M). In addition, driven by
the HowNet sememes knowledge, the proposed method is promising to adapt to
scenarios with long text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Connecting Humanities and Social Sciences: Applying Language and Speech Technology to Online Panel Surveys. (arXiv:2302.10593v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10593">
<div class="article-summary-box-inner">
<span><p>In this paper, we explore the application of language and speech technology
to open-ended questions in a Dutch panel survey. In an experimental wave
respondents could choose to answer open questions via speech or keyboard.
Automatic speech recognition (ASR) was used to process spoken responses. We
evaluated answers from these input modalities to investigate differences
between spoken and typed answers.We report the errors the ASR system produces
and investigate the impact of these errors on downstream analyses. Open-ended
questions give more freedom to answer for respondents, but entail a non-trivial
amount of work to analyse. We evaluated the feasibility of using
transformer-based models (e.g. BERT) to apply sentiment analysis and topic
modelling on the answers of open questions. A big advantage of
transformer-based models is that they are trained on a large amount of language
materials and do not necessarily need training on the target materials. This is
especially advantageous for survey data, which does not contain a lot of text
materials. We tested the quality of automatic sentiment analysis by comparing
automatic labeling with three human raters and tested the robustness of topic
modelling by comparing the generated models based on automatic and manually
transcribed spoken answers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Playing the Werewolf game with artificial intelligence for language understanding. (arXiv:2302.10646v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10646">
<div class="article-summary-box-inner">
<span><p>The Werewolf game is a social deduction game based on free natural language
communication, in which players try to deceive others in order to survive. An
important feature of this game is that a large portion of the conversations are
false information, and the behavior of artificial intelligence (AI) in such a
situation has not been widely investigated. The purpose of this study is to
develop an AI agent that can play Werewolf through natural language
conversations. First, we collected game logs from 15 human players. Next, we
fine-tuned a Transformer-based pretrained language model to construct a value
network that can predict a posterior probability of winning a game at any given
phase of the game and given a candidate for the next action. We then developed
an AI agent that can interact with humans and choose the best voting target on
the basis of its probability from the value network. Lastly, we evaluated the
performance of the agent by having it actually play the game with human
players. We found that our AI agent, Deep Wolf, could play Werewolf as
competitively as average human players in a villager or a betrayer role,
whereas Deep Wolf was inferior to human players in a werewolf or a seer role.
These results suggest that current language models have the capability to
suspect what others are saying, tell a lie, or detect lies in conversations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generic Dependency Modeling for Multi-Party Conversation. (arXiv:2302.10680v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10680">
<div class="article-summary-box-inner">
<span><p>To model the dependencies between utterances in multi-party conversations, we
propose a simple and generic framework based on the dependency parsing results
of utterances. Particularly, we present an approach to encoding the
dependencies in the form of relative dependency encoding (ReDE) and illustrate
how to implement it in Transformers by modifying the computation of
self-attention. Experimental results on four multi-party conversation
benchmarks show that this framework successfully boosts the general performance
of two Transformer-based language models and leads to comparable or even
superior performance compared to the state-of-the-art methods. The codes are
available at https://github.com/shenwzh3/ReDE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parallel Sentence-Level Explanation Generation for Real-World Low-Resource Scenarios. (arXiv:2302.10707v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10707">
<div class="article-summary-box-inner">
<span><p>In order to reveal the rationale behind model predictions, many works have
exploited providing explanations in various forms. Recently, to further
guarantee readability, more and more works turn to generate sentence-level
human language explanations. However, current works pursuing sentence-level
explanations rely heavily on annotated training data, which limits the
development of interpretability to only a few tasks. As far as we know, this
paper is the first to explore this problem smoothly from weak-supervised
learning to unsupervised learning. Besides, we also notice the high latency of
autoregressive sentence-level explanation generation, which leads to
asynchronous interpretability after prediction. Therefore, we propose a
non-autoregressive interpretable model to facilitate parallel explanation
generation and simultaneous prediction. Through extensive experiments on
Natural Language Inference task and Spouse Prediction task, we find that users
are able to train classifiers with comparable performance $10-15\times$ faster
with parallel explanation generation using only a few or no annotated training
data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChatGPT: Jack of all trades, master of none. (arXiv:2302.10724v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10724">
<div class="article-summary-box-inner">
<span><p>OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and
revolutionized the approach in artificial intelligence to human-model
interaction. The first contact with the chatbot reveals its ability to provide
detailed and precise answers in various areas. There are several publications
on ChatGPT evaluation, testing its effectiveness on well-known natural language
processing (NLP) tasks. However, the existing studies are mostly non-automated
and tested on a very limited scale. In this work, we examined ChatGPT's
capabilities on 25 diverse analytical NLP tasks, most of them subjective even
to humans, such as sentiment analysis, emotion recognition, offensiveness and
stance detection, natural language inference, word sense disambiguation,
linguistic acceptability and question answering. We automated ChatGPT's
querying process and analyzed more than 38k responses. Our comparison of its
results with available State-of-the-Art (SOTA) solutions showed that the
average loss in quality of the ChatGPT model was about 25% for zero-shot and
few-shot evaluation. We showed that the more difficult the task (lower SOTA
performance), the higher the ChatGPT loss. It especially refers to pragmatic
NLP problems like emotion recognition. We also tested the ability of
personalizing ChatGPT responses for selected subjective tasks via Random
Contextual Few-Shot Personalization, and we obtained significantly better
user-based predictions. Additional qualitative analysis revealed a ChatGPT
bias, most likely due to the rules imposed on human trainers by OpenAI. Our
results provide the basis for a fundamental discussion of whether the high
quality of recent predictive NLP models can indicate a tool's usefulness to
society and how the learning and validation procedures for such systems should
be established.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-World Deployment and Evaluation of Kwame for Science, An AI Teaching Assistant for Science Education in West Africa. (arXiv:2302.10786v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10786">
<div class="article-summary-box-inner">
<span><p>Africa has a high student-to-teacher ratio which limits students' access to
teachers for learning support such as educational question answering. In this
work, we extended Kwame, our previous AI teaching assistant for coding
education, adapted it for science education, and deployed it as a web app.
Kwame for Science provides passages from well-curated knowledge sources and
related past national exam questions as answers to questions from students
based on the Integrated Science subject of the West African Senior Secondary
Certificate Examination (WASSCE). Furthermore, students can view past national
exam questions along with their answers and filter by year, question type
(objectives, theory, and practicals), and topics that were automatically
categorized by a topic detection model which we developed (91% unweighted
average recall). We deployed Kwame for Science in the real world over 8 months
and had 750 users across 32 countries (15 in Africa) and 1.5K questions asked.
Our evaluation showed an 87.2% top 3 accuracy (n=109 questions) implying that
Kwame for Science has a high chance of giving at least one useful answer among
the 3 displayed. We categorized the reasons the model incorrectly answered
questions to provide insights for future improvements. We also share challenges
and lessons with the development, deployment, and human-computer interaction
component of such a tool to enable other researchers to deploy similar tools.
With a first-of-its-kind tool within the African context, Kwame for Science has
the potential to enable the delivery of scalable, cost-effective, and quality
remote education to millions of people across Africa.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TherapyView: Visualizing Therapy Sessions with Temporal Topic Modeling and AI-Generated Arts. (arXiv:2302.10845v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10845">
<div class="article-summary-box-inner">
<span><p>We present the TherapyView, a demonstration system to help therapists
visualize the dynamic contents of past treatment sessions, enabled by the
state-of-the-art neural topic modeling techniques to analyze the topical
tendencies of various psychiatric conditions and deep learning-based image
generation engine to provide a visual summary. The system incorporates temporal
modeling to provide a time-series representation of topic similarities at a
turn-level resolution and AI-generated artworks given the dialogue segments to
provide a concise representations of the contents covered in the session,
offering interpretable insights for therapists to optimize their strategies and
enhance the effectiveness of psychotherapy. This system provides a proof of
concept of AI-augmented therapy tools with e in-depth understanding of the
patient's mental state and enabling more effective treatment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Offline Reinforcement Learning for Mixture-of-Expert Dialogue Management. (arXiv:2302.10850v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10850">
<div class="article-summary-box-inner">
<span><p>Reinforcement learning (RL) has shown great promise for developing dialogue
management (DM) agents that are non-myopic, conduct rich conversations, and
maximize overall user satisfaction. Despite recent developments in RL and
language models (LMs), using RL to power conversational chatbots remains
challenging, in part because RL requires online exploration to learn
effectively, whereas collecting novel human-bot interactions can be expensive
and unsafe. This issue is exacerbated by the combinatorial action spaces facing
these algorithms, as most LM agents generate responses at the word level. We
develop a variety of RL algorithms, specialized to dialogue planning, that
leverage recent Mixture-of-Expert Language Models (MoE-LMs) -- models that
capture diverse semantics, generate utterances reflecting different intents,
and are amenable for multi-turn DM. By exploiting MoE-LM structure, our methods
significantly reduce the size of the action space and improve the efficacy of
RL-based DM.
</p>
<p>We evaluate our methods in open-domain dialogue to demonstrate their
effectiveness w.r.t.\ the diversity of intent in generated utterances and
overall DM performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hyena Hierarchy: Towards Larger Convolutional Language Models. (arXiv:2302.10866v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10866">
<div class="article-summary-box-inner">
<span><p>Recent advances in deep learning have relied heavily on the use of large
Transformers due to their ability to learn at scale. However, the core building
block of Transformers, the attention operator, exhibits quadratic cost in
sequence length, limiting the amount of context accessible. Existing
subquadratic methods based on low-rank and sparse approximations need to be
combined with dense attention layers to match Transformers, indicating a gap in
capability. In this work, we propose Hyena, a subquadratic drop-in replacement
for attention constructed by interleaving implicitly parametrized long
convolutions and data-controlled gating. In recall and reasoning tasks on
sequences of thousands to hundreds of thousands of tokens, Hyena improves
accuracy by more than 50 points over operators relying on state-spaces and
other implicit and explicit methods, matching attention-based models. We set a
new state-of-the-art for dense-attention-free architectures on language
modeling in standard datasets (WikiText103 and The Pile), reaching Transformer
quality with a 20% reduction in training compute required at sequence length
2K. Hyena operators are twice as fast as highly optimized attention at sequence
length 8K, and 100x faster at sequence length 64K.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient CTC Regularization via Coarse Labels for End-to-End Speech Translation. (arXiv:2302.10871v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10871">
<div class="article-summary-box-inner">
<span><p>For end-to-end speech translation, regularizing the encoder with the
Connectionist Temporal Classification (CTC) objective using the source
transcript or target translation as labels can greatly improve quality metrics.
However, CTC demands an extra prediction layer over the vocabulary space,
bringing in nonnegligible model parameters and computational overheads,
although this layer is typically not used for inference. In this paper, we
re-examine the need for genuine vocabulary labels for CTC for regularization
and explore strategies to reduce the CTC label space, targeting improved
efficiency without quality degradation. We propose coarse labeling for CTC
(CoLaCTC), which merges vocabulary labels via simple heuristic rules, such as
using truncation, division or modulo (MOD) operations. Despite its simplicity,
our experiments on 4 source and 8 target languages show that CoLaCTC with MOD
particularly can compress the label space aggressively to 256 and even further,
gaining training efficiency (1.18x ~ 1.77x speedup depending on the original
vocabulary size) yet still delivering comparable or better performance than the
CTC baseline. We also show that CoLaCTC successfully generalizes to CTC
regularization regardless of using transcript or translation for labeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">$k$NN-Adapter: Efficient Domain Adaptation for Black-Box Language Models. (arXiv:2302.10879v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.10879">
<div class="article-summary-box-inner">
<span><p>Fine-tuning a language model on a new domain is standard practice for domain
adaptation. However, it can be infeasible when it comes to modern large-scale
language models such as GPT-3, which can only be accessed through APIs, making
it difficult to access the internal parameters of the model. In this paper, we
propose $k$NN-Adapter, a method to effectively adapt these black-box large
language models (LLMs) to a new domain. The $k$NN-Adapter builds on top of the
retrieval-augmented language model, and adaptively learns to interpolate the
output of the language model with retrieval results from a datastore consisting
of the target domain data. Our experiments on four different domains
demonstrate that $k$NN-Adapter significantly improves perplexity, and works
particularly well in settings with limited access to LLMs. Additionally, we
show that $k$NN-Adapter is more effective than fine-tuning when the amount of
training data is limited. We also release a dataset to encourage further study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Wav2vec 2.0 fine-tuning for improved speech emotion recognition. (arXiv:2110.06309v3 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06309">
<div class="article-summary-box-inner">
<span><p>While Wav2Vec 2.0 has been proposed for speech recognition (ASR), it can also
be used for speech emotion recognition (SER); its performance can be
significantly improved using different fine-tuning strategies. Two baseline
methods, vanilla fine-tuning (V-FT) and task adaptive pretraining (TAPT) are
first presented. We show that V-FT is able to outperform state-of-the-art
models on the IEMOCAP dataset. TAPT, an existing NLP fine-tuning strategy,
further improves the performance on SER. We also introduce a novel fine-tuning
method termed P-TAPT, which modifies the TAPT objective to learn contextualized
emotion representations. Experiments show that P-TAPT performs better than
TAPT, especially under low-resource settings. Compared to prior works in this
literature, our top-line system achieved a 7.4\% absolute improvement in
unweighted accuracy (UA) over the state-of-the-art performance on IEMOCAP. Our
code is publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient and Training-Free Control of Language Generation. (arXiv:2205.06036v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06036">
<div class="article-summary-box-inner">
<span><p>In recent years, there has been a growing interest in the development of
language models capable of generating text with controllable attributes. While
several approaches have been proposed, many of these methods require
condition-specific data or significant computational resources. In this study,
we propose a novel method called Gamma Sampling, which enables controllable
language generation without the need for any training data and maintains a fast
generation speed. Gamma Sampling incorporates attribute-related information
into the sampling process, effectively guiding the language model to produce
text with desired attributes. Our experimental results demonstrate that Gamma
Sampling, when applied to GPT2, outperforms representative baselines in terms
of diversity, attribute relevance, and overall quality of the generated
samples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Ignore Adversarial Attacks. (arXiv:2205.11551v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11551">
<div class="article-summary-box-inner">
<span><p>Despite the strong performance of current NLP models, they can be brittle
against adversarial attacks. To enable effective learning against adversarial
inputs, we introduce the use of rationale models that can explicitly learn to
ignore attack tokens. We find that the rationale models can successfully ignore
over 90% of attack tokens. This approach leads to consistent sizable
improvements ($\sim$10%) over baseline models in robustness on three datasets
for both BERT and RoBERTa, and also reliably outperforms data augmentation with
adversarial examples alone. In many cases, we find that our method is able to
close the gap between model performance on a clean test set and an attacked
test set and hence reduce the effect of adversarial attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">History Compression via Language Models in Reinforcement Learning. (arXiv:2205.12258v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12258">
<div class="article-summary-box-inner">
<span><p>In a partially observable Markov decision process (POMDP), an agent typically
uses a representation of the past to approximate the underlying MDP. We propose
to utilize a frozen Pretrained Language Transformer (PLT) for history
representation and compression to improve sample efficiency. To avoid training
of the Transformer, we introduce FrozenHopfield, which automatically associates
observations with pretrained token embeddings. To form these associations, a
modern Hopfield network stores these token embeddings, which are retrieved by
queries that are obtained by a random but fixed projection of observations. Our
new method, HELM, enables actor-critic network architectures that contain a
pretrained language Transformer for history representation as a memory module.
Since a representation of the past need not be learned, HELM is much more
sample efficient than competitors. On Minigrid and Procgen environments HELM
achieves new state-of-the-art results. Our code is available at
https://github.com/ml-jku/helm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Affordance Extraction with an External Knowledge Database for Text-Based Simulated Environments. (arXiv:2207.00265v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.00265">
<div class="article-summary-box-inner">
<span><p>Text-based simulated environments have proven to be a valid testbed for
machine learning approaches. The process of affordance extraction can be used
to generate possible actions for interaction within such an environment. In
this paper the capabilities and challenges for utilizing external knowledge
databases (in particular ConceptNet) in the process of affordance extraction
are studied. An algorithm for automated affordance extraction is introduced and
evaluated on the Interactive Fiction (IF) platforms TextWorld and Jericho. For
this purpose, the collected affordances are translated into text commands for
IF agents. To probe the quality of the automated evaluation process, an
additional human baseline study is conducted. The paper illustrates that,
despite some challenges, external databases can in principle be used for
affordance extraction. The paper concludes with recommendations for further
modification and improvement of the process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Parallelism Tradeoff: Limitations of Log-Precision Transformers. (arXiv:2207.00729v2 [cs.CC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.00729">
<div class="article-summary-box-inner">
<span><p>Despite their omnipresence in modern NLP, characterizing the computational
power of transformer neural nets remains an interesting open question. We prove
that transformers whose arithmetic precision is logarithmic in the number of
input tokens (and whose feedforward nets are computable using space linear in
their input) can be simulated by constant-depth logspace-uniform threshold
circuits. This provides insight on the power of transformers using known
results in complexity theory. For example, if $\mathsf L \neq \mathsf P$ (i.e.,
not all poly-time problems can be solved using logarithmic space), then
transformers cannot even accurately solve linear equalities or check membership
in an arbitrary context-free grammar with empty productions. Our result
intuitively emerges from the transformer architecture's high parallelizability.
We thus speculatively introduce the idea of a fundamental parallelism tradeoff:
any model architecture as parallelizable as the transformer will obey
limitations similar to it. Since parallelism is key to training models at
massive scale, this suggests a potential inherent weakness of the scaling
paradigm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text-Derived Knowledge Helps Vision: A Simple Cross-modal Distillation for Video-based Action Anticipation. (arXiv:2210.05991v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.05991">
<div class="article-summary-box-inner">
<span><p>Anticipating future actions in a video is useful for many autonomous and
assistive technologies. Most prior action anticipation work treat this as a
vision modality problem, where the models learn the task information primarily
from the video features in the action anticipation datasets. However, knowledge
about action sequences can also be obtained from external textual data. In this
work, we show how knowledge in pretrained language models can be adapted and
distilled into vision-based action anticipation models. We show that a simple
distillation technique can achieve effective knowledge transfer and provide
consistent gains on a strong vision model (Anticipative Vision Transformer) for
two action anticipation datasets (3.5% relative gain on EGTEA-GAZE+ and 7.2%
relative gain on EPIC-KITCHEN 55), giving a new state-of-the-art result.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Information Filter upon Diversity-Improved Decoding for Diversity-Faithfulness Tradeoff in NLG. (arXiv:2210.13829v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.13829">
<div class="article-summary-box-inner">
<span><p>Some Natural Language Generation (NLG) tasks require both faithfulness and
diversity. The decoding strategy is intensively related to the quality of the
generated text. Strategies such as beam search, greedy search, etc., perform
with low diversity and high repetition. On the other hand, guided decoding, the
solution towards diversity, may generate unfaithful expressions. To this end,
this paper presents Information Filter upon Diversity-Improved Decoding (IFDID)
to obtain the tradeoff between diversity and faithfulness. IFDID is a two-stage
decoding strategy leveraging the proposed Enhance-Filter framework, which
achieves the tradeoff by increasing the probabilities of some typical tokens
being selected and subsequently filtering them by their information amount. To
verify the effectiveness, we compare our method with other baselines on related
CommonGEN, RocStories and AdGen benchmarks, which cover Chinese and English
datasets. Our numerical experimental results and human evaluation outcomes
verify the effectiveness of the proposed approach, as our approach achieves a
1.24 higher ROUGE score describing faithfulness as well as higher diversity
represented by 62.5% higher upon Dist-2 than traditional approaches,
demonstrating that IFDID is a novel SOTA decoding strategy for the tradeoff
between diversity and faithfulness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MT4SSL: Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets. (arXiv:2211.07321v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2211.07321">
<div class="article-summary-box-inner">
<span><p>In this paper, we provide a new perspective on self-supervised speech models
from how the self-training targets are obtained. We generalize the targets
extractor into Offline Targets Extractor (Off-TE) and Online Targets Extractor
(On-TE). Based on this, we propose a new multi-tasking learning framework for
self-supervised learning, MT4SSL, which stands for Boosting Self-Supervised
Speech Representation Learning by Integrating Multiple Targets. MT4SSL refers
to two typical models, HuBERT and data2vec, which use the K-means algorithm as
an Off-TE and a teacher network without gradients as an On-TE, respectively.
Our model outperforms previous SSL methods by nontrivial margins on the
LibriSpeech benchmark, and is comparable to or even better than the
best-performing models with no need for that much data. Furthermore, we find
that using both Off-TE and On-TE results in better convergence in the
pre-training phase. With both effectiveness and efficiency, we think that doing
multi-task learning on self-supervised speech models from our perspective is a
promising trend.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Lexical Borrowings from Dominant Languages in Multilingual Wordlists. (arXiv:2302.00189v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00189">
<div class="article-summary-box-inner">
<span><p>Language contact is a pervasive phenomenon reflected in the borrowing of
words from donor to recipient languages. Most computational approaches to
borrowing detection treat all languages under study as equally important, even
though dominant languages have a stronger impact on heritage languages than
vice versa. We test new methods for lexical borrowing detection in contact
situations where dominant languages play an important role, applying two
classical sequence comparison methods and one machine learning method to a
sample of seven Latin American languages which have all borrowed extensively
from Spanish. All methods perform well, with the supervised machine learning
system outperforming the classical systems. A review of detection errors shows
that borrowing detection could be substantially improved by taking into account
donor words with divergent meanings from recipient words.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Categorical Archive of ChatGPT Failures. (arXiv:2302.03494v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03494">
<div class="article-summary-box-inner">
<span><p>Large language models have been demonstrated to be valuable in different
fields. ChatGPT, developed by OpenAI, has been trained using massive amounts of
data and simulates human conversation by comprehending context and generating
appropriate responses. It has garnered significant attention due to its ability
to effectively answer a broad range of human inquiries, with fluent and
comprehensive answers surpassing prior public chatbots in both security and
usefulness. However, a comprehensive analysis of ChatGPT's failures is lacking,
which is the focus of this study. Eleven categories of failures, including
reasoning, factual errors, math, coding, and bias, are presented and discussed.
The risks, limitations, and societal implications of ChatGPT are also
highlighted. The goal of this study is to assist researchers and developers in
enhancing future language models and chatbots.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Song of Ice and Fire: Analyzing Textual Autotelic Agents in ScienceWorld. (arXiv:2302.05244v4 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05244">
<div class="article-summary-box-inner">
<span><p>Building open-ended agents that can autonomously discover a diversity of
behaviours is one of the long-standing goals of artificial intelligence. This
challenge can be studied in the framework of autotelic RL agents, i.e. agents
that learn by selecting and pursuing their own goals, self-organizing a
learning curriculum. Recent work identified language has a key dimension of
autotelic learning, in particular because it enables abstract goal sampling and
guidance from social peers for hindsight relabelling. Within this perspective,
we study the following open scientific questions: What is the impact of
hindsight feedback from a social peer (e.g. selective vs. exhaustive)? How can
the agent learn from very rare language goal examples in its experience replay?
How can multiple forms of exploration be combined, and take advantage of easier
goals as stepping stones to reach harder ones? To address these questions, we
use ScienceWorld, a textual environment with rich abstract and combinatorial
physics. We show the importance of selectivity from the social peer's feedback;
that experience replay needs to over-sample examples of rare goals; and that
following self-generated goal sequences where the agent's competence is
intermediate leads to significant improvements in final performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI Chat Assistants can Improve Conversations about Divisive Topics. (arXiv:2302.07268v3 [cs.HC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.07268">
<div class="article-summary-box-inner">
<span><p>A rapidly increasing amount of human conversation occurs online. But
divisiveness and conflict can fester in text-based interactions on social media
platforms, in messaging apps, and on other digital forums. Such toxicity
increases polarization and, importantly, corrodes the capacity of diverse
societies to develop efficient solutions to complex social problems that impact
everyone. Scholars and civil society groups promote interventions that can make
interpersonal conversations less divisive or more productive in offline
settings, but scaling these efforts to the amount of discourse that occurs
online is extremely challenging. We present results of a large-scale experiment
that demonstrates how online conversations about divisive topics can be
improved with artificial intelligence tools. Specifically, we employ a large
language model to make real-time, evidence-based recommendations intended to
improve participants' perception of feeling understood in conversations. We
find that these interventions improve the reported quality of the conversation,
reduce political divisiveness, and improve the tone, without systematically
changing the content of the conversation or moving people's policy attitudes.
These findings have important implications for future research on social media,
political deliberation, and the growing community of scholars interested in the
place of artificial intelligence within computational social science.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks. (arXiv:2302.08043v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08043">
<div class="article-summary-box-inner">
<span><p>Graphs can model complex relationships between objects, enabling a myriad of
Web applications such as online page/article classification and social
recommendation. While graph neural networks(GNNs) have emerged as a powerful
tool for graph representation learning, in an end-to-end supervised setting,
their performance heavily rely on a large amount of task-specific supervision.
To reduce labeling requirement, the "pre-train, fine-tune" and "pre-train,
prompt" paradigms have become increasingly common. In particular, prompting is
a popular alternative to fine-tuning in natural language processing, which is
designed to narrow the gap between pre-training and downstream objectives in a
task-specific manner. However, existing study of prompting on graphs is still
limited, lacking a universal treatment to appeal to different downstream tasks.
In this paper, we propose GraphPrompt, a novel pre-training and prompting
framework on graphs. GraphPrompt not only unifies pre-training and downstream
tasks into a common task template, but also employs a learnable prompt to
assist a downstream task in locating the most relevant knowledge from the
pre-train model in a task-specific manner. Finally, we conduct extensive
experiments on five public datasets to evaluate and analyze GraphPrompt.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InstructABSA: Instruction Learning for Aspect Based Sentiment Analysis. (arXiv:2302.08624v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08624">
<div class="article-summary-box-inner">
<span><p>In this paper, we present InstructABSA, Aspect-Based Sentiment Analysis
(ABSA) using instruction learning paradigm for all ABSA subtasks: Aspect Term
Extraction (ATE), Aspect Term Sentiment Classification (ATSC), and Joint Task
modeling. Our method introduces positive, negative, and neutral examples to
each training sample, and instruction tunes the model (Tk-Instruct Base) for
each ABSA subtask, yielding significant performance improvements. Experimental
results on the Sem Eval 2014 dataset demonstrate that InstructABSA outperforms
the previous state-of-the-art (SOTA) approaches on all three ABSA subtasks
(ATE, ATSC, and Joint Task) by a significant margin, outperforming 7x larger
models. In particular, InstructABSA surpasses the SOTA on the restaurant ATE
subtask by 7.31% points and on the Laptop Joint Task by 8.63% points. Our
results also suggest a strong generalization ability to unseen tasks across all
three subtasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human Emotion Knowledge Representation Emerges in Large Language Model and Supports Discrete Emotion Inference. (arXiv:2302.09582v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.09582">
<div class="article-summary-box-inner">
<span><p>How humans infer discrete emotions is a fundamental research question in the
field of psychology. While conceptual knowledge about emotions (emotion
knowledge) has been suggested to be essential for emotion inference, evidence
to date is mostly indirect and inconclusive. As the large language models
(LLMs) have been shown to support effective representations of various human
conceptual knowledge, the present study further employed artificial neurons in
LLMs to investigate the mechanism of human emotion inference. With artificial
neurons activated by prompts, the LLM (RoBERTa) demonstrated a similar
conceptual structure of 27 discrete emotions as that of human behaviors.
Furthermore, the LLM-based conceptual structure revealed a human-like reliance
on 14 underlying conceptual attributes of emotions for emotion inference. Most
importantly, by manipulating attribute-specific neurons, we found that the
corresponding LLM's emotion inference performance deteriorated, and the
performance deterioration was correlated to the effectiveness of
representations of the conceptual attributes on the human side. Our findings
provide direct evidence for the emergence of emotion knowledge representation
in large language models and suggest its casual support for discrete emotion
inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation. (arXiv:2302.09664v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.09664">
<div class="article-summary-box-inner">
<span><p>We introduce a method to measure uncertainty in large language models. For
tasks like question answering, it is essential to know when we can trust the
natural language outputs of foundation models. We show that measuring
uncertainty in natural language is challenging because of "semantic
equivalence" -- different sentences can mean the same thing. To overcome these
challenges we introduce semantic entropy -- an entropy which incorporates
linguistic invariances created by shared meanings. Our method is unsupervised,
uses only a single model, and requires no modifications to off-the-shelf
language models. In comprehensive ablation studies we show that the semantic
entropy is more predictive of model accuracy on question answering data sets
than comparable baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emphasizing Unseen Words: New Vocabulary Acquisition for End-to-End Speech Recognition. (arXiv:2302.09723v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.09723">
<div class="article-summary-box-inner">
<span><p>Due to the dynamic nature of human language, automatic speech recognition
(ASR) systems need to continuously acquire new vocabulary. Out-Of-Vocabulary
(OOV) words, such as trending words and new named entities, pose problems to
modern ASR systems that require long training times to adapt their large
numbers of parameters. Different from most previous research focusing on
language model post-processing, we tackle this problem on an earlier processing
level and eliminate the bias in acoustic modeling to recognize OOV words
acoustically. We propose to generate OOV words using text-to-speech systems and
to rescale losses to encourage neural networks to pay more attention to OOV
words. Specifically, we enlarge the classification loss used for training
neural networks' parameters of utterances containing OOV words
(sentence-level), or rescale the gradient used for back-propagation for OOV
words (word-level), when fine-tuning a previously trained model on synthetic
audio. To overcome catastrophic forgetting, we also explore the combination of
loss rescaling and model regularization, i.e. L2 regularization and elastic
weight consolidation (EWC). Compared with previous methods that just fine-tune
synthetic audio with EWC, the experimental results on the LibriSpeech benchmark
reveal that our proposed loss rescaling approach can achieve significant
improvement on the recall rate with only a slight decrease on word error rate.
Moreover, word-level rescaling is more stable than utterance-level rescaling
and leads to higher recall rates and precision on OOV word recognition.
Furthermore, our proposed combined loss rescaling and weight consolidation
methods can support continual learning of an ASR system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-aware Bayesian Co-attention for Multimodal Emotion Recognition. (arXiv:2302.09856v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.09856">
<div class="article-summary-box-inner">
<span><p>Multimodal emotion recognition is a challenging research area that aims to
fuse different modalities to predict human emotion. However, most existing
models that are based on attention mechanisms have difficulty in learning
emotionally relevant parts on their own. To solve this problem, we propose to
incorporate external emotion-related knowledge in the co-attention based fusion
of pre-trained models. To effectively incorporate this knowledge, we enhance
the co-attention model with a Bayesian attention module (BAM) where a prior
distribution is estimated using the emotion-related knowledge. Experimental
results on the IEMOCAP dataset show that the proposed approach can outperform
several state-of-the-art approaches by at least 0.7% unweighted accuracy (UA).
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-02-22 23:11:52.185077548 UTC">2023-02-22 23:11:52 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>