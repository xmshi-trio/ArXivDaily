<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-10-21T01:30:00Z">10-21</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">A Continuum of Generation Tasks for Investigating Length Bias and Degenerate Repetition. (arXiv:2210.10817v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10817">
<div class="article-summary-box-inner">
<span><p>Language models suffer from various degenerate behaviors. These differ
between tasks: machine translation (MT) exhibits length bias, while tasks like
story generation exhibit excessive repetition. Recent work has attributed the
difference to task constrainedness, but evidence for this claim has always
involved many confounding variables. To study this question directly, we
introduce a new experimental framework that allows us to smoothly vary task
constrainedness, from MT at one end to fully open-ended generation at the
other, while keeping all other aspects fixed. We find that: (1) repetition
decreases smoothly with constrainedness, explaining the difference in
repetition across tasks; (2) length bias surprisingly also decreases with
constrainedness, suggesting some other cause for the difference in length bias;
(3) across the board, these problems affect the mode, not the whole
distribution; (4) the differences cannot be attributed to a change in the
entropy of the distribution, since another method of changing the entropy,
label smoothing, does not produce the same effect.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VTC: Improving Video-Text Retrieval with User Comments. (arXiv:2210.10820v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10820">
<div class="article-summary-box-inner">
<span><p>Multi-modal retrieval is an important problem for many applications, such as
recommendation and search. Current benchmarks and even datasets are often
manually constructed and consist of mostly clean samples where all modalities
are well-correlated with the content. Thus, current video-text retrieval
literature largely focuses on video titles or audio transcripts, while ignoring
user comments, since users often tend to discuss topics only vaguely related to
the video. Despite the ubiquity of user comments online, there is currently no
multi-modal representation learning datasets that includes comments. In this
paper, we a) introduce a new dataset of videos, titles and comments; b) present
an attention-based mechanism that allows the model to learn from sometimes
irrelevant data such as comments; c) show that by using comments, our method is
able to learn better, more contextualised, representations for image, video and
audio representations. Project page: https://unitaryai.github.io/vtc-paper.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Hate Speech Varies by Target Identity: A Computational Analysis. (arXiv:2210.10839v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10839">
<div class="article-summary-box-inner">
<span><p>This paper investigates how hate speech varies in systematic ways according
to the identities it targets. Across multiple hate speech datasets annotated
for targeted identities, we find that classifiers trained on hate speech
targeting specific identity groups struggle to generalize to other targeted
identities. This provides empirical evidence for differences in hate speech by
target identity; we then investigate which patterns structure this variation.
We find that the targeted demographic category (e.g. gender/sexuality or
race/ethnicity) appears to have a greater effect on the language of hate speech
than does the relative social power of the targeted identity group. We also
find that words associated with hate speech targeting specific identities often
relate to stereotypes, histories of oppression, current social movements, and
other social contexts specific to identities. These experiments suggest the
importance of considering targeted identity, as well as the social contexts
associated with these identities, in automated hate speech classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompting through Prototype: A Prototype-based Prompt Learning on Pretrained Vision-Language Models. (arXiv:2210.10841v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10841">
<div class="article-summary-box-inner">
<span><p>Prompt learning is a new learning paradigm which reformulates downstream
tasks as similar pretraining tasks on pretrained models by leveraging textual
prompts. Recent works have demonstrated that prompt learning is particularly
useful for few-shot learning, where there is limited training data. Depending
on the granularity of prompts, those methods can be roughly divided into
task-level prompting and instance-level prompting. Task-level prompting methods
learn one universal prompt for all input samples, which is efficient but
ineffective to capture subtle differences among different classes.
Instance-level prompting methods learn a specific prompt for each input, though
effective but inefficient. In this work, we develop a novel prototype-based
prompt learning method to overcome the above limitations. In particular, we
focus on few-shot image recognition tasks on pretrained vision-language models
(PVLMs) and develop a method of prompting through prototype (PTP), where we
define $K$ image prototypes and $K$ prompt prototypes. In PTP, the image
prototype represents a centroid of a certain image cluster in the latent space
and a prompt prototype is defined as a soft prompt in the continuous space. The
similarity between a query image and an image prototype determines how much
this prediction relies on the corresponding prompt prototype. Hence, in PTP,
similar images will utilize similar prompting ways. Through extensive
experiments on seven real-world benchmarks, we show that PTP is an effective
method to leverage the latent knowledge and adaptive to various PVLMs.
Moreover, through detailed analysis, we discuss pros and cons for prompt
learning and parameter-efficient fine-tuning under the context of few-shot
learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Two-Turn Debate Doesn't Help Humans Answer Hard Reading Comprehension Questions. (arXiv:2210.10860v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10860">
<div class="article-summary-box-inner">
<span><p>The use of language-model-based question-answering systems to aid humans in
completing difficult tasks is limited, in part, by the unreliability of the
text these systems generate. Using hard multiple-choice reading comprehension
questions as a testbed, we assess whether presenting humans with arguments for
two competing answer options, where one is correct and the other is incorrect,
allows human judges to perform more accurately, even when one of the arguments
is unreliable and deceptive. If this is helpful, we may be able to increase our
justified trust in language-model-based systems by asking them to produce these
arguments where needed. Previous research has shown that just a single turn of
arguments in this format is not helpful to humans. However, as debate settings
are characterized by a back-and-forth dialogue, we follow up on previous
results to test whether adding a second round of counter-arguments is helpful
to humans. We find that, regardless of whether they have access to arguments or
not, humans perform similarly on our task. These findings suggest that, in the
case of answering reading comprehension questions, debate is not a helpful
format.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QA Domain Adaptation using Hidden Space Augmentation and Self-Supervised Contrastive Adaptation. (arXiv:2210.10861v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10861">
<div class="article-summary-box-inner">
<span><p>Question answering (QA) has recently shown impressive results for answering
questions from customized domains. Yet, a common challenge is to adapt QA
models to an unseen target domain. In this paper, we propose a novel
self-supervised framework called QADA for QA domain adaptation. QADA introduces
a novel data augmentation pipeline used to augment training QA samples.
Different from existing methods, we enrich the samples via hidden space
augmentation. For questions, we introduce multi-hop synonyms and sample
augmented token embeddings with Dirichlet distributions. For contexts, we
develop an augmentation method which learns to drop context spans via a custom
attentive sampling strategy. Additionally, contrastive learning is integrated
in the proposed self-supervised adaptation framework QADA. Unlike existing
approaches, we generate pseudo labels and propose to train the model via a
novel attention-based contrastive adaptation method. The attention weights are
used to build informative features for discrepancy estimation that helps the QA
model separate answers and generalize across source and target domains. To the
best of our knowledge, our work is the first to leverage hidden space
augmentation and attention-based contrastive adaptation for self-supervised
domain adaptation in QA. Our evaluation shows that QADA achieves considerable
improvements on multiple target datasets over state-of-the-art baselines in QA
domain adaptation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">G-Augment: Searching For The Meta-Structure Of Data Augmentation Policies For ASR. (arXiv:2210.10879v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10879">
<div class="article-summary-box-inner">
<span><p>Data augmentation is a ubiquitous technique used to provide robustness to
automatic speech recognition (ASR) training. However, even as so much of the
ASR training process has become automated and more "end-to-end", the data
augmentation policy (what augmentation functions to use, and how to apply them)
remains hand-crafted. We present Graph-Augment, a technique to define the
augmentation space as directed acyclic graphs (DAGs) and search over this space
to optimize the augmentation policy itself. We show that given the same
computational budget, policies produced by G-Augment are able to perform better
than SpecAugment policies obtained by random search on fine-tuning tasks on
CHiME-6 and AMI. G-Augment is also able to establish a new state-of-the-art ASR
performance on the CHiME-6 evaluation set (30.7% WER). We further demonstrate
that G-Augment policies show better transfer properties across warm-start to
cold-start training and model size compared to random-searched SpecAugment
policies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A baseline revisited: Pushing the limits of multi-segment models for context-aware translation. (arXiv:2210.10906v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10906">
<div class="article-summary-box-inner">
<span><p>This paper addresses the task of contextual translation using multi-segment
models. Specifically we show that increasing model capacity further pushes the
limits of this approach and that deeper models are more suited to capture
context dependencies. Furthermore, improvements observed with larger models can
be transferred to smaller models using knowledge distillation. Our experiments
show that this approach achieves competitive performance across several
languages and benchmarks, without additional language-specific tuning and task
specific architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prophet Attention: Predicting Attention with Future Attention for Improved Image Captioning. (arXiv:2210.10914v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10914">
<div class="article-summary-box-inner">
<span><p>Recently, attention based models have been used extensively in many
sequence-to-sequence learning systems. Especially for image captioning, the
attention based models are expected to ground correct image regions with proper
generated words. However, for each time step in the decoding process, the
attention based models usually use the hidden state of the current input to
attend to the image regions. Under this setting, these attention models have a
"deviated focus" problem that they calculate the attention weights based on
previous words instead of the one to be generated, impairing the performance of
both grounding and captioning. In this paper, we propose the Prophet Attention,
similar to the form of self-supervision. In the training stage, this module
utilizes the future information to calculate the "ideal" attention weights
towards image regions. These calculated "ideal" weights are further used to
regularize the "deviated" attention. In this manner, image regions are grounded
with the correct words. The proposed Prophet Attention can be easily
incorporated into existing image captioning models to improve their performance
of both grounding and captioning. The experiments on the Flickr30k Entities and
the MSCOCO datasets show that the proposed Prophet Attention consistently
outperforms baselines in both automatic metrics and human evaluations. It is
worth noticing that we set new state-of-the-arts on the two benchmark datasets
and achieve the 1st place on the leaderboard of the online MSCOCO benchmark in
terms of the default ranking score, i.e., CIDEr-c40.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Document Selection for Efficient Encoder Pretraining. (arXiv:2210.10951v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10951">
<div class="article-summary-box-inner">
<span><p>Building pretrained language models is considered expensive and
data-intensive, but must we increase dataset size to achieve better
performance? We propose an alternative to larger training sets by automatically
identifying smaller yet domain-representative subsets. We extend Cynical Data
Selection, a statistical sentence scoring method that conditions on a
representative target domain corpus. As an example, we treat the OntoNotes
corpus as a target domain and pretrain a RoBERTa-like encoder from a cynically
selected subset of the Pile. On both perplexity and across several downstream
tasks in the target domain, it consistently outperforms random selection with
20x less data, 3x fewer training iterations, and 2x less estimated cloud
compute cost, validating the recipe of automatic document selection for LM
pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MBTI Personality Prediction for Fictional Characters Using Movie Scripts. (arXiv:2210.10994v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10994">
<div class="article-summary-box-inner">
<span><p>An NLP model that understands stories should be able to understand the
characters in them. To support the development of neural models for this
purpose, we construct a benchmark, Story2Personality. The task is to predict a
movie character's MBTI or Big 5 personality types based on the narratives of
the character. Experiments show that our task is challenging for the existing
text classification models, as none is able to largely outperform random
guesses. We further proposed a multi-view model for personality prediction
using both verbal and non-verbal descriptions, which gives improvement compared
to using only verbal descriptions. The uniqueness and challenges in our dataset
call for the development of narrative comprehension techniques from the
perspective of understanding characters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Chinese Spelling Check by Character Pronunciation Prediction: The Effects of Adaptivity and Granularity. (arXiv:2210.10996v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10996">
<div class="article-summary-box-inner">
<span><p>Chinese spelling check (CSC) is a fundamental NLP task that detects and
corrects spelling errors in Chinese texts. As most of these spelling errors are
caused by phonetic similarity, effectively modeling the pronunciation of
Chinese characters is a key factor for CSC. In this paper, we consider
introducing an auxiliary task of Chinese pronunciation prediction (CPP) to
improve CSC, and, for the first time, systematically discuss the adaptivity and
granularity of this auxiliary task. We propose SCOPE which builds on top of a
shared encoder two parallel decoders, one for the primary CSC task and the
other for a fine-grained auxiliary CPP task, with a novel adaptive weighting
scheme to balance the two tasks. In addition, we design a delicate iterative
correction strategy for further improvements during inference. Empirical
evaluation shows that SCOPE achieves new state-of-the-art on three CSC
benchmarks, demonstrating the effectiveness and superiority of the auxiliary
CPP task. Comprehensive ablation studies further verify the positive effects of
adaptivity and granularity of the task. Code and data used in this paper are
publicly available at https://github.com/jiahaozhenbang/SCOPE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-trained Sentence Embeddings for Implicit Discourse Relation Classification. (arXiv:2210.11005v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11005">
<div class="article-summary-box-inner">
<span><p>Implicit discourse relations bind smaller linguistic units into coherent
texts. Automatic sense prediction for implicit relations is hard, because it
requires understanding the semantics of the linked arguments. Furthermore,
annotated datasets contain relatively few labeled examples, due to the scale of
the phenomenon: on average each discourse relation encompasses several dozen
words. In this paper, we explore the utility of pre-trained sentence embeddings
as base representations in a neural network for implicit discourse relation
sense classification. We present a series of experiments using both supervised
end-to-end trained models and pre-trained sentence encoding techniques -
SkipThought, Sent2vec and Infersent. The pre-trained embeddings are competitive
with the end-to-end model, and the approaches are complementary, with combined
models yielding significant performance improvements on two of the three
evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Granularity Optimization for Non-Autoregressive Translation. (arXiv:2210.11017v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11017">
<div class="article-summary-box-inner">
<span><p>Despite low latency, non-autoregressive machine translation (NAT) suffers
severe performance deterioration due to the naive independence assumption. This
assumption is further strengthened by cross-entropy loss, which encourages a
strict match between the hypothesis and the reference token by token. To
alleviate this issue, we propose multi-granularity optimization for NAT, which
collects model behaviors on translation segments of various granularities and
integrates feedback for backpropagation. Experiments on four WMT benchmarks
show that the proposed method significantly outperforms the baseline models
trained with cross-entropy loss, and achieves the best performance on WMT'16
En-Ro and highly competitive results on WMT'14 En-De for fully
non-autoregressive translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Out-of-Distribution Detection in Natural Language Understanding via Implicit Layer Ensemble. (arXiv:2210.11034v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11034">
<div class="article-summary-box-inner">
<span><p>Out-of-distribution (OOD) detection aims to discern outliers from the
intended data distribution, which is crucial to maintaining high reliability
and a good user experience. Most recent studies in OOD detection utilize the
information from a single representation that resides in the penultimate layer
to determine whether the input is anomalous or not. Although such a method is
straightforward, the potential of diverse information in the intermediate
layers is overlooked. In this paper, we propose a novel framework based on
contrastive learning that encourages intermediate features to learn
layer-specialized representations and assembles them implicitly into a single
representation to absorb rich information in the pre-trained language model.
Extensive experiments in various intent classification and OOD datasets
demonstrate that our approach is significantly more effective than other works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Doc2Bot: Accessing Heterogeneous Documents via Conversational Bots. (arXiv:2210.11060v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11060">
<div class="article-summary-box-inner">
<span><p>This paper introduces Doc2Bot, a novel dataset for building machines that
help users seek information via conversations. This is of particular interest
for companies and organizations that own a large number of manuals or
instruction books. Despite its potential, the nature of our task poses several
challenges: (1) documents contain various structures that hinder the ability of
machines to comprehend, and (2) user information needs are often
underspecified. Compared to prior datasets that either focus on a single
structural type or overlook the role of questioning to uncover user needs, the
Doc2Bot dataset is developed to target such challenges systematically. Our
dataset contains over 100,000 turns based on Chinese documents from five
domains, larger than any prior document-grounded dialog dataset for information
seeking. We propose three tasks in Doc2Bot: (1) dialog state tracking to track
user intentions, (2) dialog policy learning to plan system actions and
contents, and (3) response generation which generates responses based on the
outputs of the dialog policy. Baseline methods based on the latest deep
learning models are presented, indicating that our proposed tasks are
challenging and worthy of further research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MovieCLIP: Visual Scene Recognition in Movies. (arXiv:2210.11065v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11065">
<div class="article-summary-box-inner">
<span><p>Longform media such as movies have complex narrative structures, with events
spanning a rich variety of ambient visual scenes. Domain specific challenges
associated with visual scenes in movies include transitions, person coverage,
and a wide array of real-life and fictional scenarios. Existing visual scene
datasets in movies have limited taxonomies and don't consider the visual scene
transition within movie clips. In this work, we address the problem of visual
scene recognition in movies by first automatically curating a new and extensive
movie-centric taxonomy of 179 scene labels derived from movie scripts and
auxiliary web-based video datasets. Instead of manual annotations which can be
expensive, we use CLIP to weakly label 1.12 million shots from 32K movie clips
based on our proposed taxonomy. We provide baseline visual models trained on
the weakly labeled dataset called MovieCLIP and evaluate them on an independent
dataset verified by human raters. We show that leveraging features from models
pretrained on MovieCLIP benefits downstream tasks such as multi-label scene and
genre classification of web videos and movie trailers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Apple of Sodom: Hidden Backdoors in Superior Sentence Embeddings via Contrastive Learning. (arXiv:2210.11082v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11082">
<div class="article-summary-box-inner">
<span><p>This paper finds that contrastive learning can produce superior sentence
embeddings for pre-trained models but is also vulnerable to backdoor attacks.
We present the first backdoor attack framework, BadCSE, for state-of-the-art
sentence embeddings under supervised and unsupervised learning settings. The
attack manipulates the construction of positive and negative pairs so that the
backdoored samples have a similar embedding with the target sample (targeted
attack) or the negative embedding of its clean version (non-targeted attack).
By injecting the backdoor in sentence embeddings, BadCSE is resistant against
downstream fine-tuning. We evaluate BadCSE on both STS tasks and other
downstream tasks. The supervised non-targeted attack obtains a performance
degradation of 194.86%, and the targeted attack maps the backdoored samples to
the target embedding with a 97.70% success rate while maintaining the model
utility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Execution Time Program Verification With Tight Bounds. (arXiv:2210.11105v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11105">
<div class="article-summary-box-inner">
<span><p>This paper presents a proof system for reasoning about execution time bounds
for a core imperative programming language. Proof systems are defined for three
different scenarios: approximations of the worst-case execution time, exact
time reasoning, and less pessimistic execution time estimation using amortized
analysis. We define a Hoare logic for the three cases and prove its soundness
with respect to an annotated cost-aware operational semantics. Finally, we
define a verification conditions (VC) generator that generates the goals needed
to prove program correctness, cost, and termination. Those goals are then sent
to the Easycrypt toolset for validation. The practicality of the proof system
is demonstrated with an implementation in OCaml of the different modules needed
to apply it to example programs. Our case studies are motivated by real-time
and cryptographic software.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Spatial Description: Controlled Spatial-Oriented Image-to-Text Generation. (arXiv:2210.11109v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11109">
<div class="article-summary-box-inner">
<span><p>Image-to-text tasks, such as open-ended image captioning and controllable
image description, have received extensive attention for decades. Here, we
further advance this line of work by presenting Visual Spatial Description
(VSD), a new perspective for image-to-text toward spatial semantics. Given an
image and two objects inside it, VSD aims to produce one description focusing
on the spatial perspective between the two objects. Accordingly, we manually
annotate a dataset to facilitate the investigation of the newly-introduced task
and build several benchmark encoder-decoder models by using VL-BART and VL-T5
as backbones. In addition, we investigate pipeline and joint end-to-end
architectures for incorporating visual spatial relationship classification
(VSRC) information into our model. Finally, we conduct experiments on our
benchmark dataset to evaluate all our models. Results show that our models are
impressive, providing accurate and human-like spatial-oriented text
descriptions. Meanwhile, VSRC has great potential for VSD, and the joint
end-to-end architecture is the better choice for their integration. We make the
dataset and codes public for research purposes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-training Language Models with Deterministic Factual Knowledge. (arXiv:2210.11165v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11165">
<div class="article-summary-box-inner">
<span><p>Previous works show that Pre-trained Language Models (PLMs) can capture
factual knowledge. However, some analyses reveal that PLMs fail to perform it
robustly, e.g., being sensitive to the changes of prompts when extracting
factual knowledge. To mitigate this issue, we propose to let PLMs learn the
deterministic relationship between the remaining context and the masked
content. The deterministic relationship ensures that the masked factual content
can be deterministically inferable based on the existing clues in the context.
That would provide more stable patterns for PLMs to capture factual knowledge
than randomly masking. Two pre-training tasks are further introduced to
motivate PLMs to rely on the deterministic relationship when filling masks.
Specifically, we use an external Knowledge Base (KB) to identify deterministic
relationships and continuously pre-train PLMs with the proposed methods. The
factual knowledge probing experiments indicate that the continuously
pre-trained PLMs achieve better robustness in factual knowledge capturing.
Further experiments on question-answering datasets show that trying to learn a
deterministic relationship with the proposed methods can also help other
knowledge-intensive tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Wait-info Policy: Balancing Source and Target at Information Level for Simultaneous Machine Translation. (arXiv:2210.11220v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11220">
<div class="article-summary-box-inner">
<span><p>Simultaneous machine translation (SiMT) outputs the translation while
receiving the source inputs, and hence needs to balance the received source
information and translated target information to make a reasonable decision
between waiting for inputs or outputting translation. Previous methods always
balance source and target information at the token level, either directly
waiting for a fixed number of tokens or adjusting the waiting based on the
current token. In this paper, we propose a Wait-info Policy to balance source
and target at the information level. We first quantify the amount of
information contained in each token, named info. Then during simultaneous
translation, the decision of waiting or outputting is made based on the
comparison results between the total info of previous target outputs and
received source inputs. Experiments show that our method outperforms strong
baselines under and achieves better balance via the proposed info.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Context-driven Visual Object Recognition based on Knowledge Graphs. (arXiv:2210.11233v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11233">
<div class="article-summary-box-inner">
<span><p>Current deep learning methods for object recognition are purely data-driven
and require a large number of training samples to achieve good results. Due to
their sole dependence on image data, these methods tend to fail when confronted
with new environments where even small deviations occur. Human perception,
however, has proven to be significantly more robust to such distribution
shifts. It is assumed that their ability to deal with unknown scenarios is
based on extensive incorporation of contextual knowledge. Context can be based
either on object co-occurrences in a scene or on memory of experience. In
accordance with the human visual cortex which uses context to form different
object representations for a seen image, we propose an approach that enhances
deep learning methods by using external contextual knowledge encoded in a
knowledge graph. Therefore, we extract different contextual views from a
generic knowledge graph, transform the views into vector space and infuse it
into a DNN. We conduct a series of experiments to investigate the impact of
different contextual views on the learned object representations for the same
image dataset. The experimental results provide evidence that the contextual
views influence the image representations in the DNN differently and therefore
lead to different predictions for the same images. We also show that context
helps to strengthen the robustness of object recognition models for
out-of-distribution images, usually occurring in transfer learning tasks or
real-world scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Semantic Relation Generation. (arXiv:2210.11253v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11253">
<div class="article-summary-box-inner">
<span><p>Scene graphs provide structured semantic understanding beyond images. For
downstream tasks, such as image retrieval, visual question answering, visual
relationship detection, and even autonomous vehicle technology, scene graphs
can not only distil complex image information but also correct the bias of
visual models using semantic-level relations, which has broad application
prospects. However, the heavy labour cost of constructing graph annotations may
hinder the application of PSG in practical scenarios. Inspired by the
observation that people usually identify the subject and object first and then
determine the relationship between them, we proposed to decouple the scene
graphs generation task into two sub-tasks: 1) an image segmentation task to
pick up the qualified objects. 2) a restricted auto-regressive text generation
task to generate the relation between given objects. Therefore, in this work,
we introduce image semantic relation generation (ISRG), a simple but effective
image-to-text model, which achieved 31 points on the OpenPSG dataset and
outperforms strong baselines respectively by 16 points (ResNet-50) and 5 points
(CLIP).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evidence > Intuition: Transferability Estimation for Encoder Selection. (arXiv:2210.11255v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11255">
<div class="article-summary-box-inner">
<span><p>With the increase in availability of large pre-trained language models (LMs)
in Natural Language Processing (NLP), it becomes critical to assess their fit
for a specific target task a priori - as fine-tuning the entire space of
available LMs is computationally prohibitive and unsustainable. However,
encoder transferability estimation has received little to no attention in NLP.
In this paper, we propose to generate quantitative evidence to predict which
LM, out of a pool of models, will perform best on a target task without having
to fine-tune all candidates. We provide a comprehensive study on LM ranking for
10 NLP tasks spanning the two fundamental problem types of classification and
structured prediction. We adopt the state-of-the-art Logarithm of Maximum
Evidence (LogME) measure from Computer Vision (CV) and find that it positively
correlates with final LM performance in 94% of the setups. In the first study
of its kind, we further compare transferability measures with the de facto
standard of human practitioner ranking, finding that evidence from quantitative
metrics is more robust than pure intuition and can help identify unexpected LM
candidates.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers. (arXiv:2210.11265v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11265">
<div class="article-summary-box-inner">
<span><p>This paper presents ReasonFormer, a unified reasoning framework for mirroring
the modular and compositional reasoning process of humans in complex decision
making. Inspired by dual-process theory in cognitive science, the
representation module (automatic thinking) and reasoning modules (controlled
thinking) are disentangled to capture different levels of cognition. Upon the
top of the representation module, the pre-trained reasoning modules are modular
and expertise in specific and fundamental reasoning skills (e.g., logic, simple
QA, etc). To mimic the controlled compositional thinking process, different
reasoning modules are dynamically activated and composed in both parallel and
cascaded manners to control what reasoning skills are activated and how deep
the reasoning process will be reached to solve the current problems. The
unified reasoning framework solves multiple tasks with a single model,and is
trained and inferred in an end-to-end manner. Evaluated on 11 datasets
requiring different reasoning skills and complexity, ReasonFormer demonstrates
substantial performance boosts, revealing the compositional reasoning ability.
Few-shot experiments exhibit better generalization ability by learning to
compose pre-trained skills for new tasks with limited data,and decoupling the
representation module and the reasoning modules. Further analysis shows the
modularity of reasoning modules as different tasks activate distinct reasoning
skills at different reasoning depths.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DialogUSR: Complex Dialogue Utterance Splitting and Reformulation for Multiple Intent Detection. (arXiv:2210.11279v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11279">
<div class="article-summary-box-inner">
<span><p>While interacting with chatbots, users may elicit multiple intents in a
single dialogue utterance. Instead of training a dedicated multi-intent
detection model, we propose DialogUSR, a dialogue utterance splitting and
reformulation task that first splits multi-intent user query into several
single-intent sub-queries and then recovers all the coreferred and omitted
information in the sub-queries. DialogUSR can serve as a plug-in and
domain-agnostic module that empowers the multi-intent detection for the
deployed chatbots with minimal efforts. We collect a high-quality naturally
occurring dataset that covers 23 domains with a multi-step crowd-souring
procedure. To benchmark the proposed dataset, we propose multiple action-based
generative models that involve end-to-end and two-stage training, and conduct
in-depth analyses on the pros and cons of the proposed baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Late Prompt Tuning: A Late Prompt Could Be Better Than Many Prompts. (arXiv:2210.11292v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11292">
<div class="article-summary-box-inner">
<span><p>Prompt tuning is a parameter-efficient tuning (PETuning) method for utilizing
pre-trained models (PTMs) that simply prepends a soft prompt to the input and
only optimizes the prompt to adapt PTMs to downstream tasks. Although it is
parameter- and deployment-efficient, its performance still lags behind other
state-of-the-art PETuning methods. Besides, the training cost of prompt tuning
is not significantly reduced due to the back-propagation through the entire
model. Through empirical analyses, we shed some light on the lagging
performance of prompt tuning and recognize a trade-off between the propagation
distance from label signals to the inserted prompt and the influence of the
prompt on model outputs. Further, we present Late Prompt Tuning (LPT) that
inserts a late prompt into an intermediate layer of the PTM instead of the
input layer or all layers. The late prompt is obtained by a neural prompt
generator conditioned on the hidden states before the prompt insertion layer
and therefore is instance-dependent. Through extensive experimental results
across various tasks and PTMs, we show that LPT can achieve competitive
performance to full model tuning and other PETuning methods under both
full-data and few-shot scenarios while possessing faster training speed and
lower memory cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The University of Edinburgh's Submission to the WMT22 Code-Mixing Shared Task (MixMT). (arXiv:2210.11309v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11309">
<div class="article-summary-box-inner">
<span><p>The University of Edinburgh participated in the WMT22 shared task on
code-mixed translation. This consists of two subtasks: i) generating code-mixed
Hindi/English (Hinglish) text generation from parallel Hindi and English
sentences and ii) machine translation from Hinglish to English. As both
subtasks are considered low-resource, we focused our efforts on careful data
generation and curation, especially the use of backtranslation from monolingual
resources. For subtask 1 we explored the effects of constrained decoding on
English and transliterated subwords in order to produce Hinglish. For subtask
2, we investigated different pretraining techniques, namely comparing simple
initialisation from existing machine translation models and aligned
augmentation. For both subtasks, we found that our baseline systems worked
best. Our systems for both subtasks were one of the overall top-performing
submissions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-Efficient Strategies for Expanding Hate Speech Detection into Under-Resourced Languages. (arXiv:2210.11359v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11359">
<div class="article-summary-box-inner">
<span><p>Hate speech is a global phenomenon, but most hate speech datasets so far
focus on English-language content. This hinders the development of more
effective hate speech detection models in hundreds of languages spoken by
billions across the world. More data is needed, but annotating hateful content
is expensive, time-consuming and potentially harmful to annotators. To mitigate
these issues, we explore data-efficient strategies for expanding hate speech
detection into under-resourced languages. In a series of experiments with mono-
and multilingual models across five non-English languages, we find that 1) a
small amount of target-language fine-tuning data is needed to achieve strong
performance, 2) the benefits of using more such data decrease exponentially,
and 3) initial fine-tuning on readily-available English data can partially
substitute target-language data and improve model generalisability. Based on
these findings, we formulate actionable recommendations for hate speech
detection in low-resource language settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meeting Decision Tracker: Making Meeting Minutes with De-Contextualized Utterances. (arXiv:2210.11374v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11374">
<div class="article-summary-box-inner">
<span><p>Meetings are a universal process to make decisions in business and project
collaboration. The capability to automatically itemize the decisions in daily
meetings allows for extensive tracking of past discussions. To that end, we
developed Meeting Decision Tracker, a prototype system to construct decision
items comprising decision utterance detector (DUD) and decision utterance
rewriter (DUR). We show that DUR makes a sizable contribution to improving the
user experience by dealing with utterance collapse in natural conversation. An
introduction video of our system is also available at
https://youtu.be/TG1pJJo0Iqo.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transcending Scaling Laws with 0.1% Extra Compute. (arXiv:2210.11399v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11399">
<div class="article-summary-box-inner">
<span><p>Scaling language models improves performance but comes with significant
computational costs. This paper proposes UL2R, a method that substantially
improves existing language models and their scaling curves with a relatively
tiny amount of extra compute. The key idea is to continue training a
state-of-the-art large language model (e.g., PaLM) on a few more steps with
UL2's mixture-of-denoiser objective. We show that, with almost negligible extra
computational costs and no new sources of data, we are able to substantially
improve the scaling properties of large language models on downstream metrics.
In this paper, we continue training PaLM with UL2R, introducing a new set of
models at 8B, 62B, and 540B scale which we call U-PaLM. Impressively, at 540B
scale, we show an approximately 2x computational savings rate where U-PaLM
achieves the same performance as the final PaLM 540B model at around half its
computational budget (i.e., saving $\sim$4.4 million TPUv4 hours). We further
show that this improved scaling curve leads to 'emergent abilities' on
challenging BIG-Bench tasks -- for instance, U-PaLM does much better than PaLM
on some tasks or demonstrates better quality at much smaller scale (62B as
opposed to 540B). Overall, we show that U-PaLM outperforms PaLM on many
few-shot setups, i.e., English NLP tasks (e.g., commonsense reasoning, question
answering), reasoning tasks with chain-of-thought (e.g., GSM8K), multilingual
tasks (MGSM, TydiQA), MMLU and challenging BIG-Bench tasks. Finally, we provide
qualitative examples showing the new capabilities of U-PaLM for single and
multi-span infilling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scaling Instruction-Finetuned Language Models. (arXiv:2210.11416v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11416">
<div class="article-summary-box-inner">
<span><p>Finetuning language models on a collection of datasets phrased as
instructions has been shown to improve model performance and generalization to
unseen tasks. In this paper we explore instruction finetuning with a particular
focus on (1) scaling the number of tasks, (2) scaling the model size, and (3)
finetuning on chain-of-thought data. We find that instruction finetuning with
the above aspects dramatically improves performance on a variety of model
classes (PaLM, T5, U-PaLM), prompting setups (zero-shot, few-shot, CoT), and
evaluation benchmarks (MMLU, BBH, TyDiQA, MGSM, open-ended generation). For
instance, Flan-PaLM 540B instruction-finetuned on 1.8K tasks outperforms PALM
540B by a large margin (+9.4% on average). Flan-PaLM 540B achieves
state-of-the-art performance on several benchmarks, such as 75.2% on five-shot
MMLU. We also publicly release Flan-T5 checkpoints, which achieve strong
few-shot performance even compared to much larger models, such as PaLM 62B.
Overall, instruction finetuning is a general method for improving the
performance and usability of pretrained language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counterfactual Recipe Generation: Exploring Compositional Generalization in a Realistic Scenario. (arXiv:2210.11431v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11431">
<div class="article-summary-box-inner">
<span><p>People can acquire knowledge in an unsupervised manner by reading, and
compose the knowledge to make novel combinations. In this paper, we investigate
whether pretrained language models can perform compositional generalization in
a realistic setting: recipe generation. We design the counterfactual recipe
generation task, which asks models to modify a base recipe according to the
change of an ingredient. This task requires compositional generalization at two
levels: the surface level of incorporating the new ingredient into the base
recipe, and the deeper level of adjusting actions related to the changing
ingredient. We collect a large-scale recipe dataset in Chinese for models to
learn culinary knowledge, and a subset of action-level fine-grained annotations
for evaluation. We finetune pretrained language models on the recipe corpus,
and use unsupervised counterfactual generation methods to generate modified
recipes. Results show that existing models have difficulties in modifying the
ingredients while preserving the original text style, and often miss actions
that need to be adjusted. Although pretrained language models can generate
fluent recipe texts, they fail to truly learn and use the culinary knowledge in
a compositional way. Code and data are available at
https://github.com/xxxiaol/counterfactual-recipe-generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Choose Your Lenses: Flaws in Gender Bias Evaluation. (arXiv:2210.11471v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.11471">
<div class="article-summary-box-inner">
<span><p>Considerable efforts to measure and mitigate gender bias in recent years have
led to the introduction of an abundance of tasks, datasets, and metrics used in
this vein. In this position paper, we assess the current paradigm of gender
bias evaluation and identify several flaws in it. First, we highlight the
importance of extrinsic bias metrics that measure how a model's performance on
some task is affected by gender, as opposed to intrinsic evaluations of model
representations, which are less strongly connected to specific harms to people
interacting with systems. We find that only a few extrinsic metrics are
measured in most studies, although more can be measured. Second, we find that
datasets and metrics are often coupled, and discuss how their coupling hinders
the ability to obtain reliable conclusions, and how one may decouple them. We
then investigate how the choice of the dataset and its composition, as well as
the choice of the metric, affect bias measurement, finding significant
variations across each of them. Finally, we propose several guidelines for more
reliable gender bias evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dialogue-adaptive Language Model Pre-training From Quality Estimation. (arXiv:2009.04984v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.04984">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PrLMs) have achieved great success on a wide
range of natural language processing tasks by virtue of the universal language
representation ability obtained by self-supervised learning on a large corpus.
These models are pre-trained on standard plain texts with general language
model (LM) training objectives, which would be insufficient to model
dialogue-exclusive attributes like specificity and informativeness reflected in
these tasks that are not explicitly captured by the pre-trained universal
language representations. In this work, we propose dialogue-adaptive
pre-training objectives (DAPO) derived from quality estimation to simulate
dialogue-specific features, namely coherence, specificity, and informativeness.
As the foundation for model pre-training, we synthesize a new dialogue corpus
and build our training set with two unsupervised methods: 1) coherence-oriented
context corruption, including utterance ordering, insertion, and replacement,
to help the model capture the coherence inside the dialogue contexts; and 2)
specificity-oriented automatic rescoring, which encourages the model to measure
the quality of the synthesized data for dialogue-adaptive pre-training by
considering specificity and informativeness. Experimental results on widely
used open-domain response selection and quality estimation benchmarks show that
DAPO significantly improves the baseline models and achieves state-of-the-art
performance on the MuTual leaderboard, verifying the effectiveness of
estimating quality evaluation factors into pre-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rewriting Meaningful Sentences via Conditional BERT Sampling and an application on fooling text classifiers. (arXiv:2010.11869v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11869">
<div class="article-summary-box-inner">
<span><p>Most adversarial attack methods that are designed to deceive a text
classifier change the text classifier's prediction by modifying a few words or
characters. Few try to attack classifiers by rewriting a whole sentence, due to
the difficulties inherent in sentence-level rephrasing as well as the problem
of setting the criteria for legitimate rewriting.
</p>
<p>In this paper, we explore the problem of creating adversarial examples with
sentence-level rewriting. We design a new sampling method, named
ParaphraseSampler, to efficiently rewrite the original sentence in multiple
ways. Then we propose a new criteria for modification, called a sentence-level
threaten model. This criteria allows for both word- and sentence-level changes,
and can be adjusted independently in two dimensions: semantic similarity and
grammatical quality. Experimental results show that many of these rewritten
sentences are misclassified by the classifier. On all 6 datasets, our
ParaphraseSampler achieves a better attack success rate than our baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">R&R: Metric-guided Adversarial Sentence Generation. (arXiv:2104.08453v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08453">
<div class="article-summary-box-inner">
<span><p>Adversarial examples are helpful for analyzing and improving the robustness
of text classifiers. Generating high-quality adversarial examples is a
challenging task as it requires generating fluent adversarial sentences that
are semantically similar to the original sentences and preserve the original
labels, while causing the classifier to misclassify them. Existing methods
prioritize misclassification by maximizing each perturbation's effectiveness at
misleading a text classifier; thus, the generated adversarial examples fall
short in terms of fluency and similarity. In this paper, we propose a rewrite
and rollback (R&amp;R) framework for adversarial attack. It improves the quality of
adversarial examples by optimizing a critique score which combines the fluency,
similarity, and misclassification metrics. R&amp;R generates high-quality
adversarial examples by allowing exploration of perturbations that do not have
immediate impact on the misclassification metric but can improve fluency and
similarity metrics. We evaluate our method on 5 representative datasets and 3
classifier architectures. Our method outperforms current state-of-the-art in
attack success rate by +16.2%, +12.8%, and +14.0% on the classifiers
respectively. Code is available at https://github.com/DAI-Lab/fibber
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph Neural Networks for Natural Language Processing: A Survey. (arXiv:2106.06090v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06090">
<div class="article-summary-box-inner">
<span><p>Deep learning has become the dominant approach in coping with various tasks
in Natural LanguageProcessing (NLP). Although text inputs are typically
represented as a sequence of tokens, there isa rich variety of NLP problems
that can be best expressed with a graph structure. As a result, thereis a surge
of interests in developing new deep learning techniques on graphs for a large
numberof NLP tasks. In this survey, we present a comprehensive overview onGraph
Neural Networks(GNNs) for Natural Language Processing. We propose a new
taxonomy of GNNs for NLP, whichsystematically organizes existing research of
GNNs for NLP along three axes: graph construction,graph representation
learning, and graph based encoder-decoder models. We further introducea large
number of NLP applications that are exploiting the power of GNNs and summarize
thecorresponding benchmark datasets, evaluation metrics, and open-source codes.
Finally, we discussvarious outstanding challenges for making the full use of
GNNs for NLP as well as future researchdirections. To the best of our
knowledge, this is the first comprehensive overview of Graph NeuralNetworks for
Natural Language Processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Attention for Automatic Chest X-ray Report Generation. (arXiv:2106.06965v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06965">
<div class="article-summary-box-inner">
<span><p>Recently, chest X-ray report generation, which aims to automatically generate
descriptions of given chest X-ray images, has received growing research
interests. The key challenge of chest X-ray report generation is to accurately
capture and describe the abnormal regions. In most cases, the normal regions
dominate the entire chest X-ray image, and the corresponding descriptions of
these normal regions dominate the final report. Due to such data bias,
learning-based models may fail to attend to abnormal regions. In this work, to
effectively capture and describe abnormal regions, we propose the Contrastive
Attention (CA) model. Instead of solely focusing on the current input image,
the CA model compares the current input image with normal images to distill the
contrastive information. The acquired contrastive information can better
represent the visual features of abnormal regions. According to the experiments
on the public IU-X-ray and MIMIC-CXR datasets, incorporating our CA into
several existing models can boost their performance across most metrics. In
addition, according to the analysis, the CA model can help existing models
better attend to the abnormal regions and provide more accurate descriptions
which are crucial for an interpretable diagnosis. Specifically, we achieve the
state-of-the-art results on the two public datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comprehensive Exploration of Pre-training Language Models. (arXiv:2106.11483v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11483">
<div class="article-summary-box-inner">
<span><p>Recently, the development of pre-trained language models has brought natural
language processing (NLP) tasks to the new state-of-the-art. In this paper we
explore the efficiency of various pre-trained language models. We pre-train a
list of transformer-based models with the same amount of text and the same
training steps. The experimental results shows that the most improvement upon
the origin BERT is adding the RNN-layer to capture more contextual information
for short text understanding. But there are no remarkable improvement for short
text understanding for similar BERT structures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Jargon: Combining Extraction and Generation for Definition Modeling. (arXiv:2111.07267v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.07267">
<div class="article-summary-box-inner">
<span><p>Can machines know what twin prime is? From the composition of this phrase,
machines may guess twin prime is a certain kind of prime, but it is still
difficult to deduce exactly what twin stands for without additional knowledge.
Here, twin prime is a jargon - a specialized term used by experts in a
particular field. Explaining jargon is challenging since it usually requires
domain knowledge to understand. Recently, there is an increasing interest in
extracting and generating definitions of words automatically. However, existing
approaches, either extraction or generation, perform poorly on jargon. In this
paper, we propose to combine extraction and generation for jargon definition
modeling: first extract self- and correlative definitional information of
target jargon from the Web and then generate the final definitions by
incorporating the extracted definitional information. Our framework is
remarkably simple but effective: experiments demonstrate our method can
generate high-quality definitions for jargon and outperform state-of-the-art
models significantly, e.g., BLEU score from 8.76 to 22.66 and human-annotated
score from 2.34 to 4.04.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Embedding Arithmetic of Multimodal Queries for Image Retrieval. (arXiv:2112.03162v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.03162">
<div class="article-summary-box-inner">
<span><p>Latent text representations exhibit geometric regularities, such as the
famous analogy: queen is to king what woman is to man. Such structured semantic
relations were not demonstrated on image representations. Recent works aiming
at bridging this semantic gap embed images and text into a multimodal space,
enabling the transfer of text-defined transformations to the image modality. We
introduce the SIMAT dataset to evaluate the task of Image Retrieval with
Multimodal queries. SIMAT contains 6k images and 18k textual transformation
queries that aim at either replacing scene elements or changing pairwise
relationships between scene elements. The goal is to retrieve an image
consistent with the (source image, text transformation) query. We use an
image/text matching oracle (OSCAR) to assess whether the image transformation
is successful. The SIMAT dataset will be publicly available. We use SIMAT to
evaluate the geometric properties of multimodal embedding spaces trained with
an image/text matching objective, like CLIP. We show that vanilla CLIP
embeddings are not very well suited to transform images with delta vectors, but
that a simple finetuning on the COCO dataset can bring dramatic improvements.
We also study whether it is beneficial to leverage pretrained universal
sentence encoders (FastText, LASER and LaBSE).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Roof-Transformer: Divided and Joined Understanding with Knowledge Enhancement. (arXiv:2112.06736v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06736">
<div class="article-summary-box-inner">
<span><p>Recent work on enhancing BERT-based language representation models with
knowledge graphs (KGs) and knowledge bases (KBs) has yielded promising results
on multiple NLP tasks. State-of-the-art approaches typically integrate the
original input sentences with KG triples and feed the combined representation
into a BERT model. However, as the sequence length of a BERT model is limited,
such a framework supports little knowledge other than the original input
sentences and is thus forced to discard some knowledge. This problem is
especially severe for downstream tasks for which the input is a long paragraph
or even a document, such as QA or reading comprehension tasks. We address this
problem with Roof-Transformer, a model with two underlying BERTs and a fusion
layer on top. One underlying BERT encodes the knowledge resources and the other
one encodes the original input sentences, and the fusion layer integrates the
two resultant encodings. Experimental results on a QA task and the GLUE
benchmark attest the effectiveness of the proposed model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Yes-Yes-Yes: Proactive Data Collection for ACL Rolling Review and Beyond. (arXiv:2201.11443v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.11443">
<div class="article-summary-box-inner">
<span><p>The shift towards publicly available text sources has enabled language
processing at unprecedented scale, yet leaves under-serviced the domains where
public and openly licensed data is scarce. Proactively collecting text data for
research is a viable strategy to address this scarcity, but lacks systematic
methodology taking into account the many ethical, legal and
confidentiality-related aspects of data collection. Our work presents a case
study on proactive data collection in peer review -- a challenging and
under-resourced NLP domain. We outline ethical and legal desiderata for
proactive data collection and introduce "Yes-Yes-Yes", the first donation-based
peer reviewing data collection workflow that meets these requirements. We
report on the implementation of Yes-Yes-Yes at ACL Rolling Review and
empirically study the implications of proactive data collection for the dataset
size and the biases induced by the donation behavior on the peer reviewing
platform.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BiFSMN: Binary Neural Network for Keyword Spotting. (arXiv:2202.06483v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.06483">
<div class="article-summary-box-inner">
<span><p>The deep neural networks, such as the Deep-FSMN, have been widely studied for
keyword spotting (KWS) applications. However, computational resources for these
networks are significantly constrained since they usually run on-call on edge
devices. In this paper, we present BiFSMN, an accurate and extreme-efficient
binary neural network for KWS. We first construct a High-frequency Enhancement
Distillation scheme for the binarization-aware training, which emphasizes the
high-frequency information from the full-precision network's representation
that is more crucial for the optimization of the binarized network. Then, to
allow the instant and adaptive accuracy-efficiency trade-offs at runtime, we
also propose a Thinnable Binarization Architecture to further liberate the
acceleration potential of the binarized network from the topology perspective.
Moreover, we implement a Fast Bitwise Computation Kernel for BiFSMN on ARMv8
devices which fully utilizes registers and increases instruction throughput to
push the limit of deployment efficiency. Extensive experiments show that BiFSMN
outperforms existing binarization methods by convincing margins on various
datasets and is even comparable with the full-precision counterpart (e.g., less
than 3% drop on Speech Commands V1-12). We highlight that benefiting from the
thinnable architecture and the optimized 1-bit implementation, BiFSMN can
achieve an impressive 22.3x speedup and 15.5x storage-saving on real-world edge
hardware. Our code is released at https://github.com/htqin/BiFSMN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">$\rm{C {\small IS}}^2$: A Simplified Commonsense Inference Evaluation for Story Prose. (arXiv:2202.07880v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.07880">
<div class="article-summary-box-inner">
<span><p>Transformers have been showing near-human performance on a variety of tasks,
but they are not without their limitations. We discuss the issue of conflating
results of transformers that are instructed to do multiple tasks
simultaneously. In particular, we focus on the domain of commonsense reasoning
within story prose, which we call contextual commonsense inference (CCI). We
look at the GLUCOSE (Mostafazadeh et al. 2020) dataset and task for predicting
implicit commonsense inferences between story sentences. Since the GLUCOSE task
simultaneously generates sentences and predicts the CCI relation, there is a
conflation in the results. Is the model really measuring CCI or is its ability
to generate grammatical text carrying the results? In this paper, we introduce
the task contextual commonsense inference in sentence selection ($\rm{C {\small
IS}}^2$), a simplified task that avoids conflation by eliminating language
generation altogether. Our findings emphasize the necessity of future work to
disentangle language generation from the desired NLP tasks at hand.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?. (arXiv:2202.12837v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.12837">
<div class="article-summary-box-inner">
<span><p>Large language models (LMs) are able to in-context learn -- perform a new
task via inference alone by conditioning on a few input-label pairs
(demonstrations) and making predictions for new inputs. However, there has been
little understanding of how the model learns and which aspects of the
demonstrations contribute to end task performance. In this paper, we show that
ground truth demonstrations are in fact not required -- randomly replacing
labels in the demonstrations barely hurts performance on a range of
classification and multi-choce tasks, consistently over 12 different models
including GPT-3. Instead, we find that other aspects of the demonstrations are
the key drivers of end task performance, including the fact that they provide a
few examples of (1) the label space, (2) the distribution of the input text,
and (3) the overall format of the sequence. Together, our analysis provides a
new way of understanding how and why in-context learning works, while opening
up new questions about how much can be learned from large language models
through inference alone.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Conformer Based Acoustic Model for Robust Automatic Speech Recognition. (arXiv:2203.00725v3 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.00725">
<div class="article-summary-box-inner">
<span><p>This study addresses robust automatic speech recognition (ASR) by introducing
a Conformer-based acoustic model. The proposed model builds on the wide
residual bi-directional long short-term memory network (WRBN) with
utterance-wise dropout and iterative speaker adaptation, but employs a
Conformer encoder instead of the recurrent network. The Conformer encoder uses
a convolution-augmented attention mechanism for acoustic modeling. The proposed
system is evaluated on the monaural ASR task of the CHiME-4 corpus. Coupled
with utterance-wise normalization and speaker adaptation, our model achieves
$6.25\%$ word error rate, which outperforms WRBN by $8.4\%$ relatively. In
addition, the proposed Conformer-based model is $18.3\%$ smaller in model size
and reduces total training time by $79.6\%$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning. (arXiv:2203.02053v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.02053">
<div class="article-summary-box-inner">
<span><p>We present modality gap, an intriguing geometric phenomenon of the
representation space of multi-modal models. Specifically, we show that
different data modalities (e.g. images and text) are embedded at arm's length
in their shared representation in multi-modal models such as CLIP. Our
systematic analysis demonstrates that this gap is caused by a combination of
model initialization and contrastive learning optimization. In model
initialization, we show empirically and theoretically that the representation
of a common deep neural network is restricted to a narrow cone. As a
consequence, in a multi-modal model with two encoders, the representations of
the two modalities are clearly apart when the model is initialized. During
optimization, contrastive learning keeps the different modalities separate by a
certain distance, which is influenced by the temperature parameter in the loss
function. Our experiments further demonstrate that varying the modality gap
distance has a significant impact in improving the model's downstream zero-shot
classification performance and fairness. Our code and data are available at
https://modalitygap.readthedocs.io/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Back to the Future: Bidirectional Information Decoupling Network for Multi-turn Dialogue Modeling. (arXiv:2204.08152v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.08152">
<div class="article-summary-box-inner">
<span><p>Multi-turn dialogue modeling as a challenging branch of natural language
understanding (NLU), aims to build representations for machines to understand
human dialogues, which provides a solid foundation for multiple downstream
tasks. Recent studies of dialogue modeling commonly employ pre-trained language
models (PrLMs) to encode the dialogue history as successive tokens, which is
insufficient in capturing the temporal characteristics of dialogues. Therefore,
we propose Bidirectional Information Decoupling Network (BiDeN) as a universal
dialogue encoder, which explicitly incorporates both the past and future
contexts and can be generalized to a wide range of dialogue-related tasks.
Experimental results on datasets of different downstream tasks demonstrate the
universality and effectiveness of our BiDeN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inferring Implicit Relations in Complex Questions with Language Models. (arXiv:2204.13778v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.13778">
<div class="article-summary-box-inner">
<span><p>A prominent challenge for modern language understanding systems is the
ability to answer implicit reasoning questions, where the required reasoning
steps for answering the question are not mentioned in the text explicitly. In
this work, we investigate why current models struggle with implicit reasoning
question answering (QA) tasks, by decoupling inference of reasoning steps from
their execution. We define a new task of implicit relation inference and
construct a benchmark, IMPLICITRELATIONS, where given a question, a model
should output a list of concept-relation pairs, where the relations describe
the implicit reasoning steps required for answering the question. Using
IMPLICITRELATIONS, we evaluate models from the GPT-3 family and find that,
while these models struggle on the implicit reasoning QA task, they often
succeed at inferring implicit relations. This suggests that the challenge in
implicit reasoning questions does not stem from the need to plan a reasoning
strategy alone, but to do it while also retrieving and reasoning over relevant
information.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CiteSum: Citation Text-guided Scientific Extreme Summarization and Domain Adaptation with Limited Supervision. (arXiv:2205.06207v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06207">
<div class="article-summary-box-inner">
<span><p>Scientific extreme summarization (TLDR) aims to form ultra-short summaries of
scientific papers. Previous efforts on curating scientific TLDR datasets failed
to scale up due to the heavy human annotation and domain expertise required. In
this paper, we propose a simple yet effective approach to automatically
extracting TLDR summaries for scientific papers from their citation texts.
Based on the proposed approach, we create a new benchmark CiteSum without human
annotation, which is around 30 times larger than the previous human-curated
dataset SciTLDR. We conduct a comprehensive analysis of CiteSum, examining its
data characteristics and establishing strong baselines. We further demonstrate
the usefulness of CiteSum by adapting models pre-trained on CiteSum (named
CITES) to new tasks and domains with limited supervision. For scientific
extreme summarization, CITES outperforms most fully-supervised methods on
SciTLDR without any fine-tuning and obtains state-of-the-art results with only
128 examples. For news extreme summarization, CITES achieves significant gains
on XSum over its base model (not pre-trained on CiteSum), e.g., +7.2 ROUGE-1
zero-shot performance and state-of-the-art few-shot performance. For news
headline generation, CITES performs the best among unsupervised and zero-shot
methods on Gigaword. Our dataset and code can be found at
https://github.com/morningmoni/CiteSum.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-training Transformer Models with Sentence-Level Objectives for Answer Sentence Selection. (arXiv:2205.10455v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10455">
<div class="article-summary-box-inner">
<span><p>An important task for designing QA systems is answer sentence selection
(AS2): selecting the sentence containing (or constituting) the answer to a
question from a set of retrieved relevant documents. In this paper, we propose
three novel sentence-level transformer pre-training objectives that incorporate
paragraph-level semantics within and across documents, to improve the
performance of transformers for AS2, and mitigate the requirement of large
labeled datasets. Specifically, the model is tasked to predict whether: (i) two
sentences are extracted from the same paragraph, (ii) a given sentence is
extracted from a given paragraph, and (iii) two paragraphs are extracted from
the same document. Our experiments on three public and one industrial AS2
datasets demonstrate the empirical superiority of our pre-trained transformers
over baseline models such as RoBERTa and ELECTRA for AS2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DEER: Descriptive Knowledge Graph for Explaining Entity Relationships. (arXiv:2205.10479v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10479">
<div class="article-summary-box-inner">
<span><p>We propose DEER (Descriptive Knowledge Graph for Explaining Entity
Relationships) - an open and informative form of modeling entity relationships.
In DEER, relationships between entities are represented by free-text relation
descriptions. For instance, the relationship between entities of machine
learning and algorithm can be represented as ``Machine learning explores the
study and construction of algorithms that can learn from and make predictions
on data.'' To construct DEER, we propose a self-supervised learning method to
extract relation descriptions with the analysis of dependency patterns and
generate relation descriptions with a transformer-based relation description
synthesizing model, where no human labeling is required. Experiments
demonstrate that our system can extract and generate high-quality relation
descriptions for explaining entity relationships. The results suggest that we
can build an open and informative knowledge graph without human annotation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relphormer: Relational Graph Transformer for Knowledge Graph Representations. (arXiv:2205.10852v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10852">
<div class="article-summary-box-inner">
<span><p>Transformers have achieved remarkable performance in widespread fields,
including natural language processing, computer vision and graph mining.
However, vanilla Transformer architectures have not yielded promising
improvements in the Knowledge Graph (KG) representations, where the
translational distance paradigm dominates this area. Note that vanilla
Transformer architectures struggle to capture the intrinsically heterogeneous
semantic and structural information of knowledge graphs. To this end, we
propose a new variant of Transformer for knowledge graph representations dubbed
Relphormer. Specifically, we introduce Triple2Seq which can dynamically sample
contextualized sub-graph sequences as the input to alleviate the heterogeneity
issue. We propose a novel structure-enhanced self-attention mechanism to encode
the relational information and keep the globally semantic information among
sub-graphs. Moreover, we propose masked knowledge modeling as a new paradigm
for knowledge graph representation learning. We apply Relphormer to three
tasks, namely, knowledge graph completion, KG-based question answering and
KG-based recommendation for evaluation. Experimental results show that
Relphormer can obtain better performance on benchmark datasets compared with
baselines. Code is available in https://github.com/zjunlp/Relphormer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Logical Reasoning with Span-Level Predictions for Interpretable and Robust NLI Models. (arXiv:2205.11432v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11432">
<div class="article-summary-box-inner">
<span><p>Current Natural Language Inference (NLI) models achieve impressive results,
sometimes outperforming humans when evaluating on in-distribution test sets.
However, as these models are known to learn from annotation artefacts and
dataset biases, it is unclear to what extent the models are learning the task
of NLI instead of learning from shallow heuristics in their training data. We
address this issue by introducing a logical reasoning framework for NLI,
creating highly transparent model decisions that are based on logical rules.
Unlike prior work, we show that improved interpretability can be achieved
without decreasing the predictive accuracy. We almost fully retain performance
on SNLI, while also identifying the exact hypothesis spans that are responsible
for each model prediction. Using the e-SNLI human explanations, we verify that
our model makes sensible decisions at a span level, despite not using any span
labels during training. We can further improve model performance and span-level
decisions by using the e-SNLI explanations during training. Finally, our model
is more robust in a reduced data setting. When training with only 1,000
examples, out-of-distribution performance improves on the MNLI matched and
mismatched validation sets by 13% and 16% relative to the baseline. Training
with fewer observations yields further improvements, both in-distribution and
out-of-distribution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Garden-Path Traversal in GPT-2. (arXiv:2205.12302v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12302">
<div class="article-summary-box-inner">
<span><p>In recent years, large-scale transformer decoders such as the GPT-x family of
models have become increasingly popular. Studies examining the behavior of
these models tend to focus only on the output of the language modeling head and
avoid analysis of the internal states of the transformer decoder. In this
study, we present a collection of methods to analyze the hidden states of GPT-2
and use the model's navigation of garden path sentences as a case study. To
enable this, we compile the largest currently available dataset of garden path
sentences. We show that Manhattan distances and cosine similarities provide
more reliable insights compared to established surprisal methods that analyze
next-token probabilities computed by a language modeling head. Using these
methods, we find that negating tokens have minimal impacts on the model's
representations for unambiguous forms of sentences with ambiguity solely over
what the object of a verb is, but have a more substantial impact of
representations for unambiguous sentences whose ambiguity would stem from the
voice of a verb. Further, we find that analyzing the decoder model's hidden
states reveals periods of ambiguity that might conclude in a garden path effect
but happen not to, whereas surprisal analyses routinely miss this detail.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are Large Pre-Trained Language Models Leaking Your Personal Information?. (arXiv:2205.12628v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12628">
<div class="article-summary-box-inner">
<span><p>Are Large Pre-Trained Language Models Leaking Your Personal Information? In
this paper, we analyze whether Pre-Trained Language Models (PLMs) are prone to
leaking personal information. Specifically, we query PLMs for email addresses
with contexts of the email address or prompts containing the owner's name. We
find that PLMs do leak personal information due to memorization. However, since
the models are weak at association, the risk of specific personal information
being extracted by attackers is low. We hope this work could help the community
to better understand the privacy risk of PLMs and bring new insights to make
PLMs safe.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Adversarial Attack on Vision-Language Pre-training Models. (arXiv:2206.09391v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09391">
<div class="article-summary-box-inner">
<span><p>While vision-language pre-training model (VLP) has shown revolutionary
improvements on various vision-language (V+L) tasks, the studies regarding its
adversarial robustness remain largely unexplored. This paper studied the
adversarial attack on popular VLP models and V+L tasks. First, we analyzed the
performance of adversarial attacks under different settings. By examining the
influence of different perturbed objects and attack targets, we concluded some
key observations as guidance on both designing strong multimodal adversarial
attack and constructing robust VLP models. Second, we proposed a novel
multimodal attack method on the VLP models called Collaborative Multimodal
Adversarial Attack (Co-Attack), which collectively carries out the attacks on
the image modality and the text modality. Experimental results demonstrated
that the proposed method achieves improved attack performances on different V+L
downstream tasks and VLP models. The analysis observations and novel attack
method hopefully provide new understanding into the adversarial robustness of
VLP models, so as to contribute their safe and reliable deployment in more
real-world scenarios. Code is available at
https://github.com/adversarial-for-goodness/Co-Attack.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Competence-based Multimodal Curriculum Learning for Medical Report Generation. (arXiv:2206.14579v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14579">
<div class="article-summary-box-inner">
<span><p>Medical report generation task, which targets to produce long and coherent
descriptions of medical images, has attracted growing research interests
recently. Different from the general image captioning tasks, medical report
generation is more challenging for data-driven neural models. This is mainly
due to 1) the serious data bias and 2) the limited medical data. To alleviate
the data bias and make best use of available data, we propose a
Competence-based Multimodal Curriculum Learning framework (CMCL). Specifically,
CMCL simulates the learning process of radiologists and optimizes the model in
a step by step manner. Firstly, CMCL estimates the difficulty of each training
instance and evaluates the competence of current model; Secondly, CMCL selects
the most suitable batch of training instances considering current model
competence. By iterating above two steps, CMCL can gradually improve the
model's performance. The experiments on the public IU-Xray and MIMIC-CXR
datasets show that CMCL can be incorporated into existing models to improve
their performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepGen: Diverse Search Ad Generation and Real-Time Customization. (arXiv:2208.03438v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.03438">
<div class="article-summary-box-inner">
<span><p>We present DeepGen, a system deployed at web scale for automatically creating
sponsored search advertisements (ads) for BingAds customers. We leverage
state-of-the-art natural language generation (NLG) models to generate fluent
ads from advertiser's web pages in an abstractive fashion and solve practical
issues such as factuality and inference speed. In addition, our system creates
a customized ad in real-time in response to the user's search query, therefore
highlighting different aspects of the same product based on what the user is
looking for. To achieve this, our system generates a diverse choice of smaller
pieces of the ad ahead of time and, at query time, selects the most relevant
ones to be stitched into a complete ad. We improve generation diversity by
training a controllable NLG model to generate multiple ads for the same web
page highlighting different selling points. Our system design further improves
diversity horizontally by first running an ensemble of generation models
trained with different objectives and then using a diversity sampling algorithm
to pick a diverse subset of generation results for online selection.
Experimental results show the effectiveness of our proposed system design. Our
system is currently deployed in production, serving ${\sim}4\%$ of global ads
served in Bing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TexPrax: A Messaging Application for Ethical, Real-time Data Collection and Annotation. (arXiv:2208.07846v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.07846">
<div class="article-summary-box-inner">
<span><p>Collecting and annotating task-oriented dialog data is difficult, especially
for highly specific domains that require expert knowledge. At the same time,
informal communication channels such as instant messengers are increasingly
being used at work. This has led to a lot of work-relevant information that is
disseminated through those channels and needs to be post-processed manually by
the employees. To alleviate this problem, we present TexPrax, a messaging
system to collect and annotate problems, causes, and solutions that occur in
work-related chats. TexPrax uses a chatbot to directly engage the employees to
provide lightweight annotations on their conversation and ease their
documentation work. To comply with data privacy and security regulations, we
use an end-to-end message encryption and give our users full control over their
data which has various advantages over conventional annotation tools. We
evaluate TexPrax in a user-study with German factory employees who ask their
colleagues for solutions on problems that arise during their daily work.
Overall, we collect 202 task-oriented German dialogues containing 1,027
sentences with sentence-level expert annotations. Our data analysis also
reveals that real-world conversations frequently contain instances with
code-switching, varying abbreviations for the same entity, and dialects which
NLP systems should be able to handle.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UKP-SQuARE v2: Explainability and Adversarial Attacks for Trustworthy QA. (arXiv:2208.09316v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2208.09316">
<div class="article-summary-box-inner">
<span><p>Question Answering (QA) systems are increasingly deployed in applications
where they support real-world decisions. However, state-of-the-art models rely
on deep neural networks, which are difficult to interpret by humans. Inherently
interpretable models or post hoc explainability methods can help users to
comprehend how a model arrives at its prediction and, if successful, increase
their trust in the system. Furthermore, researchers can leverage these insights
to develop new methods that are more accurate and less biased. In this paper,
we introduce SQuARE v2, the new version of SQuARE, to provide an explainability
infrastructure for comparing models based on methods such as saliency maps and
graph-based explanations. While saliency maps are useful to inspect the
importance of each input token for the model's prediction, graph-based
explanations from external Knowledge Graphs enable the users to verify the
reasoning behind the model prediction. In addition, we provide multiple
adversarial attacks to compare the robustness of QA models. With these
explainability methods and adversarial attacks, we aim to ease the research on
trustworthy QA models. SQuARE is available on https://square.ukp-lab.de.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IDIAPers @ Causal News Corpus 2022: Extracting Cause-Effect-Signal Triplets via Pre-trained Autoregressive Language Model. (arXiv:2209.03891v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.03891">
<div class="article-summary-box-inner">
<span><p>In this paper, we describe our shared task submissions for Subtask 2 in
CASE-2022, Event Causality Identification with Casual News Corpus. The
challenge focused on the automatic detection of all cause-effect-signal spans
present in the sentence from news-media. We detect cause-effect-signal spans in
a sentence using T5 -- a pre-trained autoregressive language model. We
iteratively identify all cause-effect-signal span triplets, always conditioning
the prediction of the next triplet on the previously predicted ones. To predict
the triplet itself, we consider different causal relationships such as
cause$\rightarrow$effect$\rightarrow$signal. Each triplet component is
generated via a language model conditioned on the sentence, the previous parts
of the current triplet, and previously predicted triplets. Despite training on
an extremely small dataset of 160 samples, our approach achieved competitive
performance, being placed second in the competition. Furthermore, we show that
assuming either cause$\rightarrow$effect or effect$\rightarrow$cause order
achieves similar results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Answering Numerical Reasoning Questions in Table-Text Hybrid Contents with Graph-based Encoder and Tree-based Decoder. (arXiv:2209.07692v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.07692">
<div class="article-summary-box-inner">
<span><p>In the real-world question answering scenarios, hybrid form combining both
tabular and textual contents has attracted more and more attention, among which
numerical reasoning problem is one of the most typical and challenging
problems. Existing methods usually adopt encoder-decoder framework to represent
hybrid contents and generate answers. However, it can not capture the rich
relationship among numerical value, table schema, and text information on the
encoder side. The decoder uses a simple predefined operator classifier which is
not flexible enough to handle numerical reasoning processes with diverse
expressions. To address these problems, this paper proposes a
\textbf{Re}lational \textbf{G}raph enhanced \textbf{H}ybrid table-text
\textbf{N}umerical reasoning model with \textbf{T}ree decoder
(\textbf{RegHNT}). It models the numerical question answering over table-text
hybrid contents as an expression tree generation task. Moreover, we propose a
novel relational graph modeling method, which models alignment between
questions, tables, and paragraphs. We validated our model on the publicly
available table-text hybrid QA benchmark (TAT-QA). The proposed RegHNT
significantly outperform the baseline model and achieve state-of-the-art
results. We openly released the source code and data at
https://github.com/lfy79001/RegHNT (2022-05-05).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Construction and Applications of Billion-Scale Pre-trained Multimodal Business Knowledge Graph. (arXiv:2209.15214v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.15214">
<div class="article-summary-box-inner">
<span><p>Business Knowledge Graphs (KGs) are important to many enterprises today,
providing factual knowledge and structured data that steer many products and
make them more intelligent. Despite their promising benefits, building business
KG necessitates solving prohibitive issues of deficient structure and multiple
modalities. In this paper, we advance the understanding of the practical
challenges related to building KG in non-trivial real-world systems. We
introduce the process of building an open business knowledge graph (OpenBG)
derived from a well-known enterprise, Alibaba Group. Specifically, we define a
core ontology to cover various abstract products and consumption demands, with
fine-grained taxonomy and multimodal facts in deployed applications. OpenBG is
an open business KG of unprecedented scale: 2.6 billion triples with more than
88 million entities covering over 1 million core classes/concepts and 2,681
types of relations. We release all the open resources (OpenBG benchmarks)
derived from it for the community and report experimental results of KG-centric
tasks. We also run up an online competition based on OpenBG benchmarks, and has
attracted thousands of teams. We further pre-train OpenBG and apply it to many
KG- enhanced downstream tasks in business scenarios, demonstrating the
effectiveness of billion-scale multimodal knowledge for e-commerce. All the
resources with codes have been released at
\url{https://github.com/OpenBGBenchmark/OpenBG}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploration of A Self-Supervised Speech Model: A Study on Emotional Corpora. (arXiv:2210.02595v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.02595">
<div class="article-summary-box-inner">
<span><p>Self-supervised speech models have grown fast during the past few years and
have proven feasible for use in various downstream tasks. Some recent work has
started to look at the characteristics of these models, yet many concerns have
not been fully addressed. In this work, we conduct a study on emotional corpora
to explore a popular self-supervised model -- wav2vec 2.0. Via a set of
quantitative analysis, we mainly demonstrate that: 1) wav2vec 2.0 appears to
discard paralinguistic information that is less useful for word recognition
purposes; 2) for emotion recognition, representations from the middle layer
alone perform as well as those derived from layer averaging, while the final
layer results in the worst performance in some cases; 3) current
self-supervised models may not be the optimal solution for downstream tasks
that make use of non-lexical features. Our work provides novel findings that
will aid future research in this area and theoretical basis for the use of
existing models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MuRAG: Multimodal Retrieval-Augmented Generator for Open Question Answering over Images and Text. (arXiv:2210.02928v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.02928">
<div class="article-summary-box-inner">
<span><p>While language Models store a massive amount of world knowledge implicitly in
their parameters, even very large models often fail to encode information about
rare entities and events, while incurring huge computational costs. Recently,
retrieval-augmented models, such as REALM, RAG, and RETRO, have incorporated
world knowledge into language generation by leveraging an external
non-parametric index and have demonstrated impressive performance with
constrained model sizes. However, these methods are restricted to retrieving
only textual knowledge, neglecting the ubiquitous amount of knowledge in other
modalities like images -- much of which contains information not covered by any
text. To address this limitation, we propose the first Multimodal
Retrieval-Augmented Transformer (MuRAG), which accesses an external
non-parametric multimodal memory to augment language generation. MuRAG is
pre-trained with a mixture of large-scale image-text and text-only corpora
using a joint contrastive and generative loss. We perform experiments on two
different datasets that require retrieving and reasoning over both images and
text to answer a given query: WebQA, and MultimodalQA. Our results show that
MuRAG achieves state-of-the-art accuracy, outperforming existing models by
10-20\% absolute on both datasets and under both distractor and full-wiki
settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Once is Enough: A Light-Weight Cross-Attention for Fast Sentence Pair Modeling. (arXiv:2210.05261v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.05261">
<div class="article-summary-box-inner">
<span><p>Transformer-based models have achieved great success on sentence pair
modeling tasks, such as answer selection and natural language inference (NLI).
These models generally perform cross-attention over input pairs, leading to
prohibitive computational costs. Recent studies propose dual-encoder and late
interaction architectures for faster computation. However, the balance between
the expressive of cross-attention and computation speedup still needs better
coordinated. To this end, this paper introduces a novel paradigm MixEncoder for
efficient sentence pair modeling. MixEncoder involves a light-weight
cross-attention mechanism. It conducts query encoding only once while modeling
the query-candidate interaction in parallel. Extensive experiments conducted on
four tasks demonstrate that our MixEncoder can speed up sentence pairing by
over 113x while achieving comparable performance as the more expensive
cross-attention models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anonymizing Speech with Generative Adversarial Networks to Preserve Speaker Privacy. (arXiv:2210.07002v3 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07002">
<div class="article-summary-box-inner">
<span><p>In order to protect the privacy of speech data, speaker anonymization aims
for hiding the identity of a speaker by changing the voice in speech
recordings. This typically comes with a privacy-utility trade-off between
protection of individuals and usability of the data for downstream
applications. One of the challenges in this context is to create non-existent
voices that sound as natural as possible.
</p>
<p>In this work, we propose to tackle this issue by generating speaker
embeddings using a generative adversarial network with Wasserstein distance as
cost function. By incorporating these artificial embeddings into a
speech-to-text-to-speech pipeline, we outperform previous approaches in terms
of privacy and utility. According to standard objective metrics and human
evaluation, our approach generates intelligible and content-preserving yet
privacy-protecting versions of the original recordings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving generalizability of distilled self-supervised speech processing models under distorted settings. (arXiv:2210.07978v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.07978">
<div class="article-summary-box-inner">
<span><p>Self-supervised learned (SSL) speech pre-trained models perform well across
various speech processing tasks. Distilled versions of SSL models have been
developed to match the needs of on-device speech applications. Though having
similar performance as original SSL models, distilled counterparts suffer from
performance degradation even more than their original versions in distorted
environments. This paper proposes to apply Cross-Distortion Mapping and Domain
Adversarial Training to SSL models during knowledge distillation to alleviate
the performance gap caused by the domain mismatch problem. Results show
consistent performance improvements under both in- and out-of-domain distorted
setups for different downstream tasks while keeping efficient model size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models for Multi-label Propaganda Detection. (arXiv:2210.08209v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08209">
<div class="article-summary-box-inner">
<span><p>The spread of propaganda through the internet has increased drastically over
the past years. Lately, propaganda detection has started gaining importance
because of the negative impact it has on society. In this work, we describe our
approach for the WANLP 2022 shared task which handles the task of propaganda
detection in a multi-label setting. The task demands the model to label the
given text as having one or more types of propaganda techniques. There are a
total of 21 propaganda techniques to be detected. We show that an ensemble of
five models performs the best on the task, scoring a micro-F1 score of 59.73%.
We also conduct comprehensive ablations and propose various future directions
for this work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Character-Centric Story Visualization via Visual Planning and Token Alignment. (arXiv:2210.08465v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08465">
<div class="article-summary-box-inner">
<span><p>Story visualization advances the traditional text-to-image generation by
enabling multiple image generation based on a complete story. This task
requires machines to 1) understand long text inputs and 2) produce a globally
consistent image sequence that illustrates the contents of the story. A key
challenge of consistent story visualization is to preserve characters that are
essential in stories. To tackle the challenge, we propose to adapt a recent
work that augments Vector-Quantized Variational Autoencoders (VQ-VAE) with a
text-tovisual-token (transformer) architecture. Specifically, we modify the
text-to-visual-token module with a two-stage framework: 1) character token
planning model that predicts the visual tokens for characters only; 2) visual
token completion model that generates the remaining visual token sequence,
which is sent to VQ-VAE for finalizing image generations. To encourage
characters to appear in the images, we further train the two-stage framework
with a character-token alignment objective. Extensive experiments and
evaluations demonstrate that the proposed method excels at preserving
characters and can produce higher quality image sequences compared with the
strong baselines. Codes can be found in https://github.com/sairin1202/VP-CSV
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Some Languages are More Equal than Others: Probing Deeper into the Linguistic Disparity in the NLP World. (arXiv:2210.08523v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.08523">
<div class="article-summary-box-inner">
<span><p>Linguistic disparity in the NLP world is a problem that has been widely
acknowledged recently. However, different facets of this problem, or the
reasons behind this disparity are seldom discussed within the NLP community.
This paper provides a comprehensive analysis of the disparity that exists
within the languages of the world. We show that simply categorising languages
considering data availability may not be always correct. Using an existing
language categorisation based on speaker population and vitality, we analyse
the distribution of language data resources, amount of NLP/CL research,
inclusion in multilingual web-based platforms and the inclusion in pre-trained
multilingual models. We show that many languages do not get covered in these
resources or platforms, and even within the languages belonging to the same
language group, there is wide disparity. We analyse the impact of family,
geographical location, GDP and the speaker population of languages and provide
possible reasons for this disparity, along with some suggestions to overcome
the same.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ELASTIC: Numerical Reasoning with Adaptive Symbolic Compiler. (arXiv:2210.10105v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10105">
<div class="article-summary-box-inner">
<span><p>Numerical reasoning over text is a challenging task of Artificial
Intelligence (AI), requiring reading comprehension and numerical reasoning
abilities. Previous approaches use numerical reasoning programs to represent
the reasoning process. However, most works do not separate the generation of
operators and operands, which are key components of a numerical reasoning
program, thus limiting their ability to generate such programs for complicated
tasks. In this paper, we introduce the numEricaL reASoning with adapTive
symbolIc Compiler (ELASTIC) model, which is constituted of the RoBERTa as the
Encoder and a Compiler with four modules: Reasoning Manager, Operator
Generator, Operands Generator, and Memory Register. ELASTIC is robust when
conducting complicated reasoning. Also, it is domain agnostic by supporting the
expansion of diverse operators without caring about the number of operands it
contains. Experiments show that ELASTIC achieves 68.96 and 65.21 of execution
accuracy and program accuracy on the FinQA dataset and 83.00 program accuracy
on the MathQA dataset, outperforming previous state-of-the-art models
significantly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LightEA: A Scalable, Robust, and Interpretable Entity Alignment Framework via Three-view Label Propagation. (arXiv:2210.10436v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10436">
<div class="article-summary-box-inner">
<span><p>Entity Alignment (EA) aims to find equivalent entity pairs between KGs, which
is the core step of bridging and integrating multi-source KGs. In this paper,
we argue that existing GNN-based EA methods inherit the inborn defects from
their neural network lineage: weak scalability and poor interpretability.
Inspired by recent studies, we reinvent the Label Propagation algorithm to
effectively run on KGs and propose a non-neural EA framework -- LightEA,
consisting of three efficient components: (i) Random Orthogonal Label
Generation, (ii) Three-view Label Propagation, and (iii) Sparse Sinkhorn
Iteration. According to the extensive experiments on public datasets, LightEA
has impressive scalability, robustness, and interpretability. With a mere tenth
of time consumption, LightEA achieves comparable results to state-of-the-art
methods across all datasets and even surpasses them on many.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attribution and Obfuscation of Neural Text Authorship: A Data Mining Perspective. (arXiv:2210.10488v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10488">
<div class="article-summary-box-inner">
<span><p>Two interlocking research questions of growing interest and importance in
privacy research are Authorship Attribution (AA) and Authorship Obfuscation
(AO). Given an artifact, especially a text t in question, an AA solution aims
to accurately attribute t to its true author out of many candidate authors
while an AO solution aims to modify t to hide its true authorship.
Traditionally, the notion of authorship and its accompanying privacy concern is
only toward human authors. However, in recent years, due to the explosive
advancements in Neural Text Generation (NTG) techniques in NLP, capable of
synthesizing human-quality open-ended texts (so-called "neural texts"), one has
to now consider authorships by humans, machines, or their combination. Due to
the implications and potential threats of neural texts when used maliciously,
it has become critical to understand the limitations of traditional AA/AO
solutions and develop novel AA/AO solutions in dealing with neural texts. In
this survey, therefore, we make a comprehensive review of recent literature on
the attribution and obfuscation of neural text authorship from a Data Mining
perspective, and share our view on their limitations and promising research
directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Separating Grains from the Chaff: Using Data Filtering to Improve Multilingual Translation for Low-Resourced African Languages. (arXiv:2210.10692v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.10692">
<div class="article-summary-box-inner">
<span><p>We participated in the WMT 2022 Large-Scale Machine Translation Evaluation
for the African Languages Shared Task. This work describes our approach, which
is based on filtering the given noisy data using a sentence-pair classifier
that was built by fine-tuning a pre-trained language model. To train the
classifier, we obtain positive samples (i.e. high-quality parallel sentences)
from a gold-standard curated dataset and extract negative samples (i.e.
low-quality parallel sentences) from automatically aligned parallel data by
choosing sentences with low alignment scores. Our final machine translation
model was then trained on filtered data, instead of the entire noisy dataset.
We empirically validate our approach by evaluating on two common datasets and
show that data filtering generally improves overall translation quality, in
some cases even significantly.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-10-21 23:19:57.376866424 UTC">2022-10-21 23:19:57 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>