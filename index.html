<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-06-26T01:30:00Z">06-26</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">A Reference-less Quality Metric for Automatic Speech Recognition via Contrastive-Learning of a Multi-Language Model with Self-Supervision. (arXiv:2306.13114v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13114">
<div class="article-summary-box-inner">
<span><p>The common standard for quality evaluation of automatic speech recognition
(ASR) systems is reference-based metrics such as the Word Error Rate (WER),
computed using manual ground-truth transcriptions that are time-consuming and
expensive to obtain. This work proposes a multi-language referenceless quality
metric, which allows comparing the performance of different ASR models on a
speech dataset without ground truth transcriptions. To estimate the quality of
ASR hypotheses, a pre-trained language model (LM) is fine-tuned with
contrastive learning in a self-supervised learning manner. In experiments
conducted on several unseen test datasets consisting of outputs from top
commercial ASR engines in various languages, the proposed referenceless metric
obtains a much higher correlation with WER scores and their ranks than the
perplexity metric from the state-of-art multi-lingual LM in all experiments,
and also reduces WER by more than $7\%$ when used for ensembling hypotheses.
The fine-tuned model and experiments are made available for the
reproducibility: https://github.com/aixplain/NoRefER
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompt to GPT-3: Step-by-Step Thinking Instructions for Humor Generation. (arXiv:2306.13195v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13195">
<div class="article-summary-box-inner">
<span><p>Artificial intelligence has made significant progress in natural language
processing, with models like GPT-3 demonstrating impressive capabilities.
However, these models still have limitations when it comes to complex tasks
that require an understanding of the user, such as mastering human comedy
writing strategies. This paper explores humor generation using GPT-3 by
modeling human comedy writing theory and leveraging step-by-step thinking
instructions. In addition, we explore the role of cognitive distance in
creating humor.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Adversarial Examples Jailbreak Large Language Models. (arXiv:2306.13213v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13213">
<div class="article-summary-box-inner">
<span><p>Recently, there has been a surge of interest in introducing vision into Large
Language Models (LLMs). The proliferation of large Visual Language Models
(VLMs), such as Flamingo, BLIP-2, and GPT-4, signifies an exciting convergence
of advancements in both visual and language foundation models. Yet, the risks
associated with this integrative approach are largely unexamined. In this
paper, we shed light on the security and safety implications of this trend.
First, we underscore that the continuous and high-dimensional nature of the
additional visual input space intrinsically makes it a fertile ground for
adversarial attacks. This unavoidably expands the attack surfaces of LLMs.
Second, we highlight that the broad functionality of LLMs also presents visual
attackers with a wider array of achievable adversarial objectives, extending
the implications of security failures beyond mere misclassification. To
elucidate these risks, we study adversarial examples in the visual input space
of a VLM. Specifically, against MiniGPT-4, which incorporates safety mechanisms
that can refuse harmful instructions, we present visual adversarial examples
that can circumvent the safety mechanisms and provoke harmful behaviors of the
model. Remarkably, we discover that adversarial examples, even if optimized on
a narrow, manually curated derogatory corpus against specific social groups,
can universally jailbreak the model's safety mechanisms. A single such
adversarial example can generally undermine MiniGPT-4's safety, enabling it to
heed a wide range of harmful instructions and produce harmful content far
beyond simply imitating the derogatory corpus used in optimization. Unveiling
these risks, we accentuate the urgent need for comprehensive risk assessments,
robust defense strategies, and the implementation of responsible practices for
the secure and safe utilization of VLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DiversiGATE: A Comprehensive Framework for Reliable Large Language Models. (arXiv:2306.13230v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13230">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce DiversiGATE, a unified framework that
consolidates diverse methodologies for LLM verification. The proposed framework
comprises two main components: Diversification and Aggregation which provide a
holistic perspective on existing verification approaches, such as
Self-Consistency, Math Prompter and WebGPT. Furthermore, we propose a novel
`SelfLearner' model that conforms to the DiversiGATE framework which can learn
from its own outputs and refine its performance over time, leading to improved
accuracy. To evaluate the effectiveness of SelfLearner, we conducted a rigorous
series of experiments, including tests on synthetic data as well as on popular
arithmetic reasoning benchmarks such as GSM8K. Our results demonstrate that our
approach outperforms traditional LLMs, achieving a considerable 54.8% -&gt; 61.8%
improvement on the GSM8K benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ToolQA: A Dataset for LLM Question Answering with External Tools. (arXiv:2306.13304v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13304">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LLMs) have demonstrated impressive performance in
various NLP tasks, but they still suffer from challenges such as hallucination
and weak numerical reasoning. To overcome these challenges, external tools can
be used to enhance LLMs' question-answering abilities. However, current
evaluation methods do not distinguish between questions that can be answered
using LLMs' internal knowledge and those that require external information
through tool use. To address this issue, we introduce a new dataset called
ToolQA, which is designed to faithfully evaluate LLMs' ability to use external
tools for question answering. Our development of ToolQA involved a scalable,
automated process for dataset curation, along with 13 specialized tools
designed for interaction with external knowledge in order to answer questions.
Importantly, we strive to minimize the overlap between our benchmark data and
LLMs' pre-training data, enabling a more precise evaluation of LLMs' tool-use
reasoning abilities. We conducted an in-depth diagnosis of existing tool-use
LLMs to highlight their strengths, weaknesses, and potential improvements. Our
findings set a new benchmark for evaluating LLMs and suggest new directions for
future advancements. Our data and code are freely available to the broader
scientific community on GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Effective and Compact Contextual Representation for Conformer Transducer Speech Recognition Systems. (arXiv:2306.13307v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13307">
<div class="article-summary-box-inner">
<span><p>Current ASR systems are mainly trained and evaluated at the utterance level.
Long range cross utterance context can be incorporated. A key task is to derive
a suitable compact representation of the most relevant history contexts. In
contrast to previous researches based on either LSTM-RNN encoded histories that
attenuate the information from longer range contexts, or frame level
concatenation of transformer context embeddings, in this paper compact
low-dimensional cross utterance contextual features are learned in the
Conformer-Transducer Encoder using specially designed attention pooling layers
that are applied over efficiently cached preceding utterances history vectors.
Experiments on the 1000-hr Gigaspeech corpus demonstrate that the proposed
contextualized streaming Conformer-Transducers outperform the baseline using
utterance internal context only with statistically significant WER reductions
of 0.7% to 0.5% absolute (4.3% to 3.1% relative) on the dev and test data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mutually Guided Few-shot Learning for Relational Triple Extraction. (arXiv:2306.13310v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13310">
<div class="article-summary-box-inner">
<span><p>Knowledge graphs (KGs), containing many entity-relation-entity triples,
provide rich information for downstream applications. Although extracting
triples from unstructured texts has been widely explored, most of them require
a large number of labeled instances. The performance will drop dramatically
when only few labeled data are available. To tackle this problem, we propose
the Mutually Guided Few-shot learning framework for Relational Triple
Extraction (MG-FTE). Specifically, our method consists of an entity-guided
relation proto-decoder to classify the relations firstly and a relation-guided
entity proto-decoder to extract entities based on the classified relations. To
draw the connection between entity and relation, we design a proto-level fusion
module to boost the performance of both entity extraction and relation
classification. Moreover, a new cross-domain few-shot triple extraction task is
introduced. Extensive experiments show that our method outperforms many
state-of-the-art methods by 12.6 F1 score on FewRel 1.0 (single-domain) and
20.5 F1 score on FewRel 2.0 (cross-domain).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Abstractive Text Summarization for Resumes With Cutting Edge NLP Transformers and LSTM. (arXiv:2306.13315v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13315">
<div class="article-summary-box-inner">
<span><p>Text summarization is a fundamental task in natural language processing that
aims to condense large amounts of textual information into concise and coherent
summaries. With the exponential growth of content and the need to extract key
information efficiently, text summarization has gained significant attention in
recent years. In this study, LSTM and pre-trained T5, Pegasus, BART and
BART-Large model performances were evaluated on the open source dataset (Xsum,
CNN/Daily Mail, Amazon Fine Food Review and News Summary) and the prepared
resume dataset. This resume dataset consists of many information such as
language, education, experience, personal information, skills, and this data
includes 75 resumes. The primary objective of this research was to classify
resume text. Various techniques such as LSTM, pre-trained models, and
fine-tuned models were assessed using a dataset of resumes. The BART-Large
model fine-tuned with the resume dataset gave the best performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stress Testing BERT Anaphora Resolution Models for Reaction Extraction in Chemical Patents. (arXiv:2306.13379v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13379">
<div class="article-summary-box-inner">
<span><p>The high volume of published chemical patents and the importance of a timely
acquisition of their information gives rise to automating information
extraction from chemical patents. Anaphora resolution is an important component
of comprehensive information extraction, and is critical for extracting
reactions. In chemical patents, there are five anaphoric relations of interest:
co-reference, transformed, reaction associated, work up, and contained. Our
goal is to investigate how the performance of anaphora resolution models for
reaction texts in chemical patents differs in a noise-free and noisy
environment and to what extent we can improve the robustness against noise of
the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Long-range Language Modeling with Self-retrieval. (arXiv:2306.13421v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13421">
<div class="article-summary-box-inner">
<span><p>Retrieval-augmented language models (LMs) have received much attention
recently. However, typically the retriever is not trained jointly as a native
component of the LM, but added to an already-pretrained LM, which limits the
ability of the LM and the retriever to adapt to one another. In this work, we
propose the Retrieval-Pretrained Transformer (RPT), an architecture and
training procedure for jointly training a retrieval-augmented LM from scratch
for the task of modeling long texts. Given a recently generated text chunk in a
long document, the LM computes query representations, which are then used to
retrieve earlier chunks in the document, located potentially tens of thousands
of tokens before. Information from retrieved chunks is fused into the LM
representations to predict the next target chunk. We train the retriever
component with a semantic objective, where the goal is to retrieve chunks that
increase the probability of the next chunk, according to a reference LM. We
evaluate RPT on four long-range language modeling tasks, spanning books, code,
and mathematical writing, and demonstrate that RPT improves retrieval quality
and subsequently perplexity across the board compared to strong baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Descriptive Image Captioning via Semipermeable Maximum Likelihood Estimation. (arXiv:2306.13460v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13460">
<div class="article-summary-box-inner">
<span><p>Image captioning aims to describe visual content in natural language. As 'a
picture is worth a thousand words', there could be various correct descriptions
for an image. However, with maximum likelihood estimation as the training
objective, the captioning model is penalized whenever its prediction mismatches
with the label. For instance, when the model predicts a word expressing richer
semantics than the label, it will be penalized and optimized to prefer more
concise expressions, referred to as conciseness optimization. In contrast,
predictions that are more concise than labels lead to richness optimization.
Such conflicting optimization directions could eventually result in the model
generating general descriptions. In this work, we introduce Semipermeable
MaxImum Likelihood Estimation (SMILE), which allows richness optimization while
blocking conciseness optimization, thus encouraging the model to generate
longer captions with more details. Extensive experiments on two mainstream
image captioning datasets MSCOCO and Flickr30K demonstrate that SMILE
significantly enhances the descriptiveness of generated captions. We further
provide in-depth investigations to facilitate a better understanding of how
SMILE works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incorporating Graph Information in Transformer-based AMR Parsing. (arXiv:2306.13467v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13467">
<div class="article-summary-box-inner">
<span><p>Abstract Meaning Representation (AMR) is a Semantic Parsing formalism that
aims at providing a semantic graph abstraction representing a given text.
Current approaches are based on autoregressive language models such as BART or
T5, fine-tuned through Teacher Forcing to obtain a linearized version of the
AMR graph from a sentence. In this paper, we present LeakDistill, a model and
method that explores a modification to the Transformer architecture, using
structural adapters to explicitly incorporate graph information into the
learned representations and improve AMR parsing performance. Our experiments
show how, by employing word-to-node alignment to embed graph structural
information into the encoder at training time, we can obtain state-of-the-art
AMR parsing through self-knowledge distillation, even without the use of
additional data. We release the code at
\url{<a href="http://www.github.com/sapienzanlp/LeakDistill">this http URL</a>}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-Infused Self Attention Transformers. (arXiv:2306.13501v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13501">
<div class="article-summary-box-inner">
<span><p>Transformer-based language models have achieved impressive success in various
natural language processing tasks due to their ability to capture complex
dependencies and contextual information using self-attention mechanisms.
However, they are not without limitations. These limitations include
hallucinations, where they produce incorrect outputs with high confidence, and
alignment issues, where they generate unhelpful and unsafe outputs for human
users. These limitations stem from the absence of implicit and missing context
in the data alone. To address this, researchers have explored augmenting these
models with external knowledge from knowledge graphs to provide the necessary
additional context. However, the ad-hoc nature of existing methods makes it
difficult to properly analyze the effects of knowledge infusion on the many
moving parts or components of a transformer. This paper introduces a systematic
method for infusing knowledge into different components of a transformer-based
model. A modular framework is proposed to identify specific components within
the transformer architecture, such as the self-attention mechanism, encoder
layers, or the input embedding layer, where knowledge infusion can be applied.
Additionally, extensive experiments are conducted on the General Language
Understanding Evaluation (GLUE) benchmark tasks, and the findings are reported.
This systematic approach aims to facilitate more principled approaches to
incorporating knowledge into language model architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Multimodal Large Language Models. (arXiv:2306.13549v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13549">
<div class="article-summary-box-inner">
<span><p>Multimodal Large Language Model (MLLM) recently has been a new rising
research hotspot, which uses powerful Large Language Models (LLMs) as a brain
to perform multimodal tasks. The surprising emergent capabilities of MLLM, such
as writing stories based on images and OCR-free math reasoning, are rare in
traditional methods, suggesting a potential path to artificial general
intelligence. In this paper, we aim to trace and summarize the recent progress
of MLLM. First of all, we present the formulation of MLLM and delineate its
related concepts. Then, we discuss the key techniques and applications,
including Multimodal Instruction Tuning (M-IT), Multimodal In-Context Learning
(M-ICL), Multimodal Chain of Thought (M-CoT), and LLM-Aided Visual Reasoning
(LAVR). Finally, we discuss existing challenges and point out promising
research directions. In light of the fact that the era of MLLM has only just
begun, we will keep updating this survey and hope it can inspire more research.
An associated GitHub link collecting the latest papers is available at
https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">System-Level Natural Language Feedback. (arXiv:2306.13588v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13588">
<div class="article-summary-box-inner">
<span><p>Natural language (NL) feedback contains rich information about the user
experience. Existing studies focus on an instance-level approach, where
feedback is used to refine specific examples, disregarding its system-wide
application. This paper proposes a general framework for unlocking the
system-level use of NL feedback. We show how to use feedback to formalize
system-level design decisions in a human-in-the-loop-process -- in order to
produce better models. In particular this is done through: (i) metric design
for tasks; and (ii) language model prompt design for refining model responses.
We conduct two case studies of this approach for improving search query
generation and dialog response generation, demonstrating the effectiveness of
the use of system-level feedback. We show the combination of system-level
feedback and instance-level feedback brings further gains, and that human
written instance-level feedback results in more grounded refinements than
GPT-3.5 written ones, underlying the importance of human feedback for building
systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Margin Maximization in Attention Mechanism. (arXiv:2306.13596v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13596">
<div class="article-summary-box-inner">
<span><p>Attention mechanism is a central component of the transformer architecture
which led to the phenomenal success of large language models. However, the
theoretical principles underlying the attention mechanism are poorly
understood, especially its nonconvex optimization dynamics. In this work, we
explore the seminal softmax-attention model $f(\boldsymbol{X})=\langle
\boldsymbol{Xv}, \texttt{softmax}(\boldsymbol{XWp})\rangle$, where,
$\boldsymbol{X}$ is the token sequence and
$(\boldsymbol{v},\boldsymbol{W},\boldsymbol{p})$ are tunable parameters. We
prove that running gradient descent on $\boldsymbol{p}$, or equivalently
$\boldsymbol{W}$, converges in direction to a max-margin solution that
separates $\textit{locally-optimal}$ tokens from non-optimal ones. This clearly
formalizes attention as a token separation mechanism. Remarkably, our results
are applicable to general data and precisely characterize $\textit{optimality}$
of tokens in terms of the value embeddings $\boldsymbol{Xv}$ and problem
geometry. We also provide a broader regularization path analysis that
establishes the margin maximizing nature of attention even for nonlinear
prediction heads. When optimizing $\boldsymbol{v}$ and $\boldsymbol{p}$
simultaneously with logistic loss, we identify conditions under which the
regularization paths directionally converge to their respective hard-margin SVM
solutions where $\boldsymbol{v}$ separates the input features based on their
labels. Interestingly, the SVM formulation of $\boldsymbol{p}$ is influenced by
the support vector geometry of $\boldsymbol{v}$. Finally, we verify our
theoretical findings via numerical experiments and provide insights.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models. (arXiv:2306.13649v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13649">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation is commonly used for compressing neural networks to
reduce their inference cost and memory footprint. However, current distillation
methods for auto-regressive models, such as generative language models (LMs),
suffer from two key issues: (1) distribution mismatch between output sequences
during training and the sequences generated by the student during its
deployment, and (2) model under-specification, where the student model may not
be expressive enough to fit the teacher's distribution. To address these
issues, we propose Generalized Knowledge Distillation (GKD). GKD mitigates
distribution mismatch by sampling output sequences from the student during
training. Furthermore, GKD handles model under-specification by optimizing
alternative divergences, such as reverse KL, that focus on generating samples
from the student that are likely under the teacher's distribution. We
demonstrate that GKD outperforms commonly-used approaches for distilling LLMs
on summarization, machine translation, and arithmetic reasoning tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bring Your Own Data! Self-Supervised Evaluation for Large Language Models. (arXiv:2306.13651v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13651">
<div class="article-summary-box-inner">
<span><p>With the rise of Large Language Models (LLMs) and their ubiquitous deployment
in diverse domains, measuring language model behavior on realistic data is
imperative. For example, a company deploying a client-facing chatbot must
ensure that the model will not respond to client requests with profanity.
Current evaluations approach this problem using small, domain-specific datasets
with human-curated labels. These evaluation sets are often sampled from a
narrow and simplified distribution, and data sources can unknowingly be leaked
into the training set which can lead to misleading evaluations. To bypass these
drawbacks, we propose a framework for self-supervised evaluation of LLMs by
analyzing their sensitivity or invariance to transformations on the input text.
Self-supervised evaluation can directly monitor LLM behavior on datasets
collected in the wild or streamed during live model deployment. We demonstrate
self-supervised evaluation strategies for measuring closed-book knowledge,
toxicity, and long-range context dependence, in addition to sensitivity to
grammatical structure and tokenization errors. When comparisons to similar
human-labeled benchmarks are available, we find strong correlations between
self-supervised and human-supervised evaluations. The self-supervised paradigm
complements current evaluation strategies that rely on labeled data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Determinantal Beam Search. (arXiv:2106.07400v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07400">
<div class="article-summary-box-inner">
<span><p>Beam search is a go-to strategy for decoding neural sequence models. The
algorithm can naturally be viewed as a subset optimization problem, albeit one
where the corresponding set function does not reflect interactions between
candidates. Empirically, this leads to sets often exhibiting high overlap,
e.g., strings may differ by only a single word. Yet in use-cases that call for
multiple solutions, a diverse or representative set is often desired. To
address this issue, we propose a reformulation of beam search, which we call
determinantal beam search. Determinantal beam search has a natural relationship
to determinantal point processes (DPPs), models over sets that inherently
encode intra-set interactions. By posing iterations in beam search as a series
of subdeterminant maximization problems, we can turn the algorithm into a
diverse subset selection process. In a case study, we use the string
subsequence kernel to explicitly encourage n-gram coverage in text generated
from a sequence model. We observe that our algorithm offers competitive
performance against other diverse set generation strategies in the context of
language generation, while providing a more general approach to optimizing for
diversity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Gender Fairness of Pre-Trained Language Models without Catastrophic Forgetting. (arXiv:2110.05367v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.05367">
<div class="article-summary-box-inner">
<span><p>Existing studies addressing gender bias of pre-trained language models,
usually build a small gender-neutral data set and conduct a second phase
pre-training on the model with such data. However, given the limited size and
concentrated focus of the gender-neutral data, catastrophic forgetting would
occur during second-phase pre-training. Forgetting information in the original
training data may damage the model's downstream performance by a large margin.
In this work, we empirically show that catastrophic forgetting occurs in such
methods by evaluating them with general NLP tasks in GLUE. Then, we propose a
new method, GEnder Equality Prompt (GEEP), to improve gender fairness of
pre-trained models with less forgetting. GEEP freezes the pre-trained model and
learns gender-related prompts with gender-neutral data. Empirical results show
that GEEP not only achieves SOTA performances on gender fairness tasks, but
also forgets less and performs better on GLUE by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">INSCIT: Information-Seeking Conversations with Mixed-Initiative Interactions. (arXiv:2207.00746v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.00746">
<div class="article-summary-box-inner">
<span><p>In an information-seeking conversation, a user may ask questions that are
under-specified or unanswerable. An ideal agent would interact by initiating
different response types according to the available knowledge sources. However,
most current studies either fail to or artificially incorporate such agent-side
initiative. This work presents InSCIt, a dataset for Information-Seeking
Conversations with mixed-initiative Interactions. It contains 4.7K user-agent
turns from 805 human-human conversations where the agent searches over
Wikipedia and either directly answers, asks for clarification, or provides
relevant information to address user queries. The data supports two subtasks,
evidence passage identification and response generation, as well as a human
evaluation protocol to assess model performance. We report results of two
systems based on state-of-the-art models of conversational knowledge
identification and open-domain question answering. Both systems significantly
underperform humans, suggesting ample room for improvement in future studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Natural Bias for Language Generation Models. (arXiv:2212.09686v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.09686">
<div class="article-summary-box-inner">
<span><p>After just a few hundred training updates, a standard probabilistic model for
language generation has likely not yet learnt many semantic or syntactic rules
of natural language, making it difficult to estimate the probability
distribution over next tokens. Yet around this point, these models have
identified a simple, loss-minimising behaviour: to output the unigram
distribution of the target training corpus. The use of such a heuristic raises
the question: Can we initialise our models with this behaviour and save
precious compute resources and model capacity? Here we show that we can
effectively endow standard neural language generation models with a separate
module that reflects unigram frequency statistics as prior knowledge, simply by
initialising the bias term in a model's final linear layer with the log-unigram
distribution. We use neural machine translation as a test bed for this simple
technique and observe that it: (i) improves learning efficiency; (ii) achieves
better overall performance; and perhaps most importantly (iii) appears to
disentangle strong frequency effects by encouraging the model to specialise in
non-frequency-related aspects of language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions. (arXiv:2212.10509v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.10509">
<div class="article-summary-box-inner">
<span><p>Prompting-based large language models (LLMs) are surprisingly powerful at
generating natural language reasoning steps or Chains-of-Thoughts (CoT) for
multi-step question answering (QA). They struggle, however, when the necessary
knowledge is either unavailable to the LLM or not up-to-date within its
parameters. While using the question to retrieve relevant text from an external
knowledge source helps LLMs, we observe that this one-step retrieve-and-read
approach is insufficient for multi-step QA. Here, \textit{what to retrieve}
depends on \textit{what has already been derived}, which in turn may depend on
\textit{what was previously retrieved}. To address this, we propose IRCoT, a
new approach for multi-step QA that interleaves retrieval with steps
(sentences) in a CoT, guiding the retrieval with CoT and in turn using
retrieved results to improve CoT. Using IRCoT with GPT3 substantially improves
retrieval (up to 21 points) as well as downstream QA (up to 15 points) on four
datasets: HotpotQA, 2WikiMultihopQA, MuSiQue, and IIRC. We observe similar
substantial gains in out-of-distribution (OOD) settings as well as with much
smaller models such as Flan-T5-large without additional training. IRCoT reduces
model hallucination, resulting in factually more accurate CoT reasoning. Code,
data, and prompts are available at \url{https://github.com/stonybrooknlp/ircot}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction. (arXiv:2301.09209v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09209">
<div class="article-summary-box-inner">
<span><p>We study object interaction anticipation in egocentric videos. This task
requires an understanding of the spatiotemporal context formed by past actions
on objects, coined action context. We propose TransFusion, a multimodal
transformer-based architecture. It exploits the representational power of
language by summarising the action context. TransFusion leverages pre-trained
image captioning and vision-language models to extract the action context from
past video frames. This action context together with the next video frame is
processed by the multimodal fusion module to forecast the next object
interaction. Our model enables more efficient end-to-end learning. The large
pre-trained language models add common sense and a generalisation capability.
Experiments on Ego4D and EPIC-KITCHENS-100 show the effectiveness of our
multimodal fusion model. They also highlight the benefits of using
language-based context summaries in a task where vision seems to suffice. Our
method outperforms state-of-the-art approaches by 40.4% in relative terms in
overall mAP on the Ego4D test set. We validate the effectiveness of TransFusion
via experiments on EPIC-KITCHENS-100. Video and code are available at
https://eth-ait.github.io/transfusion-proj/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extending the Pre-Training of BLOOM for Improved Support of Traditional Chinese: Models, Methods and Results. (arXiv:2303.04715v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04715">
<div class="article-summary-box-inner">
<span><p>In this paper we present the multilingual language model BLOOM-zh that
features enhanced support for Traditional Chinese. BLOOM-zh has its origins in
the open-source BLOOM models presented by BigScience in 2022. Starting from
released models, we extended the pre-training of BLOOM by additional 7.4
billion tokens in Traditional Chinese and English covering a variety of domains
such as news articles, books, encyclopedias, educational materials as well as
spoken language. In order to show the properties of BLOOM-zh, both existing and
newly created benchmark scenarios are used for evaluating the performance.
BLOOM-zh outperforms its predecessor on most Traditional Chinese benchmarks
while maintaining its English capability. We release all our models to the
research community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Automated Prompting: Are We Actually Doing Better?. (arXiv:2304.03609v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.03609">
<div class="article-summary-box-inner">
<span><p>Current literature demonstrates that Large Language Models (LLMs) are great
few-shot learners, and prompting significantly increases their performance on a
range of downstream tasks in a few-shot learning setting. An attempt to
automate human-led prompting followed, with some progress achieved. In
particular, subsequent work demonstrates automation can outperform fine-tuning
in certain K-shot learning scenarios.
</p>
<p>In this paper, we revisit techniques for automated prompting on six different
downstream tasks and a larger range of K-shot learning settings. We find that
automated prompting does not consistently outperform simple manual prompts. Our
work suggests that, in addition to fine-tuning, manual prompts should be used
as a baseline in this line of research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Supplementary Features of BiLSTM for Enhanced Sequence Labeling. (arXiv:2305.19928v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19928">
<div class="article-summary-box-inner">
<span><p>Sequence labeling tasks require the computation of sentence representations
for each word within a given sentence. A prevalent method incorporates a
Bi-directional Long Short-Term Memory (BiLSTM) layer to enhance the sequence
structure information. However, empirical evidence Li (2020) suggests that the
capacity of BiLSTM to produce sentence representations for sequence labeling
tasks is inherently limited. This limitation primarily results from the
integration of fragments from past and future sentence representations to
formulate a complete sentence representation. In this study, we observed that
the entire sentence representation, found in both the first and last cells of
BiLSTM, can supplement each the individual sentence representation of each
cell. Accordingly, we devised a global context mechanism to integrate entire
future and past sentence representations into each cell's sentence
representation within the BiLSTM framework. By incorporating the BERT model
within BiLSTM as a demonstration, and conducting exhaustive experiments on nine
datasets for sequence labeling tasks, including named entity recognition (NER),
part of speech (POS) tagging, and End-to-End Aspect-Based sentiment analysis
(E2E-ABSA). We noted significant improvements in F1 scores and accuracy across
all examined datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEACE: Perfect linear concept erasure in closed form. (arXiv:2306.03819v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.03819">
<div class="article-summary-box-inner">
<span><p>Concept erasure aims to remove specified features from a representation. It
can improve fairness (e.g. preventing a classifier from using gender or race)
and interpretability (e.g. removing a concept to observe changes in model
behavior). We introduce LEAst-squares Concept Erasure (LEACE), a closed-form
method which provably prevents all linear classifiers from detecting a concept
while changing the representation as little as possible, as measured by a broad
class of norms. We apply LEACE to large language models with a novel procedure
called "concept scrubbing," which erases target concept information from every
layer in the network. We demonstrate our method on two tasks: measuring the
reliance of language models on part-of-speech information, and reducing gender
bias in BERT embeddings. Code is available at
https://github.com/EleutherAI/concept-erasure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visually-Grounded Descriptions Improve Zero-Shot Image Classification. (arXiv:2306.06077v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.06077">
<div class="article-summary-box-inner">
<span><p>Language-vision models like CLIP have made significant progress in zero-shot
vision tasks, such as zero-shot image classification (ZSIC). However,
generating specific and expressive class descriptions remains a major
challenge. Existing approaches suffer from granularity and label ambiguity
issues. To tackle these challenges, we propose V-GLOSS: Visual Glosses, a novel
method leveraging modern language models and semantic knowledge bases to
produce visually-grounded class descriptions. We demonstrate V-GLOSS's
effectiveness by achieving state-of-the-art results on benchmark ZSIC datasets
including ImageNet and STL-10. In addition, we introduce a silver dataset with
class descriptions generated by V-GLOSS, and show its usefulness for vision
tasks. We make available our code and dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human-in-the-Loop through Chain-of-Thought. (arXiv:2306.07932v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.07932">
<div class="article-summary-box-inner">
<span><p>While the emergence of powerful language models along with Chain-of-thought
prompting has made automation more and more omnipresent, it sometimes
demonstrates its weakness in long-term or multi-step logical reasoning. For
example, users don't always get desirable answers for complex mathematical
problems without human involvement. Against this background, we present the
Manual Correction System (MCS) -- a human-in-the-loop system enhanced by
Chain-of-Thought prompting, which explores how manual correction of sub-logics
in rationales can improve LLM's reasoning performance. Moving one step forward,
considering a system with human-in-the-loop involves more than having humans
improve performance but also controlling the cost. Therefore, we post a
Cost-utility Analysis Model for Human-in-the-Loop systems (CAMLOP) based on
classical economics theory to analyze, quantify and balance the utility and the
corresponding cost. We conduct experiments of MCS and CAMLOP with twelve
datasets. A significant advantage w.r.t cost and utility proves its superiority
over strong baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought. (arXiv:2306.12672v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.12672">
<div class="article-summary-box-inner">
<span><p>How does language inform our downstream thinking? In particular, how do
humans make meaning from language--and how can we leverage a theory of
linguistic meaning to build machines that think in more human-like ways? In
this paper, we propose rational meaning construction, a computational framework
for language-informed thinking that combines neural language models with
probabilistic models for rational inference. We frame linguistic meaning as a
context-sensitive mapping from natural language into a probabilistic language
of thought (PLoT)--a general-purpose symbolic substrate for generative world
modeling. Our architecture integrates two computational tools that have not
previously come together: we model thinking with probabilistic programs, an
expressive representation for commonsense reasoning; and we model meaning
construction with large language models (LLMs), which support broad-coverage
translation from natural language utterances to code expressions in a
probabilistic programming language. We illustrate our framework through
examples covering four core domains from cognitive science: probabilistic
reasoning, logical and relational reasoning, visual and physical reasoning, and
social reasoning. In each, we show that LLMs can generate context-sensitive
translations that capture pragmatically-appropriate linguistic meanings, while
Bayesian inference with the generated programs supports coherent and robust
commonsense reasoning. We extend our framework to integrate
cognitively-motivated symbolic modules (physics simulators, graphics engines,
and planning algorithms) to provide a unified commonsense thinking interface
from language. Finally, we explore how language can drive the construction of
world models themselves. We hope this work will provide a roadmap towards
cognitive models and AI systems that synthesize the insights of both modern and
classical computational perspectives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GIMLET: A Unified Graph-Text Model for Instruction-Based Molecule Zero-Shot Learning. (arXiv:2306.13089v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.13089">
<div class="article-summary-box-inner">
<span><p>Molecule property prediction has gained significant attention in recent
years. The main bottleneck is the label insufficiency caused by expensive lab
experiments. In order to alleviate this issue and to better leverage textual
knowledge for tasks, this study investigates the feasibility of employing
natural language instructions to accomplish molecule-related tasks in a
zero-shot setting. We discover that existing molecule-text models perform
poorly in this setting due to inadequate treatment of instructions and limited
capacity for graphs. To overcome these issues, we propose GIMLET, which unifies
language models for both graph and text data. By adopting generalized position
embedding, our model is extended to encode both graph structures and
instruction text without additional graph encoding modules. GIMLET also
decouples encoding of the graph from tasks instructions in the attention
mechanism, enhancing the generalization of graph features across novel tasks.
We construct a dataset consisting of more than two thousand molecule tasks with
corresponding instructions derived from task descriptions. We pretrain GIMLET
on the molecule tasks along with instructions, enabling the model to transfer
effectively to a broad range of tasks. Experimental results demonstrate that
GIMLET significantly outperforms molecule-text baselines in instruction-based
zero-shot learning, even achieving closed results to supervised GNN models on
tasks such as toxcast and muv.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MarioGPT: Open-Ended Text2Level Generation through Large Language Models. (arXiv:2302.05981v2 [cs.AI] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.05981">
<div class="article-summary-box-inner">
<span><p>Procedural Content Generation (PCG) algorithms provide a technique to
generate complex and diverse environments in an automated way. However, while
generating content with PCG methods is often straightforward, generating
meaningful content that reflects specific intentions and constraints remains
challenging. Furthermore, many PCG algorithms lack the ability to generate
content in an open-ended manner. Recently, Large Language Models (LLMs) have
shown to be incredibly effective in many diverse domains. These trained LLMs
can be fine-tuned, re-using information and accelerating training for new
tasks. In this work, we introduce MarioGPT, a fine-tuned GPT2 model trained to
generate tile-based game levels, in our case Super Mario Bros levels. We show
that MarioGPT can not only generate diverse levels, but can be text-prompted
for controllable level generation, addressing one of the key challenges of
current PCG techniques. As far as we know, MarioGPT is the first text-to-level
model. We also combine MarioGPT with novelty search, enabling it to generate
diverse levels with varying play-style dynamics (i.e. player paths). This
combination allows for the open-ended generation of an increasingly diverse
range of content.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-06-26 23:12:52.910487086 UTC">2023-06-26 23:12:52 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>