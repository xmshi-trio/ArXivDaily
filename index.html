<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2023-01-25T01:30:00Z">01-25</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly-Supervised Questions for Zero-Shot Relation Extraction. (arXiv:2301.09640v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09640">
<div class="article-summary-box-inner">
<span><p>Zero-Shot Relation Extraction (ZRE) is the task of Relation Extraction where
the training and test sets have no shared relation types. This very challenging
domain is a good test of a model's ability to generalize. Previous approaches
to ZRE reframed relation extraction as Question Answering (QA), allowing for
the use of pre-trained QA models. However, this method required manually
creating gold question templates for each new relation. Here, we do away with
these gold templates and instead learn a model that can generate questions for
unseen relations. Our technique can successfully translate relation
descriptions into relevant questions, which are then leveraged to generate the
correct tail entity. On tail entity extraction, we outperform the previous
state-of-the-art by more than 16 F1 points without using gold question
templates. On the RE-QA dataset where no previous baseline for relation
extraction exists, our proposed algorithm comes within 0.7 F1 points of a
system that uses gold question templates. Our model also outperforms the
state-of-the-art ZRE baselines on the FewRel and WikiZSL datasets, showing that
QA models no longer need template questions to match the performance of models
specifically tailored to the ZRE task. Our implementation is available at
https://github.com/fyshelab/QA-ZRE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Selective Explanations: Leveraging Human Input to Align Explainable AI. (arXiv:2301.09656v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09656">
<div class="article-summary-box-inner">
<span><p>While a vast collection of explainable AI (XAI) algorithms have been
developed in recent years, they are often criticized for significant gaps with
how humans produce and consume explanations. As a result, current XAI
techniques are often found to be hard to use and lack effectiveness. In this
work, we attempt to close these gaps by making AI explanations selective -- a
fundamental property of human explanations -- by selectively presenting a
subset from a large set of model reasons based on what aligns with the
recipient's preferences. We propose a general framework for generating
selective explanations by leveraging human input on a small sample. This
framework opens up a rich design space that accounts for different selectivity
goals, types of input, and more. As a showcase, we use a decision-support task
to explore selective explanations based on what the decision-maker would
consider relevant to the decision task. We conducted two experimental studies
to examine three out of a broader possible set of paradigms based on our
proposed framework: in Study 1, we ask the participants to provide their own
input to generate selective explanations, with either open-ended or
critique-based input. In Study 2, we show participants selective explanations
based on input from a panel of similar users (annotators). Our experiments
demonstrate the promise of selective explanations in reducing over-reliance on
AI and improving decision outcomes and subjective perceptions of the AI, but
also paint a nuanced picture that attributes some of these positive effects to
the opportunity to provide one's own input to augment AI explanations. Overall,
our work proposes a novel XAI framework inspired by human communication
behaviors and demonstrates its potentials to encourage future work to better
align AI explanations with human production and consumption of explanations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Noisy Parallel Data Alignment. (arXiv:2301.09685v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09685">
<div class="article-summary-box-inner">
<span><p>An ongoing challenge in current natural language processing is how its major
advancements tend to disproportionately favor resource-rich languages, leaving
a significant number of under-resourced languages behind. Due to the lack of
resources required to train and evaluate models, most modern language
technologies are either nonexistent or unreliable to process endangered, local,
and non-standardized languages. Optical character recognition (OCR) is often
used to convert endangered language documents into machine-readable data.
However, such OCR output is typically noisy, and most word alignment models are
not built to work under such noisy conditions. In this work, we study the
existing word-level alignment models under noisy settings and aim to make them
more robust to noisy data. Our noise simulation and structural biasing method,
tested on multiple language pairs, manages to reduce the alignment error rate
on a state-of-the-art neural-based alignment model up to 59.6%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PRIMEQA: The Prime Repository for State-of-the-Art MultilingualQuestion Answering Research and Development. (arXiv:2301.09715v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09715">
<div class="article-summary-box-inner">
<span><p>The field of Question Answering (QA) has made remarkable progress in recent
years, thanks to the advent of large pre-trained language models, newer
realistic benchmark datasets with leaderboards, and novel algorithms for key
components such as retrievers and readers. In this paper, we introduce PRIMEQA:
a one-stop and open-source QA repository with an aim to democratize QA
re-search and facilitate easy replication of state-of-the-art (SOTA) QA
methods. PRIMEQA supports core QA functionalities like retrieval and reading
comprehension as well as auxiliary capabilities such as question generation.It
has been designed as an end-to-end toolkit for various use cases: building
front-end applications, replicating SOTA methods on pub-lic benchmarks, and
expanding pre-existing methods. PRIMEQA is available at :
https://github.com/primeqa.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topic Ontologies for Arguments. (arXiv:2301.09759v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09759">
<div class="article-summary-box-inner">
<span><p>Many computational argumentation tasks, like stance classification, are
topic-dependent: the effectiveness of approaches to these tasks significantly
depends on whether the approaches were trained on arguments from the same
topics as those they are tested on. So, which are these topics that researchers
train approaches on? This paper contributes the first comprehensive survey of
topic coverage, assessing 45 argument corpora. For the assessment, we take the
first step towards building an argument topic ontology, consulting three
diverse authoritative sources: the World Economic Forum, the Wikipedia list of
controversial topics, and Debatepedia. Comparing the topic sets between the
authoritative sources and corpora, our analysis shows that the corpora
topics-which are mostly those frequently discussed in public online fora - are
covered well by the sources. However, other topics from the sources are less
extensively covered by the corpora of today, revealing interesting future
directions for corpus construction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Truveta Mapper: A Zero-shot Ontology Alignment Framework. (arXiv:2301.09767v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09767">
<div class="article-summary-box-inner">
<span><p>In this paper, a new perspective is suggested for unsupervised Ontology
Matching (OM) or Ontology Alignment (OA) by treating it as a translation task.
Ontologies are represented as graphs, and the translation is performed from a
node in the source ontology graph to a path in the target ontology graph. The
proposed framework, Truveta Mapper (TM), leverages a multi-task
sequence-to-sequence transformer model to perform alignment across multiple
ontologies in a zero-shot, unified and end-to-end manner. Multi-tasking enables
the model to implicitly learn the relationship between different ontologies via
transfer-learning without requiring any explicit cross-ontology manually
labeled data. This also enables the formulated framework to outperform existing
solutions for both runtime latency and alignment quality. The model is
pre-trained and fine-tuned only on publicly available text corpus and
inner-ontologies data. The proposed solution outperforms state-of-the-art
approaches, Edit-Similarity, LogMap, AML, BERTMap, and the recently presented
new OM frameworks in Ontology Alignment Evaluation Initiative (OAEI22), offers
log-linear complexity in contrast to quadratic in the existing end-to-end
methods, and overall makes the OM task efficient and more straightforward
without much post-processing involving mapping extension or mapping repair.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer-Patcher: One Mistake worth One Neuron. (arXiv:2301.09785v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09785">
<div class="article-summary-box-inner">
<span><p>Large Transformer-based Pretrained Language Models (PLMs) dominate almost all
Natural Language Processing (NLP) tasks. Nevertheless, they still make mistakes
from time to time. For a model deployed in an industrial environment, fixing
these mistakes quickly and robustly is vital to improve user experiences.
Previous works formalize such problems as Model Editing (ME) and mostly focus
on fixing one mistake. However, the one-mistake-fixing scenario is not an
accurate abstraction of the real-world challenge. In the deployment of AI
services, there are ever-emerging mistakes, and the same mistake may recur if
not corrected in time. Thus a preferable solution is to rectify the mistakes as
soon as they appear nonstop. Therefore, we extend the existing ME into
Sequential Model Editing (SME) to help develop more practical editing methods.
Our study shows that most current ME methods could yield unsatisfying results
in this scenario. We then introduce Transformer-Patcher, a novel model editor
that can shift the behavior of transformer-based models by simply adding and
training a few neurons in the last Feed-Forward Network layer. Experimental
results on both classification and generation tasks show that
Transformer-Patcher can successively correct up to thousands of errors
(Reliability) and generalize to their equivalent inputs (Generality) while
retaining the model's accuracy on irrelevant inputs (Locality). Our method
outperforms previous fine-tuning and HyperNetwork-based methods and achieves
state-of-the-art performance for Sequential Model Editing (SME). The code is
available at https://github.com/ZeroYuHuang/Transformer-Patcher.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Very Large Pretrained Language Models Learn Storytelling With A Few Examples?. (arXiv:2301.09790v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09790">
<div class="article-summary-box-inner">
<span><p>While pre-trained language models can generate individually fluent sentences
for automatic story generation, they struggle to generate stories that are
coherent, sensible and interesting. Current state-of-the-art (SOTA) story
generation models explore using higher-level features such as plots or
commonsense knowledge to improve the quality of generated stories. Prompt-based
learning using very large pre-trained language models (VLPLMs) such as GPT3 has
demonstrated impressive performance even across various NLP tasks. In this
paper, we present an extensive study using automatic and human evaluation to
compare the story generation capability of VLPLMs to those SOTA models in three
different datasets where stories differ in style, register and length. Our
results show that VLPLMs generate much higher quality stories than other story
generation models, and to a certain extent rival human authors, although
preliminary investigation also reveals that they tend to ``plagiarise'' real
stories in scenarios that involve world knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low-Resource Compositional Semantic Parsing with Concept Pretraining. (arXiv:2301.09809v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09809">
<div class="article-summary-box-inner">
<span><p>Semantic parsing plays a key role in digital voice assistants such as Alexa,
Siri, and Google Assistant by mapping natural language to structured meaning
representations. When we want to improve the capabilities of a voice assistant
by adding a new domain, the underlying semantic parsing model needs to be
retrained using thousands of annotated examples from the new domain, which is
time-consuming and expensive. In this work, we present an architecture to
perform such domain adaptation automatically, with only a small amount of
metadata about the new domain and without any new training data (zero-shot) or
with very few examples (few-shot). We use a base seq2seq (sequence-to-sequence)
architecture and augment it with a concept encoder that encodes intent and slot
tags from the new domain. We also introduce a novel decoder-focused approach to
pretrain seq2seq models to be concept aware using Wikidata and use it to help
our model learn important concepts and perform well in low-resource settings.
We report few-shot and zero-shot results for compositional semantic parsing on
the TOPv2 dataset and show that our model outperforms prior approaches in
few-shot settings for the TOPv2 and SNIPS datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Stability Analysis of Fine-Tuning a Pre-Trained Model. (arXiv:2301.09820v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09820">
<div class="article-summary-box-inner">
<span><p>Fine-tuning a pre-trained model (such as BERT, ALBERT, RoBERTa, T5, GPT,
etc.) has proven to be one of the most promising paradigms in recent NLP
research. However, numerous recent works indicate that fine-tuning suffers from
the instability problem, i.e., tuning the same model under the same setting
results in significantly different performance. Many recent works have proposed
different methods to solve this problem, but there is no theoretical
understanding of why and how these methods work. In this paper, we propose a
novel theoretical stability analysis of fine-tuning that focuses on two
commonly used settings, namely, full fine-tuning and head tuning. We define the
stability under each setting and prove the corresponding stability bounds. The
theoretical bounds explain why and how several existing methods can stabilize
the fine-tuning procedure. In addition to being able to explain most of the
observed empirical discoveries, our proposed theoretical analysis framework can
also help in the design of effective and provable methods. Based on our theory,
we propose three novel strategies to stabilize the fine-tuning procedure,
namely, Maximal Margin Regularizer (MMR), Multi-Head Loss (MHLoss), and Self
Unsupervised Re-Training (SURT). We extensively evaluate our proposed
approaches on 11 widely used real-world benchmark datasets, as well as hundreds
of synthetic classification datasets. The experiment results show that our
proposed methods significantly stabilize the fine-tuning procedure and also
corroborate our theoretical analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Identification of Disaster News For Crisis Management Using Machine Learning. (arXiv:2301.09896v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09896">
<div class="article-summary-box-inner">
<span><p>A lot of news sources picked up on Typhoon Rai (also known locally as Typhoon
Odette), along with fake news outlets. The study honed in on the issue, to
create a model that can identify between legitimate and illegitimate news
articles. With this in mind, we chose the following machine learning algorithms
in our development: Logistic Regression, Random Forest and Multinomial Naive
Bayes. Bag of Words, TF-IDF and Lemmatization were implemented in the Model.
Gathering 160 datasets from legitimate and illegitimate sources, the machine
learning was trained and tested. By combining all the machine learning
techniques, the Combined BOW model was able to reach an accuracy of 91.07%,
precision of 88.33%, recall of 94.64%, and F1 score of 91.38% and Combined
TF-IDF model was able to reach an accuracy of 91.18%, precision of 86.89%,
recall of 94.64%, and F1 score of 90.60%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-lingual German Biomedical Information Extraction: from Zero-shot to Human-in-the-Loop. (arXiv:2301.09908v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09908">
<div class="article-summary-box-inner">
<span><p>This paper presents our project proposal for extracting biomedical
information from German clinical narratives with limited amounts of
annotations. We first describe the applied strategies in transfer learning and
active learning for solving our problem. After that, we discuss the design of
the user interface for both supplying model inspection and obtaining user
annotations in the interactive environment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conclusion-based Counter-Argument Generation. (arXiv:2301.09911v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09911">
<div class="article-summary-box-inner">
<span><p>In real-world debates, the most common way to counter an argument is to
reason against its main point, that is, its conclusion. Existing work on the
automatic generation of natural language counter-arguments does not address the
relation to the conclusion, possibly because many arguments leave their
conclusion implicit. In this paper, we hypothesize that the key to effective
counter-argument generation is to explicitly model the argument's conclusion
and to ensure that the stance of the generated counter is opposite to that
conclusion. In particular, we propose a multitask approach that jointly learns
to generate both the conclusion and the counter of an input argument. The
approach employs a stance-based ranking component that selects the counter from
a diverse set of generated candidates whose stance best opposes the generated
conclusion. In both automatic and manual evaluation, we provide evidence that
our approach generates more relevant and stance-adhering counters than strong
baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Applications and Challenges of Sentiment Analysis in Real-life Scenarios. (arXiv:2301.09912v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09912">
<div class="article-summary-box-inner">
<span><p>Sentiment analysis has benefited from the availability of lexicons and
benchmark datasets created over decades of research. However, its applications
to the real world are a driving force for research in SA. This chapter
describes some of these applications and related challenges in real-life
scenarios. In this chapter, we focus on five applications of SA: health, social
policy, e-commerce, digital humanities and other areas of NLP. This chapter is
intended to equip an NLP researcher with the `what', `why' and `how' of
applications of SA: what is the application about, why it is important and
challenging and how current research in SA deals with the application. We note
that, while the use of deep learning techniques is a popular paradigm that
spans these applications, challenges around privacy and selection bias of
datasets is a recurring theme across several applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Opportunities and Challenges in Neural Dialog Tutoring. (arXiv:2301.09919v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09919">
<div class="article-summary-box-inner">
<span><p>Designing dialog tutors has been challenging as it involves modeling the
diverse and complex pedagogical strategies employed by human tutors. Although
there have been significant recent advances in neural conversational systems
using large language models and growth in available dialog corpora, dialog
tutoring has largely remained unaffected by these advances. In this paper, we
rigorously analyze various generative language models on two dialog tutoring
datasets for language learning using automatic and human evaluations to
understand the new opportunities brought by these advances as well as the
challenges we must overcome to build models that would be usable in real
educational settings. We find that although current approaches can model
tutoring in constrained learning scenarios when the number of concepts to be
taught and possible teacher strategies are small, they perform poorly in less
constrained scenarios. Our human quality evaluation shows that both models and
ground-truth annotations exhibit low performance in terms of equitable
tutoring, which measures learning opportunities for students and how engaging
the dialog is. To understand the behavior of our models in a real tutoring
setting, we conduct a user study using expert annotators and find a
significantly large number of model reasoning errors in 45% of conversations.
Finally, we connect our findings to outline future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multitask Instruction-based Prompting for Fallacy Recognition. (arXiv:2301.09992v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09992">
<div class="article-summary-box-inner">
<span><p>Fallacies are used as seemingly valid arguments to support a position and
persuade the audience about its validity. Recognizing fallacies is an
intrinsically difficult task both for humans and machines. Moreover, a big
challenge for computational models lies in the fact that fallacies are
formulated differently across the datasets with differences in the input format
(e.g., question-answer pair, sentence with fallacy fragment), genre (e.g.,
social media, dialogue, news), as well as types and number of fallacies (from 5
to 18 types per dataset). To move towards solving the fallacy recognition task,
we approach these differences across datasets as multiple tasks and show how
instruction-based prompting in a multitask setup based on the T5 model improves
the results against approaches built for a specific dataset such as T5, BERT or
GPT-3. We show the ability of this multitask prompting approach to recognize 28
unique fallacies across domains and genres and study the effect of model size
and prompt choice by analyzing the per-class (i.e., fallacy type) results.
Finally, we analyze the effect of annotation quality on model performance, and
the feasibility of complementing this approach with external knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Inclusive Language to Gender-Neutral Machine Translation. (arXiv:2301.10075v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10075">
<div class="article-summary-box-inner">
<span><p>Gender inclusivity in language has become a central topic of debate and
research. Its application in the cross-lingual contexts of human and machine
translation (MT), however, remains largely unexplored. Here, we discuss
Gender-Neutral Translation (GNT) as a form of gender inclusivity in translation
and advocate for its adoption for MT models, which have been found to
perpetuate gender bias and discrimination. To this aim, we review a selection
of relevant institutional guidelines for Gender-Inclusive Language (GIL) to
collect and systematize useful strategies of gender neutralization. Then, we
discuss GNT and its scenarios of use, devising a list of desiderata. Finally,
we identify the main technical challenges to the implementation of GNT in MT.
Throughout these contributions we focus on translation from English into
Italian, as representative of salient linguistic transfer problems, due to the
different rules for gender marking in their grammar.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models as Fiduciaries: A Case Study Toward Robustly Communicating With Artificial Intelligence Through Legal Standards. (arXiv:2301.10095v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10095">
<div class="article-summary-box-inner">
<span><p>Artificial Intelligence (AI) is taking on increasingly autonomous roles,
e.g., browsing the web as a research assistant and managing money. But
specifying goals and restrictions for AI behavior is difficult. Similar to how
parties to a legal contract cannot foresee every potential "if-then"
contingency of their future relationship, we cannot specify desired AI behavior
for all circumstances. Legal standards facilitate the robust communication of
inherently vague and underspecified goals. Instructions (in the case of
language models, "prompts") that employ legal standards will allow AI agents to
develop shared understandings of the spirit of a directive that can adapt to
novel situations, and generalize expectations regarding acceptable actions to
take in unspecified states of the world. Standards have built-in context that
is lacking from other goal specification languages, such as plain language and
programming languages. Through an empirical study on thousands of evaluation
labels we constructed from U.S. court opinions, we demonstrate that large
language models (LLMs) are beginning to exhibit an "understanding" of one of
the most relevant legal standards for AI agents: fiduciary obligations.
Performance comparisons across models suggest that, as LLMs continue to exhibit
improved core capabilities, their legal standards understanding will also
continue to improve. OpenAI's latest LLM has 78% accuracy on our data, their
previous release has 73% accuracy, and a model from their 2020 GPT-3 paper has
27% accuracy (worse than random). Our research is an initial step toward a
framework for evaluating AI understanding of legal standards more broadly, and
for conducting reinforcement learning with legal feedback (RLLF).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Semantic Scholar Open Data Platform. (arXiv:2301.10140v1 [cs.DL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10140">
<div class="article-summary-box-inner">
<span><p>The volume of scientific output is creating an urgent need for automated
tools to help scientists keep up with developments in their field. Semantic
Scholar (S2) is an open data platform and website aimed at accelerating science
by helping scholars discover and understand scientific literature. We combine
public and proprietary data sources using state-of-the-art techniques for
scholarly PDF content extraction and automatic knowledge graph construction to
build the Semantic Scholar Academic Graph, the largest open scientific
literature graph to-date, with 200M+ papers, 80M+ authors, 550M+
paper-authorship edges, and 2.4B+ citation edges. The graph includes advanced
semantic features such as structurally parsed text, natural language summaries,
and vector embeddings. In this paper, we describe the components of the S2 data
processing pipeline and the associated APIs offered by the platform. We will
update this living document to reflect changes as we add new data offerings and
improve existing services.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lexi: Self-Supervised Learning of the UI Language. (arXiv:2301.10165v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10165">
<div class="article-summary-box-inner">
<span><p>Humans can learn to operate the user interface (UI) of an application by
reading an instruction manual or how-to guide. Along with text, these resources
include visual content such as UI screenshots and images of application icons
referenced in the text. We explore how to leverage this data to learn generic
visio-linguistic representations of UI screens and their components. These
representations are useful in many real applications, such as accessibility,
voice navigation, and task automation. Prior UI representation models rely on
UI metadata (UI trees and accessibility labels), which is often missing,
incompletely defined, or not accessible. We avoid such a dependency, and
propose Lexi, a pre-trained vision and language model designed to handle the
unique features of UI screens, including their text richness and context
sensitivity. To train Lexi we curate the UICaption dataset consisting of 114k
UI images paired with descriptions of their functionality. We evaluate Lexi on
four tasks: UI action entailment, instruction-based UI image retrieval,
grounding referring expressions, and UI entity recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Vision-Language Models for Granular Market Change Prediction. (arXiv:2301.10166v1 [q-fin.ST])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10166">
<div class="article-summary-box-inner">
<span><p>Predicting future direction of stock markets using the historical data has
been a fundamental component in financial forecasting. This historical data
contains the information of a stock in each specific time span, such as the
opening, closing, lowest, and highest price. Leveraging this data, the future
direction of the market is commonly predicted using various time-series models
such as Long-Short Term Memory networks. This work proposes modeling and
predicting market movements with a fundamentally new approach, namely by
utilizing image and byte-based number representation of the stock data
processed with the recently introduced Vision-Language models. We conduct a
large set of experiments on the hourly stock data of the German share index and
evaluate various architectures on stock price prediction using historical stock
data. We conduct a comprehensive evaluation of the results with various metrics
to accurately depict the actual performance of various approaches. Our
evaluation results show that our novel approach based on representation of
stock data as text (bytes) and image significantly outperforms strong deep
learning-based baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MTTN: Multi-Pair Text to Text Narratives for Prompt Generation. (arXiv:2301.10172v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10172">
<div class="article-summary-box-inner">
<span><p>The explosive popularity of diffusion models[ 1][ 2][ 3 ] has provided a huge
stage for further development in generative-text modelling. As prompt based
models are very nuanced, such that a carefully generated prompt can produce
truely breath taking images, on the contrary producing powerful or even
meaningful prompt is a hit or a miss. To lavish on this we have introduced a
large scale derived and synthesized dataset built with on real prompts and
indexed with popular image-text datasets like MS-COCO[4 ], Flickr[ 5], etc. We
have also introduced staging for these sentences that sequentially reduce the
context and increase the complexity, that will further strengthen the output
because of the complex annotations that are being created. MTTN consists of
over 2.4M sentences that are divided over 5 stages creating a combination
amounting to over 12M pairs, along with a vocab size of consisting more than
300 thousands unique words that creates an abundance of variations. The
original 2.4M million pairs are broken down in such a manner that it produces a
true scenario of internet lingo that is used globally thereby heightening the
robustness of the dataset, and any model trained on it.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multi-Purpose Audio-Visual Corpus for Multi-Modal Persian Speech Recognition: the Arman-AV Dataset. (arXiv:2301.10180v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10180">
<div class="article-summary-box-inner">
<span><p>In recent years, significant progress has been made in automatic lip reading.
But these methods require large-scale datasets that do not exist for many
low-resource languages. In this paper, we have presented a new multipurpose
audio-visual dataset for Persian. This dataset consists of almost 220 hours of
videos with 1760 corresponding speakers. In addition to lip reading, the
dataset is suitable for automatic speech recognition, audio-visual speech
recognition, and speaker recognition. Also, it is the first large-scale lip
reading dataset in Persian. A baseline method was provided for each mentioned
task. In addition, we have proposed a technique to detect visemes (a visual
equivalent of a phoneme) in Persian. The visemes obtained by this method
increase the accuracy of the lip reading task by 7% relatively compared to the
previously proposed visemes, which can be applied to other languages as well.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ViHOS: Hate Speech Spans Detection for Vietnamese. (arXiv:2301.10186v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10186">
<div class="article-summary-box-inner">
<span><p>The rise in hateful and offensive language directed at other users is one of
the adverse side effects of the increased use of social networking platforms.
This could make it difficult for human moderators to review tagged comments
filtered by classification systems. To help address this issue, we present the
ViHOS (Vietnamese Hate and Offensive Spans) dataset, the first human-annotated
corpus containing 26k spans on 11k comments. We also provide definitions of
hateful and offensive spans in Vietnamese comments as well as detailed
annotation guidelines. Besides, we conduct experiments with various
state-of-the-art models. Specifically, XLM-R$_{Large}$ achieved the best
F1-scores in Single span detection and All spans detection, while
PhoBERT$_{Large}$ obtained the highest in Multiple spans detection. Finally,
our error analysis demonstrates the difficulties in detecting specific types of
spans in our data for future research.
</p>
<p>Disclaimer: This paper contains real comments that could be considered
profane, offensive, or abusive.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Watermark for Large Language Models. (arXiv:2301.10226v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.10226">
<div class="article-summary-box-inner">
<span><p>Potential harms of large language models can be mitigated by watermarking
model output, i.e., embedding signals into generated text that are invisible to
humans but algorithmically detectable from a short span of tokens. We propose a
watermarking framework for proprietary language models. The watermark can be
embedded with negligible impact on text quality, and can be detected using an
efficient open-source algorithm without access to the language model API or
parameters. The watermark works by selecting a randomized set of whitelist
tokens before a word is generated, and then softly promoting use of whitelist
tokens during sampling. We propose a statistical test for detecting the
watermark with interpretable p-values, and derive an information-theoretic
framework for analyzing the sensitivity of the watermark. We test the watermark
using a multi-billion parameter model from the Open Pretrained Transformer
(OPT) family, and discuss robustness and security.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-grained Early Frequency Attention for Deep Speaker Representation Learning. (arXiv:2009.01822v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.01822">
<div class="article-summary-box-inner">
<span><p>Deep learning techniques have considerably improved speech processing in
recent years. Speaker representations extracted by deep learning models are
being used in a wide range of tasks such as speaker recognition and speech
emotion recognition. Attention mechanisms have started to play an important
role in improving deep learning models in the field of speech processing.
Nonetheless, despite the fact that important speaker-related information can be
embedded in individual frequency-bins of the input spectral representations,
current attention models are unable to attend to fine-grained information items
in spectral representations. In this paper we propose Fine-grained Early
Frequency Attention (FEFA) for speaker representation learning. Our model is a
simple and lightweight model that can be integrated into various CNN pipelines
and is capable of focusing on information items as small as frequency-bins. We
evaluate the proposed model on three tasks of speaker recognition, speech
emotion recognition, and spoken digit recognition. We use Three widely used
public datasets, namely VoxCeleb, IEMOCAP, and Free Spoken Digit Dataset for
our experiments. We attach FEFA to several prominent deep learning models and
evaluate its impact on the final performance. We also compare our work with
other related works in the area. Our experiments show that by adding FEFA to
different CNN architectures, performance is consistently improved by
substantial margins, and the models equipped with FEFA outperform all the other
attentive models. We also test our model against different levels of added
noise showing improvements in robustness and less sensitivity compared to the
backbone networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robustness through Data Augmentation Loss Consistency. (arXiv:2110.11205v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.11205">
<div class="article-summary-box-inner">
<span><p>While deep learning through empirical risk minimization (ERM) has succeeded
at achieving human-level performance at a variety of complex tasks, ERM is not
robust to distribution shifts or adversarial attacks. Synthetic data
augmentation followed by empirical risk minimization (DA-ERM) is a simple and
widely used solution to improve robustness in ERM. In addition, consistency
regularization can be applied to further improve the robustness of the model by
forcing the representation of the original sample and the augmented one to be
similar. However, existing consistency regularization methods are not
applicable to covariant data augmentation, where the label in the augmented
sample is dependent on the augmentation function. For example, dialog state
covaries with named entity when we augment data with a new named entity. In
this paper, we propose data augmented loss invariant regularization (DAIR), a
simple form of consistency regularization that is applied directly at the loss
level rather than intermediate features, making it widely applicable to both
invariant and covariant data augmentation regardless of network architecture,
problem setup, and task. We apply DAIR to real-world learning problems
involving covariant data augmentation: robust neural task-oriented dialog state
tracking and robust visual question answering. We also apply DAIR to tasks
involving invariant data augmentation: robust regression, robust classification
against adversarial attacks, and robust ImageNet classification under
distribution shift. Our experiments show that DAIR consistently outperforms ERM
and DA-ERM with little marginal computational cost and sets new
state-of-the-art results in several benchmarks involving covariant data
augmentation. Our code of all experiments is available at:
https://github.com/optimization-for-data-driven-science/DAIR.git
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HTMOT : Hierarchical Topic Modelling Over Time. (arXiv:2112.03104v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.03104">
<div class="article-summary-box-inner">
<span><p>Over the years, topic models have provided an efficient way of extracting
insights from text. However, while many models have been proposed, none are
able to model topic temporality and hierarchy jointly. Modelling time provide
more precise topics by separating lexically close but temporally distinct
topics while modelling hierarchy provides a more detailed view of the content
of a document corpus. In this study, we therefore propose a novel method,
HTMOT, to perform Hierarchical Topic Modelling Over Time. We train HTMOT using
a new implementation of Gibbs sampling, which is more efficient. Specifically,
we show that only applying time modelling to deep sub-topics provides a way to
extract specific stories or events while high level topics extract larger
themes in the corpus. Our results show that our training procedure is fast and
can extract accurate high-level topics and temporally precise sub-topics. We
measured our model's performance using the Word Intrusion task and outlined
some limitations of this evaluation method, especially for hierarchical models.
As a case study, we focused on the various developments in the space industry
in 2020.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can large language models reason about medical questions?. (arXiv:2207.08143v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2207.08143">
<div class="article-summary-box-inner">
<span><p>Although large language models (LLMs) often produce impressive outputs, it
remains unclear how they perform in real-world scenarios requiring strong
reasoning skills and expert domain knowledge. We set out to investigate whether
GPT-3.5 (Codex and InstructGPT) can be applied to answer and reason about
difficult real-world-based questions. We utilize two multiple-choice medical
exam questions (USMLE and MedMCQA) and a medical reading comprehension dataset
(PubMedQA). We investigate multiple prompting scenarios: Chain-of-Thought (CoT,
think step-by-step), zero- and few-shot (prepending the question with
question-answer exemplars) and retrieval augmentation (injecting Wikipedia
passages into the prompt). For a subset of the USMLE questions, a medical
expert reviewed and annotated the model's CoT. We found that InstructGPT can
often read, reason and recall expert knowledge. Failure are primarily due to
lack of knowledge and reasoning errors and trivial guessing heuristics are
observed, e.g.\ too often predicting labels A and D on USMLE. Sampling and
combining many completions overcome some of these limitations. Using 100
samples, Codex 5-shot CoT not only gives close to well-calibrated predictive
probability but also achieves human-level performances on the three datasets.
USMLE: 60.2%, MedMCQA: 62.7% and PubMedQA: 78.2%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reasoning over Different Types of Knowledge Graphs: Static, Temporal and Multi-Modal. (arXiv:2212.05767v5 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.05767">
<div class="article-summary-box-inner">
<span><p>Knowledge graph reasoning (KGR), aiming to deduce new facts from existing
facts based on mined logic rules underlying knowledge graphs (KGs), has become
a fast-growing research direction. It has been proven to significantly benefit
the usage of KGs in many AI applications, such as question answering and
recommendation systems, etc. According to the graph types, the existing KGR
models can be roughly divided into three categories, i.e., static models,
temporal models, and multi-modal models. The early works in this domain mainly
focus on static KGR and tend to directly apply general knowledge graph
embedding models to the reasoning task. However, these models are not suitable
for more complex but practical tasks, such as inductive static KGR, temporal
KGR, and multi-modal KGR. To this end, multiple works have been developed
recently, but no survey papers and open-source repositories comprehensively
summarize and discuss models in this important direction. To fill the gap, we
conduct a survey for knowledge graph reasoning tracing from static to temporal
and then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR
models, and typical datasets are introduced and discussed consequently.
Moreover, we discuss the challenges and potential opportunities. The
corresponding open-source repository is shared on GitHub:
https://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Foresight -- Generative Pretrained Transformer (GPT) for Modelling of Patient Timelines using EHRs. (arXiv:2212.08072v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.08072">
<div class="article-summary-box-inner">
<span><p>Background: Electronic Health Records hold detailed longitudinal information
about each patient's health status and general clinical history, a large
portion of which is stored within the unstructured text. Existing approaches
focus mostly on structured data and a subset of single-domain outcomes. We
explore how temporal modelling of patients from free text and structured data,
using deep generative transformers can be used to forecast a wide range of
future disorders, substances, procedures or findings. Methods: We present
Foresight, a novel transformer-based pipeline that uses named entity
recognition and linking tools to convert document text into structured, coded
concepts, followed by providing probabilistic forecasts for future medical
events such as disorders, substances, procedures and findings. We processed the
entire free-text portion from three different hospital datasets totalling
811336 patients covering both physical and mental health. Findings: On tests in
two UK hospitals (King's College Hospital, South London and Maudsley) and the
US MIMIC-III dataset precision@10 0.68, 0.76 and 0.88 was achieved for
forecasting the next disorder in a patient timeline, while precision@10 of
0.80, 0.81 and 0.91 was achieved for forecasting the next biomedical concept.
Foresight was also validated on 34 synthetic patient timelines by five
clinicians and achieved relevancy of 97% for the top forecasted candidate
disorder. As a generative model, it can forecast follow-on biomedical concepts
for as many steps as required. Interpretation: Foresight is a general-purpose
model for biomedical concept modelling that can be used for real-world risk
forecasting, virtual trials and clinical research to study the progression of
disorders, simulate interventions and counterfactuals, and educational
purposes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grammar construction methods for extended deterministic expressions. (arXiv:2301.01621v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.01621">
<div class="article-summary-box-inner">
<span><p>Extended regular expressions with counting and interleaving are widely used
in practice. However the related theoretical studies for this kind of
expressions currently cannot meet the need of practical work. This paper
develops syntax definitions for extended deterministic expressions and their
subclasses, hope to completely solve the long-standing problem that there are
no syntax definitions for this kind of expressions, which has become an
important reason for restricting the use of extended expressions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Agnostic Data-Driven Inverse Text Normalization. (arXiv:2301.08506v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.08506">
<div class="article-summary-box-inner">
<span><p>With the emergence of automatic speech recognition (ASR) models, converting
the spoken form text (from ASR) to the written form is in urgent need. This
inverse text normalization (ITN) problem attracts the attention of researchers
from various fields. Recently, several works show that data-driven ITN methods
can output high-quality written form text. Due to the scarcity of labeled
spoken-written datasets, the studies on non-English data-driven ITN are quite
limited. In this work, we propose a language-agnostic data-driven ITN framework
to fill this gap. Specifically, we leverage the data augmentation in
conjunction with neural machine translated data for low resource languages.
Moreover, we design an evaluation method for language agnostic ITN model when
only English data is available. Our empirical evaluation shows this language
agnostic modeling approach is effective for low resource languages while
preserving the performance for high resource languages.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2023-01-25 23:12:57.520032161 UTC">2023-01-25 23:12:57 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>