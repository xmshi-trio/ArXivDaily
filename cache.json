{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-06-13T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Zero-Shot Dialogue Relation Extraction by Relating Explainable Triggers and Relation Names. (arXiv:2306.06141v1 [cs.CL])","link":"http://arxiv.org/abs/2306.06141","description":"<p>Developing dialogue relation extraction (DRE) systems often requires a large\namount of labeled data, which can be costly and time-consuming to annotate. In\norder to improve scalability and support diverse, unseen relation extraction,\nthis paper proposes a method for leveraging the ability to capture triggers and\nrelate them to previously unseen relation names. Specifically, we introduce a\nmodel that enables zero-shot dialogue relation extraction by utilizing\ntrigger-capturing capabilities. Our experiments on a benchmark DialogRE dataset\ndemonstrate that the proposed model achieves significant improvements for both\nseen and unseen relations. Notably, this is the first attempt at zero-shot\ndialogue relation extraction using trigger-capturing capabilities, and our\nresults suggest that this approach is effective for inferring previously unseen\nrelation types. Overall, our findings highlight the potential for this method\nto enhance the scalability and practicality of DRE systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Ze-Song Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yun-Nung Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SentiGOLD: A Large Bangla Gold Standard Multi-Domain Sentiment Analysis Dataset and its Evaluation. (arXiv:2306.06147v1 [cs.CL])","link":"http://arxiv.org/abs/2306.06147","description":"<p>This study introduces SentiGOLD, a Bangla multi-domain sentiment analysis\ndataset. Comprising 70,000 samples, it was created from diverse sources and\nannotated by a gender-balanced team of linguists. SentiGOLD adheres to\nestablished linguistic conventions agreed upon by the Government of Bangladesh\nand a Bangla linguistics committee. Unlike English and other languages, Bangla\nlacks standard sentiment analysis datasets due to the absence of a national\nlinguistics framework. The dataset incorporates data from online video\ncomments, social media posts, blogs, news, and other sources while maintaining\ndomain and class distribution rigorously. It spans 30 domains (e.g., politics,\nentertainment, sports) and includes 5 sentiment classes (strongly negative,\nweakly negative, neutral, and strongly positive). The annotation scheme,\napproved by the national linguistics committee, ensures a robust Inter\nAnnotator Agreement (IAA) with a Fleiss' kappa score of 0.88. Intra- and\ncross-dataset evaluation protocols are applied to establish a standard\nclassification system. Cross-dataset evaluation on the noisy SentNoB dataset\npresents a challenging test scenario. Additionally, zero-shot experiments\ndemonstrate the generalizability of SentiGOLD. The top model achieves a macro\nf1 score of 0.62 (intra-dataset) across 5 classes, setting a benchmark, and\n0.61 (cross-dataset from SentNoB) across 3 classes, comparable to the\nstate-of-the-art. Fine-tuned sentiment analysis model can be accessed at\nhttps://sentiment.bangla.gov.bd.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">Md. Ekramul Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_L/0/1/0/all/0/1\">Labib Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Faisal Ahamed Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hossain_S/0/1/0/all/0/1\">Shazzad Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hossain_S/0/1/0/all/0/1\">Sourave Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashid_M/0/1/0/all/0/1\">Mohammad Mamun Or Rashid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammed_N/0/1/0/all/0/1\">Nabeel Mohammed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amin_M/0/1/0/all/0/1\">Mohammad Ruhul Amin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"$FPDM$: Domain-Specific Fast Pre-training Technique using Document-Level Metadata. (arXiv:2306.06190v1 [cs.CL])","link":"http://arxiv.org/abs/2306.06190","description":"<p>Pre-training Transformers has shown promising results on open-domain and\ndomain-specific downstream tasks. However, state-of-the-art Transformers\nrequire an unreasonably large amount of pre-training data and compute. In this\npaper, we propose $FPDM$ (Fast Pre-training Technique using Document Level\nMetadata), a novel, compute-efficient framework that utilizes Document metadata\nand Domain-Specific Taxonomy as supervision signals to pre-train transformer\nencoder on a domain-specific corpus. The main innovation is that during\ndomain-specific pretraining, an open-domain encoder is continually pre-trained\nusing sentence-level embeddings as inputs (to accommodate long documents),\nhowever, fine-tuning is done with token-level embeddings as inputs to this\nencoder. We show that $FPDM$ outperforms several transformer-based baselines in\nterms of character-level F1 scores and other automated metrics in the Customer\nSupport, Scientific, and Legal Domains, and shows a negligible drop in\nperformance on open-domain benchmarks. Importantly, the novel use of\ndocument-level supervision along with sentence-level embedding input for\npre-training reduces pre-training compute by around $1,000$, $4,500$, and $500$\ntimes compared to MLM and/or NSP in Customer Support, Scientific, and Legal\nDomains, respectively. Code and datasets are available at\nhttps://bit.ly/FPDMCode.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nandy_A/0/1/0/all/0/1\">Abhilash Nandy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapadnis_M/0/1/0/all/0/1\">Manav Nitin Kapadnis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patnaik_S/0/1/0/all/0/1\">Sohan Patnaik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Butala_Y/0/1/0/all/0/1\">Yash Parag Butala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguly_N/0/1/0/all/0/1\">Niloy Ganguly</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reliability Check: An Analysis of GPT-3's Response to Sensitive Topics and Prompt Wording. (arXiv:2306.06199v1 [cs.CL])","link":"http://arxiv.org/abs/2306.06199","description":"<p>Large language models (LLMs) have become mainstream technology with their\nversatile use cases and impressive performance. Despite the countless\nout-of-the-box applications, LLMs are still not reliable. A lot of work is\nbeing done to improve the factual accuracy, consistency, and ethical standards\nof these models through fine-tuning, prompting, and Reinforcement Learning with\nHuman Feedback (RLHF), but no systematic analysis of the responses of these\nmodels to different categories of statements, or on their potential\nvulnerabilities to simple prompting changes is available. In this work, we\nanalyze what confuses GPT-3: how the model responds to certain sensitive topics\nand what effects the prompt wording has on the model response. We find that\nGPT-3 correctly disagrees with obvious Conspiracies and Stereotypes but makes\nmistakes with common Misconceptions and Controversies. The model responses are\ninconsistent across prompts and settings, highlighting GPT-3's unreliability.\nDataset and code of our analysis is available in\nhttps://github.com/tanny411/GPT3-Reliability-Check.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khatun_A/0/1/0/all/0/1\">Aisha Khatun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Daniel G. Brown</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Morphosyntactic probing of multilingual BERT models. (arXiv:2306.06205v1 [cs.CL])","link":"http://arxiv.org/abs/2306.06205","description":"<p>We introduce an extensive dataset for multilingual probing of morphological\ninformation in language models (247 tasks across 42 languages from 10\nfamilies), each consisting of a sentence with a target word and a morphological\ntag as the desired label, derived from the Universal Dependencies treebanks. We\nfind that pre-trained Transformer models (mBERT and XLM-RoBERTa) learn features\nthat attain strong performance across these tasks. We then apply two methods to\nlocate, for each probing task, where the disambiguating information resides in\nthe input. The first is a new perturbation method that masks various parts of\ncontext; the second is the classical method of Shapley values. The most\nintriguing finding that emerges is a strong tendency for the preceding context\nto hold more information relevant to the prediction than the following context.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Acs_J/0/1/0/all/0/1\">Judit Acs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamerlik_E/0/1/0/all/0/1\">Endre Hamerlik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_R/0/1/0/all/0/1\">Roy Schwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kornai_A/0/1/0/all/0/1\">Andras Kornai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conformalizing Machine Translation Evaluation. (arXiv:2306.06221v1 [cs.CL])","link":"http://arxiv.org/abs/2306.06221","description":"<p>Several uncertainty estimation methods have been recently proposed for\nmachine translation evaluation. While these methods can provide a useful\nindication of when not to trust model predictions, we show in this paper that\nthe majority of them tend to underestimate model uncertainty, and as a result\nthey often produce misleading confidence intervals that do not cover the ground\ntruth. We propose as an alternative the use of conformal prediction, a\ndistribution-free method to obtain confidence intervals with a theoretically\nestablished guarantee on coverage. First, we demonstrate that split conformal\nprediction can ``correct'' the confidence intervals of previous methods to\nyield a desired coverage level. Then, we highlight biases in estimated\nconfidence intervals, both in terms of the translation language pairs and the\nquality of translations. We apply conditional conformal prediction techniques\nto obtain calibration subsets for each data subgroup, leading to equalized\ncoverage.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zerva_C/0/1/0/all/0/1\">Chrysoula Zerva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1\">Andr&#xe9; F. T. Martins</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Probing self-supervised speech models for phonetic and phonemic information: a case study in aspiration. (arXiv:2306.06232v1 [cs.CL])","link":"http://arxiv.org/abs/2306.06232","description":"<p>Textless self-supervised speech models have grown in capabilities in recent\nyears, but the nature of the linguistic information they encode has not yet\nbeen thoroughly examined. We evaluate the extent to which these models' learned\nrepresentations align with basic representational distinctions made by humans,\nfocusing on a set of phonetic (low-level) and phonemic (more abstract)\ncontrasts instantiated in word-initial stops. We find that robust\nrepresentations of both phonetic and phonemic distinctions emerge in early\nlayers of these models' architectures, and are preserved in the principal\ncomponents of deeper layer representations. Our analyses suggest two sources\nfor this success: some can only be explained by the optimization of the models\non speech data, while some can be attributed to these models' high-dimensional\narchitectures. Our findings show that speech-trained HuBERT derives a low-noise\nand low-dimensional subspace corresponding to abstract phonological\ndistinctions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Martin_K/0/1/0/all/0/1\">Kinan Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gauthier_J/0/1/0/all/0/1\">Jon Gauthier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Breiss_C/0/1/0/all/0/1\">Canaan Breiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_R/0/1/0/all/0/1\">Roger Levy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Foundation Models to Detect Policy Violations with Minimal Supervision. (arXiv:2306.06234v1 [cs.CL])","link":"http://arxiv.org/abs/2306.06234","description":"<p>Foundation models, i.e. large neural networks pre-trained on large text\ncorpora, have revolutionized NLP. They can be instructed directly (e.g.\n(<a href=\"/abs/2005.14165\">arXiv:2005.14165</a>)) - this is called hard prompting - and they can be tuned\nusing very little data (e.g. (<a href=\"/abs/2104.08691\">arXiv:2104.08691</a>)) - this technique is called\nsoft prompting. We seek to leverage their capabilities to detect policy\nviolations. Our contributions are: We identify a hard prompt that adapts\nchain-of-thought prompting to policy violation tasks. This prompt produces\npolicy violation classifications, along with extractive explanations that\njustify the classification. We compose the hard-prompts with soft prompt tuning\nto produce a classifier that attains high accuracy with very little\nsupervision; the same classifier also produces explanations. Though the\nsupervision only acts on the classifications, we find that the modified\nexplanations remain consistent with the (tuned) model's response. Along the\nway, we identify several unintuitive aspects of foundation models. For\ninstance, adding an example from a specific class can actually reduce\npredictions of that class, and separately, the effects of tokenization on\nscoring etc. Based on our technical results, we identify a simple workflow for\nproduct teams to quickly develop effective policy violation detectors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mittal_S/0/1/0/all/0/1\">Sid Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1\">Vineet Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Frederick Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundararajan_M/0/1/0/all/0/1\">Mukund Sundararajan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Record Deduplication for Entity Distribution Modeling in ASR Transcripts. (arXiv:2306.06246v1 [cs.CL])","link":"http://arxiv.org/abs/2306.06246","description":"<p>Voice digital assistants must keep up with trending search queries. We rely\non a speech recognition model using contextual biasing with a rapidly updated\nset of entities, instead of frequent model retraining, to keep up with trends.\nThere are several challenges with this approach: (1) the entity set must be\nfrequently reconstructed, (2) the entity set is of limited size due to latency\nand accuracy trade-offs, and (3) finding the true entity distribution for\nbiasing is complicated by ASR misrecognition. We address these challenges and\ndefine an entity set by modeling customers true requested entity distribution\nfrom ASR output in production using record deduplication, a technique from the\nfield of entity resolution. Record deduplication resolves or deduplicates\ncoreferences, including misrecognitions, of the same latent entity. Our method\nsuccessfully retrieves 95% of misrecognized entities and when used for\ncontextual biasing shows an estimated 5% relative word error rate reduction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1\">Tianyu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_C/0/1/0/all/0/1\">Chung Hoon Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wivagg_C/0/1/0/all/0/1\">Carl Wivagg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shimizu_K/0/1/0/all/0/1\">Kanna Shimizu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Measuring and Modifying Factual Knowledge in Large Language Models. (arXiv:2306.06264v1 [cs.CL])","link":"http://arxiv.org/abs/2306.06264","description":"<p>Large Language Models (LLMs) store an extensive amount of factual knowledge\nobtained from vast collections of text. To effectively utilize these models for\ndownstream tasks, it is crucial to have reliable methods for measuring their\nknowledge. However, existing approaches for knowledge measurement have certain\nlimitations, and despite recent efforts, they fail to provide accurate\nmeasurements and the necessary insights for modifying the knowledge within\nLLMs. In this work, we employ information theory-based measurements to provide\na framework estimating the factual knowledge contained within large language\nmodels. More specifically, we measure knowledge by analyzing the LLM's\nprediction probability distribution before and after instilling the target\nknowledge, employing metrics such as entropy and KL-divergence. Introducing our\nmetrics, we first assess their accuracy in comparison to previous ranking-based\nmethods, surpassing them by over $35\\%$ in a synthetic experiment. Then, we\nexplore two prominent methods of knowledge instillation, discovering that LLMs\nexhibit limitations in capturing new knowledge under specific circumstances for\none of these methods. Lastly, we demonstrate the applicability of our methods\nin extracting unlearned and mislearned facts in LLMs through their application\nto in-context learning. We make code and data for all methods and experiments\nin this paper publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pezeshkpour_P/0/1/0/all/0/1\">Pouya Pezeshkpour</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Protect Your Prompts: Protocols for IP Protection in LLM Applications. (arXiv:2306.06297v1 [cs.CL])","link":"http://arxiv.org/abs/2306.06297","description":"<p>With the rapid adoption of AI in the form of large language models (LLMs),\nthe potential value of carefully engineered prompts has become significant.\nHowever, to realize this potential, prompts should be tradable on an open\nmarket. Since prompts are, at present, generally economically non-excludable,\nby virtue of their nature as text, no general competitive market has yet been\nestablished. This note discusses two protocols intended to provide protection\nof prompts, elevating their status as intellectual property, thus confirming\nthe intellectual property rights of prompt engineers, and potentially\nsupporting the flourishing of an open market for LLM prompts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wyk_M/0/1/0/all/0/1\">M.A. van Wyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bekker_M/0/1/0/all/0/1\">M. Bekker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richards_X/0/1/0/all/0/1\">X.L. Richards</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nixon_K/0/1/0/all/0/1\">K.J. Nixon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Arabic Multimodal Dataset for Sentiment Analysis. (arXiv:2306.06322v1 [cs.CL])","link":"http://arxiv.org/abs/2306.06322","description":"<p>Multimodal Sentiment Analysis (MSA) has recently become a centric research\ndirection for many real-world applications. This proliferation is due to the\nfact that opinions are central to almost all human activities and are key\ninfluencers of our behaviors. In addition, the recent deployment of Deep\nLearning-based (DL) models has proven their high efficiency for a wide range of\nWestern languages. In contrast, Arabic DL-based multimodal sentiment analysis\n(MSA) is still in its infantile stage due, mainly, to the lack of standard\ndatasets. In this paper, our investigation is twofold. First, we design a\npipeline that helps building our Arabic Multimodal dataset leveraging both\nstate-of-the-art transformers and feature extraction tools within word\nalignment techniques. Thereafter, we validate our dataset using\nstate-of-the-art transformer-based model dealing with multimodality. Despite\nthe small size of the outcome dataset, experiments show that Arabic\nmultimodality is very promising\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Haouhat_A/0/1/0/all/0/1\">Abdelhamid Haouhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bellaouar_S/0/1/0/all/0/1\">Slimane Bellaouar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nehar_A/0/1/0/all/0/1\">Attia Nehar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cherroun_H/0/1/0/all/0/1\">Hadda Cherroun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating the Effectiveness of ChatGPT in Mathematical Reasoning and Problem Solving: Evidence from the Vietnamese National High School Graduation Examination. (arXiv:2306.06331v1 [cs.CL])","link":"http://arxiv.org/abs/2306.06331","description":"<p>This study offers a complete analysis of ChatGPT's mathematics abilities in\nresponding to multiple-choice questions for the Vietnamese National High School\nGraduation Examination (VNHSGE) on a range of subjects and difficulty levels.\nThe dataset included 250 questions divided into four levels: knowledge (K),\ncomprehension (C), application (A), and high application (H), and it included\nten themes that covered diverse mathematical concepts. The outcomes demonstrate\nthat ChatGPT's performance varies depending on the difficulty level and\nsubject. It performed best on questions at Level (K), with an accuracy rate of\n$83\\%$; but, as the difficulty level rose, it scored poorly, with an accuracy\nrate of $10\\%$. The study has also shown that ChatGPT significantly succeeds in\nproviding responses to questions on subjects including exponential and\nlogarithmic functions, geometric progression, and arithmetic progression. The\nstudy found that ChatGPT had difficulty correctly answering questions on topics\nincluding derivatives and applications, spatial geometry, and Oxyz spatial\ncalculus. Additionally, this study contrasted ChatGPT outcomes with Vietnamese\nstudents in VNHSGE and in other math competitions. ChatGPT dominated in the SAT\nMath competition with a success rate of $70\\%$, followed by VNHSGE mathematics\n($58.8\\%)$. However, its success rates were lower on other exams, such as AP\nStatistics, the GRE Quantitative, AMC 10, AMC 12, and AP Calculus BC. These\nresults suggest that ChatGPT has the potential to be an effective teaching tool\nfor mathematics, but more work is needed to enhance its handling of graphical\ndata and address the challenges presented by questions that are getting more\nchallenging.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dao_X/0/1/0/all/0/1\">Xuan-Quy Dao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1\">Ngoc-Bich Le</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Non-autoregressive Translation Quality with Pretrained Language Model, Embedding Distillation and Upsampling Strategy for CTC. (arXiv:2306.06345v1 [cs.CL])","link":"http://arxiv.org/abs/2306.06345","description":"<p>Non-autoregressive approaches aim to improve the inference speed of\ntranslation models, particularly those that generate output in a one-pass\nforward manner. However, these approaches often suffer from a significant drop\nin translation quality compared to autoregressive models. This paper introduces\na series of innovative techniques to enhance the translation quality of\nNon-Autoregressive Translation (NAT) models while maintaining a substantial\nacceleration in inference speed. We propose fine-tuning Pretrained Multilingual\nLanguage Models (PMLMs) with the CTC loss to train NAT models effectively.\nFurthermore, we adopt the MASK insertion scheme for up-sampling instead of\ntoken duplication, and we present an embedding distillation method to further\nenhance performance. In our experiments, our model outperforms the baseline\nautoregressive model (Transformer \\textit{base}) on multiple datasets,\nincluding WMT'14 DE$\\leftrightarrow$EN, WMT'16 RO$\\leftrightarrow$EN, and\nIWSLT'14 DE$\\leftrightarrow$EN. Notably, our model achieves better performance\nthan the baseline autoregressive model on the IWSLT'14 En$\\leftrightarrow$De\nand WMT'16 En$\\leftrightarrow$Ro datasets, even without using distillation data\nduring training. It is worth highlighting that on the IWSLT'14\nDE$\\rightarrow$EN dataset, our model achieves an impressive BLEU score of\n39.59, setting a new state-of-the-art performance. Additionally, our model\nexhibits a remarkable speed improvement of 16.35 times compared to the\nautoregressive model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Syu_S/0/1/0/all/0/1\">Shen-sian Syu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Juncheng Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Review of State-of-The-Art Methods for Java Code Generation from Natural Language Text. (arXiv:2306.06371v1 [cs.CL])","link":"http://arxiv.org/abs/2306.06371","description":"<p>Java Code Generation consists in generating automatically Java code from a\nNatural Language Text. This NLP task helps in increasing programmers'\nproductivity by providing them with immediate solutions to the simplest and\nmost repetitive tasks. Code generation is a challenging task because of the\nhard syntactic rules and the necessity of a deep understanding of the semantic\naspect of the programming language. Many works tried to tackle this task using\neither RNN-based, or Transformer-based models. The latter achieved remarkable\nadvancement in the domain and they can be divided into three groups: (1)\nencoder-only models, (2) decoder-only models, and (3) encoder-decoder models.\nIn this paper, we provide a comprehensive review of the evolution and progress\nof deep learning models in Java code generation task. We focus on the most\nimportant methods and present their merits and limitations, as well as the\nobjective functions used by the community. In addition, we provide a detailed\ndescription of datasets and evaluation metrics used in the literature. Finally,\nwe discuss results of different models on CONCODE dataset, then propose some\nfuture directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Espejel_J/0/1/0/all/0/1\">Jessica L&#xf3;pez Espejel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alassan_M/0/1/0/all/0/1\">Mahaman Sanoussi Yahaya Alassan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chouham_E/0/1/0/all/0/1\">El Mehdi Chouham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dahhane_W/0/1/0/all/0/1\">Walid Dahhane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ettifouri_E/0/1/0/all/0/1\">El Hassane Ettifouri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-Row, Multi-Span Distant Supervision For Table+Text Question. (arXiv:2112.07337v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2112.07337","description":"<p>Question answering (QA) over tables and linked text, also called TextTableQA,\nhas witnessed significant research in recent years, as tables are often found\nembedded in documents along with related text. HybridQA and OTT-QA are the two\nbest-known TextTableQA datasets, with questions that are best answered by\ncombining information from both table cells and linked text passages. A common\nchallenge in both datasets, and TextTableQA in general, is that the training\ninstances include just the question and answer, where the gold answer may match\nnot only multiple table cells across table rows but also multiple text spans\nwithin the scope of a table row and its associated text. This leads to a noisy\nmulti instance training regime. We present MITQA, a transformer-based\nTextTableQA system that is explicitly designed to cope with distant supervision\nalong both these axes, through a multi-instance loss objective, together with\ncareful curriculum design. Our experiments show that the proposed\nmulti-instance distant supervision approach helps MITQA get state-of-the-art\nresults beating the existing baselines for both HybridQA and OTT-QA, putting\nMITQA at the top of HybridQA leaderboard with best EM and F1 scores on a held\nout test set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vishwajeet Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_Y/0/1/0/all/0/1\">Yash Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chemmengath_S/0/1/0/all/0/1\">Saneem Chemmengath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_J/0/1/0/all/0/1\">Jaydeep Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarti_S/0/1/0/all/0/1\">Soumen Chakrabarti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bharadwaj_S/0/1/0/all/0/1\">Samarth Bharadwaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1\">FeiFei Pan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Measuring the Impact of Individual Domain Factors in Self-Supervised Pre-Training. (arXiv:2203.00648v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2203.00648","description":"<p>Human speech data comprises a rich set of domain factors such as accent,\nsyntactic and semantic variety, or acoustic environment. Previous work explores\nthe effect of domain mismatch in automatic speech recognition between\npre-training and fine-tuning as a whole but does not dissect the contribution\nof individual factors. In this paper, we present a controlled study to better\nunderstand the effect of such factors on the performance of pre-trained\nrepresentations on automatic speech recognition. To do so, we pre-train models\neither on modified natural speech or synthesized audio, with a single domain\nfactor modified, and then measure performance after fine-tuning. Results show\nthat phonetic domain factors play an important role during pre-training while\ngrammatical and syntactic factors are far less important. To our knowledge,\nthis is the first study to better understand the domain characteristics of\npre-trained sets in self-supervised pre-training for speech.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sanabria_R/0/1/0/all/0/1\">Ramon Sanabria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1\">Wei-Ning Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baevski_A/0/1/0/all/0/1\">Alexei Baevski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Auli_M/0/1/0/all/0/1\">Michael Auli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Recent Advances in Neural Text Generation: A Task-Agnostic Survey. (arXiv:2203.03047v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2203.03047","description":"<p>In recent years, considerable research has been dedicated to the application\nof neural models in the field of natural language generation (NLG). The primary\nobjective is to generate text that is both linguistically natural and\nhuman-like, while also exerting control over the generation process. This paper\noffers a comprehensive and task-agnostic survey of the recent advancements in\nneural text generation. These advancements have been facilitated through a\nmultitude of developments, which we categorize into four key areas: data\nconstruction, neural frameworks, training and inference strategies, and\nevaluation metrics. By examining these different aspects, we aim to provide a\nholistic overview of the progress made in the field. Furthermore, we explore\nthe future directions for the advancement of neural text generation, which\nencompass the utilization of neural pipelines and the incorporation of\nbackground knowledge. These avenues present promising opportunities to further\nenhance the capabilities of NLG systems. Overall, this survey serves to\nconsolidate the current state of the art in neural text generation and\nhighlights potential avenues for future research and development in this\ndynamic field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Chen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerin_F/0/1/0/all/0/1\">Frank Guerin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ClaimDiff: Comparing and Contrasting Claims on Contentious Issues. (arXiv:2205.12221v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.12221","description":"<p>With the growing importance of detecting misinformation, many studies have\nfocused on verifying factual claims by retrieving evidence. However, canonical\nfact verification tasks do not apply to catching subtle differences in\nfactually consistent claims, which might still bias the readers, especially on\ncontentious political or economic issues. Our underlying assumption is that\namong the trusted sources, one's argument is not necessarily more true than the\nother, requiring comparison rather than verification. In this study, we propose\nClaimDiff, a novel dataset that primarily focuses on comparing the nuance\nbetween claim pairs. In ClaimDiff, we provide 2,941 annotated claim pairs from\n268 news articles. We observe that while humans are capable of detecting the\nnuances between claims, strong baselines struggle to detect them, showing over\na 19% absolute gap with the humans. We hope this initial study could help\nreaders to gain an unbiased grasp of contentious issues through machine-aided\ncomparison.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ko_M/0/1/0/all/0/1\">Miyoung Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seong_I/0/1/0/all/0/1\">Ingyu Seong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hwaran Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Joonsuk Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1\">Minsuk Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1\">Minjoon Seo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal Pre-training. (arXiv:2206.00621v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.00621","description":"<p>In this paper, we introduce Cross-View Language Modeling, a simple and\neffective pre-training framework that unifies cross-lingual and cross-modal\npre-training with shared architectures and objectives. Our approach is\nmotivated by a key observation that cross-lingual and cross-modal pre-training\nshare the same goal of aligning two different views of the same object into a\ncommon semantic space. To this end, the cross-view language modeling framework\nconsiders both multi-modal data (i.e., image-caption pairs) and multi-lingual\ndata (i.e., parallel sentence pairs) as two different views of the same object,\nand trains the model to align the two views by maximizing the mutual\ninformation between them with conditional masked language modeling and\ncontrastive learning. We pre-train CCLM, a Cross-lingual Cross-modal Language\nModel, with the cross-view language modeling framework. Empirical results on\nIGLUE, a multi-lingual multi-modal benchmark, and two multi-lingual image-text\nretrieval datasets show that while conceptually simpler, CCLM significantly\noutperforms the prior state-of-the-art with an average absolute improvement of\nover 10%. Moreover, CCLM is the first multi-lingual multi-modal pre-trained\nmodel that surpasses the translate-test performance of representative English\nvision-language models by zero-shot cross-lingual transfer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wangchunshu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_A/0/1/0/all/0/1\">Ao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1\">Ziming Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinsong Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DiMS: Distilling Multiple Steps of Iterative Non-Autoregressive Transformers for Machine Translation. (arXiv:2206.02999v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.02999","description":"<p>The computational benefits of iterative non-autoregressive transformers\ndecrease as the number of decoding steps increases. As a remedy, we introduce\nDistill Multiple Steps (DiMS), a simple yet effective distillation technique to\ndecrease the number of required steps to reach a certain translation quality.\nThe distilled model enjoys the computational benefits of early iterations while\npreserving the enhancements from several iterative steps. DiMS relies on two\nmodels namely student and teacher. The student is optimized to predict the\noutput of the teacher after multiple decoding steps while the teacher follows\nthe student via a slow-moving average. The moving average keeps the teacher's\nknowledge updated and enhances the quality of the labels provided by the\nteacher. During inference, the student is used for translation and no\nadditional computation is added. We verify the effectiveness of DiMS on various\nmodels obtaining 7.8 and 12.9 BLEU points improvements in single-step\ntranslation accuracy on distilled and raw versions of WMT'14 De-En.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_S/0/1/0/all/0/1\">Sajad Norouzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseinzadeh_R/0/1/0/all/0/1\">Rasa Hosseinzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_F/0/1/0/all/0/1\">Felipe Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Volkovs_M/0/1/0/all/0/1\">Maksims Volkovs</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models. (arXiv:2206.04615v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.04615","description":"<p>Language models demonstrate both quantitative improvement and new qualitative\ncapabilities with increasing scale. Despite their potentially transformative\nimpact, these new capabilities are as yet poorly characterized. In order to\ninform future research, prepare for disruptive new model capabilities, and\nameliorate socially harmful effects, it is vital that we understand the present\nand near-future capabilities and limitations of language models. To address\nthis challenge, we introduce the Beyond the Imitation Game benchmark\n(BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 450\nauthors across 132 institutions. Task topics are diverse, drawing problems from\nlinguistics, childhood development, math, common-sense reasoning, biology,\nphysics, social bias, software development, and beyond. BIG-bench focuses on\ntasks that are believed to be beyond the capabilities of current language\nmodels. We evaluate the behavior of OpenAI's GPT models, Google-internal dense\ntransformer architectures, and Switch-style sparse transformers on BIG-bench,\nacross model sizes spanning millions to hundreds of billions of parameters. In\naddition, a team of human expert raters performed all tasks in order to provide\na strong baseline. Findings include: model performance and calibration both\nimprove with scale, but are poor in absolute terms (and when compared with\nrater performance); performance is remarkably similar across model classes,\nthough with benefits from sparsity; tasks that improve gradually and\npredictably commonly involve a large knowledge or memorization component,\nwhereas tasks that exhibit \"breakthrough\" behavior at a critical scale often\ninvolve multiple steps or components, or brittle metrics; social bias typically\nincreases with scale in settings with ambiguous context, but this can be\nimproved with prompting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1\">Aarohi Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastogi_A/0/1/0/all/0/1\">Abhinav Rastogi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1\">Abhishek Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoeb_A/0/1/0/all/0/1\">Abu Awal Md Shoeb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abid_A/0/1/0/all/0/1\">Abubakar Abid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisch_A/0/1/0/all/0/1\">Adam Fisch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_A/0/1/0/all/0/1\">Adam R. Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santoro_A/0/1/0/all/0/1\">Adam Santoro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Aditya Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garriga_Alonso_A/0/1/0/all/0/1\">Adri&#xe0; Garriga-Alonso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kluska_A/0/1/0/all/0/1\">Agnieszka Kluska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewkowycz_A/0/1/0/all/0/1\">Aitor Lewkowycz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Akshat Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Power_A/0/1/0/all/0/1\">Alethea Power</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_A/0/1/0/all/0/1\">Alex Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warstadt_A/0/1/0/all/0/1\">Alex Warstadt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kocurek_A/0/1/0/all/0/1\">Alexander W. Kocurek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Safaya_A/0/1/0/all/0/1\">Ali Safaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tazarv_A/0/1/0/all/0/1\">Ali Tazarv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_A/0/1/0/all/0/1\">Alice Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parrish_A/0/1/0/all/0/1\">Alicia Parrish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_A/0/1/0/all/0/1\">Allen Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hussain_A/0/1/0/all/0/1\">Aman Hussain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Askell_A/0/1/0/all/0/1\">Amanda Askell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dsouza_A/0/1/0/all/0/1\">Amanda Dsouza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slone_A/0/1/0/all/0/1\">Ambrose Slone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahane_A/0/1/0/all/0/1\">Ameet Rahane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_A/0/1/0/all/0/1\">Anantharaman S. Iyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreassen_A/0/1/0/all/0/1\">Anders Andreassen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1\">Andrea Madotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santilli_A/0/1/0/all/0/1\">Andrea Santilli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stuhlmuller_A/0/1/0/all/0/1\">Andreas Stuhlm&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1\">Andrew Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+La_A/0/1/0/all/0/1\">Andrew La</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lampinen_A/0/1/0/all/0/1\">Andrew Lampinen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_A/0/1/0/all/0/1\">Andy Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_A/0/1/0/all/0/1\">Angela Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Angelica Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vuong_A/0/1/0/all/0/1\">Anh Vuong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Animesh Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gottardi_A/0/1/0/all/0/1\">Anna Gottardi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norelli_A/0/1/0/all/0/1\">Antonio Norelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkatesh_A/0/1/0/all/0/1\">Anu Venkatesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gholamidavoodi_A/0/1/0/all/0/1\">Arash Gholamidavoodi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabassum_A/0/1/0/all/0/1\">Arfa Tabassum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menezes_A/0/1/0/all/0/1\">Arul Menezes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirubarajan_A/0/1/0/all/0/1\">Arun Kirubarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mullokandov_A/0/1/0/all/0/1\">Asher Mullokandov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herrick_A/0/1/0/all/0/1\">Austin Herrick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Efrat_A/0/1/0/all/0/1\">Avia Efrat</a>, et al. (400 additional authors not shown)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Visual Grounding by Encouraging Consistent Gradient-based Explanations. (arXiv:2206.15462v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2206.15462","description":"<p>We propose a margin-based loss for vision-language model pretraining that\nencourages gradient-based explanations that are consistent with region-level\nannotations. We refer to this objective as Attention Mask Consistency (AMC) and\ndemonstrate that it produces superior visual grounding performance compared to\nmodels that rely instead on region-level annotations for explicitly training an\nobject detector such as Faster R-CNN. AMC works by encouraging gradient-based\nexplanation masks that focus their attention scores mostly within annotated\nregions of interest for images that contain such annotations. Particularly, a\nmodel trained with AMC on top of standard vision-language modeling objectives\nobtains a state-of-the-art accuracy of 86.59% in the Flickr30k visual grounding\nbenchmark, an absolute improvement of 5.48% when compared to the best previous\nmodel. Our approach also performs exceedingly well on established benchmarks\nfor referring expression comprehension and offers the added benefit by design\nof gradient-based explanations that better align with human annotations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Ziyan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kafle_K/0/1/0/all/0/1\">Kushal Kafle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dernoncourt_F/0/1/0/all/0/1\">Franck Dernoncourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ordonez_V/0/1/0/all/0/1\">Vicente Ordonez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in Transformers. (arXiv:2210.06313v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2210.06313","description":"<p>This paper studies the curious phenomenon for machine learning models with\nTransformer architectures that their activation maps are sparse. By activation\nmap we refer to the intermediate output of the multi-layer perceptrons (MLPs)\nafter a ReLU activation function, and by sparse we mean that on average very\nfew entries (e.g., 3.0% for T5-Base and 6.3% for ViT-B16) are nonzero for each\ninput to MLP. Moreover, larger Transformers with more layers and wider MLP\nhidden dimensions are sparser as measured by the percentage of nonzero entries.\nThrough extensive experiments we demonstrate that the emergence of sparsity is\na prevalent phenomenon that occurs for both natural language processing and\nvision tasks, on both training and evaluation data, for Transformers of various\nconfigurations, at layers of all depth levels, as well as for other\narchitectures including MLP-mixers and 2-layer MLPs. We show that sparsity also\nemerges using training datasets with random labels, or with random inputs, or\nwith infinite amount of data, demonstrating that sparsity is not a result of a\nspecific family of datasets. We discuss how sparsity immediately implies a way\nto significantly reduce the FLOP count and improve efficiency for Transformers.\nMoreover, we demonstrate perhaps surprisingly that enforcing an even sparser\nactivation via Top-k thresholding with a small value of k brings a collection\nof desired but missing properties for Transformers, namely less sensitivity to\nnoisy training data, more robustness to input corruptions, and better\ncalibration for their prediction confidence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zonglin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chong You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhojanapalli_S/0/1/0/all/0/1\">Srinadh Bhojanapalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Daliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawat_A/0/1/0/all/0/1\">Ankit Singh Rawat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddi_S/0/1/0/all/0/1\">Sashank J. Reddi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_K/0/1/0/all/0/1\">Ke Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chern_F/0/1/0/all/0/1\">Felix Chern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Felix Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1\">Ruiqi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sanjiv Kumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Instruction Tuning for Few-Shot Aspect-Based Sentiment Analysis. (arXiv:2210.06629v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.06629","description":"<p>Aspect-based Sentiment Analysis (ABSA) is a fine-grained sentiment analysis\ntask which involves four elements from user-generated texts: aspect term,\naspect category, opinion term, and sentiment polarity. Most computational\napproaches focus on some of the ABSA sub-tasks such as tuple (aspect term,\nsentiment polarity) or triplet (aspect term, opinion term, sentiment polarity)\nextraction using either pipeline or joint modeling approaches. Recently,\ngenerative approaches have been proposed to extract all four elements as (one\nor more) quadruplets from text as a single task. In this work, we take a step\nfurther and propose a unified framework for solving ABSA, and the associated\nsub-tasks to improve the performance in few-shot scenarios. To this end, we\nfine-tune a T5 model with instructional prompts in a multi-task learning\nfashion covering all the sub-tasks, as well as the entire quadruple prediction\ntask. In experiments with multiple benchmark datasets, we show that the\nproposed multi-task prompting approach brings performance boost (by absolute\n8.29 F1) in the few-shot learning setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Varia_S/0/1/0/all/0/1\">Siddharth Varia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halder_K/0/1/0/all/0/1\">Kishaloy Halder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vacareanu_R/0/1/0/all/0/1\">Robert Vacareanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ballesteros_M/0/1/0/all/0/1\">Miguel Ballesteros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benajiba_Y/0/1/0/all/0/1\">Yassine Benajiba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+John_N/0/1/0/all/0/1\">Neha Anna John</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anubhai_R/0/1/0/all/0/1\">Rishita Anubhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muresan_S/0/1/0/all/0/1\">Smaranda Muresan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generating Multilingual Gender-Ambiguous Text-to-Speech Voices. (arXiv:2211.00375v3 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2211.00375","description":"<p>The gender of any voice user interface is a key element of its perceived\nidentity. Recently, there has been increasing interest in interfaces where the\ngender is ambiguous rather than clearly identifying as female or male. This\nwork addresses the task of generating novel gender-ambiguous TTS voices in a\nmulti-speaker, multilingual setting. This is accomplished by efficiently\nsampling from a latent speaker embedding space using a proposed gender-aware\nmethod. Extensive objective and subjective evaluations clearly indicate that\nthis method is able to efficiently generate a range of novel, diverse voices\nthat are consistent and perceived as more gender-ambiguous than a baseline\nvoice across all the languages examined. Interestingly, the gender perception\nis found to be robust across two demographic factors of the listeners: native\nlanguage and gender. To our knowledge, this is the first systematic and\nvalidated approach that can reliably generate a variety of gender-ambiguous\nvoices.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Markopoulos_K/0/1/0/all/0/1\">Konstantinos Markopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maniati_G/0/1/0/all/0/1\">Georgia Maniati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vamvoukakis_G/0/1/0/all/0/1\">Georgios Vamvoukakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellinas_N/0/1/0/all/0/1\">Nikolaos Ellinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vardaxoglou_G/0/1/0/all/0/1\">Georgios Vardaxoglou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakoulidis_P/0/1/0/all/0/1\">Panos Kakoulidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1\">Junkwang Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jho_G/0/1/0/all/0/1\">Gunu Jho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_I/0/1/0/all/0/1\">Inchul Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalamandaris_A/0/1/0/all/0/1\">Aimilios Chalamandaris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsiakoulis_P/0/1/0/all/0/1\">Pirros Tsiakoulis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raptis_S/0/1/0/all/0/1\">Spyros Raptis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Does Debiasing Inevitably Degrade the Model Performance. (arXiv:2211.07350v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.07350","description":"<p>Gender bias in language models has attracted sufficient attention because it\nthreatens social justice. However, most of the current debiasing methods\ndegraded the model's performance on other tasks while the degradation mechanism\nis still mysterious. We propose a theoretical framework explaining the three\ncandidate mechanisms of the language model's gender bias. We use our\ntheoretical framework to explain why the current debiasing methods cause\nperformance degradation. We also discover a pathway through which debiasing\nwill not degrade the model performance. We further develop a\ncausality-detection fine-tuning approach to correct gender bias. The numerical\nexperiment demonstrates that our method is able to lead to double dividends:\npartially mitigating gender bias while avoiding performance degradation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yiran Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haotian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yang Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adaptation Approaches for Nearest Neighbor Language Models. (arXiv:2211.07828v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.07828","description":"<p>Semi-parametric Nearest Neighbor Language Models ($k$NN-LMs) have produced\nimpressive gains over purely parametric LMs, by leveraging large-scale\nneighborhood retrieval over external memory datastores. However, there has been\nlittle investigation into adapting such models for new domains. This work\nattempts to fill that gap and suggests the following approaches for adapting\n$k$NN-LMs -- 1) adapting the underlying LM (using Adapters), 2) expanding\nneighborhood retrieval over an additional adaptation datastore, and 3) adapting\nthe weights (scores) of retrieved neighbors using a learned Rescorer module. We\nstudy each adaptation strategy separately, as well as the combined performance\nimprovement through ablation experiments and an extensive set of evaluations\nrun over seven adaptation domains. Our combined adaptation approach\nconsistently outperforms purely parametric adaptation and zero-shot ($k$NN-LM)\nbaselines that construct datastores from the adaptation data. On average, we\nsee perplexity improvements of 17.1% and 16% for these respective baselines,\nacross domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhardwaj_R/0/1/0/all/0/1\">Rishabh Bhardwaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polovets_G/0/1/0/all/0/1\">George Polovets</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sunkara_M/0/1/0/all/0/1\">Monica Sunkara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Federated Neural Topic Models. (arXiv:2212.02269v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2212.02269","description":"<p>Over the last years, topic modeling has emerged as a powerful technique for\norganizing and summarizing big collections of documents or searching for\nparticular patterns in them. However, privacy concerns may arise when\ncross-analyzing data from different sources. Federated topic modeling solves\nthis issue by allowing multiple parties to jointly train a topic model without\nsharing their data. While several federated approximations of classical topic\nmodels do exist, no research has been conducted on their application for neural\ntopic models. To fill this gap, we propose and analyze a federated\nimplementation based on state-of-the-art neural topic modeling implementations,\nshowing its benefits when there is a diversity of topics across the nodes'\ndocuments and the need to build a joint model. In practice, our approach is\nequivalent to a centralized model training, but preserves the privacy of the\nnodes. Advantages of this federated scenario are illustrated by means of\nexperiments using both synthetic and real data scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Calvo_Bartolome_L/0/1/0/all/0/1\">Lorena Calvo-Bartolom&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arenas_Garcia_J/0/1/0/all/0/1\">Jer&#xf3;nimo Arenas-Garc&#xed;a</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Continual Knowledge Distillation for Neural Machine Translation. (arXiv:2212.09097v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09097","description":"<p>While many parallel corpora are not publicly accessible for data copyright,\ndata privacy and competitive differentiation reasons, trained translation\nmodels are increasingly available on open platforms. In this work, we propose a\nmethod called continual knowledge distillation to take advantage of existing\ntranslation models to improve one model of interest. The basic idea is to\nsequentially transfer knowledge from each trained model to the distilled model.\nExtensive experiments on Chinese-English and German-English datasets show that\nour method achieves significant and consistent improvements over strong\nbaselines under both homogeneous and heterogeneous trained model settings and\nis robust to malicious models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuanchi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BLIND: Bias Removal With No Demographics. (arXiv:2212.10563v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10563","description":"<p>Models trained on real-world data tend to imitate and amplify social biases.\nCommon methods to mitigate biases require prior information on the types of\nbiases that should be mitigated (e.g., gender or racial bias) and the social\ngroups associated with each data sample. In this work, we introduce BLIND, a\nmethod for bias removal with no prior knowledge of the demographics in the\ndataset. While training a model on a downstream task, BLIND detects biased\nsamples using an auxiliary model that predicts the main model's success, and\ndown-weights those samples during the training process. Experiments with racial\nand gender biases in sentiment classification and occupation classification\ntasks demonstrate that BLIND mitigates social biases without relying on a\ncostly demographic annotation process. Our method is competitive with other\nmethods that require demographic information and sometimes even surpasses them.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Orgad_H/0/1/0/all/0/1\">Hadas Orgad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1\">Yonatan Belinkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning. (arXiv:2212.10773v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10773","description":"<p>Instruction tuning, a new learning paradigm that fine-tunes pre-trained\nlanguage models on tasks specified through instructions, has shown promising\nzero-shot performance on various natural language processing tasks. However, it\nhas yet to be explored for vision and multimodal tasks. In this work, we\nintroduce MUL-TIINSTRUCT, the first multimodal instruction tuning benchmark\ndataset that consists of 62 diverse multimodal tasks in a unified seq-to-seq\nformat covering 10 broad categories. The tasks are derived from 21 existing\nopen-source datasets and each task is equipped with 5 expert-written\ninstructions. We take OFA as the base pre-trained model for multimodal\ninstruction tuning, and to further improve its zero-shot performance, we\nexplore multiple transfer learning strategies to leverage the large-scale\nNATURAL INSTRUCTIONS dataset. Experimental results demonstrate strong zero-shot\nperformance on various unseen multimodal tasks and the benefit of transfer\nlearning from a text-only instruction dataset. We also design a new evaluation\nmetric - Sensitivity, to evaluate how sensitive the model is to the variety of\ninstructions. Our results indicate that fine-tuning the model on a diverse set\nof tasks and instructions leads to a reduced sensitivity to variations in\ninstructions for each task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhiyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Ying Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Lifu Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT: Jack of all trades, master of none. (arXiv:2302.10724v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.10724","description":"<p>OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and\nrevolutionized the approach in artificial intelligence to human-model\ninteraction. Several publications on ChatGPT evaluation test its effectiveness\non well-known natural language processing (NLP) tasks. However, the existing\nstudies are mostly non-automated and tested on a very limited scale. In this\nwork, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks,\nmost of them subjective even to humans, such as sentiment analysis, emotion\nrecognition, offensiveness, and stance detection. In contrast, the other tasks\nrequire more objective reasoning like word sense disambiguation, linguistic\nacceptability, and question answering. We also evaluated GPT-4 model on five\nselected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process\nand analyzed more than 49k responses. Our comparison of its results with\navailable State-of-the-Art (SOTA) solutions showed that the average loss in\nquality of the ChatGPT model was about 25% for zero-shot and few-shot\nevaluation. For GPT-4 model, a loss for semantic tasks is significantly lower\nthan for ChatGPT. We showed that the more difficult the task (lower SOTA\nperformance), the higher the ChatGPT loss. It especially refers to pragmatic\nNLP problems like emotion recognition. We also tested the ability to\npersonalize ChatGPT responses for selected subjective tasks via Random\nContextual Few-Shot Personalization, and we obtained significantly better\nuser-based predictions. Additional qualitative analysis revealed a ChatGPT\nbias, most likely due to the rules imposed on human trainers by OpenAI. Our\nresults provide the basis for a fundamental discussion of whether the high\nquality of recent predictive NLP models can indicate a tool's usefulness to\nsociety and how the learning and validation procedures for such systems should\nbe established.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kocon_J/0/1/0/all/0/1\">Jan Koco&#x144;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cichecki_I/0/1/0/all/0/1\">Igor Cichecki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaszyca_O/0/1/0/all/0/1\">Oliwier Kaszyca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kochanek_M/0/1/0/all/0/1\">Mateusz Kochanek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szydlo_D/0/1/0/all/0/1\">Dominika Szyd&#x142;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baran_J/0/1/0/all/0/1\">Joanna Baran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bielaniewicz_J/0/1/0/all/0/1\">Julita Bielaniewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gruza_M/0/1/0/all/0/1\">Marcin Gruza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janz_A/0/1/0/all/0/1\">Arkadiusz Janz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanclerz_K/0/1/0/all/0/1\">Kamil Kanclerz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kocon_A/0/1/0/all/0/1\">Anna Koco&#x144;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koptyra_B/0/1/0/all/0/1\">Bart&#x142;omiej Koptyra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mieleszczenko_Kowszewicz_W/0/1/0/all/0/1\">Wiktoria Mieleszczenko-Kowszewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milkowski_P/0/1/0/all/0/1\">Piotr Mi&#x142;kowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oleksy_M/0/1/0/all/0/1\">Marcin Oleksy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piasecki_M/0/1/0/all/0/1\">Maciej Piasecki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radlinski_L/0/1/0/all/0/1\">&#x141;ukasz Radli&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wojtasik_K/0/1/0/all/0/1\">Konrad Wojtasik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wozniak_S/0/1/0/all/0/1\">Stanis&#x142;aw Wo&#x17a;niak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazienko_P/0/1/0/all/0/1\">Przemys&#x142;aw Kazienko</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Robustness of Text Vectorizers. (arXiv:2303.07203v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.07203","description":"<p>A fundamental issue in machine learning is the robustness of the model with\nrespect to changes in the input. In natural language processing, models\ntypically contain a first embedding layer, transforming a sequence of tokens\ninto vector representations. While the robustness with respect to changes of\ncontinuous inputs is well-understood, the situation is less clear when\nconsidering discrete changes, for instance replacing a word by another in an\ninput sentence. Our work formally proves that popular embedding schemes, such\nas concatenation, TF-IDF, and Paragraph Vector (a.k.a. doc2vec), exhibit\nrobustness in the H\\\"older or Lipschitz sense with respect to the Hamming\ndistance. We provide quantitative bounds for these schemes and demonstrate how\nthe constants involved are affected by the length of the document. These\nfindings are exemplified through a series of numerical examples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Catellier_R/0/1/0/all/0/1\">R&#xe9;mi Catellier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaiter_S/0/1/0/all/0/1\">Samuel Vaiter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garreau_D/0/1/0/all/0/1\">Damien Garreau</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stop Words for Processing Software Engineering Documents: Do they Matter?. (arXiv:2303.10439v2 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2303.10439","description":"<p>Stop words, which are considered non-predictive, are often eliminated in\nnatural language processing tasks. However, the definition of uninformative\nvocabulary is vague, so most algorithms use general knowledge-based stop lists\nto remove stop words. There is an ongoing debate among academics about the\nusefulness of stop word elimination, especially in domain-specific settings. In\nthis work, we investigate the usefulness of stop word removal in a software\nengineering context. To do this, we replicate and experiment with three\nsoftware engineering research tools from related work. Additionally, we\nconstruct a corpus of software engineering domain-related text from 10,000\nStack Overflow questions and identify 200 domain-specific stop words using\ntraditional information-theoretic methods. Our results show that the use of\ndomain-specific stop words significantly improved the performance of research\ntools compared to the use of a general stop list and that 17 out of 19\nevaluation measures showed better performance.\n</p>\n<p>Online appendix: https://zenodo.org/record/7865748\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yaohou Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_C/0/1/0/all/0/1\">Chetan Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Treude_C/0/1/0/all/0/1\">Christoph Treude</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reflexion: Language Agents with Verbal Reinforcement Learning. (arXiv:2303.11366v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2303.11366","description":"<p>Large language models (LLMs) have been increasingly used to interact with\nexternal environments (e.g., games, compilers, APIs) as goal-driven agents.\nHowever, it remains challenging for these language agents to quickly and\nefficiently learn from trial-and-error as traditional reinforcement learning\nmethods require extensive training samples and expensive model fine-tuning. We\npropose Reflexion, a novel framework to reinforce language agents not by\nupdating weights, but instead through linguistic feedback. Concretely,\nReflexion agents verbally reflect on task feedback signals, then maintain their\nown reflective text in an episodic memory buffer to induce better\ndecision-making in subsequent trials. Reflexion is flexible enough to\nincorporate various types (scalar values or free-form language) and sources\n(external or internally simulated) of feedback signals, and obtains significant\nimprovements over a baseline agent across diverse tasks (sequential\ndecision-making, coding, language reasoning). For example, Reflexion achieves a\n91% pass@1 accuracy on the HumanEval coding benchmark, surpassing the previous\nstate-of-the-art GPT-4 that achieves 80%. We also conduct ablation and analysis\nstudies using different feedback signals, feedback incorporation methods, and\nagent types, and provide insights into how they affect performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shinn_N/0/1/0/all/0/1\">Noah Shinn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cassano_F/0/1/0/all/0/1\">Federico Cassano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labash_B/0/1/0/all/0/1\">Beck Labash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopinath_A/0/1/0/all/0/1\">Ashwin Gopinath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_S/0/1/0/all/0/1\">Shunyu Yao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SwissBERT: The Multilingual Language Model for Switzerland. (arXiv:2303.13310v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.13310","description":"<p>We present SwissBERT, a masked language model created specifically for\nprocessing Switzerland-related text. SwissBERT is a pre-trained model that we\nadapted to news articles written in the national languages of Switzerland --\nGerman, French, Italian, and Romansh. We evaluate SwissBERT on natural language\nunderstanding tasks related to Switzerland and find that it tends to outperform\nprevious models on these tasks, especially when processing contemporary news\nand/or Romansh Grischun. Since SwissBERT uses language adapters, it may be\nextended to Swiss German dialects in future work. The model and our open-source\ncode are publicly released at https://github.com/ZurichNLP/swissbert.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vamvas_J/0/1/0/all/0/1\">Jannis Vamvas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graen_J/0/1/0/all/0/1\">Johannes Gra&#xeb;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sennrich_R/0/1/0/all/0/1\">Rico Sennrich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Vax-Culture: A Dataset for Studying Vaccine Discourse on Twitter. (arXiv:2304.06858v3 [cs.SI] UPDATED)","link":"http://arxiv.org/abs/2304.06858","description":"<p>Vaccine hesitancy continues to be a main challenge for public health\nofficials during the COVID-19 pandemic. As this hesitancy undermines vaccine\ncampaigns, many researchers have sought to identify its root causes, finding\nthat the increasing volume of anti-vaccine misinformation on social media\nplatforms is a key element of this problem. We explored Twitter as a source of\nmisleading content with the goal of extracting overlapping cultural and\npolitical beliefs that motivate the spread of vaccine misinformation. To do\nthis, we have collected a data set of vaccine-related Tweets and annotated them\nwith the help of a team of annotators with a background in communications and\njournalism. Ultimately we hope this can lead to effective and targeted public\nhealth communication strategies for reaching individuals with anti-vaccine\nbeliefs. Moreover, this information helps with developing Machine Learning\nmodels to automatically detect vaccine misinformation posts and combat their\nnegative impacts. In this paper, we present Vax-Culture, a novel Twitter\nCOVID-19 dataset consisting of 6373 vaccine-related tweets accompanied by an\nextensive set of human-provided annotations including vaccine-hesitancy stance,\nindication of any misinformation in tweets, the entities criticized and\nsupported in each tweet and the communicated message of each tweet. Moreover,\nwe define five baseline tasks including four classification and one sequence\ngeneration tasks, and report the results of a set of recent transformer-based\nmodels for them. The dataset and code are publicly available at\nhttps://github.com/mrzarei5/Vax-Culture.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zarei_M/0/1/0/all/0/1\">Mohammad Reza Zarei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christensen_M/0/1/0/all/0/1\">Michael Christensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Everts_S/0/1/0/all/0/1\">Sarah Everts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komeili_M/0/1/0/all/0/1\">Majid Komeili</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved with Text. (arXiv:2304.06939v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2304.06939","description":"<p>In-context vision and language models like Flamingo support arbitrarily\ninterleaved sequences of images and text as input. This format not only enables\nfew-shot learning via interleaving independent supervised (image, text)\nexamples, but also, more complex prompts involving interaction between images,\ne.g., \"What do image A and image B have in common?\" To support this interface,\npretraining occurs over web corpora that similarly contain interleaved\nimages+text. To date, however, large-scale data of this form have not been\npublicly available.\n</p>\n<p>We release Multimodal C4, an augmentation of the popular text-only C4 corpus\nwith images interleaved. We use a linear assignment algorithm to place images\ninto longer bodies of text using CLIP features, a process that we show\noutperforms alternatives. Multimodal C4 spans everyday topics like cooking,\ntravel, technology, etc. A manual inspection of a random sample of documents\nshows that a vast majority (88%) of images are topically relevant, and that\nlinear assignment frequently selects individual sentences specifically\nwell-aligned with each image (80%). After filtering NSFW images, ads, etc., the\nresulting corpus consists of 101.2M documents with 571M images interleaved in\n43B English tokens.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wanrong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1\">Jack Hessel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadalla_A/0/1/0/all/0/1\">Anas Awadalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gadre_S/0/1/0/all/0/1\">Samir Yitzhak Gadre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodge_J/0/1/0/all/0/1\">Jesse Dodge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_A/0/1/0/all/0/1\">Alex Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Youngjae Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1\">Ludwig Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Instructed Reinforcement Learning for Human-AI Coordination. (arXiv:2304.07297v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2304.07297","description":"<p>One of the fundamental quests of AI is to produce agents that coordinate well\nwith humans. This problem is challenging, especially in domains that lack high\nquality human behavioral data, because multi-agent reinforcement learning (RL)\noften converges to different equilibria from the ones that humans prefer. We\npropose a novel framework, instructRL, that enables humans to specify what kind\nof strategies they expect from their AI partners through natural language\ninstructions. We use pretrained large language models to generate a prior\npolicy conditioned on the human instruction and use the prior to regularize the\nRL objective. This leads to the RL agent converging to equilibria that are\naligned with human preferences. We show that instructRL converges to human-like\npolicies that satisfy the given instructions in a proof-of-concept environment\nas well as the challenging Hanabi benchmark. Finally, we show that knowing the\nlanguage instruction significantly boosts human-AI coordination performance in\nhuman evaluations in Hanabi.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hengyuan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadigh_D/0/1/0/all/0/1\">Dorsa Sadigh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM as A Robotic Brain: Unifying Egocentric Memory and Control. (arXiv:2304.09349v4 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2304.09349","description":"<p>Embodied AI focuses on the study and development of intelligent systems that\npossess a physical or virtual embodiment (i.e. robots) and are able to\ndynamically interact with their environment. Memory and control are the two\nessential parts of an embodied system and usually require separate frameworks\nto model each of them. In this paper, we propose a novel and generalizable\nframework called LLM-Brain: using Large-scale Language Model as a robotic brain\nto unify egocentric memory and control. The LLM-Brain framework integrates\nmultiple multimodal language models for robotic tasks, utilizing a zero-shot\nlearning approach. All components within LLM-Brain communicate using natural\nlanguage in closed-loop multi-round dialogues that encompass perception,\nplanning, control, and memory. The core of the system is an embodied LLM to\nmaintain egocentric memory and control the robot. We demonstrate LLM-Brain by\nexamining two downstream tasks: active exploration and embodied question\nanswering. The active exploration tasks require the robot to extensively\nexplore an unknown environment within a limited number of actions. Meanwhile,\nthe embodied question answering tasks necessitate that the robot answers\nquestions based on observations acquired during prior explorations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mai_J/0/1/0/all/0/1\">Jinjie Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_G/0/1/0/all/0/1\">Guocheng Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhoseiny_M/0/1/0/all/0/1\">Mohamed Elhoseiny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1\">Bernard Ghanem</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"(Vector) Space is Not the Final Frontier: Product Search as Program Synthesis. (arXiv:2304.11473v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2304.11473","description":"<p>As ecommerce continues growing, huge investments in ML and NLP for\nInformation Retrieval are following. While the vector space model dominated\nretrieval modelling in product search - even as vectorization itself greatly\nchanged with the advent of deep learning -, our position paper argues in a\ncontrarian fashion that program synthesis provides significant advantages for\nmany queries and a significant number of players in the market. We detail the\nindustry significance of the proposed approach, sketch implementation details,\nand address common objections drawing from our experience building a similar\nsystem at Tooso.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tagliabue_J/0/1/0/all/0/1\">Jacopo Tagliabue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greco_C/0/1/0/all/0/1\">Ciro Greco</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WizardLM: Empowering Large Language Models to Follow Complex Instructions. (arXiv:2304.12244v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.12244","description":"<p>Training large language models (LLMs) with open-domain instruction following\ndata brings colossal success. However, manually creating such instruction data\nis very time-consuming and labor-intensive. Moreover, humans may struggle to\nproduce high-complexity instructions. In this paper, we show an avenue for\ncreating large amounts of instruction data with varying levels of complexity\nusing LLM instead of humans. Starting with an initial set of instructions, we\nuse our proposed Evol-Instruct to rewrite them step by step into more complex\ninstructions. Then, we mix all generated instruction data to fine-tune LLaMA.\nWe call the resulting model WizardLM. Human evaluations on a\ncomplexity-balanced test bed and Vicuna's testset show that instructions from\nEvol-Instruct are superior to human-created ones. By analyzing the human\nevaluation results of the high complexity part, we demonstrate that outputs\nfrom our WizardLM are preferred to outputs from OpenAI ChatGPT. In GPT-4\nautomatic evaluation, WizardLM achieves more than 90\\% capacity of ChatGPT on\n17 out of 29 skills. Even though WizardLM still lags behind ChatGPT in some\naspects, our findings suggest that fine-tuning with AI-evolved instructions is\na promising direction for enhancing LLMs. Our code and data are public at\nhttps://github.com/nlpxucan/WizardLM\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Can Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1\">Qingfeng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1\">Kai Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xiubo Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Pu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiazhan Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1\">Chongyang Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Daxin Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChartSumm: A Comprehensive Benchmark for Automatic Chart Summarization of Long and Short Summaries. (arXiv:2304.13620v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.13620","description":"<p>Automatic chart to text summarization is an effective tool for the visually\nimpaired people along with providing precise insights of tabular data in\nnatural language to the user. A large and well-structured dataset is always a\nkey part for data driven models. In this paper, we propose ChartSumm: a\nlarge-scale benchmark dataset consisting of a total of 84,363 charts along with\ntheir metadata and descriptions covering a wide range of topics and chart types\nto generate short and long summaries. Extensive experiments with strong\nbaseline models show that even though these models generate fluent and\ninformative summaries by achieving decent scores in various automatic\nevaluation metrics, they often face issues like suffering from hallucination,\nmissing out important data points, in addition to incorrect explanation of\ncomplex trends in the charts. We also investigated the potential of expanding\nChartSumm to other languages using automated translation tools. These make our\ndataset a challenging benchmark for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_R/0/1/0/all/0/1\">Raian Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_R/0/1/0/all/0/1\">Rizvi Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhad_A/0/1/0/all/0/1\">Abdullah Al Farhad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laskar_M/0/1/0/all/0/1\">Md Tahmid Rahman Laskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashmafee_M/0/1/0/all/0/1\">Md. Hamjajul Ashmafee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamal_A/0/1/0/all/0/1\">Abu Raihan Mostofa Kamal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation. (arXiv:2305.01210v2 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2305.01210","description":"<p>Program synthesis has been long studied with recent approaches focused on\ndirectly using the power of Large Language Models (LLMs) to generate code.\nProgramming benchmarks, with curated synthesis problems and test-cases, are\nused to measure the performance of various LLMs on code synthesis. However,\nthese test-cases can be limited in both quantity and quality for fully\nassessing the functional correctness of the generated code. Such limitation in\nthe existing benchmarks begs the following question: In the era of LLMs, is the\ncode generated really correct? To answer this, we propose EvalPlus -- a code\nsynthesis benchmarking framework to rigorously evaluate the functional\ncorrectness of LLM-synthesized code. EvalPlus augments a given evaluation\ndataset with large amounts of test-cases newly produced by an automatic test\ninput generator, powered by both LLM- and mutation-based strategies. While\nEvalPlus is general, we extend the test-cases of the popular HUMANEVAL\nbenchmark by 81x to build HUMANEVAL+. Our extensive evaluation across 19\npopular LLMs (e.g., GPT-4 and ChatGPT) demonstrates that HUMANEVAL+ is able to\ncatch significant amounts of previously undetected wrong code synthesized by\nLLMs, reducing the pass@k by 13.6-15.3% on average. Our work not only indicates\nthat prior popular code synthesis evaluation results do not accurately reflect\nthe true performance of LLMs for code synthesis, but also opens up a new\ndirection to improve such programming benchmarks through automated testing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiawei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1\">Chunqiu Steven Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lingming Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Causality-aware Concept Extraction based on Knowledge-guided Prompting. (arXiv:2305.01876v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.01876","description":"<p>Concepts benefit natural language understanding but are far from complete in\nexisting knowledge graphs (KGs). Recently, pre-trained language models (PLMs)\nhave been widely used in text-based concept extraction (CE). However, PLMs tend\nto mine the co-occurrence associations from massive corpus as pre-trained\nknowledge rather than the real causal effect between tokens. As a result, the\npre-trained knowledge confounds PLMs to extract biased concepts based on\nspurious co-occurrence correlations, inevitably resulting in low precision. In\nthis paper, through the lens of a Structural Causal Model (SCM), we propose\nequipping the PLM-based extractor with a knowledge-guided prompt as an\nintervention to alleviate concept bias. The prompt adopts the topic of the\ngiven entity from the existing knowledge in KGs to mitigate the spurious\nco-occurrence correlations between entities and biased concepts. Our extensive\nexperiments on representative multilingual KG datasets justify that our\nproposed prompt can effectively alleviate concept bias and improve the\nperformance of PLM-based CE models.The code has been released on\nhttps://github.com/siyuyuan/KPCE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1\">Siyu Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Deqing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinxi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1\">Shuyu Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jiaqing Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yanghua Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1\">Rui Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Statistical Exploration of Text Partition Into Constituents: The Case of the Priestly Source in the Books of Genesis and Exodus. (arXiv:2305.02170v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02170","description":"<p>We present a pipeline for a statistical textual exploration, offering a\nstylometry-based explanation and statistical validation of a hypothesized\npartition of a text. Given a parameterization of the text, our pipeline: (1)\ndetects literary features yielding the optimal overlap between the hypothesized\nand unsupervised partitions, (2) performs a hypothesis-testing analysis to\nquantify the statistical significance of the optimal overlap, while conserving\nimplicit correlations between units of text that are more likely to be grouped,\nand (3) extracts and quantifies the importance of features most responsible for\nthe classification, estimates their statistical stability and cluster-wise\nabundance.\n</p>\n<p>We apply our pipeline to the first two books in the Bible, where one\nstylistic component stands out in the eyes of biblical scholars, namely, the\nPriestly component. We identify and explore statistically significant stylistic\ndifferences between the Priestly and non-Priestly components.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yoffe_G/0/1/0/all/0/1\">Gideon Yoffe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buhler_A/0/1/0/all/0/1\">Axel B&#xfc;hler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dershowitz_N/0/1/0/all/0/1\">Nachum Dershowitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finkelstein_I/0/1/0/all/0/1\">Israel Finkelstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piasetzky_E/0/1/0/all/0/1\">Eli Piasetzky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romer_T/0/1/0/all/0/1\">Thomas R&#xf6;mer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sober_B/0/1/0/all/0/1\">Barak Sober</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language, Time Preferences, and Consumer Behavior: Evidence from Large Language Models. (arXiv:2305.02531v2 [econ.GN] UPDATED)","link":"http://arxiv.org/abs/2305.02531","description":"<p>Language has a strong influence on our perceptions of time and rewards. This\nraises the question of whether large language models, when asked in different\nlanguages, show different preferences for rewards over time and if their\nchoices are similar to those of humans. In this study, we analyze the responses\nof GPT-3.5 (hereafter referred to as GPT) to prompts in multiple languages,\nexploring preferences between smaller, sooner rewards and larger, later\nrewards. Our results show that GPT displays greater patience when prompted in\nlanguages with weak future tense references (FTR), such as German and Mandarin,\ncompared to languages with strong FTR, like English and French. These findings\nare consistent with existing literature and suggest a correlation between GPT's\nchoices and the preferences of speakers of these languages. However, further\nanalysis reveals that the preference for earlier or later rewards does not\nsystematically change with reward gaps, indicating a lexicographic preference\nfor earlier payments. While GPT may capture intriguing variations across\nlanguages, our findings indicate that the choices made by these models do not\ncorrespond to those of human decision-makers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/econ/1/au:+Goli_A/0/1/0/all/0/1\">Ali Goli</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Singh_A/0/1/0/all/0/1\">Amandeep Singh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MGR: Multi-generator Based Rationalization. (arXiv:2305.04492v6 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.04492","description":"<p>Rationalization is to employ a generator and a predictor to construct a\nself-explaining NLP model in which the generator selects a subset of\nhuman-intelligible pieces of the input text to the following predictor.\nHowever, rationalization suffers from two key challenges, i.e., spurious\ncorrelation and degeneration, where the predictor overfits the spurious or\nmeaningless pieces solely selected by the not-yet well-trained generator and in\nturn deteriorates the generator. Although many studies have been proposed to\naddress the two challenges, they are usually designed separately and do not\ntake both of them into account. In this paper, we propose a simple yet\neffective method named MGR to simultaneously solve the two problems. The key\nidea of MGR is to employ multiple generators such that the occurrence stability\nof real pieces is improved and more meaningful pieces are delivered to the\npredictor. Empirically, we show that MGR improves the F1 score by up to 20.9%\nas compared to state-of-the-art methods. Codes are available at\nhttps://github.com/jugechengzi/Rationalization-MGR .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haozhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruixuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xinyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuankai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yang Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models. (arXiv:2305.10276v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10276","description":"<p>In this paper, we take the initiative to investigate the performance of LLMs\non complex planning tasks that require LLMs to understand a virtual spatial\nenvironment simulated via natural language and act correspondingly in text. We\npropose a benchmark named Natural Language Planning and Action (Natala)\ncomposed of a set of novel tasks: Brick World, NLVR-based Manipulations, and\nNatural Language Navigation. We found that current popular LLMs such as ChatGPT\nstill lack abilities in complex planning. This arises a question -- do the LLMs\nhave a good understanding of the environments described in natural language, or\nmaybe other alternatives such as symbolic representations are neater and hence\nbetter to be understood by LLMs? To this end, we propose a novel method called\nCoS (Chain-of-Symbol Prompting) that represents the complex environments with\ncondensed symbolic spatial representations during the chained intermediate\nthinking steps. CoS is easy to use and does not need additional training on\nLLMs. Extensive experiments indicate that CoS clearly surpasses the performance\nof the Chain-of-Thought (CoT) Prompting in all three planning tasks with even\nfewer tokens used in the inputs compared with CoT on ChatGPT and InstructGPT.\nThe performance gain is strong, by up to 60.8% accuracy (from 31.8% to 92.6%)\non Brick World for ChatGPT. CoS also reduces the number of tokens in the prompt\nobviously, by up to 65.8% of the tokens (from 407 to 139) for the intermediate\nsteps from demonstrations on Brick World. Code and data available at:\nhttps://github.com/hanxuhu/chain-of-symbol-planning\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hanxu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hongyuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huajian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Prompt-based Question Answering for Object Prediction in the Open Research Knowledge Graph. (arXiv:2305.12900v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12900","description":"<p>There have been many recent investigations into prompt-based training of\ntransformer language models for new text genres in low-resource settings. The\nprompt-based training approach has been found to be effective in generalizing\npre-trained or fine-tuned models for transfer to resource-scarce settings. This\nwork, for the first time, reports results on adopting prompt-based training of\ntransformers for \\textit{scholarly knowledge graph object prediction}. The work\nis unique in the following two main aspects. 1) It deviates from the other\nworks proposing entity and relation extraction pipelines for predicting objects\nof a scholarly knowledge graph. 2) While other works have tested the method on\ntext genera relatively close to the general knowledge domain, we test the\nmethod for a significantly different domain, i.e. scholarly knowledge, in turn\ntesting the linguistic, probabilistic, and factual generalizability of these\nlarge-scale transformer models. We find that (i) per expectations, transformer\nmodels when tested out-of-the-box underperform on a new domain of data, (ii)\nprompt-based training of the models achieve performance boosts of up to 40\\% in\na relaxed evaluation setting, and (iii) testing the models on a starkly\ndifferent domain even with a clever training objective in a low resource\nsetting makes evident the domain knowledge capture gap offering an\nempirically-verified incentive for investing more attention and resources to\nthe scholarly domain in the context of transformer models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+DSouza_J/0/1/0/all/0/1\">Jennifer D&#x27;Souza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hrou_M/0/1/0/all/0/1\">Moussab Hrou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Auer_S/0/1/0/all/0/1\">S&#xf6;ren Auer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ambiguity Meets Uncertainty: Investigating Uncertainty Estimation for Word Sense Disambiguation. (arXiv:2305.13119v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13119","description":"<p>Word sense disambiguation (WSD), which aims to determine an appropriate sense\nfor a target word given its context, is crucial for natural language\nunderstanding. Existing supervised methods treat WSD as a classification task\nand have achieved remarkable performance. However, they ignore uncertainty\nestimation (UE) in the real-world setting, where the data is always noisy and\nout of distribution. This paper extensively studies UE on the benchmark\ndesigned for WSD. Specifically, we first compare four uncertainty scores for a\nstate-of-the-art WSD model and verify that the conventional predictive\nprobabilities obtained at the end of the model are inadequate to quantify\nuncertainty. Then, we examine the capability of capturing data and model\nuncertainties by the model with the selected UE score on well-designed test\nscenarios and discover that the model reflects data uncertainty satisfactorily\nbut underestimates model uncertainty. Furthermore, we explore numerous lexical\nproperties that intrinsically affect data uncertainty and provide a detailed\nanalysis of four critical aspects: the syntactic category, morphology, sense\ngranularity, and semantic relations. The code is available at\nhttps://github.com/RyanLiut/WSD-UE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Ying Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding Programs by Exploiting (Fuzzing) Test Cases. (arXiv:2305.13592v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.13592","description":"<p>Semantic understanding of programs has attracted great attention in the\ncommunity. Inspired by recent successes of large language models (LLMs) in\nnatural language understanding, tremendous progress has been made by treating\nprogramming language as another sort of natural language and training LLMs on\ncorpora of program code. However, programs are essentially different from texts\nafter all, in a sense that they are normally heavily structured and\nsyntax-strict. In particular, programs and their basic units (i.e., functions\nand subroutines) are designed to demonstrate a variety of behaviors and/or\nprovide possible outputs, given different inputs. The relationship between\ninputs and possible outputs/behaviors represents the functions/subroutines and\nprofiles the program as a whole. Therefore, we propose to incorporate such a\nrelationship into learning, for achieving a deeper semantic understanding of\nprograms. To obtain inputs that are representative enough to trigger the\nexecution of most part of the code, we resort to fuzz testing and propose fuzz\ntuning to boost the performance of program understanding and code\nrepresentation learning, given a pre-trained LLM. The effectiveness of the\nproposed method is verified on two program understanding tasks including code\nclone detection and code classification, and it outperforms current\nstate-of-the-arts by large margins. Code is available at\nhttps://github.com/rabbitjy/FuzzTuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jianyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1\">Yuyang Rong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yiwen Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yifeng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Grammatical Error Correction Systems with Explanations. (arXiv:2305.15676v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15676","description":"<p>Grammatical error correction systems improve written communication by\ndetecting and correcting language mistakes. To help language learners better\nunderstand why the GEC system makes a certain correction, the causes of errors\n(evidence words) and the corresponding error types are two key factors. To\nenhance GEC systems with explanations, we introduce EXPECT, a large dataset\nannotated with evidence words and grammatical error types. We propose several\nbaselines and analysis to understand this task. Furthermore, human evaluation\nverifies our explainable GEC system's explanations can assist second-language\nlearners in determining whether to accept a correction suggestion and in\nunderstanding the associated grammar rule.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fei_Y/0/1/0/all/0/1\">Yuejiao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Leyang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Sen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1\">Zhenzhong Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Surface-Based Retrieval Reduces Perplexity of Retrieval-Augmented Language Models. (arXiv:2305.16243v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.16243","description":"<p>Augmenting language models with a retrieval mechanism has been shown to\nsignificantly improve their performance while keeping the number of parameters\nlow. Retrieval-augmented models commonly rely on a semantic retrieval mechanism\nbased on the similarity between dense representations of the query chunk and\npotential neighbors. In this paper, we study the state-of-the-art Retro model\nand observe that its performance gain is better explained by surface-level\nsimilarities, such as token overlap. Inspired by this, we replace the semantic\nretrieval in Retro with a surface-level method based on BM25, obtaining a\nsignificant reduction in perplexity. As full BM25 retrieval can be\ncomputationally costly for large datasets, we also apply it in a re-ranking\nscenario, gaining part of the perplexity reduction with minimal computational\noverhead.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Doostmohammadi_E/0/1/0/all/0/1\">Ehsan Doostmohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norlund_T/0/1/0/all/0/1\">Tobias Norlund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuhlmann_M/0/1/0/all/0/1\">Marco Kuhlmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johansson_R/0/1/0/all/0/1\">Richard Johansson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Open-Domain Dialogues in Latent Space with Next Sentence Prediction and Mutual Information. (arXiv:2305.16967v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.16967","description":"<p>The long-standing one-to-many issue of the open-domain dialogues poses\nsignificant challenges for automatic evaluation methods, i.e., there may be\nmultiple suitable responses which differ in semantics for a given\nconversational context. To tackle this challenge, we propose a novel\nlearning-based automatic evaluation metric (CMN), which can robustly evaluate\nopen-domain dialogues by augmenting Conditional Variational Autoencoders\n(CVAEs) with a Next Sentence Prediction (NSP) objective and employing Mutual\nInformation (MI) to model the semantic similarity of text in the latent space.\nExperimental results on two open-domain dialogue datasets demonstrate the\nsuperiority of our method compared with a wide range of baselines, especially\nin handling responses which are distant to the golden reference responses in\nsemantics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1\">Kun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bohao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rong_W/0/1/0/all/0/1\">Wenge Rong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villavicencio_A/0/1/0/all/0/1\">Aline Villavicencio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_X/0/1/0/all/0/1\">Xiaohui Cui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Backdooring Neural Code Search. (arXiv:2305.17506v2 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2305.17506","description":"<p>Reusing off-the-shelf code snippets from online repositories is a common\npractice, which significantly enhances the productivity of software developers.\nTo find desired code snippets, developers resort to code search engines through\nnatural language queries. Neural code search models are hence behind many such\nengines. These models are based on deep learning and gain substantial attention\ndue to their impressive performance. However, the security aspect of these\nmodels is rarely studied. Particularly, an adversary can inject a backdoor in\nneural code search models, which return buggy or even vulnerable code with\nsecurity/privacy issues. This may impact the downstream software (e.g., stock\ntrading systems and autonomous driving) and cause financial loss and/or\nlife-threatening incidents. In this paper, we demonstrate such attacks are\nfeasible and can be quite stealthy. By simply modifying one variable/function\nname, the attacker can make buggy/vulnerable code rank in the top 11%. Our\nattack BADCODE features a special trigger generation and injection procedure,\nmaking the attack more effective and stealthy. The evaluation is conducted on\ntwo neural code search models and the results show our attack outperforms\nbaselines by 60%. Our user study demonstrates that our attack is more stealthy\nthan the baseline by two times based on the F1 score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Weisong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuchen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_G/0/1/0/all/0/1\">Guanhong Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_C/0/1/0/all/0/1\">Chunrong Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Quanjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1\">Bin Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"One Network, Many Masks: Towards More Parameter-Efficient Transfer Learning. (arXiv:2305.17682v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.17682","description":"<p>Fine-tuning pre-trained language models for multiple tasks tends to be\nexpensive in terms of storage. To mitigate this, parameter-efficient transfer\nlearning (PETL) methods have been proposed to address this issue, but they\nstill require a significant number of parameters and storage when being applied\nto broader ranges of tasks. To achieve even greater storage reduction, we\npropose PROPETL, a novel method that enables efficient sharing of a single PETL\nmodule which we call prototype network (e.g., adapter, LoRA, and prefix-tuning)\nacross layers and tasks. We then learn binary masks to select different\nsub-networks from the shared prototype network and apply them as PETL modules\ninto different layers. We find that the binary masks can determine crucial\ninformation from the network, which is often ignored in previous studies. Our\nwork can also be seen as a type of pruning method, where we find that\noverparameterization also exists in the seemingly small PETL modules. We\nevaluate PROPETL on various downstream tasks and show that it can outperform\nother PETL methods with approximately 10% of the parameter storage required by\nthe latter.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_G/0/1/0/all/0/1\">Guangtao Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Peiyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"W-procer: Weighted Prototypical Contrastive Learning for Medical Few-Shot Named Entity Recognition. (arXiv:2305.18624v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.18624","description":"<p>Contrastive learning has become a popular solution for few-shot Name Entity\nRecognization (NER). The conventional configuration strives to reduce the\ndistance between tokens with the same labels and increase the distance between\ntokens with different labels. The effect of this setup may, however, in the\nmedical domain, there are a lot of entities annotated as OUTSIDE (O), and they\nare undesirably pushed apart to other entities that are not labeled as OUTSIDE\n(O) by the current contrastive learning method end up with a noisy prototype\nfor the semantic representation of the label, though there are many OUTSIDE (O)\nlabeled entities are relevant to the labeled entities. To address this\nchallenge, we propose a novel method named Weighted Prototypical Contrastive\nLearning for Medical Few Shot Named Entity Recognization (W-PROCER). Our\napproach primarily revolves around constructing the prototype-based contractive\nloss and weighting network. These components play a crucial role in assisting\nthe model in differentiating the negative samples from OUTSIDE (O) tokens and\nenhancing the discrimination ability of contrastive learning. Experimental\nresults show that our proposed W-PROCER framework significantly outperforms the\nstrong baselines on the three medical benchmark datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingchen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yang Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_J/0/1/0/all/0/1\">Jeremy Yeung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Huixue Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_H/0/1/0/all/0/1\">Huaiyuan Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating Label Biases for In-context Learning. (arXiv:2305.19148v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.19148","description":"<p>Various design settings for in-context learning (ICL), such as the choice and\norder of the in-context examples, can bias a model toward a particular\nprediction without being reflective of an understanding of the task. While many\nstudies discuss these design choices, there have been few systematic\ninvestigations into categorizing them and mitigating their impact. In this\nwork, we define a typology for three types of label biases in ICL for text\nclassification: vanilla-label bias, context-label bias, and domain-label bias\n(which we conceptualize and detect for the first time).\n</p>\n<p>Our analysis demonstrates that prior label bias calibration methods fall\nshort of addressing all three types of biases. Specifically, domain-label bias\nrestricts LLMs to random-level performance on many tasks regardless of the\nchoice of in-context examples. To mitigate the effect of these biases, we\npropose a simple bias calibration method that estimates a language model's\nlabel bias using random in-domain words from the task corpus. After controlling\nfor this estimated bias when making predictions, our novel domain-context\ncalibration significantly improves the ICL performance of GPT-J and GPT-3 on a\nwide range of tasks. The gain is substantial on tasks with large domain-label\nbias (up to 37% in Macro-F1). Furthermore, our results generalize to models\nwith different scales, pretraining methods, and manually-designed task\ninstructions, showing the prevalence of label biases in ICL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fei_Y/0/1/0/all/0/1\">Yu Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yifan Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1\">Antoine Bosselut</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"infoVerse: A Universal Framework for Dataset Characterization with Multidimensional Meta-information. (arXiv:2305.19344v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.19344","description":"<p>The success of NLP systems often relies on the availability of large,\nhigh-quality datasets. However, not all samples in these datasets are equally\nvaluable for learning, as some may be redundant or noisy. Several methods for\ncharacterizing datasets based on model-driven meta-information (e.g., model's\nconfidence) have been developed, but the relationship and complementary effects\nof these methods have received less attention. In this paper, we introduce\ninfoVerse, a universal framework for dataset characterization, which provides a\nnew feature space that effectively captures multidimensional characteristics of\ndatasets by incorporating various model-driven meta-information. infoVerse\nreveals distinctive regions of the dataset that are not apparent in the\noriginal semantic space, hence guiding users (or models) in identifying which\nsamples to focus on for exploration, assessment, or annotation. Additionally,\nwe propose a novel sampling method on infoVerse to select a set of data points\nthat maximizes informativeness. In three real-world applications (data pruning,\nactive learning, and data annotation), the samples chosen on infoVerse space\nconsistently outperform strong baselines in all applications. Our code and demo\nare publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jaehyung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yekyung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langis_K/0/1/0/all/0/1\">Karin de Langis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jinwoo Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1\">Dongyeop Kang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-grained Text Style Transfer with Diffusion-Based Language Models. (arXiv:2305.19512v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.19512","description":"<p>Diffusion probabilistic models have shown great success in generating\nhigh-quality images controllably, and researchers have tried to utilize this\ncontrollability into text generation domain. Previous works on diffusion-based\nlanguage models have shown that they can be trained without external knowledge\n(such as pre-trained weights) and still achieve stable performance and\ncontrollability. In this paper, we trained a diffusion-based model on StylePTB\ndataset, the standard benchmark for fine-grained text style transfers. The\ntasks in StylePTB requires much more refined control over the output text\ncompared to tasks evaluated in previous works, and our model was able to\nachieve state-of-the-art performance on StylePTB on both individual and\ncompositional transfers. Moreover, our model, trained on limited data from\nStylePTB without external knowledge, outperforms previous works that utilized\npretrained weights, embeddings, and external grammar parsers, and this may\nindicate that diffusion-based language models have great potential under\nlow-resource settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_Y/0/1/0/all/0/1\">Yiwei Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1\">Tiange Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiacheng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hollon_T/0/1/0/all/0/1\">Todd C. Hollon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Honglak Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DC CoMix TTS: An End-to-End Expressive TTS with Discrete Code Collaborated with Mixer. (arXiv:2305.19567v3 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2305.19567","description":"<p>Despite the huge successes made in neutral TTS, content-leakage remains a\nchallenge. In this paper, we propose a new input representation and simple\narchitecture to achieve improved prosody modeling. Inspired by the recent\nsuccess in the use of discrete code in TTS, we introduce discrete code to the\ninput of the reference encoder. Specifically, we leverage the vector quantizer\nfrom the audio compression model to exploit the diverse acoustic information it\nhas already been trained on. In addition, we apply the modified MLP-Mixer to\nthe reference encoder, making the architecture lighter. As a result, we train\nthe prosody transfer TTS in an end-to-end manner. We prove the effectiveness of\nour method through both subjective and objective evaluations. We demonstrate\nthat the reference encoder learns better speaker-independent prosody when\ndiscrete code is utilized as input in the experiments. In addition, we obtain\ncomparable results even when fewer parameters are inputted.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yerin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koo_M/0/1/0/all/0/1\">Myoung-Wan Koo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Augmentation Approaches for Source Code Models: A Survey. (arXiv:2305.19915v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.19915","description":"<p>The increasingly popular adoption of source code in many critical tasks\nmotivates the development of data augmentation (DA) techniques to enhance\ntraining data and improve various capabilities (e.g., robustness and\ngeneralizability) of these models. Although a series of DA methods have been\nproposed and tailored for source code models, there lacks a comprehensive\nsurvey and examination to understand their effectiveness and implications. This\npaper fills this gap by conducting a comprehensive and integrative survey of\ndata augmentation for source code, wherein we systematically compile and\nencapsulate existing literature to provide a comprehensive overview of the\nfield. We start by constructing a taxonomy of DA for source code models model\napproaches, followed by a discussion on prominent, methodologically\nillustrative approaches. Next, we highlight the general strategies and\ntechniques to optimize the DA quality. Subsequently, we underscore techniques\nthat find utility in widely-accepted source code scenarios and downstream\ntasks. Finally, we outline the prevailing challenges and potential\nopportunities for future research. In essence, this paper endeavors to\ndemystify the corpus of existing literature on DA for source code models, and\nfoster further exploration in this sphere. Complementing this, we present a\ncontinually updated GitHub repository that hosts a list of update-to-date\npapers on DA for source code models, accessible at\n\\url{https://github.com/terryyz/DataAug4Code}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_T/0/1/0/all/0/1\">Terry Yue Zhuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhou Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhensu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yufei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Li Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1\">Xiaoning Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1\">Zhenchang Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_D/0/1/0/all/0/1\">David Lo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Focused Prefix Tuning for Controllable Text Generation. (arXiv:2306.00369v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.00369","description":"<p>In a controllable text generation dataset, there exist unannotated attributes\nthat could provide irrelevant learning signals to models that use it for\ntraining and thus degrade their performance. We propose focused prefix\ntuning(FPT) to mitigate the problem and to enable the control to focus on the\ndesired attribute. Experimental results show that FPT can achieve better\ncontrol accuracy and text fluency than baseline models in single-attribute\ncontrol tasks. In multi-attribute control tasks, FPT achieves comparable\ncontrol accuracy with the state-of-the-art approach while keeping the\nflexibility to control new attributes without retraining existing models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Congda Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tianyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shing_M/0/1/0/all/0/1\">Makoto Shing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sawada_K/0/1/0/all/0/1\">Kei Sawada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okumura_M/0/1/0/all/0/1\">Manabu Okumura</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Make Your Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning. (arXiv:2306.00477v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.00477","description":"<p>Parameter-efficient fine-tuning (PEFT) of pre-trained language models (PLMs)\nhas emerged as a highly successful approach, with training only a small number\nof parameters without sacrificing performance and becoming the de-facto\nlearning paradigm with the increasing size of PLMs. However, existing PEFT\nmethods are not memory-efficient, because they still require caching most of\nthe intermediate activations for the gradient calculation, akin to fine-tuning.\nOne effective way to reduce the activation memory is to apply a reversible\nmodel, so the intermediate activations are not necessary to be cached and can\nbe recomputed. Nevertheless, modifying a PLM to its reversible variant with\nPEFT is not straightforward, since the reversible model has a distinct\narchitecture from the currently released PLMs. In this paper, we first\ninvestigate what is a key factor for the success of existing PEFT methods, and\nrealize that it's essential to preserve the PLM's starting point when\ninitializing a PEFT method. With this finding, we propose memory-efficient\nfine-tuning (MEFT) that inserts adapters into a PLM, preserving the PLM's\nstarting point and making it reversible without additional pre-training. We\nevaluate MEFT on the GLUE benchmark and five question-answering tasks with\nvarious backbones, BERT, RoBERTa, BART and OPT. MEFT significantly reduces the\nactivation memory up to 84% of full fine-tuning with a negligible amount of\ntrainable parameters. Moreover, MEFT achieves the same score on GLUE and a\ncomparable score on the question-answering tasks as full fine-tuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liao_B/0/1/0/all/0/1\">Baohao Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Shaomu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monz_C/0/1/0/all/0/1\">Christof Monz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Benchmarking Robustness of Adaptation Methods on Pre-trained Vision-Language Models. (arXiv:2306.02080v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2306.02080","description":"<p>Various adaptation methods, such as LoRA, prompts, and adapters, have been\nproposed to enhance the performance of pre-trained vision-language models in\nspecific domains. The robustness of these adaptation methods against\ndistribution shifts have not been studied. In this study, we assess the\nrobustness of 11 widely-used adaptation methods across 4 vision-language\ndatasets under multimodal corruptions. Concretely, we introduce 7 benchmark\ndatasets, including 96 visual and 87 textual corruptions, to investigate the\nrobustness of different adaptation methods, the impact of available adaptation\nexamples, and the influence of trainable parameter size during adaptation. Our\nanalysis reveals that: 1) Adaptation methods are more sensitive to text\ncorruptions than visual corruptions. 2) Full fine-tuning does not consistently\nprovide the highest robustness; instead, adapters can achieve better robustness\nwith comparable clean performance. 3) Contrary to expectations, our findings\nindicate that increasing the number of adaptation data and parameters does not\nguarantee enhanced robustness; instead it results in even lower robustness. We\nhope this study could benefit future research in the development of robust\nmultimodal adaptation methods. The benchmark, code, and dataset used in this\nstudy can be accessed at https://adarobustness.github.io .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jindong Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zhen Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yunpu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1\">Volker Tresp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evolution of Efficient Symbolic Communication Codes. (arXiv:2306.02383v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.02383","description":"<p>The paper explores how the human natural language structure can be seen as a\nproduct of evolution of inter-personal communication code, targeting\nmaximisation of such culture-agnostic and cross-lingual metrics such as\nanti-entropy, compression factor and cross-split F1 score. The exploration is\ndone as part of a larger unsupervised language learning effort, the attempt is\nmade to perform meta-learning in a space of hyper-parameters maximising F1\nscore based on the \"ground truth\" language structure, by means of maximising\nthe metrics mentioned above. The paper presents preliminary results of\ncross-lingual word-level segmentation tokenisation study for Russian, Chinese\nand English as well as subword segmentation or morphological parsing study for\nEnglish. It is found that language structure form the word-level segmentation\nor tokenisation can be found as driven by all of these metrics, anti-entropy\nbeing more relevant to English and Russian while compression factor more\nspecific for Chinese. The study for subword segmentation or morphological\nparsing on English lexicon has revealed straight connection between the\ncompression been found to be associated with compression factor, while,\nsurprising, the same connection with anti-entropy has turned to be the inverse.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kolonin_A/0/1/0/all/0/1\">Anton Kolonin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion. (arXiv:2306.02561v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.02561","description":"<p>We present LLM-Blender, an ensembling framework designed to attain\nconsistently superior performance by leveraging the diverse strengths of\nmultiple open-source large language models (LLMs). Our framework consists of\ntwo modules: PairRanker and GenFuser, addressing the observation that optimal\nLLMs for different examples can significantly vary. PairRanker employs a\nspecialized pairwise comparison method to distinguish subtle differences\nbetween candidate outputs. It jointly encodes the input text and a pair of\ncandidates, using cross-attention encoders to determine the superior one. Our\nresults demonstrate that PairRanker exhibits the highest correlation with\nChatGPT-based ranking. Then, GenFuser aims to merge the top-ranked candidates,\ngenerating an improved output by capitalizing on their strengths and mitigating\ntheir weaknesses. To facilitate large-scale evaluation, we introduce a\nbenchmark dataset, MixInstruct, which is a mixture of multiple instruction\ndatasets featuring oracle pairwise comparisons. Our LLM-Blender significantly\noutperform individual LLMs and baseline methods across various metrics,\nestablishing a substantial performance gap.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Dongfu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding. (arXiv:2306.02858v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.02858","description":"<p>We present Video-LLaMA, a multi-modal framework that empowers Large Language\nModels (LLMs) with the capability of understanding both visual and auditory\ncontent in the video. Video-LLaMA bootstraps cross-modal training from the\nfrozen pre-trained visual &amp; audio encoders and the frozen LLMs. Unlike previous\nvision-LLMs that focus on static image comprehensions such as MiniGPT-4 and\nLLaVA, Video-LLaMA mainly tackles two challenges in video understanding: (1)\ncapturing the temporal changes in visual scenes, (2) integrating audio-visual\nsignals. To counter the first challenge, we propose a Video Q-former to\nassemble the pre-trained image encoder into our video encoder and introduce a\nvideo-to-text generation task to learn video-language correspondence. For the\nsecond challenge, we leverage ImageBind, a universal embedding model aligning\nmultiple modalities as the pre-trained audio encoder, and introduce an Audio\nQ-former on top of ImageBind to learn reasonable auditory query embeddings for\nthe LLM module. To align the output of both visual &amp; audio encoders with LLM's\nembedding space, we train Video-LLaMA on massive video/image-caption pairs as\nwell as visual-instruction-tuning datasets of moderate amount but higher\nquality. We found Video-LLaMA showcases the ability to perceive and comprehend\nvideo content, generating meaningful responses that are grounded in the visual\nand auditory information presented in the videos. This highlights the potential\nof Video-LLaMA as a promising prototype for audio-visual AI assistants.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Applying Standards to Advance Upstream & Downstream Ethics in Large Language Models. (arXiv:2306.03503v2 [cs.CY] UPDATED)","link":"http://arxiv.org/abs/2306.03503","description":"<p>This paper explores how AI-owners can develop safeguards for AI-generated\ncontent by drawing from established codes of conduct and ethical standards in\nother content-creation industries. It delves into the current state of ethical\nawareness on Large Language Models (LLMs). By dissecting the mechanism of\ncontent generation by LLMs, four key areas (upstream/downstream and at user\nprompt/answer), where safeguards could be effectively applied, are identified.\nA comparative analysis of these four areas follows and includes an evaluation\nof the existing ethical safeguards in terms of cost, effectiveness, and\nalignment with established industry practices. The paper's key argument is that\nexisting IT-related ethical codes, while adequate for traditional IT\nengineering, are inadequate for the challenges posed by LLM-based content\ngeneration. Drawing from established practices within journalism, we propose\npotential standards for businesses involved in distributing and selling\nLLM-generated content. Finally, potential conflicts of interest between dataset\ncuration at upstream and ethical benchmarking downstream are highlighted to\nunderscore the need for a broader evaluation beyond mere output. This study\nprompts a nuanced conversation around ethical implications in this rapidly\nevolving field of content generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Berengueres_J/0/1/0/all/0/1\">Jose Berengueres</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandell_M/0/1/0/all/0/1\">Marybeth Sandell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating the Effectiveness of Natural Language Inference for Hate Speech Detection in Languages with Limited Labeled Data. (arXiv:2306.03722v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.03722","description":"<p>Most research on hate speech detection has focused on English where a\nsizeable amount of labeled training data is available. However, to expand hate\nspeech detection into more languages, approaches that require minimal training\ndata are needed. In this paper, we test whether natural language inference\n(NLI) models which perform well in zero- and few-shot settings can benefit hate\nspeech detection performance in scenarios where only a limited amount of\nlabeled data is available in the target language. Our evaluation on five\nlanguages demonstrates large performance improvements of NLI fine-tuning over\ndirect fine-tuning in the target language. However, the effectiveness of\nprevious work that proposed intermediate fine-tuning on English data is hard to\nmatch. Only in settings where the English training data does not match the test\ndomain, can our customised NLI-formulation outperform intermediate fine-tuning\non English. Based on our extensive experiments, we propose a set of\nrecommendations for hate speech detection in languages where minimal labeled\ntraining data is available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Goldzycher_J/0/1/0/all/0/1\">Janis Goldzycher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preisig_M/0/1/0/all/0/1\">Moritz Preisig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amrhein_C/0/1/0/all/0/1\">Chantal Amrhein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_G/0/1/0/all/0/1\">Gerold Schneider</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ECQED: Emotion-Cause Quadruple Extraction in Dialogs. (arXiv:2306.03969v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.03969","description":"<p>The existing emotion-cause pair extraction (ECPE) task, unfortunately,\nignores extracting the emotion type and cause type, while these fine-grained\nmeta-information can be practically useful in real-world applications, i.e.,\nchat robots and empathic dialog generation. Also the current ECPE is limited to\nthe scenario of single text piece, while neglecting the studies at dialog level\nthat should have more realistic values. In this paper, we extend the ECPE task\nwith a broader definition and scenario, presenting a new task, Emotion-Cause\nQuadruple Extraction in Dialogs (ECQED), which requires detecting emotion-cause\nutterance pairs and emotion and cause types. We present an ECQED model based on\na structural and semantic heterogeneous graph as well as a parallel grid\ntagging scheme, which advances in effectively incorporating the dialog context\nstructure, meanwhile solving the challenging overlapped quadruple issue. Via\nexperiments we show that introducing the fine-grained emotion and cause\nfeatures evidently helps better dialog generation. Also our proposed ECQED\nsystem shows exceptional superiority over baselines on both the emotion-cause\nquadruple or pair extraction tasks, meanwhile being highly efficient.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Li Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_D/0/1/0/all/0/1\">Donghong Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Fei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shengqiong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jingye Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bobo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_C/0/1/0/all/0/1\">Chong Teng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TKDP: Threefold Knowledge-enriched Deep Prompt Tuning for Few-shot Named Entity Recognition. (arXiv:2306.03974v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.03974","description":"<p>Few-shot named entity recognition (NER) exploits limited annotated instances\nto identify named mentions. Effectively transferring the internal or external\nresources thus becomes the key to few-shot NER. While the existing prompt\ntuning methods have shown remarkable few-shot performances, they still fail to\nmake full use of knowledge. In this work, we investigate the integration of\nrich knowledge to prompt tuning for stronger few-shot NER. We propose\nincorporating the deep prompt tuning framework with threefold knowledge (namely\nTKDP), including the internal 1) context knowledge and the external 2) label\nknowledge &amp; 3) sememe knowledge. TKDP encodes the three feature sources and\nincorporates them into the soft prompt embeddings, which are further injected\ninto an existing pre-trained language model to facilitate predictions. On five\nbenchmark datasets, our knowledge-enriched model boosts by at most 11.53% F1\nover the raw deep prompt method, and significantly outperforms 8\nstrong-performing baseline systems in 5-/10-/20-shot settings, showing great\npotential in few-shot NER. Our TKDP can be broadly adapted to other few-shot\ntasks without effort.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Fei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jingye Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bobo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Liang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_C/0/1/0/all/0/1\">Chong Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_D/0/1/0/all/0/1\">Donghong Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revisiting Conversation Discourse for Dialogue Disentanglement. (arXiv:2306.03975v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.03975","description":"<p>Dialogue disentanglement aims to detach the chronologically ordered\nutterances into several independent sessions. Conversation utterances are\nessentially organized and described by the underlying discourse, and thus\ndialogue disentanglement requires the full understanding and harnessing of the\nintrinsic discourse attribute. In this paper, we propose enhancing dialogue\ndisentanglement by taking full advantage of the dialogue discourse\ncharacteristics. First of all, in feature encoding stage, we construct the\nheterogeneous graph representations to model the various dialogue-specific\ndiscourse structural features, including the static speaker-role structures\n(i.e., speaker-utterance and speaker-mentioning structure) and the dynamic\ncontextual structures (i.e., the utterance-distance and partial-replying\nstructure). We then develop a structure-aware framework to integrate the rich\nstructural features for better modeling the conversational semantic context.\nSecond, in model learning stage, we perform optimization with a hierarchical\nranking loss mechanism, which groups dialogue utterances into different\ndiscourse levels and carries training covering pair-wise and session-wise\nlevels hierarchically. Third, in inference stage, we devise an easy-first\ndecoding algorithm, which performs utterance pairing under the easy-to-hard\nmanner with a global context, breaking the constraint of traditional sequential\ndecoding order. On two benchmark datasets, our overall system achieves new\nstate-of-the-art performances on all evaluations. In-depth analyses further\ndemonstrate the efficacy of each proposed idea and also reveal how our methods\nhelp advance the task. Our work has great potential to facilitate broader\nmulti-party multi-thread dialogue applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bobo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Fei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shengqiong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_L/0/1/0/all/0/1\">Lizi Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yinwei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_D/0/1/0/all/0/1\">Donghong Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems. (arXiv:2306.04357v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.04357","description":"<p>Dialogue response selection aims to select an appropriate response from\nseveral candidates based on a given user and system utterance history. Recent\nstudies have been improving the accuracy of dialogue response selection through\npost-training, mostly relying on naive masked language modeling methods.\nHowever, the recently developed generative methods have shown promising text\nrepresentation capabilities in IR community, which could potentially lead to\nbetter dialogue semantics modeling. Thus, in this paper, we propose Dial-MAE\n(Dialogue Contextual Masking Auto-encoder), a straightforward yet effective\npost-training technique tailored for dialogue response selection. Dial-MAE uses\nan asymmetric encoder-decoder architecture that learns to better compress the\nsemantics of the dialogue into dialogue-dense vectors. The process of Dial-MAE\ninvolves a deep encoder creating a dialogue embedding with the masked dialogue\ncontext, followed by a shallow decoder that uses this embedding along with the\nhighly masked response to restore the original response. Our experiments have\ndemonstrated that Dial-MAE is highly effective, achieving state-of-the-art\nperformance on two commonly evaluated benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1\">Zhenpeng Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xing Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_G/0/1/0/all/0/1\">Guangyuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Songlin Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large Language Models. (arXiv:2306.04757v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.04757","description":"<p>Instruction-tuned large language models have revolutionized natural language\nprocessing and have shown great potential in applications such as\nconversational agents. These models, such as GPT-4, can not only master\nlanguage but also solve complex tasks in areas like mathematics, coding,\nmedicine, and law. Despite their impressive capabilities, there is still a lack\nof comprehensive understanding regarding their full potential, primarily due to\nthe black-box nature of many models and the absence of holistic evaluation\nstudies. To address these challenges, we present INSTRUCTEVAL, a more\ncomprehensive evaluation suite designed specifically for instruction-tuned\nlarge language models. Unlike previous works, our evaluation involves a\nrigorous assessment of models based on problem-solving, writing ability, and\nalignment to human values. We take a holistic approach to analyze various\nfactors affecting model performance, including the pretraining foundation,\ninstruction-tuning data, and training methods. Our findings reveal that the\nquality of instruction data is the most crucial factor in scaling model\nperformance. While open-source models demonstrate impressive writing abilities,\nthere is substantial room for improvement in problem-solving and alignment. We\nare encouraged by the rapid development of models by the open-source community,\nbut we also highlight the need for rigorous evaluation to support claims made\nabout these models. Through INSTRUCTEVAL, we aim to foster a deeper\nunderstanding of instruction-tuned models and advancements in their\ncapabilities. INSTRUCTEVAL is publicly available at\nhttps://github.com/declare-lab/instruct-eval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chia_Y/0/1/0/all/0/1\">Yew Ken Chia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_P/0/1/0/all/0/1\">Pengfei Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1\">Soujanya Poria</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-06-12T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","content":"http://purl.org/rss/1.0/modules/content/"}}]}]}