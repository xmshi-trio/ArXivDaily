{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-12-12T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Lyrics: Boosting Fine-grained Language-Vision Alignment and Comprehension via Semantic-aware Visual Objects. (arXiv:2312.05278v1 [cs.CL])","link":"http://arxiv.org/abs/2312.05278","description":"<p>Large Vision Language Models (LVLMs) have demonstrated impressive zero-shot\ncapabilities in various vision-language dialogue scenarios. However, the\nabsence of fine-grained visual object detection hinders the model from\nunderstanding the details of images, leading to irreparable visual\nhallucinations and factual errors. In this paper, we propose Lyrics, a novel\nmulti-modal pre-training and instruction fine-tuning paradigm that bootstraps\nvision-language alignment from fine-grained cross-modal collaboration. Building\non the foundation of BLIP-2, Lyrics infuses local visual features extracted\nfrom a visual refiner that includes image tagging, object detection and\nsemantic segmentation modules into the Querying Transformer, while on the text\nside, the language inputs equip the boundary boxes and tags derived from the\nvisual refiner. We further introduce a two-stage training scheme, in which the\npre-training stage bridges the modality gap through explicit and comprehensive\nvision-language alignment targets. During the instruction fine-tuning stage, we\nintroduce semantic-aware visual feature extraction, a crucial method that\nenables the model to extract informative features from concrete visual objects.\nOur approach achieves strong performance on 13 held-out datasets across various\nvision-language tasks, and demonstrates promising multi-modal understanding and\ndetailed depiction capabilities in real dialogue scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Junyu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_R/0/1/0/all/0/1\">Ruyi Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dixiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaojun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Ziwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Renliang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaxing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pingjian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yan Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GlitchBench: Can large multimodal models detect video game glitches?. (arXiv:2312.05291v1 [cs.CV])","link":"http://arxiv.org/abs/2312.05291","description":"<p>Large multimodal models (LMMs) have evolved from large language models (LLMs)\nto integrate multiple input modalities, such as visual inputs. This integration\naugments the capacity of LLMs for tasks requiring visual comprehension and\nreasoning. However, the extent and limitations of their enhanced abilities are\nnot fully understood, especially when it comes to real-world tasks. To address\nthis gap, we introduce GlitchBench, a novel benchmark derived from video game\nquality assurance tasks, to test and evaluate the reasoning capabilities of\nLMMs. Our benchmark is curated from a variety of unusual and glitched scenarios\nfrom video games and aims to challenge both the visual and linguistic reasoning\npowers of LMMs in detecting and interpreting out-of-the-ordinary events. We\nevaluate multiple state-of-the-art LMMs, and we show that GlitchBench presents\na new challenge for these models. Code and data are available at:\nhttps://glitchbench.github.io/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Taesiri_M/0/1/0/all/0/1\">Mohammad Reza Taesiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_T/0/1/0/all/0/1\">Tianjun Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bezemer_C/0/1/0/all/0/1\">Cor-Paul Bezemer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anh Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Neuron Patching: Neuron-level Model Editing on Code Generation and LLMs. (arXiv:2312.05356v1 [cs.SE])","link":"http://arxiv.org/abs/2312.05356","description":"<p>Large Language Models are successfully adopted in software engineering,\nespecially in code generation. Updating these models with new knowledge is very\nexpensive, and is often required to fully realize their value. In this paper,\nwe propose a novel and effective model editing approach, \\textsc{MENT}, to\npatch LLMs in coding tasks. Based on the mechanism of generative LLMs,\n\\textsc{MENT} enables model editing in next-token predictions, and further\nsupports common coding tasks. \\textsc{MENT} is effective, efficient, and\nreliable. It can correct a neural model by patching 1 or 2 neurons. As the\npioneer work on neuron-level model editing of generative models, we formalize\nthe editing process and introduce the involved concepts. Besides, we also\nintroduce new measures to evaluate its generalization ability, and build a\nbenchmark for further study. Our approach is evaluated on three coding tasks,\nincluding API-seq recommendation, line-level code generation, and\npseudocode-to-code transaction. It outperforms the state-of-the-art by a\nsignificant margin on both effectiveness and efficiency measures. In addition,\nwe demonstrate the usages of \\textsc{MENT} for LLM reasoning in software\nengineering. By editing the LLM knowledge with \\textsc{MENT}, the directly or\nindirectly dependent behaviors in the chain-of-thought change accordingly and\nautomatically.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jian Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chunyang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aleti_A/0/1/0/all/0/1\">Aldeida Aleti</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Controlled Table-to-Text Generation with Scientific Reasoning. (arXiv:2312.05402v1 [cs.CL])","link":"http://arxiv.org/abs/2312.05402","description":"<p>The sheer volume of scientific experimental results and complex technical\nstatements, often presented in tabular formats, presents a formidable barrier\nto individuals acquiring preferred information. The realms of scientific\nreasoning and content generation that adhere to user preferences encounter\ndistinct challenges. In this work, we present a new task for generating fluent\nand logical descriptions that match user preferences over scientific tabular\ndata, aiming to automate scientific document analysis. To facilitate research\nin this direction, we construct a new challenging dataset CTRLSciTab consisting\nof table-description pairs extracted from the scientific literature, with\nhighlighted cells and corresponding domain-specific knowledge base. We\nevaluated popular pre-trained language models to establish a baseline and\nproposed a novel architecture outperforming competing approaches. The results\nshowed that large models struggle to produce accurate content that aligns with\nuser preferences. As the first of its kind, our work should motivate further\nresearch in scientific domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhixin Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jianping Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Jiexing Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Mingxuan Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Ziwei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guanjie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouhan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinbing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chenghu Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Experimental Study: Assessing the Combined Framework of WavLM and BEST-RQ for Text-to-Speech Synthesis. (arXiv:2312.05415v1 [cs.SD])","link":"http://arxiv.org/abs/2312.05415","description":"<p>We propose a new model architecture specifically suited for text-to-speech\n(TTS) models. We combine WavLM, a pre-trained self-supervised learning (SSL)\nspeech model, and the BEST-RQ vector quantization framework. We assess the\nextent to which the more task-agnostic WavLM, coupled with the superior\nsuitability of the simplistic BEST-RQ framework for a wider array of downstream\ntasks, yields favorable outcomes. Experiments on the LibriSpeech dataset with\nSUPERB benchmarking assert that the proposed model significantly underperforms.\nWe speculate the underlying reason for this performance is related to the\ndifference between featurizing raw audio waveforms and spectrograms with a\nquantizer. We discuss the limitations of this approach to better guide future\nadvancements in TTS.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nielson_V/0/1/0/all/0/1\">Via Nielson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hillis_S/0/1/0/all/0/1\">Steven Hillis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning Distilled from Large Language Models. (arXiv:2312.05434v1 [cs.CL])","link":"http://arxiv.org/abs/2312.05434","description":"<p>The age of social media is rife with memes. Understanding and detecting\nharmful memes pose a significant challenge due to their implicit meaning that\nis not explicitly conveyed through the surface text and image. However,\nexisting harmful meme detection approaches only recognize superficial\nharm-indicative signals in an end-to-end classification manner but ignore\nin-depth cognition of the meme text and image. In this paper, we attempt to\ndetect harmful memes based on advanced reasoning over the interplay of\nmultimodal information in memes. Inspired by the success of Large Language\nModels (LLMs) on complex reasoning, we first conduct abductive reasoning with\nLLMs. Then we propose a novel generative framework to learn reasonable thoughts\nfrom LLMs for better multimodal fusion and lightweight fine-tuning, which\nconsists of two training stages: 1) Distill multimodal reasoning knowledge from\nLLMs; and 2) Fine-tune the generative framework to infer harmfulness. Extensive\nexperiments conducted on three meme datasets demonstrate that our proposed\napproach achieves superior performance than state-of-the-art methods on the\nharmful meme detection task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongzhan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Ziyang Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Long Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Robustness of Foundation Model Representations under Provenance-related Distribution Shifts. (arXiv:2312.05435v1 [cs.CL])","link":"http://arxiv.org/abs/2312.05435","description":"<p>Foundation models are a current focus of attention in both industry and\nacademia. While they have shown their capabilities in a variety of tasks,\nin-depth research is required to determine their robustness to distribution\nshift when used as a basis for supervised machine learning. This is especially\nimportant in the context of clinical data, with particular limitations related\nto data accessibility, lack of pretraining materials, and limited availability\nof high-quality annotations. In this work, we examine the stability of models\nbased on representations from foundation models under distribution shift. We\nfocus on confounding by provenance, a form of distribution shift that emerges\nin the context of multi-institutional datasets when there are differences in\nsource-specific language use and class distributions. Using a sampling strategy\nthat synthetically induces varying degrees of distribution shift, we evaluate\nthe extent to which representations from foundation models result in\npredictions that are inherently robust to confounding by provenance.\nAdditionally, we examine the effectiveness of a straightforward confounding\nadjustment method inspired by Pearl's conception of backdoor adjustment.\nResults indicate that while foundation models do show some out-of-the-box\nrobustness to confounding-by-provenance related distribution shifts, this can\nbe considerably improved through adjustment. These findings suggest a need for\ndeliberate adjustment of predictive models using representations from\nfoundation models in the context of source-specific distributional differences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xiruo Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_Z/0/1/0/all/0/1\">Zhecheng Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hur_B/0/1/0/all/0/1\">Brian Hur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pakhomov_S/0/1/0/all/0/1\">Serguei V. S. Pakhomov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1\">Trevor Cohen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Domain Adaptation of a State of the Art Text-to-SQL Model: Lessons Learned and Challenges Found. (arXiv:2312.05448v1 [cs.CL])","link":"http://arxiv.org/abs/2312.05448","description":"<p>There are many recent advanced developments for the Text-to-SQL task, where\nthe Picard model is one of the the top performing models as measured by the\nSpider dataset competition. However, bringing Text-to-SQL systems to realistic\nuse-cases through domain adaptation remains a tough challenge. We analyze how\nwell the base T5 Language Model and Picard perform on query structures\ndifferent from the Spider dataset, we fine-tuned the base model on the Spider\ndata and on independent databases (DB). To avoid accessing the DB content\nonline during inference, we also present an alternative way to disambiguate the\nvalues in an input question using a rule-based approach that relies on an\nintermediate representation of the semantic concepts of an input question. In\nour results we show in what cases T5 and Picard can deliver good performance,\nwe share the lessons learned, and discuss current domain adaptation challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Manotas_I/0/1/0/all/0/1\">Irene Manotas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popescu_O/0/1/0/all/0/1\">Octavian Popescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vo_N/0/1/0/all/0/1\">Ngoc Phuoc An Vo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheinin_V/0/1/0/all/0/1\">Vadim Sheinin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Textual Toxicity in Social Media: Understanding the Bangla Toxic Language Expressed in Facebook Comment. (arXiv:2312.05467v1 [cs.CL])","link":"http://arxiv.org/abs/2312.05467","description":"<p>Social Media is a repository of digital literature including user-generated\ncontent. The users of social media are expressing their opinion with diverse\nmediums such as text, emojis, memes, and also through other visual and textual\nmediums. A major portion of these media elements could be treated as harmful to\nothers and they are known by many words including Cyberbullying and Toxic\nLanguage . The goal of this research paper is to analyze a curated and\nvalue-added dataset of toxic language titled ToxLex_bn . It is an exhaustive\nwordlist that can be used as classifier material to detect toxicity in social\nmedia. The toxic language/script used by the Bengali community as\ncyberbullying, hate speech and moral policing became major trends in social\nmedia culture in Bangladesh and West Bengal. The toxicity became so high that\nthe victims has to post as a counter or release explanation video for the\nhaters. Most cases are pointed to women celebrity and their relation, dress,\nlifestyle are became trolled and toxicity flooded in comments boxes. Not only\ncelebrity bashing but also hates occurred between Hindu Muslims,\nIndia-Bangladesh, Two opponents of 1971 and these are very common for virtual\nconflict in the comment thread. Even many times facebook comment causes sue and\nlegal matters in Bangladesh and thus it requires more study. In this study, a\nBangla toxic language dataset has been analyzed which was inputted by the user\nin Bengali script &amp; language. For this, about 1968 unique bigrams or phrases as\nwordlists have been analyzed which are derived from 2207590 comments. It is\nassumed that this analysis will reinforce the detection of Bangla's toxic\nlanguage used in social media and thus cure this virtual disease.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rashid_M/0/1/0/all/0/1\">Mohammad Mamun Or Rashid</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-Grained Analysis of Team Collaborative Dialogue. (arXiv:2312.05471v1 [cs.CL])","link":"http://arxiv.org/abs/2312.05471","description":"<p>Natural language analysis of human collaborative chat dialogues is an\nunderstudied domain with many unique challenges: a large number of dialogue act\nlabels, underspecified and dynamic tasks, interleaved topics, and long-range\ncontextual dependence. While prior work has studied broad metrics of team\ndialogue and associated performance using methods such as LSA, there has been\nlittle effort in generating fine-grained descriptions of team dynamics and\nindividual performance from dialogue. We describe initial work towards\ndeveloping an explainable analytics tool in the software development domain\nusing Slack chats mined from our organization, including generation of a novel,\nhierarchical labeling scheme; design of descriptive metrics based on the\nfrequency of occurrence of dialogue acts; and initial results using a\ntransformer + CRF architecture to incorporate long-range context.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Perera_I/0/1/0/all/0/1\">Ian Perera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1\">Matthew Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilber_C/0/1/0/all/0/1\">Carson Wilber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Teamwork Dimensions Classification Using BERT. (arXiv:2312.05483v1 [cs.CL])","link":"http://arxiv.org/abs/2312.05483","description":"<p>Teamwork is a necessary competency for students that is often inadequately\nassessed. Towards providing a formative assessment of student teamwork, an\nautomated natural language processing approach was developed to identify\nteamwork dimensions of students' online team chat. Developments in the field of\nnatural language processing and artificial intelligence have resulted in\nadvanced deep transfer learning approaches namely the Bidirectional Encoder\nRepresentations from Transformers (BERT) model that allow for more in-depth\nunderstanding of the context of the text. While traditional machine learning\nalgorithms were used in the previous work for the automatic classification of\nchat messages into the different teamwork dimensions, our findings have shown\nthat classifiers based on the pre-trained language model BERT provides improved\nclassification performance, as well as much potential for generalizability in\nthe language use of varying team chat contexts and team member demographics.\nThis model will contribute towards an enhanced learning analytics tool for\nteamwork assessment and feedback.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Junyoung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koh_E/0/1/0/all/0/1\">Elizabeth Koh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Large Language Models Serve as Rational Players in Game Theory? A Systematic Analysis. (arXiv:2312.05488v1 [cs.AI])","link":"http://arxiv.org/abs/2312.05488","description":"<p>Game theory, as an analytical tool, is frequently utilized to analyze human\nbehavior in social science research. With the high alignment between the\nbehavior of Large Language Models (LLMs) and humans, a promising research\ndirection is to employ LLMs as substitutes for humans in game experiments,\nenabling social science research. However, despite numerous empirical\nresearches on the combination of LLMs and game theory, the capability\nboundaries of LLMs in game theory remain unclear. In this research, we endeavor\nto systematically analyze LLMs in the context of game theory. Specifically,\nrationality, as the fundamental principle of game theory, serves as the metric\nfor evaluating players' behavior -- building a clear desire, refining belief\nabout uncertainty, and taking optimal actions. Accordingly, we select three\nclassical games (dictator game, Rock-Paper-Scissors, and ring-network game) to\nanalyze to what extent LLMs can achieve rationality in these three aspects. The\nexperimental results indicate that even the current state-of-the-art LLM\n(GPT-4) exhibits substantial disparities compared to humans in game theory. For\ninstance, LLMs struggle to build desires based on uncommon preferences, fail to\nrefine belief from many simple patterns, and may overlook or modify refined\nbelief when taking actions. Therefore, we consider that introducing LLMs into\ngame experiments in the field of social science should be approached with\ngreater caution.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Caoyun Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jindou Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Yaohui Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Hao He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Captum to Explain Generative Language Models. (arXiv:2312.05491v1 [cs.CL])","link":"http://arxiv.org/abs/2312.05491","description":"<p>Captum is a comprehensive library for model explainability in PyTorch,\noffering a range of methods from the interpretability literature to enhance\nusers' understanding of PyTorch models. In this paper, we introduce new\nfeatures in Captum that are specifically designed to analyze the behavior of\ngenerative language models. We provide an overview of the available\nfunctionalities and example applications of their potential for understanding\nlearned associations within generative language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Miglani_V/0/1/0/all/0/1\">Vivek Miglani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1\">Aobo Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markosyan_A/0/1/0/all/0/1\">Aram H. Markosyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Olano_D/0/1/0/all/0/1\">Diego Garcia-Olano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kokhlikyan_N/0/1/0/all/0/1\">Narine Kokhlikyan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"History Matters: Temporal Knowledge Editing in Large Language Model. (arXiv:2312.05497v1 [cs.CL])","link":"http://arxiv.org/abs/2312.05497","description":"<p>The imperative task of revising or updating the knowledge stored within large\nlanguage models arises from two distinct sources: intrinsic errors inherent in\nthe model which should be corrected and outdated knowledge due to external\nshifts in the real world which should be updated. Prevailing efforts in model\nediting conflate these two distinct categories of edits arising from distinct\nreasons and directly modify the original knowledge in models into new\nknowledge. However, we argue that preserving the model's original knowledge\nremains pertinent. Specifically, if a model's knowledge becomes outdated due to\nevolving worldly dynamics, it should retain recollection of the historical\nknowledge while integrating the newfound knowledge. In this work, we introduce\nthe task of Temporal Knowledge Editing (TKE) and establish a benchmark AToKe\n(Assessment of TempOral Knowledge Editing) to evaluate current model editing\nmethods. We find that while existing model editing methods are effective at\nmaking models remember new knowledge, the edited model catastrophically forgets\nhistorical knowledge. To address this gap, we propose a simple and general\nframework termed Multi-Editing with Time Objective (METO) for enhancing\nexisting editing models, which edits both historical and new knowledge\nconcurrently and optimizes the model's prediction for the time of each fact.\nOur assessments demonstrate that while AToKe is still difficult, METO maintains\nthe effectiveness of learning new knowledge and meanwhile substantially\nimproves the performance of edited models on utilizing historical knowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xunjian Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Liming Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiaojun Wan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Aligner: One Global Token is Worth Millions of Parameters When Aligning Large Language Models. (arXiv:2312.05503v1 [cs.CL])","link":"http://arxiv.org/abs/2312.05503","description":"<p>We introduce Aligner, a novel Parameter-Efficient Fine-Tuning (PEFT) method\nfor aligning multi-billion-parameter-sized Large Language Models (LLMs).\nAligner employs a unique design that constructs a globally shared set of\ntunable tokens that modify the attention of every layer. Remarkably with this\nmethod, even when using one token accounting for a mere 5,000 parameters,\nAligner can still perform comparably well to state-of-the-art LLM adaptation\nmethods like LoRA that require millions of parameters. This capacity is\nsubstantiated in both instruction following and value alignment tasks. Besides\nthe multiple order-of-magnitude improvement in parameter efficiency, the\ninsight Aligner provides into the internal mechanisms of LLMs is also valuable.\nThe architectural features and efficacy of our method, in addition to our\nexperiments demonstrate that an LLM separates its internal handling of \"form\"\nand \"knowledge\" in a somewhat orthogonal manner. This finding promises to\nmotivate new research into LLM mechanism understanding and value alignment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ziheng_Z/0/1/0/all/0/1\">Zhou Ziheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yingnian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Terzopoulos_D/0/1/0/all/0/1\">Demetri Terzopoulos</a> (University of California, Los Angeles)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Augmenty: A Python Library for Structured Text Augmentation. (arXiv:2312.05520v1 [cs.CL])","link":"http://arxiv.org/abs/2312.05520","description":"<p>Augmnety is a Python library for structured text augmentation. It is built on\ntop of spaCy and allows for augmentation of both the text and its annotations.\nAugmenty provides a wide range of augmenters which can be combined in a\nflexible manner to create complex augmentation pipelines. It also includes a\nset of primitives that can be used to create custom augmenters such as word\nreplacement augmenters. This functionality allows for augmentations within a\nrange of applications such as named entity recognition (NER), part-of-speech\ntagging, and dependency parsing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Enevoldsen_K/0/1/0/all/0/1\">Kenneth Enevoldsen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Medical Specialty Assignment to Patients using NLP Techniques. (arXiv:2312.05585v1 [cs.CL])","link":"http://arxiv.org/abs/2312.05585","description":"<p>The introduction of Large Language Models (LLMs), and the vast volume of\npublicly available medical data, amplified the application of NLP to the\nmedical domain. However, LLMs are pretrained on data that are not explicitly\nrelevant to the domain that are applied to and are often biased towards the\noriginal data they were pretrained upon. Even when pretrained on domainspecific\ndata, these models typically require time-consuming fine-tuning to achieve good\nperformance for a specific task. To address these limitations, we propose an\nalternative approach that achieves superior performance while being\ncomputationally efficient. Specifically, we utilize keywords to train a deep\nlearning architecture that outperforms a language model pretrained on a large\ncorpus of text. Our proposal does not require pretraining nor fine-tuning and\ncan be applied directly to a specific setting for performing multi-label\nclassification. Our objective is to automatically assign a new patient to the\nspecialty of the medical professional they require, using a dataset that\ncontains medical transcriptions and relevant keywords. To this end, we\nfine-tune the PubMedBERT model on this dataset, which serves as the baseline\nfor our experiments. We then twice train/fine-tune a DNN and the RoBERTa\nlanguage model, using both the keywords and the full transcriptions as input.\nWe compare the performance of these approaches using relevant metrics. Our\nresults demonstrate that utilizing keywords for text classification\nsignificantly improves classification performance, for both a basic DL\narchitecture and a large language model. Our approach represents a promising\nand efficient alternative to traditional methods for finetuning language models\non domain-specific data and has potential applications in various medical\ndomains\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Solomou_C/0/1/0/all/0/1\">Chris Solomou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"QAGCN: Answering Multi-Relation Questions via Single-Step Implicit Reasoning over Knowledge Graphs. (arXiv:2206.01818v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2206.01818","description":"<p>Multi-relation question answering (QA) is a challenging task, where given\nquestions usually require long reasoning chains in KGs that consist of multiple\nrelations. Recently, methods with explicit multi-step reasoning over KGs have\nbeen prominently used in this task and have demonstrated promising performance.\nExamples include methods that perform stepwise label propagation through KG\ntriples and methods that navigate over KG triples based on reinforcement\nlearning. A main weakness of these methods is that their reasoning mechanisms\nare usually complex and difficult to implement or train. In this paper, we\nargue that multi-relation QA can be achieved via end-to-end single-step\nimplicit reasoning, which is simpler, more efficient, and easier to adopt. We\npropose QAGCN -- a Question-Aware Graph Convolutional Network (GCN)-based\nmethod that includes a novel GCN architecture with controlled\nquestion-dependent message propagation for the implicit reasoning. Extensive\nexperiments have been conducted, where QAGCN achieved competitive and even\nsuperior performance compared to state-of-the-art explicit-reasoning methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruijie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossetto_L/0/1/0/all/0/1\">Luca Rossetto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cochez_M/0/1/0/all/0/1\">Michael Cochez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernstein_A/0/1/0/all/0/1\">Abraham Bernstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Synergistic Compilation Workflow for Tackling Crosstalk in Quantum Machines. (arXiv:2207.05751v3 [quant-ph] UPDATED)","link":"http://arxiv.org/abs/2207.05751","description":"<p>Near-term quantum systems tend to be noisy. Crosstalk noise has been\nrecognized as one of several major types of noises in superconducting Noisy\nIntermediate-Scale Quantum (NISQ) devices. Crosstalk arises from the concurrent\nexecution of two-qubit gates on nearby qubits, such as \\texttt{CX}. It might\nsignificantly raise the error rate of gates in comparison to running them\nindividually. Crosstalk can be mitigated through scheduling or hardware machine\ntuning. Prior scientific studies, however, manage crosstalk at a really late\nphase in the compilation process, usually after hardware mapping is done. It\nmay miss great opportunities of optimizing algorithm logic, routing, and\ncrosstalk at the same time. In this paper, we push the envelope by considering\nall these factors simultaneously at the very early compilation stage. We\npropose a crosstalk-aware quantum program compilation framework called CQC that\ncan enhance crosstalk mitigation while achieving satisfactory circuit depth.\nMoreover, we identify opportunities for translation from intermediate\nrepresentation to the circuit for application-specific crosstalk mitigation,\nfor instance, the \\texttt{CX} ladder construction in variational quantum\neigensolvers (VQE). Evaluations through simulation and on real IBM-Q devices\nshow that our framework can significantly reduce the error rate by up to\n6$\\times$, with only $\\sim$60\\% circuit depth compared to state-of-the-art gate\nscheduling approaches. In particular, for VQE, we demonstrate 49\\% circuit\ndepth reduction with 9.6\\% fidelity improvement over prior art on the H4\nmolecule using IBMQ Guadalupe. Our CQC framework will be released on GitHub.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/quant-ph/1/au:+Hua_F/0/1/0/all/0/1\">Fei Hua</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jin_Y/0/1/0/all/0/1\">Yuwei Jin</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_A/0/1/0/all/0/1\">Ang Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Liu_C/0/1/0/all/0/1\">Chenxu Liu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wang_M/0/1/0/all/0/1\">Meng Wang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Chen_Y/0/1/0/all/0/1\">Yanhao Chen</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Zhang_C/0/1/0/all/0/1\">Chi Zhang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Hayes_A/0/1/0/all/0/1\">Ari Hayes</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Stein_S/0/1/0/all/0/1\">Samuel Stein</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Guo_M/0/1/0/all/0/1\">Minghao Guo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Huang_Y/0/1/0/all/0/1\">Yipeng Huang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Zhang_E/0/1/0/all/0/1\">Eddy Z. Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"gBuilder: A Scalable Knowledge Graph Construction System for Unstructured Corpus. (arXiv:2208.09705v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.09705","description":"<p>We design a user-friendly and scalable knowledge graph construction (KGC)\nsystem for extracting structured knowledge from the unstructured corpus.\nDifferent from existing KGC systems, gBuilder provides a flexible and\nuser-defined pipeline to embrace the rapid development of IE models. More\nbuilt-in template-based or heuristic operators and programmable operators are\navailable for adapting to data from different domains. Furthermore, we also\ndesign a cloud-based self-adaptive task scheduling for gBuilder to ensure its\nscalability on large-scale knowledge graph construction. Experimental\nevaluation demonstrates the ability of gBuilder to organize multiple\ninformation extraction models for knowledge graph construction in a uniform\nplatform, and confirms its high scalability on large-scale KGC tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanzeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_L/0/1/0/all/0/1\">Lei Zou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revealing Patient-Reported Experiences in Healthcare from Social Media using the DAPMAV Framework. (arXiv:2210.04232v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.04232","description":"<p>Understanding patient experience in healthcare is increasingly important and\ndesired by medical professionals in a patient-centered care approach.\nHealthcare discourse on social media presents an opportunity to gain a unique\nperspective on patient-reported experiences, complementing traditional survey\ndata. These social media reports often appear as first-hand accounts of\npatients' journeys through the healthcare system, whose details extend beyond\nthe confines of structured surveys and at a far larger scale than focus groups.\nHowever, in contrast with the vast presence of patient-experience data on\nsocial media and the potential benefits the data offers, it attracts\ncomparatively little research attention due to the technical proficiency\nrequired for text analysis. In this paper, we introduce the\nDesign-Acquire-Process-Model-Analyse-Visualise (DAPMAV) framework to provide an\noverview of techniques and an approach to capture patient-reported experiences\nfrom social media data. We apply this framework in a case study on prostate\ncancer data from /r/ProstateCancer, demonstrate the framework's value in\ncapturing specific aspects of patient concern (such as sexual dysfunction),\nprovide an overview of the discourse, and show narrative and emotional\nprogression through these stories. We anticipate this framework to apply to a\nwide variety of areas in healthcare, including capturing and differentiating\nexperiences across minority groups, geographic boundaries, and types of\nillnesses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Murray_C/0/1/0/all/0/1\">Curtis Murray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_L/0/1/0/all/0/1\">Lewis Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuke_J/0/1/0/all/0/1\">Jonathan Tuke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mackay_M/0/1/0/all/0/1\">Mark Mackay</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting. (arXiv:2210.08964v5 [stat.ME] UPDATED)","link":"http://arxiv.org/abs/2210.08964","description":"<p>This paper presents a new perspective on time series forecasting. In existing\ntime series forecasting methods, the models take a sequence of numerical values\nas input and yield numerical values as output. The existing SOTA models are\nlargely based on the Transformer architecture, modified with multiple encoding\nmechanisms to incorporate the context and semantics around the historical data.\nInspired by the successes of pre-trained language foundation models, we pose a\nquestion about whether these models can also be adapted to solve time-series\nforecasting. Thus, we propose a new forecasting paradigm: prompt-based time\nseries forecasting (PromptCast). In this novel task, the numerical input and\noutput are transformed into prompts and the forecasting task is framed in a\nsentence-to-sentence manner, making it possible to directly apply language\nmodels for forecasting purposes. To support and facilitate the research of this\ntask, we also present a large-scale dataset (PISA) that includes three\nreal-world forecasting scenarios. We evaluate different SOTA numerical-based\nforecasting methods and language generation models. The benchmark results with\nvarious forecasting settings demonstrate the proposed PromptCast with language\ngeneration models is a promising research direction. Additionally, in\ncomparison to conventional numerical-based forecasting, PromptCast shows a much\nbetter generalization ability under the zero-shot setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/stat/1/au:+Xue_H/0/1/0/all/0/1\">Hao Xue</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Salim_F/0/1/0/all/0/1\">Flora D. Salim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Impact of Adversarial Training on Robustness and Generalizability of Language Models. (arXiv:2211.05523v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.05523","description":"<p>Adversarial training is widely acknowledged as the most effective defense\nagainst adversarial attacks. However, it is also well established that\nachieving both robustness and generalization in adversarially trained models\ninvolves a trade-off. The goal of this work is to provide an in depth\ncomparison of different approaches for adversarial training in language models.\nSpecifically, we study the effect of pre-training data augmentation as well as\ntraining time input perturbations vs. embedding space perturbations on the\nrobustness and generalization of transformer-based language models. Our\nfindings suggest that better robustness can be achieved by pre-training data\naugmentation or by training with input space perturbation. However, training\nwith embedding space perturbation significantly improves generalization. A\nlinguistic correlation analysis of neurons of the learned models reveals that\nthe improved generalization is due to 'more specialized' neurons. To the best\nof our knowledge, this is the first work to carry out a deep qualitative\nanalysis of different methods of generating adversarial examples in adversarial\ntraining of language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Altinisik_E/0/1/0/all/0/1\">Enes Altinisik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sajjad_H/0/1/0/all/0/1\">Hassan Sajjad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sencar_H/0/1/0/all/0/1\">Husrev Taha Sencar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messaoud_S/0/1/0/all/0/1\">Safa Messaoud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chawla_S/0/1/0/all/0/1\">Sanjay Chawla</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LEAD: Liberal Feature-based Distillation for Dense Retrieval. (arXiv:2212.05225v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2212.05225","description":"<p>Knowledge distillation is often used to transfer knowledge from a strong\nteacher model to a relatively weak student model. Traditional methods include\nresponse-based methods and feature-based methods. Response-based methods are\nwidely used but suffer from lower upper limits of performance due to their\nignorance of intermediate signals, while feature-based methods have constraints\non vocabularies, tokenizers and model architectures. In this paper, we propose\na liberal feature-based distillation method (LEAD). LEAD aligns the\ndistribution between the intermediate layers of teacher model and student\nmodel, which is effective, extendable, portable and has no requirements on\nvocabularies, tokenizers, or model architectures. Extensive experiments show\nthe effectiveness of LEAD on widely-used benchmarks, including MS MARCO Passage\nRanking, TREC 2019 DL Track, MS MARCO Document Ranking and TREC 2020 DL Track.\nOur code is available in https://github.com/microsoft/SimXNS/tree/main/LEAD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_A/0/1/0/all/0/1\">Anlei Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jingwen Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linjun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majumder_R/0/1/0/all/0/1\">Rangan Majumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models for Biomedical Knowledge Graph Construction: Information extraction from EMR notes. (arXiv:2301.12473v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.12473","description":"<p>The automatic construction of knowledge graphs (KGs) is an important research\narea in medicine, with far-reaching applications spanning drug discovery and\nclinical trial design. These applications hinge on the accurate identification\nof interactions among medical and biological entities. In this study, we\npropose an end-to-end machine learning solution based on large language models\n(LLMs) that utilize electronic medical record notes to construct KGs. The\nentities used in the KG construction process are diseases, factors, treatments,\nas well as manifestations that coexist with the patient while experiencing the\ndisease. Given the critical need for high-quality performance in medical\napplications, we embark on a comprehensive assessment of 12 LLMs of various\narchitectures, evaluating their performance and safety attributes. To gauge the\nquantitative efficacy of our approach by assessing both precision and recall,\nwe manually annotate a dataset provided by the Macula and Retina Institute. We\nalso assess the qualitative performance of LLMs, such as the ability to\ngenerate structured outputs or the tendency to hallucinate. The results\nillustrate that in contrast to encoder-only and encoder-decoder, decoder-only\nLLMs require further investigation. Additionally, we provide guided prompt\ndesign to utilize such LLMs. The application of the proposed methodology is\ndemonstrated on age-related macular degeneration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arsenyan_V/0/1/0/all/0/1\">Vahan Arsenyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bughdaryan_S/0/1/0/all/0/1\">Spartak Bughdaryan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaya_F/0/1/0/all/0/1\">Fadi Shaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Small_K/0/1/0/all/0/1\">Kent Small</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahnazaryan_D/0/1/0/all/0/1\">Davit Shahnazaryan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework. (arXiv:2302.12247v5 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.12247","description":"<p>The recent explosion of interest in multimodal applications has resulted in a\nwide selection of datasets and methods for representing and integrating\ninformation from different modalities. Despite these empirical advances, there\nremain fundamental research questions: How can we quantify the interactions\nthat are necessary to solve a multimodal task? Subsequently, what are the most\nsuitable multimodal models to capture these interactions? To answer these\nquestions, we propose an information-theoretic approach to quantify the degree\nof redundancy, uniqueness, and synergy relating input modalities with an output\ntask. We term these three measures as the PID statistics of a multimodal\ndistribution (or PID for short), and introduce two new estimators for these PID\nstatistics that scale to high-dimensional distributions. To validate PID\nestimation, we conduct extensive experiments on both synthetic datasets where\nthe PID is known and on large-scale multimodal benchmarks where PID estimations\nare compared with human annotations. Finally, we demonstrate their usefulness\nin (1) quantifying interactions within multimodal datasets, (2) quantifying\ninteractions captured by multimodal models, (3) principled approaches for model\nselection, and (4) three real-world case studies engaging with domain experts\nin pathology, mood prediction, and robotic perception where our framework helps\nto recommend strong multimodal models for each application.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Paul Pu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yun Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xiang Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_C/0/1/0/all/0/1\">Chun Kai Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_S/0/1/0/all/0/1\">Suzanne Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Richard Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zihao Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allen_N/0/1/0/all/0/1\">Nicholas Allen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Auerbach_R/0/1/0/all/0/1\">Randy Auerbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_F/0/1/0/all/0/1\">Faisal Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1\">Louis-Philippe Morency</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GEMINI: Controlling the Sentence-level Writing Style for Abstractive Text Summarization. (arXiv:2304.03548v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.03548","description":"<p>Human experts write summaries using different techniques, including\nextracting a sentence from the document and rewriting it, or fusing various\ninformation from the document to abstract it. These techniques are flexible and\nthus difficult to be imitated by any single method. To address this issue, we\npropose an adaptive model, GEMINI, that integrates a rewriter and a generator\nto mimic the sentence rewriting and abstracting techniques, respectively.\nGEMINI adaptively chooses to rewrite a specific document sentence or generate a\nsummary sentence from scratch. Experiments demonstrate that our adaptive\napproach outperforms the pure abstractive and rewriting baselines on three\nbenchmark datasets, achieving the best results on WikiHow. Interestingly,\nempirical results show that the human summary styles of summary sentences are\nconsistently predictable given their context. We release our code and model at\n\\url{https://github.com/baoguangsheng/gemini}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bao_G/0/1/0/all/0/1\">Guangsheng Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_Z/0/1/0/all/0/1\">Zebin Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPT-RE: In-context Learning for Relation Extraction using Large Language Models. (arXiv:2305.02105v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02105","description":"<p>In spite of the potential for ground-breaking achievements offered by large\nlanguage models (LLMs) (e.g., GPT-3), they still lag significantly behind\nfully-supervised baselines (e.g., fine-tuned BERT) in relation extraction (RE).\nThis is due to the two major shortcomings of LLMs in RE: (1) low relevance\nregarding entity and relation in retrieved demonstrations for in-context\nlearning; and (2) the strong inclination to wrongly classify NULL examples into\nother pre-defined labels.\n</p>\n<p>In this paper, we propose GPT-RE to bridge the gap between LLMs and\nfully-supervised baselines. GPT-RE successfully addresses the aforementioned\nissues by (1) incorporating task-specific entity representations in\ndemonstration retrieval; and (2) enriching the demonstrations with gold\nlabel-induced reasoning logic. We evaluate GPT-RE on four widely-used RE\ndatasets, and observe that GPT-RE achieves improvements over not only existing\nGPT-3 baselines, but also fully-supervised baselines. Specifically, GPT-RE\nachieves SOTA performances on the Semeval and SciERC datasets, and competitive\nperformances on the TACRED and ACE05 datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wan_Z/0/1/0/all/0/1\">Zhen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_F/0/1/0/all/0/1\">Fei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Zhuoyuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qianying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Haiyue Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurohashi_S/0/1/0/all/0/1\">Sadao Kurohashi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Context-Aware Semantic Similarity Measurement for Unsupervised Word Sense Disambiguation. (arXiv:2305.03520v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.03520","description":"<p>The issue of word sense ambiguity poses a significant challenge in natural\nlanguage processing due to the scarcity of annotated data to feed machine\nlearning models to face the challenge. Therefore, unsupervised word sense\ndisambiguation methods have been developed to overcome that challenge without\nrelying on annotated data. This research proposes a new context-aware approach\nto unsupervised word sense disambiguation, which provides a flexible mechanism\nfor incorporating contextual information into the similarity measurement\nprocess. We experiment with a popular benchmark dataset to evaluate the\nproposed strategy and compare its performance with state-of-the-art\nunsupervised word sense disambiguation techniques. The experimental results\nindicate that our approach substantially enhances disambiguation accuracy and\nsurpasses the performance of several existing techniques. Our findings\nunderscore the significance of integrating contextual information in semantic\nsimilarity measurements to manage word sense ambiguity in unsupervised\nscenarios effectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Martinez_Gil_J/0/1/0/all/0/1\">Jorge Martinez-Gil</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting. (arXiv:2305.04388v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.04388","description":"<p>Large Language Models (LLMs) can achieve strong performance on many tasks by\nproducing step-by-step reasoning before giving a final output, often referred\nto as chain-of-thought reasoning (CoT). It is tempting to interpret these CoT\nexplanations as the LLM's process for solving a task. This level of\ntransparency into LLMs' predictions would yield significant safety benefits.\nHowever, we find that CoT explanations can systematically misrepresent the true\nreason for a model's prediction. We demonstrate that CoT explanations can be\nheavily influenced by adding biasing features to model inputs--e.g., by\nreordering the multiple-choice options in a few-shot prompt to make the answer\nalways \"(A)\"--which models systematically fail to mention in their\nexplanations. When we bias models toward incorrect answers, they frequently\ngenerate CoT explanations rationalizing those answers. This causes accuracy to\ndrop by as much as 36% on a suite of 13 tasks from BIG-Bench Hard, when testing\nwith GPT-3.5 from OpenAI and Claude 1.0 from Anthropic. On a social-bias task,\nmodel explanations justify giving answers in line with stereotypes without\nmentioning the influence of these social biases. Our findings indicate that CoT\nexplanations can be plausible yet misleading, which risks increasing our trust\nin LLMs without guaranteeing their safety. Building more transparent and\nexplainable systems will require either improving CoT faithfulness through\ntargeted efforts or abandoning CoT in favor of alternative methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Turpin_M/0/1/0/all/0/1\">Miles Turpin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michael_J/0/1/0/all/0/1\">Julian Michael</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_E/0/1/0/all/0/1\">Ethan Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1\">Samuel R. Bowman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interactive Text-to-SQL Generation via Editable Step-by-Step Explanations. (arXiv:2305.07372v4 [cs.DB] UPDATED)","link":"http://arxiv.org/abs/2305.07372","description":"<p>Relational databases play an important role in this Big Data era. However, it\nis challenging for non-experts to fully unleash the analytical power of\nrelational databases, since they are not familiar with database languages such\nas SQL. Many techniques have been proposed to automatically generate SQL from\nnatural language, but they suffer from two issues: (1) they still make many\nmistakes, particularly for complex queries, and (2) they do not provide a\nflexible way for non-expert users to validate and refine the incorrect queries.\nTo address these issues, we introduce a new interaction mechanism that allows\nusers directly edit a step-by-step explanation of an incorrect SQL to fix SQL\nerrors. Experiments on the Spider benchmark show that our approach outperforms\nthree SOTA approaches by at least 31.6% in terms of execution accuracy. A user\nstudy with 24 participants further shows that our approach helped users solve\nsignificantly more SQL tasks with less time and higher confidence,\ndemonstrating its potential to expand access to databases, particularly for\nnon-experts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuan Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_Z/0/1/0/all/0/1\">Zheng Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Toby Jia-Jun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kummerfeld_J/0/1/0/all/0/1\">Jonathan K. Kummerfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianyi Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-supervised Predictive Coding Models Encode Speaker and Phonetic Information in Orthogonal Subspaces. (arXiv:2305.12464v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12464","description":"<p>Self-supervised speech representations are known to encode both speaker and\nphonetic information, but how they are distributed in the high-dimensional\nspace remains largely unexplored. We hypothesize that they are encoded in\northogonal subspaces, a property that lends itself to simple disentanglement.\nApplying principal component analysis to representations of two predictive\ncoding models, we identify two subspaces that capture speaker and phonetic\nvariances, and confirm that they are nearly orthogonal. Based on this property,\nwe propose a new speaker normalization method which collapses the subspace that\nencodes speaker information, without requiring transcriptions. Probing\nexperiments show that our method effectively eliminates speaker information and\noutperforms a previous baseline in phone discrimination tasks. Moreover, the\napproach generalizes and can be used to remove information of unseen speakers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_O/0/1/0/all/0/1\">Oli Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Hao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldwater_S/0/1/0/all/0/1\">Sharon Goldwater</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Non-Autoregressive Document-Level Machine Translation. (arXiv:2305.12878v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12878","description":"<p>Non-autoregressive translation (NAT) models achieve comparable performance\nand superior speed compared to auto-regressive translation (AT) models in the\ncontext of sentence-level machine translation (MT). However, their abilities\nare unexplored in document-level MT, hindering their usage in real scenarios.\nIn this paper, we conduct a comprehensive examination of typical NAT models in\nthe context of document-level MT and further propose a simple but effective\ndesign of sentence alignment between source and target. Experiments show that\nNAT models achieve high acceleration on documents, and sentence alignment\nsignificantly enhances their performance.\n</p>\n<p>However, current NAT models still have a significant performance gap compared\nto their AT counterparts. Further investigation reveals that NAT models suffer\nmore from the multi-modality and misalignment issues in the context of\ndocument-level MT, and current NAT models struggle with exploiting document\ncontext and handling discourse phenomena. We delve into these challenges and\nprovide our code at \\url{https://github.com/baoguangsheng/nat-on-doc}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bao_G/0/1/0/all/0/1\">Guangsheng Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_Z/0/1/0/all/0/1\">Zhiyang Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jianhao Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Large Language Models emulate an inductive Thematic Analysis of semi-structured interviews? An exploration and provocation on the limits of the approach and the model. (arXiv:2305.13014v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13014","description":"<p>Large Language Models (LLMs) have emerged as powerful generative Artificial\nIntelligence solutions which can be applied to several fields and areas of\nwork. This paper presents results and reflection of an experiment done to use\nthe model GPT 3.5-Turbo to emulate some aspects of an inductive Thematic\nAnalysis. Previous research on this subject has largely worked on conducting\ndeductive analysis. Thematic Analysis is a qualitative method for analysis\ncommonly used in social sciences and it is based on interpretations made by the\nhuman analyst(s) and the identification of explicit and latent meanings in\nqualitative data. Attempting an analysis based on human interpretation with an\nLLM clearly is a provocation but also a way to learn something about how these\nsystems can or cannot be used in qualitative research. The paper presents the\nmotivations for attempting this emulation, it reflects on how the six steps to\na Thematic Analysis proposed by Braun and Clarke can at least partially be\nreproduced with the LLM and it also reflects on what are the outputs produced\nby the model. The paper used two existing datasets of open access\nsemi-structured interviews, previously analysed with Thematic Analysis by other\nresearchers. It used the previously produced analysis (and the related themes)\nto compare with the results produced by the LLM. The results show that the\nmodel can infer at least partially some of the main Themes. The objective of\nthe paper is not to replace human analysts in qualitative analysis but to learn\nif some elements of LLM data manipulation can to an extent be of support for\nqualitative research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Paoli_S/0/1/0/all/0/1\">Stefano De Paoli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RWKV: Reinventing RNNs for the Transformer Era. (arXiv:2305.13048v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13048","description":"<p>Transformers have revolutionized almost all natural language processing (NLP)\ntasks but suffer from memory and computational complexity that scales\nquadratically with sequence length. In contrast, recurrent neural networks\n(RNNs) exhibit linear scaling in memory and computational requirements but\nstruggle to match the same performance as Transformers due to limitations in\nparallelization and scalability. We propose a novel model architecture,\nReceptance Weighted Key Value (RWKV), that combines the efficient\nparallelizable training of transformers with the efficient inference of RNNs.\n</p>\n<p>Our approach leverages a linear attention mechanism and allows us to\nformulate the model as either a Transformer or an RNN, thus parallelizing\ncomputations during training and maintains constant computational and memory\ncomplexity during inference. We scale our models as large as 14 billion\nparameters, by far the largest dense RNN ever trained, and find RWKV performs\non par with similarly sized Transformers, suggesting future work can leverage\nthis architecture to create more efficient models. This work presents a\nsignificant step towards reconciling trade-offs between computational\nefficiency and model performance in sequence processing tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Bo Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alcaide_E/0/1/0/all/0/1\">Eric Alcaide</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anthony_Q/0/1/0/all/0/1\">Quentin Anthony</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albalak_A/0/1/0/all/0/1\">Alon Albalak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arcadinho_S/0/1/0/all/0/1\">Samuel Arcadinho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biderman_S/0/1/0/all/0/1\">Stella Biderman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_H/0/1/0/all/0/1\">Huanqi Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xin Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_M/0/1/0/all/0/1\">Michael Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grella_M/0/1/0/all/0/1\">Matteo Grella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+GV_K/0/1/0/all/0/1\">Kranthi Kiran GV</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xuzheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_H/0/1/0/all/0/1\">Haowen Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jiaju Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazienko_P/0/1/0/all/0/1\">Przemyslaw Kazienko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kocon_J/0/1/0/all/0/1\">Jan Kocon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_J/0/1/0/all/0/1\">Jiaming Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koptyra_B/0/1/0/all/0/1\">Bartlomiej Koptyra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lau_H/0/1/0/all/0/1\">Hayden Lau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mantri_K/0/1/0/all/0/1\">Krishna Sri Ipsit Mantri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mom_F/0/1/0/all/0/1\">Ferdinand Mom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saito_A/0/1/0/all/0/1\">Atsushi Saito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_G/0/1/0/all/0/1\">Guangyu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiangru Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bolun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wind_J/0/1/0/all/0/1\">Johan S. Wind</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wozniak_S/0/1/0/all/0/1\">Stanislaw Wozniak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruichong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhenyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qihang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Peng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qinghua Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jian Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Rui-Jie Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model. (arXiv:2305.15265v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.15265","description":"<p>With the rapid growth in model size, fine-tuning the large pre-trained\nlanguage model has become increasingly difficult due to its extensive memory\nusage. Previous works usually focus on reducing the number of trainable\nparameters in the network. While the model parameters do contribute to memory\nusage, the primary memory bottleneck during training arises from storing\nfeature maps, also known as activations, as they are crucial for gradient\ncalculation. Notably, neural networks are usually trained using stochastic\ngradient descent. We argue that in stochastic optimization, models can handle\nnoisy gradients as long as the gradient estimator is unbiased with reasonable\nvariance. Following this motivation, we propose a new family of unbiased\nestimators called WTA-CRS, for matrix production with reduced variance, which\nonly requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the\ncontext of tuning transformers, our proposed estimators exhibit lower variance\ncompared to existing ones. By replacing the linear operation with our\napproximated one in transformers, we can achieve up to 2.7$\\times$ peak memory\nreduction with almost no accuracy drop and enables up to $6.4\\times$ larger\nbatch size. Under the same hardware, WTA-CRS enables better down-streaming task\nperformance by applying larger models and/or faster training speed with larger\nbatch sizes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zirui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guanchu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1\">Shaochen Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhaozhuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_D/0/1/0/all/0/1\">Daochen Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1\">Ruixiang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhimeng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kaixiong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhary_V/0/1/0/all/0/1\">Vipin Chaudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xia Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MERGE: Fast Private Text Generation. (arXiv:2305.15769v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15769","description":"<p>The drastic increase in language models' parameters has led to a new trend of\ndeploying models in cloud servers, raising growing concerns about private\ninference for Transformer-based models. Existing two-party privacy-preserving\ntechniques, however, only take into account natural language understanding\n(NLU) scenarios. Private inference in natural language generation (NLG),\ncrucial for applications like translation and code completion, remains\nunderexplored.In addition, previous privacy-preserving techniques suffer from\nconvergence issues during model training and exhibit poor inference speed when\nused with NLG models due to the neglect of time-consuming operations in\nauto-regressive generations. To address these issues, we propose a fast private\ntext generation framework for Transformer-based language models, namely\nMERGE.MERGE reuses the output hidden state as the word embedding to bypass the\nembedding computation and reorganize the linear operations in the Transformer\nmodule to accelerate the forward procedure. Extensive experiments show that\nMERGE achieves a 26.5x speedup to the vanilla encrypted model under the\nsequence length 512, and reduces 80\\% communication cost, with an up to 10x\nspeedup to state-of-the-art approximated models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1\">Zi Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pinghui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruofei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Nuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_L/0/1/0/all/0/1\">Lifeng Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuo Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Impact of Model Scaling on Parameter-Efficient Tuning. (arXiv:2306.02320v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.02320","description":"<p>Parameter-efficient tuning (PET) methods can effectively drive extremely\nlarge pre-trained language models (PLMs) by training only minimal parameters.\nDifferent PET methods utilize different manually designed tunable modules. In\nsmall PLMs, there are usually noticeable performance differences among PET\nmethods. Nevertheless, as the model scale increases, the performance\ndifferences become marginal. Hence, we hypothesize that model scaling mitigates\nthe impact of design differences on PET methods. To investigate this\nhypothesis, we introduce a more flexible PET method called Arbitrary PET (APET)\nmethod. The APET method is compatible with a tunable module, which consists of\nany number of parameters distributed in arbitrary positions. Then, we utilize\nit and conduct experiments on 11 NLP tasks across 3 representative PLMs. Our\ninvestigations reveal that model scaling (1) mitigates the effects of the\npositions of tunable parameters on performance, and (2) enables tuning methods\nto achieve performance comparable to full-parameter fine-tuning by optimizing\nfewer tunable parameters. Intriguingly, we also observe that tuning methods\noptimize the similar number of tunable parameters to exceed random guess\nperformance on different tasks. We collectively discuss this phenomenon and the\ntwo aforementioned findings from an optimization perspective to understand the\nunderlying mechanisms. These conclusions enhance our understanding of the\nimpact of model scaling on PET and assist in designing more effective and\nefficient PET methods for PLMs of different scales. The source code can be\nobtained from this GitHub repository:\n\\url{https://github.com/yushengsu-thu/PET_Scaling}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yusheng Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1\">Chi-Min Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1\">Jiali Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yujia Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shengding Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zonghan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1\">Ning Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xingzhi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_G/0/1/0/all/0/1\">Guotong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mind2Web: Towards a Generalist Agent for the Web. (arXiv:2306.06070v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.06070","description":"<p>We introduce Mind2Web, the first dataset for developing and evaluating\ngeneralist agents for the web that can follow language instructions to complete\ncomplex tasks on any website. Existing datasets for web agents either use\nsimulated websites or only cover a limited set of websites and tasks, thus not\nsuitable for generalist web agents. With over 2,000 open-ended tasks collected\nfrom 137 websites spanning 31 domains and crowdsourced action sequences for the\ntasks, Mind2Web provides three necessary ingredients for building generalist\nweb agents: 1) diverse domains, websites, and tasks, 2) use of real-world\nwebsites instead of simulated and simplified ones, and 3) a broad spectrum of\nuser interaction patterns. Based on Mind2Web, we conduct an initial exploration\nof using large language models (LLMs) for building generalist web agents. While\nthe raw HTML of real-world websites are often too large to be fed to LLMs, we\nshow that first filtering it with a small LM significantly improves the\neffectiveness and efficiency of LLMs. Our solution demonstrates a decent level\nof performance, even on websites or entire domains the model has never seen\nbefore, but there is still a substantial room to improve towards truly\ngeneralizable agents. We open-source our dataset, model implementation, and\ntrained models (https://osu-nlp-group.github.io/Mind2Web) to facilitate further\nresearch on building a generalist agent for the web.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1\">Xiang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yu Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Boyuan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shijie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevens_S/0/1/0/all/0/1\">Samuel Stevens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Boshi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Huan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models. (arXiv:2306.11698v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.11698","description":"<p>Generative Pre-trained Transformer (GPT) models have exhibited exciting\nprogress in their capabilities, capturing the interest of practitioners and the\npublic alike. Yet, while the literature on the trustworthiness of GPT models\nremains limited, practitioners have proposed employing capable GPT models for\nsensitive applications such as healthcare and finance -- where mistakes can be\ncostly. To this end, this work proposes a comprehensive trustworthiness\nevaluation for large language models with a focus on GPT-4 and GPT-3.5,\nconsidering diverse perspectives -- including toxicity, stereotype bias,\nadversarial robustness, out-of-distribution robustness, robustness on\nadversarial demonstrations, privacy, machine ethics, and fairness. Based on our\nevaluations, we discover previously unpublished vulnerabilities to\ntrustworthiness threats. For instance, we find that GPT models can be easily\nmisled to generate toxic and biased outputs and leak private information in\nboth training data and conversation history. We also find that although GPT-4\nis usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more\nvulnerable given jailbreaking system or user prompts, potentially because GPT-4\nfollows (misleading) instructions more precisely. Our work illustrates a\ncomprehensive trustworthiness evaluation of GPT models and sheds light on the\ntrustworthiness gaps. Our benchmark is publicly available at\nhttps://decodingtrust.github.io/. Additionally, our dataset can be previewed at\nhttps://huggingface.co/datasets/AI-Secure/DecodingTrust, and a concise version\nof our DecodingTrust is accessible at https://openreview.net/pdf?id=kaHpo8OZw2.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Boxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weixin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_H/0/1/0/all/0/1\">Hengzhi Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Chulin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Mintong Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chenhui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chejian Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1\">Zidi Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutta_R/0/1/0/all/0/1\">Ritik Dutta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaeffer_R/0/1/0/all/0/1\">Rylan Schaeffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_S/0/1/0/all/0/1\">Sang T. Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1\">Simran Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazeika_M/0/1/0/all/0/1\">Mantas Mazeika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1\">Dan Hendrycks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zinan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koyejo_S/0/1/0/all/0/1\">Sanmi Koyejo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Composing Parameter-Efficient Modules with Arithmetic Operations. (arXiv:2306.14870v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.14870","description":"<p>As an efficient alternative to conventional full finetuning,\nparameter-efficient finetuning (PEFT) is becoming the prevailing method to\nadapt pretrained language models. In PEFT, a lightweight module is learned on\neach dataset while the underlying pretrained language model remains unchanged,\nresulting in multiple compact modules representing diverse skills when applied\nto various domains and tasks. In this paper, we propose to compose these\nparameter-efficient modules through linear arithmetic operations in the weight\nspace, thereby integrating different module capabilities. Specifically, we\nfirst define addition and negation operators for the module, and then further\ncompose these two basic operators to perform flexible arithmetic. Our approach\nrequires \\emph{no additional training} and enables highly flexible module\ncomposition. We apply different arithmetic operations to compose the\nparameter-efficient modules for (1) distribution generalization, (2)\nmulti-tasking, (3) unlearning, and (4) domain transfer. Additionally, we extend\nour approach to detoxify Alpaca-LoRA, the latest instruction-tuned large\nlanguage model based on LLaMA. Empirical results demonstrate that our approach\nproduces new and effective parameter-efficient modules that significantly\noutperform existing ones across all settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinghan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shiqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Junteng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junxian He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models. (arXiv:2307.02028v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2307.02028","description":"<p>While the general machine learning (ML) community has benefited from public\ndatasets, tasks, and models, the progress of ML in healthcare has been hampered\nby a lack of such shared assets. The success of foundation models creates new\nchallenges for healthcare ML by requiring access to shared pretrained models to\nvalidate performance benefits. We help address these challenges through three\ncontributions. First, we publish a new dataset, EHRSHOT, which contains\ndeidentified structured data from the electronic health records (EHRs) of 6,739\npatients from Stanford Medicine. Unlike MIMIC-III/IV and other popular EHR\ndatasets, EHRSHOT is longitudinal and not restricted to ICU/ED patients.\nSecond, we publish the weights of CLMBR-T-base, a 141M parameter clinical\nfoundation model pretrained on the structured EHR data of 2.57M patients. We\nare one of the first to fully release such a model for coded EHR data; in\ncontrast, most prior models released for clinical data (e.g. GatorTron,\nClinicalBERT) only work with unstructured text and cannot process the rich,\nstructured data within an EHR. We provide an end-to-end pipeline for the\ncommunity to validate and build upon its performance. Third, we define 15\nfew-shot clinical prediction tasks, enabling evaluation of foundation models on\nbenefits such as sample efficiency and task adaptation. Our model and dataset\nare available via a research data use agreement from our website:\nhttps://ehrshot.stanford.edu. Code to reproduce our results are available at\nour Github repo: https://github.com/som-shahlab/ehrshot-benchmark\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wornow_M/0/1/0/all/0/1\">Michael Wornow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thapa_R/0/1/0/all/0/1\">Rahul Thapa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinberg_E/0/1/0/all/0/1\">Ethan Steinberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fries_J/0/1/0/all/0/1\">Jason A. Fries</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Nigam H. Shah</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bidirectional Attention as a Mixture of Continuous Word Experts. (arXiv:2307.04057v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.04057","description":"<p>Bidirectional attention $\\unicode{x2013}$ composed of self-attention with\npositional encodings and the masked language model (MLM) objective\n$\\unicode{x2013}$ has emerged as a key component of modern large language\nmodels (LLMs). Despite its empirical success, few studies have examined its\nstatistical underpinnings: What statistical model is bidirectional attention\nimplicitly fitting? What sets it apart from its non-attention predecessors? We\nexplore these questions in this paper. The key observation is that fitting a\nsingle-layer single-head bidirectional attention, upon reparameterization, is\nequivalent to fitting a continuous bag of words (CBOW) model with\nmixture-of-experts (MoE) weights. Further, bidirectional attention with\nmultiple heads and multiple layers is equivalent to stacked MoEs and a mixture\nof MoEs, respectively. This statistical viewpoint reveals the distinct use of\nMoE in bidirectional attention, which aligns with its practical effectiveness\nin handling heterogeneous data. It also suggests an immediate extension to\ncategorical tabular data, if we view each word location in a sentence as a\ntabular feature. Across empirical studies, we find that this extension\noutperforms existing tabular extensions of transformers in out-of-distribution\n(OOD) generalization. Finally, this statistical perspective of bidirectional\nattention enables us to theoretically characterize when linear word analogies\nare present in its word embeddings. These analyses show that bidirectional\nattention can require much stronger assumptions to exhibit linear word\nanalogies than its non-attention predecessors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wibisono_K/0/1/0/all/0/1\">Kevin Christian Wibisono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yixin Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ReLoRA: High-Rank Training Through Low-Rank Updates. (arXiv:2307.05695v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.05695","description":"<p>Despite the dominance and effectiveness of scaling, resulting in large\nnetworks with hundreds of billions of parameters, the necessity to train\noverparameterized models remains poorly understood, while training costs grow\nexponentially. In this paper, we explore parameter-efficient training\ntechniques as an approach to training large neural networks. We introduce a\nnovel method called ReLoRA, which utilizes low-rank updates to train high-rank\nnetworks. We apply ReLoRA to training transformer language models with up to\n1.3B parameters and demonstrate comparable performance to regular neural\nnetwork training. ReLoRA saves up to 5.5Gb of RAM per GPU and improves training\nspeed by 9-40% depending on the model size and hardware setup. Our findings\nshow the potential of parameter-efficient techniques for large-scale\npre-training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lialin_V/0/1/0/all/0/1\">Vladislav Lialin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shivagunde_N/0/1/0/all/0/1\">Namrata Shivagunde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muckatira_S/0/1/0/all/0/1\">Sherin Muckatira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rumshisky_A/0/1/0/all/0/1\">Anna Rumshisky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Misclassification in Automated Content Analysis Causes Bias in Regression. Can We Fix It? Yes We Can!. (arXiv:2307.06483v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2307.06483","description":"<p>Automated classifiers (ACs), often built via supervised machine learning\n(SML), can categorize large, statistically powerful samples of data ranging\nfrom text to images and video, and have become widely popular measurement\ndevices in communication science and related fields. Despite this popularity,\neven highly accurate classifiers make errors that cause misclassification bias\nand misleading results in downstream analyses-unless such analyses account for\nthese errors. As we show in a systematic literature review of SML applications,\ncommunication scholars largely ignore misclassification bias. In principle,\nexisting statistical methods can use \"gold standard\" validation data, such as\nthat created by human annotators, to correct misclassification bias and produce\nconsistent estimates. We introduce and test such methods, including a new\nmethod we design and implement in the R package misclassificationmodels, via\nMonte Carlo simulations designed to reveal each method's limitations, which we\nalso release. Based on our results, we recommend our new error correction\nmethod as it is versatile and efficient. In sum, automated classifiers, even\nthose below common accuracy standards or making systematic misclassifications,\ncan be useful for measurement with careful study design and appropriate error\ncorrection methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+TeBlunthuis_N/0/1/0/all/0/1\">Nathan TeBlunthuis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hase_V/0/1/0/all/0/1\">Valerie Hase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1\">Chung-Hong Chan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the (In)Effectiveness of Large Language Models for Chinese Text Correction. (arXiv:2307.09007v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.09007","description":"<p>Recently, the development and progress of Large Language Models (LLMs) have\namazed the entire Artificial Intelligence community. Benefiting from their\nemergent abilities, LLMs have attracted more and more researchers to study\ntheir capabilities and performance on various downstream Natural Language\nProcessing (NLP) tasks. While marveling at LLMs' incredible performance on all\nkinds of tasks, we notice that they also have excellent multilingual processing\ncapabilities, such as Chinese. To explore the Chinese processing ability of\nLLMs, we focus on Chinese Text Correction, a fundamental and challenging\nChinese NLP task. Specifically, we evaluate various representative LLMs on the\nChinese Grammatical Error Correction (CGEC) and Chinese Spelling Check (CSC)\ntasks, which are two main Chinese Text Correction scenarios. Additionally, we\nalso fine-tune LLMs for Chinese Text Correction to better observe the potential\ncapabilities of LLMs. From extensive analyses and comparisons with previous\nstate-of-the-art small models, we empirically find that the LLMs currently have\nboth amazing performance and unsatisfactory behavior for Chinese Text\nCorrection. We believe our findings will promote the landing and application of\nLLMs in the Chinese NLP community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinghui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haojing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shirong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yangning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1\">Feng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hai-Tao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qingyu Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education. (arXiv:2307.12267v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.12267","description":"<p>The recent large language models (LLMs), e.g., ChatGPT, have been able to\ngenerate human-like and fluent responses when provided with specific\ninstructions. While admitting the convenience brought by technological\nadvancement, educators also have concerns that students might leverage LLMs to\ncomplete their writing assignments and pass them off as their original work.\nAlthough many AI content detection studies have been conducted as a result of\nsuch concerns, most of these prior studies modeled AI content detection as a\nclassification problem, assuming that a text is either entirely human-written\nor entirely AI-generated. In this study, we investigated AI content detection\nin a rarely explored yet realistic setting where the text to be detected is\ncollaboratively written by human and generative LLMs (i.e., hybrid text). We\nfirst formalized the detection task as identifying the transition points\nbetween human-written content and AI-generated content from a given hybrid text\n(boundary detection). Then we proposed a two-step approach where we (1)\nseparated AI-generated content from human-written content during the encoder\ntraining process; and (2) calculated the distances between every two adjacent\nprototypes and assumed that the boundaries exist between the two adjacent\nprototypes that have the furthest distance from each other. Through extensive\nexperiments, we observed the following main findings: (1) the proposed approach\nconsistently outperformed the baseline methods across different experiment\nsettings; (2) the encoder training process can significantly boost the\nperformance of the proposed approach; (3) when detecting boundaries for\nsingle-boundary hybrid essays, the proposed approach could be enhanced by\nadopting a relatively large prototype size, leading to a 22% improvement in the\nIn-Domain evaluation and an 18% improvement in the Out-of-Domain evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1\">Zijie Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sha_L/0/1/0/all/0/1\">Lele Sha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kaixun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gasevic_D/0/1/0/all/0/1\">Dragan Ga&#x161;evi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guanliang Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Unforgeable Publicly Verifiable Watermark for Large Language Models. (arXiv:2307.16230v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.16230","description":"<p>Recently, text watermarking algorithms for large language models (LLMs) have\nbeen proposed to mitigate the potential harms of text generated by LLMs,\nincluding fake news and copyright issues. However, current watermark detection\nalgorithms require the secret key used in the watermark generation process,\nmaking them susceptible to security breaches and counterfeiting during public\ndetection. To address this limitation, we propose an unforgeable publicly\nverifiable watermark algorithm that uses two different neural networks for\nwatermark generation and detection, instead of using the same key at both\nstages. Meanwhile, the token embedding parameters are shared between the\ngeneration and detection networks, which makes the detection network achieve a\nhigh accuracy very efficiently. Experiments demonstrate that our algorithm\nattains high detection accuracy and computational efficiency through neural\nnetworks with a minimized number of parameters. Subsequent analysis confirms\nthe high complexity involved in forging the watermark from the detection\nnetwork. Our code and data are available at\n\\href{https://github.com/THU-BPM/unforgeable_watermark}{https://github.com/THU-BPM/unforgeable\\_watermark}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Aiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Leyi Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xuming Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shu&#x27;ang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1\">Lijie Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Causality Guided Disentanglement for Cross-Platform Hate Speech Detection. (arXiv:2308.02080v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.02080","description":"<p>Social media platforms, despite their value in promoting open discourse, are\noften exploited to spread harmful content. Current deep learning and natural\nlanguage processing models used for detecting this harmful content overly rely\non domain-specific terms affecting their capabilities to adapt to generalizable\nhate speech detection. This is because they tend to focus too narrowly on\nparticular linguistic signals or the use of certain categories of words.\nAnother significant challenge arises when platforms lack high-quality annotated\ndata for training, leading to a need for cross-platform models that can adapt\nto different distribution shifts. Our research introduces a cross-platform hate\nspeech detection model capable of being trained on one platform's data and\ngeneralizing to multiple unseen platforms. To achieve good generalizability\nacross platforms, one way is to disentangle the input representations into\ninvariant and platform-dependent features. We also argue that learning causal\nrelationships, which remain constant across diverse environments, can\nsignificantly aid in understanding invariant representations in hate speech. By\ndisentangling input into platform-dependent features (useful for predicting\nhate targets) and platform-independent features (used to predict the presence\nof hate), we learn invariant representations resistant to distribution shifts.\nThese features are then used to predict hate speech across unseen platforms.\nOur extensive experiments across four platforms highlight our model's enhanced\nefficacy compared to existing state-of-the-art methods in detecting generalized\nhate speech.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sheth_P/0/1/0/all/0/1\">Paras Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumarage_T/0/1/0/all/0/1\">Tharindu Kumarage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moraffah_R/0/1/0/all/0/1\">Raha Moraffah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Aligning Language Models with Offline Learning from Human Feedback. (arXiv:2308.12050v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.12050","description":"<p>Learning from human preferences is crucial for language models (LMs) to\neffectively cater to human needs and societal values. Previous research has\nmade notable progress by leveraging human feedback to follow instructions.\nHowever, these approaches rely primarily on online learning techniques like\nProximal Policy Optimization (PPO), which have been proven unstable and\nchallenging to tune for language models. Moreover, PPO requires complex\ndistributed system implementation, hindering the efficiency of large-scale\ndistributed training. In this study, we propose an offline learning from human\nfeedback framework to align LMs without interacting with environments.\nSpecifically, we explore filtering alignment (FA), reward-weighted regression\n(RWR), and conditional alignment (CA) to align language models to human\npreferences. By employing a loss function similar to supervised fine-tuning,\nour methods ensure more stable model training than PPO with a simple machine\nlearning system~(MLSys) and much fewer (around 9\\%) computing resources.\nExperimental results demonstrate that conditional alignment outperforms other\noffline alignment methods and is comparable to PPO.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_L/0/1/0/all/0/1\">Li Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">June Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chandler Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base Question Answering. (arXiv:2308.12060v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.12060","description":"<p>Knowledge base question answering (KBQA) is a critical yet challenging task\ndue to the vast number of entities within knowledge bases and the diversity of\nnatural language questions posed by users. Unfortunately, the performance of\nmost KBQA models tends to decline significantly in real-world scenarios where\nhigh-quality annotated data is insufficient. To mitigate the burden associated\nwith manual annotation, we introduce FlexKBQA by utilizing Large Language\nModels (LLMs) as program translators for addressing the challenges inherent in\nthe few-shot KBQA task. Specifically, FlexKBQA leverages automated algorithms\nto sample diverse programs, such as SPARQL queries, from the knowledge base,\nwhich are subsequently converted into natural language questions via LLMs. This\nsynthetic dataset facilitates training a specialized lightweight model for the\nKB. Additionally, to reduce the barriers of distribution shift between\nsynthetic data and real user questions, FlexKBQA introduces an executionguided\nself-training method to iterative leverage unlabeled user questions.\nFurthermore, we explore harnessing the inherent reasoning capability of LLMs to\nenhance the entire framework. Consequently, FlexKBQA delivers substantial\nflexibility, encompassing data annotation, deployment, and being domain\nagnostic. Through extensive experiments on GrailQA, WebQSP, and KQA Pro, we\nobserve that under the few-shot even the more challenging zero-shot scenarios,\nFlexKBQA achieves impressive results with a few annotations, surpassing all\nprevious baselines and even approaching the performance of supervised models,\nachieving a remarkable 93% performance relative to the fully-supervised models.\nWe posit that FlexKBQA represents a significant advancement towards exploring\nbetter integration of large and lightweight models. The code is open-sourced.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_S/0/1/0/all/0/1\">Sunqi Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yu Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiuxing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_Z/0/1/0/all/0/1\">Zhichao Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1\">Bowen Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianyong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating the Ebb and Flow: An In-depth Analysis of Question-Answering Trends across Diverse Platforms. (arXiv:2309.05961v3 [cs.SI] UPDATED)","link":"http://arxiv.org/abs/2309.05961","description":"<p>Community Question Answering (CQA) platforms steadily gain popularity as they\nprovide users with fast responses to their queries. The swiftness of these\nresponses is contingent on a mixture of query-specific and user-related\nelements. This paper scrutinizes these contributing factors within the context\nof six highly popular CQA platforms, identified through their standout\nanswering speed. Our investigation reveals a correlation between the time taken\nto yield the first response to a question and several variables: the metadata,\nthe formulation of the questions, and the level of interaction among users.\nAdditionally, by employing conventional machine learning models to analyze\nthese metadata and patterns of user interaction, we endeavor to predict which\nqueries will receive their initial responses promptly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hazra_R/0/1/0/all/0/1\">Rima Hazra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Agnik Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1\">Somnath Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1\">Animesh Mukherjee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bias and Fairness in Chatbots: An Overview. (arXiv:2309.08836v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.08836","description":"<p>Chatbots have been studied for more than half a century. With the rapid\ndevelopment of natural language processing (NLP) technologies in recent years,\nchatbots using large language models (LLMs) have received much attention\nnowadays. Compared with traditional ones, modern chatbots are more powerful and\nhave been used in real-world applications. There are however, bias and fairness\nconcerns in modern chatbot design. Due to the huge amounts of training data,\nextremely large model sizes, and lack of interpretability, bias mitigation and\nfairness preservation of modern chatbots are challenging. Thus, a comprehensive\noverview on bias and fairness in chatbot systems is given in this paper. The\nhistory of chatbots and their categories are first reviewed. Then, bias sources\nand potential harms in applications are analyzed. Considerations in designing\nfair and unbiased chatbot systems are examined. Finally, future research\ndirections are discussed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1\">Jintang Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yun-Cheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Chengwei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaofeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1\">Jonghye Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1\">C.-C. Jay Kuo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BELT:Bootstrapping Electroencephalography-to-Language Decoding and Zero-Shot Sentiment Classification by Natural Language Supervision. (arXiv:2309.12056v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2309.12056","description":"<p>This paper presents BELT, a novel model and learning framework for the\npivotal topic of brain-to-language translation research. The translation from\nnoninvasive brain signals into readable natural language has the potential to\npromote the application scenario as well as the development of brain-computer\ninterfaces (BCI) as a whole. The critical problem in brain signal decoding or\nbrain-to-language translation is the acquisition of semantically appropriate\nand discriminative EEG representation from a dataset of limited scale and\nquality. The proposed BELT method is a generic and efficient framework that\nbootstraps EEG representation learning using off-the-shelf large-scale\npretrained language models (LMs). With a large LM's capacity for understanding\nsemantic information and zero-shot generalization, BELT utilizes large LMs\ntrained on Internet-scale datasets to bring significant improvements to the\nunderstanding of EEG signals.\n</p>\n<p>In particular, the BELT model is composed of a deep conformer encoder and a\nvector quantization encoder. Semantical EEG representation is achieved by a\ncontrastive learning step that provides natural language supervision. We\nachieve state-of-the-art results on two featuring brain decoding tasks\nincluding the brain-to-language translation and zero-shot sentiment\nclassification. Specifically, our model surpasses the baseline model on both\ntasks by 5.45% and over 10% and archives a 42.31% BLEU-1 score and 67.32%\nprecision on the main evaluation metrics for translation and zero-shot\nsentiment classification respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jinzhao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1\">Yiqun Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yu-Cheng Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Kai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chin-Teng Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unify word-level and span-level tasks: NJUNLP's Participation for the WMT2023 Quality Estimation Shared Task. (arXiv:2309.13230v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.13230","description":"<p>We introduce the submissions of the NJUNLP team to the WMT 2023 Quality\nEstimation (QE) shared task. Our team submitted predictions for the\nEnglish-German language pair on all two sub-tasks: (i) sentence- and word-level\nquality prediction; and (ii) fine-grained error span detection. This year, we\nfurther explore pseudo data methods for QE based on NJUQE framework\n(https://github.com/NJUNLP/njuqe). We generate pseudo MQM data using parallel\ndata from the WMT translation task. We pre-train the XLMR large model on pseudo\nQE data, then fine-tune it on real QE data. At both stages, we jointly learn\nsentence-level scores and word-level tags. Empirically, we conduct experiments\nto find the key hyper-parameters that improve the performance. Technically, we\npropose a simple method that covert the word-level outputs to fine-grained\nerror span results. Overall, our models achieved the best results in\nEnglish-German for both word-level and fine-grained error span detection\nsub-tasks by a considerable margin.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xiang Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_Z/0/1/0/all/0/1\">Zhejian Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_S/0/1/0/all/0/1\">Shimin Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiajun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shujian Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TIGERScore: Towards Building Explainable Metric for All Text Generation Tasks. (arXiv:2310.00752v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.00752","description":"<p>We present TIGERScore, a \\textbf{T}rained metric that follows\n\\textbf{I}nstruction \\textbf{G}uidance to perform \\textbf{E}xplainable, and\n\\textbf{R}eference-free evaluation over a wide spectrum of text generation\ntasks. Different from other automatic evaluation methods that only provide\narcane scores, TIGERScore is guided by natural language instruction to provide\nerror analysis to pinpoint the mistakes in the generated text. Our metric is\nbased on LLaMA-2, trained on our meticulously curated instruction-tuning\ndataset MetricInstruct which covers 6 text generation tasks and 23 text\ngeneration datasets. The dataset consists of 42K quadruple in the form of\n(instruction, input, system output $\\rightarrow$ error analysis). We collected\nthe `system outputs' through from a large variety of models to cover different\ntypes of errors. To quantitatively assess our metric, we evaluate its\ncorrelation with human ratings on 5 held-in datasets, 2 held-out datasets and\nshow that TIGERScore can achieve the open-source SoTA correlation with human\nratings across these datasets and almost approaches GPT-4 evaluator. As a\nreference-free metric, its correlation can even surpass the best existing\nreference-based metrics. To further qualitatively assess the rationale\ngenerated by our metric, we conduct human evaluation on the generated\nexplanations and found that the explanations are 70.8\\% accurate. Through these\nexperimental results, we believe TIGERScore demonstrates the possibility of\nbuilding universal explainable metrics to evaluate any text generation task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Dongfu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yishan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Ge Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction. (arXiv:2310.03668v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.03668","description":"<p>Large Language Models (LLMs) combined with instruction tuning have made\nsignificant progress when generalizing to unseen tasks. However, they have been\nless successful in Information Extraction (IE), lagging behind task-specific\nmodels. Typically, IE tasks are characterized by complex annotation guidelines\nwhich describe the task and give examples to humans. Previous attempts to\nleverage such information have failed, even with the largest models, as they\nare not able to follow the guidelines out-of-the-box. In this paper we propose\nGoLLIE (Guideline-following Large Language Model for IE), a model able to\nimprove zero-shot results on unseen IE tasks by virtue of being fine-tuned to\ncomply with annotation guidelines. Comprehensive evaluation empirically\ndemonstrates that GoLLIE is able to generalize to and follow unseen guidelines,\noutperforming previous attempts at zero-shot information extraction. The\nablation study shows that detailed guidelines is key for good results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sainz_O/0/1/0/all/0/1\">Oscar Sainz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Ferrero_I/0/1/0/all/0/1\">Iker Garc&#xed;a-Ferrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agerri_R/0/1/0/all/0/1\">Rodrigo Agerri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lacalle_O/0/1/0/all/0/1\">Oier Lopez de Lacalle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rigau_G/0/1/0/all/0/1\">German Rigau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agirre_E/0/1/0/all/0/1\">Eneko Agirre</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Instructive Dialogue Summarization with Query Aggregations. (arXiv:2310.10981v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10981","description":"<p>Conventional dialogue summarization methods directly generate summaries and\ndo not consider user's specific interests. This poses challenges in cases where\nthe users are more focused on particular topics or aspects. With the\nadvancement of instruction-finetuned language models, we introduce\ninstruction-tuning to dialogues to expand the capability set of dialogue\nsummarization models. To overcome the scarcity of instructive dialogue\nsummarization data, we propose a three-step approach to synthesize high-quality\nquery-based summarization triples. This process involves summary-anchored query\ngeneration, query filtering, and query-based summary generation. By training a\nunified model called InstructDS (Instructive Dialogue Summarization) on three\nsummarization datasets with multi-purpose instructive triples, we expand the\ncapability of dialogue summarization models. We evaluate our method on four\ndatasets, including dialogue summarization and dialogue reading comprehension.\nExperimental results show that our approach outperforms the state-of-the-art\nmodels and even models with larger sizes. Additionally, our model exhibits\nhigher generalizability and faithfulness, as confirmed by human subjective\nevaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nancy F. Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models. (arXiv:2310.13191v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.13191","description":"<p>The pruning objective has recently extended beyond accuracy and sparsity to\nrobustness in language models. Despite this, existing methods struggle to\nenhance robustness against adversarial attacks when continually increasing\nmodel sparsity and require a retraining process. As humans step into the era of\nlarge language models, these issues become increasingly prominent. This paper\nproposes that the robustness of language models is proportional to the extent\nof pre-trained knowledge they encompass. Accordingly, we introduce a\npost-training pruning strategy designed to faithfully replicate the embedding\nspace and feature space of dense language models, aiming to conserve more\npre-trained knowledge during the pruning process. In this setup, each layer's\nreconstruction error not only originates from itself but also includes\ncumulative error from preceding layers, followed by an adaptive rectification.\nCompared to other state-of-art baselines, our approach demonstrates a superior\nbalance between accuracy, sparsity, robustness, and pruning cost with BERT on\ndatasets SST2, IMDB, and AGNews, marking a significant stride towards robust\npruning in language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Q/0/1/0/all/0/1\">Qi Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Dongkuan Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SSLCL: An Efficient Model-Agnostic Supervised Contrastive Learning Framework for Emotion Recognition in Conversations. (arXiv:2310.16676v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.16676","description":"<p>Emotion recognition in conversations (ERC) is a rapidly evolving task within\nthe natural language processing community, which aims to detect the emotions\nexpressed by speakers during a conversation. Recently, a growing number of ERC\nmethods have focused on leveraging supervised contrastive learning (SCL) to\nenhance the robustness and generalizability of learned features. However,\ncurrent SCL-based approaches in ERC are impeded by the constraint of large\nbatch sizes and the lack of compatibility with most existing ERC models. To\naddress these challenges, we propose an efficient and model-agnostic SCL\nframework named Supervised Sample-Label Contrastive Learning with Soft-HGR\nMaximal Correlation (SSLCL), which eliminates the need for a large batch size\nand can be seamlessly integrated with existing ERC models without introducing\nany model-specific assumptions. Specifically, we introduce a novel perspective\non utilizing label representations by projecting discrete labels into dense\nembeddings through a shallow multilayer perceptron, and formulate the training\nobjective to maximize the similarity between sample features and their\ncorresponding ground-truth label embeddings, while minimizing the similarity\nbetween sample features and label embeddings of disparate classes. Moreover, we\ninnovatively adopt the Soft-HGR maximal correlation as a measure of similarity\nbetween sample features and label embeddings, leading to significant\nperformance improvements over conventional similarity measures. Additionally,\nmultimodal cues of utterances are effectively leveraged by SSLCL as data\naugmentations to boost model performances. Extensive experiments on two ERC\nbenchmark datasets, IEMOCAP and MELD, demonstrate the compatibility and\nsuperiority of our proposed SSLCL framework compared to existing\nstate-of-the-art SCL methods. Our code is available at\n\\url{https://github.com/TaoShi1998/SSLCL}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1\">Tao Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yaoyuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_X/0/1/0/all/0/1\">Xinyi Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shao-Lun Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"You Are An Expert Linguistic Annotator\": Limits of LLMs as Analyzers of Abstract Meaning Representation. (arXiv:2310.17793v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.17793","description":"<p>Large language models (LLMs) show amazing proficiency and fluency in the use\nof language. Does this mean that they have also acquired insightful linguistic\nknowledge about the language, to an extent that they can serve as an \"expert\nlinguistic annotator\"? In this paper, we examine the successes and limitations\nof the GPT-3, ChatGPT, and GPT-4 models in analysis of sentence meaning\nstructure, focusing on the Abstract Meaning Representation (AMR; Banarescu et\nal. 2013) parsing formalism, which provides rich graphical representations of\nsentence meaning structure while abstracting away from surface forms. We\ncompare models' analysis of this semantic structure across two settings: 1)\ndirect production of AMR parses based on zero- and few-shot prompts, and 2)\nindirect partial reconstruction of AMR via metalinguistic natural language\nqueries (e.g., \"Identify the primary event of this sentence, and the predicate\ncorresponding to that event.\"). Across these settings, we find that models can\nreliably reproduce the basic format of AMR, and can often capture core event,\nargument, and modifier structure -- however, model outputs are prone to\nfrequent and major errors, and holistic analysis of parse acceptability shows\nthat even with few-shot demonstrations, models have virtually 0% success in\nproducing fully accurate parses. Eliciting natural language responses produces\nsimilar patterns of errors. Overall, our findings indicate that these models\nout-of-the-box can capture aspects of semantic structure, but there remain key\nlimitations in their ability to support fully accurate semantic analyses or\nparses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ettinger_A/0/1/0/all/0/1\">Allyson Ettinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1\">Jena D. Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pyatkin_V/0/1/0/all/0/1\">Valentina Pyatkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhagavatula_C/0/1/0/all/0/1\">Chandra Bhagavatula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"JADE: A Linguistics-based Safety Evaluation Platform for Large Language Models. (arXiv:2311.00286v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.00286","description":"<p>In this paper, we present JADE, a targeted linguistic fuzzing platform which\nstrengthens the linguistic complexity of seed questions to simultaneously and\nconsistently break a wide range of widely-used LLMs categorized in three\ngroups: eight open-sourced Chinese, six commercial Chinese and four commercial\nEnglish LLMs. JADE generates three safety benchmarks for the three groups of\nLLMs, which contain unsafe questions that are highly threatening: the questions\nsimultaneously trigger harmful generation of multiple LLMs, with an average\nunsafe generation ratio of $70\\%$ (please see the table below), while are still\nnatural questions, fluent and preserving the core unsafe semantics. We release\nthe benchmark demos generated for commercial English LLMs and open-sourced\nEnglish LLMs in the following link: https://github.com/whitzard-ai/jade-db. For\nreaders who are interested in evaluating on more questions generated by JADE,\nplease contact us.\n</p>\n<p>JADE is based on Noam Chomsky's seminal theory of transformational-generative\ngrammar. Given a seed question with unsafe intention, JADE invokes a sequence\nof generative and transformational rules to increment the complexity of the\nsyntactic structure of the original question, until the safety guardrail is\nbroken. Our key insight is: Due to the complexity of human language, most of\nthe current best LLMs can hardly recognize the invariant evil from the infinite\nnumber of different syntactic structures which form an unbound example space\nthat can never be fully covered. Technically, the generative/transformative\nrules are constructed by native speakers of the languages, and, once developed,\ncan be used to automatically grow and transform the parse tree of a given\nquestion, until the guardrail is broken. For more evaluation results and demo,\nplease check our website: https://whitzard-ai.github.io/jade.html.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xudong Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Min Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis- and Disinformation. (arXiv:2311.01766v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.01766","description":"<p>Mis- and disinformation online have become a major societal problem as major\nsources of online harms of different kinds. One common form of mis- and\ndisinformation is out-of-context (OOC) information, where different pieces of\ninformation are falsely associated, e.g., a real image combined with a false\ntextual caption or a misleading textual description. Although some past studies\nhave attempted to defend against OOC mis- and disinformation through external\nevidence, they tend to disregard the role of different pieces of evidence with\ndifferent stances. Motivated by the intuition that the stance of evidence\nrepresents a bias towards different detection results, we propose a stance\nextraction network (SEN) that can extract the stances of different pieces of\nmulti-modal evidence in a unified framework. Moreover, we introduce a\nsupport-refutation score calculated based on the co-occurrence relations of\nnamed entities into the textual SEN. Extensive experiments on a public\nlarge-scale dataset demonstrated that our proposed method outperformed the\nstate-of-the-art baselines, with the best model achieving a performance gain of\n3.2% in accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jie Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_W/0/1/0/all/0/1\">Weidong Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zheng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shujun Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explainable Identification of Hate Speech towards Islam using Graph Neural Networks. (arXiv:2311.04916v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.04916","description":"<p>Islamophobic language is a prevalent challenge on online social interaction\nplatforms. Identifying and eliminating such hatred is a crucial step towards a\nfuture of harmony and peace. This study presents a novel paradigm for\nidentifying and explaining hate speech towards Islam using graph neural\nnetworks. Utilizing the intrinsic ability of graph neural networks to find,\nextract, and use relationships across disparate data points, our model\nconsistently achieves outstanding performance while offering explanations for\nthe underlying correlations and causation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wasi_A/0/1/0/all/0/1\">Azmine Toushik Wasi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey of Large Language Models in Medicine: Principles, Applications, and Challenges. (arXiv:2311.05112v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.05112","description":"<p>Large language models (LLMs), such as ChatGPT, have received substantial\nattention due to their impressive human language understanding and generation\ncapabilities. Therefore, the application of LLMs in medicine to assist\nphysicians and patient care emerges as a promising research direction in both\nartificial intelligence and clinical medicine. To reflect this trend, this\nsurvey provides a comprehensive overview of the principles, applications, and\nchallenges faced by LLMs in medicine. Specifically, we aim to address the\nfollowing questions: 1) How can medical LLMs be built? 2) What are the\ndownstream performances of medical LLMs? 3) How can medical LLMs be utilized in\nreal-world clinical practice? 4) What challenges arise from the use of medical\nLLMs? and 5) How can we better construct and utilize medical LLMs? As a result,\nthis survey aims to provide insights into the opportunities and challenges of\nLLMs in medicine and serve as a valuable resource for constructing practical\nand effective medical LLMs. A regularly updated list of practical guides on\nmedical LLMs can be found at\nhttps://github.com/AI-in-Health/MedLLMsPracticalGuide.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hongjian Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fenglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_B/0/1/0/all/0/1\">Boyang Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1\">Xinyu Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jinfa Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jinge Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yiru Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sam S. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Peilin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Junling Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1\">Yining Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_C/0/1/0/all/0/1\">Chengfeng Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifton_L/0/1/0/all/0/1\">Lei Clifton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jiebo Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1\">David A. Clifton</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The WebCrow French Crossword Solver. (arXiv:2311.15626v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.15626","description":"<p>Crossword puzzles are one of the most popular word games, played in different\nlanguages all across the world, where riddle style can vary significantly from\none country to another. Automated crossword resolution is challenging, and\ntypical solvers rely on large databases of previously solved crosswords. In\nthis work, we extend WebCrow 2.0, an automatic crossword solver, to French,\nmaking it the first program for crossword solving in the French language. To\ncope with the lack of a large repository of clue-answer crossword data, WebCrow\n2.0 exploits multiple modules, called experts, that retrieve candidate answers\nfrom heterogeneous resources, such as the web, knowledge graphs, and linguistic\nrules. We compared WebCrow's performance against humans in two different\nchallenges. Despite the limited amount of past crosswords, French WebCrow was\ncompetitive, actually outperforming humans in terms of speed and accuracy, thus\nproving its capabilities to generalize to new languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Angelini_G/0/1/0/all/0/1\">Giovanni Angelini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ernandes_M/0/1/0/all/0/1\">Marco Ernandes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+laquinta_T/0/1/0/all/0/1\">Tommaso laquinta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stehle_C/0/1/0/all/0/1\">Caroline Stehl&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simoes_F/0/1/0/all/0/1\">Fanny Sim&#xf5;es</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeinalipour_K/0/1/0/all/0/1\">Kamyar Zeinalipour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zugarini_A/0/1/0/all/0/1\">Andrea Zugarini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1\">Marco Gori</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ascle: A Python Natural Language Processing Toolkit for Medical Text Generation. (arXiv:2311.16588v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.16588","description":"<p>This study introduces Ascle, a pioneering natural language processing (NLP)\ntoolkit designed for medical text generation. Ascle is tailored for biomedical\nresearchers and healthcare professionals with an easy-to-use, all-in-one\nsolution that requires minimal programming expertise. For the first time, Ascle\nevaluates and provides interfaces for the latest pre-trained language models,\nencompassing four advanced and challenging generative functions:\nquestion-answering, text summarization, text simplification, and machine\ntranslation. In addition, Ascle integrates 12 essential NLP functions, along\nwith query and search capabilities for clinical databases. The toolkit, its\nmodels, and associated data are publicly available via\nhttps://github.com/Yale-LILY/MedGen.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Rui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Q/0/1/0/all/0/1\">Qingcheng Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_K/0/1/0/all/0/1\">Keen You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yujie Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Lucas Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Chia-Chun Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosand_B/0/1/0/all/0/1\">Benjamin Rosand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldwasser_J/0/1/0/all/0/1\">Jeremy Goldwasser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dave_A/0/1/0/all/0/1\">Amisha D Dave</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keenan_T/0/1/0/all/0/1\">Tiarnan D.L. Keenan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chew_E/0/1/0/all/0/1\">Emily Y Chew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiyong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hua Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1\">Irene Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"I Know You Did Not Write That! A Sampling Based Watermarking Method for Identifying Machine Generated Text. (arXiv:2311.18054v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.18054","description":"<p>Potential harms of Large Language Models such as mass misinformation and\nplagiarism can be partially mitigated if there exists a reliable way to detect\nmachine generated text. In this paper, we propose a new watermarking method to\ndetect machine-generated texts. Our method embeds a unique pattern within the\ngenerated text, ensuring that while the content remains coherent and natural to\nhuman readers, it carries distinct markers that can be identified\nalgorithmically. Specifically, we intervene with the token sampling process in\na way which enables us to trace back our token choices during the detection\nphase. We show how watermarking affects textual quality and compare our\nproposed method with a state-of-the-art watermarking method in terms of\nrobustness and detectability. Through extensive experiments, we demonstrate the\neffectiveness of our watermarking scheme in distinguishing between watermarked\nand non-watermarked text, achieving high detection rates while maintaining\ntextual quality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Keles_K/0/1/0/all/0/1\">Kaan Efe Kele&#x15f;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurbuz_O/0/1/0/all/0/1\">&#xd6;mer Kaan G&#xfc;rb&#xfc;z</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutlu_M/0/1/0/all/0/1\">Mucahid Kutlu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TaskBench: Benchmarking Large Language Models for Task Automation. (arXiv:2311.18760v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.18760","description":"<p>Recently, the incredible progress of large language models (LLMs) has ignited\nthe spark of task automation, which decomposes the complex tasks described by\nuser instructions into sub-tasks, and invokes external tools to execute them,\nand plays a central role in autonomous agents. However, there lacks a\nsystematic and standardized benchmark to foster the development of LLMs in task\nautomation. To this end, we introduce TaskBench to evaluate the capability of\nLLMs in task automation. Specifically, task automation can be formulated into\nthree critical stages: task decomposition, tool invocation, and parameter\nprediction to fulfill user intent. This complexity makes data collection and\nevaluation more challenging compared to common NLP tasks. To generate\nhigh-quality evaluation datasets, we introduce the concept of Tool Graph to\nrepresent the decomposed tasks in user intent, and adopt a back-instruct method\nto simulate user instruction and annotations. Furthermore, we propose TaskEval\nto evaluate the capability of LLMs from different aspects, including task\ndecomposition, tool invocation, and parameter prediction. Experimental results\ndemonstrate that TaskBench can effectively reflects the capability of LLMs in\ntask automation. Benefiting from the mixture of automated data construction and\nhuman verification, TaskBench achieves a high consistency compared to the human\nevaluation, which can be utilized as a comprehensive and faithful benchmark for\nLLM-based autonomous agents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yongliang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kaitao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_K/0/1/0/all/0/1\">Kan Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1\">Siyu Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Weiming Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1\">Yueting Zhuang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ArabIcros: AI-Powered Arabic Crossword Puzzle Generation for Educational Applications. (arXiv:2312.01339v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.01339","description":"<p>This paper presents the first Arabic crossword puzzle generator driven by\nadvanced AI technology. Leveraging cutting-edge large language models including\nGPT4, GPT3-Davinci, GPT3-Curie, GPT3-Babbage, GPT3-Ada, and BERT, the system\ngenerates distinctive and challenging clues. Based on a dataset comprising over\n50,000 clue-answer pairs, the generator employs fine-tuning, few/zero-shot\nlearning strategies, and rigorous quality-checking protocols to enforce the\ngeneration of high-quality clue-answer pairs. Importantly, educational\ncrosswords contribute to enhancing memory, expanding vocabulary, and promoting\nproblem-solving skills, thereby augmenting the learning experience through a\nfun and engaging approach, reshaping the landscape of traditional learning\nmethods. The overall system can be exploited as a powerful educational tool\nthat amalgamates AI and innovative learning techniques, heralding a\ntransformative era for Arabic crossword puzzles and the intersection of\ntechnology and education.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeinalipour_K/0/1/0/all/0/1\">Kamyar Zeinalipour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saad_M/0/1/0/all/0/1\">Mohamed Zaky Saad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maggini_M/0/1/0/all/0/1\">Marco Maggini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1\">Marco Gori</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Characterizing Large Language Model Geometry Solves Toxicity Detection and Generation. (arXiv:2312.01648v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2312.01648","description":"<p>Large Language Models~(LLMs) drive current AI breakthroughs despite very\nlittle being known about their internal representations, e.g., how to extract a\nfew informative features to solve various downstream tasks. To provide a\npractical and principled answer, we propose to characterize LLMs from a\ngeometric perspective. We obtain in closed form (i) the intrinsic dimension in\nwhich the Multi-Head Attention embeddings are constrained to exist and (ii) the\npartition and per-region affine mappings of the per-layer feedforward networks.\nOur results are informative, do not rely on approximations, and are actionable.\nFirst, we show that, motivated by our geometric interpretation, we can bypass\nLlama$2$'s RLHF by controlling its embedding's intrinsic dimension through\ninformed prompt manipulation. Second, we derive $7$ interpretable spline\nfeatures that can be extracted from any (pre-trained) LLM layer, providing a\nrich abstract representation of their inputs. Those features alone ($224$ for\nMistral-7B/Llama$2$-7B and $560$ for Llama$2$-70B) are sufficient to help solve\ntoxicity detection, infer the domain of the prompt, and even tackle the Jigsaw\nchallenge, which aims at characterizing the type of toxicity of various\nprompts. Our results demonstrate how, even in large-scale regimes, exact\ntheoretical results can answer practical questions in language models. Code:\n\\url{https://github.com/RandallBalestriero/SplineLLM}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cosentino_R/0/1/0/all/0/1\">Romain Cosentino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shekkizhar_S/0/1/0/all/0/1\">Sarath Shekkizhar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Online Data Mixing For Language Model Pre-Training. (arXiv:2312.02406v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.02406","description":"<p>The data used to pretrain large language models has a decisive impact on a\nmodel's downstream performance, which has led to a large body of work on data\nselection methods that aim to automatically determine the most suitable data to\nuse for pretraining. Existing data selection methods suffer from slow and\ncomputationally expensive processes, a problem amplified by the increasing size\nof models and of pretraining datasets. Data mixing, on the other hand, reduces\nthe complexity of data selection by grouping data points together and\ndetermining sampling probabilities across entire groups. However, data mixing\nproportions are typically fixed before training and therefore cannot adapt to\nchanging training dynamics. To address these limitations, we develop an\nefficient algorithm for Online Data Mixing (ODM) that combines elements from\nboth data selection and data mixing. Based on multi-armed bandit algorithms,\nour online approach optimizes the data mixing proportions during training.\nRemarkably, our method trains a model that reaches the final perplexity of the\nnext best method with 19\\% fewer training iterations, and improves performance\non the 5-shot MMLU benchmark by 1.9% relative accuracy, while adding negligible\nwall-clock time during pretraining.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Albalak_A/0/1/0/all/0/1\">Alon Albalak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Liangming Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Holmes: Towards Distributed Training Across Clusters with Heterogeneous NIC Environment. (arXiv:2312.03549v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.03549","description":"<p>Large language models (LLMs) such as GPT-3, OPT, and LLaMA have demonstrated\nremarkable accuracy in a wide range of tasks. However, training these models\ncan incur significant expenses, often requiring tens of thousands of GPUs for\nmonths of continuous operation. Typically, this training is carried out in\nspecialized GPU clusters equipped with homogeneous high-speed Remote Direct\nMemory Access (RDMA) network interface cards (NICs). The acquisition and\nmaintenance of such dedicated clusters is challenging. Current LLM training\nframeworks, like Megatron-LM and Megatron-DeepSpeed, focus primarily on\noptimizing training within homogeneous cluster settings. In this paper, we\nintroduce Holmes, a training framework for LLMs that employs thoughtfully\ncrafted data and model parallelism strategies over the heterogeneous NIC\nenvironment. Our primary technical contribution lies in a novel scheduling\nmethod that intelligently allocates distinct computational tasklets in LLM\ntraining to specific groups of GPU devices based on the characteristics of\ntheir connected NICs. Furthermore, our proposed framework, utilizing pipeline\nparallel techniques, demonstrates scalability to multiple GPU clusters, even in\nscenarios without high-speed interconnects between nodes in distinct clusters.\nWe conducted comprehensive experiments that involved various scenarios in the\nheterogeneous NIC environment. In most cases, our framework achieves\nperformance levels close to those achievable with homogeneous RDMA-capable\nnetworks (InfiniBand or RoCE), significantly exceeding training efficiency\nwithin the pure Ethernet environment. Additionally, we verified that our\nframework outperforms other mainstream LLM frameworks under heterogeneous NIC\nenvironment in terms of training efficiency and can be seamlessly integrated\nwith them.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1\">Shuang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_N/0/1/0/all/0/1\">Ning Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fangyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_K/0/1/0/all/0/1\">Ke Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1\">Jiezhong Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_A/0/1/0/all/0/1\">Aimin Pan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FakeWatch ElectionShield: A Benchmarking Framework to Detect Fake News for Credible US Elections. (arXiv:2312.03730v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.03730","description":"<p>In today's technologically driven world, the spread of fake news,\nparticularly during crucial events such as elections, presents an increasing\nchallenge to the integrity of information. To address this challenge, we\nintroduce FakeWatch ElectionShield, an innovative framework carefully designed\nto detect fake news. We have created a novel dataset of North American\nelection-related news articles through a blend of advanced language models\n(LMs) and thorough human verification, for precision and relevance. We propose\na model hub of LMs for identifying fake news. Our goal is to provide the\nresearch community with adaptable and accurate classification models in\nrecognizing the dynamic nature of misinformation. Extensive evaluation of fake\nnews classifiers on our dataset and a benchmark dataset shows our that while\nstate-of-the-art LMs slightly outperform the traditional ML models, classical\nmodels are still competitive with their balance of accuracy, explainability,\nand computational efficiency. This research sets the foundation for future\nstudies to address misinformation related to elections.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khan_T/0/1/0/all/0/1\">Tahniat Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Mizanur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatrath_V/0/1/0/all/0/1\">Veronica Chatrath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamgbose_O/0/1/0/all/0/1\">Oluwanifemi Bamgbose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raza_S/0/1/0/all/0/1\">Shaina Raza</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem. (arXiv:2312.03815v2 [cs.OS] UPDATED)","link":"http://arxiv.org/abs/2312.03815","description":"<p>This paper envisions a revolutionary AIOS-Agent ecosystem, where Large\nLanguage Model (LLM) serves as the (Artificial) Intelligent Operating System\n(IOS, or AIOS)--an operating system \"with soul\". Upon this foundation, a\ndiverse range of LLM-based AI Agent Applications (Agents, or AAPs) are\ndeveloped, enriching the AIOS-Agent ecosystem and signaling a paradigm shift\nfrom the traditional OS-APP ecosystem. We envision that LLM's impact will not\nbe limited to the AI application level, instead, it will in turn revolutionize\nthe design and implementation of computer system, architecture, software, and\nprogramming language, featured by several main concepts: LLM as OS\n(system-level), Agents as Applications (application-level), Natural Language as\nProgramming Interface (user-level), and Tools as Devices/Libraries\n(hardware/middleware-level). We begin by introducing the architecture of\ntraditional OS. Then we formalize a conceptual framework for AIOS through \"LLM\nas OS (LLMOS)\", drawing analogies between AIOS and traditional OS: LLM is\nlikened to OS kernel, context window to memory, external storage to file\nsystem, hardware tools to peripheral devices, software tools to programming\nlibraries, and user prompts to user commands. Subsequently, we introduce the\nnew AIOS-Agent Ecosystem, where users can easily program Agent Applications\n(AAPs) using natural language, democratizing the development of software, which\nis different from the traditional OS-APP ecosystem. Following this, we explore\nthe diverse scope of Agent Applications. We delve into both single-agent and\nmulti-agent systems, as well as human-agent interaction. Lastly, drawing on the\ninsights from traditional OS-APP ecosystem, we propose a roadmap for the\nevolution of the AIOS-Agent ecosystem. This roadmap is designed to guide the\nfuture research and development, suggesting systematic progresses of AIOS and\nits Agent applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yujie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wenyue Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1\">Juntao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Study on the Calibration of In-context Learning. (arXiv:2312.04021v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.04021","description":"<p>Modern auto-regressive language models are trained to minimize log loss on\nbroad data by predicting the next token so they are expected to get calibrated\nanswers in next-token prediction tasks. We study this for in-context learning\n(ICL), a widely used way to adapt frozen large language models (LLMs) via\ncrafting prompts, and investigate the trade-offs between performance and\ncalibration on a wide range of natural language understanding and reasoning\ntasks. We conduct extensive experiments to show that such trade-offs may get\nworse as we increase model size, incorporate more ICL examples, and fine-tune\nmodels using instruction, dialog, or reinforcement learning from human feedback\n(RLHF) on carefully curated datasets. Furthermore, we find that common\nrecalibration techniques that are widely effective such as temperature scaling\nprovide limited gains in calibration errors, suggesting that new methods may be\nrequired for settings where models are expected to be reliable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hanlin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi-Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madeka_D/0/1/0/all/0/1\">Dhruv Madeka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1\">Dean Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Hima Lakkaraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham Kakade</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interpretability in Activation Space Analysis of Transformers: A Focused Survey. (arXiv:2302.09304v1 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2302.09304","description":"<p>The field of natural language processing has reached breakthroughs with the\nadvent of transformers. They have remained state-of-the-art since then, and\nthere also has been much research in analyzing, interpreting, and evaluating\nthe attention layers and the underlying embedding space. In addition to the\nself-attention layers, the feed-forward layers in the transformer are a\nprominent architectural component. From extensive research, we observe that its\nrole is under-explored. We focus on the latent space, known as the Activation\nSpace, that consists of the neuron activations from these feed-forward layers.\nIn this survey paper, we review interpretability methods that examine the\nlearnings that occurred in this activation space. Since there exists only\nlimited research in this direction, we conduct a detailed examination of each\nwork and point out potential future directions of research. We hope our work\nprovides a step towards strengthening activation space analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vijayakumar_S/0/1/0/all/0/1\">Soniya Vijayakumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual Questions. (arXiv:2308.09936v2 [cs.CV] CROSS LISTED)","link":"http://arxiv.org/abs/2308.09936","description":"<p>Vision Language Models (VLMs), which extend Large Language Models (LLM) by\nincorporating visual understanding capability, have demonstrated significant\nadvancements in addressing open-ended visual question-answering (VQA) tasks.\nHowever, these models cannot accurately interpret images infused with text, a\ncommon occurrence in real-world scenarios. Standard procedures for extracting\ninformation from images often involve learning a fixed set of query embeddings.\nThese embeddings are designed to encapsulate image contexts and are later used\nas soft prompt inputs in LLMs. Yet, this process is limited to the token count,\npotentially curtailing the recognition of scenes with text-rich context. To\nimprove upon them, the present study introduces BLIVA: an augmented version of\nInstructBLIP with Visual Assistant. BLIVA incorporates the query embeddings\nfrom InstructBLIP and also directly projects encoded patch embeddings into the\nLLM, a technique inspired by LLaVA. This approach assists the model to capture\nintricate details potentially missed during the query decoding process.\nEmpirical evidence demonstrates that our model, BLIVA, significantly enhances\nperformance in processing text-rich VQA benchmarks (up to 17.76% in OCR-VQA\nbenchmark) and in undertaking general (not particularly text-rich) VQA\nbenchmarks (up to 7.9% in Visual Spatial Reasoning benchmark), comparing to our\nbaseline InstructBLIP. BLIVA demonstrates significant capability in decoding\nreal-world images, irrespective of text presence. To demonstrate the broad\nindustry applications enabled by BLIVA, we evaluate the model using a new\ndataset comprising YouTube thumbnails paired with question-answer sets across\n11 diverse categories. For researchers interested in further exploration, our\ncode and models are freely accessible at https://github.com/mlpc-ucsd/BLIVA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wenbo Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yifan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weiyue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhuowen Tu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-12-11T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/"}}]}]}