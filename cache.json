{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-11-23T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"MSG-BART: Multi-granularity Scene Graph-Enhanced Encoder-Decoder Language Model for Video-grounded Dialogue Generation. (arXiv:2311.12820v1 [cs.CV])","link":"http://arxiv.org/abs/2311.12820","description":"<p>Generating dialogue grounded in videos requires a high level of understanding\nand reasoning about the visual scenes in the videos. However, existing large\nvisual-language models are not effective due to their latent features and\ndecoder-only structure, especially with respect to spatio-temporal relationship\nreasoning. In this paper, we propose a novel approach named MSG-BART, which\nenhances the integration of video information by incorporating a\nmulti-granularity spatio-temporal scene graph into an encoder-decoder\npre-trained language model. Specifically, we integrate the global and local\nscene graph into the encoder and decoder, respectively, to improve both overall\nperception and target reasoning capability. To further improve the information\nselection capability, we propose a multi-pointer network to facilitate\nselection between text and video. Extensive experiments are conducted on three\nvideo-grounded dialogue benchmarks, which show the significant superiority of\nthe proposed MSG-BART compared to a range of state-of-the-art approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hongcheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhe Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pingjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HPC-GPT: Integrating Large Language Model for High-Performance Computing. (arXiv:2311.12833v1 [cs.DC])","link":"http://arxiv.org/abs/2311.12833","description":"<p>Large Language Models (LLMs), including the LLaMA model, have exhibited their\nefficacy across various general-domain natural language processing (NLP) tasks.\nHowever, their performance in high-performance computing (HPC) domain tasks has\nbeen less than optimal due to the specialized expertise required to interpret\nthe model responses. In response to this challenge, we propose HPC-GPT, a novel\nLLaMA-based model that has been supervised fine-tuning using generated QA\n(Question-Answer) instances for the HPC domain. To evaluate its effectiveness,\nwe concentrate on two HPC tasks: managing AI models and datasets for HPC, and\ndata race detection. By employing HPC-GPT, we demonstrate comparable\nperformance with existing methods on both tasks, exemplifying its excellence in\nHPC-related scenarios. Our experiments on open-source benchmarks yield\nextensive results, underscoring HPC-GPT's potential to bridge the performance\ngap between LLMs and HPC-specific tasks. With HPC-GPT, we aim to pave the way\nfor LLMs to excel in HPC domains, simplifying the utilization of language\nmodels in complex computing applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xianzhong Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Le Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emani_M/0/1/0/all/0/1\">Murali Emani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1\">Chunhua Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_P/0/1/0/all/0/1\">Pei-Hung Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vanderbruggen_T/0/1/0/all/0/1\">Tristan Vanderbruggen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zhen Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cerpa_A/0/1/0/all/0/1\">Alberto E. Cerpa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_W/0/1/0/all/0/1\">Wan Du</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modular Blended Attention Network for Video Question Answering. (arXiv:2311.12866v1 [cs.CV])","link":"http://arxiv.org/abs/2311.12866","description":"<p>In multimodal machine learning tasks, it is due to the complexity of the\nassignments that the network structure, in most cases, is assembled in a\nsophisticated way. The holistic architecture can be separated into several\nlogical parts according to the respective ends that the modules are devised to\nachieve. As the number of modalities of information representation increases,\nconstructing ad hoc subnetworks for processing the data from divergent\nmodalities while mediating the fusion of different information types has become\na cumbersome and expensive problem. In this paper, we present an approach to\nfacilitate the question with a reusable and composable neural unit; by\nconnecting the units in series or parallel, the arduous network constructing of\nmultimodal machine learning tasks will be accomplished in a much\nstraightforward way. Additionally, through parameter sharing (weights\nreplication) among the units, the space complexity will be significantly\nreduced. We have conducted experiments on three commonly used datasets; our\nmethod achieves impressive performance compared to several video QA baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingjie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Embodied Generalist Agent in 3D World. (arXiv:2311.12871v1 [cs.CV])","link":"http://arxiv.org/abs/2311.12871","description":"<p>Leveraging massive knowledge and learning schemes from large language models\n(LLMs), recent machine learning models show notable successes in building\ngeneralist agents that exhibit the capability of general-purpose task solving\nin diverse domains, including natural language processing, computer vision, and\nrobotics. However, a significant challenge remains as these models exhibit\nlimited ability in understanding and interacting with the 3D world. We argue\nthis limitation significantly hinders the current models from performing\nreal-world tasks and further achieving general intelligence. To this end, we\nintroduce an embodied multi-modal and multi-task generalist agent that excels\nin perceiving, grounding, reasoning, planning, and acting in the 3D world. Our\nproposed agent, referred to as LEO, is trained with shared LLM-based model\narchitectures, objectives, and weights in two stages: (i) 3D vision-language\nalignment and (ii) 3D vision-language-action instruction tuning. To facilitate\nthe training, we meticulously curate and generate an extensive dataset\ncomprising object-level and scene-level multi-modal tasks with exceeding scale\nand complexity, necessitating a deep understanding of and interaction with the\n3D world. Through rigorous experiments, we demonstrate LEO's remarkable\nproficiency across a wide spectrum of tasks, including 3D captioning, question\nanswering, embodied reasoning, embodied navigation, and robotic manipulation.\nOur ablation results further provide valuable insights for the development of\nfuture embodied generalist agents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiangyong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yong_S/0/1/0/all/0/1\">Silong Yong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linghu_X/0/1/0/all/0/1\">Xiongkun Linghu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Puhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_B/0/1/0/all/0/1\">Baoxiong Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Siyuan Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Overview of Current Applications of Large Language Models in Various Medical Specialities. (arXiv:2311.12882v1 [cs.CL])","link":"http://arxiv.org/abs/2311.12882","description":"<p>This paper gives an overview of the latest applications of Large Language\nModels (LLMs) in the healthcare sector, highlighting their transformative role\nin enhancing medical care quality. By processing vast amounts of data from\ndiverse medical domains, LLMs have become pivotal in assisting doctors,\nhealthcare providers, and patients. We explore their utilization in various\nmedical specialties, such as cancer diagnostics, dentistry, nephrology,\ndermatology, etc. The paper includes the LLM methodologies applied in various\nmedical specialties, different data types in the medical domains and the\nrelevant input formatting for LLMs, along with practical use-cases of LLMs in\nthe healthcare domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mumtaz_U/0/1/0/all/0/1\">Ummara Mumtaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_A/0/1/0/all/0/1\">Awais Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mumtaz_S/0/1/0/all/0/1\">Summaya Mumtaz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GAIA: a benchmark for General AI Assistants. (arXiv:2311.12983v1 [cs.CL])","link":"http://arxiv.org/abs/2311.12983","description":"<p>We introduce GAIA, a benchmark for General AI Assistants that, if solved,\nwould represent a milestone in AI research. GAIA proposes real-world questions\nthat require a set of fundamental abilities such as reasoning, multi-modality\nhandling, web browsing, and generally tool-use proficiency. GAIA questions are\nconceptually simple for humans yet challenging for most advanced AIs: we show\nthat human respondents obtain 92\\% vs. 15\\% for GPT-4 equipped with plugins.\nThis notable performance disparity contrasts with the recent trend of LLMs\noutperforming humans on tasks requiring professional skills in e.g. law or\nchemistry. GAIA's philosophy departs from the current trend in AI benchmarks\nsuggesting to target tasks that are ever more difficult for humans. We posit\nthat the advent of Artificial General Intelligence (AGI) hinges on a system's\ncapability to exhibit similar robustness as the average human does on such\nquestions. Using GAIA's methodology, we devise 466 questions and their answer.\nWe release our questions while retaining answers to 300 of them to power a\nleader-board available at https://huggingface.co/gaia-benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mialon_G/0/1/0/all/0/1\">Gr&#xe9;goire Mialon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fourrier_C/0/1/0/all/0/1\">Cl&#xe9;mentine Fourrier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swift_C/0/1/0/all/0/1\">Craig Swift</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_T/0/1/0/all/0/1\">Thomas Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1\">Yann LeCun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scialom_T/0/1/0/all/0/1\">Thomas Scialom</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Graph Attention Autoencoder for Attributed Networks using K-means Loss. (arXiv:2311.12986v1 [cs.CL])","link":"http://arxiv.org/abs/2311.12986","description":"<p>Multimodal Sentiment Analysis (MSA) has recently become a centric research\ndirection for many real-world applications. This proliferation is due to the\nfact that opinions are central to almost all human activities and are key\ninfluencers of our behaviors. In addition, the recent deployment of Deep\nLearning-based (DL) models has proven their high efficiency for a wide range of\nWestern languages. In contrast, Arabic DL-based multimodal sentiment analysis\n(MSA) is still in its infantile stage due, mainly, to the lack of standard\ndatasets. % The contribution In this paper, our investigation is twofold.\nFirst, we design a pipeline that helps building our Arabic Multimodal dataset\nleveraging both state-of-the-art transformers and feature extraction tools\nwithin word alignment techniques. Thereafter, we validate our dataset using\nstate-of-the-art transformer-based model dealing with multimodality. Despite\nthe small size of the outcome dataset, experiments show that Arabic\nmultimodality is very promising.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bekkaira_A/0/1/0/all/0/1\">Abdelfateh Bekkaira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bellaouar_S/0/1/0/all/0/1\">Slimane Bellaouar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oulad_Naoui_S/0/1/0/all/0/1\">Slimane Oulad-Naoui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Systematic word meta-sense extension. (arXiv:2311.13029v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13029","description":"<p>The meaning of polysemous words often varies in a highly productive yet\npredictable way. Generalizing the regularity between conventional senses to\nderive novel word meaning is crucial for automated processing of non-literal\nlanguage uses such as figurative expressions. We introduce a novel task called\nsystematic word meta-sense extension (SWORME) to test and improve language\nmodels' ability to extend word meaning to denote new semantic domains (also\ncalled meta-senses) that bear regular semantic relations with existing senses.\nWe found that language models prefer incremental lexical semantic change toward\nconceptually similar meta-senses such as logical metonymy, and are much worse\nat predicting highly non-literal meaning extensions such as metaphors. We\npropose a novel analogy-based method of word meaning extension, and show that\nit effectively improves language model systematicity in making both gradual and\nradical types of meta-sense extension. We further demonstrate that learning\nsystematic meta-sense extensions benefits language models on multiple\nbenchmarks of figurative language understanding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Lei Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Text: Unveiling Multimodal Proficiency of Large Language Models with MultiAPI Benchmark. (arXiv:2311.13053v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13053","description":"<p>The proliferation of Large Language Models like ChatGPT has significantly\nadvanced language understanding and generation, impacting a broad spectrum of\napplications. However, these models predominantly excel in text-based tasks,\noverlooking the complexity of real-world multimodal information. This study\nintroduces MultiAPI, a pioneering comprehensive large-scale API benchmark\ndataset aimed at expanding LLMs' proficiency in multimodal contexts. Developed\ncollaboratively through ChatGPT, MultiAPI consists of 235 diverse API calls and\n2,038 contextual prompts, offering a unique platform evaluation of\ntool-augmented LLMs handling multimodal tasks. Through comprehensive\nexperiments, our findings reveal that while LLMs demonstrate proficiency in API\ncall decision-making, they face challenges in domain identification, function\nselection, and argument generation. What's more, we surprisingly notice that\nauxiliary context can actually impair the performance. An in-depth error\nanalysis paves the way for a new paradigm to address these challenges,\nsuggesting a potential direction for future LLM research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jianfeng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiawei Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Attribution and Alignment: Effects of Local Context Repetition on Utterance Production and Comprehension in Dialogue. (arXiv:2311.13061v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13061","description":"<p>Language models are often used as the backbone of modern dialogue systems.\nThese models are pre-trained on large amounts of written fluent language.\nRepetition is typically penalised when evaluating language model generations.\nHowever, it is a key component of dialogue. Humans use local and partner\nspecific repetitions; these are preferred by human users and lead to more\nsuccessful communication in dialogue. In this study, we evaluate (a) whether\nlanguage models produce human-like levels of repetition in dialogue, and (b)\nwhat are the processing mechanisms related to lexical re-use they use during\ncomprehension. We believe that such joint analysis of model production and\ncomprehension behaviour can inform the development of cognitively inspired\ndialogue generation systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Molnar_A/0/1/0/all/0/1\">Aron Molnar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jumelet_J/0/1/0/all/0/1\">Jaap Jumelet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giulianelli_M/0/1/0/all/0/1\">Mario Giulianelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinclair_A/0/1/0/all/0/1\">Arabella Sinclair</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Logical Reasoning in Large Language Models to Facilitate Legal Applications. (arXiv:2311.13095v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13095","description":"<p>Language serves as a vehicle for conveying thought, enabling communication\namong individuals. The ability to distinguish between diverse concepts,\nidentify fairness and injustice, and comprehend a range of legal notions\nfundamentally relies on logical reasoning. Large Language Models (LLMs) attempt\nto emulate human language understanding and generation, but their competency in\nlogical reasoning remains limited. This paper seeks to address the\nphilosophical question: How can we effectively teach logical reasoning to LLMs\nwhile maintaining a deep understanding of the intricate relationship between\nlanguage and logic? By focusing on bolstering LLMs' capabilities in logical\nreasoning, we aim to expand their applicability in law and other\nlogic-intensive disciplines. To this end, we propose a Reinforcement Learning\nfrom Logical Feedback (RLLF) approach, which serves as a potential framework\nfor refining LLMs' reasoning capacities. Through RLLF and a revised evaluation\nmethodology, we explore new avenues for research in this domain and contribute\nto the development of LLMs capable of handling complex legal reasoning tasks\nwhile acknowledging the fundamental connection between language and logic.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Ha-Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fungwacharakorn_W/0/1/0/all/0/1\">Wachara Fungwacharakorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Satoh_K/0/1/0/all/0/1\">Ken Satoh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting out-of-distribution text using topological features of transformer-based language models. (arXiv:2311.13102v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13102","description":"<p>We attempt to detect out-of-distribution (OOD) text samples though applying\nTopological Data Analysis (TDA) to attention maps in transformer-based language\nmodels. We evaluate our proposed TDA-based approach for out-of-distribution\ndetection on BERT, a transformer-based language model, and compare the to a\nmore traditional OOD approach based on BERT CLS embeddings. We found that our\nTDA approach outperforms the CLS embedding approach at distinguishing\nin-distribution data (politics and entertainment news articles from HuffPost)\nfrom far out-of-domain samples (IMDB reviews), but its effectiveness\ndeteriorates with near out-of-domain (CNN/Dailymail) or same-domain (business\nnews articles from HuffPost) datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pollano_A/0/1/0/all/0/1\">Andres Pollano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_A/0/1/0/all/0/1\">Anupam Chaudhuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simmons_A/0/1/0/all/0/1\">Anj Simmons</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Perceptual Structure in the Absence of Grounding for LLMs: The Impact of Abstractedness and Subjectivity in Color Language. (arXiv:2311.13105v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13105","description":"<p>The need for grounding in language understanding is an active research topic.\nPrevious work has suggested that color perception and color language appear as\na suitable test bed to empirically study the problem, given its cognitive\nsignificance and showing that there is considerable alignment between a defined\ncolor space and the feature space defined by a language model. To further study\nthis issue, we collect a large scale source of colors and their descriptions,\ncontaining almost a 1 million examples , and perform an empirical analysis to\ncompare two kinds of alignments: (i) inter-space, by learning a mapping between\nembedding space and color space, and (ii) intra-space, by means of prompting\ncomparatives between color descriptions. Our results show that while color\nspace alignment holds for monolexemic, highly pragmatic color descriptions,\nthis alignment drops considerably in the presence of examples that exhibit\nelements of real linguistic usage such as subjectivity and abstractedness,\nsuggesting that grounding may be required in such cases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Loyola_P/0/1/0/all/0/1\">Pablo Loyola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marrese_Taylor_E/0/1/0/all/0/1\">Edison Marrese-Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoyos_Idobro_A/0/1/0/all/0/1\">Andres Hoyos-Idobro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"White-Box Transformers via Sparse Rate Reduction: Compression Is All There Is?. (arXiv:2311.13110v1 [cs.LG])","link":"http://arxiv.org/abs/2311.13110","description":"<p>In this paper, we contend that a natural objective of representation learning\nis to compress and transform the distribution of the data, say sets of tokens,\ntowards a low-dimensional Gaussian mixture supported on incoherent subspaces.\nThe goodness of such a representation can be evaluated by a principled measure,\ncalled sparse rate reduction, that simultaneously maximizes the intrinsic\ninformation gain and extrinsic sparsity of the learned representation. From\nthis perspective, popular deep network architectures, including transformers,\ncan be viewed as realizing iterative schemes to optimize this measure.\nParticularly, we derive a transformer block from alternating optimization on\nparts of this objective: the multi-head self-attention operator compresses the\nrepresentation by implementing an approximate gradient descent step on the\ncoding rate of the features, and the subsequent multi-layer perceptron\nsparsifies the features. This leads to a family of white-box transformer-like\ndeep network architectures, named CRATE, which are mathematically fully\ninterpretable. We show, by way of a novel connection between denoising and\ncompression, that the inverse to the aforementioned compressive encoding can be\nrealized by the same class of CRATE architectures. Thus, the so-derived\nwhite-box architectures are universal to both encoders and decoders.\nExperiments show that these networks, despite their simplicity, indeed learn to\ncompress and sparsify representations of large-scale real-world image and text\ndatasets, and achieve performance very close to highly engineered\ntransformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the\nproposed computational framework demonstrates great potential in bridging the\ngap between theory and practice of deep learning, from a unified perspective of\ndata compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buchanan_S/0/1/0/all/0/1\">Sam Buchanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pai_D/0/1/0/all/0/1\">Druv Pai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_T/0/1/0/all/0/1\">Tianzhe Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Ziyang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_S/0/1/0/all/0/1\">Shengbang Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1\">Hao Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_Y/0/1/0/all/0/1\">Yuexiang Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haeffele_B/0/1/0/all/0/1\">Benjamin D. Haeffele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Combatting Human Trafficking in the Cyberspace: A Natural Language Processing-Based Methodology to Analyze the Language in Online Advertisements. (arXiv:2311.13118v1 [cs.LG])","link":"http://arxiv.org/abs/2311.13118","description":"<p>This project tackles the pressing issue of human trafficking in online C2C\nmarketplaces through advanced Natural Language Processing (NLP) techniques. We\nintroduce a novel methodology for generating pseudo-labeled datasets with\nminimal supervision, serving as a rich resource for training state-of-the-art\nNLP models. Focusing on tasks like Human Trafficking Risk Prediction (HTRP) and\nOrganized Activity Detection (OAD), we employ cutting-edge Transformer models\nfor analysis. A key contribution is the implementation of an interpretability\nframework using Integrated Gradients, providing explainable insights crucial\nfor law enforcement. This work not only fills a critical gap in the literature\nbut also offers a scalable, machine learning-driven approach to combat human\nexploitation online. It serves as a foundation for future research and\npractical applications, emphasizing the role of machine learning in addressing\ncomplex social issues.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Perez_A/0/1/0/all/0/1\">Alejandro Rodriguez Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rivas_P/0/1/0/all/0/1\">Pablo Rivas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Better Parameter-Efficient Fine-Tuning for Large Language Models: A Position Paper. (arXiv:2311.13126v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13126","description":"<p>This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junbing Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jun Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms. (arXiv:2311.13133v1 [cs.LG])","link":"http://arxiv.org/abs/2311.13133","description":"<p>Large Language Models are traditionally finetuned on large instruction\ndatasets. However recent studies suggest that small, high-quality datasets can\nsuffice for general purpose instruction following. This lack of consensus\nsurrounding finetuning best practices is in part due to rapidly diverging\napproaches to LLM evaluation. In this study, we ask whether a small amount of\ndiverse finetuning samples can improve performance on both traditional\nperplexity-based NLP benchmarks, and on open-ended, model-based evaluation. We\nfinetune open-source MPT-7B and MPT-30B models on instruction finetuning\ndatasets of various sizes ranging from 1k to 60k samples. We find that subsets\nof 1k-6k instruction finetuning samples are sufficient to achieve good\nperformance on both (1) traditional NLP benchmarks and (2) model-based\nevaluation. Finally, we show that mixing textbook-style and open-ended QA\nfinetuning datasets optimizes performance on both evaluation paradigms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jha_A/0/1/0/all/0/1\">Aditi Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Havens_S/0/1/0/all/0/1\">Sam Havens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dohmann_J/0/1/0/all/0/1\">Jeremey Dohmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trott_A/0/1/0/all/0/1\">Alex Trott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portes_J/0/1/0/all/0/1\">Jacob Portes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ComPEFT: Compression for Communicating Parameter Efficient Updates via Sparsification and Quantization. (arXiv:2311.13171v1 [cs.LG])","link":"http://arxiv.org/abs/2311.13171","description":"<p>Parameter-efficient fine-tuning (PEFT) techniques make it possible to\nefficiently adapt a language model to create \"expert\" models that specialize to\nnew tasks or domains. Recent techniques in model merging and compositional\ngeneralization leverage these expert models by dynamically composing modules to\nimprove zero/few-shot generalization. Despite the efficiency of PEFT methods,\nthe size of expert models can make it onerous to retrieve expert models per\nquery over high-latency networks like the Internet or serve multiple experts on\na single GPU. To address these issues, we present ComPEFT, a novel method for\ncompressing fine-tuning residuals (task vectors) of PEFT based models. ComPEFT\nemploys sparsification and ternary quantization to reduce the size of the PEFT\nmodule without performing any additional retraining while preserving or\nenhancing model performance. In extensive evaluation across T5, T0, and\nLLaMA-based models with 200M - 65B parameters, ComPEFT achieves compression\nratios of 8x - 50x. In particular, we show that ComPEFT improves with scale -\nstronger models exhibit higher compressibility and better performance. For\nexample, we show that ComPEFT applied to LLaMA outperforms QLoRA by 4.16% on\nMMLU with a storage size reduction of up to 26x. In addition, we show that the\ncompressed experts produced by ComPEFT maintain few-shot compositional\ngeneralization capabilities, facilitate efficient communication and\ncomputation, and exhibit enhanced performance when merged. Lastly, we provide\nan analysis of different method components, compare it with other PEFT methods,\nand test ComPEFT's efficacy for compressing the residual of full-finetuning.\nOur code is available at https://github.com/prateeky2806/compeft.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yadav_P/0/1/0/all/0/1\">Prateek Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1\">Leshem Choshen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AS-LLM: When Algorithm Selection Meets Large Language Model. (arXiv:2311.13184v1 [cs.LG])","link":"http://arxiv.org/abs/2311.13184","description":"<p>Algorithm selection aims to identify the most suitable algorithm for solving\na specific problem before execution, which has become a critical process of the\nAutoML. Current mainstream algorithm selection techniques rely heavily on\nfeature representations of various problems and employ the performance of each\nalgorithm as supervised information. However, there is a significant research\ngap concerning the consideration of algorithm features. This gap is primarily\nattributed to the inherent complexity of algorithms, making it particularly\nchallenging to find a universally effective feature extraction method that is\napplicable across a diverse range of algorithms. Unfortunately, neglecting this\naspect undoubtedly impacts the accuracy of algorithm selection and indirectly\nnecessitates an increased volume of problem data for training purposes. This\npaper takes a significant stride towards addressing this gap by proposing an\napproach that integrates algorithm representation into the algorithm selection\nprocess. Specifically, our proposed model employs distinct modules to extract\nrepresentations of both problems and algorithms, where the algorithm\nrepresentation leverages the capabilities of pre-trained LLMs in the realm of\ncode comprehension. Following the extraction of embedding vectors for both\nalgorithms and problems, the most suitable algorithm is determined through\ncalculations of matching degrees. Our experiments not only validate the\neffectiveness of the proposed model but also showcase the performance of\ndifferent embedded pre-trained LLMs, which suggests that the proposed algorithm\nselection framework holds the potential to serve as a baseline task for\nevaluating the code representation capabilities of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xingyu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yan Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jibin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_K/0/1/0/all/0/1\">Kay Chen Tan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus. (arXiv:2311.13230v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13230","description":"<p>Large Language Models (LLMs) have gained significant popularity for their\nimpressive performance across diverse fields. However, LLMs are prone to\nhallucinate untruthful or nonsensical outputs that fail to meet user\nexpectations in many real-world applications. Existing works for detecting\nhallucinations in LLMs either rely on external knowledge for reference\nretrieval or require sampling multiple responses from the LLM for consistency\nverification, making these methods costly and inefficient. In this paper, we\npropose a novel reference-free, uncertainty-based method for detecting\nhallucinations in LLMs. Our approach imitates human focus in factuality\nchecking from three aspects: 1) focus on the most informative and important\nkeywords in the given text; 2) focus on the unreliable tokens in historical\ncontext which may lead to a cascade of hallucinations; and 3) focus on the\ntoken properties such as token type and token frequency. Experimental results\non relevant datasets demonstrate the effectiveness of our proposed method,\nwhich achieves state-of-the-art performance across all the evaluation metrics\nand eliminates the need for additional information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianhang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1\">Lin Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qipeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1\">Cheng Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chenghu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinbing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_L/0/1/0/all/0/1\">Luoyi Fu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Calibration of Large Language Models and Alignment. (arXiv:2311.13240v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13240","description":"<p>As large language models attract increasing attention and find widespread\napplication, concurrent challenges of reliability also arise at the same time.\nConfidence calibration, an effective analysis method for gauging the\nreliability of deep models, serves as a crucial tool for assessing and\nimproving their reliability. However, such investigation has been comparatively\nunderexplored. In this work, we conduct a systematic examination of the\ncalibration of aligned language models throughout the entire construction\nprocess, including pretraining and alignment training. At each stage, we\ninvestigate how different training settings, such as parameter scales and\ntraining data, affect model calibration. To thoroughly assess model\ncalibration, we evaluate models on three most concerned aspects: generation,\nfactuality and understanding. Our work sheds light on whether popular LLMs are\nwell-calibrated and how the training process influences model calibration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chiwei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Benfeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Quan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongdong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Zhendong Mao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Instruction Optimization for Open-source LLM Instruction Tuning. (arXiv:2311.13246v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13246","description":"<p>Instruction tuning is crucial for enabling Language Learning Models (LLMs) in\nresponding to human instructions. The quality of instruction pairs used for\ntuning greatly affects the performance of LLMs. However, the manual creation of\nhigh-quality instruction datasets is costly, leading to the adoption of\nautomatic generation of instruction pairs by LLMs as a popular alternative in\nthe training of open-source LLMs. To ensure the high quality of LLM-generated\ninstruction datasets, several approaches have been proposed. Nevertheless,\nexisting methods either compromise dataset integrity by filtering a large\nproportion of samples, or are unsuitable for industrial applications. In this\npaper, instead of discarding low-quality samples, we propose CoachLM, a novel\napproach to enhance the quality of instruction datasets through automatic\nrevisions on samples in the dataset. CoachLM is trained from the samples\nrevised by human experts and significantly increases the proportion of\nhigh-quality samples in the dataset from 17.7% to 78.9%. The effectiveness of\nCoachLM is further assessed on various real-world instruction test sets. The\nresults show that CoachLM improves the instruction-following capabilities of\nthe instruction-tuned LLM by an average of 29.9%, which even surpasses larger\nLLMs with nearly twice the number of parameters. Furthermore, CoachLM is\nsuccessfully deployed in a data management system for LLMs at Huawei, resulting\nin an efficiency improvement of up to 20% in the cleaning of 40k real-world\ninstruction pairs. We release the training data and code of CoachLM\n(https://github.com/lunyiliu/CoachLM).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yilun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_S/0/1/0/all/0/1\">Shimin Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiaofeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Ming Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wenbing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Junhao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1\">Chang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yutai Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Miao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Hongxia Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yanfei Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided Code-Vision Representation. (arXiv:2311.13258v1 [cs.CV])","link":"http://arxiv.org/abs/2311.13258","description":"<p>State-of-the-art vision-language models (VLMs) still have limited performance\nin structural knowledge extraction, such as relations between objects. In this\nwork, we present ViStruct, a training framework to learn VLMs for effective\nvisual structural knowledge extraction. Two novel designs are incorporated.\nFirst, we propose to leverage the inherent structure of programming language to\ndepict visual structural information. This approach enables explicit and\nconsistent representation of visual structural information of multiple\ngranularities, such as concepts, relations, and events, in a well-organized\nstructured format. Second, we introduce curriculum-based learning for VLMs to\nprogressively comprehend visual structures, from fundamental visual concepts to\nintricate event structures. Our intuition is that lower-level knowledge may\ncontribute to complex visual structure understanding. Furthermore, we compile\nand release a collection of datasets tailored for visual structural knowledge\nextraction. We adopt a weakly-supervised approach to directly generate visual\nevent structures from captions for ViStruct training, capitalizing on abundant\nimage-caption pairs from the web. In experiments, we evaluate ViStruct on\nvisual structure prediction tasks, demonstrating its effectiveness in improving\nthe understanding of visual structures. The code is public at\n\\url{https://github.com/Yangyi-Chen/vi-struct}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yangyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Manling Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoiem_D/0/1/0/all/0/1\">Derek Hoiem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparative Experimentation of Accuracy Metrics in Automated Medical Reporting: The Case of Otitis Consultations. (arXiv:2311.13273v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13273","description":"<p>Generative Artificial Intelligence (AI) can be used to automatically generate\nmedical reports based on transcripts of medical consultations. The aim is to\nreduce the administrative burden that healthcare professionals face. The\naccuracy of the generated reports needs to be established to ensure their\ncorrectness and usefulness. There are several metrics for measuring the\naccuracy of AI generated reports, but little work has been done towards the\napplication of these metrics in medical reporting. A comparative\nexperimentation of 10 accuracy metrics has been performed on AI generated\nmedical reports against their corresponding General Practitioner's (GP) medical\nreports concerning Otitis consultations. The number of missing, incorrect, and\nadditional statements of the generated reports have been correlated with the\nmetric scores. In addition, we introduce and define a Composite Accuracy Score\nwhich produces a single score for comparing the metrics within the field of\nautomated medical reporting. Findings show that based on the correlation study\nand the Composite Accuracy Score, the ROUGE-L and Word Mover's Distance metrics\nare the preferred metrics, which is not in line with previous work. These\nfindings help determine the accuracy of an AI generated medical report, which\naids the development of systems that generate medical reports for GPs to reduce\nthe administrative burden.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Faber_W/0/1/0/all/0/1\">Wouter Faber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bootsma_R/0/1/0/all/0/1\">Renske Eline Bootsma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huibers_T/0/1/0/all/0/1\">Tom Huibers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dulmen_S/0/1/0/all/0/1\">Sandra van Dulmen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brinkkemper_S/0/1/0/all/0/1\">Sjaak Brinkkemper</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Summarization Performance through Transformer-Based Prompt Engineering in Automated Medical Reporting. (arXiv:2311.13274v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13274","description":"<p>Customized medical prompts enable Large Language Models (LLM) to effectively\naddress medical dialogue summarization. The process of medical reporting is\noften time-consuming for healthcare professionals. Implementing medical\ndialogue summarization techniques presents a viable solution to alleviate this\ntime constraint by generating automated medical reports. The effectiveness of\nLLMs in this process is significantly influenced by the formulation of the\nprompt, which plays a crucial role in determining the quality and relevance of\nthe generated reports. In this research, we used a combination of two distinct\nprompting strategies, known as shot prompting and pattern prompting to enhance\nthe performance of automated medical reporting. The evaluation of the automated\nmedical reports is carried out using the ROUGE score and a human evaluation\nwith the help of an expert panel. The two-shot prompting approach in\ncombination with scope and domain context outperforms other methods and\nachieves the highest score when compared to the human reference set by a\ngeneral practitioner. However, the automated reports are approximately twice as\nlong as the human references, due to the addition of both redundant and\nrelevant statements that are added to the report.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zandvoort_D/0/1/0/all/0/1\">Daphne van Zandvoort</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiersema_L/0/1/0/all/0/1\">Laura Wiersema</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huibers_T/0/1/0/all/0/1\">Tom Huibers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dulmen_S/0/1/0/all/0/1\">Sandra van Dulmen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brinkkemper_S/0/1/0/all/0/1\">Sjaak Brinkkemper</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Intention and Context Elicitation with Large Language Models in the Legal Aid Intake Process. (arXiv:2311.13281v1 [cs.CY])","link":"http://arxiv.org/abs/2311.13281","description":"<p>Large Language Models (LLMs) and chatbots show significant promise in\nstreamlining the legal intake process. This advancement can greatly reduce the\nworkload and costs for legal aid organizations, improving availability while\nmaking legal assistance more accessible to a broader audience. However, a key\nchallenge with current LLMs is their tendency to overconfidently deliver an\nimmediate 'best guess' to a client's question based on the output distribution\nlearned over the training data. This approach often overlooks the client's\nactual intentions or the specifics of their legal situation. As a result,\nclients may not realize the importance of providing essential additional\ncontext or expressing their underlying intentions, which are crucial for their\nlegal cases. Traditionally, logic based decision trees have been used to\nautomate intake for specific access to justice issues, such as immigration and\neviction. But those solutions lack scalability. We demonstrate a\nproof-of-concept using LLMs to elicit and infer clients' underlying intentions\nand specific legal circumstances through free-form, language-based\ninteractions. We also propose future research directions to use supervised\nfine-tuning or offline reinforcement learning to automatically incorporate\nintention and context elicitation in chatbots without explicit prompting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Goodson_N/0/1/0/all/0/1\">Nick Goodson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1\">Rongfei Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rethinking Radiology Report Generation via Causal Reasoning and Counterfactual Augmentation. (arXiv:2311.13307v1 [cs.CV])","link":"http://arxiv.org/abs/2311.13307","description":"<p>Radiology Report Generation (RRG) draws attention as an interaction between\nvision and language fields. Previous works inherited the ideology of\nvision-to-language generation tasks,aiming to generate paragraphs with high\nconsistency as reports. However, one unique characteristic of RRG, the\nindependence between diseases, was neglected, leading to the injection of the\nspurious confounder, i.e., the disease co-occurrence. Unfortunately, this\nconfounder confuses the process of report generation worse because of the\nbiased RRG data distribution. In this paper, to rethink this issue thoroughly,\nwe reason about its causes and effects from a novel perspective of statistics\nand causality, where the Joint Vision Coupling and the Conditional Sentence\nCoherence Coupling are two aspects prone to implicitly decrease the accuracy of\nreports. Then, a counterfactual augmentation strategy that contains the\nCounterfactual Sample Synthesis and the Counterfactual Report Reconstruction\nsub-methods is proposed to break these two aspects of spurious effects.\nExperimental results and further analyses on two widely used datasets justify\nour reasoning and proposed methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xiao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiafan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_W/0/1/0/all/0/1\">Wenbin Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruxin Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating Large Language Model Hallucinations via Autonomous Knowledge Graph-based Retrofitting. (arXiv:2311.13314v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13314","description":"<p>Incorporating factual knowledge in knowledge graph is regarded as a promising\napproach for mitigating the hallucination of large language models (LLMs).\nExisting methods usually only use the user's input to query the knowledge\ngraph, thus failing to address the factual hallucination generated by LLMs\nduring its reasoning process. To address this problem, this paper proposes\nKnowledge Graph-based Retrofitting (KGR), a new framework that incorporates\nLLMs with KGs to mitigate factual hallucination during the reasoning process by\nretrofitting the initial draft responses of LLMs based on the factual knowledge\nstored in KGs. Specifically, KGR leverages LLMs to extract, select, validate,\nand retrofit factual statements within the model-generated responses, which\nenables an autonomous knowledge verifying and refining procedure without any\nadditional manual efforts. Experiments show that KGR can significantly improve\nthe performance of LLMs on factual QA benchmarks especially when involving\ncomplex reasoning processes, which demonstrates the necessity and effectiveness\nof KGR in mitigating hallucination and enhancing the reliability of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guan_X/0/1/0/all/0/1\">Xinyan Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yanjiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongyu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yaojie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Ben He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xianpei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Le Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fact-based Court Judgment Prediction. (arXiv:2311.13350v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13350","description":"<p>This extended abstract extends the research presented in \"ILDC for CJPE:\nIndian Legal Documents Corpus for Court Judgment Prediction and Explanation\"\n\\cite{malik-etal-2021-ildc}, focusing on fact-based judgment prediction within\nthe context of Indian legal documents. We introduce two distinct problem\nvariations: one based solely on facts, and another combining facts with rulings\nfrom lower courts (RLC). Our research aims to enhance early-phase case outcome\nprediction, offering significant benefits to legal professionals and the\ngeneral public. The results, however, indicated a performance decline compared\nto the original ILDC for CJPE study, even after implementing various weightage\nschemes in our DELSumm algorithm. Additionally, using only facts for legal\njudgment prediction with different transformer models yielded results inferior\nto the state-of-the-art outcomes reported in the \"ILDC for CJPE\" study.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nigam_S/0/1/0/all/0/1\">Shubham Kumar Nigam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deroy_A/0/1/0/all/0/1\">Aniket Deroy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generation of Explanations for Logic Reasoning. (arXiv:2311.13455v1 [cs.AI])","link":"http://arxiv.org/abs/2311.13455","description":"<p>This thesis delves into a fortiori arguments in deductive reasoning,\nunderscoring their relevance in various domains such as law, philosophy, and\nartificial intelligence. The research is centred on employing GPT-3.5-turbo to\nautomate the analysis of these arguments, with a focus on understanding\nintricate reasoning processes, generating clear and coherent explanations, and\ncreating novel arguments. The methodology encompasses a series of tasks\nincluding detailed reasoning, interpretation, and the augmentation of a\nfortiori arguments. It involves meticulously identifying these arguments in\ndiverse contexts, differentiating comparative elements, and categorizing them\nbased on their logical structure.\n</p>\n<p>Extensive experiments reveals the challenges encountered by GPT-3.5-turbo in\naccurately detecting and classifying a fortiori arguments. Nevertheless, the\nmodel demonstrates a performance that rivals specialized models, particularly\nin extracting key components and interpreting underlying properties. The\nintegration of external information into the model's processing significantly\nelevates the quality of the generated explanations. Additionally, the model\nexhibits a noteworthy capability in augmenting arguments, thus contributing to\nthe enrichment of the data set.\n</p>\n<p>Despite facing certain limitations, this thesis makes significant\ncontributions to the fields of artificial intelligence and logical reasoning.\nIt introduces novel methodologies, establishes a rigorous evaluation framework,\nand provides deep insights that set the stage for future advancements in\nautomated logical reasoning. The findings and methodologies presented herein\nnot only underscore the potential of AI in complex reasoning tasks but also\nhighlight areas for future research and development.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1\">Yanyi Pu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Complexity-Guided Curriculum Learning for Text Graphs. (arXiv:2311.13472v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13472","description":"<p>Curriculum learning provides a systematic approach to training. It refines\ntraining progressively, tailors training to task requirements, and improves\ngeneralization through exposure to diverse examples. We present a curriculum\nlearning approach that builds on existing knowledge about text and graph\ncomplexity formalisms for training with text graph data. The core part of our\napproach is a novel data scheduler, which employs \"spaced repetition\" and\ncomplexity formalisms to guide the training process. We demonstrate the\neffectiveness of the proposed approach on several text graph tasks and graph\nneural network architectures. The proposed model gains more and uses less data;\nconsistently prefers text over graph complexity indices throughout training,\nwhile the best curricula derived from text and graph complexity indices are\nequally effective; and it learns transferable curricula across GNN models and\ndatasets. In addition, we find that both node-level (local) and graph-level\n(global) graph complexity indices, as well as shallow and traditional text\ncomplexity indices play a crucial role in effective curriculum learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vakil_N/0/1/0/all/0/1\">Nidhi Vakil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amiri_H/0/1/0/all/0/1\">Hadi Amiri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Machine Translation to Control Formality Features in the Target Language. (arXiv:2311.13475v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13475","description":"<p>Formality plays a significant role in language communication, especially in\nlow-resource languages such as Hindi, Japanese and Korean. These languages\nutilise formal and informal expressions to convey messages based on social\ncontexts and relationships. When a language translation technique is used to\ntranslate from a source language that does not pertain the formality (e.g.\nEnglish) to a target language that does, there is a missing information on\nformality that could be a challenge in producing an accurate outcome. This\nresearch explores how this issue should be resolved when machine learning\nmethods are used to translate from English to languages with formality, using\nHindi as the example data. This was done by training a bilingual model in a\nformality-controlled setting and comparing its performance with a pre-trained\nmultilingual model in a similar setting. Since there are not a lot of training\ndata with ground truth, automated annotation techniques were employed to\nincrease the data size. The primary modeling approach involved leveraging\ntransformer models, which have demonstrated effectiveness in various natural\nlanguage processing tasks. We evaluate the official formality accuracy(ACC) by\ncomparing the predicted masked tokens with the ground truth. This metric\nprovides a quantitative measure of how well the translations align with the\ndesired outputs. Our study showcases a versatile translation strategy that\nconsiders the nuances of formality in the target language, catering to diverse\nlanguage communication needs and scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tyagi_H/0/1/0/all/0/1\">Harshita Tyagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_P/0/1/0/all/0/1\">Prashasta Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hyowon Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Current Topological and Machine Learning Applications for Bias Detection in Text. (arXiv:2311.13495v1 [cs.CY])","link":"http://arxiv.org/abs/2311.13495","description":"<p>Institutional bias can impact patient outcomes, educational attainment, and\nlegal system navigation. Written records often reflect bias, and once bias is\nidentified; it is possible to refer individuals for training to reduce bias.\nMany machine learning tools exist to explore text data and create predictive\nmodels that can search written records to identify real-time bias. However, few\nprevious studies investigate large language model embeddings and geometric\nmodels of biased text data to understand geometry's impact on bias modeling\naccuracy. To overcome this issue, this study utilizes the RedditBias database\nto analyze textual biases. Four transformer models, including BERT and RoBERTa\nvariants, were explored. Post-embedding, t-SNE allowed two-dimensional\nvisualization of data. KNN classifiers differentiated bias types, with lower\nk-values proving more effective. Findings suggest BERT, particularly mini BERT,\nexcels in bias classification, while multilingual models lag. The\nrecommendation emphasizes refining monolingual models and exploring\ndomain-specific biases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Farrelly_C/0/1/0/all/0/1\">Colleen Farrelly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_Y/0/1/0/all/0/1\">Yashbir Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hathaway_Q/0/1/0/all/0/1\">Quincy A. Hathaway</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carlsson_G/0/1/0/all/0/1\">Gunnar Carlsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_A/0/1/0/all/0/1\">Ashok Choudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_R/0/1/0/all/0/1\">Rahul Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doretto_G/0/1/0/all/0/1\">Gianfranco Doretto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Himeur_Y/0/1/0/all/0/1\">Yassine Himeur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atalls_S/0/1/0/all/0/1\">Shadi Atalls</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansoor_W/0/1/0/all/0/1\">Wathiq Mansoor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LM-Cocktail: Resilient Tuning of Language Models via Model Merging. (arXiv:2311.13534v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13534","description":"<p>The pre-trained language models are continually fine-tuned to better support\ndownstream applications. However, this operation may result in significant\nperformance degeneration on general tasks beyond the targeted domain. To\novercome this problem, we propose a novel method which enables the fine-tuned\nmodel to stay resilient in general perspectives. Our method is conducted in the\nform of model merging (namely LM-Cocktail), where the fine-tuned language model\nis merged with the pre-trained base model or the peer models from other domains\nthrough weighted average. Despite simplicity, LM-Cocktail is surprisingly\neffective: the resulted model is able to achieve a strong empirical performance\nin the whole scope of general tasks while preserving a superior capacity in its\ntargeted domain. We conduct comprehensive experiments with LLama and BGE model\non popular benchmarks, including FLAN, MMLU, MTEB, whose results validate the\nefficacy of our proposed method. The code and checkpoints are available at\nhttps://github.com/FlagOpen/FlagEmbedding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1\">Shitao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Peitian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_X/0/1/0/all/0/1\">Xingrun Xing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering. (arXiv:2311.13565v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13565","description":"<p>We address the task of evidence retrieval for long document question\nanswering, which involves locating relevant paragraphs within a document to\nanswer a question. We aim to assess the applicability of large language models\n(LLMs) in the task of zero-shot long document evidence retrieval, owing to\ntheir unprecedented performance across various NLP tasks. However, currently\nthe LLMs can consume limited context lengths as input, thus providing document\nchunks as inputs might overlook the global context while missing out on\ncapturing the inter-segment dependencies. Moreover, directly feeding the large\ninput sets can incur significant computational costs, particularly when\nprocessing the entire document (and potentially incurring monetary expenses\nwith enterprise APIs like OpenAI's GPT variants). To address these challenges,\nwe propose a suite of techniques that exploit the discourse structure commonly\nfound in documents. By utilizing this structure, we create a condensed\nrepresentation of the document, enabling a more comprehensive understanding and\nanalysis of relationships between different parts. We retain $99.6\\%$ of the\nbest zero-shot approach's performance, while processing only $26\\%$ of the\ntotal tokens used by the best approach in the information seeking evidence\nretrieval setup. We also show how our approach can be combined with\n\\textit{self-ask} reasoning agent to achieve best zero-shot performance in\ncomplex multi-hop question answering, just $\\approx 4\\%$ short of zero-shot\nperformance using gold evidence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nair_I/0/1/0/all/0/1\">Inderjeet Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Somasundaram_S/0/1/0/all/0/1\">Shwetha Somasundaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxena_A/0/1/0/all/0/1\">Apoorv Saxena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_K/0/1/0/all/0/1\">Koustava Goswami</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PaSS: Parallel Speculative Sampling. (arXiv:2311.13581v1 [cs.CL])","link":"http://arxiv.org/abs/2311.13581","description":"<p>Scaling the size of language models to tens of billions of parameters has led\nto impressive performance on a wide range of tasks. At generation, these models\nare used auto-regressively, requiring a forward pass for each generated token,\nand thus reading the full set of parameters from memory. This memory access\nforms the primary bottleneck for generation and it worsens as the model size\nincreases. Moreover, executing a forward pass for multiple tokens in parallel\noften takes nearly the same time as it does for just one token. These two\nobservations lead to the development of speculative sampling, where a second\nsmaller model is used to draft a few tokens, that are then validated or\nrejected using a single forward pass of the large model. Unfortunately, this\nmethod requires two models that share the same tokenizer and thus limits its\nadoption. As an alternative, we propose to use parallel decoding as a way to\ndraft multiple tokens from a single model with no computational cost, nor the\nneed for a second model. Our approach only requires an additional input token\nthat marks the words that will be generated simultaneously. We show promising\nperformance (up to $30\\%$ speed-up) while requiring only as few as $O(d_{emb})$\nadditional parameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Monea_G/0/1/0/all/0/1\">Giovanni Monea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joulin_A/0/1/0/all/0/1\">Armand Joulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grave_E/0/1/0/all/0/1\">Edouard Grave</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Representation Projection Invariance Mitigates Representation Collapse. (arXiv:2205.11603v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.11603","description":"<p>Fine-tuning contextualized representations learned by pre-trained language\nmodels remains a prevalent practice in NLP. However, fine-tuning can lead to\nrepresentation degradation (also known as representation collapse), which may\nresult in instability, sub-optimal performance, and weak generalization.\n</p>\n<p>In this paper, we propose Representation Projection Invariance (REPINA), a\nnovel regularization method to maintain the information content of\nrepresentation and reduce representation collapse during fine-tuning by\ndiscouraging undesirable changes in the representations. We study the empirical\nbehavior of the proposed regularization in comparison to 5 comparable baselines\nacross 13 language understanding tasks (GLUE benchmark and six additional\ndatasets). When evaluating in-domain performance, REPINA consistently\noutperforms other baselines on most tasks (10 out of 13). We also demonstrate\nits effectiveness in few-shot settings and robustness to label perturbation. As\na by-product, we extend previous studies of representation collapse and propose\nseveral metrics to quantify it. Our empirical findings show that our approach\nis significantly more effective at mitigating representation collapse.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Razdaibiedina_A/0/1/0/all/0/1\">Anastasia Razdaibiedina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khetan_A/0/1/0/all/0/1\">Ashish Khetan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karnin_Z/0/1/0/all/0/1\">Zohar Karnin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapoor_V/0/1/0/all/0/1\">Vishaal Kapoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madan_V/0/1/0/all/0/1\">Vivek Madan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GraphCFC: A Directed Graph Based Cross-Modal Feature Complementation Approach for Multimodal Conversational Emotion Recognition. (arXiv:2207.12261v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2207.12261","description":"<p>Emotion Recognition in Conversation (ERC) plays a significant part in\nHuman-Computer Interaction (HCI) systems since it can provide empathetic\nservices. Multimodal ERC can mitigate the drawbacks of uni-modal approaches.\nRecently, Graph Neural Networks (GNNs) have been widely used in a variety of\nfields due to their superior performance in relation modeling. In multimodal\nERC, GNNs are capable of extracting both long-distance contextual information\nand inter-modal interactive information. Unfortunately, since existing methods\nsuch as MMGCN directly fuse multiple modalities, redundant information may be\ngenerated and diverse information may be lost. In this work, we present a\ndirected Graph based Cross-modal Feature Complementation (GraphCFC) module that\ncan efficiently model contextual and interactive information. GraphCFC\nalleviates the problem of heterogeneity gap in multimodal fusion by utilizing\nmultiple subspace extractors and Pair-wise Cross-modal Complementary (PairCC)\nstrategy. We extract various types of edges from the constructed graph for\nencoding, thus enabling GNNs to extract crucial contextual and interactive\ninformation more accurately when performing message passing. Furthermore, we\ndesign a GNN structure called GAT-MLP, which can provide a new unified network\nframework for multimodal learning. The experimental results on two benchmark\ndatasets show that our GraphCFC outperforms the state-of-the-art (SOTA)\napproaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_G/0/1/0/all/0/1\">Guoqing Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1\">Zhigang Zeng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pragmatics in Language Grounding: Phenomena, Tasks, and Modeling Approaches. (arXiv:2211.08371v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.08371","description":"<p>People rely heavily on context to enrich meaning beyond what is literally\nsaid, enabling concise but effective communication. To interact successfully\nand naturally with people, user-facing artificial intelligence systems will\nrequire similar skills in pragmatics: relying on various types of context --\nfrom shared linguistic goals and conventions, to the visual and embodied world\n-- to use language effectively. We survey existing grounded settings and\npragmatic modeling approaches and analyze how the task goals, environmental\ncontexts, and communicative affordances in each work enrich linguistic meaning.\nWe present recommendations for future grounded task design to naturally elicit\npragmatic phenomena, and suggest directions that focus on a broader range of\ncommunicative contexts and affordances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1\">Daniel Fried</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomlin_N/0/1/0/all/0/1\">Nicholas Tomlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jennifer Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_R/0/1/0/all/0/1\">Roma Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nematzadeh_A/0/1/0/all/0/1\">Aida Nematzadeh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Persian Typographical Error Type Detection Using Deep Neural Networks on Algorithmically-Generated Misspellings. (arXiv:2305.11731v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11731","description":"<p>Spelling correction is a remarkable challenge in the field of natural\nlanguage processing. The objective of spelling correction tasks is to recognize\nand rectify spelling errors automatically. The development of applications that\ncan effectually diagnose and correct Persian spelling and grammatical errors\nhas become more important in order to improve the quality of Persian text. The\nTypographical Error Type Detection in Persian is a relatively understudied\narea. Therefore, this paper presents a compelling approach for detecting\ntypographical errors in Persian texts. Our work includes the presentation of a\npublicly available dataset called FarsTypo, which comprises 3.4 million words\narranged in chronological order and tagged with their corresponding\npart-of-speech. These words cover a wide range of topics and linguistic styles.\nWe develop an algorithm designed to apply Persian-specific errors to a scalable\nportion of these words, resulting in a parallel dataset of correct and\nincorrect words. By leveraging FarsTypo, we establish a strong foundation and\nconduct a thorough comparison of various methodologies employing different\narchitectures. Additionally, we introduce a groundbreaking Deep Sequential\nNeural Network that utilizes both word and character embeddings, along with\nbidirectional LSTM layers, for token classification aimed at detecting\ntypographical errors across 51 distinct classes. Our approach is contrasted\nwith highly advanced industrial systems that, unlike this study, have been\ndeveloped using a diverse range of resources. The outcomes of our final method\nproved to be highly competitive, achieving an accuracy of 97.62%, precision of\n98.83%, recall of 98.61%, and surpassing others in terms of speed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Mohammad Dehghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faili_H/0/1/0/all/0/1\">Heshaam Faili</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Active Learning Principles for In-Context Learning with Large Language Models. (arXiv:2305.14264v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14264","description":"<p>The remarkable advancements in large language models (LLMs) have\nsignificantly enhanced the performance in few-shot learning settings. By using\nonly a small number of labeled examples, referred to as demonstrations, LLMs\ncan effectively grasp the task at hand through in-context learning. However,\nthe process of selecting appropriate demonstrations has received limited\nattention in prior work. This paper addresses the issue of identifying the most\ninformative demonstrations for few-shot learning by approaching it as a\npool-based Active Learning (AL) problem over a single iteration. Our objective\nis to investigate how AL algorithms can serve as effective demonstration\nselection methods for in-context learning. We compare various standard AL\nalgorithms based on uncertainty, diversity, and similarity, and consistently\nobserve that the latter outperforms all other methods, including random\nsampling. Notably, uncertainty sampling, despite its success in conventional\nsupervised learning scenarios, performs poorly in this context. Our extensive\nexperimentation involving a diverse range of GPT and OPT models across $24$\nclassification and multi-choice tasks, coupled with thorough analysis,\nunambiguously demonstrates that in-context example selection through AL\nprioritizes high-quality examples that exhibit low uncertainty and bear\nsimilarity to the test examples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Margatina_K/0/1/0/all/0/1\">Katerina Margatina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schick_T/0/1/0/all/0/1\">Timo Schick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dwivedi_Yu_J/0/1/0/all/0/1\">Jane Dwivedi-Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pre-training Language Models for Comparative Reasoning. (arXiv:2305.14457v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14457","description":"<p>Comparative reasoning is a process of comparing objects, concepts, or\nentities to draw conclusions, which constitutes a fundamental cognitive\nability. In this paper, we propose a novel framework to pre-train language\nmodels for enhancing their abilities of comparative reasoning over texts. While\nthere have been approaches for NLP tasks that require comparative reasoning,\nthey suffer from costly manual data labeling and limited generalizability to\ndifferent tasks. Our approach introduces a novel method of collecting scalable\ndata for text-based entity comparison, which leverages both structured and\nunstructured data. Moreover, we present a framework of pre-training language\nmodels via three novel objectives on comparative reasoning. Evaluation on\ndownstream tasks including comparative question answering, question generation,\nand summarization shows that our pre-training framework significantly improves\nthe comparative reasoning abilities of language models, especially under\nlow-resource conditions. This work also releases the first integrated benchmark\nfor comparative reasoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1\">Mengxia Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Dual-Stream Recurrence-Attention Network With Global-Local Awareness for Emotion Recognition in Textual Dialog. (arXiv:2307.00449v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.00449","description":"<p>In real-world dialog systems, the ability to understand the user's emotions\nand interact anthropomorphically is of great significance. Emotion Recognition\nin Conversation (ERC) is one of the key ways to accomplish this goal and has\nattracted growing attention. How to model the context in a conversation is a\ncentral aspect and a major challenge of ERC tasks. Most existing approaches\nstruggle to adequately incorporate both global and local contextual\ninformation, and their network structures are overly sophisticated. For this\nreason, we propose a simple and effective Dual-stream Recurrence-Attention\nNetwork (DualRAN), which is based on Recurrent Neural Network (RNN) and\nMulti-head ATtention network (MAT). DualRAN eschews the complex components of\ncurrent methods and focuses on combining recurrence-based methods with\nattention-based ones. DualRAN is a dual-stream structure mainly consisting of\nlocal- and global-aware modules, modeling a conversation simultaneously from\ndistinct perspectives. In addition, we develop two single-stream network\nvariants for DualRAN, i.e., SingleRANv1 and SingleRANv2. According to the\nexperimental findings, DualRAN boosts the weighted F1 scores by 1.43% and 0.64%\non the IEMOCAP and MELD datasets, respectively, in comparison to the strongest\nbaseline. On two other datasets (i.e., EmoryNLP and DailyDialog), our method\nalso attains competitive results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1\">Zhigang Zeng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals. (arXiv:2310.00603v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.00603","description":"<p>Causal explanations of the predictions of NLP systems are essential to ensure\nsafety and establish trust. Yet, existing methods often fall short of\nexplaining model predictions effectively or efficiently and are often\nmodel-specific. In this paper, we address model-agnostic explanations,\nproposing two approaches for counterfactual (CF) approximation. The first\napproach is CF generation, where a large language model (LLM) is prompted to\nchange a specific text concept while keeping confounding concepts unchanged.\nWhile this approach is demonstrated to be very effective, applying LLM at\ninference-time is costly. We hence present a second approach based on matching,\nand propose a method that is guided by an LLM at training-time and learns a\ndedicated embedding space. This space is faithful to a given causal graph and\neffectively serves to identify matches that approximate CFs. After showing\ntheoretically that approximating CFs is required in order to construct faithful\nexplanations, we benchmark our approaches and explain several models, including\nLLMs with billions of parameters. Our empirical results demonstrate the\nexcellent performance of CF generation models as model-agnostic explainers.\nMoreover, our matching approach, which requires far less test-time resources,\nalso provides effective explanations, surpassing many baselines. We also find\nthat Top-K techniques universally improve every tested method. Finally, we\nshowcase the potential of LLMs in constructing new benchmarks for model\nexplanation and subsequently validate our conclusions. Our work illuminates new\npathways for efficient and accurate approaches to interpreting NLP systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gat_Y/0/1/0/all/0/1\">Yair Gat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calderon_N/0/1/0/all/0/1\">Nitay Calderon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1\">Amir Feder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chapanin_A/0/1/0/all/0/1\">Alexander Chapanin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Amit Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1\">Roi Reichart</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation. (arXiv:2310.03214v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.03214","description":"<p>Most large language models (LLMs) are trained once and never updated; thus,\nthey lack the ability to dynamically adapt to our ever-changing world. In this\nwork, we perform a detailed study of the factuality of LLM-generated text in\nthe context of answering questions that test current world knowledge.\nSpecifically, we introduce FreshQA, a novel dynamic QA benchmark encompassing a\ndiverse range of question and answer types, including questions that require\nfast-changing world knowledge as well as questions with false premises that\nneed to be debunked. We benchmark a diverse array of both closed and\nopen-source LLMs under a two-mode evaluation procedure that allows us to\nmeasure both correctness and hallucination. Through human evaluations involving\nmore than 50K judgments, we shed light on limitations of these models and\ndemonstrate significant room for improvement: for instance, all models\n(regardless of model size) struggle on questions that involve fast-changing\nknowledge and false premises. Motivated by these results, we present\nFreshPrompt, a simple few-shot prompting method that substantially boosts the\nperformance of an LLM on FreshQA by incorporating relevant and up-to-date\ninformation retrieved from a search engine into the prompt. Our experiments\nshow that FreshPrompt outperforms both competing search engine-augmented\nprompting methods such as Self-Ask (Press et al., 2022) as well as commercial\nsystems such as Perplexity.AI. Further analysis of FreshPrompt reveals that\nboth the number of retrieved evidences and their order play a key role in\ninfluencing the correctness of LLM-generated answers. Additionally, instructing\nthe LLM to generate concise and direct answers helps reduce hallucination\ncompared to encouraging more verbose answers. To facilitate future work, we\nrelease FreshQA at github.com/freshllms/freshqa and commit to updating it at\nregular intervals.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1\">Tu Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1\">Mohit Iyyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuezhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Constant_N/0/1/0/all/0/1\">Noah Constant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jerry Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jason Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tar_C/0/1/0/all/0/1\">Chris Tar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1\">Yun-Hsuan Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Denny Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luong_T/0/1/0/all/0/1\">Thang Luong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Merging Experts into One: Improving Computational Efficiency of Mixture of Experts. (arXiv:2310.09832v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.09832","description":"<p>Scaling the size of language models usually leads to remarkable advancements\nin NLP tasks. But it often comes with a price of growing computational cost.\nAlthough a sparse Mixture of Experts (MoE) can reduce the cost by activating a\nsmall subset of parameters (e.g., one expert) for each input, its computation\nescalates significantly if increasing the number of activated experts, limiting\nits practical utility. Can we retain the advantages of adding more experts\nwithout substantially increasing the computational costs? In this paper, we\nfirst demonstrate the superiority of selecting multiple experts and then\npropose a computation-efficient approach called \\textbf{\\texttt{Merging Experts\ninto One}} (MEO), which reduces the computation cost to that of a single\nexpert. Extensive experiments show that MEO significantly improves\ncomputational efficiency, e.g., FLOPS drops from 72.0G of vanilla MoE to 28.6G\n(MEO). Moreover, we propose a token-level attention block that further enhances\nthe efficiency and performance of token-level MEO, e.g., 83.3\\% (MEO) vs.\n82.6\\% (vanilla MoE) average score on the GLUE benchmark. Our code will be\nreleased upon acceptance. Code will be released at:\n\\url{https://github.com/Shwai-He/MEO}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1\">Shwai He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_R/0/1/0/all/0/1\">Run-Ze Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lifelong Sequence Generation with Dynamic Module Expansion and Adaptation. (arXiv:2310.09886v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.09886","description":"<p>Lifelong sequence generation (LSG), a problem in continual learning, aims to\ncontinually train a model on a sequence of generation tasks to learn constantly\nemerging new generation patterns while avoiding the forgetting of previous\nknowledge. Existing LSG methods mainly focus on maintaining old knowledge while\npaying little attention to knowledge transfer across tasks. In contrast, humans\ncan better learn new tasks by leveraging previously acquired knowledge from\nsimilar tasks. Inspired by the learning paradigm of humans, we propose Dynamic\nModule Expansion and Adaptation (DMEA), which enables the model to dynamically\ndetermine the architecture for acquiring new knowledge based on task\ncorrelation and select the most similar previous tasks to facilitate adaptation\nto new tasks. In addition, as the learning process can easily be biased towards\nthe current task which might cause more severe forgetting of previously learned\nknowledge, we propose dynamic gradient scaling to balance the learning of the\ncurrent task and replayed tasks. With extensive experiments, we demonstrate\nthat DMEA can consistently outperform existing methods in different LSG\nsettings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1\">Chengwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Representational Capacity of Recurrent Neural Language Models. (arXiv:2310.12942v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12942","description":"<p>This work investigates the computational expressivity of language models\n(LMs) based on recurrent neural networks (RNNs). Siegelmann and Sontag (1992)\nfamously showed that RNNs with rational weights and hidden states and unbounded\ncomputation time are Turing complete. However, LMs define weightings over\nstrings in addition to just (unweighted) language membership and the analysis\nof the computational power of RNN LMs (RLMs) should reflect this. We extend the\nTuring completeness result to the probabilistic case, showing how a rationally\nweighted RLM with unbounded computation time can simulate any deterministic\nprobabilistic Turing machine (PTM) with rationally weighted transitions. Since,\nin practice, RLMs work in real-time, processing a symbol at every time step, we\ntreat the above result as an upper bound on the expressivity of RLMs. We also\nprovide a lower bound by showing that under the restriction to real-time\ncomputation, such models can simulate deterministic real-time rational PTMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nowak_F/0/1/0/all/0/1\">Franz Nowak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svete_A/0/1/0/all/0/1\">Anej Svete</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Li Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Integrating Pre-trained Language Model into Neural Machine Translation. (arXiv:2310.19680v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.19680","description":"<p>Neural Machine Translation (NMT) has become a significant technology in\nnatural language processing through extensive research and development.\nHowever, the deficiency of high-quality bilingual language pair data still\nposes a major challenge to improving NMT performance. Recent studies have been\nexploring the use of contextual information from pre-trained language model\n(PLM) to address this problem. Yet, the issue of incompatibility between PLM\nand NMT model remains unresolved. This study proposes PLM-integrated NMT\n(PiNMT) model to overcome the identified problems. PiNMT model consists of\nthree critical components, PLM Multi Layer Converter, Embedding Fusion, and\nCosine Alignment, each playing a vital role in providing effective PLM\ninformation to NMT. Furthermore, two training strategies, Separate Learning\nRates and Dual Step Training, are also introduced in this paper. By\nimplementing the proposed PiNMT model and training strategy, we achieve\nstate-of-the-art performance on the IWSLT'14 En$\\leftrightarrow$De dataset.\nThis study's outcomes are noteworthy as they demonstrate a novel approach for\nefficiently integrating PLM with NMT to overcome incompatibility and enhance\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Soon-Jae Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_C/0/1/0/all/0/1\">Chang-Sung Jeong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning. (arXiv:2311.00321v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.00321","description":"<p>With the proliferation of social media, accurate detection of hate speech has\nbecome critical to ensure safety online. To combat nuanced forms of hate\nspeech, it is important to identify and thoroughly explain hate speech to help\nusers understand its harmful effects. Recent benchmarks have attempted to\ntackle this issue by training generative models on free-text annotations of\nimplications in hateful text. However, we find significant reasoning gaps in\nthe existing annotations schemes, which may hinder the supervision of detection\nmodels. In this paper, we introduce a hate speech detection framework, HARE,\nwhich harnesses the reasoning capabilities of large language models (LLMs) to\nfill these gaps in explanations of hate speech, thus enabling effective\nsupervision of detection models. Experiments on SBIC and Implicit Hate\nbenchmarks show that our method, using model-generated data, consistently\noutperforms baselines, using existing free-text human annotations. Analysis\ndemonstrates that our method enhances the explanation quality of trained models\nand improves generalization to unseen datasets. Our code is available at\nhttps://github.com/joonkeekim/hare-hate-speech.git.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yongjin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Joonkee Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yujin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_N/0/1/0/all/0/1\">Namgyu Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1\">James Thorne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Se-young Yun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Language Agent for Autonomous Driving. (arXiv:2311.10813v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2311.10813","description":"<p>Human-level driving is an ultimate goal of autonomous driving. Conventional\napproaches formulate autonomous driving as a perception-prediction-planning\nframework, yet their systems do not capitalize on the inherent reasoning\nability and experiential knowledge of humans. In this paper, we propose a\nfundamental paradigm shift from current pipelines, exploiting Large Language\nModels (LLMs) as a cognitive agent to integrate human-like intelligence into\nautonomous driving systems. Our approach, termed Agent-Driver, transforms the\ntraditional autonomous driving pipeline by introducing a versatile tool library\naccessible via function calls, a cognitive memory of common sense and\nexperiential knowledge for decision-making, and a reasoning engine capable of\nchain-of-thought reasoning, task planning, motion planning, and\nself-reflection. Powered by LLMs, our Agent-Driver is endowed with intuitive\ncommon sense and robust reasoning capabilities, thus enabling a more nuanced,\nhuman-like approach to autonomous driving. We evaluate our approach on the\nlarge-scale nuScenes benchmark, and extensive experiments substantiate that our\nAgent-Driver significantly outperforms the state-of-the-art driving methods by\na large margin. Our approach also demonstrates superior interpretability and\nfew-shot learning ability to these methods. Code will be released.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiageng Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Junjie Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yuxi Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1\">Marco Pavone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yue Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In-Context Learning Functions with Varying Number of Minima. (arXiv:2311.12538v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2311.12538","description":"<p>Large Language Models (LLMs) have proven effective at In-Context Learning\n(ICL), an ability that allows them to create predictors from labeled examples.\nFew studies have explored the interplay between ICL and specific properties of\nfunctions it attempts to approximate. In our study, we use a formal framework\nto explore ICL and propose a new task of approximating functions with varying\nnumber of minima. We implement a method that allows for producing functions\nwith given inputs as minima. We find that increasing the number of minima\ndegrades ICL performance. At the same time, our evaluation shows that ICL\noutperforms 2-layer Neural Network (2NN) model. Furthermore, ICL learns faster\nthan 2NN in all settings. We validate the findings through a set of few-shot\nexperiments across various hyperparameter configurations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oniani_D/0/1/0/all/0/1\">David Oniani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanshan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-11-22T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/"}}]}]}