{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-09-11T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"LanSER: Language-Model Supported Speech Emotion Recognition. (arXiv:2309.03978v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03978","description":"<p>Speech emotion recognition (SER) models typically rely on costly\nhuman-labeled data for training, making scaling methods to large speech\ndatasets and nuanced emotion taxonomies difficult. We present LanSER, a method\nthat enables the use of unlabeled data by inferring weak emotion labels via\npre-trained large language models through weakly-supervised learning. For\ninferring weak labels constrained to a taxonomy, we use a textual entailment\napproach that selects an emotion label with the highest entailment score for a\nspeech transcript extracted via automatic speech recognition. Our experimental\nresults show that models pre-trained on large datasets with this weak\nsupervision outperform other baseline models on standard SER datasets when\nfine-tuned, and show improved label efficiency. Despite being pre-trained on\nlabels derived only from text, we show that the resulting representations\nappear to model the prosodic content of speech.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gong_T/0/1/0/all/0/1\">Taesik Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belanich_J/0/1/0/all/0/1\">Josh Belanich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Somandepalli_K/0/1/0/all/0/1\">Krishna Somandepalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagrani_A/0/1/0/all/0/1\">Arsha Nagrani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eoff_B/0/1/0/all/0/1\">Brian Eoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jou_B/0/1/0/all/0/1\">Brendan Jou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ConDA: Contrastive Domain Adaptation for AI-generated Text Detection. (arXiv:2309.03992v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03992","description":"<p>Large language models (LLMs) are increasingly being used for generating text\nin a variety of use cases, including journalistic news articles. Given the\npotential malicious nature in which these LLMs can be used to generate\ndisinformation at scale, it is important to build effective detectors for such\nAI-generated text. Given the surge in development of new LLMs, acquiring\nlabeled training data for supervised detectors is a bottleneck. However, there\nmight be plenty of unlabeled text data available, without information on which\ngenerator it came from. In this work we tackle this data problem, in detecting\nAI-generated news text, and frame the problem as an unsupervised domain\nadaptation task. Here the domains are the different text generators, i.e. LLMs,\nand we assume we have access to only the labeled source data and unlabeled\ntarget data. We develop a Contrastive Domain Adaptation framework, called\nConDA, that blends standard domain adaptation techniques with the\nrepresentation power of contrastive learning to learn domain invariant\nrepresentations that are effective for the final unsupervised detection task.\nOur experiments demonstrate the effectiveness of our framework, resulting in\naverage performance gains of 31.7% from the best performing baselines, and\nwithin 0.8% margin of a fully supervised detector. All our code and data is\navailable at https://github.com/AmritaBh/ConDA-gen-text-detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharjee_A/0/1/0/all/0/1\">Amrita Bhattacharjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumarage_T/0/1/0/all/0/1\">Tharindu Kumarage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moraffah_R/0/1/0/all/0/1\">Raha Moraffah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluation of large language models for discovery of gene set function. (arXiv:2309.04019v1 [q-bio.GN])","link":"http://arxiv.org/abs/2309.04019","description":"<p>Gene set analysis is a mainstay of functional genomics, but it relies on\nmanually curated databases of gene functions that are incomplete and unaware of\nbiological context. Here we evaluate the ability of OpenAI's GPT-4, a Large\nLanguage Model (LLM), to develop hypotheses about common gene functions from\nits embedded biomedical knowledge. We created a GPT-4 pipeline to label gene\nsets with names that summarize their consensus functions, substantiated by\nanalysis text and citations. Benchmarking against named gene sets in the Gene\nOntology, GPT-4 generated very similar names in 50% of cases, while in most\nremaining cases it recovered the name of a more general concept. In gene sets\ndiscovered in 'omics data, GPT-4 names were more informative than gene set\nenrichment, with supporting statements and citations that largely verified in\nhuman review. The ability to rapidly synthesize common gene functions positions\nLLMs as valuable functional genomics assistants.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-bio/1/au:+Hu_M/0/1/0/all/0/1\">Mengzhou Hu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Alkhairy_S/0/1/0/all/0/1\">Sahar Alkhairy</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lee_I/0/1/0/all/0/1\">Ingoo Lee</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Pillich_R/0/1/0/all/0/1\">Rudolf T. Pillich</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bachelder_R/0/1/0/all/0/1\">Robin Bachelder</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ideker_T/0/1/0/all/0/1\">Trey Ideker</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Pratt_D/0/1/0/all/0/1\">Dexter Pratt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TIDE: Textual Identity Detection for Evaluating and Augmenting Classification and Language Models. (arXiv:2309.04027v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04027","description":"<p>Machine learning models can perpetuate unintended biases from unfair and\nimbalanced datasets. Evaluating and debiasing these datasets and models is\nespecially hard in text datasets where sensitive attributes such as race,\ngender, and sexual orientation may not be available. When these models are\ndeployed into society, they can lead to unfair outcomes for historically\nunderrepresented groups. In this paper, we present a dataset coupled with an\napproach to improve text fairness in classifiers and language models. We create\na new, more comprehensive identity lexicon, TIDAL, which includes 15,123\nidentity terms and associated sense context across three demographic\ncategories. We leverage TIDAL to develop an identity annotation and\naugmentation tool that can be used to improve the availability of identity\ncontext and the effectiveness of ML fairness techniques. We evaluate our\napproaches using human contributors, and additionally run experiments focused\non dataset and model debiasing. Results show our assistive annotation technique\nimproves the reliability and velocity of human-in-the-loop processes. Our\ndataset and methods uncover more disparities during evaluation, and also\nproduce more fair models during remediation. These approaches provide a\npractical path forward for scaling classifier and generative model fairness in\nreal-world settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Klu_E/0/1/0/all/0/1\">Emmanuel Klu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sethi_S/0/1/0/all/0/1\">Sameer Sethi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multiple Representation Transfer from Large Language Models to End-to-End ASR Systems. (arXiv:2309.04031v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04031","description":"<p>Transferring the knowledge of large language models (LLMs) is a promising\ntechnique to incorporate linguistic knowledge into end-to-end automatic speech\nrecognition (ASR) systems. However, existing works only transfer a single\nrepresentation of LLM (e.g. the last layer of pretrained BERT), while the\nrepresentation of a text is inherently non-unique and can be obtained variously\nfrom different layers, contexts and models. In this work, we explore a wide\nrange of techniques to obtain and transfer multiple representations of LLMs\ninto a transducer-based ASR system. While being conceptually simple, we show\nthat transferring multiple representations of LLMs can be an effective\nalternative to transferring only a single representation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Udagawa_T/0/1/0/all/0/1\">Takuma Udagawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_M/0/1/0/all/0/1\">Masayuki Suzuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurata_G/0/1/0/all/0/1\">Gakuto Kurata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muraoka_M/0/1/0/all/0/1\">Masayasu Muraoka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saon_G/0/1/0/all/0/1\">George Saon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluation and Mitigation of Agnosia in Multimodal Large Language Models. (arXiv:2309.04041v1 [cs.CV])","link":"http://arxiv.org/abs/2309.04041","description":"<p>While Multimodal Large Language Models (MLLMs) are widely used for a variety\nof vision-language tasks, one observation is that they sometimes misinterpret\nvisual inputs or fail to follow textual instructions even in straightforward\ncases, leading to irrelevant responses, mistakes, and ungrounded claims. This\nobservation is analogous to a phenomenon in neuropsychology known as Agnosia,\nan inability to correctly process sensory modalities and recognize things\n(e.g., objects, colors, relations). In our study, we adapt this similar concept\nto define \"agnosia in MLLMs\", and our goal is to comprehensively evaluate and\nmitigate such agnosia in MLLMs. Inspired by the diagnosis and treatment process\nin neuropsychology, we propose a novel framework EMMA (Evaluation and\nMitigation of Multimodal Agnosia). In EMMA, we develop an evaluation module\nthat automatically creates fine-grained and diverse visual question answering\nexamples to assess the extent of agnosia in MLLMs comprehensively. We also\ndevelop a mitigation module to reduce agnosia in MLLMs through multimodal\ninstruction tuning on fine-grained conversations. To verify the effectiveness\nof our framework, we evaluate and analyze agnosia in seven state-of-the-art\nMLLMs using 9K test samples. The results reveal that most of them exhibit\nagnosia across various aspects and degrees. We further develop a fine-grained\ninstruction set and tune MLLMs to mitigate agnosia, which led to notable\nimprovement in accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiaying Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_J/0/1/0/all/0/1\">Jinmeng Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kezhen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xiaoyuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yawen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1\">Baochen Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Carl Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jie Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Multi-document Summarization with Holistic Inference. (arXiv:2309.04087v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04087","description":"<p>Multi-document summarization aims to obtain core information from a\ncollection of documents written on the same topic. This paper proposes a new\nholistic framework for unsupervised multi-document extractive summarization.\nOur method incorporates the holistic beam search inference method associated\nwith the holistic measurements, named Subset Representative Index (SRI). SRI\nbalances the importance and diversity of a subset of sentences from the source\ndocuments and can be calculated in unsupervised and adaptive manners. To\ndemonstrate the effectiveness of our method, we conduct extensive experiments\non both small and large-scale multi-document summarization datasets under both\nunsupervised and adaptive settings. The proposed method outperforms strong\nbaselines by a significant margin, as indicated by the resulting ROUGE scores\nand diversity measures. Our findings also suggest that diversity is essential\nfor improving multi-document summary performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haopeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1\">Sangwoo Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kaiqiang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiawei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Meta predictive learning model of natural languages. (arXiv:2309.04106v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04106","description":"<p>Large language models based on self-attention mechanisms have achieved\nastonishing performances not only in natural language itself, but also in a\nvariety of tasks of different nature. However, regarding processing language,\nour human brain may not operate using the same principle. Then, a debate is\nestablished on the connection between brain computation and artificial\nself-supervision adopted in large language models. One of most influential\nhypothesis in brain computation is the predictive coding framework, which\nproposes to minimize the prediction error by local learning. However, the role\nof predictive coding and the associated credit assignment in language\nprocessing remains unknown. Here, we propose a mean-field learning model within\nthe predictive coding framework, assuming that the synaptic weight of each\nconnection follows a spike and slab distribution, and only the distribution is\ntrained. This meta predictive learning is successfully validated on classifying\nhandwritten digits where pixels are input to the network in sequence, and on\nthe toy and real language corpus. Our model reveals that most of the\nconnections become deterministic after learning, while the output connections\nhave a higher level of variability. The performance of the resulting network\nensemble changes continuously with data load, further improving with more\ntraining data, in analogy with the emergent behavior of large language models.\nTherefore, our model provides a starting point to investigate the physics and\nbiology correspondences of the language processing and the unexpected general\nintelligence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1\">Junbin Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haiping Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RST-style Discourse Parsing Guided by Document-level Content Structures. (arXiv:2309.04141v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04141","description":"<p>Rhetorical Structure Theory based Discourse Parsing (RST-DP) explores how\nclauses, sentences, and large text spans compose a whole discourse and presents\nthe rhetorical structure as a hierarchical tree. Existing RST parsing pipelines\nconstruct rhetorical structures without the knowledge of document-level content\nstructures, which causes relatively low performance when predicting the\ndiscourse relations for large text spans. Recognizing the value of high-level\ncontent-related information in facilitating discourse relation recognition, we\npropose a novel pipeline for RST-DP that incorporates structure-aware news\ncontent sentence representations derived from the task of News Discourse\nProfiling. By incorporating only a few additional layers, this enhanced\npipeline exhibits promising performance across various RST parsing metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Ming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1\">Ruihong Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NESTLE: a No-Code Tool for Statistical Analysis of Legal Corpus. (arXiv:2309.04146v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04146","description":"<p>The statistical analysis of large scale legal corpus can provide valuable\nlegal insights. For such analysis one needs to (1) select a subset of the\ncorpus using document retrieval tools, (2) structuralize text using information\nextraction (IE) systems, and (3) visualize the data for the statistical\nanalysis. Each process demands either specialized tools or programming skills\nwhereas no comprehensive unified \"no-code\" tools have been available.\nEspecially for IE, if the target information is not predefined in the ontology\nof the IE system, one needs to build their own system. Here we provide NESTLE,\na no code tool for large-scale statistical analysis of legal corpus. With\nNESTLE, users can search target documents, extract information, and visualize\nthe structured data all via the chat interface with accompanying auxiliary GUI\nfor the fine-level control. NESTLE consists of three main components: a search\nengine, an end-to-end IE system, and a Large Language Model (LLM) that glues\nthe whole components together and provides the chat interface. Powered by LLM\nand the end-to-end IE system, NESTLE can extract any type of information that\nhas not been predefined in the IE system opening up the possibility of\nunlimited customizable statistical analysis of the corpus without writing a\nsingle line of code. The use of the custom end-to-end IE system also enables\nfaster and low-cost IE on large scale corpus. We validate our system on 15\nKorean precedent IE tasks and 3 legal text classification tasks from LEXGLUE.\nThe comprehensive experiments reveal NESTLE can achieve GPT-4 comparable\nperformance by training the internal IE module with 4 human-labeled, and 192\nLLM-labeled examples. The detailed analysis provides the insight on the\ntrade-off between accuracy, time, and cost in building such system.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyoungyeon Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Seungkum Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1\">Wonseok Hwang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-Utterance Conditioned VAE for Speech Generation. (arXiv:2309.04156v1 [cs.SD])","link":"http://arxiv.org/abs/2309.04156","description":"<p>Speech synthesis systems powered by neural networks hold promise for\nmultimedia production, but frequently face issues with producing expressive\nspeech and seamless editing. In response, we present the Cross-Utterance\nConditioned Variational Autoencoder speech synthesis (CUC-VAE S2) framework to\nenhance prosody and ensure natural speech generation. This framework leverages\nthe powerful representational capabilities of pre-trained language models and\nthe re-expression abilities of variational autoencoders (VAEs). The core\ncomponent of the CUC-VAE S2 framework is the cross-utterance CVAE, which\nextracts acoustic, speaker, and textual features from surrounding sentences to\ngenerate context-sensitive prosodic features, more accurately emulating human\nprosody generation. We further propose two practical algorithms tailored for\ndistinct speech synthesis applications: CUC-VAE TTS for text-to-speech and\nCUC-VAE SE for speech editing. The CUC-VAE TTS is a direct application of the\nframework, designed to generate audio with contextual prosody derived from\nsurrounding texts. On the other hand, the CUC-VAE SE algorithm leverages real\nmel spectrogram sampling conditioned on contextual information, producing audio\nthat closely mirrors real sound and thereby facilitating flexible speech\nediting based on text such as deletion, insertion, and replacement.\nExperimental results on the LibriTTS datasets demonstrate that our proposed\nmodels significantly enhance speech synthesis and editing, producing more\nnatural and expressive speech.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Cheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1\">Guangzhi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zu_W/0/1/0/all/0/1\">Weiqin Zu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zheng Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Ying Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1\">Wei Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1\">Fanglei Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GLS-CSC: A Simple but Effective Strategy to Mitigate Chinese STM Models' Over-Reliance on Superficial Clue. (arXiv:2309.04162v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04162","description":"<p>Pre-trained models have achieved success in Chinese Short Text Matching (STM)\ntasks, but they often rely on superficial clues, leading to a lack of robust\npredictions. To address this issue, it is crucial to analyze and mitigate the\ninfluence of superficial clues on STM models. Our study aims to investigate\ntheir over-reliance on the edit distance feature, commonly used to measure the\nsemantic similarity of Chinese text pairs, which can be considered a\nsuperficial clue. To mitigate STM models' over-reliance on superficial clues,\nwe propose a novel resampling training strategy called Gradually Learn Samples\nContaining Superficial Clue (GLS-CSC). Through comprehensive evaluations of\nIn-Domain (I.D.), Robustness (Rob.), and Out-Of-Domain (O.O.D.) test sets, we\ndemonstrate that GLS-CSC outperforms existing methods in terms of enhancing the\nrobustness and generalization of Chinese STM models. Moreover, we conduct a\ndetailed analysis of existing methods and reveal their commonality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yanrui Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Sendong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuhan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_R/0/1/0/all/0/1\">Rai Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Manifold-based Verbalizer Space Re-embedding for Tuning-free Prompt-based Classification. (arXiv:2309.04174v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04174","description":"<p>Prompt-based classification adapts tasks to a cloze question format utilizing\nthe [MASK] token and the filled tokens are then mapped to labels through\npre-defined verbalizers. Recent studies have explored the use of verbalizer\nembeddings to reduce labor in this process. However, all existing studies\nrequire a tuning process for either the pre-trained models or additional\ntrainable embeddings. Meanwhile, the distance between high-dimensional\nverbalizer embeddings should not be measured by Euclidean distance due to the\npotential for non-linear manifolds in the representation space. In this study,\nwe propose a tuning-free manifold-based space re-embedding method called\nLocally Linear Embedding with Intra-class Neighborhood Constraint (LLE-INC) for\nverbalizer embeddings, which preserves local properties within the same class\nas guidance for classification. Experimental results indicate that even without\ntuning any parameters, our LLE-INC is on par with automated verbalizers with\nparameter tuning. And with the parameter updating, our approach further\nenhances prompt-based tuning by up to 3.2%. Furthermore, experiments with the\nLLaMA-7B&amp;13B indicate that LLE-INC is an efficient tuning-free classification\napproach for the hyper-scale language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haochun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Sendong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_N/0/1/0/all/0/1\">Nuwa Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_M/0/1/0/all/0/1\">Muzhen Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge-tuning Large Language Models with Structured Medical Knowledge Bases for Reliable Response Generation in Chinese. (arXiv:2309.04175v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04175","description":"<p>Large Language Models (LLMs) have demonstrated remarkable success in diverse\nnatural language processing (NLP) tasks in general domains. However, LLMs\nsometimes generate responses with the hallucination about medical facts due to\nlimited domain knowledge. Such shortcomings pose potential risks in the\nutilization of LLMs within medical contexts. To address this challenge, we\npropose knowledge-tuning, which leverages structured medical knowledge bases\nfor the LLMs to grasp domain knowledge efficiently and facilitate reliable\nresponse generation. We also release cMedKnowQA, a Chinese medical knowledge\nquestion-answering dataset constructed from medical knowledge bases to assess\nthe medical knowledge proficiency of LLMs. Experimental results show that the\nLLMs which are knowledge-tuned with cMedKnowQA, can exhibit higher levels of\naccuracy in response generation compared with vanilla instruction-tuning and\noffer a new reliable way for the domain adaptation of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haochun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Sendong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiang_Z/0/1/0/all/0/1\">Zewen Qiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zijian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_N/0/1/0/all/0/1\">Nuwa Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yanrui Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_M/0/1/0/all/0/1\">MuZhen Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Haoqiang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuhan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haoming Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The CALLA Dataset: Probing LLMs' Interactive Knowledge Acquisition from Chinese Medical Literature. (arXiv:2309.04198v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04198","description":"<p>The application of Large Language Models (LLMs) to the medical domain has\nstimulated the interest of researchers. Recent studies have focused on\nconstructing Instruction Fine-Tuning (IFT) data through medical knowledge\ngraphs to enrich the interactive medical knowledge of LLMs. However, the\nmedical literature serving as a rich source of medical knowledge remains\nunexplored. Our work introduces the CALLA dataset to probe LLMs' interactive\nknowledge acquisition from Chinese medical literature. It assesses the\nproficiency of LLMs in mastering medical knowledge through a free-dialogue\nfact-checking task. We identify a phenomenon called the ``fact-following\nresponse``, where LLMs tend to affirm facts mentioned in questions and display\na reluctance to challenge them. To eliminate the inaccurate evaluation caused\nby this phenomenon, for the golden fact, we artificially construct test data\nfrom two perspectives: one consistent with the fact and one inconsistent with\nthe fact. Drawing from the probing experiment on the CALLA dataset, we conclude\nthat IFT data highly correlated with the medical literature corpus serves as a\npotent catalyst for LLMs, enabling themselves to skillfully employ the medical\nknowledge acquired during the pre-training phase within interactive scenarios,\nenhancing accuracy. Furthermore, we design a framework for automatically\nconstructing IFT data based on medical literature and discuss some real-world\napplications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yanrui Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Sendong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuhan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_R/0/1/0/all/0/1\">Rai Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UQ at #SMM4H 2023: ALEX for Public Health Analysis with Social Media. (arXiv:2309.04213v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04213","description":"<p>As social media becomes increasingly popular, more and more activities\nrelated to public health emerge. Current techniques for public health analysis\ninvolve popular models such as BERT and large language models (LLMs). However,\nthe costs of training in-domain LLMs for public health are especially\nexpensive. Furthermore, such kinds of in-domain datasets from social media are\ngenerally imbalanced. To tackle these challenges, the data imbalance issue can\nbe overcome by data augmentation and balanced training. Moreover, the ability\nof the LLMs can be effectively utilized by prompting the model properly. In\nthis paper, a novel ALEX framework is proposed to improve the performance of\npublic health analysis on social media by adopting an LLMs explanation\nmechanism. Results show that our ALEX model got the best performance among all\nsubmissions in both Task 2 and Task 4 with a high score in Task 1 in Social\nMedia Mining for Health 2023 (SMM4H)[1]. Our code has been released at https://\ngithub.com/YanJiangJerry/ALEX.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_R/0/1/0/all/0/1\">Ruihong Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zi Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting. (arXiv:2309.04269v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04269","description":"<p>Selecting the ``right'' amount of information to include in a summary is a\ndifficult task. A good summary should be detailed and entity-centric without\nbeing overly dense and hard to follow. To better understand this tradeoff, we\nsolicit increasingly dense GPT-4 summaries with what we refer to as a ``Chain\nof Density'' (CoD) prompt. Specifically, GPT-4 generates an initial\nentity-sparse summary before iteratively incorporating missing salient entities\nwithout increasing the length. Summaries generated by CoD are more abstractive,\nexhibit more fusion, and have less of a lead bias than GPT-4 summaries\ngenerated by a vanilla prompt. We conduct a human preference study on 100 CNN\nDailyMail articles and find that that humans prefer GPT-4 summaries that are\nmore dense than those generated by a vanilla prompt and almost as dense as\nhuman written summaries. Qualitative analysis supports the notion that there\nexists a tradeoff between informativeness and readability. 500 annotated CoD\nsummaries, as well as an extra 5,000 unannotated summaries, are freely\navailable on HuggingFace\n(https://huggingface.co/datasets/griffin/chain_of_density).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Adams_G/0/1/0/all/0/1\">Griffin Adams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabbri_A/0/1/0/all/0/1\">Alexander Fabbri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ladhak_F/0/1/0/all/0/1\">Faisal Ladhak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lehman_E/0/1/0/all/0/1\">Eric Lehman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhadad_N/0/1/0/all/0/1\">No&#xe9;mie Elhadad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fuzzy Fingerprinting Transformer Language-Models for Emotion Recognition in Conversations. (arXiv:2309.04292v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04292","description":"<p>Fuzzy Fingerprints have been successfully used as an interpretable text\nclassification technique, but, like most other techniques, have been largely\nsurpassed in performance by Large Pre-trained Language Models, such as BERT or\nRoBERTa. These models deliver state-of-the-art results in several Natural\nLanguage Processing tasks, namely Emotion Recognition in Conversations (ERC),\nbut suffer from the lack of interpretability and explainability. In this paper,\nwe propose to combine the two approaches to perform ERC, as a means to obtain\nsimpler and more interpretable Large Language Models-based classifiers. We\npropose to feed the utterances and their previous conversational turns to a\npre-trained RoBERTa, obtaining contextual embedding utterance representations,\nthat are then supplied to an adapted Fuzzy Fingerprint classification module.\nWe validate our approach on the widely used DailyDialog ERC benchmark dataset,\nin which we obtain state-of-the-art level results using a much lighter model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pereira_P/0/1/0/all/0/1\">Patr&#xed;cia Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_R/0/1/0/all/0/1\">Rui Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moniz_H/0/1/0/all/0/1\">Helena Moniz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coheur_L/0/1/0/all/0/1\">Luisa Coheur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_J/0/1/0/all/0/1\">Joao Paulo Carvalho</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Encoding Multi-Domain Scientific Papers by Ensembling Multiple CLS Tokens. (arXiv:2309.04333v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04333","description":"<p>Many useful tasks on scientific documents, such as topic classification and\ncitation prediction, involve corpora that span multiple scientific domains.\nTypically, such tasks are accomplished by representing the text with a vector\nembedding obtained from a Transformer's single CLS token. In this paper, we\nargue that using multiple CLS tokens could make a Transformer better specialize\nto multiple scientific domains. We present Multi2SPE: it encourages each of\nmultiple CLS tokens to learn diverse ways of aggregating token embeddings, then\nsums them up together to create a single vector representation. We also propose\nour new multi-domain benchmark, Multi-SciDocs, to test scientific paper vector\nencoders under multi-domain settings. We show that Multi2SPE reduces error by\nup to 25 percent in multi-domain citation prediction, while requiring only a\nnegligible amount of computation in addition to one BERT forward pass.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Seoh_R/0/1/0/all/0/1\">Ronald Seoh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1\">Haw-Shiuan Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1\">Andrew McCallum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Static Datasets: A Deep Interaction Approach to LLM Evaluation. (arXiv:2309.04369v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04369","description":"<p>Large Language Models (LLMs) have made progress in various real-world tasks,\nwhich stimulates requirements for the evaluation of LLMs. Existing LLM\nevaluation methods are mainly supervised signal-based which depends on static\ndatasets and cannot evaluate the ability of LLMs in dynamic real-world\nscenarios where deep interaction widely exists. Other LLM evaluation methods\nare human-based which are costly and time-consuming and are incapable of\nlarge-scale evaluation of LLMs. To address the issues above, we propose a novel\nDeep Interaction-based LLM-evaluation framework. In our proposed framework,\nLLMs' performances in real-world domains can be evaluated from their deep\ninteraction with other LLMs in elaborately designed evaluation tasks.\nFurthermore, our proposed framework is a general evaluation method that can be\napplied to a host of real-world tasks such as machine translation and code\ngeneration. We demonstrate the effectiveness of our proposed method through\nextensive experiments on four elaborately designed evaluation tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiatong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Rui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MoEController: Instruction-based Arbitrary Image Manipulation with Mixture-of-Expert Controllers. (arXiv:2309.04372v1 [cs.CV])","link":"http://arxiv.org/abs/2309.04372","description":"<p>Diffusion-model-based text-guided image generation has recently made\nastounding progress, producing fascinating results in open-domain image\nmanipulation tasks. Few models, however, currently have complete zero-shot\ncapabilities for both global and local image editing due to the complexity and\ndiversity of image manipulation tasks. In this work, we propose a method with a\nmixture-of-expert (MOE) controllers to align the text-guided capacity of\ndiffusion models with different kinds of human instructions, enabling our model\nto handle various open-domain image manipulation tasks with natural language\ninstructions. First, we use large language models (ChatGPT) and conditional\nimage synthesis models (ControlNet) to generate a large number of global image\ntransfer dataset in addition to the instruction-based local image editing\ndataset. Then, using an MOE technique and task-specific adaptation training on\na large-scale dataset, our conditional diffusion model can edit images globally\nand locally. Extensive experiments demonstrate that our approach performs\nsurprisingly well on various image manipulation tasks when dealing with\nopen-domain images and arbitrary human instructions. Please refer to our\nproject page: [https://oppo-mente-lab.github.io/moe_controller/]\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sijia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Haonan Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CSPRD: A Financial Policy Retrieval Dataset for Chinese Stock Market. (arXiv:2309.04389v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04389","description":"<p>In recent years, great advances in pre-trained language models (PLMs) have\nsparked considerable research focus and achieved promising performance on the\napproach of dense passage retrieval, which aims at retrieving relative passages\nfrom massive corpus with given questions. However, most of existing datasets\nmainly benchmark the models with factoid queries of general commonsense, while\nspecialised fields such as finance and economics remain unexplored due to the\ndeficiency of large-scale and high-quality datasets with expert annotations. In\nthis work, we propose a new task, policy retrieval, by introducing the Chinese\nStock Policy Retrieval Dataset (CSPRD), which provides 700+ prospectus passages\nlabeled by experienced experts with relevant articles from 10k+ entries in our\ncollected Chinese policy corpus. Experiments on lexical, embedding and\nfine-tuned bi-encoder models show the effectiveness of our proposed CSPRD yet\nalso suggests ample potential for improvement. Our best performing baseline\nachieves 56.1% MRR@10, 28.5% NDCG@10, 37.5% Recall@10 and 80.6% Precision@10 on\ndev set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jinyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zeyang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jinhao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Y/0/1/0/all/0/1\">Yongjian Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1\">Dawei Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models. (arXiv:2309.04461v1 [cs.CL])","link":"http://arxiv.org/abs/2309.04461","description":"<p>Vision-language models (VLMs) have recently demonstrated strong efficacy as\nvisual assistants that can parse natural queries about the visual content and\ngenerate human-like outputs. In this work, we explore the ability of these\nmodels to demonstrate human-like reasoning based on the perceived information.\nTo address a crucial concern regarding the extent to which their reasoning\ncapabilities are fully consistent and grounded, we also measure the reasoning\nconsistency of these models. We achieve this by proposing a chain-of-thought\n(CoT) based consistency measure. However, such an evaluation requires a\nbenchmark that encompasses both high-level inference and detailed reasoning\nchains, which is costly. We tackle this challenge by proposing a\nLLM-Human-in-the-Loop pipeline, which notably reduces cost while simultaneously\nensuring the generation of a high-quality dataset. Based on this pipeline and\nthe existing coarse-grained annotated dataset, we build the CURE benchmark to\nmeasure both the zero-shot reasoning performance and consistency of VLMs. We\nevaluate existing state-of-the-art VLMs, and find that even the best-performing\nmodel is unable to demonstrate strong visual reasoning capabilities and\nconsistency, indicating that substantial efforts are required to enable VLMs to\nperform visual reasoning as systematically and consistently as humans. As an\nearly step, we propose a two-stage training framework aimed at improving both\nthe reasoning performance and consistency of VLMs. The first stage involves\nemploying supervised fine-tuning of VLMs using step-by-step reasoning samples\nautomatically generated by LLMs. In the second stage, we further augment the\ntraining process by incorporating feedback provided by LLMs to produce\nreasoning chains that are highly consistent and grounded. We empirically\nhighlight the effectiveness of our framework in both reasoning performance and\nconsistency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yangyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sikka_K/0/1/0/all/0/1\">Karan Sikka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cogswell_M/0/1/0/all/0/1\">Michael Cogswell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Divakaran_A/0/1/0/all/0/1\">Ajay Divakaran</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting Text Formality: A Study of Text Classification Approaches. (arXiv:2204.08975v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.08975","description":"<p>Formality is one of the important characteristics of text documents. The\nautomatic detection of the formality level of a text is potentially beneficial\nfor various natural language processing tasks. Before, two large-scale datasets\nwere introduced for multiple languages featuring formality annotation -- GYAFC\nand X-FORMAL. However, they were primarily used for the training of style\ntransfer models. At the same time, the detection of text formality on its own\nmay also be a useful application. This work proposes the first to our knowledge\nsystematic study of formality detection methods based on statistical,\nneural-based, and Transformer-based machine learning methods and delivers the\nbest-performing models for public usage. We conducted three types of\nexperiments -- monolingual, multilingual, and cross-lingual. The study shows\nthe overcome of Char BiLSTM model over Transformer-based ones for the\nmonolingual and multilingual formality classification task, while\nTransformer-based classifiers are more stable to cross-lingual knowledge\ntransfer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dementieva_D/0/1/0/all/0/1\">Daryna Dementieva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babakov_N/0/1/0/all/0/1\">Nikolay Babakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panchenko_A/0/1/0/all/0/1\">Alexander Panchenko</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Less is More: A Lightweight and Robust Neural Architecture for Discourse Parsing. (arXiv:2210.09537v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.09537","description":"<p>Complex feature extractors are widely employed for text representation\nbuilding. However, these complex feature extractors make the NLP systems prone\nto overfitting especially when the downstream training datasets are relatively\nsmall, which is the case for several discourse parsing tasks. Thus, we propose\nan alternative lightweight neural architecture that removes multiple complex\nfeature extractors and only utilizes learnable self-attention modules to\nindirectly exploit pretrained neural language models, in order to maximally\npreserve the generalizability of pre-trained language models. Experiments on\nthree common discourse parsing tasks show that powered by recent pretrained\nlanguage models, the lightweight architecture consisting of only two\nself-attention layers obtains much better generalizability and robustness.\nMeanwhile, it achieves comparable or even better system performance with fewer\nlearnable parameters and less processing time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Ming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1\">Ruihong Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TikTalk: A Video-Based Dialogue Dataset for Multi-Modal Chitchat in Real World. (arXiv:2301.05880v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.05880","description":"<p>To facilitate the research on intelligent and human-like chatbots with\nmulti-modal context, we introduce a new video-based multi-modal dialogue\ndataset, called TikTalk. We collect 38K videos from a popular video-sharing\nplatform, along with 367K conversations posted by users beneath them. Users\nengage in spontaneous conversations based on their multi-modal experiences from\nwatching videos, which helps recreate real-world chitchat context. Compared to\nprevious multi-modal dialogue datasets, the richer context types in TikTalk\nlead to more diverse conversations, but also increase the difficulty in\ncapturing human interests from intricate multi-modal information to generate\npersonalized responses. Moreover, external knowledge is more frequently evoked\nin our dataset. These facts reveal new challenges for multi-modal dialogue\nmodels. We quantitatively demonstrate the characteristics of TikTalk, propose a\nvideo-based multi-modal chitchat task, and evaluate several dialogue baselines.\nExperimental results indicate that the models incorporating large language\nmodels (LLM) can generate more diverse responses, while the model utilizing\nknowledge graphs to introduce external knowledge performs the best overall.\nFurthermore, no existing model can solve all the above challenges well. There\nis still a large room for future improvements, even for LLM with visual\nextensions. Our dataset is available at\n\\url{https://ruc-aimind.github.io/projects/TikTalk/}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongpeng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruan_L/0/1/0/all/0/1\">Ludan Ruan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1\">Wenke Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Peiyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Jingyuan Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yixin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Di Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1\">Ruihua Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiwu Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MQAG: Multiple-choice Question Answering and Generation for Assessing Information Consistency in Summarization. (arXiv:2301.12307v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.12307","description":"<p>State-of-the-art summarization systems can generate highly fluent summaries.\nThese summaries, however, may contain factual inconsistencies and/or\ninformation not present in the source. Hence, an important component of\nassessing the quality of summaries is to determine whether there is information\nconsistency between the source and the summary. Existing approaches are\ntypically based on lexical matching or representation-based methods. In this\nwork, we introduce an alternative scheme based on standard\ninformation-theoretic measures in which the information present in the source\nand summary is directly compared. We propose a Multiple-choice Question\nAnswering and Generation framework, MQAG, which approximates the information\nconsistency by computing the expected statistical distance between summary and\nsource answer distributions over automatically generated multiple-choice\nquestions. This approach exploits multiple-choice answer probabilities, as\npredicted answer distributions can be compared. We conduct experiments on four\nsummary evaluation datasets: QAG-CNNDM/XSum, XSum-Hallucination, Podcast\nAssessment, and SummEval. Experiments show that MQAG, using models trained on\nSQuAD or RACE, outperforms existing evaluation methods on the majority of\ntasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Manakul_P/0/1/0/all/0/1\">Potsawee Manakul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liusie_A/0/1/0/all/0/1\">Adian Liusie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gales_M/0/1/0/all/0/1\">Mark J. F. Gales</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Entity Tracking in Language Models. (arXiv:2305.02363v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02363","description":"<p>Keeping track of how states of entities change as a text or dialog unfolds is\na key prerequisite to discourse understanding. Yet, there have been few\nsystematic investigations into the ability of large language models (LLMs) to\ntrack discourse entities. In this work, we present a task probing to what\nextent a language model can infer the final state of an entity given an English\ndescription of the initial state and a series of state-changing operations. We\nuse this task to first investigate whether Flan-T5, GPT-3 and GPT-3.5 can track\nthe state of entities, and find that only GPT-3.5 models, which have been\npretrained on large amounts of code, exhibit this ability. We then investigate\nwhether smaller models pretrained primarily on text can learn to track\nentities, through finetuning T5 on several training/evaluation splits. While\nperformance degrades for more complex splits, we find that even when evaluated\non a different set of entities from training or longer operation sequences, a\nfinetuned model can perform non-trivial entity tracking. Taken together, these\nresults suggest that language models can learn to track entities but\npretraining on text corpora alone does not make this capacity surface.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1\">Najoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuster_S/0/1/0/all/0/1\">Sebastian Schuster</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Conditional Generative Chatbot using Transformer Model. (arXiv:2306.02074v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.02074","description":"<p>A Chatbot serves as a communication tool between a human user and a machine\nto achieve an appropriate answer based on the human input. In more recent\napproaches, a combination of Natural Language Processing and sequential models\nare used to build a generative Chatbot. The main challenge of these models is\ntheir sequential nature, which leads to less accurate results. To tackle this\nchallenge, in this paper, a novel architecture is proposed using conditional\nWasserstein Generative Adversarial Networks and a transformer model for answer\ngeneration in Chatbots. While the generator of the proposed model consists of a\nfull transformer model to generate an answer, the discriminator includes only\nthe encoder part of a transformer model followed by a classifier. To the best\nof our knowledge, this is the first time that a generative Chatbot is proposed\nusing the embedded transformer in both generator and discriminator models.\nRelying on the parallel computing of the transformer model, the results of the\nproposed model on the Cornell Movie-Dialog corpus and the Chit-Chat datasets\nconfirm the superiority of the proposed model compared to state-of-the-art\nalternatives using different evaluation metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Esfandiari_N/0/1/0/all/0/1\">Nura Esfandiari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiani_K/0/1/0/all/0/1\">Kourosh Kiani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastgoo_R/0/1/0/all/0/1\">Razieh Rastgoo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ValiTex -- a unified validation framework for computational text-based measures of social science constructs. (arXiv:2307.02863v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.02863","description":"<p>Guidance on how to validate computational text-based measures of social\nscience constructs is fragmented. Although scholars generally acknowledge the\nimportance of validating their text-based measures, they often lack common\nterminology and a unified framework to do so. This paper introduces ValiTex, a\nnew validation framework designed to assist scholars in validly measuring\nsocial science constructs based on textual data. The framework draws on a\nlong-established validity concept in psychometrics but extends these concepts\nto cover the specific needs of computational text analysis. ValiTex consists of\ntwo components, a conceptual framework and a dynamic checklist. Whereas the\nconceptual framework provides a general structure along distinct phases on how\nto approach validation, the dynamic checklist defines specific validation steps\nand provides guidance on which steps might be considered recommendable (i.e.,\nproviding relevant and necessary validation evidence) or optional (i.e., useful\nfor providing additional supporting validation evidence). We demonstrate the\nutility of the framework by applying it to a use case of detecting sexism from\nsocial media data\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Birkenmaier_L/0/1/0/all/0/1\">Lukas Birkenmaier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_C/0/1/0/all/0/1\">Claudia Wagner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lechner_C/0/1/0/all/0/1\">Clemens Lechner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning. (arXiv:2308.12032v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.12032","description":"<p>In the realm of Large Language Models, the balance between instruction data\nquality and quantity has become a focal point. Recognizing this, we introduce a\nself-guided methodology for LLMs to autonomously discern and select cherry\nsamples from vast open-source datasets, effectively minimizing manual curation\nand potential cost for instruction tuning an LLM. Our key innovation, the\nInstruction-Following Difficulty (IFD) metric, emerges as a pivotal tool to\nidentify discrepancies between a model's expected responses and its autonomous\ngeneration prowess. Through the adept application of IFD, cherry samples are\npinpointed, leading to a marked uptick in model training efficiency. Empirical\nvalidations on renowned datasets like Alpaca and WizardLM underpin our\nfindings; with a mere 10% of conventional data input, our strategy showcases\nimproved results. This synthesis of self-guided cherry-picking and the IFD\nmetric signifies a transformative leap in the optimization of LLMs, promising\nboth efficiency and resource-conscious advancements.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Ming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhitao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiuhai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lichang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_N/0/1/0/all/0/1\">Ning Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianzong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1\">Jing Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation. (arXiv:2308.15363v2 [cs.DB] UPDATED)","link":"http://arxiv.org/abs/2308.15363","description":"<p>Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL\ntask. However, the absence of a systematical benchmark inhibits the development\nof designing effective, efficient and economic LLM-based Text-to-SQL solutions.\nTo address this challenge, in this paper, we first conduct a systematical and\nextensive comparison over existing prompt engineering methods, including\nquestion representation, example selection and example organization, and with\nthese experimental results, we elaborate their pros and cons. Based on these\nfindings, we propose a new integrated solution, named DAIL-SQL, which refreshes\nthe Spider leaderboard with 86.6% execution accuracy and sets a new bar. To\nexplore the potential of open-source LLM, we investigate them in various\nscenarios, and further enhance their performance with supervised fine-tuning.\nOur explorations highlight open-source LLMs' potential in Text-to-SQL, as well\nas the advantages and disadvantages of the supervised fine-tuning.\nAdditionally, towards an efficient and economic LLM-based Text-to-SQL solution,\nwe emphasize the token efficiency in prompt engineering and compare the prior\nstudies under this metric. We hope that our work provides a deeper\nunderstanding of Text-to-SQL with LLMs, and inspires further investigations and\nbroad applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_D/0/1/0/all/0/1\">Dawei Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haibin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yaliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiuyu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yichen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1\">Bolin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"When Do Program-of-Thoughts Work for Reasoning?. (arXiv:2308.15452v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.15452","description":"<p>The reasoning capabilities of Large Language Models (LLMs) play a pivotal\nrole in the realm of embodied artificial intelligence. Although there are\neffective methods like program-of-thought prompting for LLMs which uses\nprogramming language to tackle complex reasoning tasks, the specific impact of\ncode data on the improvement of reasoning capabilities remains under-explored.\nTo address this gap, we propose complexity-impacted reasoning score (CIRS),\nwhich combines structural and logical attributes, to measure the correlation\nbetween code and reasoning abilities. Specifically, we use the abstract syntax\ntree to encode the structural information and calculate logical complexity by\nconsidering the difficulty and the cyclomatic complexity. Through an empirical\nanalysis, we find not all code data of complexity can be learned or understood\nby LLMs. Optimal level of complexity is critical to the improvement of\nreasoning abilities by program-aided prompting. Then we design an\nauto-synthesizing and stratifying algorithm, and apply it to instruction\ngeneration for mathematical reasoning and code data filtering for code\ngeneration tasks. Extensive results demonstrates the effectiveness of our\nproposed approach. Code will be integrated into the EasyInstruct framework at\nhttps://github.com/zjunlp/EasyInstruct.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1\">Zhen Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yinuo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guozhou Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation. (arXiv:2308.16797v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.16797","description":"<p>Despite significant research effort in the development of automatic dialogue\nevaluation metrics, little thought is given to evaluating dialogues other than\nin English. At the same time, ensuring metrics are invariant to semantically\nsimilar responses is also an overlooked topic. In order to achieve the desired\nproperties of robustness and multilinguality for dialogue evaluation metrics,\nwe propose a novel framework that takes advantage of the strengths of current\nevaluation models with the newly-established paradigm of prompting Large\nLanguage Models (LLMs). Empirical results show our framework achieves state of\nthe art results in terms of mean Spearman correlation scores across several\nbenchmarks and ranks first place on both the Robust and Multilingual tasks of\nthe DSTC11 Track 4 \"Automatic Evaluation Metrics for Open-Domain Dialogue\nSystems\", proving the evaluation capabilities of prompted LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mendonca_J/0/1/0/all/0/1\">John Mendon&#xe7;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pereira_P/0/1/0/all/0/1\">Patr&#xed;cia Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moniz_H/0/1/0/all/0/1\">Helena Moniz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_J/0/1/0/all/0/1\">Jo&#xe3;o Paulo Carvalho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavie_A/0/1/0/all/0/1\">Alon Lavie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trancoso_I/0/1/0/all/0/1\">Isabel Trancoso</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior. (arXiv:2309.00359v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.00359","description":"<p>Shannon, in his seminal paper introducing information theory, divided the\ncommunication into three levels: technical, semantic, and effectivenss. While\nthe technical level is concerned with accurate reconstruction of transmitted\nsymbols, the semantic and effectiveness levels deal with the inferred meaning\nand its effect on the receiver. Thanks to telecommunications, the first level\nproblem has produced great advances like the internet. Large Language Models\n(LLMs) make some progress towards the second goal, but the third level still\nremains largely untouched. The third problem deals with predicting and\noptimizing communication for desired receiver behavior. LLMs, while showing\nwide generalization capabilities across a wide range of tasks, are unable to\nsolve for this. One reason for the underperformance could be a lack of\n\"behavior tokens\" in LLMs' training corpora. Behavior tokens define receiver\nbehavior over a communication, such as shares, likes, clicks, purchases,\nretweets, etc. While preprocessing data for LLM training, behavior tokens are\noften removed from the corpora as noise. Therefore, in this paper, we make some\ninitial progress towards reintroducing behavior tokens in LLM training. The\ntrained models, other than showing similar performance to LLMs on content\nunderstanding tasks, show generalization capabilities on behavior simulation,\ncontent simulation, behavior understanding, and behavior domain adaptation.\nUsing a wide range of tasks on two corpora, we show results on all these\ncapabilities. We call these models Large Content and Behavior Models (LCBMs).\nFurther, to spur more research on LCBMs, we release our new Content Behavior\nCorpus (CBC), a repository containing communicator, message, and corresponding\nreceiver behavior.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khandelwal_A/0/1/0/all/0/1\">Ashmit Khandelwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1\">Aditya Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharyya_A/0/1/0/all/0/1\">Aanisha Bhattacharyya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_Y/0/1/0/all/0/1\">Yaman K Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Somesh Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_U/0/1/0/all/0/1\">Uttaran Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dasgupta_I/0/1/0/all/0/1\">Ishita Dasgupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrangeli_S/0/1/0/all/0/1\">Stefano Petrangeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rajiv Ratn Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changyou Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_B/0/1/0/all/0/1\">Balaji Krishnamurthy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"All Labels Together: Low-shot Intent Detection with an Efficient Label Semantic Encoding Paradigm. (arXiv:2309.03563v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.03563","description":"<p>In intent detection tasks, leveraging meaningful semantic information from\nintent labels can be particularly beneficial for few-shot scenarios. However,\nexisting few-shot intent detection methods either ignore the intent labels,\n(e.g. treating intents as indices) or do not fully utilize this information\n(e.g. only using part of the intent labels). In this work, we present an\nend-to-end One-to-All system that enables the comparison of an input utterance\nwith all label candidates. The system can then fully utilize label semantics in\nthis way. Experiments on three few-shot intent detection tasks demonstrate that\nOne-to-All is especially effective when the training resource is extremely\nscarce, achieving state-of-the-art performance in 1-, 3- and 5-shot settings.\nMoreover, we present a novel pretraining strategy for our model that utilizes\nindirect supervision from paraphrasing, enabling zero-shot cross-domain\ngeneralization on intent detection tasks. Our code is at\nhttps://github.com/jiangshdd/AllLablesTogether.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Jiangshu Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1\">Congying Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1\">Wenpeng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_T/0/1/0/all/0/1\">Tingting Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring an LM to generate Prolog Predicates from Mathematics Questions. (arXiv:2309.03667v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.03667","description":"<p>Recently, there has been a surge in interest in NLP driven by ChatGPT.\nChatGPT, a transformer-based generative language model of substantial scale,\nexhibits versatility in performing various tasks based on natural language.\nNevertheless, large language models often exhibit poor performance in solving\nmathematics questions that require reasoning. Prior research has demonstrated\nthe effectiveness of chain-of-thought prompting in enhancing reasoning\ncapabilities. Now, we aim to investigate whether fine-tuning a model for the\ngeneration of Prolog codes, a logic language, and subsequently passing these\ncodes to a compiler can further improve accuracy. Consequently, we employ\nchain-of-thought to fine-tune LLaMA7B as a baseline model and develop other\nfine-tuned LLaMA7B models for the generation of Prolog code, Prolog code +\nchain-of-thought, and chain-of-thought + Prolog code, respectively. The results\nreveal that the Prolog generation model surpasses the baseline in performance,\nwhile the combination generation models do not yield significant improvements.\nThe Prolog corpus based on GSM8K and the correspondingly finetuned Prolog\ngeneration model based on LLaMA7B are released to the research community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaocheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tam_Y/0/1/0/all/0/1\">Yik-Cheung Tam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Large Language Models' Selection Bias in Multi-Choice Questions. (arXiv:2309.03882v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.03882","description":"<p>Multi-choice questions (MCQs) serve as a common yet important task format in\nthe research of large language models (LLMs). Our work shows that LLMs exhibit\nan inherent \"selection bias\" in MCQs, which refers to LLMs' preferences to\nselect options located at specific positions (like \"Option C\"). This bias is\nprevalent across various LLMs, making their performance vulnerable to option\nposition changes in MCQs. We identify that one primary cause resulting in\nselection bias is option numbering, i.e., the ID symbols A/B/C/D associated\nwith the options. To mitigate selection bias, we propose a new method called\nPriDe. PriDe first decomposes the observed model prediction distribution into\nan intrinsic prediction over option contents and a prior distribution over\noption IDs. It then estimates the prior by permutating option contents on a\nsmall number of test samples, which is used to debias the subsequent test\nsamples. We demonstrate that, as a label-free, inference-time method, PriDe\nachieves a more effective and computation-efficient debiasing than strong\nbaselines. We further show that the priors estimated by PriDe generalize well\nacross different domains, highlighting its practical potential in broader\nscenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chujie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparing How a Chatbot References User Utterances from Previous Chatting Sessions: An Investigation of Users' Privacy Concerns and Perceptions. (arXiv:2308.04879v1 [cs.HC] CROSS LISTED)","link":"http://arxiv.org/abs/2308.04879","description":"<p>Chatbots are capable of remembering and referencing previous conversations,\nbut does this enhance user engagement or infringe on privacy? To explore this\ntrade-off, we investigated the format of how a chatbot references previous\nconversations with a user and its effects on a user's perceptions and privacy\nconcerns. In a three-week longitudinal between-subjects study, 169 participants\ntalked about their dental flossing habits to a chatbot that either, (1-None):\ndid not explicitly reference previous user utterances, (2-Verbatim): referenced\nprevious utterances verbatim, or (3-Paraphrase): used paraphrases to reference\nprevious utterances. Participants perceived Verbatim and Paraphrase chatbots as\nmore intelligent and engaging. However, the Verbatim chatbot also raised\nprivacy concerns with participants. To gain insights as to why people prefer\ncertain conditions or had privacy concerns, we conducted semi-structured\ninterviews with 15 participants. We discuss implications from our findings that\ncan help designers choose an appropriate format to reference previous user\nutterances and inform in the design of longitudinal dialogue scripting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cox_S/0/1/0/all/0/1\">Samuel Rhys Cox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yi-Chieh Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ooi_W/0/1/0/all/0/1\">Wei Tsang Ooi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-09-10T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","dc":"http://purl.org/dc/elements/1.1/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/"}}]}]}