{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-10-04T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Cordyceps@LT-EDI: Depression Detection with Reddit and Self-training. (arXiv:2310.01418v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01418","description":"<p>Depression is debilitating, and not uncommon. Indeed, studies of excessive\nsocial media users show correlations with depression, ADHD, and other mental\nhealth concerns. Given that there is a large number of people with excessive\nsocial media usage, then there is a significant population of potentially\nundiagnosed users and posts that they create. In this paper, we propose a\ndepression severity detection system using a semi-supervised learning technique\nto predict if a post is from a user who is experiencing severe, moderate, or\nlow (non-diagnostic) levels of depression. Namely, we use a trained model to\nclassify a large number of unlabelled social media posts from Reddit, then use\nthese generated labels to train a more powerful classifier. We demonstrate our\nframework on Detecting Signs of Depression from Social Media Text -\nLT-EDI@RANLP 2023 shared task, where our framework ranks 3rd overall.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ninalga_D/0/1/0/all/0/1\">Dean Ninalga</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ruffle&Riley: Towards the Automated Induction of Conversational Tutoring Systems. (arXiv:2310.01420v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01420","description":"<p>Conversational tutoring systems (CTSs) offer learning experiences driven by\nnatural language interaction. They are known to promote high levels of\ncognitive engagement and benefit learning outcomes, particularly in reasoning\ntasks. Nonetheless, the time and cost required to author CTS content is a major\nobstacle to widespread adoption. In this paper, we introduce a novel type of\nCTS that leverages the recent advances in large language models (LLMs) in two\nways: First, the system induces a tutoring script automatically from a lesson\ntext. Second, the system automates the script orchestration via two LLM-based\nagents (Ruffle&amp;Riley) with the roles of a student and a professor in a\nlearning-by-teaching format. The system allows a free-form conversation that\nfollows the ITS-typical outer-/inner-loop structure. In an initial\nbetween-subject online user study (N = 100) comparing Ruffle&amp;Riley to simpler\nQA chatbots and reading activity, we found no significant differences in\npost-test scores. Nonetheless, in the learning experience survey, Ruffle&amp;Riley\nusers expressed higher ratings of understanding and remembering and further\nperceived the offered support as more helpful and the conversation as coherent.\nOur study provides insights for a new generation of scalable CTS technologies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schmucker_R/0/1/0/all/0/1\">Robin Schmucker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Meng Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azaria_A/0/1/0/all/0/1\">Amos Azaria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_T/0/1/0/all/0/1\">Tom Mitchell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Empirical Study of AI Generated Text Detection Tools. (arXiv:2310.01423v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01423","description":"<p>Since ChatGPT has emerged as a major AIGC model, providing high-quality\nresponses across a wide range of applications (including software development\nand maintenance), it has attracted much interest from many individuals. ChatGPT\nhas great promise, but there are serious problems that might arise from its\nmisuse, especially in the realms of education and public safety. Several AIGC\ndetectors are available, and they have all been tested on genuine text.\nHowever, more study is needed to see how effective they are for multi-domain\nChatGPT material. This study aims to fill this need by creating a multi-domain\ndataset for testing the state-of-the-art APIs and tools for detecting\nartificially generated information used by universities and other research\ninstitutions. A large dataset consisting of articles, abstracts, stories, news,\nand product reviews was created for this study. The second step is to use the\nnewly created dataset to put six tools through their paces. Six different\nartificial intelligence (AI) text identification systems, including \"GPTkit,\"\n\"GPTZero,\" \"Originality,\" \"Sapling,\" \"Writer,\" and \"Zylalab,\" have accuracy\nrates between 55.29 and 97.0%. Although all the tools fared well in the\nevaluations, originality was particularly effective across the board.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Akram_A/0/1/0/all/0/1\">Arslan Akram</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Identifying and Mitigating Privacy Risks Stemming from Language Models: A Survey. (arXiv:2310.01424v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01424","description":"<p>Rapid advancements in language models (LMs) have led to their adoption across\nmany sectors. Alongside the potential benefits, such models present a range of\nrisks, including around privacy. In particular, as LMs have grown in size, the\npotential to memorise aspects of their training data has increased, resulting\nin the risk of leaking private information. As LMs become increasingly\nwidespread, it is vital that we understand such privacy risks and how they\nmight be mitigated. To help researchers and policymakers understand the state\nof knowledge around privacy attacks and mitigations, including where more work\nis needed, we present the first technical survey on LM privacy. We (i) identify\na taxonomy of salient dimensions where attacks differ on LMs, (ii) survey\nexisting attacks and use our taxonomy of dimensions to highlight key trends,\n(iii) discuss existing mitigation strategies, highlighting their strengths and\nlimitations, identifying key gaps and demonstrating open problems and areas for\nconcern.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Smith_V/0/1/0/all/0/1\">Victoria Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shamsabadi_A/0/1/0/all/0/1\">Ali Shahin Shamsabadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashurst_C/0/1/0/all/0/1\">Carolyn Ashurst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Borges and AI. (arXiv:2310.01425v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01425","description":"<p>Many believe that Large Language Models (LLMs) open the era of Artificial\nIntelligence (AI). Some see opportunities while others see dangers. Yet both\nproponents and opponents grasp AI through the imagery popularised by science\nfiction. Will the machine become sentient and rebel against its creators? Will\nwe experience a paperclip apocalypse? Before answering such questions, we\nshould first ask whether this mental imagery provides a good description of the\nphenomenon at hand. Understanding weather patterns through the moods of the\ngods only goes so far. The present paper instead advocates understanding LLMs\nand their connection to AI through the imagery of Jorge Luis Borges, a master\nof 20th century literature, forerunner of magical realism, and precursor to\npostmodern literature. This exercise leads to a new perspective that\nilluminates the relation between language modelling and artificial\nintelligence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bottou_L/0/1/0/all/0/1\">L&#xe9;on Bottou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhardt Sch&#xf6;lkopf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Attention Sorting Combats Recency Bias In Long Context Language Models. (arXiv:2310.01427v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01427","description":"<p>Current language models often fail to incorporate long contexts efficiently\nduring generation. We show that a major contributor to this issue are attention\npriors that are likely learned during pre-training: relevant information\nlocated earlier in context is attended to less on average. Yet even when models\nfail to use the information from a relevant document in their response, they\nstill pay preferential attention to that document compared to an irrelevant\ndocument at the same position. We leverage this fact to introduce ``attention\nsorting'': perform one step of decoding, sort documents by the attention they\nreceive (highest attention going last), repeat the process, generate the answer\nwith the newly sorted context. We find that attention sorting improves\nperformance of long context models. Our findings highlight some challenges in\nusing off-the-shelf language models for retrieval augmented generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peysakhovich_A/0/1/0/all/0/1\">Alexander Peysakhovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lerer_A/0/1/0/all/0/1\">Adam Lerer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chatmap : Large Language Model Interaction with Cartographic Data. (arXiv:2310.01429v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01429","description":"<p>The swift advancement and widespread availability of foundational Large\nLanguage Models (LLMs), complemented by robust fine-tuning methodologies, have\ncatalyzed their adaptation for innovative and industrious applications.\nEnabling LLMs to recognize and interpret geospatial data, while offering a\nlinguistic access to vast cartographic datasets, is of significant importance.\nOpenStreetMap (OSM) is the most ambitious open-source global initiative\noffering detailed urban and rural geographic data, curated by a community of\nover 10 million contributors, which constitutes a great potential for LLM\napplications. In this study, we demonstrate the proof of concept and details of\nthe process of fine-tuning a relatively small scale (1B parameters) LLM with a\nrelatively small artificial dataset curated by a more capable teacher model, in\norder to provide a linguistic interface to the OSM data of an arbitrary urban\nregion. Through this interface, users can inquire about a location's\nattributes, covering a wide spectrum of concepts, such as its touristic appeal\nor the potential profitability of various businesses in that vicinity. The\nstudy aims to provide an initial guideline for such generative artificial\nintelligence (AI) adaptations and demonstrate early signs of useful emerging\nabilities in this context even in minimal computational settings. The\nembeddings of artificially curated prompts including OSM data are also\ninvestigated in detail, which might be instrumental for potential geospatially\naware urban Retrieval Augmented Generation (RAG) applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Unlu_E/0/1/0/all/0/1\">Eren Unlu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sarcasm in Sight and Sound: Benchmarking and Expansion to Improve Multimodal Sarcasm Detection. (arXiv:2310.01430v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01430","description":"<p>The introduction of the MUStARD dataset, and its emotion recognition\nextension MUStARD++, have identified sarcasm to be a multi-modal phenomenon --\nexpressed not only in natural language text, but also through manners of speech\n(like tonality and intonation) and visual cues (facial expression). With this\nwork, we aim to perform a rigorous benchmarking of the MUStARD++ dataset by\nconsidering state-of-the-art language, speech, and visual encoders, for fully\nutilizing the totality of the multi-modal richness that it has to offer,\nachieving a 2\\% improvement in macro-F1 over the existing benchmark.\nAdditionally, to cure the imbalance in the `sarcasm type' category in\nMUStARD++, we propose an extension, which we call \\emph{MUStARD++ Balanced},\nbenchmarking the same with instances from the extension split across both train\nand test sets, achieving a further 2.4\\% macro-F1 boost. The new clips were\ntaken from a novel source -- the TV show, House MD, which adds to the diversity\nof the dataset, and were manually annotated by multiple annotators with\nsubstantial inter-annotator agreement in terms of Cohen's kappa and\nKrippendorf's alpha. Our code, extended data, and SOTA benchmark models are\nmade public.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhosale_S/0/1/0/all/0/1\">Swapnil Bhosale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_A/0/1/0/all/0/1\">Abhra Chaudhuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1\">Alex Lee Robert Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_D/0/1/0/all/0/1\">Divyank Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutta_A/0/1/0/all/0/1\">Anjan Dutta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiatian Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharyya_P/0/1/0/all/0/1\">Pushpak Bhattacharyya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanojia_D/0/1/0/all/0/1\">Diptesh Kanojia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Split and Merge: Aligning Position Biases in Large Language Model based Evaluators. (arXiv:2310.01432v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01432","description":"<p>Large language models (LLMs) have shown promise as automated evaluators for\nassessing the quality of answers generated by AI systems. However, these\nLLM-based evaluators exhibit position bias, or inconsistency, when used to\nevaluate candidate answers in pairwise comparisons, favoring either the first\nor second answer regardless of content. To address this limitation, we propose\nPORTIA, an alignment-based system designed to mimic human comparison strategies\nto calibrate position bias in a lightweight yet effective manner. Specifically,\nPORTIA splits the answers into multiple segments, aligns similar content across\ncandidate answers, and then merges them back into a single prompt for\nevaluation by LLMs. We conducted extensive experiments with six diverse LLMs to\nevaluate 11,520 answer pairs. Our results show that PORTIA markedly enhances\nthe consistency rates for all the models and comparison forms tested, achieving\nan average relative improvement of 47.46%. Remarkably, PORTIA enables less\nadvanced GPT models to achieve 88% agreement with the state-of-the-art GPT-4\nmodel at just 10% of the cost. Furthermore, it rectifies around 80% of the\nposition bias instances within the GPT-4 model, elevating its consistency rate\nup to 98%. Subsequent human evaluations indicate that the PORTIA-enhanced\nGPT-3.5 model can even surpass the standalone GPT-4 in terms of alignment with\nhuman evaluators. These findings highlight PORTIA's ability to correct position\nbias, improve LLM consistency, and boost performance while keeping\ncost-efficiency. This represents a valuable step toward a more reliable and\nscalable use of LLMs for automated evaluations across diverse applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zongjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chaozheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1\">Pingchuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Daoyuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianxiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Cuiyun Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revolutionizing Mobile Interaction: Enabling a 3 Billion Parameter GPT LLM on Mobile. (arXiv:2310.01434v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01434","description":"<p>The field of Artificial Intelligence has witnessed remarkable progress in\nrecent years, especially with the emergence of powerful large language models\n(LLMs) based on the transformer architecture. Cloud-based LLMs, such as\nOpenAI's ChatGPT, offer impressive capabilities but come with concerns\nregarding latency and privacy due to network dependencies. This article\npresents an innovative approach to LLM inference, envisioning a future where\nLLMs with billions of parameters can be executed directly on mobile devices\nwithout network connectivity. The article showcases a fine-tuned GPT LLM with 3\nbillion parameters that can operate smoothly on devices with as low as 4GB of\nmemory. Through the integration of native code and model quantization\ntechniques, the application not only serves as a general-purpose assistant but\nalso facilitates seamless mobile interactions with text-to-actions features.\nThe article provides insights into the training pipeline, implementation\ndetails, test results, and future directions of on-device LLM inference. This\nbreakthrough technology opens up possibilities for empowering users with\nsophisticated AI capabilities while preserving their privacy and eliminating\nlatency concerns.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Carreira_S/0/1/0/all/0/1\">Samuel Carreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marques_T/0/1/0/all/0/1\">Tom&#xe1;s Marques</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_J/0/1/0/all/0/1\">Jos&#xe9; Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grilo_C/0/1/0/all/0/1\">Carlos Grilo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Many Voices of Duying: Revisiting the Disputed Essays Between Lu Xun and Zhou Zuoren. (arXiv:2310.01440v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01440","description":"<p>Lu Xun and Zhou Zuoren stand as two of the most influential writers in modern\nChinese literature. Beyond their familial ties as brothers, they were also\nintimate collaborators during the nascent stages of their writing careers. This\nresearch employs quantitative methods to revisit three disputed essays\npseudonymously published by the brothers in 1912. Our stylometric analysis uses\nan interpretable authorship attribution model to investigate the essays'\nauthorship and examine the brothers' respective writing styles. Our findings\nsuggest that 'Looking at the Country of China' was authored by Lu Xun.\nMoreover, 'People of Yue, Forget Not Your Ancestors' Instructions' seems to be\neither predominantly authored or extensively revised by Lu Xun given its\nnotable stylistic similarities to 'Looking at the Land of Yue,' a piece Zhou\nZuoren recognized as his own, but edited by Lu Xun. The third essay, 'Where Has\nthe Character of the Republic Gone?,' exhibits a 'diluted', mixed writing\nstyle, suggesting thorough collaboration. We offer visual representations of\nessay features to facilitate a nuanced and intuitive understanding. We have\nuncovered evidence suggesting Lu Xun's covert engagement with social issues\nduring his purported 'silent era' and provided insights into the brothers'\nformative intellectual trajectories.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiangqiong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haining Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UPAR: A Kantian-Inspired Prompting Framework for Enhancing Large Language Model Capabilities. (arXiv:2310.01441v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01441","description":"<p>Large Language Models (LLMs) have demonstrated impressive inferential\ncapabilities, with numerous research endeavors devoted to enhancing this\ncapacity through prompting. Despite these efforts, a unified epistemological\nfoundation is still conspicuously absent. Drawing inspiration from Kant's a\npriori philosophy, we propose the UPAR prompting framework, designed to emulate\nthe structure of human cognition within LLMs. The UPAR framework is delineated\ninto four phases: \"Understand\", \"Plan\", \"Act\", and \"Reflect\", enabling the\nextraction of structured information from complex contexts, prior planning of\nsolutions, execution according to plan, and self-reflection. This structure\nsignificantly augments the explainability and accuracy of LLM inference,\nproducing a human-understandable and inspectable inferential trajectory.\nFurthermore, our work offers an epistemological foundation for existing\nprompting techniques, allowing for a possible systematic integration of these\nmethods. With GPT-4, our approach elevates the accuracy from COT baseline of\n22.92% to 58.33% in a challenging subset of GSM8K, and from 67.91% to 75.40% in\nthe causal judgment task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Geng_H/0/1/0/all/0/1\">Hejia Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Boxun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adapting LLM Agents Through Communication. (arXiv:2310.01444v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01444","description":"<p>Recent advancements in large language models (LLMs) have shown potential for\nhuman-like agents. To help these agents adapt to new tasks without extensive\nhuman supervision, we propose the Learning through Communication (LTC)\nparadigm, a novel training approach enabling LLM agents to improve continuously\nthrough interactions with their environments and other agents. Recent\nadvancements in large language models (LLMs) have shown potential for\nhuman-like agents. To help these agents adapt to new tasks without extensive\nhuman supervision, we propose the Learning through Communication (LTC)\nparadigm, a novel training approach enabling LLM agents to improve continuously\nthrough interactions with their environments and other agents. Through\niterative exploration and PPO training, LTC empowers the agent to assimilate\nshort-term experiences into long-term memory. To optimize agent interactions\nfor task-specific learning, we introduce three structured communication\npatterns: Monologue, Dialogue, and Analogue-tailored for common tasks such as\ndecision-making, knowledge-intensive reasoning, and numerical reasoning. We\nevaluated LTC on three datasets: ALFWorld (decision-making), HotpotQA\n(knowledge-intensive reasoning), and GSM8k (numerical reasoning). On ALFWorld,\nit exceeds the instruction tuning baseline by 12% in success rate. On HotpotQA,\nLTC surpasses the instruction-tuned LLaMA-7B agent by 5.1% in EM score, and it\noutperforms the instruction-tuned 9x larger PaLM-62B agent by 0.6%. On GSM8k,\nLTC outperforms the CoT-Tuning baseline by 3.6% in accuracy. The results\nshowcase the versatility and efficiency of the LTC approach across diverse\ndomains. We will open-source our code to promote further development of the\ncommunity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yadong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santacroce_M/0/1/0/all/0/1\">Michael Santacroce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yelong Shen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adaptive-Solver Framework for Dynamic Strategy Selection in Large Language Model Reasoning. (arXiv:2310.01446v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01446","description":"<p>Large Language Models (LLMs) are showcasing impressive ability in handling\ncomplex reasoning tasks. In real-world situations, problems often span a\nspectrum of complexities. Humans inherently adjust their problem-solving\napproaches based on task complexity. However, most methodologies that leverage\nLLMs tend to adopt a uniform approach: utilizing consistent models, prompting\nmethods, and degrees of problem decomposition, regardless of the problem\ncomplexity. Inflexibility of them can bring unnecessary computational overhead\nor sub-optimal performance. To address this problem, we introduce an\nAdaptive-Solver framework. It strategically modulates solving strategies based\non the difficulties of the problems. Given an initial solution, the framework\nfunctions with two primary modules. The initial evaluation module assesses the\nadequacy of the current solution. If improvements are needed, the subsequent\nadaptation module comes into play. Within this module, three key adaptation\nstrategies are employed: (1) Model Adaptation: Switching to a stronger LLM when\na weaker variant is inadequate. (2) Prompting Method Adaptation: Alternating\nbetween different prompting techniques to suit the problem's nuances. (3)\nDecomposition Granularity Adaptation: Breaking down a complex problem into more\nfine-grained sub-questions to enhance solvability. Through such dynamic\nadaptations, our framework not only enhances computational efficiency but also\nelevates the overall performance. This dual-benefit ensures both the efficiency\nof the system for simpler tasks and the precision required for more complex\nquestions. Experimental results from complex reasoning tasks reveal that the\nprompting method adaptation and decomposition granularity adaptation enhance\nperformance across all tasks. Furthermore, the model adaptation approach\nsignificantly reduces API costs (up to 50%) while maintaining superior\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jianpeng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_W/0/1/0/all/0/1\">Wanjun Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanlin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiahai Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Meta Semantic Template for Evaluation of Large Language Models. (arXiv:2310.01448v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01448","description":"<p>Do large language models (LLMs) genuinely understand the semantics of the\nlanguage, or just memorize the training data? The recent concern on potential\ndata contamination of LLMs has raised awareness of the community to conduct\nresearch on LLMs evaluation. In this paper, we propose MSTemp, an approach that\ncreates meta semantic templates to evaluate the semantic understanding ability\nof LLMs. The core of MSTemp is not to perform evaluation directly on existing\nbenchmark datasets, but to generate new out-of-distribution (OOD) evaluation\nsets using existing datasets as seeds. Specifically, for a given sentence,\nMSTemp leverages another language model to generate new samples while\npreserving its semantics. The new samples are called semantic templates to the\noriginal sentence. Then, MSTemp generates evaluation samples via sentence\nparsing and random word replacement on the semantic templates. MSTemp is highly\nflexible, dynamic, and cost-effective. Our initial experiments show that\nMSTemp-generated samples can significantly reduce the performance of LLMs using\nexisting datasets as seeds. We hope this initial work can shed light on future\nresearch of LLMs evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yachuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_Q/0/1/0/all/0/1\">Qiaozhu Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fooling the Textual Fooler via Randomizing Latent Representations. (arXiv:2310.01452v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01452","description":"<p>Despite outstanding performance in a variety of NLP tasks, recent studies\nhave revealed that NLP models are vulnerable to adversarial attacks that\nslightly perturb the input to cause the models to misbehave. Among these\nattacks, adversarial word-level perturbations are well-studied and effective\nattack strategies. Since these attacks work in black-box settings, they do not\nrequire access to the model architecture or model parameters and thus can be\ndetrimental to existing NLP applications. To perform an attack, the adversary\nqueries the victim model many times to determine the most important words in an\ninput text and to replace these words with their corresponding synonyms. In\nthis work, we propose a lightweight and attack-agnostic defense whose main goal\nis to perplex the process of generating an adversarial example in these\nquery-based black-box attacks; that is to fool the textual fooler. This\ndefense, named AdvFooler, works by randomizing the latent representation of the\ninput at inference time. Different from existing defenses, AdvFooler does not\nnecessitate additional computational overhead during training nor relies on\nassumptions about the potential adversarial perturbation set while having a\nnegligible impact on the model's accuracy. Our theoretical and empirical\nanalyses highlight the significance of robustness resulting from confusing the\nadversary via randomizing the latent space, as well as the impact of\nrandomization on clean accuracy. Finally, we empirically demonstrate near\nstate-of-the-art robustness of AdvFooler against representative adversarial\nword-level attacks on two benchmark datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hoang_D/0/1/0/all/0/1\">Duy C. Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quang H. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manchanda_S/0/1/0/all/0/1\">Saurav Manchanda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_M/0/1/0/all/0/1\">MinLong Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1\">Kok-Seng Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doan_K/0/1/0/all/0/1\">Khoa D. Doan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NarrativePlay: Interactive Narrative Understanding. (arXiv:2310.01459v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01459","description":"<p>In this paper, we introduce NarrativePlay, a novel system that allows users\nto role-play a fictional character and interact with other characters in\nnarratives such as novels in an immersive environment. We leverage Large\nLanguage Models (LLMs) to generate human-like responses, guided by personality\ntraits extracted from narratives. The system incorporates auto-generated visual\ndisplay of narrative settings, character portraits, and character speech,\ngreatly enhancing user experience. Our approach eschews predefined sandboxes,\nfocusing instead on main storyline events extracted from narratives from the\nperspective of a user-selected character. NarrativePlay has been evaluated on\ntwo types of narratives, detective and adventure stories, where users can\neither explore the world or improve their favorability with the narrative\ncharacters through conversations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Runcong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenjia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiazheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Lixing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yulan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1\">Lin Gui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FedBPT: Efficient Federated Black-box Prompt Tuning for Large Language Models. (arXiv:2310.01467v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01467","description":"<p>Pre-trained language models (PLM) have revolutionized the NLP landscape,\nachieving stellar performances across diverse tasks. These models, while\nbenefiting from vast training data, often require fine-tuning on specific data\nto cater to distinct downstream tasks. However, this data adaptation process\nhas inherent security and privacy concerns, primarily when leveraging\nuser-generated, device-residing data. Federated learning (FL) provides a\nsolution, allowing collaborative model fine-tuning without centralized data\ncollection. However, applying FL to finetune PLMs is hampered by challenges,\nincluding restricted model parameter access, high computational requirements,\nand communication overheads. This paper introduces Federated Black-box Prompt\nTuning (FedBPT), a framework designed to address these challenges. FedBPT does\nnot require the clients to access the model parameters. By focusing on training\noptimal prompts and utilizing gradient-free optimization methods, FedBPT\nreduces the number of exchanged variables, boosts communication efficiency, and\nminimizes computational and storage costs. Experiments highlight the\nframework's ability to drastically cut communication and memory costs while\nmaintaining competitive performance. Ultimately, FedBPT presents a promising\nsolution for efficient, privacy-preserving fine-tuning of PLM in the age of\nlarge language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jingwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Ziyue Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hongxu Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Dong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Daguang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiran Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_H/0/1/0/all/0/1\">Holger R. Roth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Entity-Deduction Arena: A playground for probing the conversational reasoning and planning capabilities of LLMs. (arXiv:2310.01468v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01468","description":"<p>Large language models (LLMs) are currently effective at answering questions\nthat are clearly asked. However, when faced with ambiguous queries they can act\nunpredictably and produce incorrect outputs. This underscores the need for the\ndevelopment of intelligent agents capable of asking clarification questions to\nresolve ambiguities effectively. This capability requires complex\nunderstanding, state tracking, reasoning and planning over multiple\nconversational turns. However, directly measuring this can be challenging. In\nthis paper, we offer a surrogate problem which assesses an LLMs's capability to\ndeduce an entity unknown to itself, but revealed to a judge, by asking the\njudge a series of queries. This \\textit{entity-deducing game} can serve as an\nevaluation framework to probe the conversational reasoning and planning\ncapabilities of language models. We systematically evaluate various LLMs and\ndiscover significant differences in their performance on this task. We find\nthat strong LLMs like GPT-4 outperform human players by a large margin. We\nfurther employ Behavior Cloning (BC) to examine whether a weaker model is\ncapable of imitating a stronger model and generalizing to data or domains,\nusing only the demonstrations from a stronger model. We finally propose to use\nReinforcement Learning to enhance reasoning and planning capacity of Vicuna\nmodels through episodes of game playing, which lead to significant performance\nimprovement. We hope that this problem offers insights into how autonomous\nagents could be trained to behave more intelligently in ambiguous\ncircumstances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yizhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiarui Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaitly_N/0/1/0/all/0/1\">Navdeep Jaitly</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples. (arXiv:2310.01469v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01469","description":"<p>Large Language Models (LLMs), including GPT-3.5, LLaMA, and PaLM, seem to be\nknowledgeable and able to adapt to many tasks. However, we still can not\ncompletely trust their answer, since LLMs suffer from\nhallucination--fabricating non-existent facts to cheat users without\nperception. And the reasons for their existence and pervasiveness remain\nunclear. In this paper, we demonstrate that non-sense prompts composed of\nrandom tokens can also elicit the LLMs to respond with hallucinations. This\nphenomenon forces us to revisit that hallucination may be another view of\nadversarial examples, and it shares similar features with conventional\nadversarial examples as the basic feature of LLMs. Therefore, we formalize an\nautomatic hallucination triggering method as the hallucination attack in an\nadversarial way. Finally, we explore basic feature of attacked adversarial\nprompts and propose a simple yet effective defense strategy. Our code is\nreleased on GitHub.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jia-Yu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_K/0/1/0/all/0/1\">Kun-Peng Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhen-Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_M/0/1/0/all/0/1\">Mu-Nan Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Li Yuan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Making Retrieval-Augmented Language Models Robust to Irrelevant Context. (arXiv:2310.01558v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01558","description":"<p>Retrieval-augmented language models (RALMs) hold promise to produce language\nunderstanding systems that are are factual, efficient, and up-to-date. An\nimportant desideratum of RALMs, is that retrieved information helps model\nperformance when it is relevant, and does not harm performance when it is not.\nThis is particularly important in multi-hop reasoning scenarios, where misuse\nof irrelevant evidence can lead to cascading errors. However, recent work has\nshown that retrieval augmentation can sometimes have a negative effect on\nperformance. In this work, we present a thorough analysis on five open-domain\nquestion answering benchmarks, characterizing cases when retrieval reduces\naccuracy. We then propose two methods to mitigate this issue. First, a simple\nbaseline that filters out retrieved passages that do not entail question-answer\npairs according to a natural language inference (NLI) model. This is effective\nin preventing performance reduction, but at a cost of also discarding relevant\npassages. Thus, we propose a method for automatically generating data to\nfine-tune the language model to properly leverage retrieved passages, using a\nmix of relevant and irrelevant contexts at training time. We empirically show\nthat even 1,000 examples suffice to train the model to be robust to irrelevant\ncontexts while maintaining high performance on examples with relevant ones.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yoran_O/0/1/0/all/0/1\">Ori Yoran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolfson_T/0/1/0/all/0/1\">Tomer Wolfson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_O/0/1/0/all/0/1\">Ori Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Defending Against Authorship Identification Attacks. (arXiv:2310.01568v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01568","description":"<p>Authorship identification has proven unsettlingly effective in inferring the\nidentity of the author of an unsigned document, even when sensitive personal\ninformation has been carefully omitted. In the digital era, individuals leave a\nlasting digital footprint through their written content, whether it is posted\non social media, stored on their employer's computers, or located elsewhere.\nWhen individuals need to communicate publicly yet wish to remain anonymous,\nthere is little available to protect them from unwanted authorship\nidentification. This unprecedented threat to privacy is evident in scenarios\nsuch as whistle-blowing. Proposed defenses against authorship identification\nattacks primarily aim to obfuscate one's writing style, thereby making it\nunlinkable to their pre-existing writing, while concurrently preserving the\noriginal meaning and grammatical integrity. The presented work offers a\ncomprehensive review of the advancements in this research area spanning over\nthe past two decades and beyond. It emphasizes the methodological frameworks of\nmodification and generation-based strategies devised to evade authorship\nidentification attacks, highlighting joint efforts from the differential\nprivacy community. Limitations of current research are discussed, with a\nspotlight on open challenges and potential research avenues.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haining Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Review of Digital Learning Environments for Teaching Natural Language Processing in K-12 Education. (arXiv:2310.01603v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01603","description":"<p>Natural Language Processing (NLP) plays a significant role in our daily lives\nand has become an essential part of Artificial Intelligence (AI) education in\nK-12. As children grow up with NLP-powered applications, it is crucial to\nintroduce NLP concepts to them, fostering their understanding of language\nprocessing, language generation, and ethical implications of AI and NLP. This\npaper presents a comprehensive review of digital learning environments for\nteaching NLP in K-12. Specifically, it explores existing digital learning\ntools, discusses how they support specific NLP tasks and procedures, and\ninvestigates their explainability and evaluation results in educational\ncontexts. By examining the strengths and limitations of these tools, this\nliterature review sheds light on the current state of NLP learning tools in\nK-12 education. It aims to guide future research efforts to refine existing\ntools, develop new ones, and explore more effective and inclusive strategies\nfor integrating NLP into K-12 educational contexts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_X/0/1/0/all/0/1\">Xiaoyi Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boyer_K/0/1/0/all/0/1\">Kristy Elizabeth Boyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VAL: Interactive Task Learning with GPT Dialog Parsing. (arXiv:2310.01627v1 [cs.HC])","link":"http://arxiv.org/abs/2310.01627","description":"<p>Reinforcement learning often requires millions of examples to produce static,\nblack-box models. In contrast, interactive task learning (ITL) emphasizes\nincremental knowledge acquisition from limited instruction provided by humans\nin modalities such as natural language. However, in practice, ITL systems often\nsuffers from brittle, error-prone language parsing. Large language models\n(LLMs) are resistant to brittleness but are not interpretable and cannot learn\nincrementally. We present VAL, an ITL system with a new philosophy for\nLLM/symbolic integration. By using LLMs only for specific tasks -- such as\npredicate and argument selection -- within an algorithmic framework, VAL reaps\nthe benefits of LLMs to support interactive learning of hierarchical task\nknowledge from natural language. Acquired knowledge is human interpretable and\ngeneralizes to support execution of novel tasks without additional training. We\nstudied users' interactions with VAL in a video game setting, finding that most\nusers could successfully teach VAL using language they felt was natural.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lawley_L/0/1/0/all/0/1\">Lane Lawley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MacLellan_C/0/1/0/all/0/1\">Christopher J. MacLellan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"One model to rule them all ? Towards End-to-End Joint Speaker Diarization and Speech Recognition. (arXiv:2310.01688v1 [eess.AS])","link":"http://arxiv.org/abs/2310.01688","description":"<p>This paper presents a novel framework for joint speaker diarization (SD) and\nautomatic speech recognition (ASR), named SLIDAR (sliding-window\ndiarization-augmented recognition). SLIDAR can process arbitrary length inputs\nand can handle any number of speakers, effectively solving ``who spoke what,\nwhen'' concurrently. SLIDAR leverages a sliding window approach and consists of\nan end-to-end diarization-augmented speech transcription (E2E DAST) model which\nprovides, locally, for each window: transcripts, diarization and speaker\nembeddings. The E2E DAST model is based on an encoder-decoder architecture and\nleverages recent techniques such as serialized output training and\n``Whisper-style\" prompting. The local outputs are then combined to get the\nfinal SD+ASR result by clustering the speaker embeddings to get global speaker\nidentities. Experiments performed on monaural recordings from the AMI corpus\nconfirm the effectiveness of the method in both close-talk and far-field speech\nscenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Cornell_S/0/1/0/all/0/1\">Samuele Cornell</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jung_J/0/1/0/all/0/1\">Jee-weon Jung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Squartini_S/0/1/0/all/0/1\">Stefano Squartini</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across Language Models. (arXiv:2310.01691v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01691","description":"<p>Prompt tuning in natural language processing (NLP) has become an increasingly\npopular method for adapting large language models to specific tasks. However,\nthe transferability of these prompts, especially continuous prompts, between\ndifferent models remains a challenge. In this work, we propose a zero-shot\ncontinuous prompt transfer method, where source prompts are encoded into\nrelative space and the corresponding target prompts are searched for\ntransferring to target models. Experimental results confirm the effectiveness\nof our method, showing that 'task semantics' in continuous prompts can be\ngeneralized across various language models. Moreover, we find that combining\n'task semantics' from multiple source models can further enhance the\ngeneralizability of transfer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zijun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yongkang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mou_L/0/1/0/all/0/1\">Lili Mou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Closing the Curious Case of Neural Text Degeneration. (arXiv:2310.01693v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01693","description":"<p>Despite their ubiquity in language generation, it remains unknown why\ntruncation sampling heuristics like nucleus sampling are so effective. We\nprovide a theoretical explanation for the effectiveness of the truncation\nsampling by proving that truncation methods that discard tokens below some\nprobability threshold (the most common type of truncation) can guarantee that\nall sampled tokens have nonzero true probability. However, thresholds are a\ncoarse heuristic, and necessarily discard some tokens with nonzero true\nprobability as well. In pursuit of a more precise sampling strategy, we show\nthat we can leverage a known source of model errors, the softmax bottleneck, to\nprove that certain tokens have nonzero true probability, without relying on a\nthreshold. Based on our findings, we develop an experimental truncation\nstrategy and the present pilot studies demonstrating the promise of this type\nof algorithm. Our evaluations show that our method outperforms its\nthreshold-based counterparts under automatic and human evaluation metrics for\nlow-entropy (i.e., close to greedy) open-ended text generation. Our theoretical\nfindings and pilot experiments provide both insight into why truncation\nsampling works, and make progress toward more expressive sampling algorithms\nthat better surface the generative capabilities of large language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Finlayson_M/0/1/0/all/0/1\">Matthew Finlayson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hewitt_J/0/1/0/all/0/1\">John Hewitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koller_A/0/1/0/all/0/1\">Alexander Koller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swayamdipta_S/0/1/0/all/0/1\">Swabha Swayamdipta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deciphering Diagnoses: How Large Language Models Explanations Influence Clinical Decision Making. (arXiv:2310.01708v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01708","description":"<p>Clinical Decision Support Systems (CDSS) utilize evidence-based knowledge and\npatient data to offer real-time recommendations, with Large Language Models\n(LLMs) emerging as a promising tool to generate plain-text explanations for\nmedical decisions. This study explores the effectiveness and reliability of\nLLMs in generating explanations for diagnoses based on patient complaints.\nThree experienced doctors evaluated LLM-generated explanations of the\nconnection between patient complaints and doctor and model-assigned diagnoses\nacross several stages. Experimental results demonstrated that LLM explanations\nsignificantly increased doctors' agreement rates with given diagnoses and\nhighlighted potential errors in LLM outputs, ranging from 5% to 30%. The study\nunderscores the potential and challenges of LLMs in healthcare and emphasizes\nthe need for careful integration and evaluation to ensure patient safety and\noptimal clinical utility.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Umerenkov_D/0/1/0/all/0/1\">D.Umerenkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zubkova_G/0/1/0/all/0/1\">G.Zubkova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nesterov_A/0/1/0/all/0/1\">A.Nesterov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ensemble Distillation for Unsupervised Constituency Parsing. (arXiv:2310.01717v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01717","description":"<p>We investigate the unsupervised constituency parsing task, which organizes\nwords and phrases of a sentence into a hierarchical structure without using\nlinguistically annotated data. We observe that existing unsupervised parsers\ncapture differing aspects of parsing structures, which can be leveraged to\nenhance unsupervised parsing performance. To this end, we propose a notion of\n\"tree averaging,\" based on which we further propose a novel ensemble method for\nunsupervised parsing. To improve inference efficiency, we further distill the\nensemble knowledge into a student model; such an ensemble-then-distill process\nis an effective approach to mitigate the over-smoothing problem existing in\ncommon multi-teacher distilling methods. Experiments show that our method\nsurpasses all previous approaches, consistently demonstrating its effectiveness\nand robustness across various runs, with different ensemble components, and\nunder domain-shift conditions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shayegh_B/0/1/0/all/0/1\">Behzad Shayegh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yanshuai Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaodan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_J/0/1/0/all/0/1\">Jackie C.K. Cheung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mou_L/0/1/0/all/0/1\">Lili Mou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Nugget: Neural Agglomerative Embeddings of Text. (arXiv:2310.01732v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01732","description":"<p>Embedding text sequences is a widespread requirement in modern language\nunderstanding. Existing approaches focus largely on constant-size\nrepresentations. This is problematic, as the amount of information contained in\ntext often varies with the length of the input. We propose a solution called\nNugget, which encodes language into a representation based on a dynamically\nselected subset of input tokens. These nuggets are learned through tasks like\nautoencoding and machine translation, and intuitively segment language into\nmeaningful units. We demonstrate Nugget outperforms related approaches in tasks\ninvolving semantic comparison. Finally, we illustrate these compact units allow\nfor expanding the contextual window of a language model (LM), suggesting new\nfuture LMs that can condition on significantly larger amounts of content.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_G/0/1/0/all/0/1\">Guanghui Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stack Attention: Improving the Ability of Transformers to Model Hierarchical Patterns. (arXiv:2310.01749v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01749","description":"<p>Attention, specifically scaled dot-product attention, has proven effective\nfor natural language, but it does not have a mechanism for handling\nhierarchical patterns of arbitrary nesting depth, which limits its ability to\nrecognize certain syntactic structures. To address this shortcoming, we propose\nstack attention: an attention operator that incorporates stacks, inspired by\ntheir theoretical connections to context-free languages (CFLs). We show that\nstack attention is analogous to standard attention, but with a latent model of\nsyntax that requires no syntactic supervision. We propose two variants: one\nrelated to deterministic pushdown automata (PDAs) and one based on\nnondeterministic PDAs, which allows transformers to recognize arbitrary CFLs.\nWe show that transformers with stack attention are very effective at learning\nCFLs that standard transformers struggle on, achieving strong results on a CFL\nwith theoretically maximal parsing difficulty. We also show that stack\nattention is more effective at natural language modeling under a constrained\nparameter budget, and we include results on machine translation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+DuSell_B/0/1/0/all/0/1\">Brian DuSell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_D/0/1/0/all/0/1\">David Chiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SEA: Sparse Linear Attention with Estimated Attention Mask. (arXiv:2310.01777v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01777","description":"<p>The transformer architecture has made breakthroughs in recent years on tasks\nwhich require modeling pairwise relationships between sequential elements, as\nis the case in natural language understanding. However, transformers struggle\nwith long sequences due to the quadratic complexity of the attention operation,\nand previous research has aimed to lower the complexity by sparsifying or\nlinearly approximating the attention matrix. Yet, these approaches cannot\nstraightforwardly distill knowledge from a teacher's attention matrix, and\noften require complete retraining from scratch. Furthermore, previous sparse\nand linear approaches may also lose interpretability if they do not produce\nfull quadratic attention matrices. To address these challenges, we propose SEA:\nSparse linear attention with an Estimated Attention mask. SEA estimates the\nattention matrix with linear complexity via kernel-based linear attention, then\ncreates a sparse approximation to the full attention matrix with a top-k\nselection to perform a sparse attention operation. For language modeling tasks\n(Wikitext2), previous linear and sparse attention methods show a roughly\ntwo-fold worse perplexity scores over the quadratic OPT-125M baseline, while\nSEA achieves an even better perplexity than OPT-125M, using roughly half as\nmuch memory as OPT-125M. Moreover, SEA maintains an interpretable attention\nmatrix and can utilize knowledge distillation to lower the complexity of\nexisting pretrained transformers. We believe that our work will have a large\npractical impact, as it opens the possibility of running large transformers on\nresource-limited devices with less memory.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Heejun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jina Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willette_J/0/1/0/all/0/1\">Jeffrey Willette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can large language models provide useful feedback on research papers? A large-scale empirical analysis. (arXiv:2310.01783v1 [cs.LG])","link":"http://arxiv.org/abs/2310.01783","description":"<p>Expert feedback lays the foundation of rigorous research. However, the rapid\ngrowth of scholarly production and intricate knowledge specialization challenge\nthe conventional scientific feedback mechanisms. High-quality peer reviews are\nincreasingly difficult to obtain. Researchers who are more junior or from\nunder-resourced settings have especially hard times getting timely feedback.\nWith the breakthrough of large language models (LLM) such as GPT-4, there is\ngrowing interest in using LLMs to generate scientific feedback on research\nmanuscripts. However, the utility of LLM-generated feedback has not been\nsystematically studied. To address this gap, we created an automated pipeline\nusing GPT-4 to provide comments on the full PDFs of scientific papers. We\nevaluated the quality of GPT-4's feedback through two large-scale studies. We\nfirst quantitatively compared GPT-4's generated feedback with human peer\nreviewer feedback in 15 Nature family journals (3,096 papers in total) and the\nICLR machine learning conference (1,709 papers). The overlap in the points\nraised by GPT-4 and by human reviewers (average overlap 30.85% for Nature\njournals, 39.23% for ICLR) is comparable to the overlap between two human\nreviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The\noverlap between GPT-4 and human reviewers is larger for the weaker papers. We\nthen conducted a prospective user study with 308 researchers from 110 US\ninstitutions in the field of AI and computational biology to understand how\nresearchers perceive feedback generated by our GPT-4 system on their own\npapers. Overall, more than half (57.4%) of the users found GPT-4 generated\nfeedback helpful/very helpful and 82.4% found it more beneficial than feedback\nfrom at least some human reviewers. While our findings show that LLM-generated\nfeedback can help researchers, we also identify several limitations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1\">Weixin Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuhui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_H/0/1/0/all/0/1\">Hancheng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Binglu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_D/0/1/0/all/0/1\">Daisy Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xinyu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vodrahalli_K/0/1/0/all/0/1\">Kailas Vodrahalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1\">Siyu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_D/0/1/0/all/0/1\">Daniel Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yian Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McFarland_D/0/1/0/all/0/1\">Daniel McFarland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Cannot Self-Correct Reasoning Yet. (arXiv:2310.01798v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01798","description":"<p>Large Language Models (LLMs) have emerged as a groundbreaking technology with\ntheir unparalleled text generation capabilities across various applications.\nNevertheless, concerns persist regarding the accuracy and appropriateness of\ntheir generated content. A contemporary methodology, self-correction, has been\nproposed as a remedy to these issues. Building upon this premise, this paper\ncritically examines the role and efficacy of self-correction within LLMs,\nshedding light on its true potential and limitations. Central to our\ninvestigation is the notion of intrinsic self-correction, whereby an LLM\nattempts to correct its initial responses based solely on its inherent\ncapabilities, without the crutch of external feedback. In the context of\nreasoning, our research indicates that LLMs struggle to self-correct their\nresponses without external feedback, and at times, their performance might even\ndegrade post self-correction. Drawing from these insights, we offer suggestions\nfor future research and practical applications in this field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinyun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Swaroop Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Huaixiu Steven Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_A/0/1/0/all/0/1\">Adams Wei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xinying Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Denny Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs. (arXiv:2310.01801v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01801","description":"<p>In this study, we introduce adaptive KV cache compression, a plug-and-play\nmethod that reduces the memory footprint of generative inference for Large\nLanguage Models (LLMs). Different from the conventional KV cache that retains\nkey and value vectors for all context tokens, we conduct targeted profiling to\ndiscern the intrinsic structure of attention modules. Based on the recognized\nstructure, we then construct the KV cache in an adaptive manner: evicting\nlong-range contexts on attention heads emphasizing local contexts, discarding\nnon-special tokens on attention heads centered on special tokens, and only\nemploying the standard KV cache for attention heads that broadly attend to all\ntokens. Moreover, with the lightweight attention profiling used to guide the\nconstruction of the adaptive KV cache, FastGen can be deployed without\nresource-intensive fine-tuning or re-training. In our experiments across\nvarious asks, FastGen demonstrates substantial reduction on GPU memory\nconsumption with negligible generation quality loss. We will release our code\nand the compatible CUDA kernel for reproducibility.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Suyu Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Liyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Minjia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Empirical Study of PEFT techniques for Winter Wheat Segmentation. (arXiv:2310.01825v1 [cs.CV])","link":"http://arxiv.org/abs/2310.01825","description":"<p>Parameter Efficient Fine Tuning (PEFT) techniques have recently experienced\nsignificant growth and have been extensively employed to adapt large vision and\nlanguage models to various domains, enabling satisfactory model performance\nwith minimal computational needs. Despite these advances, more research has yet\nto delve into potential PEFT applications in real-life scenarios, particularly\nin the critical domains of remote sensing and crop monitoring. The diversity of\nclimates across different regions and the need for comprehensive large-scale\ndatasets have posed significant obstacles to accurately identify crop types\nacross varying geographic locations and changing growing seasons. This study\nseeks to bridge this gap by comprehensively exploring the feasibility of\ncross-area and cross-year out-of-distribution generalization using the\nState-of-the-Art (SOTA) wheat crop monitoring model. The aim of this work is to\nexplore PEFT approaches for crop monitoring. Specifically, we focus on adapting\nthe SOTA TSViT model to address winter wheat field segmentation, a critical\ntask for crop monitoring and food security. This adaptation process involves\nintegrating different PEFT techniques, including BigFit, LoRA, Adaptformer, and\nprompt tuning. Using PEFT techniques, we achieved notable results comparable to\nthose achieved using full fine-tuning methods while training only a mere 0.7%\nparameters of the whole TSViT architecture. The in-house labeled data-set,\nreferred to as the Beqaa-Lebanon dataset, comprises high-quality annotated\npolygons for wheat and non-wheat classes with a total surface of 170 kmsq, over\nfive consecutive years. Using Sentinel-2 images, our model achieved a 84%\nF1-score. We intend to publicly release the Lebanese winter wheat data set,\ncode repository, and model weights.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zahweh_M/0/1/0/all/0/1\">Mohamad Hasan Zahweh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasrallah_H/0/1/0/all/0/1\">Hasan Nasrallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shukor_M/0/1/0/all/0/1\">Mustafa Shukor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faour_G/0/1/0/all/0/1\">Ghaleb Faour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghandour_A/0/1/0/all/0/1\">Ali J. Ghandour</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation. (arXiv:2310.01828v1 [cs.CV])","link":"http://arxiv.org/abs/2310.01828","description":"<p>eXplainable Artificial Intelligence (XAI) has emerged as an essential\nrequirement when dealing with mission-critical applications, ensuring\ntransparency and interpretability of the employed black box AI models. The\nsignificance of XAI spans various domains, from healthcare to finance, where\nunderstanding the decision-making process of deep learning algorithms is\nessential. Most AI-based computer vision models are often black boxes; hence,\nproviding explainability of deep neural networks in image processing is crucial\nfor their wide adoption and deployment in medical image analysis, autonomous\ndriving, and remote sensing applications. Recently, several XAI methods for\nimage classification tasks have been introduced. On the contrary, image\nsegmentation has received comparatively less attention in the context of\nexplainability, although it is a fundamental task in computer vision\napplications, especially in remote sensing. Only some research proposes\ngradient-based XAI algorithms for image segmentation. This paper adapts the\nrecent gradient-free Sobol XAI method for semantic segmentation. To measure the\nperformance of the Sobol method for segmentation, we propose a quantitative XAI\nevaluation method based on a learnable noise model. The main objective of this\nmodel is to induce noise on the explanation maps, where higher induced noise\nsignifies low accuracy and vice versa. A benchmark analysis is conducted to\nevaluate and compare performance of three XAI methods, including Seg-Grad-CAM,\nSeg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation\ntechnique. This constitutes the first attempt to run and evaluate XAI methods\nusing high-resolution satellite images.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shreim_H/0/1/0/all/0/1\">Hossein Shreim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gizzini_A/0/1/0/all/0/1\">Abdul Karim Gizzini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghandour_A/0/1/0/all/0/1\">Ali J. Ghandour</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extending CAM-based XAI methods for Remote Sensing Imagery Segmentation. (arXiv:2310.01837v1 [cs.CV])","link":"http://arxiv.org/abs/2310.01837","description":"<p>Current AI-based methods do not provide comprehensible physical\ninterpretations of the utilized data, extracted features, and\npredictions/inference operations. As a result, deep learning models trained\nusing high-resolution satellite imagery lack transparency and explainability\nand can be merely seen as a black box, which limits their wide-level adoption.\nExperts need help understanding the complex behavior of AI models and the\nunderlying decision-making process. The explainable artificial intelligence\n(XAI) field is an emerging field providing means for robust, practical, and\ntrustworthy deployment of AI models. Several XAI techniques have been proposed\nfor image classification tasks, whereas the interpretation of image\nsegmentation remains largely unexplored. This paper offers to bridge this gap\nby adapting the recent XAI classification algorithms and making them usable for\nmuti-class image segmentation, where we mainly focus on buildings' segmentation\nfrom high-resolution satellite images. To benchmark and compare the performance\nof the proposed approaches, we introduce a new XAI evaluation methodology and\nmetric based on \"Entropy\" to measure the model uncertainty. Conventional XAI\nevaluation methods rely mainly on feeding area-of-interest regions from the\nimage back to the pre-trained (utility) model and then calculating the average\nchange in the probability of the target class. Those evaluation metrics lack\nthe needed robustness, and we show that using Entropy to monitor the model\nuncertainty in segmenting the pixels within the target class is more suitable.\nWe hope this work will pave the way for additional XAI research for image\nsegmentation and applications in the remote sensing discipline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gizzini_A/0/1/0/all/0/1\">Abdul Karim Gizzini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shukor_M/0/1/0/all/0/1\">Mustafa Shukor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghandour_A/0/1/0/all/0/1\">Ali J. Ghandour</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Preserving Phonemic Distinctions for Ordinal Regression: A Novel Loss Function for Automatic Pronunciation Assessment. (arXiv:2310.01839v1 [eess.AS])","link":"http://arxiv.org/abs/2310.01839","description":"<p>Automatic pronunciation assessment (APA) manages to quantify the\npronunciation proficiency of a second language (L2) learner in a language.\nPrevailing approaches to APA normally leverage neural models trained with a\nregression loss function, such as the mean-squared error (MSE) loss, for\nproficiency level prediction. Despite most regression models can effectively\ncapture the ordinality of proficiency levels in the feature space, they are\nconfronted with a primary obstacle that different phoneme categories with the\nsame proficiency level are inevitably forced to be close to each other,\nretaining less phoneme-discriminative information. On account of this, we\ndevise a phonemic contrast ordinal (PCO) loss for training regression-based APA\nmodels, which aims to preserve better phonemic distinctions between phoneme\ncategories meanwhile considering ordinal relationships of the regression target\noutput. Specifically, we introduce a phoneme-distinct regularizer into the MSE\nloss, which encourages feature representations of different phoneme categories\nto be far apart while simultaneously pulling closer the representations\nbelonging to the same phoneme category by means of weighted distances. An\nextensive set of experiments carried out on the speechocean762 benchmark\ndataset suggest the feasibility and effectiveness of our model in relation to\nsome existing state-of-the-art models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Yan_B/0/1/0/all/0/1\">Bi-Cheng Yan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Wei Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yi-Cheng Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jiun-Ting Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lin_C/0/1/0/all/0/1\">Chi-Han Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_B/0/1/0/all/0/1\">Berlin Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-Shot Refinement of Buildings' Segmentation Models using SAM. (arXiv:2310.01845v1 [cs.CV])","link":"http://arxiv.org/abs/2310.01845","description":"<p>Foundation models have excelled in various tasks but are often evaluated on\ngeneral benchmarks. The adaptation of these models for specific domains, such\nas remote sensing imagery, remains an underexplored area. In remote sensing,\nprecise building instance segmentation is vital for applications like urban\nplanning. While Convolutional Neural Networks (CNNs) perform well, their\ngeneralization can be limited. For this aim, we present a novel approach to\nadapt foundation models to address existing models' generalization dropback.\nAmong several models, our focus centers on the Segment Anything Model (SAM), a\npotent foundation model renowned for its prowess in class-agnostic image\nsegmentation capabilities. We start by identifying the limitations of SAM,\nrevealing its suboptimal performance when applied to remote sensing imagery.\nMoreover, SAM does not offer recognition abilities and thus fails to classify\nand tag localized objects. To address these limitations, we introduce different\nprompting strategies, including integrating a pre-trained CNN as a prompt\ngenerator. This novel approach augments SAM with recognition abilities, a first\nof its kind. We evaluated our method on three remote sensing datasets,\nincluding the WHU Buildings dataset, the Massachusetts Buildings dataset, and\nthe AICrowd Mapping Challenge. For out-of-distribution performance on the WHU\ndataset, we achieve a 5.47% increase in IoU and a 4.81% improvement in\nF1-score. For in-distribution performance on the WHU dataset, we observe a\n2.72% and 1.58% increase in True-Positive-IoU and True-Positive-F1 score,\nrespectively. We intend to release our code repository, hoping to inspire\nfurther exploration of foundation models for domain-specific tasks within the\nremote sensing community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mayladan_A/0/1/0/all/0/1\">Ali Mayladan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasrallah_H/0/1/0/all/0/1\">Hasan Nasrallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moughnieh_H/0/1/0/all/0/1\">Hasan Moughnieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shukor_M/0/1/0/all/0/1\">Mustafa Shukor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghandour_A/0/1/0/all/0/1\">Ali J. Ghandour</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Benchmarking and Improving Generator-Validator Consistency of Language Models. (arXiv:2310.01846v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01846","description":"<p>As of September 2023, ChatGPT correctly answers \"what is 7+8\" with 15, but\nwhen asked \"7+8=15, True or False\" it responds with \"False\". This inconsistency\nbetween generating and validating an answer is prevalent in language models\n(LMs) and erodes trust. In this paper, we propose a framework for measuring the\nconsistency between generation and validation (which we call\ngenerator-validator consistency, or GV-consistency), finding that even GPT-4, a\nstate-of-the-art LM, is GV-consistent only 76% of the time. To improve the\nconsistency of LMs, we propose to finetune on the filtered generator and\nvalidator responses that are GV-consistent, and call this approach consistency\nfine-tuning. We find that this approach improves GV-consistency of Alpaca-30B\nfrom 60% to 93%, and the improvement extrapolates to unseen tasks and domains\n(e.g., GV-consistency for positive style transfers extrapolates to unseen\nstyles like humor). In addition to improving consistency, consistency\nfine-tuning improves both generator quality and validator accuracy without\nusing any labeled data. Evaluated across 6 tasks, including math questions,\nknowledge-intensive QA, and instruction following, our method improves the\ngenerator quality by 16% and the validator accuracy by 6.3% across all tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Lisa Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_V/0/1/0/all/0/1\">Vaishnavi Shrivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Siyan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1\">Tatsunori Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-tuned vs. Prompt-tuned Supervised Representations: Which Better Account for Brain Language Representations?. (arXiv:2310.01854v1 [cs.AI])","link":"http://arxiv.org/abs/2310.01854","description":"<p>To decipher the algorithm underlying the human brain's language\nrepresentation, previous work probed brain responses to language input with\npre-trained artificial neural network (ANN) models fine-tuned on NLU tasks.\nHowever, full fine-tuning generally updates the entire parametric space and\ndistorts pre-trained features, cognitively inconsistent with the brain's robust\nmulti-task learning ability. Prompt-tuning, in contrast, protects pre-trained\nweights and learns task-specific embeddings to fit a task. Could prompt-tuning\ngenerate representations that better account for the brain's language\nrepresentations than fine-tuning? If so, what kind of NLU task leads a\npre-trained model to better decode the information represented in the human\nbrain? We investigate these questions by comparing prompt-tuned and fine-tuned\nrepresentations in neural decoding, that is predicting the linguistic stimulus\nfrom the brain activities evoked by the stimulus. We find that on none of the\n10 NLU tasks, full fine-tuning significantly outperforms prompt-tuning in\nneural decoding, implicating that a more brain-consistent tuning method yields\nrepresentations that better correlate with brain data. Moreover, we identify\nthat tasks dealing with fine-grained concept meaning yield representations that\nbetter decode brain activation patterns than other tasks, especially the\nsyntactic chunking task. This indicates that our brain encodes more\nfine-grained concept information than shallow syntactic information when\nrepresenting languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jingyuan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moens_M/0/1/0/all/0/1\">Marie-Francine Moens</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Effective and Parameter-Efficient Reusing Fine-Tuned Models. (arXiv:2310.01886v1 [cs.LG])","link":"http://arxiv.org/abs/2310.01886","description":"<p>Many pre-trained large-scale models provided online have become highly\neffective in transferring to downstream tasks. At the same time, various\ntask-specific models fine-tuned on these pre-trained models are available\nonline for public use. In practice, as collecting task-specific data is\nlabor-intensive and fine-tuning the large pre-trained models is computationally\nexpensive, one can reuse task-specific finetuned models to deal with downstream\ntasks. However, using a model per task causes a heavy burden on storage and\nserving. Recently, many training-free and parameter-efficient methods have been\nproposed for reusing multiple fine-tuned task-specific models into a single\nmulti-task model. However, these methods exhibit a large accuracy gap compared\nwith using a fine-tuned model per task. In this paper, we propose\nParameter-Efficient methods for ReUsing (PERU) fine-tuned models. For reusing\nFully Fine-Tuned (FFT) models, we propose PERU-FFT by injecting a sparse task\nvector into a merged model by magnitude pruning. For reusing LoRA fine-tuned\nmodels, we propose PERU-LoRA use a lower-rank matrix to approximate the LoRA\nmatrix by singular value decomposition. Both PERUFFT and PERU-LoRA are\ntraining-free. Extensive experiments conducted on computer vision and natural\nlanguage process tasks demonstrate the effectiveness and parameter-efficiency\nof the proposed methods. The proposed PERU-FFT and PERU-LoRA outperform\nexisting reusing model methods by a large margin and achieve comparable\nperformance to using a fine-tuned model per task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Weisen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Baijiong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Han Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_a/0/1/0/all/0/1\">and Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1\">James T. Kwok</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ring Attention with Blockwise Transformers for Near-Infinite Context. (arXiv:2310.01889v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01889","description":"<p>Transformers have emerged as the architecture of choice for many\nstate-of-the-art AI models, showcasing exceptional performance across a wide\nrange of AI applications. However, the memory demands imposed by Transformers\nlimit their ability to handle long sequences, thereby creating challenges for\ntasks involving extended sequences or long-term dependencies. We present a\ndistinct approach, Ring Attention, which leverages blockwise computation of\nself-attention to distribute long sequences across multiple devices while\nconcurrently overlapping the communication of key-value blocks with the\ncomputation of blockwise attention. By processing longer input sequences while\nmaintaining memory efficiency, Ring Attention enables training and inference of\nsequences that are device count times longer than those of prior\nmemory-efficient Transformers, effectively eliminating the memory constraints\nimposed by individual devices. Extensive experiments on language modeling tasks\ndemonstrate the effectiveness of Ring Attention in allowing large sequence\ninput size and improving performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaharia_M/0/1/0/all/0/1\">Matei Zaharia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hierarchical Evaluation Framework: Best Practices for Human Evaluation. (arXiv:2310.01917v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01917","description":"<p>Human evaluation plays a crucial role in Natural Language Processing (NLP) as\nit assesses the quality and relevance of developed systems, thereby\nfacilitating their enhancement. However, the absence of widely accepted human\nevaluation metrics in NLP hampers fair comparisons among different systems and\nthe establishment of universal assessment standards. Through an extensive\nanalysis of existing literature on human evaluation metrics, we identified\nseveral gaps in NLP evaluation methodologies. These gaps served as motivation\nfor developing our own hierarchical evaluation framework. The proposed\nframework offers notable advantages, particularly in providing a more\ncomprehensive representation of the NLP system's performance. We applied this\nframework to evaluate the developed Machine Reading Comprehension system, which\nwas utilized within a human-AI symbiosis model. The results highlighted the\nassociations between the quality of inputs and outputs, underscoring the\nnecessity to evaluate both components rather than solely focusing on outputs.\nIn future work, we will investigate the potential time-saving benefits of our\nproposed framework for evaluators assessing NLP systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bojic_I/0/1/0/all/0/1\">Iva Bojic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jessica Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Si Yuan Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_Q/0/1/0/all/0/1\">Qi Chwen Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Car_J/0/1/0/all/0/1\">Josip Car</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Navigating Cultural Chasms: Exploring and Unlocking the Cultural POV of Text-To-Image Models. (arXiv:2310.01929v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01929","description":"<p>Text-To-Image (TTI) models, exemplified by DALL-E and StableDiffusion, have\nrecently gained prominence for their remarkable zero-shot capabilities in\ngenerating images guided by textual prompts. Language, as a conduit of culture,\nplays a pivotal role in these models' multilingual capabilities, which in turn\nshape their cultural agency. In this study, we explore the cultural perception\nembedded in TTI models by characterizing culture across three hierarchical\ntiers: cultural dimensions, cultural domains, and cultural concepts. We propose\na comprehensive suite of evaluation techniques, including intrinsic evaluations\nusing the CLIP space, extrinsic evaluations with a Visual-Question-Answer (VQA)\nmodel, and human assessments, to discern TTI cultural perceptions. To\nfacilitate our research, we introduce the CulText2I dataset, derived from four\ndiverse TTI models and spanning ten languages. Our experiments reveal insights\ninto these models' cultural awareness, cultural distinctions, and the unlocking\nof cultural features, releasing the potential for cross-cultural applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ventura_M/0/1/0/all/0/1\">Mor Ventura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_David_E/0/1/0/all/0/1\">Eyal Ben-David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1\">Anna Korhonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1\">Roi Reichart</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving. (arXiv:2310.01957v1 [cs.RO])","link":"http://arxiv.org/abs/2310.01957","description":"<p>Large Language Models (LLMs) have shown promise in the autonomous driving\nsector, particularly in generalization and interpretability. We introduce a\nunique object-level multimodal LLM architecture that merges vectorized numeric\nmodalities with a pre-trained LLM to improve context understanding in driving\nsituations. We also present a new dataset of 160k QA pairs derived from 10k\ndriving scenarios, paired with high quality control commands collected with RL\nagent and question answer pairs generated by teacher LLM (GPT-3.5). A distinct\npretraining strategy is devised to align numeric vector modalities with static\nLLM representations using vector captioning language data. We also introduce an\nevaluation metric for Driving QA and demonstrate our LLM-driver's proficiency\nin interpreting driving scenarios, answering questions, and decision-making.\nOur findings highlight the potential of LLM-based driving action generation in\ncomparison to traditional behavioral cloning. We make our benchmark, datasets,\nand model available for further exploration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Long Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinavski_O/0/1/0/all/0/1\">Oleg Sinavski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hunermann_J/0/1/0/all/0/1\">Jan H&#xfc;nermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karnsund_A/0/1/0/all/0/1\">Alice Karnsund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willmott_A/0/1/0/all/0/1\">Andrew James Willmott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birch_D/0/1/0/all/0/1\">Danny Birch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maund_D/0/1/0/all/0/1\">Daniel Maund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shotton_J/0/1/0/all/0/1\">Jamie Shotton</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Models as Knowledge Bases for Visual Word Sense Disambiguation. (arXiv:2310.01960v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01960","description":"<p>Visual Word Sense Disambiguation (VWSD) is a novel challenging task that lies\nbetween linguistic sense disambiguation and fine-grained multimodal retrieval.\nThe recent advancements in the development of visiolinguistic (VL) transformers\nsuggest some off-the-self implementations with encouraging results, which\nhowever we argue that can be further improved. To this end, we propose some\nknowledge-enhancement techniques towards improving the retrieval performance of\nVL transformers via the usage of Large Language Models (LLMs) as Knowledge\nBases. More specifically, knowledge stored in LLMs is retrieved with the help\nof appropriate prompts in a zero-shot manner, achieving performance\nadvancements. Moreover, we convert VWSD to a purely textual question-answering\n(QA) problem by considering generated image captions as multiple-choice\ncandidate answers. Zero-shot and few-shot prompting strategies are leveraged to\nexplore the potential of such a transformation, while Chain-of-Thought (CoT)\nprompting in the zero-shot setting is able to reveal the internal reasoning\nsteps an LLM follows to select the appropriate candidate. In total, our\npresented approach is the first one to analyze the merits of exploiting\nknowledge stored in LLMs in different ways to solve WVSD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kritharoula_A/0/1/0/all/0/1\">Anastasia Kritharoula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lymperaiou_M/0/1/0/all/0/1\">Maria Lymperaiou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stamou_G/0/1/0/all/0/1\">Giorgos Stamou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems. (arXiv:2310.01991v1 [cs.CL])","link":"http://arxiv.org/abs/2310.01991","description":"<p>While forward reasoning (i.e. find the answer given the question) has been\nexplored extensively in the recent literature, backward reasoning is relatively\nunexplored. We examine the backward reasoning capabilities of LLMs on Math Word\nProblems (MWPs): given a mathematical question and its answer, with some\ndetails omitted from the question, can LLMs effectively retrieve the missing\ninformation?\n</p>\n<p>In this paper, we formally define the backward reasoning task on math word\nproblems and modify three datasets to evaluate this task: GSM8k, SVAMP and\nMultiArith. Our findings show a significant drop in the accuracy of models on\nbackward reasoning compared to forward reasoning across four SOTA LLMs (GPT4,\nGPT3.5, PaLM-2, and LLaMa-2). Utilizing the specific format of this task, we\npropose three novel techniques that improve performance: Rephrase reformulates\nthe given problem into a forward reasoning problem, PAL-Tools combines the idea\nof Program-Aided LLMs to produce a set of equations that can be solved by an\nexternal solver, and Check your Work exploits the availability of natural\nverifier of high accuracy in the forward direction, interleaving solving and\nverification steps. Finally, realizing that each of our base methods correctly\nsolves a different set of problems, we propose a novel Bayesian formulation for\ncreating an ensemble over these base methods aided by a verifier to further\nboost the accuracy by a significant margin. Extensive experimentation\ndemonstrates that our techniques successively improve the performance of LLMs\non the backward reasoning task, with the final ensemble-based method resulting\nin a substantial performance gain compared to the raw LLMs with standard\nprompting techniques such as chain-of-thought.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deb_A/0/1/0/all/0/1\">Aniruddha Deb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oza_N/0/1/0/all/0/1\">Neeva Oza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1\">Sarthak Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khandelwal_D/0/1/0/all/0/1\">Dinesh Khandelwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_D/0/1/0/all/0/1\">Dinesh Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_P/0/1/0/all/0/1\">Parag Singla</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OceanGPT: A Large Language Model for Ocean Science Tasks. (arXiv:2310.02031v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02031","description":"<p>Ocean science, which delves into the oceans that are reservoirs of life and\nbiodiversity, is of great significance given that oceans cover over 70% of our\nplanet's surface. Recently, advances in Large Language Models (LLMs) have\ntransformed the paradigm in science. Despite the success in other domains,\ncurrent LLMs often fall short in catering to the needs of domain experts like\noceanographers, and the potential of LLMs for ocean science is under-explored.\nThe intrinsic reason may be the immense and intricate nature of ocean data as\nwell as the necessity for higher granularity and richness in knowledge. To\nalleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean\ndomain, which is expert in various ocean science tasks. We propose DoInstruct,\na novel framework to automatically obtain a large volume of ocean domain\ninstruction data, which generates instructions based on multi-agent\ncollaboration. Additionally, we construct the first oceanography benchmark,\nOceanBench, to evaluate the capabilities of LLMs in the ocean domain. Though\ncomprehensive experiments, OceanGPT not only shows a higher level of knowledge\nexpertise for oceans science tasks but also gains preliminary embodied\nintelligence capabilities in ocean technology. Codes, data and checkpoints will\nsoon be available at https://github.com/zjunlp/KnowLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1\">Zhen Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1\">Yida Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_Y/0/1/0/all/0/1\">Yixin Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guozhou Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Jury: A Comprehensive Evaluation Toolkit. (arXiv:2310.02040v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02040","description":"<p>Evaluation plays a critical role in deep learning as a fundamental block of\nany prediction-based system. However, the vast number of Natural Language\nProcessing (NLP) tasks and the development of various metrics have led to\nchallenges in evaluating different systems with different metrics. To address\nthese challenges, we introduce jury, a toolkit that provides a unified\nevaluation framework with standardized structures for performing evaluation\nacross different tasks and metrics. The objective of jury is to standardize and\nimprove metric evaluation for all systems and aid the community in overcoming\nthe challenges in evaluation. Since its open-source release, jury has reached a\nwide audience and is available at https://github.com/obss/jury.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cavusoglu_D/0/1/0/all/0/1\">Devrim Cavusoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sert_U/0/1/0/all/0/1\">Ulas Sert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1\">Secil Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altinuc_S/0/1/0/all/0/1\">Sinan Altinuc</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tuning Large language model for End-to-end Speech Translation. (arXiv:2310.02050v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02050","description":"<p>With the emergence of large language models (LLMs), multimodal models based\non LLMs have demonstrated significant potential. Models such as LLaSM, X-LLM,\nand SpeechGPT exhibit an impressive ability to comprehend and generate human\ninstructions. However, their performance often falters when faced with complex\ntasks like end-to-end speech translation (E2E-ST), a cross-language and\ncross-modal translation task. In comparison to single-modal models, multimodal\nmodels lag behind in these scenarios. This paper introduces LST, a Large\nmultimodal model designed to excel at the E2E-ST task. LST consists of a speech\nfrontend, an adapter, and a LLM backend. The training of LST consists of two\nstages: (1) Modality adjustment, where the adapter is tuned to align speech\nrepresentation with text embedding space, and (2) Downstream task fine-tuning,\nwhere both the adapter and LLM model are trained to optimize performance on the\nE2EST task. Experimental results on the MuST-C speech translation benchmark\ndemonstrate that LST-13B achieves BLEU scores of 30.39/41.55/35.33 on\nEn-De/En-Fr/En-Es language pairs, surpassing previous models and establishing a\nnew state-of-the-art. Additionally, we conduct an in-depth analysis of\nsingle-modal model selection and the impact of training strategies, which lays\nthe foundation for future research. We will open up our code and models after\nreview.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_N/0/1/0/all/0/1\">Nianwen Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yaqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenlin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xukui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_D/0/1/0/all/0/1\">Dan Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_X/0/1/0/all/0/1\">Xiaolin Jiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Controlling Topic-Focus Articulation in Meaning-to-Text Generation using Graph Neural Networks. (arXiv:2310.02053v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02053","description":"<p>A bare meaning representation can be expressed in various ways using natural\nlanguage, depending on how the information is structured on the surface level.\nWe are interested in finding ways to control topic-focus articulation when\ngenerating text from meaning. We focus on distinguishing active and passive\nvoice for sentences with transitive verbs. The idea is to add pragmatic\ninformation such as topic to the meaning representation, thereby forcing either\nactive or passive voice when given to a natural language generation system. We\nuse graph neural models because there is no explicit information about word\norder in a meaning represented by a graph. We try three different methods for\ntopic-focus articulation (TFA) employing graph neural models for a\nmeaning-to-text generation task. We propose a novel encoding strategy about\nnode aggregation in graph neural models, which instead of traditional encoding\nby aggregating adjacent node information, learns node representations by using\ndepth-first search. The results show our approach can get competitive\nperformance with state-of-art graph models on general text generation, and lead\nto significant improvements on the task of active-passive conversion compared\nto traditional adjacency-based aggregation strategies. Different types of TFA\ncan have a huge impact on the performance of the graph models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chunliu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noord_R/0/1/0/all/0/1\">Rik van Noord</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bos_J/0/1/0/all/0/1\">Johan Bos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FRMT: A Benchmark for Few-Shot Region-Aware Machine Translation. (arXiv:2210.00193v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.00193","description":"<p>We present FRMT, a new dataset and evaluation benchmark for Few-shot\nRegion-aware Machine Translation, a type of style-targeted translation. The\ndataset consists of professional translations from English into two regional\nvariants each of Portuguese and Mandarin Chinese. Source documents are selected\nto enable detailed analysis of phenomena of interest, including lexically\ndistinct terms and distractor terms. We explore automatic evaluation metrics\nfor FRMT and validate their correlation with expert human evaluation across\nboth region-matched and mismatched rating scenarios. Finally, we present a\nnumber of baseline models for this task, and offer guidelines for how\nresearchers can train, evaluate, and compare their own models. Our dataset and\nevaluation code are publicly available: https://bit.ly/frmt-task\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Riley_P/0/1/0/all/0/1\">Parker Riley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dozat_T/0/1/0/all/0/1\">Timothy Dozat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Botha_J/0/1/0/all/0/1\">Jan A. Botha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_X/0/1/0/all/0/1\">Xavier Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garrette_D/0/1/0/all/0/1\">Dan Garrette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riesa_J/0/1/0/all/0/1\">Jason Riesa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firat_O/0/1/0/all/0/1\">Orhan Firat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Constant_N/0/1/0/all/0/1\">Noah Constant</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DialoGen: Generalized Long-Range Context Representation for Dialogue Systems. (arXiv:2210.06282v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.06282","description":"<p>Long-range context modeling is crucial to both dialogue understanding and\ngeneration. The most popular method for dialogue context representation is to\nconcatenate the last-$k$ utterances in chronological order. However, this\nmethod may not be ideal for conversations containing long-range dependencies,\ni.e., when there is a need to look beyond last-$k$ utterances to generate a\nmeaningful response. In this work, we propose DialoGen, a novel encoder-decoder\nbased framework for dialogue generation with a generalized context\nrepresentation that can look beyond the last-$k$ utterances. The main idea of\nour approach is to identify and utilize the most relevant historical utterances\ninstead of last-$k$, which also enables the compact representation of dialogue\nhistory with fewer tokens. We study the effectiveness of our proposed method on\nboth dialogue generation (open-domain) and understanding (DST). Even with a\ncompact context representation, DialoGen performs comparably to the\nstate-of-the-art models on the open-domain DailyDialog dataset. We observe a\nsimilar behavior on the DST task of the MultiWOZ dataset when the proposed\ncontext representation is applied to existing DST models. We also discuss the\ngeneralizability and interpretability of DialoGen and show that the relevance\nscore of previous utterances agrees well with human cognition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dey_S/0/1/0/all/0/1\">Suvodip Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desarkar_M/0/1/0/all/0/1\">Maunendra Sankar Desarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ekbal_A/0/1/0/all/0/1\">Asif Ekbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srijith_P/0/1/0/all/0/1\">P.K. Srijith</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Query Rewriting for Effective Misinformation Discovery. (arXiv:2210.07467v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.07467","description":"<p>We propose a novel system to help fact-checkers formulate search queries for\nknown misinformation claims and effectively search across multiple social media\nplatforms. We introduce an adaptable rewriting strategy, where editing actions\nfor queries containing claims (e.g., swap a word with its synonym; change verb\ntense into present simple) are automatically learned through offline\nreinforcement learning. Our model uses a decision transformer to learn a\nsequence of editing actions that maximizes query retrieval metrics such as mean\naverage precision. We conduct a series of experiments showing that our query\nrewriting system achieves a relative increase in the effectiveness of the\nqueries of up to 42%, while producing editing action sequences that are human\ninterpretable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kazemi_A/0/1/0/all/0/1\">Ashkan Kazemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abzaliev_A/0/1/0/all/0/1\">Artem Abzaliev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_N/0/1/0/all/0/1\">Naihao Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1\">Rui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_Rosas_V/0/1/0/all/0/1\">Ver&#xf3;nica P&#xe9;rez-Rosas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1\">Rada Mihalcea</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Few-Shot Generalization by Exploring and Exploiting Auxiliary Data. (arXiv:2302.00674v4 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.00674","description":"<p>Few-shot learning is valuable in many real-world applications, but learning a\ngeneralizable model without overfitting to the few labeled datapoints is\nchallenging. In this work, we focus on Few-shot Learning with Auxiliary Data\n(FLAD), a training paradigm that assumes access to auxiliary data during\nfew-shot learning in hopes of improving generalization. Previous works have\nproposed automated methods for mixing auxiliary and target data, but these\nmethods typically scale linearly (or worse) with the number of auxiliary\ndatasets, limiting their practicality. In this work we relate FLAD to the\nexplore-exploit dilemma that is central to the multi-armed bandit setting and\nderive algorithms whose computational complexity is independent of the number\nof auxiliary datasets, allowing us to scale to 100x more auxiliary datasets\nthan prior methods. We propose two algorithms -- EXP3-FLAD and UCB1-FLAD -- and\ncompare them with prior FLAD methods that either explore or exploit, finding\nthat the combination of exploration and exploitation is crucial. Through\nextensive experimentation we find that our methods outperform all pre-existing\nFLAD methods by 4% and lead to the first 3 billion parameter language models\nthat outperform the 175 billion parameter GPT-3. Overall, our work suggests\nthat the discovery of better, more efficient mixing strategies for FLAD may\nprovide a viable path towards substantially improving generalization in\nfew-shot learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Albalak_A/0/1/0/all/0/1\">Alon Albalak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chain of Hindsight Aligns Language Models with Feedback. (arXiv:2302.02676v7 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.02676","description":"<p>Learning from human preferences is important for language models to match\nhuman needs and to align with human and social values. Prior works have\nachieved remarkable successes by learning from human feedback to understand and\nfollow instructions. Nonetheless, these methods are either founded on\nhand-picked model generations that are favored by human annotators, rendering\nthem inefficient in terms of data utilization and challenging to apply in\ngeneral, or they depend on reinforcement learning, which often suffers from\nimperfect reward functions and relies on extremely challenging optimizations.\nIn this work, we propose a novel technique, Chain of Hindsight, that is easy to\noptimize and can learn from any form of feedback, regardless of its polarity.\nOur idea is inspired by how humans learn from extensive feedback presented in\nthe form of languages. We convert all types of feedback into sequences of\nsentences, which are then used to fine-tune the model, allowing us to take\nadvantage of the language comprehension capabilities of language models. We\ncondition the model on a sequence of model generations paired with feedback. By\ndoing so, the model is trained to generate outputs based on feedback, while\nlearning to identify and correct negative attributes or errors. Applying our\nmethod to large language models, we observed that Chain of Hindsight\nsignificantly surpasses previous methods in aligning language models with human\npreferences. We report significant improvements on summarization and dialogue\nbenchmarks, with our approach markedly preferred in human evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sferrazza_C/0/1/0/all/0/1\">Carmelo Sferrazza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Possibilities of AI-Generated Text Detection. (arXiv:2304.04736v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.04736","description":"<p>Our work addresses the critical issue of distinguishing text generated by\nLarge Language Models (LLMs) from human-produced text, a task essential for\nnumerous applications. Despite ongoing debate about the feasibility of such\ndifferentiation, we present evidence supporting its consistent achievability,\nexcept when human and machine text distributions are indistinguishable across\ntheir entire support. Drawing from information theory, we argue that as\nmachine-generated text approximates human-like quality, the sample size needed\nfor detection increases. We establish precise sample complexity bounds for\ndetecting AI-generated text, laying groundwork for future research aimed at\ndeveloping advanced, multi-sample detectors. Our empirical evaluations across\nmultiple datasets (Xsum, Squad, IMDb, and Kaggle FakeNews) confirm the\nviability of enhanced detection methods. We test various state-of-the-art text\ngenerators, including GPT-2, GPT-3.5-Turbo, Llama, Llama-2-13B-Chat-HF, and\nLlama-2-70B-Chat-HF, against detectors, including oBERTa-Large/Base-Detector,\nGPTZero. Our findings align with OpenAI's empirical data related to sequence\nlength, marking the first theoretical substantiation for these observations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1\">Souradip Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bedi_A/0/1/0/all/0/1\">Amrit Singh Bedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Sicheng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bang An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1\">Dinesh Manocha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Furong Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bridging Discrete and Backpropagation: Straight-Through and Beyond. (arXiv:2304.08612v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2304.08612","description":"<p>Backpropagation, the cornerstone of deep learning, is limited to computing\ngradients for continuous variables. This limitation poses challenges for\nproblems involving discrete latent variables. To address this issue, we propose\na novel approach to approximate the gradient of parameters involved in\ngenerating discrete latent variables. First, we examine the widely used\nStraight-Through (ST) heuristic and demonstrate that it works as a first-order\napproximation of the gradient. Guided by our findings, we propose ReinMax,\nwhich achieves second-order accuracy by integrating Heun's method, a\nsecond-order numerical method for solving ODEs. ReinMax does not require\nHessian or other second-order derivatives, thus having negligible computation\noverheads. Extensive experimental results on various tasks demonstrate the\nsuperiority of ReinMax over the state of the art. Implementations are released\nat https://github.com/microsoft/ReinMax.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Liyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1\">Chengyu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-Modal Retrieval for Motion and Text via DopTriple Loss. (arXiv:2305.04195v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.04195","description":"<p>Cross-modal retrieval of image-text and video-text is a prominent research\narea in computer vision and natural language processing. However, there has\nbeen insufficient attention given to cross-modal retrieval between human motion\nand text, despite its wide-ranging applicability. To address this gap, we\nutilize a concise yet effective dual-unimodal transformer encoder for tackling\nthis task. Recognizing that overlapping atomic actions in different human\nmotion sequences can lead to semantic conflicts between samples, we explore a\nnovel triplet loss function called DropTriple Loss. This loss function discards\nfalse negative samples from the negative sample set and focuses on mining\nremaining genuinely hard negative samples for triplet training, thereby\nreducing violations they cause. We evaluate our model and approach on the\nHumanML3D and KIT Motion-Language datasets. On the latest HumanML3D dataset, we\nachieve a recall of 62.9% for motion retrieval and 71.5% for text retrieval\n(both based on R@10). The source code for our approach is publicly available at\nhttps://github.com/eanson023/rehamot.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Sheng Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoqiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1\">Xin Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mengyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hong Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"What do others think?\": Task-Oriented Conversational Modeling with Subjective Knowledge. (arXiv:2305.12091v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12091","description":"<p>Task-oriented Dialogue (TOD) Systems aim to build dialogue systems that\nassist users in accomplishing specific goals, such as booking a hotel or a\nrestaurant. Traditional TODs rely on domain-specific APIs/DBs or external\nfactual knowledge to generate responses, which cannot accommodate subjective\nuser requests (e.g., \"Is the WIFI reliable?\" or \"Does the restaurant have a\ngood atmosphere?\"). To address this issue, we propose a novel task of\nsubjective-knowledge-based TOD (SK-TOD). We also propose the first\ncorresponding dataset, which contains subjective knowledge-seeking dialogue\ncontexts and manually annotated responses grounded in subjective knowledge\nsources. When evaluated with existing TOD approaches, we find that this task\nposes new challenges such as aggregating diverse opinions from multiple\nknowledge snippets. We hope this task and dataset can promote further research\non TOD and subjective content understanding. The code and the dataset are\navailable at https://github.com/alexa/dstc11-track5.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gella_S/0/1/0/all/0/1\">Spandana Gella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seokhwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1\">Di Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hazarika_D/0/1/0/all/0/1\">Devamanyu Hazarika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papangelis_A/0/1/0/all/0/1\">Alexandros Papangelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hedayatnia_B/0/1/0/all/0/1\">Behnam Hedayatnia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namazifar_M/0/1/0/all/0/1\">Mahdi Namazifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1\">Dilek Hakkani-Tur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources. (arXiv:2305.13269v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13269","description":"<p>We present chain-of-knowledge (CoK), a novel framework that augments large\nlanguage models (LLMs) by dynamically incorporating grounding information from\nheterogeneous sources. It results in more factual rationales and reduced\nhallucination in generation. Specifically, CoK consists of three stages:\nreasoning preparation, dynamic knowledge adapting, and answer consolidation.\nGiven a knowledge-intensive question, CoK first prepares several preliminary\nrationales and answers while identifying the relevant knowledge domains. If\nthere is no majority consensus among the answers from samples, CoK corrects the\nrationales step by step by adapting knowledge from the identified domains.\nThese corrected rationales can plausibly serve as a better foundation for the\nfinal answer consolidation. Unlike prior studies that primarily use\nunstructured data, CoK also leverages structured knowledge sources such as\nWikidata and tables that provide more reliable factual information. To access\nboth unstructured and structured knowledge sources in the dynamic knowledge\nadapting stage, we propose an adaptive query generator that allows the\ngeneration of queries for various types of query languages, including SPARQL,\nSQL, and natural sentences. Moreover, to minimize error propagation between\nrationales, CoK corrects the rationales progressively using preceding corrected\nrationales to generate and correct subsequent rationales. Extensive experiments\nshow that CoK consistently improves the performance of LLMs on\nknowledge-intensive tasks across different domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xingxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Ruochen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chia_Y/0/1/0/all/0/1\">Yew Ken Chia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1\">Bosheng Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1\">Soujanya Poria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adaptive Chameleon or Stubborn Sloth: Revealing the Behavior of Large Language Models in Knowledge Conflicts. (arXiv:2305.13300v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13300","description":"<p>By providing external information to large language models (LLMs), tool\naugmentation (including retrieval augmentation) has emerged as a promising\nsolution for addressing the limitations of LLMs' static parametric memory.\nHowever, how receptive are LLMs to such external evidence, especially when the\nevidence conflicts with their parametric memory? We present the first\ncomprehensive and controlled investigation into the behavior of LLMs when\nencountering knowledge conflicts. We propose a systematic framework to elicit\nhigh-quality parametric memory from LLMs and construct the corresponding\ncounter-memory, which enables us to conduct a series of controlled experiments.\nOur investigation reveals seemingly contradicting behaviors of LLMs. On the one\nhand, different from prior wisdom, we find that LLMs can be highly receptive to\nexternal evidence even when that conflicts with their parametric memory, given\nthat the external evidence is coherent and convincing. On the other hand, LLMs\nalso demonstrate a strong confirmation bias when the external evidence contains\nsome information that is consistent with their parametric memory, despite being\npresented with conflicting evidence at the same time. These results pose\nimportant implications that are worth careful consideration for the further\ndevelopment and deployment of tool- and retrieval-augmented LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jian Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiangjie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_R/0/1/0/all/0/1\">Renze Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLMatic: Neural Architecture Search via Large Language Models and Quality Diversity Optimization. (arXiv:2306.01102v5 [cs.NE] UPDATED)","link":"http://arxiv.org/abs/2306.01102","description":"<p>Large Language Models (LLMs) have emerged as powerful tools capable of\naccomplishing a broad spectrum of tasks. Their abilities span numerous areas,\nand one area where they have made a significant impact is in the domain of code\ngeneration. In this context, we view LLMs as mutation and crossover tools.\nMeanwhile, Quality-Diversity (QD) algorithms are known to discover diverse and\nrobust solutions. By merging the code-generating abilities of LLMs with the\ndiversity and robustness of QD solutions, we introduce LLMatic, a Neural\nArchitecture Search (NAS) algorithm. While LLMs struggle to conduct NAS\ndirectly through prompts, LLMatic uses a procedural approach, leveraging QD for\nprompts and network architecture to create diverse and highly performant\nnetworks. We test LLMatic on the CIFAR-10 image classification benchmark,\ndemonstrating that it can produce competitive networks with just $2,000$\nsearches, even without prior knowledge of the benchmark domain or exposure to\nany previous top-performing models for the benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nasir_M/0/1/0/all/0/1\">Muhammad U. Nasir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Earle_S/0/1/0/all/0/1\">Sam Earle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1\">Julian Togelius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+James_S/0/1/0/all/0/1\">Steven James</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cleghorn_C/0/1/0/all/0/1\">Christopher Cleghorn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generalized Knowledge Distillation for Auto-regressive Language Models. (arXiv:2306.13649v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2306.13649","description":"<p>Knowledge distillation (KD) is widely used for compressing a teacher model to\nreduce its inference cost and memory footprint, by training a smaller student\nmodel. However, current KD methods for auto-regressive sequence models suffer\nfrom distribution mismatch between output sequences seen during training and\nthose generated by the student during inference. To address this issue, we\nintroduce Generalized Knowledge Distillation (GKD). Instead of solely relying\non a fixed set of output sequences, GKD trains the student on its\nself-generated output sequences by leveraging feedback from the teacher on such\nsequences. Unlike supervised KD approaches, GKD also offers the flexibility to\nemploy alternative loss functions between the student and teacher, which can be\nuseful when the student lacks the expressivity to mimic the teacher's\ndistribution. Furthermore, GKD facilitates the seamless integration of\ndistillation with RL fine-tuning (RLHF). We demonstrate the efficacy of GKD for\ndistilling auto-regressive T5 language models on summarization, translation,\nand arithmetic reasoning tasks as well as task-agnostic instruction tuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_R/0/1/0/all/0/1\">Rishabh Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vieillard_N/0/1/0/all/0/1\">Nino Vieillard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yongchao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanczyk_P/0/1/0/all/0/1\">Piotr Stanczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramos_S/0/1/0/all/0/1\">Sabela Ramos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1\">Matthieu Geist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachem_O/0/1/0/all/0/1\">Olivier Bachem</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RecallM: An Adaptable Memory Mechanism with Temporal Understanding for Large Language Models. (arXiv:2307.02738v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2307.02738","description":"<p>Large Language Models (LLMs) have made extraordinary progress in the field of\nArtificial Intelligence and have demonstrated remarkable capabilities across a\nlarge variety of tasks and domains. However, as we venture closer to creating\nArtificial General Intelligence (AGI) systems, we recognize the need to\nsupplement LLMs with long-term memory to overcome the context window limitation\nand more importantly, to create a foundation for sustained reasoning,\ncumulative learning and long-term user interaction. In this paper we propose\nRecallM, a novel architecture for providing LLMs with an adaptable and\nupdatable long-term memory mechanism. Unlike previous methods, the RecallM\narchitecture is particularly effective at belief updating and maintaining a\ntemporal understanding of the knowledge provided to it. We demonstrate through\nvarious experiments the effectiveness of this architecture. Furthermore,\nthrough our own temporal understanding and belief updating experiments, we show\nthat RecallM is four times more effective than using a vector database for\nupdating knowledge previously stored in long-term memory. We also demonstrate\nthat RecallM shows competitive performance on general question-answering and\nin-context learning tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kynoch_B/0/1/0/all/0/1\">Brandon Kynoch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Latapie_H/0/1/0/all/0/1\">Hugo Latapie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sluis_D/0/1/0/all/0/1\">Dwane van der Sluis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In-context Autoencoder for Context Compression in a Large Language Model. (arXiv:2307.06945v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.06945","description":"<p>We propose the In-context Autoencoder (ICAE), leveraging the power of a large\nlanguage models (LLM) to compress a long context into short compact memory\nslots that can be directly conditioned on by the LLM for various purposes. ICAE\nis first pretrained using both autoencoding and language modeling objectives on\nmassive text data, enabling it to generate memory slots that accurately and\ncomprehensively represent the original context; Then, it is fine-tuned on\ninstruction data for producing desirable responses to various prompts.\nExperiments demonstrate that our lightweight ICAE, introducing fewer than 1%\nadditional parameters, effectively achieves 4X context compression based on\nLlama, offering advantages in both improved latency and GPU memory cost during\ninference, and showing an interesting insight in memorization as well as\npotential for scalability. These promising results imply a novel perspective on\nthe connection between working memory in cognitive science and representation\nlearning in LLMs, revealing ICAE's significant implications in addressing the\nlong context problem and suggesting further research in LLM context management.\nOur data, code and model are released at https://github.com/getao/icae.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1\">Tao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jing Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Si-Qing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Abusing Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs. (arXiv:2307.10490v4 [cs.CR] UPDATED)","link":"http://arxiv.org/abs/2307.10490","description":"<p>We demonstrate how images and sounds can be used for indirect prompt and\ninstruction injection in multi-modal LLMs. An attacker generates an adversarial\nperturbation corresponding to the prompt and blends it into an image or audio\nrecording. When the user asks the (unmodified, benign) model about the\nperturbed image or audio, the perturbation steers the model to output the\nattacker-chosen text and/or make the subsequent dialog follow the attacker's\ninstruction. We illustrate this attack with several proof-of-concept examples\ntargeting LLaVa and PandaGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bagdasaryan_E/0/1/0/all/0/1\">Eugene Bagdasaryan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_T/0/1/0/all/0/1\">Tsung-Yin Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nassi_B/0/1/0/all/0/1\">Ben Nassi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shmatikov_V/0/1/0/all/0/1\">Vitaly Shmatikov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In-Context Learning Learns Label Relationships but Is Not Conventional Learning. (arXiv:2307.12375v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.12375","description":"<p>The predictions of Large Language Models (LLMs) on downstream tasks often\nimprove significantly when including examples of the input--label relationship\nin the context. However, there is currently no consensus about how this\nin-context learning (ICL) ability of LLMs works. For example, while Xie et al.\n(2021) liken ICL to a general-purpose learning algorithm, Min et al. (2022)\nargue ICL does not even learn label relationships from in-context examples. In\nthis paper, we provide novel insights into how ICL leverages label information,\nrevealing both capabilities and limitations. To ensure we obtain a\ncomprehensive picture of ICL behavior, we study probabilistic aspects of ICL\npredictions and thoroughly examine the dynamics of ICL as more examples are\nprovided. Our experiments show that ICL predictions almost always depend on\nin-context labels, and that ICL can learn truly novel tasks in-context.\nHowever, we also find that ICL struggles to fully overcome prediction\npreferences acquired from pre-training data, and, further, that ICL does not\nconsider all in-context information equally.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kossen_J/0/1/0/all/0/1\">Jannik Kossen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1\">Tom Rainforth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis. (arXiv:2307.12856v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2307.12856","description":"<p>Pre-trained large language models (LLMs) have recently achieved better\ngeneralization and sample efficiency in autonomous web automation. However, the\nperformance on real-world websites has still suffered from (1) open domainness,\n(2) limited context length, and (3) lack of inductive bias on HTML. We\nintroduce WebAgent, an LLM-driven agent that learns from self-experience to\ncomplete tasks on real websites following natural language instructions.\nWebAgent plans ahead by decomposing instructions into canonical\nsub-instructions, summarizes long HTML documents into task-relevant snippets,\nand acts on websites via Python programs generated from those. We design\nWebAgent with Flan-U-PaLM, for grounded code generation, and HTML-T5, new\npre-trained LLMs for long HTML documents using local and global attention\nmechanisms and a mixture of long-span denoising objectives, for planning and\nsummarization. We empirically demonstrate that our modular recipe improves the\nsuccess on real websites by over 50%, and that HTML-T5 is the best model to\nsolve various HTML understanding tasks; achieving 18.7% higher success rate\nthan the prior method on MiniWoB web automation benchmark, and SoTA performance\non Mind2Web, an offline task planning evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gur_I/0/1/0/all/0/1\">Izzeddin Gur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furuta_H/0/1/0/all/0/1\">Hiroki Furuta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_A/0/1/0/all/0/1\">Austin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Safdari_M/0/1/0/all/0/1\">Mustafa Safdari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsuo_Y/0/1/0/all/0/1\">Yutaka Matsuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eck_D/0/1/0/all/0/1\">Douglas Eck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faust_A/0/1/0/all/0/1\">Aleksandra Faust</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs. (arXiv:2307.16789v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2307.16789","description":"<p>Despite the advancements of open-source large language models (LLMs), e.g.,\nLLaMA, they remain significantly limited in tool-use capabilities, i.e., using\nexternal tools (APIs) to fulfill human instructions. The reason is that current\ninstruction tuning largely focuses on basic language tasks but ignores the\ntool-use domain. This is in contrast to the excellent tool-use capabilities of\nstate-of-the-art (SOTA) closed-source LLMs, e.g., ChatGPT. To bridge this gap,\nwe introduce ToolLLM, a general tool-use framework encompassing data\nconstruction, model training, and evaluation. We first present ToolBench, an\ninstruction-tuning dataset for tool use, which is constructed automatically\nusing ChatGPT. Specifically, the construction can be divided into three stages:\n(i) API collection: we collect 16,464 real-world RESTful APIs spanning 49\ncategories from RapidAPI Hub; (ii) instruction generation: we prompt ChatGPT to\ngenerate diverse instructions involving these APIs, covering both single-tool\nand multi-tool scenarios; (iii) solution path annotation: we use ChatGPT to\nsearch for a valid solution path (chain of API calls) for each instruction. To\nenhance the reasoning capabilities of LLMs, we develop a novel depth-first\nsearch-based decision tree algorithm. It enables LLMs to evaluate multiple\nreasoning traces and expand the search space. Moreover, to evaluate the\ntool-use capabilities of LLMs, we develop an automatic evaluator: ToolEval.\nBased on ToolBench, we fine-tune LLaMA to obtain an LLM ToolLLaMA, and equip it\nwith a neural API retriever to recommend appropriate APIs for each instruction.\nExperiments show that ToolLLaMA demonstrates a remarkable ability to execute\ncomplex instructions and generalize to unseen APIs, and exhibits comparable\nperformance to ChatGPT. Our ToolLLaMA also demonstrates strong zero-shot\ngeneralization ability in an out-of-distribution tool-use dataset: APIBench.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yujia Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1\">Shihao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yining Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kunlun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_L/0/1/0/all/0/1\">Lan Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yaxi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cong_X/0/1/0/all/0/1\">Xin Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiangru Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_B/0/1/0/all/0/1\">Bill Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Sihan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lauren Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_R/0/1/0/all/0/1\">Runchu Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1\">Ruobing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerstein_M/0/1/0/all/0/1\">Mark Gerstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dahai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Race Detection Using Large Language Models. (arXiv:2308.07505v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2308.07505","description":"<p>Large language models (LLMs) are demonstrating significant promise as an\nalternate strategy to facilitate analyses and optimizations of high-performance\ncomputing programs, circumventing the need for resource-intensive manual tool\ncreation. In this paper, we explore a novel LLM-based data race detection\napproach combining prompting engineering and fine-tuning techniques. We create\na dedicated dataset named DRB-ML, which is derived from DataRaceBench, with\nfine-grain labels showing the presence of data race pairs and their associated\nvariables, line numbers, and read/write information. DRB-ML is then used to\nevaluate representative LLMs and fine-tune open-source ones. Our experiment\nshows that LLMs can be a viable approach to data race detection. However, they\nstill cannot compete with traditional data race detection tools when we need\ndetailed information about variable pairs causing data races.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Le Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xianzhong Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emani_M/0/1/0/all/0/1\">Murali Emani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vanderbruggen_T/0/1/0/all/0/1\">Tristan Vanderbruggen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_P/0/1/0/all/0/1\">Pei-hung Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1\">Chuanhua Liao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models. (arXiv:2308.16137v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.16137","description":"<p>In recent years, there have been remarkable advancements in the performance\nof Transformer-based Large Language Models (LLMs) across various domains. As\nthese LLMs are deployed for increasingly complex domains, they often face the\nneed to follow longer user prompts or generate longer texts. In these\nsituations, the $\\textit{length generalization failure}$ of LLMs on long\nsequences becomes more prominent. Most pre-training schemes truncate training\nsequences to a fixed length. LLMs often struggle to generate fluent and\ncoherent texts after longer contexts, even with relative positional encoding\nspecifically designed to cope with this problem. Common solutions such as\nfinetuning on longer corpora often involve daunting hardware and time costs and\nrequire careful training process design. To more efficiently extrapolate\nexisting LLMs' generation quality to longer texts, we theoretically and\nempirically investigate the main out-of-distribution (OOD) factors contributing\nto this problem. Inspired by this diagnosis, we propose a simple yet effective\nsolution for on-the-fly length generalization, LM-Infinite. It involves only a\n$\\mathbf{\\Lambda}$-shaped attention mask (to avoid excessive attended tokens)\nand a distance limit (to avoid unseen distances) while requiring no parameter\nupdates or learning. We find it applicable to a variety of LLMs using\nrelative-position encoding methods. LM-Infinite is computationally efficient\nwith $O(n)$ time and space, and demonstrates consistent text generation fluency\nand quality to as long as 128k tokens on ArXiv and OpenWebText2 datasets, with\n2.72x decoding speedup. We will make the codes publicly available following\npublication.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_W/0/1/0/all/0/1\">Wenhan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sinong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning. (arXiv:2309.05653v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05653","description":"<p>We introduce MAmmoTH, a series of open-source large language models (LLMs)\nspecifically tailored for general math problem-solving. The MAmmoTH models are\ntrained on MathInstruct, our meticulously curated instruction tuning dataset.\nMathInstruct is compiled from 13 math datasets with intermediate rationales,\nsix of which have rationales newly curated by us. It presents a unique hybrid\nof chain-of-thought (CoT) and program-of-thought (PoT) rationales, and also\nensures extensive coverage of diverse fields in math. The hybrid of CoT and PoT\nnot only unleashes the potential of tool use but also allows different thought\nprocesses for different math problems. As a result, the MAmmoTH series\nsubstantially outperform existing open-source models on nine mathematical\nreasoning datasets across all scales with an average accuracy gain between 16%\nand 32%. Remarkably, our MAmmoTH-7B model reaches 33% on MATH (a\ncompetition-level dataset), which exceeds the best open-source 7B model\n(WizardMath) by 23%, and the MAmmoTH-34B model achieves 44% accuracy on MATH,\neven surpassing GPT-4's CoT result. Our work underscores the importance of\ndiverse problem coverage and the use of hybrid rationales in developing\nsuperior math generalist models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1\">Xiang Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1\">Xingwei Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Ge Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yao Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Huan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multiple evolutionary pressures shape identical consonant avoidance in the world's languages. (arXiv:2309.14006v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.14006","description":"<p>Languages disfavor word forms containing sequences of similar or identical\nconsonants, due to the biomechanical and cognitive difficulties posed by\npatterns of this sort. However, the specific evolutionary processes responsible\nfor this phenomenon are not fully understood. Words containing sequences of\nidentical consonants may be more likely to arise than those without; processes\nof word form mutation may be more likely to remove than create sequences of\nidentical consonants in word forms; finally, words containing identical\nconsonants may die out more frequently than those without. Phylogenetic\nanalyses of the evolution of homologous word forms indicate that words with\nidentical consonants arise less frequently than those without, and processes\nwhich mutate word forms are more likely to remove sequences of identical\nconsonants than introduce them. However, words with identical consonants do not\ndie out more frequently than those without. Further analyses reveal that forms\nwith identical consonants are replaced in basic meaning functions more\nfrequently than words without. Taken together, results suggest that the under\nrepresentation of sequences of identical consonants is overwhelmingly a\nbyproduct of constraints on word form coinage, though processes related to word\nusage also serve to ensure that such patterns are infrequent in more salient\nvocabulary items. These findings clarify previously unknown aspects of\nprocesses of lexical evolution and competition that take place during language\nchange, optimizing communicative systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cathcart_C/0/1/0/all/0/1\">Chundra A. Cathcart</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Intuitive or Dependent? Investigating LLMs' Robustness to Conflicting Prompts. (arXiv:2309.17415v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.17415","description":"<p>This paper explores the robustness of LLMs' preference to their internal\nmemory or the given prompt, which may contain contrasting information in\nreal-world applications due to noise or task settings. To this end, we\nestablish a quantitative benchmarking framework and conduct the role playing\nintervention to control LLMs' preference. In specific, we define two types of\nrobustness, factual robustness targeting the ability to identify the correct\nfact from prompts or memory, and decision style to categorize LLMs' behavior in\nmaking consistent choices -- assuming there is no definitive \"right\" answer --\nintuitive, dependent, or rational based on cognitive theory. Our findings,\nderived from extensive experiments on seven open-source and closed-source LLMs,\nreveal that these models are highly susceptible to misleading prompts,\nespecially for instructing commonsense knowledge. While detailed instructions\ncan mitigate the selection of misleading answers, they also increase the\nincidence of invalid responses. After Unraveling the preference, we intervene\ndifferent sized LLMs through specific style of role instruction, showing their\nvarying upper bound of robustness and adaptivity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ying_J/0/1/0/all/0/1\">Jiahao Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yixin Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_K/0/1/0/all/0/1\">Kai Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yidong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Long Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yongbin Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"JoMA: Demystifying Multilayer Transformers via JOint Dynamics of MLP and Attention. (arXiv:2310.00535v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.00535","description":"<p>We propose Joint MLP/Attention (JoMA) dynamics, a novel mathematical\nframework to understand the training procedure of multilayer Transformer\narchitectures. This is achieved by integrating out the self-attention layer in\nTransformers, producing a modified dynamics of MLP layers only. JoMA removes\nunrealistic assumptions in previous analysis (e.g., lack of residual\nconnection) and predicts that the attention first becomes sparse (to learn\nsalient tokens), then dense (to learn less salient tokens) in the presence of\nnonlinear activations, while in the linear case, it is consistent with existing\nworks that show attention becomes sparse over time. We leverage JoMA to\nqualitatively explains how tokens are combined to form hierarchies in\nmultilayer Transformers, when the input tokens are generated by a latent\nhierarchical generative model. Experiments on models trained from real-world\ndataset (Wikitext2/Wikitext103) and various pre-trained models (OPT, Pythia)\nverify our theoretical findings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuandong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhenyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Beidi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1\">Simon Du</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Wavelet Scattering Transform for Improving Generalization in Low-Resourced Spoken Language Identification. (arXiv:2310.00602v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2310.00602","description":"<p>Commonly used features in spoken language identification (LID), such as\nmel-spectrogram or MFCC, lose high-frequency information due to windowing. The\nloss further increases for longer temporal contexts. To improve generalization\nof the low-resourced LID systems, we investigate an alternate feature\nrepresentation, wavelet scattering transform (WST), that compensates for the\nshortcomings. To our knowledge, WST is not explored earlier in LID tasks. We\nfirst optimize WST features for multiple South Asian LID corpora. We show that\nLID requires low octave resolution and frequency-scattering is not useful.\nFurther, cross-corpora evaluations show that the optimal WST hyper-parameters\ndepend on both train and test corpora. Hence, we develop fused ECAPA-TDNN based\nLID systems with different sets of WST hyper-parameters to improve\ngeneralization for unknown data. Compared to MFCC, EER is reduced upto 14.05%\nand 6.40% for same-corpora and blind VoxLingua107 evaluations, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Dey_S/0/1/0/all/0/1\">Spandan Dey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Singh_P/0/1/0/all/0/1\">Premjeet Singh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Saha_G/0/1/0/all/0/1\">Goutam Saha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TRAM: Benchmarking Temporal Reasoning for Large Language Models. (arXiv:2310.00835v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.00835","description":"<p>Reasoning about time is essential for understanding the nuances of events\ndescribed in natural language. Previous research on this topic has been limited\nin scope, characterized by a lack of standardized benchmarks that would allow\nfor consistent evaluations across different studies. In this paper, we\nintroduce TRAM, a temporal reasoning benchmark composed of ten datasets,\nencompassing various temporal aspects of events such as order, arithmetic,\nfrequency, and duration, designed to facilitate a comprehensive evaluation of\nthe temporal reasoning capabilities of large language models (LLMs). We conduct\nan extensive evaluation using popular LLMs, such as GPT-4 and Llama2, in both\nzero-shot and few-shot learning scenarios. Additionally, we employ BERT-based\nmodels to establish the baseline evaluations. Our findings indicate that these\nmodels still trail human performance in temporal reasoning tasks. It is our\naspiration that TRAM will spur further progress in enhancing the temporal\nreasoning abilities of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yun Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"appjsonify: An Academic Paper PDF-to-JSON Conversion Toolkit. (arXiv:2310.01206v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.01206","description":"<p>We present appjsonify, a Python-based PDF-to-JSON conversion toolkit for\nacademic papers. It parses a PDF file using several visual-based document\nlayout analysis models and rule-based text processing approaches. appjsonify is\na flexible tool that allows users to easily configure the processing pipeline\nto handle a specific format of a paper they wish to process. We are publicly\nreleasing appjsonify as an easy-to-install toolkit available via PyPI and\nGitHub.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yamaguchi_A/0/1/0/all/0/1\">Atsuki Yamaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morishita_T/0/1/0/all/0/1\">Terufumi Morishita</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Generalization of Training-based ChatGPT Detection Methods. (arXiv:2310.01307v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.01307","description":"<p>ChatGPT is one of the most popular language models which achieve amazing\nperformance on various natural language tasks. Consequently, there is also an\nurgent need to detect the texts generated ChatGPT from human written. One of\nthe extensively studied methods trains classification models to distinguish\nboth. However, existing studies also demonstrate that the trained models may\nsuffer from distribution shifts (during test), i.e., they are ineffective to\npredict the generated texts from unseen language tasks or topics. In this work,\nwe aim to have a comprehensive investigation on these methods' generalization\nbehaviors under distribution shift caused by a wide range of factors, including\nprompts, text lengths, topics, and language tasks. To achieve this goal, we\nfirst collect a new dataset with human and ChatGPT texts, and then we conduct\nextensive studies on the collected dataset. Our studies unveil insightful\nfindings which provide guidance for developing future methodologies or data\ncollection strategies for ChatGPT detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Han Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengfei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1\">Shenglai Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1\">Yingqian Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Amy Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Representation Engineering: A Top-Down Approach to AI Transparency. (arXiv:2310.01405v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.01405","description":"<p>In this paper, we identify and characterize the emerging area of\nrepresentation engineering (RepE), an approach to enhancing the transparency of\nAI systems that draws on insights from cognitive neuroscience. RepE places\npopulation-level representations, rather than neurons or circuits, at the\ncenter of analysis, equipping us with novel methods for monitoring and\nmanipulating high-level cognitive phenomena in deep neural networks (DNNs). We\nprovide baselines and an initial analysis of RepE techniques, showing that they\noffer simple yet effective solutions for improving our understanding and\ncontrol of large language models. We showcase how these methods can provide\ntraction on a wide range of safety-relevant problems, including honesty,\nharmlessness, power-seeking, and more, demonstrating the promise of top-down\ntransparency research. We hope that this work catalyzes further exploration of\nRepE and fosters advancements in the transparency and safety of AI systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zou_A/0/1/0/all/0/1\">Andy Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phan_L/0/1/0/all/0/1\">Long Phan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sarah Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campbell_J/0/1/0/all/0/1\">James Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_P/0/1/0/all/0/1\">Phillip Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1\">Richard Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_A/0/1/0/all/0/1\">Alexander Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xuwang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazeika_M/0/1/0/all/0/1\">Mantas Mazeika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dombrowski_A/0/1/0/all/0/1\">Ann-Kathrin Dombrowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1\">Shashwat Goel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1\">Nathaniel Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byun_M/0/1/0/all/0/1\">Michael J. Byun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallen_A/0/1/0/all/0/1\">Alex Mallen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basart_S/0/1/0/all/0/1\">Steven Basart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koyejo_S/0/1/0/all/0/1\">Sanmi Koyejo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fredrikson_M/0/1/0/all/0/1\">Matt Fredrikson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1\">J. Zico Kolter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1\">Dan Hendrycks</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sci-Net: Scale Invariant Model for Buildings Segmentation from Aerial Imagery. (arXiv:2111.06812v5 [cs.CV] CROSS LISTED)","link":"http://arxiv.org/abs/2111.06812","description":"<p>Buildings' segmentation is a fundamental task in the field of earth\nobservation and aerial imagery analysis. Most existing deep learning-based\nmethods in the literature can be applied to a fixed or narrow-range spatial\nresolution imagery. In practical scenarios, users deal with a broad spectrum of\nimage resolutions. Thus, a given aerial image often needs to be re-sampled to\nmatch the spatial resolution of the dataset used to train the deep learning\nmodel, which results in a degradation in segmentation performance. To overcome\nthis challenge, we propose, in this manuscript, Scale-invariant Neural Network\n(Sci-Net) architecture that segments buildings from wide-range spatial\nresolution aerial images. Specifically, our approach leverages UNet\nhierarchical representation and Dense Atrous Spatial Pyramid Pooling to extract\nfine-grained multi-scale representations. Sci-Net significantly outperforms\nstate of the art models on the Open Cities AI and the Multi-Scale Building\ndatasets with a steady improvement margin across different spatial resolutions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nasrallah_H/0/1/0/all/0/1\">Hasan Nasrallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shukor_M/0/1/0/all/0/1\">Mustafa Shukor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghandour_A/0/1/0/all/0/1\">Ali J. Ghandour</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-10-03T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"syn":"http://purl.org/rss/1.0/modules/syndication/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/"}}]}]}