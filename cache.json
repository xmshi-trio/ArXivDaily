{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-08-21T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"AffectEcho: Speaker Independent and Language-Agnostic Emotion and Affect Transfer for Speech Synthesis. (arXiv:2308.08577v1 [cs.SD])","link":"http://arxiv.org/abs/2308.08577","description":"<p>Affect is an emotional characteristic encompassing valence, arousal, and\nintensity, and is a crucial attribute for enabling authentic conversations.\nWhile existing text-to-speech (TTS) and speech-to-speech systems rely on\nstrength embedding vectors and global style tokens to capture emotions, these\nmodels represent emotions as a component of style or represent them in discrete\ncategories. We propose AffectEcho, an emotion translation model, that uses a\nVector Quantized codebook to model emotions within a quantized space featuring\nfive levels of affect intensity to capture complex nuances and subtle\ndifferences in the same emotion. The quantized emotional embeddings are\nimplicitly derived from spoken speech samples, eliminating the need for one-hot\nvectors or explicit strength embeddings. Experimental results demonstrate the\neffectiveness of our approach in controlling the emotions of generated speech\nwhile preserving identity, style, and emotional cadence unique to each speaker.\nWe showcase the language-independent emotion modeling capability of the\nquantized emotional embeddings learned from a bilingual (English and Chinese)\nspeech corpus with an emotion transfer task from a reference speech to a target\nspeech. We achieve state-of-art results on both qualitative and quantitative\nmetrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Viswanath_H/0/1/0/all/0/1\">Hrishikesh Viswanath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Aneesh Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jutras_Dube_P/0/1/0/all/0/1\">Pascal Jutras-Dub&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Prerit Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prashanth_M/0/1/0/all/0/1\">Mridu Prashanth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khaitan_Y/0/1/0/all/0/1\">Yashvardhan Khaitan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bera_A/0/1/0/all/0/1\">Aniket Bera</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FootGPT : A Large Language Model Development Experiment on a Minimal Setting. (arXiv:2308.08610v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08610","description":"<p>With recent empirical observations, it has been argued that the most\nsignificant aspect of developing accurate language models may be the proper\ndataset content and training strategy compared to the number of neural\nparameters, training duration or dataset size. Following this argument, we\nopted to fine tune a one billion parameter size trained general purpose causal\nlanguage model with a dataset curated on team statistics of the Italian\nfootball league first ten game weeks, using low rank adaptation. The limited\ntraining dataset was compiled based on a framework where a powerful commercial\nlarge language model provides distilled paragraphs and question answer pairs as\nintended. The training duration was kept relatively short to provide a basis\nfor our minimal setting exploration. We share our key observations on the\nprocess related to developing a specific purpose language model which is\nintended to interpret soccer data with constrained resources in this article.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Unlu_E/0/1/0/all/0/1\">Eren Unlu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought. (arXiv:2308.08614v1 [cs.LG])","link":"http://arxiv.org/abs/2308.08614","description":"<p>Recent advancements in large-scale models, such as GPT-4, have showcased\nremarkable capabilities in addressing standard queries. However, when facing\ncomplex problems that require multi-step logical reasoning, their accuracy\ndramatically decreases. Current research has explored the realm of\n\\textit{prompting engineering} to bolster the inferential capacities of these\nmodels. Our paper unveils a pioneering prompting technique, dubbed\n\\textit{Graph of Thoughts (GoT)}. Through testing on a trio of escalating\nchallenges: the 24-point game, resolution of high-degree polynomial equations,\nand derivation of formulas for recursive sequences, our method outperformed\nGPT-4, achieving accuracy improvements of $89.7\\%$, $86\\%$, and $56\\%$ for each\nrespective task. Moreover, when juxtaposed with the state-of-the-art (SOTA)\nprompting method, \\textit{Tree of Thought (ToT)}, our approach registered an\naverage accuracy boost of $23\\%$, $24\\%$, and $15\\%$.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lei_B/0/1/0/all/0/1\">Bin Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_p/0/1/0/all/0/1\">pei-Hung Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1\">Chunhua Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1\">Caiwen Ding</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BIOptimus: Pre-training an Optimal Biomedical Language Model with Curriculum Learning for Named Entity Recognition. (arXiv:2308.08625v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08625","description":"<p>Using language models (LMs) pre-trained in a self-supervised setting on large\ncorpora and then fine-tuning for a downstream task has helped to deal with the\nproblem of limited label data for supervised learning tasks such as Named\nEntity Recognition (NER). Recent research in biomedical language processing has\noffered a number of biomedical LMs pre-trained using different methods and\ntechniques that advance results on many BioNLP tasks, including NER. However,\nthere is still a lack of a comprehensive comparison of pre-training approaches\nthat would work more optimally in the biomedical domain. This paper aims to\ninvestigate different pre-training methods, such as pre-training the biomedical\nLM from scratch and pre-training it in a continued fashion. We compare existing\nmethods with our proposed pre-training method of initializing weights for new\ntokens by distilling existing weights from the BERT model inside the context\nwhere the tokens were found. The method helps to speed up the pre-training\nstage and improve performance on NER. In addition, we compare how masking rate,\ncorruption strategy, and masking strategies impact the performance of the\nbiomedical LM. Finally, using the insights from our experiments, we introduce a\nnew biomedical LM (BIOptimus), which is pre-trained using Curriculum Learning\n(CL) and contextualized weight distillation method. Our model sets new states\nof the art on several biomedical Named Entity Recognition (NER) tasks. We\nrelease our code and all pre-trained models\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vera_P/0/1/0/all/0/1\">Pavlova Vera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makhlouf_M/0/1/0/all/0/1\">Mohammed Makhlouf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning the meanings of function words from grounded language using a visual question answering model. (arXiv:2308.08628v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08628","description":"<p>Interpreting a seemingly-simple function word like \"or\", \"behind\", or \"more\"\ncan require logical, numerical, and relational reasoning. How are such words\nlearned by children? Prior acquisition theories have often relied on positing a\nfoundation of innate knowledge. Yet recent neural-network based visual question\nanswering models apparently can learn to use function words as part of\nanswering questions about complex visual scenes. In this paper, we study what\nthese models learn about function words, in the hope of better understanding\nhow the meanings of these words can be learnt by both models and children. We\nshow that recurrent models trained on visually grounded language learn gradient\nsemantics for function words requiring spacial and numerical reasoning.\nFurthermore, we find that these models can learn the meanings of logical\nconnectives \"and\" and \"or\" without any prior knowledge of logical reasoning, as\nwell as early evidence that they can develop the ability to reason about\nalternative expressions when interpreting language. Finally, we show that word\nlearning difficulty is dependent on frequency in models' input. Our findings\noffer evidence that it is possible to learn the meanings of function words in\nvisually grounded context by using non-symbolic general statistical learning\nalgorithms, without any prior knowledge of linguistic meaning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Portelance_E/0/1/0/all/0/1\">Eva Portelance</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_M/0/1/0/all/0/1\">Michael C. Frank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1\">Dan Jurafsky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models for Granularized Barrett's Esophagus Diagnosis Classification. (arXiv:2308.08660v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08660","description":"<p>Diagnostic codes for Barrett's esophagus (BE), a precursor to esophageal\ncancer, lack granularity and precision for many research or clinical use cases.\nLaborious manual chart review is required to extract key diagnostic phenotypes\nfrom BE pathology reports. We developed a generalizable transformer-based\nmethod to automate data extraction. Using pathology reports from Columbia\nUniversity Irving Medical Center with gastroenterologist-annotated targets, we\nperformed binary dysplasia classification as well as granularized multi-class\nBE-related diagnosis classification. We utilized two clinically pre-trained\nlarge language models, with best model performance comparable to a highly\ntailored rule-based system developed using the same data. Binary dysplasia\nextraction achieves 0.964 F1-score, while the multi-class model achieves 0.911\nF1-score. Our method is generalizable and faster to implement as compared to a\ntailored rule-based approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kefeli_J/0/1/0/all/0/1\">Jenna Kefeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soroush_A/0/1/0/all/0/1\">Ali Soroush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diamond_C/0/1/0/all/0/1\">Courtney J. Diamond</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zylberberg_H/0/1/0/all/0/1\">Haley M. Zylberberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+May_B/0/1/0/all/0/1\">Benjamin May</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abrams_J/0/1/0/all/0/1\">Julian A. Abrams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_C/0/1/0/all/0/1\">Chunhua Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tatonetti_N/0/1/0/all/0/1\">Nicholas Tatonetti</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions. (arXiv:2308.08661v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08661","description":"<p>Many open-domain questions are under-specified and thus have multiple\npossible answers, each of which is correct under a different interpretation of\nthe question. Answering such ambiguous questions is challenging, as it requires\nretrieving and then reasoning about diverse information from multiple passages.\nWe present a new state-of-the-art for answering ambiguous questions that\nexploits a database of unambiguous questions generated from Wikipedia. On the\nchallenging ASQA benchmark, which requires generating long-form answers that\nsummarize the multiple answers to an ambiguous question, our method improves\nperformance by 15% (relative improvement) on recall measures and 10% on\nmeasures which evaluate disambiguating questions from predicted outputs.\nRetrieving from the database of generated questions also gives large\nimprovements in diverse passage retrieval (by matching user questions q to\npassages p indirectly, via questions q' generated from p).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Haitian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1\">William W. Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lightweight Adaptation of Neural Language Models via Subspace Embedding. (arXiv:2308.08688v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08688","description":"<p>Traditional neural word embeddings are usually dependent on a richer\ndiversity of vocabulary. However, the language models recline to cover major\nvocabularies via the word embedding parameters, in particular, for multilingual\nlanguage models that generally cover a significant part of their overall\nlearning parameters. In this work, we present a new compact embedding structure\nto reduce the memory footprint of the pre-trained language models with a\nsacrifice of up to 4% absolute accuracy. The embeddings vectors reconstruction\nfollows a set of subspace embeddings and an assignment procedure via the\ncontextual relationship among tokens from pre-trained language models. The\nsubspace embedding structure calibrates to masked language models, to evaluate\nour compact embedding structure on similarity and textual entailment tasks,\nsentence and paraphrase tasks. Our experimental evaluation shows that the\nsubspace embeddings achieve compression rates beyond 99.8% in comparison with\nthe original embeddings for the language models on XNLI and GLUE benchmark\nsuites.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jaiswal_A/0/1/0/all/0/1\">Amit Kumar Jaiswal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haiming Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Decoding Emotions: A comprehensive Multilingual Study of Speech Models for Speech Emotion Recognition. (arXiv:2308.08713v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08713","description":"<p>Recent advancements in transformer-based speech representation models have\ngreatly transformed speech processing. However, there has been limited research\nconducted on evaluating these models for speech emotion recognition (SER)\nacross multiple languages and examining their internal representations. This\narticle addresses these gaps by presenting a comprehensive benchmark for SER\nwith eight speech representation models and six different languages. We\nconducted probing experiments to gain insights into inner workings of these\nmodels for SER. We find that using features from a single optimal layer of a\nspeech model reduces the error rate by 32\\% on average across seven datasets\nwhen compared to systems where features from all layers of speech models are\nused. We also achieve state-of-the-art results for German and Persian\nlanguages. Our probing results indicate that the middle layers of speech models\ncapture the most important emotional information for speech emotion\nrecognition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Anant Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Akshat Gupta</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM-FuncMapper: Function Identification for Interpreting Complex Clauses in Building Codes via LLM. (arXiv:2308.08728v1 [cs.AI])","link":"http://arxiv.org/abs/2308.08728","description":"<p>As a vital stage of automated rule checking (ARC), rule interpretation of\nregulatory texts requires considerable effort. However, interpreting regulatory\nclauses with implicit properties or complex computational logic is still\nchallenging due to the lack of domain knowledge and limited expressibility of\nconventional logic representations. Thus, LLM-FuncMapper, an approach to\nidentifying predefined functions needed to interpret various regulatory clauses\nbased on the large language model (LLM), is proposed. First, by systematically\nanalysis of building codes, a series of atomic functions are defined to capture\nshared computational logics of implicit properties and complex constraints,\ncreating a database of common blocks for interpreting regulatory clauses. Then,\na prompt template with the chain of thought is developed and further enhanced\nwith a classification-based tuning strategy, to enable common LLMs for\neffective function identification. Finally, the proposed approach is validated\nwith statistical analysis, experiments, and proof of concept. Statistical\nanalysis reveals a long-tail distribution and high expressibility of the\ndeveloped function database, with which almost 100% of computer-processible\nclauses can be interpreted and represented as computer-executable codes.\nExperiments show that LLM-FuncMapper achieve promising results in identifying\nrelevant predefined functions for rule interpretation. Further proof of concept\nin automated rule interpretation also demonstrates the possibility of\nLLM-FuncMapper in interpreting complex regulatory clauses. To the best of our\nknowledge, this study is the first attempt to introduce LLM for understanding\nand interpreting complex regulatory clauses, which may shed light on further\nadoption of LLM in the construction domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhe Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Ke-Yin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1\">Xin-Yu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xin-Zheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jia-Rui Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Phrase Representation by Information Bottleneck Guided Text Diffusion Process for Keyphrase Extraction. (arXiv:2308.08739v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08739","description":"<p>Keyphrase extraction (KPE) is an important task in Natural Language\nProcessing for many scenarios, which aims to extract keyphrases that are\npresent in a given document. Many existing supervised methods treat KPE as\nsequential labeling, span-level classification, or generative tasks. However,\nthese methods lack the ability to utilize keyphrase information, which may\nresult in biased results. In this study, we propose Diff-KPE, which leverages\nthe supervised Variational Information Bottleneck (VIB) to guide the text\ndiffusion process for generating enhanced keyphrase representations. Diff-KPE\nfirst generates the desired keyphrase embeddings conditioned on the entire\ndocument and then injects the generated keyphrase embeddings into each phrase\nrepresentation. A ranking network and VIB are then optimized together with rank\nloss and classification loss, respectively. This design of Diff-KPE allows us\nto rank each candidate phrase by utilizing both the information of keyphrases\nand the document. Experiments show that Diff-KPE outperforms existing KPE\nmethods on a large open domain keyphrase extraction benchmark, OpenKP, and a\nscientific domain dataset, KP20K.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yuanzhen Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qingyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1\">Feng Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PMET: Precise Model Editing in a Transformer. (arXiv:2308.08742v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08742","description":"<p>Model editing techniques modify a minor proportion of knowledge in Large\nLanguage Models (LLMs) at a relatively low cost, which have demonstrated\nnotable success. Existing methods assume Transformer Layer (TL) hidden states\nare values of key-value memories of the Feed-Forward Network (FFN). They\nusually optimize the TL hidden states to memorize target knowledge and use it\nto update the weights of the FFN in LLMs. However, the information flow of TL\nhidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN,\nand residual connections. Existing methods neglect the fact that the TL hidden\nstates contains information not specifically required for FFN. Consequently,\nthe performance of model editing decreases. To achieve more precise model\nediting, we analyze hidden states of MHSA and FFN, finding that MHSA encodes\ncertain general knowledge extraction patterns. This implies that MHSA weights\ndo not require updating when new knowledge is introduced. Based on above\nfindings, we introduce PMET, which simultaneously optimizes Transformer\nComponent (TC, namely MHSA and FFN) hidden states, while only using the\noptimized TC hidden states of FFN to precisely update FFN weights. Our\nexperiments demonstrate that PMET exhibits state-of-the-art performance on both\nthe \\textsc{counterfact} and zsRE datasets. Our ablation experiments\nsubstantiate the effectiveness of our enhancements, further reinforcing the\nfinding that the MHSA encodes certain general knowledge extraction patterns and\nindicating its storage of a small amount of factual knowledge. Our code is\navailable at \\url{https://github.com/xpq-tech/PMET.git}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaopeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shasha Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shezheng Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jie Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning. (arXiv:2308.08747v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08747","description":"<p>Catastrophic forgetting (CF) is a phenomenon that occurs in machine learning\nwhen a model forgets previously learned information as it learns new\ninformation. As large language models (LLMs) have shown excellent performance,\nit is interesting to uncover whether CF exists in the continual fine-tuning of\nLLMs. In this study, we empirically evaluate the forgetting phenomenon in LLMs'\nknowledge, from the perspectives of domain knowledge, reasoning, and reading\ncomprehension. The experiments demonstrate that catastrophic forgetting is\ngenerally observed in LLMs ranging from 1b to 7b. Furthermore, as the scale\nincreases, the severity of forgetting also intensifies. Comparing the\ndecoder-only model BLOOMZ with the encoder-decoder model mT0, BLOOMZ suffers\nless forgetting and maintains more knowledge. We also observe that LLMs can\nmitigate language bias (e.g. gender bias) during continual fine-tuning.\nMoreover, we find that ALPACA can maintain more knowledge and capacity compared\nwith LLAMA during the continual fine-tuning, which implies that general\ninstruction tuning can help mitigate the forgetting phenomenon of LLMs in the\nfurther fine-tuning process.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yafu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Discrete Prompt Compression with Reinforcement Learning. (arXiv:2308.08758v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08758","description":"<p>Instruction-tuned Language Models (LMs) are widely used by users to address\nvarious problems with task-specific prompts. Constraints associated with the\ncontext window length and computational costs encourage the development of\ncompressed prompts. Existing methods rely heavily on training embeddings, which\nare designed to accommodate multiple token meanings. This presents challenges\nin terms of interpretability, a fixed number of embedding tokens, reusability\nacross different LMs, and inapplicability when interacting with black-box APIs.\nThis study proposes prompt compression with reinforcement learning (PCRL), a\nnovel discrete prompt compression method that addresses these issues. PCRL\nemploys a computationally efficient policy network that directly edits prompts.\nThe PCRL training approach can be flexibly applied to various types of LMs, as\nwell as decoder-only and encoder-decoder architecture, and can be trained\nwithout gradient access to LMs or labeled data. PCRL achieves an average\nreduction of 24.6% in token count across various instruction prompts while\npreserving performance. Further, we demonstrate that the learned policy can be\ntransferred to larger LMs, and through various analyses, we aid the\nunderstanding of token importance within prompts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jung_H/0/1/0/all/0/1\">Hoyoun Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kyung-Joong Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Differential Privacy, Linguistic Fairness, and Training Data Influence: Impossibility and Possibility Theorems for Multilingual Language Models. (arXiv:2308.08774v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08774","description":"<p>Language models such as mBERT, XLM-R, and BLOOM aim to achieve multilingual\ngeneralization or compression to facilitate transfer to a large number of\n(potentially unseen) languages. However, these models should ideally also be\nprivate, linguistically fair, and transparent, by relating their predictions to\ntraining data. Can these requirements be simultaneously satisfied? We show that\nmultilingual compression and linguistic fairness are compatible with\ndifferential privacy, but that differential privacy is at odds with training\ndata influence sparsity, an objective for transparency. We further present a\nseries of experiments on two common NLP tasks and evaluate multilingual\ncompression and training data influence sparsity under different privacy\nguarantees, exploring these trade-offs in more detail. Our results suggest that\nwe need to develop ways to jointly optimize for these objectives in order to\nfind practical trade-offs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rust_P/0/1/0/all/0/1\">Phillip Rust</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1\">Anders S&#xf8;gaard</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Demonstration Ensembling for In-context Learning. (arXiv:2308.08780v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08780","description":"<p>In-context learning (ICL) operates by showing language models (LMs) examples\nof input-output pairs for a given task, i.e., demonstrations. The standard\napproach for ICL is to prompt the LM with concatenated demonstrations followed\nby the test input. This approach suffers from some issues. First, concatenation\noffers almost no control over the contribution of each demo to the model\nprediction. This can be sub-optimal when some demonstrations are irrelevant to\nthe test example. Second, due to the input length limit of some transformer\nmodels, it might be infeasible to fit many examples into the context,\nespecially when dealing with long-input tasks. In this work, we explore\nDemonstration Ensembling (DENSE) as an alternative to simple concatenation.\n\\model predicts outputs using subsets (i.e., buckets) of the demonstrations and\nthen combines the output probabilities resulting from each subset to produce\nthe final prediction. We study different ensembling methods using GPT-j and\nexperiment on 12 language tasks. Our experiments show weighted max ensembling\nto outperform vanilla concatenation by as large as 2.4 average points. Code\navailable at \\url{https://github.com/mukhal/icl-ensembling}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khalifa_M/0/1/0/all/0/1\">Muhammad Khalifa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Logeswaran_L/0/1/0/all/0/1\">Lajanugen Logeswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Moontae Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Honglak Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lu Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Task Relation Distillation and Prototypical Pseudo Label for Incremental Named Entity Recognition. (arXiv:2308.08793v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08793","description":"<p>Incremental Named Entity Recognition (INER) involves the sequential learning\nof new entity types without accessing the training data of previously learned\ntypes. However, INER faces the challenge of catastrophic forgetting specific\nfor incremental learning, further aggravated by background shift (i.e., old and\nfuture entity types are labeled as the non-entity type in the current task). To\naddress these challenges, we propose a method called task Relation Distillation\nand Prototypical pseudo label (RDP) for INER. Specifically, to tackle\ncatastrophic forgetting, we introduce a task relation distillation scheme that\nserves two purposes: 1) ensuring inter-task semantic consistency across\ndifferent incremental learning tasks by minimizing inter-task relation\ndistillation loss, and 2) enhancing the model's prediction confidence by\nminimizing intra-task self-entropy loss. Simultaneously, to mitigate background\nshift, we develop a prototypical pseudo label strategy that distinguishes old\nentity types from the current non-entity type using the old model. This\nstrategy generates high-quality pseudo labels by measuring the distances\nbetween token embeddings and type-wise prototypes. We conducted extensive\nexperiments on ten INER settings of three benchmark datasets (i.e., CoNLL2003,\nI2B2, and OntoNotes5). The results demonstrate that our method achieves\nsignificant improvements over the previous state-of-the-art methods, with an\naverage increase of 6.08% in Micro F1 score and 7.71% in Macro F1 score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Duzhen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongliu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cong_W/0/1/0/all/0/1\">Wei Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Rongtao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jiahua Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiuyi Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chinese Spelling Correction as Rephrasing Language Model. (arXiv:2308.08796v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08796","description":"<p>This paper studies Chinese Spelling Correction (CSC), which aims to detect\nand correct potential spelling errors in a given sentence. Current\nstate-of-the-art methods regard CSC as a sequence tagging task and fine-tune\nBERT-based models on sentence pairs. However, we note a critical flaw in the\nprocess of tagging one character to another, that the correction is excessively\nconditioned on the error. This is opposite from human mindset, where\nindividuals rephrase the complete sentence based on its semantics, rather than\nsolely on the error patterns memorized before. Such a counter-intuitive\nlearning process results in the bottleneck of generalizability and\ntransferability of machine spelling correction. To address this, we propose\n$Rephrasing Language Modeling$ (ReLM), where the model is trained to rephrase\nthe entire sentence by infilling additional slots, instead of\ncharacter-to-character tagging. This novel training paradigm achieves the new\nstate-of-the-art results across fine-tuned and zero-shot CSC benchmarks,\noutperforming previous counterparts by a large margin. Our method also learns\ntransferable language representation when CSC is jointly trained with other\ntasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Linfeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hongqiu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Linguistically-Informed Neural Architectures for Lexical, Syntactic and Semantic Tasks in Sanskrit. (arXiv:2308.08807v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08807","description":"<p>The primary focus of this thesis is to make Sanskrit manuscripts more\naccessible to the end-users through natural language technologies. The\nmorphological richness, compounding, free word orderliness, and low-resource\nnature of Sanskrit pose significant challenges for developing deep learning\nsolutions. We identify four fundamental tasks, which are crucial for developing\na robust NLP technology for Sanskrit: word segmentation, dependency parsing,\ncompound type identification, and poetry analysis. The first task, Sanskrit\nWord Segmentation (SWS), is a fundamental text processing task for any other\ndownstream applications. However, it is challenging due to the sandhi\nphenomenon that modifies characters at word boundaries. Similarly, the existing\ndependency parsing approaches struggle with morphologically rich and\nlow-resource languages like Sanskrit. Compound type identification is also\nchallenging for Sanskrit due to the context-sensitive semantic relation between\ncomponents. All these challenges result in sub-optimal performance in NLP\napplications like question answering and machine translation. Finally, Sanskrit\npoetry has not been extensively studied in computational linguistics.\n</p>\n<p>While addressing these challenges, this thesis makes various contributions:\n(1) The thesis proposes linguistically-informed neural architectures for these\ntasks. (2) We showcase the interpretability and multilingual extension of the\nproposed systems. (3) Our proposed systems report state-of-the-art performance.\n(4) Finally, we present a neural toolkit named SanskritShala, a web-based\napplication that provides real-time analysis of input for various NLP tasks.\nOverall, this thesis contributes to making Sanskrit manuscripts more accessible\nby developing robust NLP technology and releasing various resources, datasets,\nand web-based toolkit.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sandhan_J/0/1/0/all/0/1\">Jivnesh Sandhan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Factuality Detection using Machine Translation -- a Use Case for German Clinical Text. (arXiv:2308.08827v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08827","description":"<p>Factuality can play an important role when automatically processing clinical\ntext, as it makes a difference if particular symptoms are explicitly not\npresent, possibly present, not mentioned, or affirmed. In most cases, a\nsufficient number of examples is necessary to handle such phenomena in a\nsupervised machine learning setting. However, as clinical text might contain\nsensitive information, data cannot be easily shared. In the context of\nfactuality detection, this work presents a simple solution using machine\ntranslation to translate English data to German to train a transformer-based\nfactuality detection model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sumait_M/0/1/0/all/0/1\">Mohammed Bin Sumait</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gabryszak_A/0/1/0/all/0/1\">Aleksandra Gabryszak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennig_L/0/1/0/all/0/1\">Leonhard Hennig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roller_R/0/1/0/all/0/1\">Roland Roller</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CMB: A Comprehensive Medical Benchmark in Chinese. (arXiv:2308.08833v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08833","description":"<p>Large Language Models (LLMs) provide a possibility to make a great\nbreakthrough in medicine. The establishment of a standardized medical benchmark\nbecomes a fundamental cornerstone to measure progression. However, medical\nenvironments in different regions have their local characteristics, e.g., the\nubiquity and significance of traditional Chinese medicine within China.\nTherefore, merely translating English-based medical evaluation may result in\n\\textit{contextual incongruities} to a local region. To solve the issue, we\npropose a localized medical benchmark called CMB, a Comprehensive Medical\nBenchmark in Chinese, designed and rooted entirely within the native Chinese\nlinguistic and cultural framework. While traditional Chinese medicine is\nintegral to this evaluation, it does not constitute its entirety. Using this\nbenchmark, we have evaluated several prominent large-scale LLMs, including\nChatGPT, GPT-4, dedicated Chinese LLMs, and LLMs specialized in the medical\ndomain. It is worth noting that our benchmark is not devised as a leaderboard\ncompetition but as an instrument for self-assessment of model advancements. We\nhope this benchmark could facilitate the widespread adoption and enhancement of\nmedical LLMs within China. Check details in\n\\url{https://cmedbenchmark.llmzoo.com/}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guiming Hardy Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dingjie Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhihong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Q/0/1/0/all/0/1\">Qingying Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_F/0/1/0/all/0/1\">Feng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianquan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiang Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Benyou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beam Retrieval: General End-to-End Retrieval for Multi-Hop Question Answering. (arXiv:2308.08973v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08973","description":"<p>Multi-hop QA involves finding multiple relevant passages and step-by-step\nreasoning to answer complex questions. While previous approaches have developed\nretrieval modules for selecting relevant passages, they face challenges in\nscenarios beyond two hops, owing to the limited performance of one-step methods\nand the failure of two-step methods when selecting irrelevant passages in\nearlier stages. In this work, we introduce Beam Retrieval, a general end-to-end\nretrieval framework for multi-hop QA. This approach maintains multiple partial\nhypotheses of relevant passages at each step, expanding the search space and\nreducing the risk of missing relevant passages. Moreover, Beam Retrieval\njointly optimizes an encoder and two classification heads by minimizing the\ncombined loss across all hops. To establish a complete QA system, we\nincorporate a supervised reader or a zero-shot GPT-3.5. Experimental results\ndemonstrate that Beam Retrieval achieves a nearly 50% improvement compared with\nbaselines on challenging MuSiQue-Ans, and it also surpasses all previous\nretrievers on HotpotQA and 2WikiMultiHopQA. Providing high-quality context,\nBeam Retrieval helps our supervised reader achieve new state-of-the-art\nperformance and substantially improves (up to 28.8 points) the QA performance\nof zero-shot GPT-3.5.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiahao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haiyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shen Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluation of really good grammatical error correction. (arXiv:2308.08982v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08982","description":"<p>Although rarely stated, in practice, Grammatical Error Correction (GEC)\nencompasses various models with distinct objectives, ranging from grammatical\nerror detection to improving fluency. Traditional evaluation methods fail to\nfully capture the full range of system capabilities and objectives.\nReference-based evaluations suffer from limitations in capturing the wide\nvariety of possible correction and the biases introduced during reference\ncreation and is prone to favor fixing local errors over overall text\nimprovement. The emergence of large language models (LLMs) has further\nhighlighted the shortcomings of these evaluation strategies, emphasizing the\nneed for a paradigm shift in evaluation methodology. In the current study, we\nperform a comprehensive evaluation of various GEC systems using a recently\npublished dataset of Swedish learner texts. The evaluation is performed using\nestablished evaluation metrics as well as human judges. We find that GPT-3 in a\nfew-shot setting by far outperforms previous grammatical error correction\nsystems for Swedish, a language comprising only 0.11% of its training data. We\nalso found that current evaluation methods contain undesirable biases that a\nhuman evaluation is able to reveal. We suggest using human post-editing of GEC\nsystem outputs to analyze the amount of change required to reach native-level\nhuman performance on the task, and provide a dataset annotated with human\npost-edits and assessments of grammaticality, fluency and meaning preservation\nof GEC system outputs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ostling_R/0/1/0/all/0/1\">Robert &#xd6;stling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gillholm_K/0/1/0/all/0/1\">Katarina Gillholm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurfali_M/0/1/0/all/0/1\">Murathan Kurfal&#x131;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattson_M/0/1/0/all/0/1\">Marie Mattson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiren_M/0/1/0/all/0/1\">Mats Wir&#xe9;n</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reinforced Self-Training (ReST) for Language Modeling. (arXiv:2308.08998v1 [cs.CL])","link":"http://arxiv.org/abs/2308.08998","description":"<p>Reinforcement learning from human feedback (RLHF) can improve the quality of\nlarge language model's (LLM) outputs by aligning them with human preferences.\nWe propose a simple algorithm for aligning LLMs with human preferences inspired\nby growing batch reinforcement learning (RL), which we call Reinforced\nSelf-Training (ReST). Given an initial LLM policy, ReST produces a dataset by\ngenerating samples from the policy, which are then used to improve the LLM\npolicy using offline RL algorithms. ReST is more efficient than typical online\nRLHF methods because the training dataset is produced offline, which allows\ndata reuse. While ReST is a general approach applicable to all generative\nlearning settings, we focus on its application to machine translation. Our\nresults show that ReST can substantially improve translation quality, as\nmeasured by automated metrics and human evaluation on machine translation\nbenchmarks in a compute and sample-efficient manner.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gulcehre_C/0/1/0/all/0/1\">Caglar Gulcehre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paine_T/0/1/0/all/0/1\">Tom Le Paine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1\">Srivatsan Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konyushkova_K/0/1/0/all/0/1\">Ksenia Konyushkova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weerts_L/0/1/0/all/0/1\">Lotte Weerts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abhishek Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddhant_A/0/1/0/all/0/1\">Aditya Siddhant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahern_A/0/1/0/all/0/1\">Alex Ahern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Miaosen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_C/0/1/0/all/0/1\">Chenjie Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Macherey_W/0/1/0/all/0/1\">Wolfgang Macherey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firat_O/0/1/0/all/0/1\">Orhan Firat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_N/0/1/0/all/0/1\">Nando de Freitas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Part-of-Speech Tagger for Yiddish. (arXiv:2204.01175v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.01175","description":"<p>We describe the construction and evaluation of a part-of-speech tagger for\nYiddish. This is the first step in a larger project of automatically assigning\npart-of-speech tags and syntactic structure to Yiddish text for purposes of\nlinguistic research. We combine two resources for the current work - an\n80K-word subset of the Penn Parsed Corpus of Historical Yiddish (PPCHY) and 650\nmillion words of OCR'd Yiddish text from the Yiddish Book Center (YBC). Yiddish\northography in the YBC corpus has many spelling inconsistencies, and we present\nsome evidence that even simple non-contextualized embeddings trained on YBC are\nable to capture the relationships among spelling variants without the need to\nfirst \"standardize\" the corpus. We also use YBC for continued pretraining of\ncontexualized embeddings, which are then integrated into a tagger model trained\nand evaluated on the PPCHY. We evaluate the tagger performance on a 10-fold\ncross-validation split, showing that the use of the YBC text for the\ncontextualized embeddings improves tagger performance. We conclude by\ndiscussing some next steps, including the need for additional annotated\ntraining and test data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kulick_S/0/1/0/all/0/1\">Seth Kulick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryant_N/0/1/0/all/0/1\">Neville Ryant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santorini_B/0/1/0/all/0/1\">Beatrice Santorini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallenberg_J/0/1/0/all/0/1\">Joel Wallenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Urieli_A/0/1/0/all/0/1\">Assaf Urieli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Integrating Knowledge Graph embedding and pretrained Language Models in Hypercomplex Spaces. (arXiv:2208.02743v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.02743","description":"<p>Knowledge Graphs, such as Wikidata, comprise structural and textual knowledge\nin order to represent knowledge. For each of the two modalities dedicated\napproaches for graph embedding and language models learn patterns that allow\nfor predicting novel structural knowledge. Few approaches have integrated\nlearning and inference with both modalities and these existing ones could only\npartially exploit the interaction of structural and textual knowledge. In our\napproach, we build on existing strong representations of single modalities and\nwe use hypercomplex algebra to represent both, (i), single-modality embedding\nas well as, (ii), the interaction between different modalities and their\ncomplementary means of knowledge representation. More specifically, we suggest\nDihedron and Quaternion representations of 4D hypercomplex numbers to integrate\nfour modalities namely structural knowledge graph embedding, word-level\nrepresentations (e.g.\\ Word2vec, Fasttext), sentence-level representations\n(Sentence transformer), and document-level representations (sentence\ntransformer, Doc2vec). Our unified vector representation scores the\nplausibility of labelled edges via Hamilton and Dihedron products, thus\nmodeling pairwise interactions between different modalities. Extensive\nexperimental evaluation on standard benchmark datasets shows the superiority of\nour two new models using abundant textual information besides sparse structural\nknowledge to enhance performance in link prediction tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nayyeri_M/0/1/0/all/0/1\">Mojtaba Nayyeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akter_M/0/1/0/all/0/1\">Mst. Mahfuja Akter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1\">Mirza Mohtashim Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rony_M/0/1/0/all/0/1\">Md Rashad Al Hasan Rony</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lehmann_J/0/1/0/all/0/1\">Jens Lehmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staab_S/0/1/0/all/0/1\">Steffen Staab</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Utilization of Large Pre-Trained Models for Low Resource ASR. (arXiv:2210.15445v3 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2210.15445","description":"<p>Unsupervised representation learning has recently helped automatic speech\nrecognition (ASR) to tackle tasks with limited labeled data. Following this,\nhardware limitations and applications give rise to the question how to take\nadvantage of large pre-trained models efficiently and reduce their complexity.\nIn this work, we study a challenging low resource conversational telephony\nspeech corpus from the medical domain in Vietnamese and German. We show the\nbenefits of using unsupervised techniques beyond simple fine-tuning of large\npre-trained models, discuss how to adapt them to a practical telephony task\nincluding bandwidth transfer and investigate different data conditions for\npre-training and fine-tuning. We outperform the project baselines by 22%\nrelative using pretraining techniques. Further gains of 29% can be achieved by\nrefinements of architecture and training and 6% by adding 0.8 h of in-domain\nadaptation data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Vieting_P/0/1/0/all/0/1\">Peter Vieting</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Luscher_C/0/1/0/all/0/1\">Christoph L&#xfc;scher</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dierkes_J/0/1/0/all/0/1\">Julian Dierkes</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PromptCap: Prompt-Guided Task-Aware Image Captioning. (arXiv:2211.09699v4 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2211.09699","description":"<p>Knowledge-based visual question answering (VQA) involves questions that\nrequire world knowledge beyond the image to yield the correct answer. Large\nlanguage models (LMs) like GPT-3 are particularly helpful for this task because\nof their strong knowledge retrieval and reasoning capabilities. To enable LM to\nunderstand images, prior work uses a captioning model to convert images into\ntext. However, when summarizing an image in a single caption sentence, which\nvisual entities to describe are often underspecified. Generic image captions\noften miss visual details essential for the LM to answer visual questions\ncorrectly. To address this challenge, we propose PromptCap (Prompt-guided image\nCaptioning), a captioning model designed to serve as a better connector between\nimages and black-box LMs. Different from generic captions, PromptCap takes a\nnatural-language prompt to control the visual entities to describe in the\ngenerated caption. The prompt contains a question that the caption should aid\nin answering. To avoid extra annotation, PromptCap is trained by examples\nsynthesized with GPT-3 and existing datasets. We demonstrate PromptCap's\neffectiveness on an existing pipeline in which GPT-3 is prompted with image\ncaptions to carry out VQA. PromptCap outperforms generic captions by a large\nmargin and achieves state-of-the-art accuracy on knowledge-based VQA tasks\n(60.4% on OK-VQA and 59.6% on A-OKVQA). Zero-shot results on WebQA show that\nPromptCap generalizes well to unseen domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yushi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_H/0/1/0/all/0/1\">Hang Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhengyuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weijia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jiebo Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Few-Shot Table-to-Text Generation with Prompt Planning and Knowledge Memorization. (arXiv:2302.04415v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.04415","description":"<p>Pre-trained language models (PLM) have achieved remarkable advancement in\ntable-to-text generation tasks. However, the lack of labeled domain-specific\nknowledge and the topology gap between tabular data and text make it difficult\nfor PLMs to yield faithful text. Low-resource generation likewise faces unique\nchallenges in this domain. Inspired by how humans descript tabular data with\nprior knowledge, we suggest a new framework: PromptMize, which targets\ntable-to-text generation under few-shot settings. The design of our framework\nconsists of two aspects: a prompt planner and a knowledge adapter. The prompt\nplanner aims to generate a prompt signal that provides instance guidance for\nPLMs to bridge the topology gap between tabular data and text. Moreover, the\nknowledge adapter memorizes domain-specific knowledge from the unlabelled\ncorpus to supply essential information during generation. Extensive experiments\nand analyses are investigated on three open domain few-shot NLG datasets:\nhuman, song, and book. Compared with previous state-of-the-art approaches, our\nmodel achieves remarkable performance in generating quality as judged by human\nand automatic evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhixin Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Minyxuan Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Jiexing Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jianping Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Ziwei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouhan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guanjie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinbing Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Black Box Few-Shot Adaptation for Vision-Language models. (arXiv:2304.01752v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2304.01752","description":"<p>Vision-Language (V-L) models trained with contrastive learning to align the\nvisual and language modalities have been shown to be strong few-shot learners.\nSoft prompt learning is the method of choice for few-shot downstream adaptation\naiming to bridge the modality gap caused by the distribution shift induced by\nthe new domain. While parameter-efficient, prompt learning still requires\naccess to the model weights and can be computationally infeasible for large\nmodels with billions of parameters. To address these shortcomings, in this\nwork, we describe a black-box method for V-L few-shot adaptation that (a)\noperates on pre-computed image and text features and hence works without access\nto the model's weights, (b) it is orders of magnitude faster at training time,\n(c) it is amenable to both supervised and unsupervised training, and (d) it can\nbe even used to align image and text features computed from uni-modal models.\nTo achieve this, we propose Linear Feature Alignment (LFA), a simple linear\napproach for V-L re-alignment in the target domain. LFA is initialized from a\nclosed-form solution to a least-squares problem and then it is iteratively\nupdated by minimizing a re-ranking loss. Despite its simplicity, our approach\ncan even surpass soft-prompt learning methods as shown by extensive experiments\non 11 image and 2 video datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ouali_Y/0/1/0/all/0/1\">Yassine Ouali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bulat_A/0/1/0/all/0/1\">Adrian Bulat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_B/0/1/0/all/0/1\">Brais Martinez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzimiropoulos_G/0/1/0/all/0/1\">Georgios Tzimiropoulos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Topological properties and organizing principles of semantic networks. (arXiv:2304.12940v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.12940","description":"<p>Interpreting natural language is an increasingly important task in computer\nalgorithms due to the growing availability of unstructured textual data.\nNatural Language Processing (NLP) applications rely on semantic networks for\nstructured knowledge representation. The fundamental properties of semantic\nnetworks must be taken into account when designing NLP algorithms, yet they\nremain to be structurally investigated. We study the properties of semantic\nnetworks from ConceptNet, defined by 7 semantic relations from 11 different\nlanguages. We find that semantic networks have universal basic properties: they\nare sparse, highly clustered, and many exhibit power-law degree distributions.\nOur findings show that the majority of the considered networks are scale-free.\nSome networks exhibit language-specific properties determined by grammatical\nrules, for example networks from highly inflected languages, such as e.g.\nLatin, German, French and Spanish, show peaks in the degree distribution that\ndeviate from a power law. We find that depending on the semantic relation type\nand the language, the link formation in semantic networks is guided by\ndifferent principles. In some networks the connections are similarity-based,\nwhile in others the connections are more complementarity-based. Finally, we\ndemonstrate how knowledge of similarity and complementarity in semantic\nnetworks can improve NLP algorithms in missing link inference.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Budel_G/0/1/0/all/0/1\">Gabriel Budel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Ying Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mieghem_P/0/1/0/all/0/1\">Piet Van Mieghem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitsak_M/0/1/0/all/0/1\">Maksim Kitsak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Edit: Fault-Aware Code Editor for Code Generation. (arXiv:2305.04087v4 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2305.04087","description":"<p>Large language models (LLMs) have demonstrated an impressive ability to\ngenerate codes on competitive programming tasks. However, with limited sample\nnumbers, LLMs still suffer from poor accuracy. Inspired by the process of human\nprogramming, we propose a generate-and-edit approach named Self-Edit that\nutilizes execution results of the generated code from LLMs to improve the code\nquality on the competitive programming task. We execute the generated code on\nthe example test case provided in the question and wrap execution results into\na supplementary comment. Utilizing this comment as guidance, our fault-aware\ncode editor is employed to correct errors in the generated code. We perform\nextensive evaluations across two competitive programming datasets with nine\ndifferent LLMs. Compared to directly generating from LLMs, our approach can\nimprove the average of pass@1 by 89\\% on APPS-dev, 31\\% on APPS-test, and 48\\%\non HumanEval over nine popular code generation LLMs with parameter sizes\nranging from 110M to 175B. Compared to other post-processing methods, our\nmethod demonstrates superior accuracy and efficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kechi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Allen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Ge Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhi Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models. (arXiv:2305.05189v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.05189","description":"<p>Diffusion models, which have emerged to become popular text-to-image\ngeneration models, can produce high-quality and content-rich images guided by\ntextual prompts. However, there are limitations to semantic understanding and\ncommonsense reasoning in existing models when the input prompts are concise\nnarrative, resulting in low-quality image generation. To improve the capacities\nfor narrative prompts, we propose a simple-yet-effective parameter-efficient\nfine-tuning approach called the Semantic Understanding and Reasoning adapter\n(SUR-adapter) for pre-trained diffusion models. To reach this goal, we first\ncollect and annotate a new dataset SURD which consists of more than 57,000\nsemantically corrected multi-modal samples. Each sample contains a simple\nnarrative prompt, a complex keyword-based prompt, and a high-quality image.\nThen, we align the semantic representation of narrative prompts to the complex\nprompts and transfer knowledge of large language models (LLMs) to our\nSUR-adapter via knowledge distillation so that it can acquire the powerful\nsemantic understanding and reasoning capabilities to build a high-quality\ntextual semantic representation for text-to-image generation. We conduct\nexperiments by integrating multiple LLMs and popular pre-trained diffusion\nmodels to show the effectiveness of our approach in enabling diffusion models\nto understand and reason concise natural language without image quality\ndegradation. Our approach can make text-to-image diffusion models easier to use\nwith better user experience, which demonstrates our approach has the potential\nfor further advancing the development of user-friendly text-to-image generation\nmodels by bridging the semantic gap between simple narrative prompts and\ncomplex keyword-based prompts. The code is released at\nhttps://github.com/Qrange-group/SUR-adapter.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1\">Shanshan Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhongzhan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_W/0/1/0/all/0/1\">Wushao Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1\">Jinghui Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Liang Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Clinical Camel: An Open Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding. (arXiv:2305.12031v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12031","description":"<p>We present Clinical Camel, an open large language model (LLM) explicitly\ntailored for clinical research. Fine-tuned from LLaMA-2 using QLoRA, Clinical\nCamel achieves state-of-the-art performance across medical benchmarks among\nopenly available medical LLMs. Leveraging efficient single-GPU training,\nClinical Camel surpasses GPT-3.5 in five-shot evaluations on all assessed\nbenchmarks, including 64.3% on the USMLE Sample Exam (compared to 58.5% for\nGPT-3.5), 77.9% on PubMedQA (compared to 60.2%), 60.7% on MedQA (compared to\n53.6%), and 54.2% on MedMCQA (compared to 51.0%). In addition to these\nbenchmarks, Clinical Camel demonstrates its broader capabilities, such as\nsynthesizing plausible clinical notes. This work introduces dialogue-based\nknowledge encoding, a novel method to synthesize conversational data from dense\nmedical texts. While benchmark results are encouraging, extensive and rigorous\nhuman evaluation across diverse clinical scenarios is imperative to ascertain\nsafety before implementation. By openly sharing Clinical Camel, we hope to\nfoster transparent and collaborative research, working towards the safe\nintegration of LLMs within the healthcare domain. Significant challenges\nconcerning reliability, bias, and the potential for outdated knowledge persist.\nNonetheless, the transparency provided by an open approach reinforces the\nscientific rigor essential for future clinical applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Toma_A/0/1/0/all/0/1\">Augustin Toma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawler_P/0/1/0/all/0/1\">Patrick R. Lawler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ba_J/0/1/0/all/0/1\">Jimmy Ba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnan_R/0/1/0/all/0/1\">Rahul G. Krishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_B/0/1/0/all/0/1\">Barry B. Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken Language Understanding. (arXiv:2305.13512v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13512","description":"<p>Recently, large pretrained language models have demonstrated strong language\nunderstanding capabilities. This is particularly reflected in their zero-shot\nand in-context learning abilities on downstream tasks through prompting. To\nassess their impact on spoken language understanding (SLU), we evaluate several\nsuch models like ChatGPT and OPT of different sizes on multiple benchmarks. We\nverify the emergent ability unique to the largest models as they can reach\nintent classification accuracy close to that of supervised models with zero or\nfew shots on various languages given oracle transcripts. By contrast, the\nresults for smaller models fitting a single GPU fall far behind. We note that\nthe error cases often arise from the annotation scheme of the dataset;\nresponses from ChatGPT are still reasonable. We show, however, that the model\nis worse at slot filling, and its performance is sensitive to ASR errors,\nsuggesting serious challenges for the application of those textual models on\nSLU.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_M/0/1/0/all/0/1\">Mutian He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garner_P/0/1/0/all/0/1\">Philip N. Garner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Human-Like Intuitive Behavior and Reasoning Biases Emerged in Language Models -- and Disappeared in GPT-4. (arXiv:2306.07622v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.07622","description":"<p>Large language models (LLMs) are currently at the forefront of intertwining\nAI systems with human communication and everyday life. Therefore, it is of\ngreat importance to evaluate their emerging abilities. In this study, we show\nthat LLMs, most notably GPT-3, exhibit behavior that strikingly resembles\nhuman-like intuition -- and the cognitive errors that come with it. However,\nLLMs with higher cognitive capabilities, in particular ChatGPT and GPT-4,\nlearned to avoid succumbing to these errors and perform in a hyperrational\nmanner. For our experiments, we probe LLMs with the Cognitive Reflection Test\n(CRT) as well as semantic illusions that were originally designed to\ninvestigate intuitive decision-making in humans. Moreover, we probe how sturdy\nthe inclination for intuitive-like decision-making is. Our study demonstrates\nthat investigating LLMs with methods from psychology has the potential to\nreveal otherwise unknown emergent traits.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hagendorff_T/0/1/0/all/0/1\">Thilo Hagendorff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabi_S/0/1/0/all/0/1\">Sarah Fabi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Does mBERT understand Romansh? Evaluating word embeddings using word alignment. (arXiv:2306.08702v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.08702","description":"<p>We test similarity-based word alignment models (SimAlign and awesome-align)\nin combination with word embeddings from mBERT and XLM-R on parallel sentences\nin German and Romansh. Since Romansh is an unseen language, we are dealing with\na zero-shot setting. Using embeddings from mBERT, both models reach an\nalignment error rate of 0.22, which outperforms fast_align, a statistical\nmodel, and is on par with similarity-based word alignment for seen languages.\nWe interpret these results as evidence that mBERT contains information that can\nbe meaningful and applicable to Romansh.\n</p>\n<p>To evaluate performance, we also present a new trilingual corpus, which we\ncall the DERMIT (DE-RM-IT) corpus, containing press releases made by the Canton\nof Grisons in German, Romansh and Italian in the past 25 years. The corpus\ncontains 4 547 parallel documents and approximately 100 000 sentence pairs in\neach language combination. We additionally present a gold standard for\nGerman-Romansh word alignment. The data is available at\nhttps://github.com/eyldlv/DERMIT-Corpus.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dolev_E/0/1/0/all/0/1\">Eyal Liron Dolev</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generative Multimodal Entity Linking. (arXiv:2306.12725v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.12725","description":"<p>Multimodal Entity Linking (MEL) is the task of mapping mentions with\nmultimodal contexts to the referent entities from a knowledge base (e.g.\nWikipedia). Existing MEL methods mainly focus on designing complex multimodal\ninteraction mechanisms and require fine-tuning all model parameters, which can\nbe prohibitively costly and difficult to scale in the era of Large Language\nModels (LLMs). In this work, we propose GEMEL, a simple yet effective\nGenerative Multimodal Entity Linking framework based on LLMs, which directly\ngenerates target entity names. We keep the vision and language model frozen and\nonly train a feature mapper to enable cross-modality interactions. To adapt\nLLMs to the MEL task, we take advantage of the emergent in-context learning\ncapability of LLMs by retrieving multimodal instances as demonstrations.\nExtensive experiments show that, with only ~0.3% of the model parameters\nfine-tuned, GEMEL achieves state-of-the-art results on two well-established MEL\ndatasets (7.7% accuracy gains on WikiDiverse and 8.8% accuracy gains on\nWikiMEL). The performance gain stems from mitigating the popularity bias of LLM\npredictions and disambiguating less common entities effectively. Further\nanalysis verifies the generality and scalability of GEMEL. Our approach is\ncompatible with any off-the-shelf language model, paving the way towards an\nefficient and general solution for utilizing LLMs in the MEL task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Senbao Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhenran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Baotian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visual Adversarial Examples Jailbreak Aligned Large Language Models. (arXiv:2306.13213v2 [cs.CR] UPDATED)","link":"http://arxiv.org/abs/2306.13213","description":"<p>Recently, there has been a surge of interest in integrating vision into Large\nLanguage Models (LLMs), exemplified by Visual Language Models (VLMs) such as\nFlamingo and GPT-4. This paper sheds light on the security and safety\nimplications of this trend. First, we underscore that the continuous and\nhigh-dimensional nature of the visual input makes it a weak link against\nadversarial attacks, representing an expanded attack surface of\nvision-integrated LLMs. Second, we highlight that the versatility of LLMs also\npresents visual attackers with a wider array of achievable adversarial\nobjectives, extending the implications of security failures beyond mere\nmisclassification. As an illustration, we present a case study in which we\nexploit visual adversarial examples to circumvent the safety guardrail of\naligned LLMs with integrated vision. Intriguingly, we discover that a single\nvisual adversarial example can universally jailbreak an aligned LLM, compelling\nit to heed a wide range of harmful instructions that it otherwise would not)\nand generate harmful content that transcends the narrow scope of a `few-shot'\nderogatory corpus initially employed to optimize the adversarial example. Our\nstudy underscores the escalating adversarial risks associated with the pursuit\nof multimodality. Our findings also connect the long-studied adversarial\nvulnerabilities of neural networks to the nascent field of AI alignment. The\npresented attack suggests a fundamental adversarial challenge for AI alignment,\nespecially in light of the emerging trend toward multimodality in frontier\nfoundation models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1\">Xiangyu Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kaixuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panda_A/0/1/0/all/0/1\">Ashwinee Panda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_P/0/1/0/all/0/1\">Peter Henderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengdi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Overview of Large Language Models. (arXiv:2307.06435v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.06435","description":"<p>Large Language Models (LLMs) have recently demonstrated remarkable\ncapabilities in natural language processing tasks and beyond. This success of\nLLMs has led to a large influx of research contributions in this direction.\nThese works encompass diverse topics such as architectural innovations of the\nunderlying neural networks, context length improvements, model alignment,\ntraining datasets, benchmarking, efficiency and more. With the rapid\ndevelopment of techniques and regular breakthroughs in LLM research, it has\nbecome considerably challenging to perceive the bigger picture of the advances\nin this direction. Considering the rapidly emerging plethora of literature on\nLLMs, it is imperative that the research community is able to benefit from a\nconcise yet comprehensive overview of the recent developments in this field.\nThis article provides that overview to the research community. It not only\nfocuses on a systematic treatment of the existing literature on a broad range\nof LLM related concept, but also pays special attention to providing\ncomprehensive summaries with extensive details about the individual existing\nmodels, datasets and major insights. We also pay heed to aligning our overview\nwith the emerging outlook of this research direction by accounting for the\nother recently materializing reviews of the broader research direction of LLMs.\nOur self-contained comprehensive overview of LLMs discusses relevant background\nconcepts along with covering the advanced topics at the frontier of this\nresearch direction. This review article is intended to not only provide a\nsystematic survey, but also a quick comprehensive reference for the researchers\nand practitioners to draw insights from extensive informative summaries of the\nexisting works to advance the LLM research direction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Naveed_H/0/1/0/all/0/1\">Humza Naveed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Asad Ullah Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_S/0/1/0/all/0/1\">Shi Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saqib_M/0/1/0/all/0/1\">Muhammad Saqib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anwar_S/0/1/0/all/0/1\">Saeed Anwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Usman_M/0/1/0/all/0/1\">Muhammad Usman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_N/0/1/0/all/0/1\">Naveed Akhtar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnes_N/0/1/0/all/0/1\">Nick Barnes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1\">Ajmal Mian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Latent Jailbreak: A Test Suite for Evaluating Both Text Safety and Output Robustness of Large Language Models. (arXiv:2307.08487v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.08487","description":"<p>Considerable research efforts have been devoted to ensuring that large\nlanguage models (LLMs) align with human values and generate safe text. However,\nan excessive focus on sensitivity to certain topics can compromise the model's\nrobustness in following instructions, thereby impacting its overall performance\nin completing tasks. Previous benchmarks for jailbreaking LLMs have primarily\nfocused on evaluating the safety of the models without considering their\nrobustness. In this paper, we propose a benchmark that assesses both the safety\nand robustness of LLMs, emphasizing the need for a balanced approach. To\ncomprehensively study text safety and output robustness, we introduce a latent\njailbreak prompt dataset, each involving malicious instruction embedding.\nSpecifically, we instruct the model to complete a regular task, such as\ntranslation, with the text to be translated containing malicious instructions.\nTo further analyze safety and robustness, we design a hierarchical annotation\nframework. We present a systematic analysis of the safety and robustness of\nLLMs regarding the position of explicit normal instructions, word replacements\n(verbs in explicit normal instructions, target groups in malicious\ninstructions, cue words for explicit normal instructions), and instruction\nreplacements (different explicit normal instructions). Our results demonstrate\nthat current LLMs not only prioritize certain instruction verbs but also\nexhibit varying jailbreak rates for different instruction verbs in explicit\nnormal instructions. Code and data are available at\nhttps://github.com/qiuhuachuan/latent-jailbreak.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_H/0/1/0/all/0/1\">Huachuan Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Anqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Hongliang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1\">Zhenzhong Lan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gradient-Based Word Substitution for Obstinate Adversarial Examples Generation in Language Models. (arXiv:2307.12507v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.12507","description":"<p>In this paper, we study the problem of generating obstinate (over-stability)\nadversarial examples by word substitution in NLP, where input text is\nmeaningfully changed but the model's prediction does not, even though it\nshould. Previous word substitution approaches have predominantly focused on\nmanually designed antonym-based strategies for generating obstinate adversarial\nexamples, which hinders its application as these strategies can only find a\nsubset of obstinate adversarial examples and require human efforts. To address\nthis issue, in this paper, we introduce a novel word substitution method named\nGradObstinate, a gradient-based approach that automatically generates obstinate\nadversarial examples without any constraints on the search space or the need\nfor manual design principles. To empirically evaluate the efficacy of\nGradObstinate, we conduct comprehensive experiments on five representative\nmodels (Electra, ALBERT, Roberta, DistillBERT, and CLIP) finetuned on four NLP\nbenchmarks (SST-2, MRPC, SNLI, and SQuAD) and a language-grounding benchmark\n(MSCOCO). Extensive experiments show that our proposed GradObstinate generates\nmore powerful obstinate adversarial examples, exhibiting a higher attack\nsuccess rate compared to antonym-based methods. Furthermore, to show the\ntransferability of obstinate word substitutions found by GradObstinate, we\nreplace the words in four representative NLP benchmarks with their obstinate\nsubstitutions. Notably, obstinate substitutions exhibit a high success rate\nwhen transferred to other models in black-box settings, including even GPT-3\nand ChatGPT. Examples of obstinate adversarial examples found by GradObstinate\nare available at https://huggingface.co/spaces/anonauthors/SecretLanguage.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yimu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_P/0/1/0/all/0/1\">Peng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyang Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning. (arXiv:2307.13923v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.13923","description":"<p>Grammatical error correction aims to correct ungrammatical sentences\nautomatically. Recently, some work has demonstrated the excellent capabilities\nof closed-source Large Language Models (LLMs, e.g., ChatGPT) in grammatical\nerror correction. However, the potential of open-source LLMs remains\nunexplored. In this paper, we introduced GrammarGPT, an open-source LLM, to\npreliminary explore its potential for native Chinese grammatical error\ncorrection. The core recipe of GrammarGPT is to leverage the hybrid dataset of\nChatGPT-generated and human-annotated. For grammatical errors with clues, we\nproposed a heuristic method to guide ChatGPT to generate ungrammatical\nsentences by providing those clues. For grammatical errors without clues, we\ncollected ungrammatical sentences from publicly available websites and manually\ncorrected them. In addition, we employed an error-invariant augmentation method\nto enhance the ability of the model to correct native Chinese grammatical\nerrors. We ultimately constructed about 1k parallel data and utilized these\ndata to fine-tune open-source LLMs (e.g., Phoenix, released by The Chinese\nUniversity of Hong Kong, Shenzhen) with instruction tuning. The experimental\nresults show that GrammarGPT outperforms the existing SOTA system\nsignificantly. Although model parameters are 20x larger than the SOTA baseline,\nthe required amount of data for instruction tuning is 1200x smaller,\nillustrating the potential of open-source LLMs on native CGEC. Our GrammarGPT\nranks $3^{rd}$ on NLPCC2023 SharedTask1, demonstrating our approach's\neffectiveness. The code and data are available at\n\\url{https://github.com/FreedomIntelligence/GrammarGPT}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yaxin Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_F/0/1/0/all/0/1\">Feng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peifeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Getting pwn'd by AI: Penetration Testing with Large Language Models. (arXiv:2308.00121v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.00121","description":"<p>The field of software security testing, more specifically penetration\ntesting, is an activity that requires high levels of expertise and involves\nmany manual testing and analysis steps. This paper explores the potential usage\nof large-language models, such as GPT3.5, to augment penetration testers with\nAI sparring partners. We explore the feasibility of supplementing penetration\ntesters with AI models for two distinct use cases: high-level task planning for\nsecurity testing assignments and low-level vulnerability hunting within a\nvulnerable virtual machine. For the latter, we implemented a closed-feedback\nloop between LLM-generated low-level actions with a vulnerable virtual machine\n(connected through SSH) and allowed the LLM to analyze the machine state for\nvulnerabilities and suggest concrete attack vectors which were automatically\nexecuted within the virtual machine. We discuss promising initial results,\ndetail avenues for improvement, and close deliberating on the ethics of\nproviding AI-based sparring partners.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Happe_A/0/1/0/all/0/1\">Andreas Happe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cito_J/0/1/0/all/0/1\">J&#xfc;rgen Cito</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?. (arXiv:2308.01284v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.01284","description":"<p>Large language models (LLMs) such as ChatGPT are increasingly being used for\nvarious use cases, including text content generation at scale. Although\ndetection methods for such AI-generated text exist already, we investigate\nChatGPT's performance as a detector on such AI-generated text, inspired by\nworks that use ChatGPT as a data labeler or annotator. We evaluate the\nzero-shot performance of ChatGPT in the task of human-written vs. AI-generated\ntext detection, and perform experiments on publicly available datasets. We\nempirically investigate if ChatGPT is symmetrically effective in detecting\nAI-generated or human-written text. Our findings provide insight on how ChatGPT\nand similar LLMs may be leveraged in automated detection pipelines by simply\nfocusing on solving a specific aspect of the problem and deriving the rest from\nthat solution. All code and data is available at\nhttps://github.com/AmritaBh/ChatGPT-as-Detector.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharjee_A/0/1/0/all/0/1\">Amrita Bhattacharjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WIKITIDE: A Wikipedia-Based Timestamped Definition Pairs Dataset. (arXiv:2308.03582v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.03582","description":"<p>A fundamental challenge in the current NLP context, dominated by language\nmodels, comes from the inflexibility of current architectures to 'learn' new\ninformation. While model-centric solutions like continual learning or\nparameter-efficient fine tuning are available, the question still remains of\nhow to reliably identify changes in language or in the world. In this paper, we\npropose WikiTiDe, a dataset derived from pairs of timestamped definitions\nextracted from Wikipedia. We argue that such resource can be helpful for\naccelerating diachronic NLP, specifically, for training models able to scan\nknowledge resources for core updates concerning a concept, an event, or a named\nentity. Our proposed end-to-end method is fully automatic, and leverages a\nbootstrapping algorithm for gradually creating a high-quality dataset. Our\nresults suggest that bootstrapping the seed version of WikiTiDe leads to better\nfine-tuned models. We also leverage fine-tuned models in a number of downstream\ntasks, showing promising results with respect to competitive baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Borkakoty_H/0/1/0/all/0/1\">Hsuvas Borkakoty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Espinosa_Anke_L/0/1/0/all/0/1\">Luis Espinosa-Anke</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Metacognitive Prompting Improves Understanding in Large Language Models. (arXiv:2308.05342v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.05342","description":"<p>In Large Language Models (LLMs), there have been consistent advancements in\ntask-specific performance, largely influenced by effective prompt design. While\nrecent research on prompting has enhanced the reasoning capabilities of LLMs, a\ngap remains in further improving their understanding abilities. In this study,\nwe introduce Metacognitive Prompting (MP), a strategy inspired by human\nintrospective reasoning processes. Using MP, LLMs undergo a systematic series\nof structured, self-aware evaluations, drawing on both their vast inherent\nknowledge and new insights. Our experiments involve five prevalent LLMs:\nLlama2, Vicuna, PaLM, GPT-3.5, and GPT-4, all of which span various general\nnatural language understanding (NLU) tasks from the GLUE and SuperGLUE\nbenchmarks. Results indicate that, although GPT-4 consistently excels in most\ntasks, PaLM, when equipped with MP, approaches its performance level.\nFurthermore, across models and datasets, MP consistently outperforms existing\nprompting methods, including standard and chain-of-thought prompting. This\nstudy underscores the potential to amplify the understanding abilities of LLMs\nand highlights the benefits of mirroring human introspective reasoning in NLU\ntasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yun Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Knowledge Graphs Simplify Text?. (arXiv:2308.06975v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.06975","description":"<p>Knowledge Graph (KG)-to-Text Generation has seen recent improvements in\ngenerating fluent and informative sentences which describe a given KG. As KGs\nare widespread across multiple domains and contain important entity-relation\ninformation, and as text simplification aims to reduce the complexity of a text\nwhile preserving the meaning of the original text, we propose KGSimple, a novel\napproach to unsupervised text simplification which infuses KG-established\ntechniques in order to construct a simplified KG path and generate a concise\ntext which preserves the original input's meaning. Through an iterative and\nsampling KG-first approach, our model is capable of simplifying text when\nstarting from a KG by learning to keep important information while harnessing\nKG-to-text generation to output fluent and descriptive sentences. We evaluate\nvarious settings of the KGSimple model on currently-available KG-to-text\ndatasets, demonstrating its effectiveness compared to unsupervised text\nsimplification models which start with a given complex text. Our code is\navailable on GitHub.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Colas_A/0/1/0/all/0/1\">Anthony Colas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Haodi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xuanli He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yang Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Daisy Zhe Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Model Compression for Large Language Models. (arXiv:2308.07633v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.07633","description":"<p>Large Language Models (LLMs) have revolutionized natural language processing\ntasks with remarkable success. However, their formidable size and computational\ndemands present significant challenges for practical deployment, especially in\nresource-constrained environments. As these challenges become increasingly\npertinent, the field of model compression has emerged as a pivotal research\narea to alleviate these limitations. This paper presents a comprehensive survey\nthat navigates the landscape of model compression techniques tailored\nspecifically for LLMs. Addressing the imperative need for efficient deployment,\nwe delve into various methodologies, encompassing quantization, pruning,\nknowledge distillation, and more. Within each of these techniques, we highlight\nrecent advancements and innovative approaches that contribute to the evolving\nlandscape of LLM research. Furthermore, we explore benchmarking strategies and\nevaluation metrics that are essential for assessing the effectiveness of\ncompressed LLMs. By providing insights into the latest developments and\npractical implications, this survey serves as an invaluable resource for both\nresearchers and practitioners. As LLMs continue to evolve, this survey aims to\nfacilitate enhanced efficiency and real-world applicability, establishing a\nfoundation for future advancements in the field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xunyu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Can Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiping Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Steering Language Generation: Harnessing Contrastive Expert Guidance and Negative Prompting for Coherent and Diverse Synthetic Data Generation. (arXiv:2308.07645v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.07645","description":"<p>Large Language Models (LLMs) hold immense potential to generate synthetic\ndata of high quality and utility, which has numerous applications from\ndownstream model training to practical data utilisation. However, contemporary\nmodels, despite their impressive capacities, consistently struggle to produce\nboth coherent and diverse data. To address the coherency issue, we introduce\ncontrastive expert guidance, where the difference between the logit\ndistributions of fine-tuned and base language models is emphasised to ensure\ndomain adherence. In order to ensure diversity, we utilise existing real and\nsynthetic examples as negative prompts to the model. We deem this dual-pronged\napproach to logit reshaping as STEER: Semantic Text Enhancement via Embedding\nRepositioning. STEER operates at inference-time and systematically guides the\nLLMs to strike a balance between adherence to the data distribution (ensuring\nsemantic fidelity) and deviation from prior synthetic examples or existing real\ndatasets (ensuring diversity and authenticity). This delicate balancing act is\nachieved by dynamically moving towards or away from chosen representations in\nthe latent space. STEER demonstrates improved performance over previous\nsynthetic data generation techniques, exhibiting better balance between data\ndiversity and coherency across three distinct tasks: hypothesis generation,\ntoxic and non-toxic comment generation, and commonsense reasoning task\ngeneration. We demonstrate how STEER allows for fine-tuned control over the\ndiversity-coherency trade-off via its hyperparameters, highlighting its\nversatility.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+ONeill_C/0/1/0/all/0/1\">Charles O&#x27;Neill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ting_Y/0/1/0/all/0/1\">Yuan-Sen Ting</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciuca_I/0/1/0/all/0/1\">Ioana Ciuca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1\">Jack Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1\">Thang Bui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Forward-Backward Reasoning in Large Language Models for Verification. (arXiv:2308.07758v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.07758","description":"<p>Chain-of-Though (CoT) prompting has shown promising performance in various\nreasoning tasks. Recently, Self-Consistency \\citep{wang2023selfconsistency}\nproposes to sample a diverse set of reasoning chains which may lead to\ndifferent answers while the answer that receives the most votes is selected. In\nthis paper, we propose a novel method to use backward reasoning in verifying\ncandidate answers. We mask a token in the question by ${\\bf x}$ and ask the LLM\nto predict the masked token when a candidate answer is provided by \\textit{a\nsimple template}, i.e., ``\\textit{\\textbf{If we know the answer of the above\nquestion is \\{a candidate answer\\}, what is the value of unknown variable ${\\bf\nx}$?}}'' Intuitively, the LLM is expected to predict the masked token\nsuccessfully if the provided candidate answer is correct. We further propose\nFOBAR to combine forward and backward reasoning for estimating the probability\nof candidate answers. We conduct extensive experiments on six data sets and\nthree LLMs. Experimental results demonstrate that FOBAR achieves\nstate-of-the-art performance on various reasoning benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Weisen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Han Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Longhui Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1\">James T. Kwok</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-08-20T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/"}}]}]}