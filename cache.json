{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-06-22T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Learning to Generate Better Than Your LLM. (arXiv:2306.11816v1 [cs.LG])","link":"http://arxiv.org/abs/2306.11816","description":"<p>Reinforcement learning (RL) has emerged as a powerful paradigm for\nfine-tuning Large Language Models (LLMs) for conditional text generation. In\nparticular, recent LLMs such as ChatGPT and GPT-4 can engage in fluent\nconversations with users by incorporating RL and feedback from humans. Inspired\nby learning-to-search algorithms and capitalizing on key properties of text\ngeneration, we seek to investigate reinforcement learning algorithms beyond\ngeneral purpose algorithms such as Proximal policy optimization (PPO). In\nparticular, we extend RL algorithms to allow them to interact with a dynamic\nblack-box guide LLM such as GPT-3 and propose RL with guided feedback (RLGF), a\nsuite of RL algorithms for LLM fine-tuning. We experiment on the IMDB positive\nreview and CommonGen text generation task from the GRUE benchmark. We show that\nour RL algorithms achieve higher performance than supervised learning (SL) and\ndefault PPO baselines, demonstrating the benefit of interaction with the guide\nLLM. On CommonGen, we not only outperform our SL baselines but also improve\nbeyond PPO across a variety of lexical and semantic metrics beyond the one we\noptimized for. Notably, on the IMDB dataset, we show that our GPT-2 based\npolicy outperforms the zero-shot GPT-3 oracle, indicating that our algorithms\ncan learn from a powerful, black-box GPT-3 oracle with a simpler, cheaper, and\npublicly available GPT-2 model while gaining performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1\">Jonathan D. Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brantley_K/0/1/0/all/0/1\">Kiante Brantley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramamurthy_R/0/1/0/all/0/1\">Rajkumar Ramamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misra_D/0/1/0/all/0/1\">Dipendra Misra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wen Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EvolveMT: an Ensemble MT Engine Improving Itself with Usage Only. (arXiv:2306.11823v1 [cs.CL])","link":"http://arxiv.org/abs/2306.11823","description":"<p>This paper presents EvolveMT for efficiently combining multiple machine\ntranslation (MT) engines. The proposed system selects the output from a single\nengine for each segment by utilizing online learning techniques to predict the\nmost suitable system for every translation request. A neural quality estimation\nmetric supervises the method without requiring reference translations. The\nonline learning capability of this system allows for dynamic adaptation to\nalterations in the domain or machine translation engines, thereby obviating the\nnecessity for additional training. EvolveMT selects a subset of translation\nengines to be called based on the source sentence features. The degree of\nexploration is configurable according to the desired quality-cost trade-off.\nResults from custom datasets demonstrate that EvolveMT achieves similar\ntranslation accuracy at a lower cost than selecting the best translation of\neach segment from all translations using an MT quality estimator. To our\nknowledge, EvolveMT is the first meta MT system that adapts itself after\ndeployment to incoming translation requests from the production environment\nwithout needing costly retraining on human feedback.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuksel_K/0/1/0/all/0/1\">Kamer Ali Yuksel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunduz_A/0/1/0/all/0/1\">Ahmet Gunduz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Badrashiny_M/0/1/0/all/0/1\">Mohamed Al-Badrashiny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Shreyas Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sawaf_H/0/1/0/all/0/1\">Hassan Sawaf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Compositionality and Improved Training of NADO. (arXiv:2306.11825v1 [cs.CL])","link":"http://arxiv.org/abs/2306.11825","description":"<p>NeurAlly-Decomposed Oracle (NADO) is a powerful approach for controllable\ngeneration with large language models. Differentiating from finetuning/prompt\ntuning, it has the potential to avoid catastrophic forgetting of the large base\nmodel and achieve guaranteed convergence to an entropy-maximized closed-form\nsolution without significantly limiting the model capacity. Despite its\nsuccess, several challenges arise when applying NADO to more complex scenarios.\nFirst, the best practice of using NADO for the composition of multiple control\nsignals is under-explored. Second, vanilla NADO suffers from gradient vanishing\nfor low-probability control signals and is highly reliant on the\nforward-consistency regularization. In this paper, we study the aforementioned\nchallenges when using NADO theoretically and empirically. We show we can\nachieve guaranteed compositional generalization of NADO with a certain\npractice, and propose a novel alternative parameterization of NADO to perfectly\nguarantee the forward-consistency. We evaluate the improved training of NADO,\ni.e. NADO++, on CommonGen. Results show that NADO++ improves the effectiveness\nof the algorithm in multiple aspects.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Sidi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wenbo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1\">Chenyang Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Arpit Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shanchan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_T/0/1/0/all/0/1\">Tagyoung Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"QuOTeS: Query-Oriented Technical Summarization. (arXiv:2306.11832v1 [cs.IR])","link":"http://arxiv.org/abs/2306.11832","description":"<p>Abstract. When writing an academic paper, researchers often spend\nconsiderable time reviewing and summarizing papers to extract relevant\ncitations and data to compose the Introduction and Related Work sections. To\naddress this problem, we propose QuOTeS, an interactive system designed to\nretrieve sentences related to a summary of the research from a collection of\npotential references and hence assist in the composition of new papers. QuOTeS\nintegrates techniques from Query-Focused Extractive Summarization and\nHigh-Recall Information Retrieval to provide Interactive Query-Focused\nSummarization of scientific documents. To measure the performance of our\nsystem, we carried out a comprehensive user study where participants uploaded\npapers related to their research and evaluated the system in terms of its\nusability and the quality of the summaries it produces. The results show that\nQuOTeS provides a positive user experience and consistently provides\nquery-focused summaries that are relevant, concise, and complete. We share the\ncode of our system and the novel Query-Focused Summarization dataset collected\nduring our experiments at https://github.com/jarobyte91/quotes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ramirez_Orta_J/0/1/0/all/0/1\">Juan Ramirez-Orta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xamena_E/0/1/0/all/0/1\">Eduardo Xamena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maguitman_A/0/1/0/all/0/1\">Ana Maguitman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soto_A/0/1/0/all/0/1\">Axel J. Soto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zanoto_F/0/1/0/all/0/1\">Flavia P. Zanoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milios_E/0/1/0/all/0/1\">Evangelos Milios</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Machine Translation Corpus Generation. (arXiv:2306.11838v1 [cs.CL])","link":"http://arxiv.org/abs/2306.11838","description":"<p>This paper proposes an efficient and semi-automated method for\nhuman-in-the-loop post-editing for machine translation (MT) corpus generation.\nThe method is based on online training of a custom MT quality estimation metric\non-the-fly as linguists perform post-edits. The online estimator is used to\nprioritize worse hypotheses for post-editing, and auto-close best hypotheses\nwithout post-editing. This way, significant improvements can be achieved in the\nresulting quality of post-edits at a lower cost due to reduced human\ninvolvement. The trained estimator can also provide an online sanity check\nmechanism for post-edits and remove the need for additional linguists to review\nthem or work on the same hypotheses. In this paper, the effect of prioritizing\nwith the proposed method on the resulting MT corpus quality is presented versus\nscheduling hypotheses randomly. As demonstrated by experiments, the proposed\nmethod improves the lifecycle of MT models by focusing the linguist effort on\nproduction samples and hypotheses, which matter most for expanding MT corpora\nto be used for re-training them.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuksel_K/0/1/0/all/0/1\">Kamer Ali Yuksel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunduz_A/0/1/0/all/0/1\">Ahmet Gunduz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Shreyas Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sawaf_H/0/1/0/all/0/1\">Hassan Sawaf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieval-Based Transformer for Table Augmentation. (arXiv:2306.11843v1 [cs.CL])","link":"http://arxiv.org/abs/2306.11843","description":"<p>Data preparation, also called data wrangling, is considered one of the most\nexpensive and time-consuming steps when performing analytics or building\nmachine learning models. Preparing data typically involves collecting and\nmerging data from complex heterogeneous, and often large-scale data sources,\nsuch as data lakes. In this paper, we introduce a novel approach toward\nautomatic data wrangling in an attempt to alleviate the effort of end-users,\ne.g. data analysts, in structuring dynamic views from data lakes in the form of\ntabular data. We aim to address table augmentation tasks, including row/column\npopulation and data imputation. Given a corpus of tables, we propose a\nretrieval augmented self-trained transformer model. Our self-learning strategy\nconsists in randomly ablating tables from the corpus and training the\nretrieval-based model to reconstruct the original values or headers given the\npartial tables as input. We adopt this strategy to first train the dense neural\nretrieval model encoding table-parts to vectors, and then the end-to-end model\ntrained to perform table augmentation tasks. We test on EntiTables, the\nstandard benchmark for table augmentation, as well as introduce a new benchmark\nto advance further research: WebTables. Our model consistently and\nsubstantially outperforms both supervised statistical methods and the current\nstate-of-the-art transformer-based models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Glass_M/0/1/0/all/0/1\">Michael Glass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xueqing Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naik_A/0/1/0/all/0/1\">Ankita Rajaram Naik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossiello_G/0/1/0/all/0/1\">Gaetano Rossiello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gliozzo_A/0/1/0/all/0/1\">Alfio Gliozzo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Open-Domain Text Evaluation via Meta Distribution Modeling. (arXiv:2306.11879v1 [cs.CL])","link":"http://arxiv.org/abs/2306.11879","description":"<p>Recent advances in open-domain text generation models powered by large\npre-trained language models (LLMs) have achieved remarkable performance.\nHowever, evaluating and controlling these models for desired attributes remains\na challenge, as traditional reference-based metrics such as BLEU, ROUGE, and\nMETEOR are insufficient for open-ended generation tasks. Similarly, while\ntrainable discriminator-based evaluation metrics show promise, obtaining\nhigh-quality training data is a non-trivial task. In this paper, we introduce a\nnovel approach to evaluate open-domain generation - the Meta-Distribution\nMethods (MDM). Drawing on the correlation between the rising parameter counts\nand the improving performance of LLMs, MDM creates a mapping from the contrast\nof two probabilistic distributions -- one known to be superior to the other --\nto quality measures, which can be viewed as a distribution of distributions\ni.e. Meta-Distribution. We investigate MDM for open-domain text generation\nevaluation under two paradigms: 1) \\emph{Generative} MDM, which leverages the\nMeta-Distribution Methods to generate in-domain negative samples for training\ndiscriminator-based metrics; 2) \\emph{Discriminative} MDM, which directly uses\ndistribution discrepancies between two language models for evaluation. Our\nexperiments on multi-turn dialogue and factuality in abstractive summarization\ndemonstrate that MDMs correlate better with human judgment than existing\nautomatic evaluation metrics on both tasks, highlighting the strong performance\nand generalizability of such methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Sidi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianlu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring New Frontiers in Agricultural NLP: Investigating the Potential of Large Language Models for Food Applications. (arXiv:2306.11892v1 [cs.CL])","link":"http://arxiv.org/abs/2306.11892","description":"<p>This paper explores new frontiers in agricultural natural language processing\nby investigating the effectiveness of using food-related text corpora for\npretraining transformer-based language models. In particular, we focus on the\ntask of semantic matching, which involves establishing mappings between food\ndescriptions and nutrition data. To accomplish this, we fine-tune a pre-trained\ntransformer-based language model, AgriBERT, on this task, utilizing an external\nsource of knowledge, such as the FoodOn ontology. To advance the field of\nagricultural NLP, we propose two new avenues of exploration: (1) utilizing\nGPT-based models as a baseline and (2) leveraging ChatGPT as an external source\nof knowledge. ChatGPT has shown to be a strong baseline in many NLP tasks, and\nwe believe it has the potential to improve our model in the task of semantic\nmatching and enhance our model's understanding of food-related concepts and\nrelationships. Additionally, we experiment with other applications, such as\ncuisine prediction based on food ingredients, and expand the scope of our\nresearch to include other NLP tasks beyond semantic matching. Overall, this\npaper provides promising avenues for future research in this field, with\npotential implications for improving the performance of agricultural NLP\napplications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rezayi_S/0/1/0/all/0/1\">Saed Rezayi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zihao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhakal_C/0/1/0/all/0/1\">Chandra Dhakal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_B/0/1/0/all/0/1\">Bao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1\">Haixing Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mai_G/0/1/0/all/0/1\">Gengchen Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ninghao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhen_C/0/1/0/all/0/1\">Chen Zhen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sheng Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluation of Chinese-English Machine Translation of Emotion-Loaded Microblog Texts: A Human Annotated Dataset for the Quality Assessment of Emotion Translation. (arXiv:2306.11900v1 [cs.CL])","link":"http://arxiv.org/abs/2306.11900","description":"<p>In this paper, we focus on how current Machine Translation (MT) tools perform\non the translation of emotion-loaded texts by evaluating outputs from Google\nTranslate according to a framework proposed in this paper. We propose this\nevaluation framework based on the Multidimensional Quality Metrics (MQM) and\nperform a detailed error analysis of the MT outputs. From our analysis, we\nobserve that about 50% of the MT outputs fail to preserve the original emotion.\nAfter further analysis of the errors, we find that emotion carrying words and\nlinguistic phenomena such as polysemous words, negation, abbreviation etc., are\ncommon causes for these translation errors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qian_S/0/1/0/all/0/1\">Shenbin Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orasan_C/0/1/0/all/0/1\">Constantin Orasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carmo_F/0/1/0/all/0/1\">Felix do Carmo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qiuliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanojia_D/0/1/0/all/0/1\">Diptesh Kanojia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Opportunities and Risks of LLMs for Scalable Deliberation with Polis. (arXiv:2306.11932v1 [cs.SI])","link":"http://arxiv.org/abs/2306.11932","description":"<p>Polis is a platform that leverages machine intelligence to scale up\ndeliberative processes. In this paper, we explore the opportunities and risks\nassociated with applying Large Language Models (LLMs) towards challenges with\nfacilitating, moderating and summarizing the results of Polis engagements. In\nparticular, we demonstrate with pilot experiments using Anthropic's Claude that\nLLMs can indeed augment human intelligence to help more efficiently run Polis\nconversations. In particular, we find that summarization capabilities enable\ncategorically new methods with immense promise to empower the public in\ncollective meaning-making exercises. And notably, LLM context limitations have\na significant impact on insight and quality of these results.\n</p>\n<p>However, these opportunities come with risks. We discuss some of these risks,\nas well as principles and techniques for characterizing and mitigating them,\nand the implications for other deliberative or political systems that may\nemploy LLMs. Finally, we conclude with several open future research directions\nfor augmenting tools like Polis with LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Small_C/0/1/0/all/0/1\">Christopher T. Small</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vendrov_I/0/1/0/all/0/1\">Ivan Vendrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durmus_E/0/1/0/all/0/1\">Esin Durmus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Homaei_H/0/1/0/all/0/1\">Hadjar Homaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barry_E/0/1/0/all/0/1\">Elizabeth Barry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cornebise_J/0/1/0/all/0/1\">Julien Cornebise</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzman_T/0/1/0/all/0/1\">Ted Suzman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguli_D/0/1/0/all/0/1\">Deep Ganguli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Megill_C/0/1/0/all/0/1\">Colin Megill</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Understanding What Code Language Models Learned. (arXiv:2306.11943v1 [cs.SE])","link":"http://arxiv.org/abs/2306.11943","description":"<p>Pre-trained language models are effective in a variety of natural language\ntasks, but it has been argued their capabilities fall short of fully learning\nmeaning or understanding language. To understand the extent to which language\nmodels can learn some form of meaning, we investigate their ability to capture\nsemantics of code beyond superficial frequency and co-occurrence. In contrast\nto previous research on probing models for linguistic features, we study\npre-trained models in a setting that allows for objective and straightforward\nevaluation of a model's ability to learn semantics. In this paper, we examine\nwhether such models capture the semantics of code, which is precisely and\nformally defined. Through experiments involving the manipulation of code\nfragments, we show that code pre-trained models of code learn a robust\nrepresentation of the computational semantics of code that goes beyond\nsuperficial features of form alone\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_T/0/1/0/all/0/1\">Toufique Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chengxuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cathy Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devanbu_P/0/1/0/all/0/1\">Prem Devanbu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagae_K/0/1/0/all/0/1\">Kenji Sagae</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interactive Molecular Discovery with Natural Language. (arXiv:2306.11976v1 [cs.CL])","link":"http://arxiv.org/abs/2306.11976","description":"<p>Natural language is expected to be a key medium for various human-machine\ninteractions in the era of large language models. When it comes to the\nbiochemistry field, a series of tasks around molecules (e.g., property\nprediction, molecule mining, etc.) are of great significance while having a\nhigh technical threshold. Bridging the molecule expressions in natural language\nand chemical language can not only hugely improve the interpretability and\nreduce the operation difficulty of these tasks, but also fuse the chemical\nknowledge scattered in complementary materials for a deeper comprehension of\nmolecules. Based on these benefits, we propose the conversational molecular\ndesign, a novel task adopting natural language for describing and editing\ntarget molecules. To better accomplish this task, we design ChatMol, a\nknowledgeable and versatile generative pre-trained model, enhanced by injecting\nexperimental property information, molecular spatial knowledge, and the\nassociations between natural and chemical languages into it. Several typical\nsolutions including large language models (e.g., ChatGPT) are evaluated,\nproving the challenge of conversational molecular design and the effectiveness\nof our knowledge enhancement method. Case observations and analysis are\nconducted to provide directions for further exploration of natural-language\ninteraction in molecular discovery.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1\">Zheni Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1\">Bangchen Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shipeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiarui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1\">Haishen Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xingzhi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_G/0/1/0/all/0/1\">Guotong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"3HAN: A Deep Neural Network for Fake News Detection. (arXiv:2306.12014v1 [cs.LG])","link":"http://arxiv.org/abs/2306.12014","description":"<p>The rapid spread of fake news is a serious problem calling for AI solutions.\nWe employ a deep learning based automated detector through a three level\nhierarchical attention network (3HAN) for fast, accurate detection of fake\nnews. 3HAN has three levels, one each for words, sentences, and the headline,\nand constructs a news vector: an effective representation of an input news\narticle, by processing an article in an hierarchical bottom-up manner. The\nheadline is known to be a distinguishing feature of fake news, and furthermore,\nrelatively few words and sentences in an article are more important than the\nrest. 3HAN gives a differential importance to parts of an article, on account\nof its three layers of attention. By experiments on a large real-world data\nset, we observe the effectiveness of 3HAN with an accuracy of 96.77%. Unlike\nsome other deep learning models, 3HAN provides an understandable output through\nthe attention weights given to different parts of an article, which can be\nvisualized through a heatmap to enable further manual fact checking.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singhania_S/0/1/0/all/0/1\">Sneha Singhania</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_N/0/1/0/all/0/1\">Nigel Fernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_S/0/1/0/all/0/1\">Shrisha Rao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Semi-Autoregressive Graph Generative Model for Dependency Graph Parsing. (arXiv:2306.12018v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12018","description":"<p>Recent years have witnessed the impressive progress in Neural Dependency\nParsing. According to the different factorization approaches to the graph joint\nprobabilities, existing parsers can be roughly divided into autoregressive and\nnon-autoregressive patterns. The former means that the graph should be\nfactorized into multiple sequentially dependent components, then it can be\nbuilt up component by component. And the latter assumes these components to be\nindependent so that they can be outputted in a one-shot manner. However, when\ntreating the directed edge as an explicit dependency relationship, we discover\nthat there is a mixture of independent and interdependent components in the\ndependency graph, signifying that both aforementioned models fail to precisely\ncapture the explicit dependencies among nodes and edges. Based on this\nproperty, we design a Semi-Autoregressive Dependency Parser to generate\ndependency graphs via adding node groups and edge groups autoregressively while\npouring out all group elements in parallel. The model gains a trade-off between\nnon-autoregression and autoregression, which respectively suffer from the lack\nof target inter-dependencies and the uncertainty of graph generation orders.\nThe experiments show the proposed parser outperforms strong baselines on\nEnhanced Universal Dependencies of multiple languages, especially achieving\n$4\\%$ average promotion at graph-level accuracy. Also, the performances of\nmodel variations show the importance of specific parts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Ye Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Mingming Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Ping Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visual-Aware Text-to-Speech. (arXiv:2306.12020v1 [eess.AS])","link":"http://arxiv.org/abs/2306.12020","description":"<p>Dynamically synthesizing talking speech that actively responds to a listening\nhead is critical during the face-to-face interaction. For example, the speaker\ncould take advantage of the listener's facial expression to adjust the tones,\nstressed syllables, or pauses. In this work, we present a new visual-aware\ntext-to-speech (VA-TTS) task to synthesize speech conditioned on both textual\ninputs and sequential visual feedback (e.g., nod, smile) of the listener in\nface-to-face communication. Different from traditional text-to-speech, VA-TTS\nhighlights the impact of visual modality. On this newly-minted task, we devise\na baseline model to fuse phoneme linguistic information and listener visual\nsignals for speech synthesis. Extensive experiments on multimodal conversation\ndataset ViCo-X verify our proposal for generating more natural audio with\nscenario-appropriate rhythm and prosody.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Zhou_M/0/1/0/all/0/1\">Mohan Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bai_Y/0/1/0/all/0/1\">Yalong Bai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yao_T/0/1/0/all/0/1\">Ting Yao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_T/0/1/0/all/0/1\">Tiejun Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mei_T/0/1/0/all/0/1\">Tao Mei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Strategies in Transfer Learning for Low-Resource Speech Synthesis: Phone Mapping, Features Input, and Source Language Selection. (arXiv:2306.12040v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12040","description":"<p>We compare using a PHOIBLE-based phone mapping method and using phonological\nfeatures input in transfer learning for TTS in low-resource languages. We use\ndiverse source languages (English, Finnish, Hindi, Japanese, and Russian) and\ntarget languages (Bulgarian, Georgian, Kazakh, Swahili, Urdu, and Uzbek) to\ntest the language-independence of the methods and enhance the findings'\napplicability. We use Character Error Rates from automatic speech recognition\nand predicted Mean Opinion Scores for evaluation. Results show that both phone\nmapping and features input improve the output quality and the latter performs\nbetter, but these effects also depend on the specific language combination. We\nalso compare the recently-proposed Angular Similarity of Phone Frequencies\n(ASPF) with a family tree-based distance measure as a criterion to select\nsource languages in transfer learning. ASPF proves effective if label-based\nphone input is used, while the language distance does not have expected\neffects.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Do_P/0/1/0/all/0/1\">Phat Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coler_M/0/1/0/all/0/1\">Matt Coler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dijkstra_J/0/1/0/all/0/1\">Jelske Dijkstra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klabbers_E/0/1/0/all/0/1\">Esther Klabbers</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sample Attackability in Natural Language Adversarial Attacks. (arXiv:2306.12043v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12043","description":"<p>Adversarial attack research in natural language processing (NLP) has made\nsignificant progress in designing powerful attack methods and defence\napproaches. However, few efforts have sought to identify which source samples\nare the most attackable or robust, i.e. can we determine for an unseen target\nmodel, which samples are the most vulnerable to an adversarial attack. This\nwork formally extends the definition of sample attackability/robustness for NLP\nattacks. Experiments on two popular NLP datasets, four state of the art models\nand four different NLP adversarial attack methods, demonstrate that sample\nuncertainty is insufficient for describing characteristics of attackable/robust\nsamples and hence a deep learning based detector can perform much better at\nidentifying the most attackable and robust samples for an unseen target model.\nNevertheless, further analysis finds that there is little agreement in which\nsamples are considered the most attackable/robust across different NLP attack\nmethods, explaining a lack of portability of attackability detection methods\nacross attack methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raina_V/0/1/0/all/0/1\">Vyas Raina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gales_M/0/1/0/all/0/1\">Mark Gales</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modeling Hierarchical Reasoning Chains by Linking Discourse Units and Key Phrases for Reading Comprehension. (arXiv:2306.12069v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12069","description":"<p>Machine reading comprehension (MRC) poses new challenges over logical\nreasoning, which aims to understand the implicit logical relations entailed in\nthe given contexts and perform inference over them. Due to the complexity of\nlogic, logical relations exist at different granularity levels. However, most\nexisting methods of logical reasoning individually focus on either entity-aware\nor discourse-based information but ignore the hierarchical relations that may\neven have mutual effects. In this paper, we propose a holistic graph network\n(HGN) which deals with context at both discourse level and word level, as the\nbasis for logical reasoning, to provide a more fine-grained relation\nextraction. Specifically, node-level and type-level relations, which can be\ninterpreted as bridges in the reasoning process, are modeled by a hierarchical\ninteraction mechanism to improve the interpretation of MRC systems.\nExperimental results on logical reasoning QA datasets (ReClor and LogiQA) and\nnatural language inference datasets (SNLI and ANLI) show the effectiveness and\ngeneralization of our method, and in-depth analysis verifies its capability to\nunderstand complex logical relations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jialin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Accurate Translation via Semantically Appropriate Application of Lexical Constraints. (arXiv:2306.12089v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12089","description":"<p>Lexically-constrained NMT (LNMT) aims to incorporate user-provided\nterminology into translations. Despite its practical advantages, existing work\nhas not evaluated LNMT models under challenging real-world conditions. In this\npaper, we focus on two important but under-studied issues that lie in the\ncurrent evaluation process of LNMT studies. The model needs to cope with\nchallenging lexical constraints that are \"homographs\" or \"unseen\" during\ntraining. To this end, we first design a homograph disambiguation module to\ndifferentiate the meanings of homographs. Moreover, we propose PLUMCOT, which\nintegrates contextually rich information about unseen lexical constraints from\npre-trained language models and strengthens a copy mechanism of the pointer\nnetwork via direct supervision of a copying score. We also release HOLLY, an\nevaluation benchmark for assessing the ability of a model to cope with\n\"homographic\" and \"unseen\" lexical constraints. Experiments on HOLLY and the\nprevious test setup show the effectiveness of our method. The effects of\nPLUMCOT are shown to be remarkable in \"unseen\" constraints. Our dataset is\navailable at https://github.com/papago-lab/HOLLY-benchmark\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Baek_Y/0/1/0/all/0/1\">Yujin Baek</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Koanho Lee</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Ki_D/0/1/0/all/0/1\">Dayeon Ki</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hyoung-Gyu Lee</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">Cheonbok Park</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1\">Jaegul Choo</a> (1) ((1) KAIST, (2) Korea University, (3) Papago, Naver Corp.)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mass-Producing Failures of Multimodal Systems with Language Models. (arXiv:2306.12105v1 [cs.LG])","link":"http://arxiv.org/abs/2306.12105","description":"<p>Deployed multimodal systems can fail in ways that evaluators did not\nanticipate. In order to find these failures before deployment, we introduce\nMultiMon, a system that automatically identifies systematic failures --\ngeneralizable, natural-language descriptions of patterns of model failures. To\nuncover systematic failures, MultiMon scrapes a corpus for examples of\nerroneous agreement: inputs that produce the same output, but should not. It\nthen prompts a language model (e.g., GPT-4) to find systematic patterns of\nfailure and describe them in natural language. We use MultiMon to find 14\nsystematic failures (e.g., \"ignores quantifiers\") of the CLIP text-encoder,\neach comprising hundreds of distinct inputs (e.g., \"a shelf with a few/many\nbooks\"). Because CLIP is the backbone for most state-of-the-art multimodal\nsystems, these inputs produce failures in Midjourney 5.1, DALL-E, VideoFusion,\nand others. MultiMon can also steer towards failures relevant to specific use\ncases, such as self-driving cars. We see MultiMon as a step towards evaluation\nthat autonomously explores the long tail of potential system failures. Code for\nMULTIMON is available at https://github.com/tsb0601/MultiMon.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tong_S/0/1/0/all/0/1\">Shengbang Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_E/0/1/0/all/0/1\">Erik Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1\">Jacob Steinhardt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Which Spurious Correlations Impact Reasoning in NLI Models? A Visual Interactive Diagnosis through Data-Constrained Counterfactuals. (arXiv:2306.12146v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12146","description":"<p>We present a human-in-the-loop dashboard tailored to diagnosing potential\nspurious features that NLI models rely on for predictions. The dashboard\nenables users to generate diverse and challenging examples by drawing\ninspiration from GPT-3 suggestions. Additionally, users can receive feedback\nfrom a trained NLI model on how challenging the newly created example is and\nmake refinements based on the feedback. Through our investigation, we discover\nseveral categories of spurious correlations that impact the reasoning of NLI\nmodels, which we group into three categories: Semantic Relevance, Logical\nFallacies, and Bias. Based on our findings, we identify and describe various\nresearch opportunities, including diversifying training data and assessing NLI\nmodels' robustness by creating adversarial test suites.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chan_R/0/1/0/all/0/1\">Robin Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1\">Afra Amini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Assady_M/0/1/0/all/0/1\">Mennatallah El-Assady</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mixture Encoder for Joint Speech Separation and Recognition. (arXiv:2306.12173v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12173","description":"<p>Multi-speaker automatic speech recognition (ASR) is crucial for many\nreal-world applications, but it requires dedicated modeling techniques.\nExisting approaches can be divided into modular and end-to-end methods. Modular\napproaches separate speakers and recognize each of them with a single-speaker\nASR system. End-to-end models process overlapped speech directly in a single,\npowerful neural network. This work proposes a middle-ground approach that\nleverages explicit speech separation similarly to the modular approach but also\nincorporates mixture speech information directly into the ASR module in order\nto mitigate the propagation of errors made by the speech separator. We also\nexplore a way to exchange cross-speaker context information through a layer\nthat combines information of the individual speakers. Our system is optimized\nthrough separate and joint training stages and achieves a relative improvement\nof 7% in word error rate over a purely modular setup on the SMS-WSJ task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Berger_S/0/1/0/all/0/1\">Simon Berger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vieting_P/0/1/0/all/0/1\">Peter Vieting</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boeddeker_C/0/1/0/all/0/1\">Christoph Boeddeker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haeb_Umbach_R/0/1/0/all/0/1\">Reinhold Haeb-Umbach</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Feature Interactions Reveal Linguistic Structure in Language Models. (arXiv:2306.12181v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12181","description":"<p>We study feature interactions in the context of feature attribution methods\nfor post-hoc interpretability. In interpretability research, getting to grips\nwith feature interactions is increasingly recognised as an important challenge,\nbecause interacting features are key to the success of neural networks. Feature\ninteractions allow a model to build up hierarchical representations for its\ninput, and might provide an ideal starting point for the investigation into\nlinguistic structure in language models. However, uncovering the exact role\nthat these interactions play is also difficult, and a diverse range of\ninteraction attribution methods has been proposed. In this paper, we focus on\nthe question which of these methods most faithfully reflects the inner workings\nof the target models. We work out a grey box methodology, in which we train\nmodels to perfection on a formal language classification task, using PCFGs. We\nshow that under specific configurations, some methods are indeed able to\nuncover the grammatical rules acquired by a model. Based on these findings we\nextend our evaluation to a case study on language models, providing novel\ninsights into the linguistic structure that these models have acquired.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jumelet_J/0/1/0/all/0/1\">Jaap Jumelet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuidema_W/0/1/0/all/0/1\">Willem Zuidema</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Opening the Black Box: Analyzing Attention Weights and Hidden States in Pre-trained Language Models for Non-language Tasks. (arXiv:2306.12198v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12198","description":"<p>Investigating deep learning language models has always been a significant\nresearch area due to the ``black box\" nature of most advanced models. With the\nrecent advancements in pre-trained language models based on transformers and\ntheir increasing integration into daily life, addressing this issue has become\nmore pressing. In order to achieve an explainable AI model, it is essential to\ncomprehend the procedural steps involved and compare them with human thought\nprocesses. Thus, in this paper, we use simple, well-understood non-language\ntasks to explore these models' inner workings. Specifically, we apply a\npre-trained language model to constrained arithmetic problems with hierarchical\nstructure, to analyze their attention weight scores and hidden states. The\ninvestigation reveals promising results, with the model addressing hierarchical\nproblems in a moderately structured manner, similar to human problem-solving\nstrategies. Additionally, by inspecting the attention weights layer by layer,\nwe uncover an unconventional finding that layer 10, rather than the model's\nfinal layer, is the optimal layer to unfreeze for the least parameter-intensive\napproach to fine-tune the model. We support these findings with entropy\nanalysis and token embeddings similarity analysis. The attention analysis\nallows us to hypothesize that the model can generalize to longer sequences in\nListOps dataset, a conclusion later confirmed through testing on sequences\nlonger than those in the training set. Lastly, by utilizing a straightforward\ntask in which the model predicts the winner of a Tic Tac Toe game, we identify\nlimitations in attention analysis, particularly its inability to capture 2D\npatterns.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ballout_M/0/1/0/all/0/1\">Mohamad Ballout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krumnack_U/0/1/0/all/0/1\">Ulf Krumnack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heidemann_G/0/1/0/all/0/1\">Gunther Heidemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuhnberger_K/0/1/0/all/0/1\">Kai-Uwe K&#xfc;hnberger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating Pre-trained Language Models on Cross-Domain Datasets, a Step Closer to General AI. (arXiv:2306.12205v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12205","description":"<p>Pre-trained language models have recently emerged as a powerful tool for\nfine-tuning a variety of language tasks. Ideally, when models are pre-trained\non large amount of data, they are expected to gain implicit knowledge. In this\npaper, we investigate the ability of pre-trained language models to generalize\nto different non-language tasks. In particular, we test them on tasks from\ndifferent domains such as computer vision, reasoning on hierarchical data, and\nprotein fold prediction. The four pre-trained models that we used, T5, BART,\nBERT, and GPT-2 achieve outstanding results. They all have similar performance\nand they outperform transformers that are trained from scratch by a large\nmargin. For instance, pre-trained language models perform better on the Listops\ndataset, with an average accuracy of 58.7\\%, compared to transformers trained\nfrom scratch, which have an average accuracy of 29.0\\%. The significant\nimprovement demonstrated across three types of datasets suggests that\npre-training on language helps the models to acquire general knowledge,\nbringing us a step closer to general AI. We also showed that reducing the\nnumber of parameters in pre-trained language models does not have a great\nimpact as the performance drops slightly when using T5-Small instead of\nT5-Base. In fact, when using only 2\\% of the parameters, we achieved a great\nimprovement compared to training from scratch. Finally, in contrast to prior\nwork, we find out that using pre-trained embeddings for the input layer is\nnecessary to achieve the desired results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ballout_M/0/1/0/all/0/1\">Mohamad Ballout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krumnack_U/0/1/0/all/0/1\">Ulf Krumnack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heidemann_G/0/1/0/all/0/1\">Gunther Heidemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuhnberger_K/0/1/0/all/0/1\">Kai-Uwe K&#xfc;hnberger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Limits for Learning with Language Models. (arXiv:2306.12213v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12213","description":"<p>With the advent of large language models (LLMs), the trend in NLP has been to\ntrain LLMs on vast amounts of data to solve diverse language understanding and\ngeneration tasks. The list of LLM successes is long and varied. Nevertheless,\nseveral recent papers provide empirical evidence that LLMs fail to capture\nimportant aspects of linguistic meaning. Focusing on universal quantification,\nwe provide a theoretical foundation for these empirical findings by proving\nthat LLMs cannot learn certain fundamental semantic properties including\nsemantic entailment and consistency as they are defined in formal semantics.\nMore generally, we show that LLMs are unable to learn concepts beyond the first\nlevel of the Borel Hierarchy, which imposes severe limits on the ability of\nLMs, both large and small, to capture many aspects of linguistic meaning. This\nmeans that LLMs will continue to operate without formal guarantees on tasks\nthat require entailments and deep linguistic understanding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Asher_N/0/1/0/all/0/1\">Nicholas Asher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhar_S/0/1/0/all/0/1\">Swarnadeep Bhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaturvedi_A/0/1/0/all/0/1\">Akshay Chaturvedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hunter_J/0/1/0/all/0/1\">Julie Hunter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1\">Soumya Paul</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bidirectional End-to-End Learning of Retriever-Reader Paradigm for Entity Linking. (arXiv:2306.12245v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12245","description":"<p>Entity Linking (EL) is a fundamental task for Information Extraction and\nKnowledge Graphs. The general form of EL (i.e., end-to-end EL) aims to first\nfind mentions in the given input document and then link the mentions to\ncorresponding entities in a specific knowledge base. Recently, the paradigm of\nretriever-reader promotes the progress of end-to-end EL, benefiting from the\nadvantages of dense entity retrieval and machine reading comprehension.\nHowever, the existing study only trains the retriever and the reader separately\nin a pipeline manner, which ignores the benefit that the interaction between\nthe retriever and the reader can bring to the task. To advance the\nretriever-reader paradigm to perform more perfectly on end-to-end EL, we\npropose BEER$^2$, a Bidirectional End-to-End training framework for Retriever\nand Reader. Through our designed bidirectional end-to-end training, BEER$^2$\nguides the retriever and the reader to learn from each other, make progress\ntogether, and ultimately improve EL performance. Extensive experiments on\nbenchmarks of multiple domains demonstrate the effectiveness of our proposed\nBEER$^2$.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinghui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xingyu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yangning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pengjun Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hai-Tao Zheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Solving and Generating NPR Sunday Puzzles with Large Language Models. (arXiv:2306.12255v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12255","description":"<p>We explore the ability of large language models to solve and generate puzzles\nfrom the NPR Sunday Puzzle game show using PUZZLEQA, a dataset comprising 15\nyears of on-air puzzles. We evaluate four large language models using PUZZLEQA,\nin both multiple choice and free response formats, and explore two prompt\nengineering techniques to improve free response performance: chain-of-thought\nreasoning and prompt summarization. We find that state-of-the-art large\nlanguage models can solve many PUZZLEQA puzzles: the best model, GPT-3.5,\nachieves 50.2% loose accuracy. However, in our few-shot puzzle generation\nexperiment, we find no evidence that models can generate puzzles: GPT-3.5\ngenerates puzzles with answers that do not conform to the generated rules.\nPuzzle generation remains a challenging task for future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jingmiao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_C/0/1/0/all/0/1\">Carolyn Jane Anderson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SIFTER: A Task-specific Alignment Strategy for Enhancing Sentence Embeddings. (arXiv:2306.12280v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12280","description":"<p>The paradigm of pre-training followed by fine-tuning on downstream tasks has\nbecome the mainstream method in natural language processing tasks. Although\npre-trained models have the advantage of generalization, their performance may\nstill vary significantly across different domain tasks. This is because the\ndata distribution in different domains varies. For example, the different parts\nof the sentence 'He married Smt. Dipali Ghosh in 1947 and led a very happy\nmarried life' may have different impact for downstream tasks. For similarity\ncalculations, words such as 'led' and 'life' are more important. On the other\nhand, for sentiment analysis, the word 'happy' is crucial. This indicates that\ndifferent downstream tasks have different levels of sensitivity to sentence\ncomponents. Our starting point is to scale information of the model and data\naccording to the specifics of downstream tasks, enhancing domain information of\nrelevant parts for these tasks and reducing irrelevant elements for different\ndomain tasks, called SIFTER. In the experimental part, we use the SIFTER to\nimprove SimCSE by constructing positive sample pairs based on enhancing the\nsentence stem and reducing the unimportant components in the sentence, and\nmaximize the similarity between three sentences. Similarly, SIFTER can improve\nthe gate mechanism of the LSTM model by short-circuiting the input gate of\nimportant words so that the LSTM model remembers the important parts of the\nsentence. Our experiments demonstrate that SIFTER outperforms the SimCSE and\nLSTM baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenhao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chaoming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+zhai_Q/0/1/0/all/0/1\">Qiuhong zhai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Medical ministrations through web scraping. (arXiv:2306.12310v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12310","description":"<p>Web scraping is a technique that allows us to extract data from websites\nautomatically. in the field of medicine, web scraping can be used to collect\ninformation about medical procedures, treatments, and healthcare providers.\nthis information can be used to improve patient care, monitor the quality of\nhealthcare services, and identify areas for improvement. one area where web\nscraping can be particularly useful is in medical ministrations. medical\nministrations are the actions taken to provide medical care to patients, and\nweb scraping can help healthcare providers identify the most effective\nministrations for their patients. for example, healthcare providers can use web\nscraping to collect data about the symptoms and medical histories of their\npatients, and then use this information to determine the most appropriate\nministrations. they can also use web scraping to gather information about the\nlatest medical research and clinical trials, which can help them stay\nup-to-date with the latest treatments and procedures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sabesan_N/0/1/0/all/0/1\">Niketha Sabesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nivethitha/0/1/0/all/0/1\">Nivethitha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shreyah_J/0/1/0/all/0/1\">J.N Shreyah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+J_P/0/1/0/all/0/1\">Pranauv A J</a>, <a href=\"http://arxiv.org/find/cs/1/au:+R_S/0/1/0/all/0/1\">Shyam R</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Iterated Piecewise Affine (IPA) Approximation for Language Modeling. (arXiv:2306.12317v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12317","description":"<p>In this work, we demonstrate the application of a simple first-order Taylor\nexpansion to approximate a generic function $F: R^{n \\times m} \\to R^{n \\times\nm}$ and utilize it in language modeling. To enhance the basic Taylor expansion,\nwe introduce iteration and piecewise modeling, leading us to name the algorithm\nthe Iterative Piecewise Affine (IPA) approximation. The final algorithm\nexhibits interesting resemblances to the Transformers decoder architecture. By\ncomparing parameter arrangements in IPA and Transformers, we observe a\nstrikingly similar performance, with IPA outperforming Transformers by 1.5\\% in\nthe next token prediction task with cross-entropy loss for smaller sequence\nlengths.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shamsi_D/0/1/0/all/0/1\">Davood Shamsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wen-yu Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_B/0/1/0/all/0/1\">Brian Williams</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Solving Dialogue Grounding Embodied Task in a Simulated Environment using Further Masked Language Modeling. (arXiv:2306.12387v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12387","description":"<p>Enhancing AI systems with efficient communication skills that align with\nhuman understanding is crucial for their effective assistance to human users.\nProactive initiatives from the system side are needed to discern specific\ncircumstances and interact aptly with users to solve these scenarios. In this\nresearch, we opt for a collective building assignment taken from the Minecraft\ndataset. Our proposed method employs language modeling to enhance task\nunderstanding through state-of-the-art (SOTA) methods using language models.\nThese models focus on grounding multi-modal understandinging and task-oriented\ndialogue comprehension tasks. This focus aids in gaining insights into how well\nthese models interpret and respond to a variety of inputs and tasks. Our\nexperimental results provide compelling evidence of the superiority of our\nproposed method. This showcases a substantial improvement and points towards a\npromising direction for future research in this domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weijie Jack Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. (arXiv:2306.12420v1 [cs.CL])","link":"http://arxiv.org/abs/2306.12420","description":"<p>Large foundation models have demonstrated a great ability to achieve general\nhuman-level intelligence far beyond traditional approaches. As the technique\nkeeps attracting attention from the AI community, more and more large\nfoundation models have become publically available. However, most of those\nmodels exhibit a major deficiency in specialized-task applications, where the\nstep of finetuning is still required for obtaining satisfactory performance. As\nthe number of available models and specialized tasks keeps growing, the job of\ngeneral finetuning becomes highly nontrivial. In this paper, we take the first\nstep to address this issue. We introduce an extensible and lightweight toolkit,\nLMFlow, which aims to simplify the finetuning and inference of general large\nfoundation models. LMFlow offers a complete finetuning workflow for a large\nfoundation model to support personalized training with limited computing\nresources. Furthermore, it supports continuous pretraining, instruction tuning,\nparameter-efficient finetuning, alignment tuning, and large model inference,\nalong with carefully designed and extensible APIs. This toolkit has been\nthoroughly tested and is available at https://github.com/OptimalScale/LMFlow.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Diao_S/0/1/0/all/0/1\">Shizhe Diao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_R/0/1/0/all/0/1\">Rui Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hanze Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shum_K/0/1/0/all/0/1\">Ka Shun Shum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_W/0/1/0/all/0/1\">Wei Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tong Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VisoGender: A dataset for benchmarking gender bias in image-text pronoun resolution. (arXiv:2306.12424v1 [cs.CV])","link":"http://arxiv.org/abs/2306.12424","description":"<p>We introduce VisoGender, a novel dataset for benchmarking gender bias in\nvision-language models. We focus on occupation-related gender biases, inspired\nby Winograd and Winogender schemas, where each image is associated with a\ncaption containing a pronoun relationship of subjects and objects in the scene.\nVisoGender is balanced by gender representation in professional roles,\nsupporting bias evaluation in two ways: i) resolution bias, where we evaluate\nthe difference between gender resolution accuracies for men and women and ii)\nretrieval bias, where we compare ratios of male and female professionals\nretrieved for a gender-neutral search query. We benchmark several\nstate-of-the-art vision-language models and find that they lack the reasoning\nabilities to correctly resolve gender in complex scenes. While the direction\nand magnitude of gender bias depends on the task and the model being evaluated,\ncaptioning models generally are more accurate and less biased than CLIP-like\nmodels. Dataset and code are available at https://github.com/oxai/visogender\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hall_S/0/1/0/all/0/1\">Siobhan Mackenzie Hall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abrantes_F/0/1/0/all/0/1\">Fernanda Gon&#xe7;alves Abrantes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hanwen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sodunke_G/0/1/0/all/0/1\">Grace Sodunke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shtedritski_A/0/1/0/all/0/1\">Aleksandar Shtedritski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirk_H/0/1/0/all/0/1\">Hannah Rose Kirk</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Peekaboo: Text to Image Diffusion Models are Zero-Shot Segmentors. (arXiv:2211.13224v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2211.13224","description":"<p>Recently, text-to-image diffusion models have shown remarkable capabilities\nin creating realistic images from natural language prompts. However, few works\nhave explored using these models for semantic localization or grounding. In\nthis work, we explore how an off-the-shelf text-to-image diffusion model,\ntrained without exposure to localization information, can ground various\nsemantic phrases without segmentation-specific re-training. We introduce an\ninference time optimization process capable of generating segmentation masks\nconditioned on natural language prompts. Our proposal, Peekaboo, is a\nfirst-of-its-kind zero-shot, open-vocabulary, unsupervised semantic grounding\ntechnique leveraging diffusion models without any training. We evaluate\nPeekaboo on the Pascal VOC dataset for unsupervised semantic segmentation and\nthe RefCOCO dataset for referring segmentation, showing results competitive\nwith promising results. We also demonstrate how Peekaboo can be used to\ngenerate images with transparency, even though the underlying diffusion model\nwas only trained on RGB images - which to our knowledge we are the first to\nattempt. Please see our project page, including our code:\nhttps://ryanndagreat.github.io/peekaboo\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Burgert_R/0/1/0/all/0/1\">Ryan Burgert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_K/0/1/0/all/0/1\">Kanchana Ranasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryoo_M/0/1/0/all/0/1\">Michael S. Ryoo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VRDU: A Benchmark for Visually-rich Document Understanding. (arXiv:2211.15421v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.15421","description":"<p>Understanding visually-rich business documents to extract structured data and\nautomate business workflows has been receiving attention both in academia and\nindustry. Although recent multi-modal language models have achieved impressive\nresults, we find that existing benchmarks do not reflect the complexity of real\ndocuments seen in industry. In this work, we identify the desiderata for a more\ncomprehensive benchmark and propose one we call Visually Rich Document\nUnderstanding (VRDU). VRDU contains two datasets that represent several\nchallenges: rich schema including diverse data types as well as hierarchical\nentities, complex templates including tables and multi-column layouts, and\ndiversity of different layouts (templates) within a single document type. We\ndesign few-shot and conventional experiment settings along with a carefully\ndesigned matching algorithm to evaluate extraction results. We report the\nperformance of strong baselines and offer three observations: (1) generalizing\nto new document templates is still very challenging, (2) few-shot performance\nhas a lot of headroom, and (3) models struggle with hierarchical fields such as\nline-items in an invoice. We plan to open source the benchmark and the\nevaluation toolkit. We hope this helps the community make progress on these\nchallenging tasks in extracting structured data from visually rich documents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zilong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yichao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chen-Yu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tata_S/0/1/0/all/0/1\">Sandeep Tata</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Design and analysis of tweet-based election models for the 2021 Mexican legislative election. (arXiv:2301.00626v2 [cs.SI] UPDATED)","link":"http://arxiv.org/abs/2301.00626","description":"<p>Modelling and forecasting real-life human behaviour using online social media\nis an active endeavour of interest in politics, government, academia, and\nindustry. Since its creation in 2006, Twitter has been proposed as a potential\nlaboratory that could be used to gauge and predict social behaviour. During the\nlast decade, the user base of Twitter has been growing and becoming more\nrepresentative of the general population. Here we analyse this user base in the\ncontext of the 2021 Mexican Legislative Election. To do so, we use a dataset of\n15 million election-related tweets in the six months preceding election day. We\nexplore different election models that assign political preference to either\nthe ruling parties or the opposition. We find that models using data with\ngeographical attributes determine the results of the election with better\nprecision and accuracy than conventional polling methods. These results\ndemonstrate that analysis of public online data can outperform conventional\npolling methods, and that political analysis and general forecasting would\nlikely benefit from incorporating such data in the immediate future. Moreover,\nthe same Twitter dataset with geographical attributes is positively correlated\nwith results from official census data on population and internet usage in\nMexico. These findings suggest that we have reached a period in time when\nonline activity, appropriately curated, can provide an accurate representation\nof offline behaviour.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vigna_Gomez_A/0/1/0/all/0/1\">Alejandro Vigna-G&#xf3;mez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murillo_J/0/1/0/all/0/1\">Javier Murillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramirez_M/0/1/0/all/0/1\">Manelik Ramirez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borbolla_A/0/1/0/all/0/1\">Alberto Borbolla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marquez_I/0/1/0/all/0/1\">Ian M&#xe1;rquez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_P/0/1/0/all/0/1\">Prasun K. Ray</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PATCorrect: Non-autoregressive Phoneme-augmented Transformer for ASR Error Correction. (arXiv:2302.05040v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.05040","description":"<p>Speech-to-text errors made by automatic speech recognition (ASR) systems\nnegatively impact downstream models. Error correction models as a\npost-processing text editing method have been recently developed for refining\nthe ASR outputs. However, efficient models that meet the low latency\nrequirements of industrial grade production systems have not been well studied.\nWe propose PATCorrect-a novel non-autoregressive (NAR) approach based on\nmulti-modal fusion leveraging representations from both text and phoneme\nmodalities, to reduce word error rate (WER) and perform robustly with varying\ninput transcription quality. We demonstrate that PATCorrect consistently\noutperforms state-of-the-art NAR method on English corpus across different\nupstream ASR systems, with an overall 11.62% WER reduction (WERR) compared to\n9.46% WERR achieved by other methods using text only modality. Besides, its\ninference latency is at tens of milliseconds, making it ideal for systems with\nlow latency requirements.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhehui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamma_R/0/1/0/all/0/1\">Rajesh Kamma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eswaran_S/0/1/0/all/0/1\">Sharanya Eswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadagopan_N/0/1/0/all/0/1\">Narayanan Sadagopan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Geotechnical Parrot Tales (GPT): Harnessing Large Language Models in geotechnical engineering. (arXiv:2304.02138v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.02138","description":"<p>The widespread adoption of large language models (LLMs), such as OpenAI's\nChatGPT, could revolutionize various industries, including geotechnical\nengineering. However, GPT models can sometimes generate plausible-sounding but\nfalse outputs, leading to hallucinations. In this article, we discuss the\nimportance of prompt engineering in mitigating these risks and harnessing the\nfull potential of GPT for geotechnical applications. We explore the challenges\nand pitfalls associated with LLMs and highlight the role of context in ensuring\naccurate and valuable responses. Furthermore, we examine the development of\ncontext-specific search engines and the potential of LLMs to become a natural\ninterface for complex tasks, such as data analysis and design. We also develop\na unified interface using natural language to handle complex geotechnical\nengineering tasks and data analysis. By integrating GPT into geotechnical\nengineering workflows, professionals can streamline their work and develop\nsustainable and resilient infrastructure systems for the future.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_K/0/1/0/all/0/1\">Krishna Kumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multimodal Sentiment Analysis: A Survey. (arXiv:2305.07611v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07611","description":"<p>Multimodal sentiment analysis has become an important research area in the\nfield of artificial intelligence. With the latest advances in deep learning,\nthis technology has reached new heights. It has great potential for both\napplication and research, making it a popular research topic. This review\nprovides an overview of the definition, background, and development of\nmultimodal sentiment analysis. It also covers recent datasets and advanced\nmodels, emphasizing the challenges and future prospects of this technology.\nFinally, it looks ahead to future research directions. It should be noted that\nthis review provides constructive suggestions for promising research directions\nand building better performing multimodal sentiment analysis models, which can\nhelp researchers in this field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lai_S/0/1/0/all/0/1\">Songning Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haoxuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xifeng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1\">Zhaoxia Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhi Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing. (arXiv:2305.09770v3 [cs.HC] UPDATED)","link":"http://arxiv.org/abs/2305.09770","description":"<p>Despite a surge collection of XAI methods, users still struggle to obtain\nrequired AI explanations. Previous research suggests chatbots as dynamic\nsolutions, but the effective design of conversational XAI agents for practical\nhuman needs remains under-explored. This paper focuses on Conversational XAI\nfor AI-assisted scientific writing tasks. Drawing from human linguistic\ntheories and formative studies, we identify four design rationales:\n\"multifaceted\", \"controllability\", \"mix-initiative\", \"context-aware\ndrill-down\". We incorporate them into an interactive prototype, ConvXAI, which\nfacilitates heterogeneous AI explanations for scientific writing through\ndialogue. In two studies with 21 users, ConvXAI outperforms a GUI-based\nbaseline on improving human-perceived understanding and writing improvement.\nThe paper further discusses the practical human usage patterns in interacting\nwith ConvXAI for scientific co-writing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Hua Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chieh-Yang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tongshuang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1\">Ting-Hao &#x27;Kenneth&#x27; Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Controlling Learned Effects to Reduce Spurious Correlations in Text Classifiers. (arXiv:2305.16863v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.16863","description":"<p>To address the problem of NLP classifiers learning spurious correlations\nbetween training features and target labels, a common approach is to make the\nmodel's predictions invariant to these features. However, this can be\ncounter-productive when the features have a non-zero causal effect on the\ntarget label and thus are important for prediction. Therefore, using methods\nfrom the causal inference literature, we propose an algorithm to regularize the\nlearnt effect of the features on the model's prediction to the estimated effect\nof feature on label. This results in an automated augmentation method that\nleverages the estimated effect of a feature to appropriately change the labels\nfor new augmented inputs. On toxicity and IMDB review datasets, the proposed\nalgorithm minimises spurious correlations and improves the minority group\n(i.e., samples breaking spurious correlations) accuracy, while also improving\nthe total accuracy compared to standard training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bansal_P/0/1/0/all/0/1\">Parikshit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Amit Sharma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OpenPI-C: A Better Benchmark and Stronger Baseline for Open-Vocabulary State Tracking. (arXiv:2306.00887v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.00887","description":"<p>Open-vocabulary state tracking is a more practical version of state tracking\nthat aims to track state changes of entities throughout a process without\nrestricting the state space and entity space. OpenPI is to date the only\ndataset annotated for open-vocabulary state tracking. However, we identify\nissues with the dataset quality and evaluation metric. For the dataset, we\ncategorize 3 types of problems on the procedure level, step level and state\nchange level respectively, and build a clean dataset OpenPI-C using multiple\nrounds of human judgment. For the evaluation metric, we propose a cluster-based\nmetric to fix the original metric's preference for repetition.\n</p>\n<p>Model-wise, we enhance the seq2seq generation baseline by reinstating two key\nproperties for state tracking: temporal dependency and entity awareness. The\nstate of the world after an action is inherently dependent on the previous\nstate. We model this dependency through a dynamic memory bank and allow the\nmodel to attend to the memory slots during decoding. On the other hand, the\nstate of the world is naturally a union of the states of involved entities.\nSince the entities are unknown in the open-vocabulary setting, we propose a\ntwo-stage model that refines the state change prediction conditioned on\nentities predicted from the first stage. Empirical results show the\neffectiveness of our proposed model especially on the cluster-based metric. The\ncode and data are released at https://github.com/shirley-wu/openpi-c\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xueqing Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sha Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WHAT, WHEN, and HOW to Ground: Designing User Persona-Aware Conversational Agents for Engaging Dialogue. (arXiv:2306.03361v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.03361","description":"<p>This paper presents a method for building a personalized open-domain dialogue\nsystem to address the $\\textit{WWH}$ ($\\textit{WHAT}$, $\\textit{WHEN}$, and\n$\\textit{HOW}$) problem for natural response generation in a commercial\nsetting, where personalized dialogue responses are heavily interleaved with\ncasual response turns. The proposed approach involves weighted dataset\nblending, negative persona information augmentation methods, and the design of\npersonalized conversation datasets to address the challenges of $\\textit{WWH}$\nin personalized, open-domain dialogue systems. Our work effectively balances\ndialogue fluency and tendency to ground, while also introducing a response-type\nlabel to improve the controllability and explainability of the grounded\nresponses. The combination of these methods leads to more fluent conversations,\nas evidenced by subjective human evaluations as well as objective evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kwon_D/0/1/0/all/0/1\">Deuksin Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sunwoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Ki Hyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seojin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taeyoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_E/0/1/0/all/0/1\">Eric Davis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can ChatGPT pass the Vietnamese National High School Graduation Examination?. (arXiv:2306.09170v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.09170","description":"<p>This research article highlights the potential of AI-powered chatbots in\neducation and presents the results of using ChatGPT, a large language model, to\ncomplete the Vietnamese National High School Graduation Examination (VNHSGE).\nThe study dataset included 30 essays in the literature test case and 1,700\nmultiple-choice questions designed for other subjects. The results showed that\nChatGPT was able to pass the examination with an average score of 6-7,\ndemonstrating the technology's potential to revolutionize the educational\nlandscape. The analysis of ChatGPT performance revealed its proficiency in a\nrange of subjects, including mathematics, English, physics, chemistry, biology,\nhistory, geography, civic education, and literature, which suggests its\npotential to provide effective support for learners. However, further research\nis needed to assess ChatGPT performance on more complex exam questions and its\npotential to support learners in different contexts. As technology continues to\nevolve and improve, we can expect to see the use of AI tools like ChatGPT\nbecome increasingly common in educational settings, ultimately enhancing the\neducational experience for both students and educators.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dao_X/0/1/0/all/0/1\">Xuan-Quy Dao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1\">Ngoc-Bich Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phan_X/0/1/0/all/0/1\">Xuan-Dung Phan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ngo_B/0/1/0/all/0/1\">Bac-Bien Ngo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BayLing: Bridging Cross-lingual Alignment and Instruction Following through Interactive Translation for Large Language Models. (arXiv:2306.10968v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.10968","description":"<p>Large language models (LLMs) have demonstrated remarkable prowess in language\nunderstanding and generation. Advancing from foundation LLMs to\ninstructionfollowing LLMs, instruction tuning plays a vital role in aligning\nLLMs to human preferences. However, the existing LLMs are usually focused on\nEnglish, leading to inferior performance in non-English languages. In order to\nimprove the performance for non-English languages, it is necessary to collect\nlanguage-specific training data for foundation LLMs and construct\nlanguage-specific instructions for instruction tuning, both of which are heavy\nloads. To minimize human workload, we propose to transfer the capabilities of\nlanguage generation and instruction following from English to other languages\nthrough an interactive translation task. We have developed BayLing, an\ninstruction-following LLM by utilizing LLaMA as the foundation LLM and\nautomatically constructing interactive translation instructions for instructing\ntuning. Extensive assessments demonstrate that BayLing achieves comparable\nperformance to GPT-3.5-turbo, despite utilizing a considerably smaller\nparameter size of only 13 billion. Experimental results on translation tasks\nshow that BayLing achieves 95% of single-turn translation capability compared\nto GPT-4 with automatic evaluation and 96% of interactive translation\ncapability compared to GPT-3.5-turbo with human evaluation. To estimate the\nperformance on general tasks, we created a multi-turn instruction test set\ncalled BayLing-80. The experimental results on BayLing-80 indicate that BayLing\nachieves 89% of performance compared to GPT-3.5-turbo. BayLing also\ndemonstrates outstanding performance on knowledge assessment of Chinese GaoKao\nand English SAT, second only to GPT-3.5-turbo among a multitude of\ninstruction-following LLMs. Demo, homepage, code and models of BayLing are\navailable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaolei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Q/0/1/0/all/0/1\">Qingkai Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuocheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhengrui Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Langlin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bu_M/0/1/0/all/0/1\">Mengyu Bu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_S/0/1/0/all/0/1\">Shangtong Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunji Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xilin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-Tuning Language Models for Scientific Writing Support. (arXiv:2306.10974v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.10974","description":"<p>We support scientific writers in determining whether a written sentence is\nscientific, to which section it belongs, and suggest paraphrasings to improve\nthe sentence. Firstly, we propose a regression model trained on a corpus of\nscientific sentences extracted from peer-reviewed scientific papers and\nnon-scientific text to assign a score that indicates the scientificness of a\nsentence. We investigate the effect of equations and citations on this score to\ntest the model for potential biases. Secondly, we create a mapping of section\ntitles to a standard paper layout in AI and machine learning to classify a\nsentence to its most likely section. We study the impact of context, i.e.,\nsurrounding sentences, on the section classification performance. Finally, we\npropose a paraphraser, which suggests an alternative for a given sentence that\nincludes word substitutions, additions to the sentence, and structural changes\nto improve the writing style. We train various large language models on\nsentences extracted from arXiv papers that were peer reviewed and published at\nA*, A, B, and C ranked conferences. On the scientificness task, all models\nachieve an MSE smaller than $2\\%$. For the section classification, BERT\noutperforms WideMLP and SciBERT in most cases. We demonstrate that using\ncontext enhances the classification of a sentence, achieving up to a $90\\%$\nF1-score. Although the paraphrasing models make comparatively few alterations,\nthey produce output sentences close to the gold standard. Large fine-tuned\nmodels such as T5 Large perform best in experiments considering various\nmeasures of difference between input sentence and gold standard. Code is\nprovided under https://github.com/JustinMuecke/SciSen.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mucke_J/0/1/0/all/0/1\">Justin M&#xfc;cke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waldow_D/0/1/0/all/0/1\">Daria Waldow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metzger_L/0/1/0/all/0/1\">Luise Metzger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schauz_P/0/1/0/all/0/1\">Philipp Schauz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffman_M/0/1/0/all/0/1\">Marcel Hoffman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lell_N/0/1/0/all/0/1\">Nicolas Lell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherp_A/0/1/0/all/0/1\">Ansgar Scherp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adversarial Robustness of Prompt-based Few-Shot Learning for Natural Language Understanding. (arXiv:2306.11066v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.11066","description":"<p>State-of-the-art few-shot learning (FSL) methods leverage prompt-based\nfine-tuning to obtain remarkable results for natural language understanding\n(NLU) tasks. While much of the prior FSL methods focus on improving downstream\ntask performance, there is a limited understanding of the adversarial\nrobustness of such methods. In this work, we conduct an extensive study of\nseveral state-of-the-art FSL methods to assess their robustness to adversarial\nperturbations. To better understand the impact of various factors towards\nrobustness (or the lack of it), we evaluate prompt-based FSL methods against\nfully fine-tuned models for aspects such as the use of unlabeled data, multiple\nprompts, number of few-shot examples, model size and type. Our results on six\nGLUE tasks indicate that compared to fully fine-tuned models, vanilla FSL\nmethods lead to a notable relative drop in task performance (i.e., are less\nrobust) in the face of adversarial perturbations. However, using (i) unlabeled\ndata for prompt-based FSL and (ii) multiple prompts flip the trend. We further\ndemonstrate that increasing the number of few-shot examples and model size lead\nto increased adversarial robustness of vanilla FSL methods. Broadly, our work\nsheds light on the adversarial robustness evaluation of prompt-based FSL\nmethods for NLU tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nookala_V/0/1/0/all/0/1\">Venkata Prabhakara Sarath Nookala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_G/0/1/0/all/0/1\">Gaurav Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Subhabrata Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Srijan Kumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visually grounded few-shot word learning in low-resource settings. (arXiv:2306.11371v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2306.11371","description":"<p>We propose a visually grounded speech model that learns new words and their\nvisual depictions from just a few word-image example pairs. Given a set of test\nimages and a spoken query, we ask the model which image depicts the query word.\nPrevious work has simplified this few-shot learning problem by either using an\nartificial setting with digit word-image pairs or by using a large number of\nexamples per class. Moreover, all previous studies were performed using English\nspeech-image data. We propose an approach that can work on natural word-image\npairs but with less examples, i.e. fewer shots, and then illustrate how this\napproach can be applied for multimodal few-shot learning in a real low-resource\nlanguage, Yoruba. Our approach involves using the given word-image example\npairs to mine new unsupervised word-image training pairs from large collections\nof unlabelledspeech and images. Additionally, we use a word-to-image attention\nmechanism to determine word-image similarity. With this new model, we achieve\nbetter performance with fewer shots than previous approaches on an existing\nEnglish benchmark. Many of the model's mistakes are due to confusion between\nvisual concepts co-occurring in similar contexts. The experiments on Yoruba\nshow the benefit of transferring knowledge from a multimodal model trained on a\nlarger set of English speech-image data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Nortje_L/0/1/0/all/0/1\">Leanne Nortje</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Oneata_D/0/1/0/all/0/1\">Dan Oneata</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kamper_H/0/1/0/all/0/1\">Herman Kamper</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-06-21T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/"}}]}]}