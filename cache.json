{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2024-01-15T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"End to end Hindi to English speech conversion using Bark, mBART and a finetuned XLSR Wav2Vec2. (arXiv:2401.06183v1 [eess.AS])","link":"http://arxiv.org/abs/2401.06183","description":"<p>Speech has long been a barrier to effective communication and connection,\npersisting as a challenge in our increasingly interconnected world. This\nresearch paper introduces a transformative solution to this persistent obstacle\nan end-to-end speech conversion framework tailored for Hindi-to-English\ntranslation, culminating in the synthesis of English audio. By integrating\ncutting-edge technologies such as XLSR Wav2Vec2 for automatic speech\nrecognition (ASR), mBART for neural machine translation (NMT), and a\nText-to-Speech (TTS) synthesis component, this framework offers a unified and\nseamless approach to cross-lingual communication. We delve into the intricate\ndetails of each component, elucidating their individual contributions and\nexploring the synergies that enable a fluid transition from spoken Hindi to\nsynthesized English audio.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Tathe_A/0/1/0/all/0/1\">Aniket Tathe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kamble_A/0/1/0/all/0/1\">Anand Kamble</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kumbharkar_S/0/1/0/all/0/1\">Suyash Kumbharkar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bhandare_A/0/1/0/all/0/1\">Atharva Bhandare</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mitra_A/0/1/0/all/0/1\">Anirban C. Mitra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CrisisKAN: Knowledge-infused and Explainable Multimodal Attention Network for Crisis Event Classification. (arXiv:2401.06194v1 [cs.LG])","link":"http://arxiv.org/abs/2401.06194","description":"<p>Pervasive use of social media has become the emerging source for real-time\ninformation (like images, text, or both) to identify various events. Despite\nthe rapid growth of image and text-based event classification, the\nstate-of-the-art (SOTA) models find it challenging to bridge the semantic gap\nbetween features of image and text modalities due to inconsistent encoding.\nAlso, the black-box nature of models fails to explain the model's outcomes for\nbuilding trust in high-stakes situations such as disasters, pandemic.\nAdditionally, the word limit imposed on social media posts can potentially\nintroduce bias towards specific events. To address these issues, we proposed\nCrisisKAN, a novel Knowledge-infused and Explainable Multimodal Attention\nNetwork that entails images and texts in conjunction with external knowledge\nfrom Wikipedia to classify crisis events. To enrich the context-specific\nunderstanding of textual information, we integrated Wikipedia knowledge using\nproposed wiki extraction algorithm. Along with this, a guided cross-attention\nmodule is implemented to fill the semantic gap in integrating visual and\ntextual data. In order to ensure reliability, we employ a model-specific\napproach called Gradient-weighted Class Activation Mapping (Grad-CAM) that\nprovides a robust explanation of the predictions of the proposed model. The\ncomprehensive experiments conducted on the CrisisMMD dataset yield in-depth\nanalysis across various crisis-specific tasks and settings. As a result,\nCrisisKAN outperforms existing SOTA methodologies and provides a novel view in\nthe domain of explainable multimodal event classification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Shubham Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saini_N/0/1/0/all/0/1\">Nandini Saini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kundu_S/0/1/0/all/0/1\">Suman Kundu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1\">Debasis Das</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction. (arXiv:2401.06201v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06201","description":"<p>To address intricate real-world tasks, there has been a rising interest in\ntool utilization in applications of large language models (LLMs). To develop\nLLM-based agents, it usually requires LLMs to understand many tool functions\nfrom different tool documentation. But these documentations could be diverse,\nredundant or incomplete, which immensely affects the capability of LLMs in\nusing tools. To solve this, we introduce EASYTOOL, a framework transforming\ndiverse and lengthy tool documentation into a unified and concise tool\ninstruction for easier tool usage. EasyTool purifies essential information from\nextensive tool documentation of different sources, and elaborates a unified\ninterface (i.e., tool instruction) to offer standardized tool descriptions and\nfunctionalities for LLM-based agents. Extensive experiments on multiple\ndifferent tasks demonstrate that EasyTool can significantly reduce token\nconsumption and improve the performance of tool utilization in real-world\nscenarios. Our code will be available at\n\\url{https://github.com/microsoft/JARVIS/} in the future.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1\">Siyu Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kaitao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiangjie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yongliang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_R/0/1/0/all/0/1\">Ren Kan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Deqing Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Unsupervised Semantic Document Representation for Fine-grained Aspect-based Sentiment Analysis. (arXiv:2401.06210v1 [cs.LG])","link":"http://arxiv.org/abs/2401.06210","description":"<p>Document representation is the core of many NLP tasks on machine\nunderstanding. A general representation learned in an unsupervised manner\nreserves generality and can be used for various applications. In practice,\nsentiment analysis (SA) has been a challenging task that is regarded to be\ndeeply semantic-related and is often used to assess general representations.\nExisting methods on unsupervised document representation learning can be\nseparated into two families: sequential ones, which explicitly take the\nordering of words into consideration, and non-sequential ones, which do not\nexplicitly do so. However, both of them suffer from their own weaknesses. In\nthis paper, we propose a model that overcomes difficulties encountered by both\nfamilies of methods. Experiments show that our model outperforms\nstate-of-the-art methods on popular SA datasets and a fine-grained aspect-based\nSA by a large margin.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1\">Hao-Ming Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Pu-Jen Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LEGOBench: Leaderboard Generation Benchmark for Scientific Models. (arXiv:2401.06233v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06233","description":"<p>The ever-increasing volume of paper submissions makes it difficult to stay\ninformed about the latest state-of-the-art research. To address this challenge,\nwe introduce LEGOBench, a benchmark for evaluating systems that generate\nleaderboards. LEGOBench is curated from 22 years of preprint submission data in\narXiv and more than 11,000 machine learning leaderboards in the PapersWithCode\nportal. We evaluate the performance of four traditional graph-based ranking\nvariants and three recently proposed large language models. Our preliminary\nresults show significant performance gaps in automatic leaderboard generation.\nThe code is available on https://github.com/lingo-iitgn/LEGOBench and the\ndataset is hosted on\nhttps://osf.io/9v2py/?view_only=6f91b0b510df498ba01595f8f278f94c .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Shruti Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_S/0/1/0/all/0/1\">Shoaib Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Mayank Singh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Misconfidence-based Demonstration Selection for LLM In-Context Learning. (arXiv:2401.06301v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06301","description":"<p>In-context learning with large language models (LLMs) excels at adapting to\nvarious tasks rapidly. However, its success hinges on carefully selecting\ndemonstrations, which remains an obstacle in practice. Current approaches to\nthis problem either rely on hard-to-acquire external supervision or require\nfrequent interactions with LLMs, resulting in high costs. We propose a new\nmethod called In-Context Reflection (ICR) to overcome these challenges. ICR\nstrategically selects demonstrations to reduce the discrepancy between the\nLLM's outputs and the actual input-output mappings. Specifically, ICR starts\nwith a random set of initial demonstrations, then iteratively refines it. In\neach step, it analyzes a pool of candidate examples and identifies the ones\nmost likely to challenge the LLM's current understanding, measured by a new\nmetric called misconfidence. These most confusing examples are then selected to\nreplace the less informative demonstrations in the current set. Our\ncomprehensive evaluation across five diverse datasets encompassing 13 subtasks\nshows the efficacy of ICR. Compared to existing methods, ICR achieves an\naverage performance boost of 4%, while demonstrating remarkable cross-task\ngeneralization capabilities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shangqing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a> (Georgia Institute of Technology)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond the Surface: A Global-Scale Analysis of Visual Stereotypes in Text-to-Image Generation. (arXiv:2401.06310v1 [cs.CV])","link":"http://arxiv.org/abs/2401.06310","description":"<p>Recent studies have highlighted the issue of stereotypical depictions for\npeople of different identity groups in Text-to-Image (T2I) model generations.\nHowever, these existing approaches have several key limitations, including a\nnoticeable lack of coverage of global identity groups in their evaluation, and\nthe range of their associated stereotypes. Additionally, they often lack a\ncritical distinction between inherently visual stereotypes, such as\n`underweight' or `sombrero', and culturally dependent stereotypes like\n`attractive' or `terrorist'. In this work, we address these limitations with a\nmultifaceted approach that leverages existing textual resources to ground our\nevaluation of geo-cultural stereotypes in the generated images from T2I models.\nWe employ existing stereotype benchmarks to identify and evaluate visual\nstereotypes at a global scale, spanning 135 nationality-based identity groups.\nWe demonstrate that stereotypical attributes are thrice as likely to be present\nin images of these identities as compared to other attributes. We further\ninvestigate how disparately offensive the depictions of generated images are\nfor different nationalities. Finally, through a detailed case study, we reveal\nhow the 'default' representations of all identity groups have a stereotypical\nappearance. Moreover, for the Global South, images across different attributes\nare visually similar, even when explicitly prompted otherwise. CONTENT WARNING:\nSome examples may contain offensive stereotypes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jha_A/0/1/0/all/0/1\">Akshita Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prabhakaran_V/0/1/0/all/0/1\">Vinodkumar Prabhakaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denton_R/0/1/0/all/0/1\">Remi Denton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laszlo_S/0/1/0/all/0/1\">Sarah Laszlo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dave_S/0/1/0/all/0/1\">Shachi Dave</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qadri_R/0/1/0/all/0/1\">Rida Qadri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1\">Chandan K. Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dev_S/0/1/0/all/0/1\">Sunipa Dev</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-shot Generative Large Language Models for Systematic Review Screening Automation. (arXiv:2401.06320v1 [cs.IR])","link":"http://arxiv.org/abs/2401.06320","description":"<p>Systematic reviews are crucial for evidence-based medicine as they\ncomprehensively analyse published research findings on specific questions.\nConducting such reviews is often resource- and time-intensive, especially in\nthe screening phase, where abstracts of publications are assessed for inclusion\nin a review. This study investigates the effectiveness of using zero-shot large\nlanguage models~(LLMs) for automatic screening. We evaluate the effectiveness\nof eight different LLMs and investigate a calibration technique that uses a\npredefined recall threshold to determine whether a publication should be\nincluded in a systematic review. Our comprehensive evaluation using five\nstandard test collections shows that instruction fine-tuning plays an important\nrole in screening, that calibration renders LLMs practical for achieving a\ntargeted recall, and that combining both with an ensemble of zero-shot models\nsaves significant screening time compared to state-of-the-art approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scells_H/0/1/0/all/0/1\">Harrisen Scells</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_S/0/1/0/all/0/1\">Shengyao Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potthast_M/0/1/0/all/0/1\">Martin Potthast</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koopman_B/0/1/0/all/0/1\">Bevan Koopman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuccon_G/0/1/0/all/0/1\">Guido Zuccon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-Task Learning for Front-End Text Processing in TTS. (arXiv:2401.06321v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06321","description":"<p>We propose a multi-task learning (MTL) model for jointly performing three\ntasks that are commonly solved in a text-to-speech (TTS) front-end: text\nnormalization (TN), part-of-speech (POS) tagging, and homograph disambiguation\n(HD). Our framework utilizes a tree-like structure with a trunk that learns\nshared representations, followed by separate task-specific heads. We further\nincorporate a pre-trained language model to utilize its built-in lexical and\ncontextual knowledge, and study how to best use its embeddings so as to most\neffectively benefit our multi-task model. Through task-wise ablations, we show\nthat our full model trained on all three tasks achieves the strongest overall\nperformance compared to models trained on individual or sub-combinations of\ntasks, confirming the advantages of our MTL framework. Finally, we introduce a\nnew HD dataset containing a balanced number of sentences in diverse contexts\nfor a variety of homographs and their pronunciations. We demonstrate that\nincorporating this dataset into training significantly improves HD performance\nover only using a commonly used, but imbalanced, pre-existing dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1\">Wonjune Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hinsvark_A/0/1/0/all/0/1\">Arthur Hinsvark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1\">Qing He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning from Semi-Factuals: A Debiased and Semantic-Aware Framework for Generalized Relation Discovery. (arXiv:2401.06327v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06327","description":"<p>We introduce a novel task, called Generalized Relation Discovery (GRD), for\nopen-world relation extraction. GRD aims to identify unlabeled instances in\nexisting pre-defined relations or discover novel relations by assigning\ninstances to clusters as well as providing specific meanings for these\nclusters. The key challenges of GRD are how to mitigate the serious model\nbiases caused by labeled pre-defined relations to learn effective relational\nrepresentations and how to determine the specific semantics of novel relations\nduring classifying or clustering unlabeled instances. We then propose a novel\nframework, SFGRD, for this task to solve the above issues by learning from\nsemi-factuals in two stages. The first stage is semi-factual generation\nimplemented by a tri-view debiased relation representation module, in which we\ntake each original sentence as the main view and design two debiased views to\ngenerate semi-factual examples for this sentence. The second stage is\nsemi-factual thinking executed by a dual-space tri-view collaborative relation\nlearning module, where we design a cluster-semantic space and a class-index\nspace to learn relational semantics and relation label indices, respectively.\nIn addition, we devise alignment and selection strategies to integrate two\nspaces and establish a self-supervised learning loop for unlabeled data by\ndoing semi-factual thinking across three views. Extensive experimental results\nshow that SFGRD surpasses state-of-the-art models in terms of accuracy by\n2.36\\% $\\sim$5.78\\% and cosine similarity by 32.19\\%$\\sim$ 84.45\\% for relation\nlabel index and relation semantic quality, respectively. To the best of our\nknowledge, we are the first to exploit the efficacy of semi-factuals in\nrelation extraction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lingling Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1\">Tianlin Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenjun Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs. (arXiv:2401.06373v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06373","description":"<p>Most traditional AI safety research has approached AI models as machines and\ncentered on algorithm-focused attacks developed by security experts. As large\nlanguage models (LLMs) become increasingly common and competent, non-expert\nusers can also impose risks during daily interactions. This paper introduces a\nnew perspective to jailbreak LLMs as human-like communicators, to explore this\noverlooked intersection between everyday language interaction and AI safety.\nSpecifically, we study how to persuade LLMs to jailbreak them. First, we\npropose a persuasion taxonomy derived from decades of social science research.\nThen, we apply the taxonomy to automatically generate interpretable persuasive\nadversarial prompts (PAP) to jailbreak LLMs. Results show that persuasion\nsignificantly increases the jailbreak performance across all risk categories:\nPAP consistently achieves an attack success rate of over $92\\%$ on Llama 2-7b\nChat, GPT-3.5, and GPT-4 in $10$ trials, surpassing recent algorithm-focused\nattacks. On the defense side, we explore various mechanisms against PAP and,\nfound a significant gap in existing defenses, and advocate for more fundamental\nmitigation for highly interactive LLMs\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongpeng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingwen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weiyan Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What should I say? -- Interacting with AI and Natural Language Interfaces. (arXiv:2401.06382v1 [cs.HC])","link":"http://arxiv.org/abs/2401.06382","description":"<p>As Artificial Intelligence (AI) technology becomes more and more prevalent,\nit becomes increasingly important to explore how we as humans interact with AI.\nThe Human-AI Interaction (HAI) sub-field has emerged from the Human-Computer\nInteraction (HCI) field and aims to examine this very notion. Many interaction\npatterns have been implemented without fully understanding the changes in\nrequired cognition as well as the cognitive science implications of using these\nalternative interfaces that aim to be more human-like in nature. Prior research\nsuggests that theory of mind representations are crucial to successful and\neffortless communication, however very little is understood when it comes to\nhow theory of mind representations are established when interacting with AI.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Adkins_M/0/1/0/all/0/1\">Mark Adkins</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adaptive Data Augmentation for Aspect Sentiment Quad Prediction. (arXiv:2401.06394v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06394","description":"<p>Aspect sentiment quad prediction (ASQP) aims to predict the quad sentiment\nelements for a given sentence, which is a critical task in the field of\naspect-based sentiment analysis. However, the data imbalance issue has not\nreceived sufficient attention in ASQP task. In this paper, we divide the issue\ninto two-folds, quad-pattern imbalance and aspect-category imbalance, and\npropose an Adaptive Data Augmentation (ADA) framework to tackle the imbalance\nissue. Specifically, a data augmentation process with a condition function\nadaptively enhances the tail quad patterns and aspect categories, alleviating\nthe data imbalance in ASQP. Following previous studies, we also further explore\nthe generative framework for extracting complete quads by introducing the\ncategory prior knowledge and syntax-guided decoding target. Experimental\nresults demonstrate that data augmentation for imbalance in ASQP task can\nimprove the performance, and the proposed ADA method is superior to naive data\noversampling.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinghua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Shiyao Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuebin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tingwen Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An approach for mistranslation removal from popular dataset for Indic MT Task. (arXiv:2401.06398v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06398","description":"<p>The conversion of content from one language to another utilizing a computer\nsystem is known as Machine Translation (MT). Various techniques have come up to\nensure effective translations that retain the contextual and lexical\ninterpretation of the source language. End-to-end Neural Machine Translation\n(NMT) is a popular technique and it is now widely used in real-world MT\nsystems. Massive amounts of parallel datasets (sentences in one language\nalongside translations in another) are required for MT systems. These datasets\nare crucial for an MT system to learn linguistic structures and patterns of\nboth languages during the training phase. One such dataset is Samanantar, the\nlargest publicly accessible parallel dataset for Indian languages (ILs). Since\nthe corpus has been gathered from various sources, it contains many incorrect\ntranslations. Hence, the MT systems built using this dataset cannot perform to\ntheir usual potential. In this paper, we propose an algorithm to remove\nmistranslations from the training corpus and evaluate its performance and\nefficiency. Two Indic languages (ILs), namely, Hindi (HIN) and Odia (ODI) are\nchosen for the experiment. A baseline NMT system is built for these two ILs,\nand the effect of different dataset sizes is also investigated. The quality of\nthe translations in the experiment is evaluated using standard metrics such as\nBLEU, METEOR, and RIBES. From the results, it is observed that removing the\nincorrect translation from the dataset makes the translation quality better. It\nis also noticed that, despite the fact that the ILs-English and English-ILs\nsystems are trained using the same corpus, ILs-English works more effectively\nacross all the evaluation metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sudhansu Bala Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodrigues_L/0/1/0/all/0/1\">Leo Raphael Rodrigues</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_T/0/1/0/all/0/1\">Tapas Kumar Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patra_B/0/1/0/all/0/1\">Bidyut Kr. Patra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generalizing Visual Question Answering from Synthetic to Human-Written Questions via a Chain of QA with a Large Language Model. (arXiv:2401.06400v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06400","description":"<p>Visual question answering (VQA) is a task where an image is given, and a\nseries of questions are asked about the image. To build an efficient VQA\nalgorithm, a large amount of QA data is required which is very expensive.\nGenerating synthetic QA pairs based on templates is a practical way to obtain\ndata. However, VQA models trained on those data do not perform well on complex,\nhuman-written questions. To address this issue, we propose a new method called\n{\\it chain of QA for human-written questions} (CoQAH). CoQAH utilizes a\nsequence of QA interactions between a large language model and a VQA model\ntrained on synthetic data to reason and derive logical answers for\nhuman-written questions. We tested the effectiveness of CoQAH on two types of\nhuman-written VQA datasets for 3D-rendered and chest X-ray images and found\nthat it achieved state-of-the-art accuracy in both types of data. Notably,\nCoQAH outperformed general vision-language models, VQA models, and medical\nfoundation models with no finetuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taehee Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_Y/0/1/0/all/0/1\">Yeongjae Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_H/0/1/0/all/0/1\">Heejun Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jo_Y/0/1/0/all/0/1\">Yohan Jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_D/0/1/0/all/0/1\">Dongmyung Shin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DevEval: Evaluating Code Generation in Practical Software Projects. (arXiv:2401.06401v1 [cs.SE])","link":"http://arxiv.org/abs/2401.06401","description":"<p>How to evaluate Large Language Models (LLMs) in code generation is an open\nquestion. Many benchmarks have been proposed but are inconsistent with\npractical software projects, e.g., unreal program distributions, insufficient\ndependencies, and small-scale project contexts. Thus, the capabilities of LLMs\nin practical projects are still unclear. In this paper, we propose a new\nbenchmark named DevEval, aligned with Developers' experiences in practical\nprojects. DevEval is collected through a rigorous pipeline, containing 2,690\nsamples from 119 practical projects and covering 10 domains. Compared to\nprevious benchmarks, DevEval aligns to practical projects in multiple\ndimensions, e.g., real program distributions, sufficient dependencies, and\nenough-scale project contexts. We assess five popular LLMs on DevEval (e.g.,\ngpt-4, gpt-3.5-turbo, CodeLLaMa, and StarCoder) and reveal their actual\nabilities in code generation. For instance, the highest Pass@1 of gpt-3.5-turbo\nonly is 42 in our experiments. We also discuss the challenges and future\ndirections of code generation in practical projects. We open-source DevEval and\nhope it can facilitate the development of code generation in practical\nprojects.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Ge Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yunfei Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongmin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huanyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kaibo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lecheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1\">Zheng Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lanshen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1\">Jiazheng Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuanming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yihong Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuqi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_B/0/1/0/all/0/1\">Bin Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Mengfei Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AboutMe: Using Self-Descriptions in Webpages to Document the Effects of English Pretraining Data Filters. (arXiv:2401.06408v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06408","description":"<p>Large language models' (LLMs) abilities are drawn from their pretraining\ndata, and model development begins with data curation. However, decisions\naround what data is retained or removed during this initial stage is\nunder-scrutinized. In our work, we ground web text, which is a popular\npretraining data source, to its social and geographic contexts. We create a new\ndataset of 10.3 million self-descriptions of website creators, and extract\ninformation about who they are and where they are from: their topical\ninterests, social roles, and geographic affiliations. Then, we conduct the\nfirst study investigating how ten \"quality\" and English language identification\n(langID) filters affect webpages that vary along these social dimensions. Our\nexperiments illuminate a range of implicit preferences in data curation: we\nshow that some quality classifiers act like topical domain filters, and langID\ncan overlook English content from some regions of the world. Overall, we hope\nthat our work will encourage a new line of research on pretraining data\ncuration practices and its social implications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lucy_L/0/1/0/all/0/1\">Li Lucy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gururangan_S/0/1/0/all/0/1\">Suchin Gururangan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soldaini_L/0/1/0/all/0/1\">Luca Soldaini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strubell_E/0/1/0/all/0/1\">Emma Strubell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamman_D/0/1/0/all/0/1\">David Bamman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_L/0/1/0/all/0/1\">Lauren Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodge_J/0/1/0/all/0/1\">Jesse Dodge</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mission: Impossible Language Models. (arXiv:2401.06416v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06416","description":"<p>Chomsky and others have very directly claimed that large language models\n(LLMs) are equally capable of learning languages that are possible and\nimpossible for humans to learn. However, there is very little published\nexperimental evidence to support such a claim. Here, we develop a set of\nsynthetic impossible languages of differing complexity, each designed by\nsystematically altering English data with unnatural word orders and grammar\nrules. These languages lie on an impossibility continuum: at one end are\nlanguages that are inherently impossible, such as random and irreversible\nshuffles of English words, and on the other, languages that may not be\nintuitively impossible but are often considered so in linguistics, particularly\nthose with rules based on counting word positions. We report on a wide range of\nevaluations to assess the capacity of GPT-2 small models to learn these\nuncontroversially impossible languages, and crucially, we perform these\nassessments at various stages throughout training to compare the learning\nprocess for each language. Our core finding is that GPT-2 struggles to learn\nimpossible languages when compared to English as a control, challenging the\ncore claim. More importantly, we hope our approach opens up a productive line\nof inquiry in which different LLM architectures are tested on a variety of\nimpossible languages in an effort to learn more about how LLMs can be used as\ntools for these cognitive and typological investigations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kallini_J/0/1/0/all/0/1\">Julie Kallini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papadimitriou_I/0/1/0/all/0/1\">Isabel Papadimitriou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Futrell_R/0/1/0/all/0/1\">Richard Futrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahowald_K/0/1/0/all/0/1\">Kyle Mahowald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Automation to Augmentation: Large Language Models Elevating Essay Scoring Landscape. (arXiv:2401.06431v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06431","description":"<p>Receiving immediate and personalized feedback is crucial for second-language\nlearners, and Automated Essay Scoring (AES) systems are a vital resource when\nhuman instructors are unavailable. This study investigates the effectiveness of\nLarge Language Models (LLMs), specifically GPT-4 and fine-tuned GPT-3.5, as\ntools for AES. Our comprehensive set of experiments, conducted on both public\nand private datasets, highlights the remarkable advantages of LLM-based AES\nsystems. They include superior accuracy, consistency, generalizability, and\ninterpretability, with fine-tuned GPT-3.5 surpassing traditional grading\nmodels. Additionally, we undertake LLM-assisted human evaluation experiments\ninvolving both novice and expert graders. One pivotal discovery is that LLMs\nnot only automate the grading process but also enhance the performance of human\ngraders. Novice graders when provided with feedback generated by LLMs, achieve\na level of accuracy on par with experts, while experts become more efficient\nand maintain greater consistency in their assessments. These results underscore\nthe potential of LLMs in educational technology, paving the way for effective\ncollaboration between humans and AI, ultimately leading to transformative\nlearning experiences through AI-generated feedback.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Changrong Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wenxing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Sean Xin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kunpeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yufang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1\">Qi Fu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BOK-VQA: Bilingual Outside Knowledge-based Visual Question Answering via Graph Representation Pretraining. (arXiv:2401.06443v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06443","description":"<p>The current research direction in generative models, such as the recently\ndeveloped GPT4, aims to find relevant knowledge information for multimodal and\nmultilingual inputs to provide answers. Under these research circumstances, the\ndemand for multilingual evaluation of visual question answering (VQA) tasks, a\nrepresentative task of multimodal systems, has increased. Accordingly, we\npropose a bilingual outside-knowledge VQA (BOK-VQA) dataset in this study that\ncan be extended to multilingualism. The proposed data include 17K images, 17K\nquestion-answer pairs for both Korean and English and 280K instances of\nknowledge information related to question-answer content. We also present a\nframework that can effectively inject knowledge information into a VQA system\nby pretraining the knowledge information of BOK-VQA data in the form of graph\nembeddings. Finally, through in-depth analysis, we demonstrated the actual\neffect of the knowledge information contained in the constructed training data\non VQA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minjun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Seungwoo Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Youhan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_H/0/1/0/all/0/1\">Haneol Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_K/0/1/0/all/0/1\">Kyungtae Lim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers. (arXiv:2401.06461v1 [cs.SE])","link":"http://arxiv.org/abs/2401.06461","description":"<p>Large language models have catalyzed an unprecedented wave in code\ngeneration. While achieving significant advances, they blur the distinctions\nbetween machine-and human-authored source code, causing integrity and\nauthenticity issues of software artifacts. Previous methods such as DetectGPT\nhave proven effective in discerning machine-generated texts, but they do not\nidentify and harness the unique patterns of machine-generated code. Thus, its\napplicability falters when applied to code. In this paper, we carefully study\nthe specific patterns that characterize machine and human-authored code.\nThrough a rigorous analysis of code attributes such as length, lexical\ndiversity, and naturalness, we expose unique pat-terns inherent to each source.\nWe particularly notice that the structural segmentation of code is a critical\nfactor in identifying its provenance. Based on our findings, we propose a novel\nmachine-generated code detection method called DetectCodeGPT, which improves\nDetectGPT by capturing the distinct structural patterns of code. Diverging from\nconventional techniques that depend on external LLMs for perturbations,\nDetectCodeGPT perturbs the code corpus by strategically inserting spaces and\nnewlines, ensuring both efficacy and efficiency. Experiment results show that\nour approach significantly outperforms state-of-the-art techniques in detecting\nmachine-generated code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yuling Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_C/0/1/0/all/0/1\">Chengcheng Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1\">Xiaodong Gu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PersianMind: A Cross-Lingual Persian-English Large Language Model. (arXiv:2401.06466v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06466","description":"<p>Large language models demonstrate remarkable proficiency in various\nlinguistic tasks and have extensive knowledge across various domains. Although\nthey perform best in English, their ability in other languages is notable too.\nIn contrast, open-source models, such as LLaMa, are primarily trained on\nEnglish datasets, resulting in poor performance in non-English languages. In\nthis paper, we introduce PersianMind, an open-source bilingual large language\nmodel which demonstrates comparable performance to closed-source GPT-3.5-turbo\nin the Persian language. By expanding LLaMa2's vocabulary with 10,000 Persian\ntokens and training it on a dataset comprising nearly 2 billion Persian tokens,\nwe show that our approach preserves the model's English knowledge and employs\ntransfer learning to excel at transferring task knowledge from one language to\nanother.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rostami_P/0/1/0/all/0/1\">Pedram Rostami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salemi_A/0/1/0/all/0/1\">Ali Salemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dousti_M/0/1/0/all/0/1\">Mohammad Javad Dousti</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adapting Large Language Models for Document-Level Machine Translation. (arXiv:2401.06468v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06468","description":"<p>Large language models (LLMs) have made significant strides in various natural\nlanguage processing (NLP) tasks. Recent research shows that the\nmoderately-sized LLMs often outperform their larger counterparts after\ntask-specific fine-tuning. In this work, we delve into the process of adapting\nLLMs to specialize in document-level machine translation (DocMT) for a specific\nlanguage pair. Firstly, we explore how prompt strategies affect downstream\ntranslation performance. Then, we conduct extensive experiments with two\nfine-tuning methods, three LLM backbones, and 18 translation tasks across nine\nlanguage pairs. Our findings indicate that in some cases, these specialized\nmodels even surpass GPT-4 in translation performance, while they still\nsignificantly suffer from the off-target translation issue in others, even if\nthey are exclusively fine-tuned on bilingual parallel documents. Furthermore,\nwe provide an in-depth analysis of these LLMs tailored for DocMT, exploring\naspects such as translation errors, the scaling law of parallel documents,\nout-of-domain generalization, and the impact of zero-shot crosslingual\ntransfer. The findings of this research not only shed light on the strengths\nand limitations of LLM-based DocMT models but also provide a foundation for\nfuture research in DocMT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Minghao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1\">Thuy-Trang Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Lizhen Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_G/0/1/0/all/0/1\">George Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1\">Gholamreza Haffari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Batch-ICL: Effective, Efficient, and Order-Agnostic In-Context Learning. (arXiv:2401.06469v1 [cs.LG])","link":"http://arxiv.org/abs/2401.06469","description":"<p>In this paper, by treating in-context learning (ICL) as a meta-optimization\nprocess, we explain why LLMs are sensitive to the order of ICL examples. This\nunderstanding leads us to the development of Batch-ICL, an effective,\nefficient, and order-agnostic inference algorithm for ICL. Differing from the\nstandard N-shot learning approach, Batch-ICL employs $N$ separate 1-shot\nforward computations and aggregates the resulting meta-gradients. These\naggregated meta-gradients are then applied to a zero-shot learning to generate\nthe final prediction. This batch processing approach renders the LLM agnostic\nto the order of ICL examples. Through extensive experiments and analysis, we\ndemonstrate that Batch-ICL consistently outperforms most permutations of\nexample sequences. In some cases, it even exceeds the performance of the\noptimal order for standard ICL, all while reducing the computational resources\nrequired. Furthermore, we develop a novel variant of Batch-ICL featuring\nmultiple \"epochs\" of meta-optimization. This variant implicitly explores\npermutations of ICL examples, further enhancing ICL performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_A/0/1/0/all/0/1\">Ang Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuhan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ha_H/0/1/0/all/0/1\">Hansen Ha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1\">Rui Yan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Kun: Answer Polishment for Chinese Self-Alignment with Instruction Back-Translation. (arXiv:2401.06477v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06477","description":"<p>In this paper, we introduce Kun, a novel approach for creating high-quality\ninstruction-tuning datasets for large language models (LLMs) without relying on\nmanual annotations. Adapting a self-training algorithm based on instruction\nback-translation and answer polishment, Kun leverages unlabelled data from\ndiverse sources such as Wudao, Wanjuan, and SkyPile to generate a substantial\ndataset of over a million Chinese instructional data points. This approach\nsignificantly deviates from traditional methods by using a self-curation\nprocess to refine and select the most effective instruction-output pairs. Our\nexperiments with the 6B-parameter Yi model across various benchmarks\ndemonstrate Kun's robustness and scalability. Our method's core contributions\nlie in its algorithmic advancement, which enhances data retention and clarity,\nand its innovative data generation approach that substantially reduces the\nreliance on costly and time-consuming manual annotations. This methodology\npresents a scalable and efficient solution for improving the\ninstruction-following capabilities of LLMs, with significant implications for\ntheir application across diverse fields. The code and dataset can be found at\nhttps://github.com/Zheng0428/COIG-Kun\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1\">Tianyu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shuyue Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1\">Xingwei Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jiawei Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weixu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1\">Xinrun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Ge Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An investigation of structures responsible for gender bias in BERT and DistilBERT. (arXiv:2401.06495v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06495","description":"<p>In recent years, large Transformer-based Pre-trained Language Models (PLM)\nhave changed the Natural Language Processing (NLP) landscape, by pushing the\nperformance boundaries of the state-of-the-art on a wide variety of tasks.\nHowever, this performance gain goes along with an increase in complexity, and\nas a result, the size of such models (up to billions of parameters) represents\na constraint for their deployment on embedded devices or short-inference time\ntasks. To cope with this situation, compressed models emerged (e.g.\nDistilBERT), democratizing their usage in a growing number of applications that\nimpact our daily lives. A crucial issue is the fairness of the predictions made\nby both PLMs and their distilled counterparts. In this paper, we propose an\nempirical exploration of this problem by formalizing two questions: (1) Can we\nidentify the neural mechanism(s) responsible for gender bias in BERT (and by\nextension DistilBERT)? (2) Does distillation tend to accentuate or mitigate\ngender bias (e.g. is DistilBERT more prone to gender bias than its uncompressed\nversion, BERT)? Our findings are the following: (I) one cannot identify a\nspecific layer that produces bias; (II) every attention head uniformly encodes\nbias; except in the context of underrepresented classes with a high imbalance\nof the sensitive attribute; (III) this subset of heads is different as we\nre-fine tune the network; (IV) bias is more homogeneously produced by the heads\nin the distilled model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Leteno_T/0/1/0/all/0/1\">Thibaud Leteno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gourru_A/0/1/0/all/0/1\">Antoine Gourru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laclau_C/0/1/0/all/0/1\">Charlotte Laclau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gravier_C/0/1/0/all/0/1\">Christophe Gravier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AntEval: Quantitatively Evaluating Informativeness and Expressiveness of Agent Social Interactions. (arXiv:2401.06509v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06509","description":"<p>While Large Language Models (LLMs) based agents have successfully mimicked\nhuman behaviors in various scenarios, the realm of complex, multi-character\nsocial interactions within extended contexts remains underexplored. The\nchallenge is compounded by privacy concerns, making it difficult to capture and\nutilize intricate real-life interactions. More importantly, the absence of\nquantitative evaluation methods hampers the pursuit of high-quality agent\ninteractions, often leading to interactions that are limited in informativeness\nand expressiveness, characterized by superficial small talk without clear\nintentions. In this work, we leverage the rules of Tabletop Role-Playing Games\n(TRPG) to create an environment conducive to complex, context-rich\ninteractions, emphasizing informativeness and expressiveness. This virtual\nsetting alleviates privacy concerns and motivates agents to engage in\nmeaningful, high-quality interactions as part of their in-game objectives. To\nassess these interactions, we introduce the Agent interaction Evaluation\nframework (AntEval), targeting the qualitative evaluation of interaction\ninformativeness and expressiveness. Specifically, we propose two novel\nevaluation metrics: Information Exchanging Precision (IEP) and Interaction\nExpressiveness Gap (IEG). These metrics are designed to assess interactions in\nscenarios focused on information exchange and intention expression,\nrespectively. Our experimental results demonstrate the effectiveness of these\nmetrics in evaluating interaction quality. Notably, we identify significant\nareas for improvement in LLMs regarding social interactions, as highlighted by\nour metrics. We believe AntEval will guide further exploration in complex agent\ninteractions, bringing them closer to emulating real human behavior and\nenhancing their integration and utility in real-world applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yuanzhi Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Linchao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MetaHate: A Dataset for Unifying Efforts on Hate Speech Detection. (arXiv:2401.06526v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06526","description":"<p>Hate speech represents a pervasive and detrimental form of online discourse,\noften manifested through an array of slurs, from hateful tweets to defamatory\nposts. As such speech proliferates, it connects people globally and poses\nsignificant social, psychological, and occasionally physical threats to\ntargeted individuals and communities. Current computational linguistic\napproaches for tackling this phenomenon rely on labelled social media datasets\nfor training. For unifying efforts, our study advances in the critical need for\na comprehensive meta-collection, advocating for an extensive dataset to help\ncounteract this problem effectively. We scrutinized over 60 datasets,\nselectively integrating those pertinent into MetaHate. This paper offers a\ndetailed examination of existing collections, highlighting their strengths and\nlimitations. Our findings contribute to a deeper understanding of the existing\ndatasets, paving the way for training more robust and adaptable models. These\nenhanced models are essential for effectively combating the dynamic and complex\nnature of hate speech in the digital realm.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Piot_P/0/1/0/all/0/1\">Paloma Piot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_Rodilla_P/0/1/0/all/0/1\">Patricia Mart&#xed;n-Rodilla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parapar_J/0/1/0/all/0/1\">Javier Parapar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning. (arXiv:2401.06532v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06532","description":"<p>Large language models (LLMs) have demonstrated impressive capabilities in\nvarious natural language processing tasks. Despite this, their application to\ninformation retrieval (IR) tasks is still challenging due to the infrequent\noccurrence of many IR-specific concepts in natural language. While prompt-based\nmethods can provide task descriptions to LLMs, they often fall short in\nfacilitating comprehensive understanding and execution of IR tasks, thereby\nlimiting LLMs' applicability. To address this gap, in this work, we explore the\npotential of instruction tuning to enhance LLMs' proficiency in IR tasks. We\nintroduce a novel instruction tuning dataset, INTERS, encompassing 21 tasks\nacross three fundamental IR categories: query understanding, document\nunderstanding, and query-document relationship understanding. The data are\nderived from 43 distinct datasets with manually written templates. Our\nempirical results reveal that INTERS significantly boosts the performance of\nvarious publicly available LLMs, such as LLaMA, Mistral, and Phi, in\nsearch-related tasks. Furthermore, we conduct a comprehensive analysis to\nascertain the effects of base model selection, instruction design, volume of\ninstructions, and task variety on performance. We make our dataset and the\nmodels fine-tuned on it publicly accessible at https://github.com/DaoD/INTERS.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yutao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Peitian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chenghao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yifei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_B/0/1/0/all/0/1\">Binyu Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1\">Zhicheng Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Medical Dialogue Generation via Intuitive-then-Analytical Differential Diagnosis. (arXiv:2401.06541v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06541","description":"<p>Medical dialogue systems have attracted growing research attention as they\nhave the potential to provide rapid diagnoses, treatment plans, and health\nconsultations. In medical dialogues, a proper diagnosis is crucial as it\nestablishes the foundation for future consultations. Clinicians typically\nemploy both intuitive and analytic reasoning to formulate a differential\ndiagnosis. This reasoning process hypothesizes and verifies a variety of\npossible diseases and strives to generate a comprehensive and rigorous\ndiagnosis. However, recent studies on medical dialogue generation have\noverlooked the significance of modeling a differential diagnosis, which hinders\nthe practical application of these systems. To address the above issue, we\npropose a medical dialogue generation framework with the\nIntuitive-then-Analytic Differential Diagnosis (IADDx). Our method starts with\na differential diagnosis via retrieval-based intuitive association and\nsubsequently refines it through a graph-enhanced analytic procedure. The\nresulting differential diagnosis is then used to retrieve medical knowledge and\nguide response generation. Experimental results on two datasets validate the\nefficacy of our method. Besides, we demonstrate how our framework assists both\nclinicians and patients in understanding the diagnostic process, for instance,\nby producing intermediate results and graph-based diagnosis paths.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kaishuai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1\">Wenjun Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenjie Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Intention Analysis Prompting Makes Large Language Models A Good Jailbreak Defender. (arXiv:2401.06561v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06561","description":"<p>Aligning large language models (LLMs) with human values, particularly in the\nface of stealthy and complex jailbreaks, presents a formidable challenge. In\nthis study, we present a simple yet highly effective defense strategy, i.e.,\nIntention Analysis Prompting (IAPrompt). The principle behind is to trigger\nLLMs' inherent self-correct and improve ability through a two-stage process: 1)\nessential intention analysis, and 2) policy-aligned response. Notably, IAPrompt\nis an inference-only method, thus could enhance the safety of LLMs without\ncompromising their helpfulness. Extensive experiments on SAP200 and DAN\nbenchmarks across Vicuna, ChatGLM, MPT, DeepSeek, and GPT-3.5 show that\nIAPrompt could consistently and significantly reduce the harmfulness in\nresponse (averagely -46.5% attack success rate) and maintain the general\nhelpfulness. Further analyses present some insights into how our method works.\nTo facilitate reproducibility, We release our code and scripts at:\nhttps://github.com/alphadl/SafeLLM_with_IntentionAnalysis\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lefei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lost in the Source Language: How Large Language Models Evaluate the Quality of Machine Translation. (arXiv:2401.06568v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06568","description":"<p>Large Language Models (LLMs) have achieved remarkable results in the machine\ntranslation evaluation task, yet there remains a gap in knowledge regarding how\nthey utilize the provided data to conduct evaluations. This study aims to\nexplore how LLMs leverage source and reference information in evaluating\ntranslations, with the ultimate goal of better understanding the working\nmechanism of LLMs. To this end, we design the controlled experiments across\nvarious input modes and model types, and employ both coarse-grained and\nfine-grained prompts to discern the utility of source versus reference\ninformation. Surprisingly, we find that reference information significantly\nenhances the evaluation accuracy, while source information sometimes is\ncounterproductive, indicating a lack of cross-lingual capability when using\nLLMs to evaluate translations. We further conduct a meta-evaluation for\ntranslation error detection of LLMs, observing a similar phenomenon. These\nfindings also suggest a potential research direction for LLMs that fully\nexploits the cross-lingual capability of LLMs to achieve better performance in\nmachine translation evaluation tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhirui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xiang Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yichao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiajun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shujian Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mapping Transformer Leveraged Embeddings for Cross-Lingual Document Representation. (arXiv:2401.06583v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06583","description":"<p>Recommendation systems, for documents, have become tools to find relevant\ncontent on the Web. However, these systems have limitations when it comes to\nrecommending documents in languages different from the query language, which\nmeans they might overlook resources in non-native languages. This research\nfocuses on representing documents across languages by using Transformer\nLeveraged Document Representations (TLDRs) that are mapped to a cross-lingual\ndomain. Four multilingual pre-trained transformer models (mBERT, mT5 XLM\nRoBERTa, ErnieM) were evaluated using three mapping methods across 20 language\npairs representing combinations of five selected languages of the European\nUnion. Metrics like Mate Retrieval Rate and Reciprocal Rank were used to\nmeasure the effectiveness of mapped TLDRs compared to non-mapped ones. The\nresults highlight the power of cross-lingual representations achieved through\npre-trained transformers and mapping approaches suggesting a promising\ndirection for expanding beyond language connections, between two specific\nlanguages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tashu_T/0/1/0/all/0/1\">Tsegaye Misikir Tashu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kontos_E/0/1/0/all/0/1\">Eduard-Raul Kontos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabatelli_M/0/1/0/all/0/1\">Matthia Sabatelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valdenegro_Toro_M/0/1/0/all/0/1\">Matias Valdenegro-Toro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prometheus-Vision: Vision-Language Model as a Judge for Fine-Grained Evaluation. (arXiv:2401.06591v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06591","description":"<p>Assessing long-form responses generated by Vision-Language Models (VLMs) is\nchallenging. It not only requires checking whether the VLM follows the given\ninstruction but also verifying whether the text output is properly grounded on\nthe given image. Inspired by the recent approach of evaluating LMs with LMs, in\nthis work, we propose to evaluate VLMs with VLMs. For this purpose, we present\na new feedback dataset called the Perception Collection, encompassing 15K\ncustomized score rubrics that users might care about during assessment. Using\nthe Perception Collection, we train Prometheus-Vision, the first open-source\nVLM evaluator model that can understand the user-defined score criteria during\nevaluation. Prometheus-Vision shows the highest Pearson correlation with human\nevaluators and GPT-4V among open-source models, showing its effectiveness for\ntransparent and accessible evaluation of VLMs. We open-source our code,\ndataset, and model at https://github.com/kaistAI/prometheus-vision\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seongyun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seungone Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sue Hyun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Geewook Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1\">Minjoon Seo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mutual Enhancement of Large Language and Reinforcement Learning Models through Bi-Directional Feedback Mechanisms: A Case Study. (arXiv:2401.06603v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06603","description":"<p>Large Language Models (LLMs) have demonstrated remarkable capabilities for\nreinforcement learning (RL) models, such as planning and reasoning\ncapabilities. However, the problems of LLMs and RL model collaboration still\nneed to be solved. In this study, we employ a teacher-student learning\nframework to tackle these problems, specifically by offering feedback for LLMs\nusing RL models and providing high-level information for RL models with LLMs in\na cooperative multi-agent setting. Within this framework, the LLM acts as a\nteacher, while the RL model acts as a student. The two agents cooperatively\nassist each other through a process of recursive help, such as \"I help you help\nI help.\" The LLM agent supplies abstract information to the RL agent, enabling\nefficient exploration and policy improvement. In turn, the RL agent offers\nfeedback to the LLM agent, providing valuable, real-time information that helps\ngenerate more useful tokens. This bi-directional feedback loop promotes\noptimization, exploration, and mutual improvement for both agents, enabling\nthem to accomplish increasingly challenging tasks. Remarkably, we propose a\npractical algorithm to address the problem and conduct empirical experiments to\nevaluate the effectiveness of our method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1\">Shangding Gu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TransliCo: A Contrastive Learning Framework to Address the Script Barrier in Multilingual Pretrained Language Models. (arXiv:2401.06620v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06620","description":"<p>There are 293 scripts representing over 7,000 languages in the written form.\nDue to various reasons, many closely related languages use different scripts,\nwhich poses difficulty for multilingual pretrained language models (mPLMs) in\nlearning crosslingual knowledge through lexical overlap. As a result, mPLMs\npresent a script barrier: representations from different scripts are located in\ndifferent subspaces, which is a strong indicator of why crosslingual transfer\ninvolving languages of different scripts shows sub-optimal performance. To\naddress this problem, we propose a simple framework TransliCo that contains\nTransliteration Contrastive Modeling (TCM) to fine-tune an mPLM by contrasting\nsentences in its training data and their transliterations in a unified script\n(Latn, in our case), which ensures uniformity in the representation space for\ndifferent scripts. Using Glot500-m, an mPLM pretrained on over 500 languages,\nas our source model, we find-tune it on a small portion (5\\%) of its training\ndata, and refer to the resulting model as Furina. We show that Furina not only\nbetter aligns representations from distinct scripts but also outperforms the\noriginal Glot500-m on various crosslingual transfer tasks. Additionally, we\nachieve consistent improvement in a case study on the Indic group where the\nlanguages are highly related but use different scripts. We make our code and\nmodels publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yihong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chunlan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Haotian Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OOP: Object-Oriented Programming Evaluation Benchmark for Large Language Models. (arXiv:2401.06628v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06628","description":"<p>Advancing automated programming necessitates robust and comprehensive code\ngeneration benchmarks, yet current evaluation frameworks largely neglect\nobject-oriented programming (OOP) in favor of functional programming (FP),\ne.g., HumanEval and MBPP. To address this, our study introduces a pioneering\nOOP-focused benchmark, featuring 431 Python programs that encompass essential\nOOP concepts and features like classes and encapsulation methods. We propose a\nnovel evaluation metric, pass@o, tailored for OOP, enhancing traditional pass@k\nmeasures. Our evaluation of 23 leading large language models (LLMs), including\nboth general and code-specialized models, reveals three key insights: 1) pass@o\noffers a more relevant and comprehensive assessment for OOP code generation; 2)\nDespite excelling in FP, code-specialized LLMs like WizardCoder lag in OOP\ncompared to models like ChatGPT; 3) The poor performance of all advanced LLMs\non our OOP benchmark highlights a critical need for improvements in this field.\nOur benchmark and scripts are publicly released at:\nhttps://github.com/alphadl/OOP-eval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yong Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bo Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Experimental Contexts Can Facilitate Robust Semantic Property Inference in Language Models, but Inconsistently. (arXiv:2401.06640v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06640","description":"<p>Recent zero-shot evaluations have highlighted important limitations in the\nabilities of language models (LMs) to perform meaning extraction. However, it\nis now well known that LMs can demonstrate radical improvements in the presence\nof experimental contexts such as in-context examples and instructions. How well\ndoes this translate to previously studied meaning-sensitive tasks? We present a\ncase-study on the extent to which experimental contexts can improve LMs'\nrobustness in performing property inheritance -- predicting semantic properties\nof novel concepts, a task that they have been previously shown to fail on. Upon\ncarefully controlling the nature of the in-context examples and the\ninstructions, our work reveals that they can indeed lead to non-trivial\nproperty inheritance behavior in LMs. However, this ability is inconsistent:\nwith a minimal reformulation of the task, some LMs were found to pick up on\nshallow, non-semantic heuristics from their inputs, suggesting that the\ncomputational principles of semantic property inference are yet to be mastered\nby LMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Misra_K/0/1/0/all/0/1\">Kanishka Misra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ettinger_A/0/1/0/all/0/1\">Allyson Ettinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahowald_K/0/1/0/all/0/1\">Kyle Mahowald</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Effects of diversity incentives on sample diversity and downstream model performance in LLM-based text augmentation. (arXiv:2401.06643v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06643","description":"<p>The latest generative large language models (LLMs) have found their\napplication in data augmentation tasks, where small numbers of text samples are\nLLM-paraphrased and then used to fine-tune the model. However, more research is\nneeded to assess how different prompts, seed data selection strategies,\nfiltering methods, or model settings affect the quality of paraphrased data\n(and downstream models). In this study, we investigate three text diversity\nincentive methods well established in crowdsourcing: taboo words, hints by\nprevious outlier solutions, and chaining on previous outlier solutions. Using\nthese incentive methods as part of instructions to LLMs augmenting text\ndatasets, we measure their effects on generated texts' lexical diversity and\ndownstream model performance. We compare the effects over 5 different LLMs and\n6 datasets. We show that diversity is most increased by taboo words, while\ndownstream model performance is highest when previously created paraphrases are\nused as hints.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cegin_J/0/1/0/all/0/1\">Jan Cegin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pecher_B/0/1/0/all/0/1\">Branislav Pecher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simko_J/0/1/0/all/0/1\">Jakub Simko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srba_I/0/1/0/all/0/1\">Ivan Srba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bielikova_M/0/1/0/all/0/1\">Maria Bielikova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brusilovsky_P/0/1/0/all/0/1\">Peter Brusilovsky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WisdoM: Improving Multimodal Sentiment Analysis by Fusing Contextual World Knowledge. (arXiv:2401.06659v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06659","description":"<p>Sentiment analysis is rapidly advancing by utilizing various data modalities\n(e.g., text, image). However, most previous works relied on superficial\ninformation, neglecting the incorporation of contextual world knowledge (e.g.,\nbackground information derived from but beyond the given image and text pairs)\nand thereby restricting their ability to achieve better multimodal sentiment\nanalysis. In this paper, we proposed a plug-in framework named WisdoM, designed\nto leverage contextual world knowledge induced from the large vision-language\nmodels (LVLMs) for enhanced multimodal sentiment analysis. WisdoM utilizes a\nLVLM to comprehensively analyze both images and corresponding sentences,\nsimultaneously generating pertinent context. To reduce the noise in the\ncontext, we also introduce a training-free Contextual Fusion mechanism.\nExperimental results across diverse granularities of multimodal sentiment\nanalysis tasks consistently demonstrate that our approach has substantial\nimprovements (brings an average +1.89 F1 score among five advanced methods)\nover several state-of-the-art methods. Code will be released.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenbin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yong Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Han Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PolyTOPS: Reconfigurable and Flexible Polyhedral Scheduler. (arXiv:2401.06665v1 [cs.DC])","link":"http://arxiv.org/abs/2401.06665","description":"<p>Polyhedral techniques have been widely used for automatic code optimization\nin low-level compilers and higher-level processes. Loop optimization is central\nto this technique, and several polyhedral schedulers like Feautrier, Pluto, isl\nand Tensor Scheduler have been proposed, each of them targeting a different\narchitecture, parallelism model, or application scenario. The need for\nscenario-specific optimization is growing due to the heterogeneity of\narchitectures. One of the most critical cases is represented by NPUs (Neural\nProcessing Units) used for AI, which may require loop optimization with\ndifferent objectives. Another factor to be considered is the framework or\ncompiler in which polyhedral optimization takes place. Different scenarios,\ndepending on the target architecture, compilation environment, and application\ndomain, may require different kinds of optimization to best exploit the\narchitecture feature set.\n</p>\n<p>We introduce a new configurable polyhedral scheduler, PolyTOPS, that can be\nadjusted to various scenarios with straightforward, high-level configurations.\nThis scheduler allows the creation of diverse scheduling strategies that can be\nboth scenario-specific (like state-of-the-art schedulers) and kernel-specific,\nbreaking the concept of a one-size-fits-all scheduler approach. PolyTOPS has\nbeen used with isl and CLooG as code generators and has been integrated in\nMindSpore AKG deep learning compiler. Experimental results in different\nscenarios show good performance: a geomean speedup of 7.66x on MindSpore (for\nthe NPU Ascend architecture) hybrid custom operators over isl scheduling, a\ngeomean speedup up to 1.80x on PolyBench on different multicore architectures\nover Pluto scheduling. Finally, some comparisons with different\nstate-of-the-art tools are presented in the PolyMage scenario.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Consolaro_G/0/1/0/all/0/1\">Gianpietro Consolaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razanajato_H/0/1/0/all/0/1\">Harenome Razanajato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lossing_N/0/1/0/all/0/1\">Nelson Lossing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tchoulak_N/0/1/0/all/0/1\">Nassim Tchoulak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Susungi_A/0/1/0/all/0/1\">Adilla Susungi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alves_A/0/1/0/all/0/1\">Artur Cesar Araujo Alves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Renwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barthou_D/0/1/0/all/0/1\">Denis Barthou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ancourt_C/0/1/0/all/0/1\">Corinne Ancourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastoul_C/0/1/0/all/0/1\">Cedric Bastoul</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DQNC2S: DQN-based Cross-stream Crisis event Summarizer. (arXiv:2401.06683v1 [cs.IR])","link":"http://arxiv.org/abs/2401.06683","description":"<p>Summarizing multiple disaster-relevant data streams simultaneously is\nparticularly challenging as existing Retrieve&amp;Re-ranking strategies suffer from\nthe inherent redundancy of multi-stream data and limited scalability in a\nmulti-query setting. This work proposes an online approach to crisis timeline\ngeneration based on weak annotation with Deep Q-Networks. It selects on-the-fly\nthe relevant pieces of text without requiring neither human annotations nor\ncontent re-ranking. This makes the inference time independent of the number of\ninput queries. The proposed approach also incorporates a redundancy filter into\nthe reward function to effectively handle cross-stream content overlaps. The\nachieved ROUGE and BERTScore results are superior to those of best-performing\nmodels on the CrisisFACTS 2022 benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cambrin_D/0/1/0/all/0/1\">Daniele Rege Cambrin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cagliero_L/0/1/0/all/0/1\">Luca Cagliero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garza_P/0/1/0/all/0/1\">Paolo Garza</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Proximal Causal Inference With Text Data. (arXiv:2401.06687v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06687","description":"<p>Recent text-based causal methods attempt to mitigate confounding bias by\nincluding unstructured text data as proxies of confounding variables that are\npartially or imperfectly measured. These approaches assume analysts have\nsupervised labels of the confounders given text for a subset of instances, a\nconstraint that is not always feasible due to data privacy or cost. Here, we\naddress settings in which an important confounding variable is completely\nunobserved. We propose a new causal inference method that splits pre-treatment\ntext data, infers two proxies from two zero-shot models on the separate splits,\nand applies these proxies in the proximal g-formula. We prove that our\ntext-based proxy method satisfies identification conditions required by the\nproximal g-formula while other seemingly reasonable proposals do not. We\nevaluate our method in synthetic and semi-synthetic settings and find that it\nproduces estimates with low bias. This combination of proximal causal inference\nand zero-shot classifiers is novel (to our knowledge) and expands the set of\ntext-specific causal methods available to practitioners.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jacob M. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_R/0/1/0/all/0/1\">Rohit Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keith_K/0/1/0/all/0/1\">Katherine A. Keith</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Don't Rank, Combine! Combining Machine Translation Hypotheses Using Quality Estimation. (arXiv:2401.06688v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06688","description":"<p>Neural machine translation systems estimate probabilities of target sentences\ngiven source sentences, yet these estimates may not align with human\npreferences. This work introduces QE-fusion, a method utilizing a quality\nestimation metric (QE) that better correlates with human judgments to\nsynthesize improved translations. QE-fusion leverages a candidate pool sampled\nfrom a model, combining spans from different candidates using QE metrics such\nas CometKiwi. We compare QE-fusion against beam search and recent reranking\ntechniques, such as Minimum Bayes Risk decoding or QE-reranking. Our method\nconsistently improves translation quality in terms of COMET and BLEURT scores\nwhen applied to large language models (LLMs) used for translation (PolyLM,\nXGLM, Llama2, and Mistral) and to multilingual translation models (NLLB), over\nfive language pairs. Notably, QE-fusion exhibits larger improvements for LLMs\ndue to their ability to generate diverse outputs. We demonstrate that our\napproach generates novel translations in over half of the cases and\nconsistently outperforms other methods across varying numbers of candidates\n(5-200). Furthermore, we empirically establish that QE-fusion scales linearly\nwith the number of candidates in the pool. QE-fusion proves effective in\nenhancing LLM-based translation without the need for costly retraining of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vernikos_G/0/1/0/all/0/1\">Giorgos Vernikos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popescu_Belis_A/0/1/0/all/0/1\">Andrei Popescu-Belis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models. (arXiv:2401.06692v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06692","description":"<p>Supervised finetuning (SFT) on instruction datasets has played a crucial role\nin achieving the remarkable zero-shot generalization capabilities observed in\nmodern large language models (LLMs). However, the annotation efforts required\nto produce high quality responses for instructions are becoming prohibitively\nexpensive, especially as the number of tasks spanned by instruction datasets\ncontinues to increase. Active learning is effective in identifying useful\nsubsets of samples to annotate from an unlabeled pool, but its high\ncomputational cost remains a barrier to its widespread applicability in the\ncontext of LLMs. To mitigate the annotation cost of SFT and circumvent the\ncomputational bottlenecks of active learning, we propose using experimental\ndesign. Experimental design techniques select the most informative samples to\nlabel, and typically maximize some notion of uncertainty and/or diversity. In\nour work, we implement a framework that evaluates several existing and novel\nexperimental design techniques and find that these methods consistently yield\nsignificant gains in label efficiency with little computational overhead. On\ngenerative tasks, our methods achieve the same generalization performance with\nonly $50\\%$ of annotation cost required by random sampling.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhatt_G/0/1/0/all/0/1\">Gantavya Bhatt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yifang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Arnav M. Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jifan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_S/0/1/0/all/0/1\">Sang T. Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mussmann_S/0/1/0/all/0/1\">Stephen Mussmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yinglun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilmes_J/0/1/0/all/0/1\">Jeffrey Bilmes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1\">Simon S. Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jamieson_K/0/1/0/all/0/1\">Kevin Jamieson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ash_J/0/1/0/all/0/1\">Jordan T. Ash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nowak_R/0/1/0/all/0/1\">Robert D. Nowak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-Candidate Speculative Decoding. (arXiv:2401.06706v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06706","description":"<p>Large language models have shown impressive capabilities across a variety of\nNLP tasks, yet their generating text autoregressively is time-consuming. One\nway to speed them up is speculative decoding, which generates candidate\nsegments (a sequence of tokens) from a fast draft model that is then verified\nin parallel by the target model. However, the acceptance rate of candidate\ntokens receives limitations from several factors, such as the model, the\ndataset, and the decoding setup. This paper proposes sampling multiple\ncandidates from a draft model and then organising them in batches for\nverification. We design algorithms for efficient multi-candidate verification\nwhile maintaining the distribution of the target model. Our approach shows\nsignificant improvements in acceptance rates on multiple datasets and models,\nconsistently outperforming standard speculative decoding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Sen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shujian Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1\">Xinyu Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reliability Analysis of Psychological Concept Extraction and Classification in User-penned Text. (arXiv:2401.06709v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06709","description":"<p>The social NLP research community witness a recent surge in the computational\nadvancements of mental health analysis to build responsible AI models for a\ncomplex interplay between language use and self-perception. Such responsible AI\nmodels aid in quantifying the psychological concepts from user-penned texts on\nsocial media. On thinking beyond the low-level (classification) task, we\nadvance the existing binary classification dataset, towards a higher-level task\nof reliability analysis through the lens of explanations, posing it as one of\nthe safety measures. We annotate the LoST dataset to capture nuanced textual\ncues that suggest the presence of low self-esteem in the posts of Reddit users.\nWe further state that the NLP models developed for determining the presence of\nlow self-esteem, focus more on three types of textual cues: (i) Trigger: words\nthat triggers mental disturbance, (ii) LoST indicators: text indicators\nemphasizing low self-esteem, and (iii) Consequences: words describing the\nconsequences of mental disturbance. We implement existing classifiers to\nexamine the attention mechanism in pre-trained language models (PLMs) for a\ndomain-specific psychology-grounded task. Our findings suggest the need of\nshifting the focus of PLMs from Trigger and Consequences to a more\ncomprehensive explanation, emphasizing LoST indicators while determining low\nself-esteem in Reddit posts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Garg_M/0/1/0/all/0/1\">Muskan Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sathvik_M/0/1/0/all/0/1\">MSVPJ Sathvik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Amrit Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raza_S/0/1/0/all/0/1\">Shaina Raza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_S/0/1/0/all/0/1\">Sunghwan Sohn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Few-Shot Detection of Machine-Generated Text using Style Representations. (arXiv:2401.06712v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06712","description":"<p>The advent of instruction-tuned language models that convincingly mimic human\nwriting poses a significant risk of abuse. For example, such models could be\nused for plagiarism, disinformation, spam, or phishing. However, such abuse may\nbe counteracted with the ability to detect whether a piece of text was composed\nby a language model rather than a human. Some previous approaches to this\nproblem have relied on supervised methods trained on corpora of confirmed human\nand machine-written documents. Unfortunately, model under-specification poses\nan unavoidable challenge for neural network-based detectors, making them\nbrittle in the face of data shifts, such as the release of further language\nmodels producing still more fluent text than the models used to train the\ndetectors. Other previous approaches require access to the models that may have\ngenerated a document in question at inference or detection time, which is often\nimpractical. In light of these challenges, we pursue a fundamentally different\napproach not relying on samples from language models of concern at training\ntime. Instead, we propose to leverage representations of writing style\nestimated from human-authored text. Indeed, we find that features effective at\ndistinguishing among human authors are also effective at distinguishing human\nfrom machine authors, including state of the art large language models like\nLlama 2, ChatGPT, and GPT-4. Furthermore, given a handful of examples composed\nby each of several specific language models of interest, our approach affords\nthe ability to predict which model generated a given document.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Soto_R/0/1/0/all/0/1\">Rafael Rivera Soto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koch_K/0/1/0/all/0/1\">Kailin Koch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Aleem Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Barry Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bishop_M/0/1/0/all/0/1\">Marcus Bishop</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andrews_N/0/1/0/all/0/1\">Nicholas Andrews</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reframing Tax Law Entailment as Analogical Reasoning. (arXiv:2401.06715v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06715","description":"<p>Statutory reasoning refers to the application of legislative provisions to a\nseries of case facts described in natural language. We re-frame statutory\nreasoning as an analogy task, where each instance of the analogy task involves\na combination of two instances of statutory reasoning. This increases the\ndataset size by two orders of magnitude, and introduces an element of\ninterpretability. We show that this task is roughly as difficult to Natural\nLanguage Processing models as the original task. Finally, we come back to\nstatutory reasoning, solving it with a combination of a retrieval mechanism and\nanalogy models, and showing some progress on prior comparable work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1\">Xinrui Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Ming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weir_N/0/1/0/all/0/1\">Nathaniel Weir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holzenberger_N/0/1/0/all/0/1\">Nils Holzenberger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Relying on the Unreliable: The Impact of Language Models' Reluctance to Express Uncertainty. (arXiv:2401.06730v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06730","description":"<p>As natural language becomes the default interface for human-AI interaction,\nthere is a critical need for LMs to appropriately communicate uncertainties in\ndownstream applications. In this work, we investigate how LMs incorporate\nconfidence about their responses via natural language and how downstream users\nbehave in response to LM-articulated uncertainties. We examine publicly\ndeployed models and find that LMs are unable to express uncertainties when\nanswering questions even when they produce incorrect responses. LMs can be\nexplicitly prompted to express confidences, but tend to be overconfident,\nresulting in high error rates (on average 47%) among confident responses. We\ntest the risks of LM overconfidence by running human experiments and show that\nusers rely heavily on LM generations, whether or not they are marked by\ncertainty. Lastly, we investigate the preference-annotated datasets used in\nRLHF alignment and find that humans have a bias against texts with uncertainty.\nOur work highlights a new set of safety harms facing human-LM interactions and\nproposes design recommendations and mitigating strategies moving forward.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kaitlyn Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1\">Jena D. Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1\">Maarten Sap</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Natural Language Inference to Improve Persona Extraction from Dialogue in a New Domain. (arXiv:2401.06742v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06742","description":"<p>While valuable datasets such as PersonaChat provide a foundation for training\npersona-grounded dialogue agents, they lack diversity in conversational and\nnarrative settings, primarily existing in the \"real\" world. To develop dialogue\nagents with unique personas, models are trained to converse given a specific\npersona, but hand-crafting these persona can be time-consuming, thus methods\nexist to automatically extract persona information from existing\ncharacter-specific dialogue. However, these persona-extraction models are also\ntrained on datasets derived from PersonaChat and struggle to provide\nhigh-quality persona information from conversational settings that do not take\nplace in the real world, such as the fantasy-focused dataset, LIGHT. Creating\nnew data to train models on a specific setting is human-intensive, thus\nprohibitively expensive. To address both these issues, we introduce a natural\nlanguage inference method for post-hoc adapting a trained persona extraction\nmodel to a new setting. We draw inspiration from the literature of dialog\nnatural language inference (NLI), and devise NLI-reranking methods to extract\nstructured persona information from dialogue. Compared to existing persona\nextraction models, our method returns higher-quality extracted persona and\nrequires less human annotation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+DeLucia_A/0/1/0/all/0/1\">Alexandra DeLucia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1\">Mengjie Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maeda_Y/0/1/0/all/0/1\">Yoshinori Maeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoda_M/0/1/0/all/0/1\">Makoto Yoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamada_K/0/1/0/all/0/1\">Keiichi Yamada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wakaki_H/0/1/0/all/0/1\">Hiromi Wakaki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Unreasonable Effectiveness of Easy Training Data for Hard Tasks. (arXiv:2401.06751v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06751","description":"<p>How can we train models to perform well on hard test data when hard training\ndata is by definition difficult to label correctly? This question has been\ntermed the scalable oversight problem and has drawn increasing attention as\nlanguage models have continually improved. In this paper, we present the\nsurprising conclusion that current language models often generalize relatively\nwell from easy to hard data, even performing as well as \"oracle\" models trained\non hard data. We demonstrate this kind of easy-to-hard generalization using\nsimple training methods like in-context learning, linear classifier heads, and\nQLoRA for seven different measures of datapoint hardness, including six\nempirically diverse human hardness measures (like grade level) and one\nmodel-based measure (loss-based). Furthermore, we show that even if one cares\nmost about model performance on hard data, it can be better to collect and\ntrain on easy data rather than hard data, since hard data is generally noisier\nand costlier to collect. Our experiments use open models up to 70b in size and\nfour publicly available question-answering datasets with questions ranging in\ndifficulty from 3rd grade science questions to college level STEM questions and\ngeneral-knowledge trivia. We conclude that easy-to-hard generalization in LMs\nis surprisingly strong for the tasks studied, suggesting the scalable oversight\nproblem may be easier than previously thought. Our code is available at\nhttps://github.com/allenai/easy-to-hard-generalization\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hase_P/0/1/0/all/0/1\">Peter Hase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_P/0/1/0/all/0/1\">Peter Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiegreffe_S/0/1/0/all/0/1\">Sarah Wiegreffe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stylometry Analysis of Multi-authored Documents for Authorship and Author Style Change Detection. (arXiv:2401.06752v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06752","description":"<p>In recent years, the increasing use of Artificial Intelligence based text\ngeneration tools has posed new challenges in document provenance,\nauthentication, and authorship detection. However, advancements in stylometry\nhave provided opportunities for automatic authorship and author change\ndetection in multi-authored documents using style analysis techniques. Style\nanalysis can serve as a primary step toward document provenance and\nauthentication through authorship detection. This paper investigates three key\ntasks of style analysis: (i) classification of single and multi-authored\ndocuments, (ii) single change detection, which involves identifying the point\nwhere the author switches, and (iii) multiple author-switching detection in\nmulti-authored documents. We formulate all three tasks as classification\nproblems and propose a merit-based fusion framework that integrates several\nstate-of-the-art natural language processing (NLP) algorithms and weight\noptimization techniques. We also explore the potential of special characters,\nwhich are typically removed during pre-processing in NLP applications, on the\nperformance of the proposed methods for these tasks by conducting extensive\nexperiments on both cleaned and raw datasets. Experimental results demonstrate\nsignificant improvements over existing solutions for all three tasks on a\nbenchmark dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zamir_M/0/1/0/all/0/1\">Muhammad Tayyab Zamir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayub_M/0/1/0/all/0/1\">Muhammad Asif Ayub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gul_A/0/1/0/all/0/1\">Asma Gul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_N/0/1/0/all/0/1\">Nasir Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_K/0/1/0/all/0/1\">Kashif Ahmad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Navigating the Metrics Maze: Reconciling Score Magnitudes and Accuracies. (arXiv:2401.06760v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06760","description":"<p>Ten years ago a single metric, BLEU, governed progress in machine translation\nresearch. For better or worse, there is no such consensus today, and\nconsequently it is difficult for researchers to develop and retain the kinds of\nheuristic intuitions about metric deltas that drove earlier research and\ndeployment decisions. This paper investigates the \"dynamic range\" of a number\nof modern metrics in an effort to provide a collective understanding of the\nmeaning of differences in scores both within and among metrics; in other words,\nwe ask what point difference X in metric Y is required between two systems for\nhumans to notice? We conduct our evaluation on a new large dataset, ToShip23,\nusing it to discover deltas at which metrics achieve system-level differences\nthat are meaningful to humans, which we measure by pairwise system accuracy. We\nadditionally show that this method of establishing delta-accuracy is more\nstable than the standard use of statistical p-values in regards to testset\nsize. Where data size permits, we also explore the effect of metric deltas and\naccuracy across finer-grained features such as translation direction, domain,\nand system closeness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kocmi_T/0/1/0/all/0/1\">Tom Kocmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zouhar_V/0/1/0/all/0/1\">Vil&#xe9;m Zouhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Federmann_C/0/1/0/all/0/1\">Christian Federmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Post_M/0/1/0/all/0/1\">Matt Post</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"APAR: LLMs Can Do Auto-Parallel Auto-Regressive Decoding. (arXiv:2401.06761v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06761","description":"<p>The massive adoption of large language models (LLMs) demands efficient\ndeployment strategies. However, the auto-regressive decoding process, which is\nfundamental to how most LLMs generate text, poses challenges to achieve\nefficient serving. In this work, we introduce a parallel auto-regressive\ngeneration method. By instruct-tuning on general domain data that contains\nhierarchical structures, we enable LLMs to independently plan their generation\nprocess and perform auto-parallel auto-regressive (APAR) generation,\nsignificantly reducing the number of generation steps. APAR alone can achieve\nup to 2x speed-up, and when combined with speculative decoding, the speed-up\ncan reach up to 4x. In addition, APAR reduces the key-value cache consumption\nand attention computation during generation. This leads to a throughput\nincrease of 20-70% and a latency reduce of 20-35% in high-throughput scenarios,\ncompared to state-of-the-art serving frameworks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mingdao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1\">Aohan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bowen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Peng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yuxiao Dong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mind Your Format: Towards Consistent Evaluation of In-Context Learning Improvements. (arXiv:2401.06766v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06766","description":"<p>Large language models demonstrate a remarkable capability for learning to\nsolve new tasks from a few examples. The prompt template, or the way the input\nexamples are formatted to obtain the prompt, is an important yet often\noverlooked aspect of in-context learning. In this work, we conduct a\ncomprehensive study of the template format's influence on the in-context\nlearning performance. We evaluate the impact of the prompt template across\nmodels (from 770M to 70B parameters) and 4 standard classification datasets. We\nshow that a poor choice of the template can reduce the performance of the\nstrongest models and inference methods to a random guess level. More\nimportantly, the best templates do not transfer between different setups and\neven between models of the same family. Our findings show that the currently\nprevalent approach to evaluation, which ignores template selection, may give\nmisleading results due to different templates in different works. As a first\nstep towards mitigating this issue, we propose Template Ensembles that\naggregate model predictions across several templates. This simple test-time\naugmentation boosts average performance while being robust to the choice of\nrandom set of templates.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Voronov_A/0/1/0/all/0/1\">Anton Voronov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lena Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryabinin_M/0/1/0/all/0/1\">Max Ryabinin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Machine Translation Models are Zero-Shot Detectors of Translation Direction. (arXiv:2401.06769v1 [cs.CL])","link":"http://arxiv.org/abs/2401.06769","description":"<p>Detecting the translation direction of parallel text has applications for\nmachine translation training and evaluation, but also has forensic applications\nsuch as resolving plagiarism or forgery allegations. In this work, we explore\nan unsupervised approach to translation direction detection based on the simple\nhypothesis that\n$p(\\text{translation}|\\text{original})&gt;p(\\text{original}|\\text{translation})$,\nmotivated by the well-known simplification effect in translationese or\nmachine-translationese. In experiments with massively multilingual machine\ntranslation models across 20 translation directions, we confirm the\neffectiveness of the approach for high-resource language pairs, achieving\ndocument-level accuracies of 82-96% for NMT-produced translations, and 60-81%\nfor human translations, depending on the model used. Code and demo are\navailable at https://github.com/ZurichNLP/translation-direction-detection\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wastl_M/0/1/0/all/0/1\">Michelle Wastl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vamvas_J/0/1/0/all/0/1\">Jannis Vamvas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sennrich_R/0/1/0/all/0/1\">Rico Sennrich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NAAQA: A Neural Architecture for Acoustic Question Answering. (arXiv:2106.06147v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.06147","description":"<p>The goal of the Acoustic Question Answering (AQA) task is to answer a\nfree-form text question about the content of an acoustic scene. It was inspired\nby the Visual Question Answering (VQA) task. In this paper, based on the\npreviously introduced CLEAR dataset, we propose a new benchmark for AQA, namely\nCLEAR2, that emphasizes the specific challenges of acoustic inputs. These\ninclude handling of variable duration scenes, and scenes built with elementary\nsounds that differ between training and test set. We also introduce NAAQA, a\nneural architecture that leverages specific properties of acoustic inputs. The\nuse of 1D convolutions in time and frequency to process 2D spectro-temporal\nrepresentations of acoustic content shows promising results and enables\nreductions in model complexity. We show that time coordinate maps augment\ntemporal localization capabilities which enhance performance of the network by\n~17 percentage points. On the other hand, frequency coordinate maps have little\ninfluence on this task. NAAQA achieves 79.5% of accuracy on the AQA task with\n~4 times fewer parameters than the previously explored VQA model. We evaluate\nthe perfomance of NAAQA on an independent data set reconstructed from DAQA. We\nalso test the addition of a MALiMo module in our model on both CLEAR2 and DAQA.\nWe provide a detailed analysis of the results for the different question types.\nWe release the code to produce CLEAR2 as well as NAAQA to foster research in\nthis newly emerging machine learning task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abdelnour_J/0/1/0/all/0/1\">Jerome Abdelnour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouat_J/0/1/0/all/0/1\">Jean Rouat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salvi_G/0/1/0/all/0/1\">Giampiero Salvi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"State-of-the-art generalisation research in NLP: A taxonomy and review. (arXiv:2210.03050v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.03050","description":"<p>The ability to generalise well is one of the primary desiderata of natural\nlanguage processing (NLP). Yet, what 'good generalisation' entails and how it\nshould be evaluated is not well understood, nor are there any evaluation\nstandards for generalisation. In this paper, we lay the groundwork to address\nboth of these issues. We present a taxonomy for characterising and\nunderstanding generalisation research in NLP. Our taxonomy is based on an\nextensive literature review of generalisation research, and contains five axes\nalong which studies can differ: their main motivation, the type of\ngeneralisation they investigate, the type of data shift they consider, the\nsource of this data shift, and the locus of the shift within the modelling\npipeline. We use our taxonomy to classify over 400 papers that test\ngeneralisation, for a total of more than 600 individual experiments.\nConsidering the results of this review, we present an in-depth analysis that\nmaps out the current state of generalisation research in NLP, and we make\nrecommendations for which areas might deserve attention in the future. Along\nwith this paper, we release a webpage where the results of our review can be\ndynamically explored, and which we intend to update as new NLP generalisation\nstudies are published. With this work, we aim to take steps towards making\nstate-of-the-art generalisation testing the new status quo in NLP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1\">Dieuwke Hupkes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giulianelli_M/0/1/0/all/0/1\">Mario Giulianelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dankers_V/0/1/0/all/0/1\">Verna Dankers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1\">Mikel Artetxe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elazar_Y/0/1/0/all/0/1\">Yanai Elazar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1\">Tiago Pimentel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christodoulopoulos_C/0/1/0/all/0/1\">Christos Christodoulopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lasri_K/0/1/0/all/0/1\">Karim Lasri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saphra_N/0/1/0/all/0/1\">Naomi Saphra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinclair_A/0/1/0/all/0/1\">Arabella Sinclair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ulmer_D/0/1/0/all/0/1\">Dennis Ulmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schottmann_F/0/1/0/all/0/1\">Florian Schottmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batsuren_K/0/1/0/all/0/1\">Khuyagbaatar Batsuren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1\">Kaiser Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_K/0/1/0/all/0/1\">Koustuv Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalatbari_L/0/1/0/all/0/1\">Leila Khalatbari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryskina_M/0/1/0/all/0/1\">Maria Ryskina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frieske_R/0/1/0/all/0/1\">Rita Frieske</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhijing Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Evaluation of Neural SPARQL Query Generation from Natural Language Questions. (arXiv:2304.07772v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.07772","description":"<p>In recent years, the field of neural machine translation (NMT) for SPARQL\nquery generation has witnessed significant growth. Incorporating the copy\nmechanism with traditional encoder-decoder architectures and using pre-trained\nencoder-decoders and large language models have set new performance benchmarks.\nThis paper presents various experiments that replicate and expand upon recent\nNMT-based SPARQL generation studies, comparing pre-trained language models\n(PLMs), non-pre-trained language models (NPLMs), and large language models\n(LLMs), highlighting the impact of question annotation and the copy mechanism\nand testing various fine-tuning methods using LLMs. In particular, we provide a\nsystematic error analysis of the models and test their generalization ability.\nOur study demonstrates that the copy mechanism yields significant performance\nenhancements for most PLMs and NPLMs. Annotating the data is pivotal to\ngenerating correct URIs, with the \"tag-within\" strategy emerging as the most\neffective approach. Additionally, our findings reveal that the primary source\nof errors stems from incorrect URIs in SPARQL queries that are sometimes\nreplaced with hallucinated URIs when using base models. This does not happen\nusing the copy mechanism, but it sometimes leads to selecting wrong URIs among\ncandidates. Finally, the performance of the tested LLMs fell short of achieving\nthe desired outcomes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Diallo_P/0/1/0/all/0/1\">Papa Abdou Karim Karou Diallo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reyd_S/0/1/0/all/0/1\">Samuel Reyd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zouaq_A/0/1/0/all/0/1\">Amal Zouaq</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Assessing the Importance of Frequency versus Compositionality for Subword-based Tokenization in NMT. (arXiv:2306.01393v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.01393","description":"<p>Subword tokenization is the de facto standard for tokenization in neural\nlanguage models and machine translation systems. Three advantages are\nfrequently cited in favor of subwords: shorter encoding of frequent tokens,\ncompositionality of subwords, and ability to deal with unknown words. As their\nrelative importance is not entirely clear yet, we propose a tokenization\napproach that enables us to separate frequency (the first advantage) from\ncompositionality. The approach uses Huffman coding to tokenize words, by order\nof frequency, using a fixed amount of symbols. Experiments with CS-DE, EN-FR\nand EN-DE NMT show that frequency alone accounts for 90%-95% of the scores\nreached by BPE, hence compositionality has less importance than previously\nthought.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wolleb_B/0/1/0/all/0/1\">Benoist Wolleb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silvestri_R/0/1/0/all/0/1\">Romain Silvestri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vernikos_G/0/1/0/all/0/1\">Giorgos Vernikos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dolamic_L/0/1/0/all/0/1\">Ljiljana Dolamic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popescu_Belis_A/0/1/0/all/0/1\">Andrei Popescu-Belis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Language Plasticity via Pretraining with Active Forgetting. (arXiv:2307.01163v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.01163","description":"<p>Pretrained language models (PLMs) are today the primary model for natural\nlanguage processing. Despite their impressive downstream performance, it can be\ndifficult to apply PLMs to new languages, a barrier to making their\ncapabilities universally accessible. While prior work has shown it possible to\naddress this issue by learning a new embedding layer for the new language,\ndoing so is both data and compute inefficient. We propose to use an active\nforgetting mechanism during pretraining, as a simple way of creating PLMs that\ncan quickly adapt to new languages. Concretely, by resetting the embedding\nlayer every K updates during pretraining, we encourage the PLM to improve its\nability of learning new embeddings within a limited number of updates, similar\nto a meta-learning effect. Experiments with RoBERTa show that models pretrained\nwith our forgetting mechanism not only demonstrate faster convergence during\nlanguage adaptation but also outperform standard ones in a low-data regime,\nparticularly for languages that are distant from English.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yihong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marchisio_K/0/1/0/all/0/1\">Kelly Marchisio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raileanu_R/0/1/0/all/0/1\">Roberta Raileanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1\">David Ifeoluwa Adelani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stenetorp_P/0/1/0/all/0/1\">Pontus Stenetorp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedel_S/0/1/0/all/0/1\">Sebastian Riedel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1\">Mikel Artetxe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lightweight reranking for language model generations. (arXiv:2307.06857v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2307.06857","description":"<p>Large Language Models (LLMs) can exhibit considerable variation in the\nquality of their sampled outputs. Reranking and selecting the best generation\nfrom the sampled set is a popular way of obtaining strong gains in generation\nquality. In this paper, we present a novel approach for reranking LLM\ngenerations. Unlike other techniques that might involve additional inferences\nor training a specialized reranker, our approach relies on easy to compute\npairwise statistics between the generations that have minimal compute overhead.\nWe show that our approach can be formalized as an extension of self-consistency\nand analyze its performance in that framework, theoretically as well as via\nsimulations. We show strong improvements for selecting the best k generations\nfor code generation tasks as well as robust improvements for the best\ngeneration for the tasks of autoformalization, summarization, and translation.\nWhile our approach only assumes black-box access to LLMs, we show that\nadditional access to token probabilities can improve performance even further.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Siddhartha Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaofei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deoras_A/0/1/0/all/0/1\">Anoop Deoras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_B/0/1/0/all/0/1\">Bing Xiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lip Reading for Low-resource Languages by Learning and Combining General Speech Knowledge and Language-specific Knowledge. (arXiv:2308.09311v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2308.09311","description":"<p>This paper proposes a novel lip reading framework, especially for\nlow-resource languages, which has not been well addressed in the previous\nliterature. Since low-resource languages do not have enough video-text paired\ndata to train the model to have sufficient power to model lip movements and\nlanguage, it is regarded as challenging to develop lip reading models for\nlow-resource languages. In order to mitigate the challenge, we try to learn\ngeneral speech knowledge, the ability to model lip movements, from a\nhigh-resource language through the prediction of speech units. It is known that\ndifferent languages partially share common phonemes, thus general speech\nknowledge learned from one language can be extended to other languages. Then,\nwe try to learn language-specific knowledge, the ability to model language, by\nproposing Language-specific Memory-augmented Decoder (LMDecoder). LMDecoder\nsaves language-specific audio features into memory banks and can be trained on\naudio-text paired data which is more easily accessible than video-text paired\ndata. Therefore, with LMDecoder, we can transform the input speech units into\nlanguage-specific audio features and translate them into texts by utilizing the\nlearned rich language knowledge. Finally, by combining general speech knowledge\nand language-specific knowledge, we can efficiently develop lip reading models\neven for low-resource languages. Through extensive experiments using five\nlanguages, English, Spanish, French, Italian, and Portuguese, the effectiveness\nof the proposed method is evaluated.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeo_J/0/1/0/all/0/1\">Jeong Hun Yeo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jeongsoo Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ro_Y/0/1/0/all/0/1\">Yong Man Ro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation. (arXiv:2308.12604v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2308.12604","description":"<p>Automatic medical report generation (MRG) is of great research value as it\nhas the potential to relieve radiologists from the heavy burden of report\nwriting. Despite recent advancements, accurate MRG remains challenging due to\nthe need for precise clinical understanding and disease identification.\nMoreover, the imbalanced distribution of diseases makes the challenge even more\npronounced, as rare diseases are underrepresented in training data, making\ntheir diagnostic performance unreliable. To address these challenges, we\npropose diagnosis-driven prompts for medical report generation (PromptMRG), a\nnovel framework that aims to improve the diagnostic accuracy of MRG with the\nguidance of diagnosis-aware prompts. Specifically, PromptMRG is based on\nencoder-decoder architecture with an extra disease classification branch. When\ngenerating reports, the diagnostic results from the classification branch are\nconverted into token prompts to explicitly guide the generation process. To\nfurther improve the diagnostic accuracy, we design cross-modal feature\nenhancement, which retrieves similar reports from the database to assist the\ndiagnosis of a query image by leveraging the knowledge from a pre-trained CLIP.\nMoreover, the disease imbalanced issue is addressed by applying an adaptive\nlogit-adjusted loss to the classification branch based on the individual\nlearning status of each disease, which overcomes the barrier of text decoder's\ninability to manipulate disease distributions. Experiments on two MRG\nbenchmarks show the effectiveness of the proposed method, where it obtains\nstate-of-the-art clinical efficacy performance on both datasets. The code is\navailable at https://github.com/jhb86253817/PromptMRG.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Haibo Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_H/0/1/0/all/0/1\">Haoxuan Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TIDE: Textual Identity Detection for Evaluating and Augmenting Classification and Language Models. (arXiv:2309.04027v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.04027","description":"<p>Machine learning models can perpetuate unintended biases from unfair and\nimbalanced datasets. Evaluating and debiasing these datasets and models is\nespecially hard in text datasets where sensitive attributes such as race,\ngender, and sexual orientation may not be available. When these models are\ndeployed into society, they can lead to unfair outcomes for historically\nunderrepresented groups. In this paper, we present a dataset coupled with an\napproach to improve text fairness in classifiers and language models. We create\na new, more comprehensive identity lexicon, TIDAL, which includes 15,123\nidentity terms and associated sense context across three demographic\ncategories. We leverage TIDAL to develop an identity annotation and\naugmentation tool that can be used to improve the availability of identity\ncontext and the effectiveness of ML fairness techniques. We evaluate our\napproaches using human contributors, and additionally run experiments focused\non dataset and model debiasing. Results show our assistive annotation technique\nimproves the reliability and velocity of human-in-the-loop processes. Our\ndataset and methods uncover more disparities during evaluation, and also\nproduce more fair models during remediation. These approaches provide a\npractical path forward for scaling classifier and generative model fairness in\nreal-world settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Klu_E/0/1/0/all/0/1\">Emmanuel Klu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sethi_S/0/1/0/all/0/1\">Sameer Sethi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dynamic ASR Pathways: An Adaptive Masking Approach Towards Efficient Pruning of A Multilingual ASR Model. (arXiv:2309.13018v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2309.13018","description":"<p>Neural network pruning offers an effective method for compressing a\nmultilingual automatic speech recognition (ASR) model with minimal performance\nloss. However, it entails several rounds of pruning and re-training needed to\nbe run for each language. In this work, we propose the use of an adaptive\nmasking approach in two scenarios for pruning a multilingual ASR model\nefficiently, each resulting in sparse monolingual models or a sparse\nmultilingual model (named as Dynamic ASR Pathways). Our approach dynamically\nadapts the sub-network, avoiding premature decisions about a fixed sub-network\nstructure. We show that our approach outperforms existing pruning methods when\ntargeting sparse monolingual models. Further, we illustrate that Dynamic ASR\nPathways jointly discovers and trains better sub-networks (pathways) of a\nsingle multilingual model by adapting from different sub-network\ninitializations, thereby reducing the need for language-specific pruning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Xie_J/0/1/0/all/0/1\">Jiamin Xie</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_K/0/1/0/all/0/1\">Ke Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guo_J/0/1/0/all/0/1\">Jinxi Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tjandra_A/0/1/0/all/0/1\">Andros Tjandra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shangguan_Y/0/1/0/all/0/1\">Yuan Shangguan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sari_L/0/1/0/all/0/1\">Leda Sari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_C/0/1/0/all/0/1\">Chunyang Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jia_J/0/1/0/all/0/1\">Junteng Jia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mahadeokar_J/0/1/0/all/0/1\">Jay Mahadeokar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kalinli_O/0/1/0/all/0/1\">Ozlem Kalinli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MedAI Dialog Corpus (MEDIC): Zero-Shot Classification of Doctor and AI Responses in Health Consultations. (arXiv:2310.12489v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12489","description":"<p>Zero-shot classification enables text to be classified into classes not seen\nduring training. In this study, we examine the efficacy of zero-shot learning\nmodels in classifying healthcare consultation responses from Doctors and AI\nsystems. The models evaluated include BART, BERT, XLM, XLM-R and DistilBERT.\nThe models were tested on three different datasets based on a binary and\nmulti-label analysis to identify the origins of text in health consultations\nwithout any prior corpus training. According to our findings, the zero-shot\nlanguage models show a good understanding of language generally, but has\nlimitations when trying to classify doctor and AI responses to healthcare\nconsultations. This research provides a foundation for future research in the\nfield of medical text classification by informing the development of more\naccurate methods of classifying text written by Doctors and AI systems in\nhealth consultations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ojo_O/0/1/0/all/0/1\">Olumide E. Ojo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adebanji_O/0/1/0/all/0/1\">Olaronke O. Adebanji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gelbukh_A/0/1/0/all/0/1\">Alexander Gelbukh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calvo_H/0/1/0/all/0/1\">Hiram Calvo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feldman_A/0/1/0/all/0/1\">Anna Feldman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"O3D: Offline Data-driven Discovery and Distillation for Sequential Decision-Making with Large Language Models. (arXiv:2310.14403v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.14403","description":"<p>Recent advancements in large language models (LLMs) have exhibited promising\nperformance in solving sequential decision-making problems. By imitating\nfew-shot examples provided in the prompts (i.e., in-context learning), an LLM\nagent can interact with an external environment and complete given tasks\nwithout additional training. However, such few-shot examples are often\ninsufficient to generate high-quality solutions for complex and long-horizon\ntasks, while the limited context length cannot consume larger-scale\ndemonstrations. To this end, we propose an offline learning framework that\nutilizes offline data at scale (e.g, logs of human interactions) to facilitate\nthe in-context learning performance of LLM agents. We formally define\nLLM-powered policies with both text-based approaches and code-based approaches.\nWe then introduce an Offline Data-driven Discovery and Distillation (O3D)\nframework to improve LLM-powered policies without finetuning. O3D automatically\ndiscovers reusable skills and distills generalizable knowledge across multiple\ntasks based on offline interaction data, advancing the capability of solving\ndownstream tasks. Empirical results under two interactive decision-making\nbenchmarks (ALFWorld and WebShop) demonstrate that O3D can notably enhance the\ndecision-making capabilities of LLMs through the offline discovery and\ndistillation process, and consistently outperform baselines across various LLMs\nwith both text-based-policy and code-based-policy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yuchen Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yanchao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mengda Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madhushani_U/0/1/0/all/0/1\">Udari Madhushani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vann_J/0/1/0/all/0/1\">Jared Vann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_D/0/1/0/all/0/1\">Deepeka Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganesh_S/0/1/0/all/0/1\">Sumitra Ganesh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Disentangled Representation Learning with Large Language Models for Text-Attributed Graphs. (arXiv:2310.18152v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.18152","description":"<p>Text-attributed graphs (TAGs) are prevalent on the web and research over TAGs\nsuch as citation networks, e-commerce networks and social networks has\nattracted considerable attention in the web community. Recently, large language\nmodels (LLMs) have demonstrated exceptional capabilities across a wide range of\ntasks. However, the existing works focus on harnessing the potential of LLMs\nsolely relying on prompts to convey graph structure information to LLMs, thus\nsuffering from insufficient understanding of the complex structural\nrelationships within TAGs. To address this problem, in this paper we present\nthe Disentangled Graph-Text Learner (DGTL) model, which is able to enhance the\nreasoning and predicting capabilities of LLMs for TAGs. Our proposed DGTL model\nincorporates graph structure information through tailored disentangled graph\nneural network (GNN) layers, enabling LLMs to capture the intricate\nrelationships hidden in text-attributed graphs from multiple structural\nfactors. Furthermore, DGTL operates with frozen pre-trained LLMs, reducing\ncomputational costs and allowing much more flexibility in combining with\ndifferent LLM models. Experimental evaluations demonstrate the effectiveness of\nthe proposed DGTL model on achieving superior or comparable performance over\nstate-of-the-art baselines. Additionally, we also demonstrate that our DGTL\nmodel can offer natural language explanations for predictions, thereby\nsignificantly enhancing model interpretability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yijian Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenwu Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multistage Collaborative Knowledge Distillation from Large Language Models for Semi-Supervised Sequence Generation. (arXiv:2311.08640v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.08640","description":"<p>We study semi-supervised sequence generation tasks where labeled data are too\nscarce to effectively finetune a model and at the same time few-shot prompting\nof a large language model (LLM) has suboptimal performance. This happens when a\ntask, such as parsing, is expensive to annotate and also unfamiliar to a\npretrained LLM. In this paper, we present a discovery that student models\ndistilled from an in-context learned LLM can often generalize better than their\nteacher on such tasks. Leveraging this finding, we present a new method --\nmultistage collaborative knowledge distillation from an LLM (MCKD) -- for such\ntasks. MCKD first few-shot prompts an LLM to produce pseudolabels for unlabeled\ndata. At each intermediate knowledge distillation (KD) stage, a new pair of\nstudents is trained on disjoint partitions of the pseudolabeled data. Each\nstudent then produces new and improved pseudolabels for its unseen partition to\nbe used in the next stage of distillation. We demonstrate the advantage of\nmultistage cross-partition labeling on several syntactic and semantic parsing\ntasks. On CRAFT biomedical parsing, for example, 3-stage MCKD with 50 labeled\nexamples outperforms the prompted LLM and vanilla KD by 7.5% and 3.7% parsing\nF1, respectively, and matches the performance of supervised finetuning with 500\nexamples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jiachen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wenlong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drozdov_A/0/1/0/all/0/1\">Andrew Drozdov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rozonoyer_B/0/1/0/all/0/1\">Benjamin Rozonoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sultan_M/0/1/0/all/0/1\">Md Arafat Sultan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jay-Yoon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1\">Mohit Iyyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1\">Andrew McCallum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mergen: The First Manchu-Korean Machine Translation Model Trained on Augmented Data. (arXiv:2311.17492v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.17492","description":"<p>The Manchu language, with its roots in the historical Manchurian region of\nNortheast China, is now facing a critical threat of extinction, as there are\nvery few speakers left. In our efforts to safeguard the Manchu language, we\nintroduce Mergen, the first-ever attempt at a Manchu-Korean Machine Translation\n(MT) model. To develop this model, we utilize valuable resources such as the\nManwen Laodang(a historical book) and a Manchu-Korean dictionary. Due to the\nscarcity of a Manchu-Korean parallel dataset, we expand our data by employing\nword replacement guided by GloVe embeddings, trained on both monolingual and\nparallel texts. Our approach is built around an encoder-decoder neural machine\ntranslation model, incorporating a bi-directional Gated Recurrent Unit (GRU)\nlayer. The experiments have yielded promising results, showcasing a significant\nenhancement in Manchu-Korean translation, with a remarkable 20-30 point\nincrease in the BLEU score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1\">Jean Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byun_S/0/1/0/all/0/1\">Sungjoo Byun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Minha Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sangah Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes. (arXiv:2312.14890v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2312.14890","description":"<p>Complex reasoning ability is one of the most important features of current\nLLMs, which has also been leveraged to play an integral role in complex\ndecision-making tasks. Therefore, the investigation into the reasoning\ncapabilities of Large Language Models (LLMs) is critical: numerous benchmarks\nhave been established to assess the reasoning abilities of LLMs. However,\ncurrent benchmarks are inadequate in offering a rigorous evaluation of the full\nextent of reasoning abilities that LLMs are capable of achieving. They are also\nprone to the risk of overfitting, as these benchmarks, being publicly\naccessible and static, allow models to potentially tailor their responses to\nspecific benchmark metrics, thereby inflating their performance. Addressing\nthese limitations, our research introduces a new benchmark, named NPHardEval.\nThis benchmark is designed to evaluate the reasoning abilities of LLMs across a\nbroad spectrum of 900 algorithmic questions, extending up to the NP-Hard\ncomplexity class. These questions are meticulously chosen to represent a wide\nrange of complexity class below the NP-hard complexity class, offering a\nrigorous measure of the reasoning ability of LLMs. Through this study, we shed\nlight on the current state of reasoning in LLMs, providing an objective and\nrigorous perspective through the comparison of LLMs' performance across complex\nclasses. Moreover, this benchmark is designed with a dynamic update mechanism,\nwhere the datapoints are refreshed on a monthly basis. Such regular updates\nplay a crucial role in mitigating the risk of LLMs overfitting to the\nbenchmark, promoting a more accurate and reliable assessment of their reasoning\ncapabilities. The benchmark dataset and code of NPHardEval are available at\nhttps://github.com/casmlab/NPHardEval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Lizhou Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wenyue Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lingyao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1\">Haoyang Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stateful Conformer with Cache-based Inference for Streaming Automatic Speech Recognition. (arXiv:2312.17279v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.17279","description":"<p>In this paper, we propose an efficient and accurate streaming speech\nrecognition model based on the FastConformer architecture. We adapted the\nFastConformer architecture for streaming applications through: (1) constraining\nboth the look-ahead and past contexts in the encoder, and (2) introducing an\nactivation caching mechanism to enable the non-autoregressive encoder to\noperate autoregressively during inference. The proposed model is thoughtfully\ndesigned in a way to eliminate the accuracy disparity between the train and\ninference time which is common for many streaming models. Furthermore, our\nproposed encoder works with various decoder configurations including\nConnectionist Temporal Classification (CTC) and RNN-Transducer (RNNT) decoders.\nAdditionally, we introduced a hybrid CTC/RNNT architecture which utilizes a\nshared encoder with both a CTC and RNNT decoder to boost the accuracy and save\ncomputation. We evaluate the proposed model on LibriSpeech dataset and a\nmulti-domain large scale dataset and demonstrate that it can achieve better\naccuracy with lower latency and inference time compared to a conventional\nbuffered streaming model baseline. We also showed that training a model with\nmultiple latencies can achieve better accuracy than single latency models while\nit enables us to support multiple latencies with a single model. Our\nexperiments also showed the hybrid architecture would not only speedup the\nconvergence of the CTC decoder but also improves the accuracy of streaming\nmodels compared to single decoder models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Noroozi_V/0/1/0/all/0/1\">Vahid Noroozi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majumdar_S/0/1/0/all/0/1\">Somshubra Majumdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Ankur Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balam_J/0/1/0/all/0/1\">Jagadeesh Balam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginsburg_B/0/1/0/all/0/1\">Boris Ginsburg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLaMA Beyond English: An Empirical Study on Language Capability Transfer. (arXiv:2401.01055v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01055","description":"<p>In recent times, substantial advancements have been witnessed in large\nlanguage models (LLMs), exemplified by ChatGPT, showcasing remarkable\nproficiency across a range of complex tasks. However, many mainstream LLMs\n(e.g. LLaMA) are pretrained on English-dominant corpus, which limits their\nperformance in other non-English languages. In this paper, we focus on how to\neffectively transfer the capabilities of language generation and following\ninstructions to a non-English language. To answer this question, we conduct an\nextensive empirical investigation based on LLaMA, accumulating over 1440 GPU\nhours. We analyze the impact of key factors such as vocabulary extension,\nfurther pretraining, and instruction tuning on transfer. To accurately assess\nthe model's level of knowledge, we employ four widely used standardized testing\nbenchmarks: C-Eval, MMLU, AGI-Eval, and GAOKAO-Bench. Furthermore, a\ncomprehensive evaluation of the model's response quality is conducted,\nconsidering aspects such as accuracy, fluency, informativeness, logical\ncoherence, and harmlessness, based on LLM-Eval, a benchmarks consisting\ninstruction tasks from 17 diverse categories. Our evaluation results\ndemonstrate that comparable performance to state-of-the-art transfer models can\nbe achieved with less than 1% of the pretraining data, both in terms of\nknowledge alignment and response quality. Furthermore, the experimental\noutcomes across the thirteen low-resource languages also exhibit similar\ntrends. We anticipate that the conclusions revealed by the experiments will aid\nthe community in developing non-English LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Luhui Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can AI Be as Creative as Humans?. (arXiv:2401.01623v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2401.01623","description":"<p>Creativity serves as a cornerstone for societal progress and innovation. With\nthe rise of advanced generative AI models capable of tasks once reserved for\nhuman creativity, the study of AI's creative potential becomes imperative for\nits responsible development and application. In this paper, we provide a\ntheoretical answer to the question of whether AI can be creative. We prove in\ntheory that AI can be as creative as humans under the condition that AI can fit\nthe existing data generated by human creators. Therefore, the debate on AI's\ncreativity is reduced into the question of its ability of fitting a massive\namount of data. To arrive at this conclusion, this paper first addresses the\ncomplexities in defining creativity by introducing a new concept called\nRelative Creativity. Instead of trying to define creativity universally, we\nshift the focus to whether AI can match the creative abilities of a\nhypothetical human. This perspective draws inspiration from the Turing Test,\nexpanding upon it to address the challenges and subjectivities inherent in\nassessing creativity. This methodological shift leads to a statistically\nquantifiable assessment of AI's creativity, which we term Statistical\nCreativity. This concept allows for comparisons of AI's creative abilities with\nthose of specific human groups, and facilitates the theoretical findings of\nAI's creative potential. Building on this foundation, we discuss the\napplication of statistical creativity in prompt-conditioned autoregressive\nmodels, providing a practical means for evaluating creative abilities of\ncontemporary AI models, such as Large Language Models (LLMs). In addition to\ndefining and analyzing creativity, we introduce an actionable training\nguideline, effectively bridging the gap between theoretical quantification of\ncreativity and practical model training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haonan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1\">Michael Mozer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1\">Anirudh Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamb_A/0/1/0/all/0/1\">Alex Lamb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Weijie J Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhun Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_M/0/1/0/all/0/1\">Michael Qizhe Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_H/0/1/0/all/0/1\">Hannah Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MERA: A Comprehensive LLM Evaluation in Russian. (arXiv:2401.04531v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.04531","description":"<p>Over the past few years, one of the most notable advancements in AI research\nhas been in foundation models (FMs), headlined by the rise of language models\n(LMs). As the models' size increases, LMs demonstrate enhancements in\nmeasurable aspects and the development of new qualitative features. However,\ndespite researchers' attention and the rapid growth in LM application, the\ncapabilities, limitations, and associated risks still need to be better\nunderstood. To address these issues, we introduce an open Multimodal Evaluation\nof Russian-language Architectures (MERA), a new instruction benchmark for\nevaluating foundation models oriented towards the Russian language. The\nbenchmark encompasses 21 evaluation tasks for generative models in 11 skill\ndomains and is designed as a black-box test to ensure the exclusion of data\nleakage. The paper introduces a methodology to evaluate FMs and LMs in zero-\nand few-shot fixed instruction settings that can be extended to other\nmodalities. We propose an evaluation methodology, an open-source code base for\nthe MERA assessment, and a leaderboard with a submission system. We evaluate\nopen LMs as baselines and find that they are still far behind the human level.\nWe publicly release MERA to guide forthcoming research, anticipate\ngroundbreaking model features, standardize the evaluation procedure, and\naddress potential societal drawbacks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fenogenova_A/0/1/0/all/0/1\">Alena Fenogenova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chervyakov_A/0/1/0/all/0/1\">Artem Chervyakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martynov_N/0/1/0/all/0/1\">Nikita Martynov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kozlova_A/0/1/0/all/0/1\">Anastasia Kozlova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tikhonova_M/0/1/0/all/0/1\">Maria Tikhonova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhmetgareeva_A/0/1/0/all/0/1\">Albina Akhmetgareeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emelyanov_A/0/1/0/all/0/1\">Anton Emelyanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shevelev_D/0/1/0/all/0/1\">Denis Shevelev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lebedev_P/0/1/0/all/0/1\">Pavel Lebedev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinev_L/0/1/0/all/0/1\">Leonid Sinev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isaeva_U/0/1/0/all/0/1\">Ulyana Isaeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolomeytseva_K/0/1/0/all/0/1\">Katerina Kolomeytseva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moskovskiy_D/0/1/0/all/0/1\">Daniil Moskovskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goncharova_E/0/1/0/all/0/1\">Elizaveta Goncharova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savushkin_N/0/1/0/all/0/1\">Nikita Savushkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikhailova_P/0/1/0/all/0/1\">Polina Mikhailova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimitrov_D/0/1/0/all/0/1\">Denis Dimitrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panchenko_A/0/1/0/all/0/1\">Alexander Panchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markov_S/0/1/0/all/0/1\">Sergei Markov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation. (arXiv:2401.04679v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.04679","description":"<p>We investigate parameter-efficient fine-tuning (PEFT) methods that can\nprovide good accuracy under limited computational and memory budgets in the\ncontext of large language models (LLMs). We present a new PEFT method called\nRobust Adaptation (RoSA) inspired by robust principal component analysis (PCA)\nthat jointly trains $\\textit{low-rank}$ and $\\textit{highly-sparse}$ components\non top of a set of fixed pretrained weights to efficiently approximate the\nperformance of a full-fine-tuning (FFT) solution. Across a series of\nchallenging generative tasks such as grade-school math and SQL query\ngeneration, which require fine-tuning for good performance, we show that RoSA\noutperforms both LoRA and pure sparse fine-tuning, at the same parameter\nbudget. We provide system support for RoSA to complement the training\nalgorithm, specifically in the form of sparse GPU kernels which enable memory-\nand computationally-efficient training. Our code will be made available at\nhttps://github.com/IST-DASLab/RoSA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nikdan_M/0/1/0/all/0/1\">Mahdi Nikdan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabesh_S/0/1/0/all/0/1\">Soroush Tabesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1\">Dan Alistarh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training. (arXiv:2401.05566v2 [cs.CR] UPDATED)","link":"http://arxiv.org/abs/2401.05566","description":"<p>Humans are capable of strategically deceptive behavior: behaving helpfully in\nmost situations, but then behaving very differently in order to pursue\nalternative objectives when given the opportunity. If an AI system learned such\na deceptive strategy, could we detect it and remove it using current\nstate-of-the-art safety training techniques? To study this question, we\nconstruct proof-of-concept examples of deceptive behavior in large language\nmodels (LLMs). For example, we train models that write secure code when the\nprompt states that the year is 2023, but insert exploitable code when the\nstated year is 2024. We find that such backdoor behavior can be made\npersistent, so that it is not removed by standard safety training techniques,\nincluding supervised fine-tuning, reinforcement learning, and adversarial\ntraining (eliciting unsafe behavior and then training to remove it). The\nbackdoor behavior is most persistent in the largest models and in models\ntrained to produce chain-of-thought reasoning about deceiving the training\nprocess, with the persistence remaining even when the chain-of-thought is\ndistilled away. Furthermore, rather than removing backdoors, we find that\nadversarial training can teach models to better recognize their backdoor\ntriggers, effectively hiding the unsafe behavior. Our results suggest that,\nonce a model exhibits deceptive behavior, standard techniques could fail to\nremove such deception and create a false impression of safety.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hubinger_E/0/1/0/all/0/1\">Evan Hubinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denison_C/0/1/0/all/0/1\">Carson Denison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_J/0/1/0/all/0/1\">Jesse Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lambert_M/0/1/0/all/0/1\">Mike Lambert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_M/0/1/0/all/0/1\">Meg Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MacDiarmid_M/0/1/0/all/0/1\">Monte MacDiarmid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lanham_T/0/1/0/all/0/1\">Tamera Lanham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziegler_D/0/1/0/all/0/1\">Daniel M. Ziegler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maxwell_T/0/1/0/all/0/1\">Tim Maxwell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_N/0/1/0/all/0/1\">Newton Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jermyn_A/0/1/0/all/0/1\">Adam Jermyn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Askell_A/0/1/0/all/0/1\">Amanda Askell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radhakrishnan_A/0/1/0/all/0/1\">Ansh Radhakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anil_C/0/1/0/all/0/1\">Cem Anil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1\">David Duvenaud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguli_D/0/1/0/all/0/1\">Deep Ganguli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barez_F/0/1/0/all/0/1\">Fazl Barez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1\">Jack Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ndousse_K/0/1/0/all/0/1\">Kamal Ndousse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_K/0/1/0/all/0/1\">Kshitij Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sellitto_M/0/1/0/all/0/1\">Michael Sellitto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1\">Mrinank Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DasSarma_N/0/1/0/all/0/1\">Nova DasSarma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grosse_R/0/1/0/all/0/1\">Roger Grosse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kravec_S/0/1/0/all/0/1\">Shauna Kravec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yuntao Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witten_Z/0/1/0/all/0/1\">Zachary Witten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Favaro_M/0/1/0/all/0/1\">Marina Favaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brauner_J/0/1/0/all/0/1\">Jan Brauner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karnofsky_H/0/1/0/all/0/1\">Holden Karnofsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christiano_P/0/1/0/all/0/1\">Paul Christiano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1\">Samuel R. Bowman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graham_L/0/1/0/all/0/1\">Logan Graham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaplan_J/0/1/0/all/0/1\">Jared Kaplan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mindermann_S/0/1/0/all/0/1\">S&#xf6;ren Mindermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenblatt_R/0/1/0/all/0/1\">Ryan Greenblatt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shlegeris_B/0/1/0/all/0/1\">Buck Shlegeris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiefer_N/0/1/0/all/0/1\">Nicholas Schiefer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_E/0/1/0/all/0/1\">Ethan Perez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generative Deduplication For Socia Media Data Selection. (arXiv:2401.05883v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.05883","description":"<p>Social media data is plagued by the redundancy problem caused by its noisy\nnature, leading to increased training time and model bias. To address this\nissue, we propose a novel approach called generative deduplication. It aims to\nremove duplicate text from noisy social media data and mitigate model bias. By\ndoing so, it can improve social media language understanding performance and\nsave training time. Extensive experiments demonstrate that the proposed\ngenerative deduplication can effectively reduce training samples while\nimproving performance. This evidence suggests the effectiveness of generative\ndeduplication and its importance in social media language understanding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xianming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jing Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks. (arXiv:2401.05949v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.05949","description":"<p>In-context learning, a paradigm bridging the gap between pre-training and\nfine-tuning, has demonstrated high efficacy in several NLP tasks, especially in\nfew-shot settings. Unlike traditional fine-tuning methods, in-context learning\nadapts pre-trained models to unseen tasks without updating any parameters.\nDespite being widely applied, in-context learning is vulnerable to malicious\nattacks. In this work, we raise security concerns regarding this paradigm. Our\nstudies demonstrate that an attacker can manipulate the behavior of large\nlanguage models by poisoning the demonstration context, without the need for\nfine-tuning the model. Specifically, we have designed a new backdoor attack\nmethod, named ICLAttack, to target large language models based on in-context\nlearning. Our method encompasses two types of attacks: poisoning demonstration\nexamples and poisoning prompts, which can make models behave in accordance with\npredefined intentions. ICLAttack does not require additional fine-tuning to\nimplant a backdoor, thus preserving the model's generality. Furthermore, the\npoisoned examples are correctly labeled, enhancing the natural stealth of our\nattack method. Extensive experimental results across several language models,\nranging in size from 1.3B to 40B parameters, demonstrate the effectiveness of\nour attack method, exemplified by a high average attack success rate of 95.0%\nacross the three datasets on OPT models. Our findings highlight the\nvulnerabilities of language models, and we hope this work will raise awareness\nof the possible security threats associated with in-context learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shuai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_M/0/1/0/all/0/1\">Meihuizi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuan_L/0/1/0/all/0/1\">Luu Anh Tuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Jinming Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LEGO:Language Enhanced Multi-modal Grounding Model. (arXiv:2401.06071v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2401.06071","description":"<p>Multi-modal large language models have demonstrated impressive performance\nacross various tasks in different modalities. However, existing multi-modal\nmodels primarily emphasize capturing global information within each modality\nwhile neglecting the importance of perceiving local information across\nmodalities. Consequently, these models lack the ability to effectively\nunderstand the fine-grained details of input data, limiting their performance\nin tasks that require a more nuanced understanding. To address this limitation,\nthere is a compelling need to develop models that enable fine-grained\nunderstanding across multiple modalities, thereby enhancing their applicability\nto a wide range of tasks. In this paper, we propose LEGO, a language enhanced\nmulti-modal grounding model. Beyond capturing global information like other\nmulti-modal models, our proposed model excels at tasks demanding a detailed\nunderstanding of local information within the input. It demonstrates precise\nidentification and localization of specific regions in images or moments in\nvideos. To achieve this objective, we design a diversified dataset construction\npipeline, resulting in a multi-modal, multi-granularity dataset for model\ntraining. The code, dataset, and demo of our model can be found at https:\n//github.com/lzw-lzw/LEGO.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhaowei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yiqing Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1\">Qi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1\">Ran Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Junting Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zefeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_V/0/1/0/all/0/1\">Van Tu Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhida Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tao Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Patchscopes: A Unifying Framework for Inspecting Hidden Representations of Language Models. (arXiv:2401.06102v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.06102","description":"<p>Inspecting the information encoded in hidden representations of large\nlanguage models (LLMs) can explain models' behavior and verify their alignment\nwith human values. Given the capabilities of LLMs in generating\nhuman-understandable text, we propose leveraging the model itself to explain\nits internal representations in natural language. We introduce a framework\ncalled Patchscopes and show how it can be used to answer a wide range of\nquestions about an LLM's computation. We show that prior interpretability\nmethods based on projecting representations into the vocabulary space and\nintervening on the LLM computation can be viewed as instances of this\nframework. Moreover, several of their shortcomings such as failure in\ninspecting early layers or lack of expressivity can be mitigated by\nPatchscopes. Beyond unifying prior inspection techniques, Patchscopes also\nopens up new possibilities such as using a more capable model to explain the\nrepresentations of a smaller model, and unlocks new applications such as\nself-correction in multi-hop reasoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghandeharioun_A/0/1/0/all/0/1\">Asma Ghandeharioun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1\">Avi Caciularu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pearce_A/0/1/0/all/0/1\">Adam Pearce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dixon_L/0/1/0/all/0/1\">Lucas Dixon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geva_M/0/1/0/all/0/1\">Mor Geva</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2024-01-14T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#"}}]}]}