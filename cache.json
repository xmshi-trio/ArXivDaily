{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-08-24T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Learning to generate and corr- uh I mean repair language in real-time. (arXiv:2308.11683v1 [cs.CL])","link":"http://arxiv.org/abs/2308.11683","description":"<p>In conversation, speakers produce language incrementally, word by word, while\ncontinuously monitoring the appropriateness of their own contribution in the\ndynamically unfolding context of the conversation; and this often leads them to\nrepair their own utterance on the fly. This real-time language processing\ncapacity is furthermore crucial to the development of fluent and natural\nconversational AI. In this paper, we use a previously learned Dynamic Syntax\ngrammar and the CHILDES corpus to develop, train and evaluate a probabilistic\nmodel for incremental generation where input to the model is a purely semantic\ngeneration goal concept in Type Theory with Records (TTR). We show that the\nmodel's output exactly matches the gold candidate in 78% of cases with a\nROUGE-l score of 0.86. We further do a zero-shot evaluation of the ability of\nthe same model to generate self-repairs when the generation goal changes\nmid-utterance. Automatic evaluation shows that the model can generate\nself-repairs correctly in 85% of cases. A small human evaluation confirms the\nnaturalness and grammaticality of the generated self-repairs. Overall, these\nresults further highlight the generalisation power of grammar-based models and\nlay the foundations for more controllable, and naturally interactive\nconversational AI systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Eshghi_A/0/1/0/all/0/1\">Arash Eshghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashrafzadeh_A/0/1/0/all/0/1\">Arash Ashrafzadeh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Benchmarking (of Language Models). (arXiv:2308.11696v1 [cs.CL])","link":"http://arxiv.org/abs/2308.11696","description":"<p>The increasing versatility of language models LMs has given rise to a new\nclass of benchmarks that comprehensively assess a broad range of capabilities.\nSuch benchmarks are associated with massive computational costs reaching\nthousands of GPU hours per model. However the efficiency aspect of these\nevaluation efforts had raised little discussion in the literature. In this work\nwe present the problem of Efficient Benchmarking namely intelligently reducing\nthe computation costs of LM evaluation without compromising reliability. Using\nthe HELM benchmark as a test case we investigate how different benchmark design\nchoices affect the computation-reliability tradeoff. We propose to evaluate the\nreliability of such decisions by using a new measure Decision Impact on\nReliability DIoR for short. We find for example that the current leader on HELM\nmay change by merely removing a low-ranked model from the benchmark and observe\nthat a handful of examples suffice to obtain the correct benchmark ranking.\nConversely a slightly different choice of HELM scenarios varies ranking widely.\nBased on our findings we outline a set of concrete recommendations for more\nefficient benchmark design and utilization practices leading to dramatic cost\nsavings with minimal loss of benchmark reliability often reducing computation\nby x100 or more.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Perlitz_Y/0/1/0/all/0/1\">Yotam Perlitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bandel_E/0/1/0/all/0/1\">Elron Bandel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gera_A/0/1/0/all/0/1\">Ariel Gera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arviv_O/0/1/0/all/0/1\">Ofir Arviv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ein_Dor_L/0/1/0/all/0/1\">Liat Ein-Dor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shnarch_E/0/1/0/all/0/1\">Eyal Shnarch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slonim_N/0/1/0/all/0/1\">Noam Slonim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shmueli_Scheuer_M/0/1/0/all/0/1\">Michal Shmueli-Scheuer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1\">Leshem Choshen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Advancing Relation Extraction through Language Probing with Exemplars from Set Co-Expansion. (arXiv:2308.11720v1 [cs.CL])","link":"http://arxiv.org/abs/2308.11720","description":"<p>Relation Extraction (RE) is a pivotal task in automatically extracting\nstructured information from unstructured text. In this paper, we present a\nmulti-faceted approach that integrates representative examples and through\nco-set expansion. The primary goal of our method is to enhance relation\nclassification accuracy and mitigating confusion between contrastive classes.\n</p>\n<p>Our approach begins by seeding each relationship class with representative\nexamples. Subsequently, our co-set expansion algorithm enriches training\nobjectives by incorporating similarity measures between target pairs and\nrepresentative pairs from the target class. Moreover, the co-set expansion\nprocess involves a class ranking procedure that takes into account exemplars\nfrom contrastive classes. Contextual details encompassing relation mentions are\nharnessed via context-free Hearst patterns to ascertain contextual similarity.\n</p>\n<p>Empirical evaluation demonstrates the efficacy of our co-set expansion\napproach, resulting in a significant enhancement of relation classification\nperformance. Our method achieves an observed margin of at least 1 percent\nimprovement in accuracy in most settings, on top of existing fine-tuning\napproaches. To further refine our approach, we conduct an in-depth analysis\nthat focuses on tuning contrastive examples. This strategic selection and\ntuning effectively reduce confusion between classes sharing similarities,\nleading to a more precise classification process.\n</p>\n<p>Experimental results underscore the effectiveness of our proposed framework\nfor relation extraction. The synergy between co-set expansion and context-aware\nprompt tuning substantially contributes to improved classification accuracy.\nFurthermore, the reduction in confusion between contrastive classes through\ncontrastive examples tuning validates the robustness and reliability of our\nmethod.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yerong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Girju_R/0/1/0/all/0/1\">Roxana Girju</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Graph Prompting for Multi-Document Question Answering. (arXiv:2308.11730v1 [cs.CL])","link":"http://arxiv.org/abs/2308.11730","description":"<p>The 'pre-train, prompt, predict' paradigm of large language models (LLMs) has\nachieved remarkable success in open-domain question answering (OD-QA). However,\nfew works explore this paradigm in the scenario of multi-document question\nanswering (MD-QA), a task demanding a thorough understanding of the logical\nassociations among the contents and structures of different documents. To fill\nthis crucial gap, we propose a Knowledge Graph Prompting (KGP) method to\nformulate the right context in prompting LLMs for MD-QA, which consists of a\ngraph construction module and a graph traversal module. For graph construction,\nwe create a knowledge graph (KG) over multiple documents with nodes symbolizing\npassages or document structures (e.g., pages/tables), and edges denoting the\nsemantic/lexical similarity between passages or intra-document structural\nrelations. For graph traversal, we design an LM-guided graph traverser that\nnavigates across nodes and gathers supporting passages assisting LLMs in MD-QA.\nThe constructed graph serves as the global ruler that regulates the\ntransitional space among passages and reduces retrieval latency. Concurrently,\nthe LM-guided traverser acts as a local navigator that gathers pertinent\ncontext to progressively approach the question and guarantee retrieval quality.\nExtensive experiments underscore the efficacy of KGP for MD-QA, signifying the\npotential of leveraging graphs in enhancing the prompt design for LLMs. Our\ncode is at https://github.com/YuWVandy/KG-LLM-MDQA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipka_N/0/1/0/all/0/1\">Nedim Lipka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_R/0/1/0/all/0/1\">Ryan A. Rossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siu_A/0/1/0/all/0/1\">Alexa Siu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruiyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Derr_T/0/1/0/all/0/1\">Tyler Derr</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KnowledGPT: Enhancing Large Language Models with Retrieval and Storage Access on Knowledge Bases. (arXiv:2308.11761v1 [cs.CL])","link":"http://arxiv.org/abs/2308.11761","description":"<p>Large language models (LLMs) have demonstrated impressive impact in the field\nof natural language processing, but they still struggle with several issues\nregarding, such as completeness, timeliness, faithfulness and adaptability.\nWhile recent efforts have focuses on connecting LLMs with external knowledge\nsources, the integration of knowledge bases (KBs) remains understudied and\nfaces several challenges. In this paper, we introduce KnowledGPT, a\ncomprehensive framework to bridge LLMs with various knowledge bases,\nfacilitating both the retrieval and storage of knowledge. The retrieval process\nemploys the program of thought prompting, which generates search language for\nKBs in code format with pre-defined functions for KB operations. Besides\nretrieval, KnowledGPT offers the capability to store knowledge in a\npersonalized KB, catering to individual user demands. With extensive\nexperiments, we show that by integrating LLMs with KBs, KnowledGPT properly\nanswers a broader range of questions requiring world knowledge compared with\nvanilla LLMs, utilizing both knowledge existing in widely-known KBs and\nextracted into personalized KBs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xintao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qianwen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yongting Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jiaqing Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1\">Qianyu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1\">Zhouhong Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yanghua Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models. (arXiv:2308.11764v1 [cs.CL])","link":"http://arxiv.org/abs/2308.11764","description":"<p>Large Language Models (LLMs) have revolutionized Natural Language Processing\n(NLP). Although convenient for research and practical applications, open-source\nLLMs with fewer parameters often suffer from severe hallucinations compared to\ntheir larger counterparts. This paper focuses on measuring and reducing\nhallucinations in BLOOM 7B, a representative of such weaker open-source LLMs\nthat are publicly available for research and commercial applications. We\nintroduce HaloCheck, a lightweight BlackBox knowledge-free framework designed\nto quantify the severity of hallucinations in LLMs. Additionally, we explore\ntechniques like knowledge injection and teacher-student approaches to alleviate\nhallucinations in low-parameter LLMs. Our experiments effectively demonstrate\nthe reduction of hallucinations in challenging domains for these LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Elaraby_M/0/1/0/all/0/1\">Mohamed Elaraby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1\">Mengyin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunn_J/0/1/0/all/0/1\">Jacob Dunn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xueying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shizhu Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Detection of ChatGPT-Generated Fake Science Using Real Publication Text: Introducing xFakeBibs a Supervised-Learning Network Algorithm. (arXiv:2308.11767v1 [cs.CL])","link":"http://arxiv.org/abs/2308.11767","description":"<p>ChatGPT is becoming a new reality. In this paper, we show how to distinguish\nChatGPT-generated publications from counterparts produced by scientists. Using\na newly designed supervised Machine Learning algorithm, we demonstrate how to\ndetect machine-generated publications from those produced by scientists. The\nalgorithm was trained using 100 real publication abstracts, followed by a\n10-fold calibration approach to establish a lower-upper bound range of\nacceptance. In the comparison with ChatGPT content, it was evident that ChatGPT\ncontributed merely 23\\% of the bigram content, which is less than 50\\% of any\nof the other 10 calibrating folds. This analysis highlights a significant\ndisparity in technical terms where ChatGPT fell short of matching real science.\nWhen categorizing the individual articles, the xFakeBibs algorithm accurately\nidentified 98 out of 100 publications as fake, with 2 articles incorrectly\nclassified as real publications. Though this work introduced an algorithmic\napproach that detected the ChatGPT-generated fake science with a high degree of\naccuracy, it remains challenging to detect all fake records. This work is\nindeed a step in the right direction to counter fake science and\nmisinformation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hamed_A/0/1/0/all/0/1\">Ahmed Abdeen Hamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xindong Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Identifying depression-related topics in smartphone-collected free-response speech recordings using an automatic speech recognition system and a deep learning topic model. (arXiv:2308.11773v1 [cs.CL])","link":"http://arxiv.org/abs/2308.11773","description":"<p>Language use has been shown to correlate with depression, but large-scale\nvalidation is needed. Traditional methods like clinic studies are expensive.\nSo, natural language processing has been employed on social media to predict\ndepression, but limitations remain-lack of validated labels, biased user\nsamples, and no context. Our study identified 29 topics in 3919\nsmartphone-collected speech recordings from 265 participants using the Whisper\ntool and BERTopic model. Six topics with a median PHQ-8 greater than or equal\nto 10 were regarded as risk topics for depression: No Expectations, Sleep,\nMental Therapy, Haircut, Studying, and Coursework. To elucidate the topic\nemergence and associations with depression, we compared behavioral (from\nwearables) and linguistic characteristics across identified topics. The\ncorrelation between topic shifts and changes in depression severity over time\nwas also investigated, indicating the importance of longitudinally monitoring\nlanguage use. We also tested the BERTopic model on a similar smaller dataset\n(356 speech recordings from 57 participants), obtaining some consistent\nresults. In summary, our findings demonstrate specific speech topics may\nindicate depression severity. The presented data-driven workflow provides a\npractical approach to collecting and analyzing large-scale speech data from\nreal-world settings for digital health research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuezhou Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Folarin_A/0/1/0/all/0/1\">Amos A Folarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dineley_J/0/1/0/all/0/1\">Judith Dineley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conde_P/0/1/0/all/0/1\">Pauline Conde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angel_V/0/1/0/all/0/1\">Valeria de Angel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shaoxiong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranjan_Y/0/1/0/all/0/1\">Yatharth Ranjan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashid_Z/0/1/0/all/0/1\">Zulqarnain Rashid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stewart_C/0/1/0/all/0/1\">Callum Stewart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laiou_P/0/1/0/all/0/1\">Petroula Laiou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankesara_H/0/1/0/all/0/1\">Heet Sankesara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_L/0/1/0/all/0/1\">Linglong Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matcham_F/0/1/0/all/0/1\">Faith Matcham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_K/0/1/0/all/0/1\">Katie M White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oetzmann_C/0/1/0/all/0/1\">Carolin Oetzmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamers_F/0/1/0/all/0/1\">Femke Lamers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddi_S/0/1/0/all/0/1\">Sara Siddi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simblett_S/0/1/0/all/0/1\">Sara Simblett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1\">Bj&#xf6;rn W. Schuller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vairavan_S/0/1/0/all/0/1\">Srinivasan Vairavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wykes_T/0/1/0/all/0/1\">Til Wykes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haro_J/0/1/0/all/0/1\">Josep Maria Haro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Penninx_B/0/1/0/all/0/1\">Brenda WJH Penninx</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayan_V/0/1/0/all/0/1\">Vaibhav A Narayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hotopf_M/0/1/0/all/0/1\">Matthew Hotopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dobson_R/0/1/0/all/0/1\">Richard JB Dobson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cummins_N/0/1/0/all/0/1\">Nicholas Cummins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+consortium_R/0/1/0/all/0/1\">RADAR-CNS consortium</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Few-shot Anomaly Detection in Text with Deviation Learning. (arXiv:2308.11780v1 [cs.LG])","link":"http://arxiv.org/abs/2308.11780","description":"<p>Most current methods for detecting anomalies in text concentrate on\nconstructing models solely relying on unlabeled data. These models operate on\nthe presumption that no labeled anomalous examples are available, which\nprevents them from utilizing prior knowledge of anomalies that are typically\npresent in small numbers in many real-world applications. Furthermore, these\nmodels prioritize learning feature embeddings rather than optimizing anomaly\nscores directly, which could lead to suboptimal anomaly scoring and inefficient\nuse of data during the learning process. In this paper, we introduce FATE, a\ndeep few-shot learning-based framework that leverages limited anomaly examples\nand learns anomaly scores explicitly in an end-to-end method using deviation\nlearning. In this approach, the anomaly scores of normal examples are adjusted\nto closely resemble reference scores obtained from a prior distribution.\nConversely, anomaly samples are forced to have anomalous scores that\nconsiderably deviate from the reference score in the upper tail of the prior.\nAdditionally, our model is optimized to learn the distinct behavior of\nanomalies by utilizing a multi-head self-attention layer and multiple instance\nlearning approaches. Comprehensive experiments on several benchmark datasets\ndemonstrate that our proposed approach attains a new level of state-of-the-art\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Anindya Sundar Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ajay_A/0/1/0/all/0/1\">Aravind Ajay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1\">Sriparna Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhuyan_M/0/1/0/all/0/1\">Monowar Bhuyan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards an On-device Agent for Text Rewriting. (arXiv:2308.11807v1 [cs.CL])","link":"http://arxiv.org/abs/2308.11807","description":"<p>Large Language Models (LLMs) have demonstrated impressive capabilities for\ntext rewriting. Nonetheless, the large sizes of these models make them\nimpractical for on-device inference, which would otherwise allow for enhanced\nprivacy and economical inference. Creating a smaller yet potent language model\nfor text rewriting presents a formidable challenge because it requires\nbalancing the need for a small size with the need to retain the emergent\ncapabilities of the LLM, that requires costly data collection. To address the\nabove challenge, we introduce a new instruction tuning approach for building a\nmobile-centric text rewriting model. Our strategies enable the generation of\nhigh quality training data without any human labeling. In addition, we propose\na heuristic reinforcement learning framework which substantially enhances\nperformance without requiring preference data. To further bridge the\nperformance gap with the larger server-side model, we propose an effective\napproach that combines the mobile rewrite agent with the server model using a\ncascade. To tailor the text rewriting tasks to mobile scenarios, we introduce\nMessageRewriteEval, a benchmark that focuses on text rewriting for messages\nthrough natural language instructions. Through empirical experiments, we\ndemonstrate that our on-device model surpasses the current state-of-the-art\nLLMs in text rewriting while maintaining a significantly reduced model size.\nNotably, we show that our proposed cascading approach improves model\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yinxiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stahlberg_F/0/1/0/all/0/1\">Felix Stahlberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Shankar Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu-hui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1\">Liangchen Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_L/0/1/0/all/0/1\">Lei Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Renjie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jindong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_L/0/1/0/all/0/1\">Lei Meng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Effectiveness of GPT Models in Test-Taking: A Case Study of the Driver's License Knowledge Test. (arXiv:2308.11827v1 [cs.CL])","link":"http://arxiv.org/abs/2308.11827","description":"<p>Large language models such as Open AI's Generative Pre-trained Transformer\n(GPT) models are proficient at answering questions, but their knowledge is\nconfined to the information present in their training data. This limitation\nrenders them ineffective when confronted with questions about recent\ndevelopments or non-public documents. Our research proposes a method that\nenables GPT models to answer questions by employing context from an information\nsource not previously included in their training data. The methodology includes\npreprocessing of contextual information, the embedding of contexts and queries,\nconstructing prompt through the integration of context embeddings, and\ngenerating answers using GPT models. We applied this method in a controlled\ntest scenario using the California Driver's Handbook as the information source.\nThe GPT-3 model achieved a 96% passing score on a set of 50 sample driving\nknowledge test questions. In contrast, without context, the model's passing\nscore fell to 82%. However, the model still fails to answer some questions\ncorrectly even with providing library of context, highlighting room for\nimprovement. The research also examined the impact of prompt length and context\nformat, on the model's performance. Overall, the study provides insights into\nthe limitations and potential improvements for GPT models in question-answering\ntasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rahimi_S/0/1/0/all/0/1\">Saba Rahimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balch_T/0/1/0/all/0/1\">Tucker Balch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veloso_M/0/1/0/all/0/1\">Manuela Veloso</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cabrita: closing the gap for foreign languages. (arXiv:2308.11878v1 [cs.CL])","link":"http://arxiv.org/abs/2308.11878","description":"<p>The strategy of training the model from scratch in a specific language or\ndomain serves two essential purposes: i) enhancing performance in the\nparticular linguistic or domain context, and ii) ensuring effective\ntokenization. The main limitation inherent to this approach lies in the\nassociated cost, which can reach six to seven-digit dollar values, depending on\nthe model size and the number of parameters involved.\n</p>\n<p>The main solution to overcome the cost challenge is to rely on available\npre-trained models, which, despite recent advancements such as the LLaMA and\nLLaMA-2 models, still demonstrate inefficiency for certain specific domain\nproblems or prove ineffective in scenarios involving conversational memory\nresources, given the large number of tokens required to represent text.\n</p>\n<p>To overcome this issue, we present a methodology named Cabrita, which, as our\nresearch demonstrates, successfully addresses the performance and efficient\ntokenization problem, all at an affordable cost. We believe that this\nmethodology can be applied to any transformer-like architecture model. To\nvalidate the study, we conducted continuous pre-training exclusively using\nPortuguese text on a 3-billion-parameter model known as OpenLLaMA, resulting in\na model named openCabrita 3B. The openCabrita 3B also features a new tokenizer\nthat results in a significant reduction in the number of tokens required to\nrepresent the text. In our assessment, for few-shot learning tasks, we achieved\nsimilar results with this 3B model compared to a traditional continuous\npre-training approach as well as to 7B models English pre-trained models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Larcher_C/0/1/0/all/0/1\">Celio Larcher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piau_M/0/1/0/all/0/1\">Marcos Piau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finardi_P/0/1/0/all/0/1\">Paulo Finardi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gengo_P/0/1/0/all/0/1\">Pedro Gengo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esposito_P/0/1/0/all/0/1\">Piero Esposito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carida_V/0/1/0/all/0/1\">Vinicius Carid&#xe1;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bridging the Gap: Deciphering Tabular Data Using Large Language Model. (arXiv:2308.11891v1 [cs.CL])","link":"http://arxiv.org/abs/2308.11891","description":"<p>In the realm of natural language processing, the understanding of tabular\ndata has perpetually stood as a focal point of scholarly inquiry. The emergence\nof expansive language models, exemplified by the likes of ChatGPT, has ushered\nin a wave of endeavors wherein researchers aim to harness these models for\ntasks related to table-based question answering. Central to our investigative\npursuits is the elucidation of methodologies that amplify the aptitude of such\nlarge language models in discerning both the structural intricacies and\ninherent content of tables, ultimately facilitating their capacity to provide\ninformed responses to pertinent queries. To this end, we have architected a\ndistinctive module dedicated to the serialization of tables for seamless\nintegration with expansive language models. Additionally, we've instituted a\ncorrective mechanism within the model to rectify potential inaccuracies.\nExperimental results indicate that, although our proposed method trails the\nSOTA by approximately 11.7% in overall metrics, it surpasses the SOTA by about\n1.2% in tests on specific datasets. This research marks the first application\nof large language models to table-based question answering tasks, enhancing the\nmodel's comprehension of both table structures and content.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hengyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_P/0/1/0/all/0/1\">Peng Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1\">Zongcheng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Audio Difference Captioning Utilizing Similarity-Discrepancy Disentanglement. (arXiv:2308.11923v1 [eess.AS])","link":"http://arxiv.org/abs/2308.11923","description":"<p>We proposed Audio Difference Captioning (ADC) as a new extension task of\naudio captioning for describing the semantic differences between input pairs of\nsimilar but slightly different audio clips. The ADC solves the problem that\nconventional audio captioning sometimes generates similar captions for similar\naudio clips, failing to describe the difference in content. We also propose a\ncross-attention-concentrated transformer encoder to extract differences by\ncomparing a pair of audio clips and a similarity-discrepancy disentanglement to\nemphasize the difference in the latent space. To evaluate the proposed methods,\nwe built an AudioDiffCaps dataset consisting of pairs of similar but slightly\ndifferent audio clips with human-annotated descriptions of their differences.\nThe experiment with the AudioDiffCaps dataset showed that the proposed methods\nsolve the ADC task effectively and improve the attention weights to extract the\ndifference by visualizing them in the transformer encoder.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Takeuchi_D/0/1/0/all/0/1\">Daiki Takeuchi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ohishi_Y/0/1/0/all/0/1\">Yasunori Ohishi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Niizumi_D/0/1/0/all/0/1\">Daisuke Niizumi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Harada_N/0/1/0/all/0/1\">Noboru Harada</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kashino_K/0/1/0/all/0/1\">Kunio Kashino</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Audio Generation with Multiple Conditional Diffusion Model. (arXiv:2308.11940v1 [cs.SD])","link":"http://arxiv.org/abs/2308.11940","description":"<p>Text-based audio generation models have limitations as they cannot encompass\nall the information in audio, leading to restricted controllability when\nrelying solely on text. To address this issue, we propose a novel model that\nenhances the controllability of existing pre-trained text-to-audio models by\nincorporating additional conditions including content (timestamp) and style\n(pitch contour and energy contour) as supplements to the text. This approach\nachieves fine-grained control over the temporal order, pitch, and energy of\ngenerated audio. To preserve the diversity of generation, we employ a trainable\ncontrol condition encoder that is enhanced by a large language model and a\ntrainable Fusion-Net to encode and fuse the additional conditions while keeping\nthe weights of the pre-trained text-to-audio model frozen. Due to the lack of\nsuitable datasets and evaluation metrics, we consolidate existing datasets into\na new dataset comprising the audio and corresponding conditions and use a\nseries of evaluation metrics to evaluate the controllability performance.\nExperimental results demonstrate that our model successfully achieves\nfine-grained control to accomplish controllable audio generation. Audio samples\nand our dataset are publicly available at\nhttps://conditionaudiogen.github.io/conditionaudiogen/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhifang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jianguo Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_R/0/1/0/all/0/1\">Rui Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_L/0/1/0/all/0/1\">Long Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouchi_K/0/1/0/all/0/1\">Kazushige Ouchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiangdong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EVE: Efficient Vision-Language Pre-training with Masked Prediction and Modality-Aware MoE. (arXiv:2308.11971v1 [cs.CV])","link":"http://arxiv.org/abs/2308.11971","description":"<p>Building scalable vision-language models to learn from diverse, multimodal\ndata remains an open challenge. In this paper, we introduce an Efficient\nVision-languagE foundation model, namely EVE, which is one unified multimodal\nTransformer pre-trained solely by one unified pre-training task. Specifically,\nEVE encodes both vision and language within a shared Transformer network\nintegrated with modality-aware sparse Mixture-of-Experts (MoE) modules, which\ncapture modality-specific information by selectively switching to different\nexperts. To unify pre-training tasks of vision and language, EVE performs\nmasked signal modeling on image-text pairs to reconstruct masked signals, i.e.,\nimage pixels and text tokens, given visible signals. This simple yet effective\npre-training objective accelerates training by 3.5x compared to the model\npre-trained with Image-Text Contrastive and Image-Text Matching losses. Owing\nto the combination of the unified architecture and pre-training task, EVE is\neasy to scale up, enabling better downstream performance with fewer resources\nand faster training speed. Despite its simplicity, EVE achieves\nstate-of-the-art performance on various vision-language downstream tasks,\nincluding visual question answering, visual reasoning, and image-text\nretrieval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Longteng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jia Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_S/0/1/0/all/0/1\">Shuai Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zehuan Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Liang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongyu Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations. (arXiv:2308.11995v1 [cs.CL])","link":"http://arxiv.org/abs/2308.11995","description":"<p>Building socialbots that can have deep, engaging open-domain conversations\nwith humans is one of the grand challenges of artificial intelligence (AI). To\nthis end, bots need to be able to leverage world knowledge spanning several\ndomains effectively when conversing with humans who have their own world\nknowledge. Existing knowledge-grounded conversation datasets are primarily\nstylized with explicit roles for conversation partners. These datasets also do\nnot explore depth or breadth of topical coverage with transitions in\nconversations. We introduce Topical-Chat, a knowledge-grounded human-human\nconversation dataset where the underlying knowledge spans 8 broad topics and\nconversation partners don't have explicitly defined roles, to help further\nresearch in open-domain conversational AI. We also train several\nstate-of-the-art encoder-decoder conversational models on Topical-Chat and\nperform automated and human evaluation for benchmarking.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gopalakrishnan_K/0/1/0/all/0/1\">Karthik Gopalakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hedayatnia_B/0/1/0/all/0/1\">Behnam Hedayatnia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qinlang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gottardi_A/0/1/0/all/0/1\">Anna Gottardi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwatra_S/0/1/0/all/0/1\">Sanjeev Kwatra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkatesh_A/0/1/0/all/0/1\">Anu Venkatesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gabriel_R/0/1/0/all/0/1\">Raefer Gabriel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1\">Dilek Hakkani-Tur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Graecia capta ferum victorem cepit. Detecting Latin Allusions to Ancient Greek Literature. (arXiv:2308.12008v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12008","description":"<p>Intertextual allusions hold a pivotal role in Classical Philology, with Latin\nauthors frequently referencing Ancient Greek texts. Until now, the automatic\nidentification of these intertextual references has been constrained to\nmonolingual approaches, seeking parallels solely within Latin or Greek texts.\nIn this study, we introduce SPhilBERTa, a trilingual Sentence-RoBERTa model\ntailored for Classical Philology, which excels at cross-lingual semantic\ncomprehension and identification of identical sentences across Ancient Greek,\nLatin, and English. We generate new training data by automatically translating\nEnglish texts into Ancient Greek. Further, we present a case study,\ndemonstrating SPhilBERTa's capability to facilitate automated detection of\nintertextual parallels. Our models and resources are available at\nhttps://github.com/Heidelberg-NLP/ancient-language-models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Riemenschneider_F/0/1/0/all/0/1\">Frederick Riemenschneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Anette Frank</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Instructions to Intrinsic Human Values -- A Survey of Alignment Goals for Big Models. (arXiv:2308.12014v1 [cs.AI])","link":"http://arxiv.org/abs/2308.12014","description":"<p>Big models, exemplified by Large Language Models (LLMs), are models typically\npre-trained on massive data and comprised of enormous parameters, which not\nonly obtain significantly improved performance across diverse tasks but also\npresent emergent capabilities absent in smaller models. However, the growing\nintertwining of big models with everyday human lives poses potential risks and\nmight cause serious social harm. Therefore, many efforts have been made to\nalign LLMs with humans to make them better follow user instructions and satisfy\nhuman preferences. Nevertheless, `what to align with' has not been fully\ndiscussed, and inappropriate alignment goals might even backfire. In this\npaper, we conduct a comprehensive survey of different alignment goals in\nexisting work and trace their evolution paths to help identify the most\nessential goal. Particularly, we investigate related works from two\nperspectives: the definition of alignment goals and alignment evaluation. Our\nanalysis encompasses three distinct levels of alignment goals and reveals a\ngoal transformation from fundamental abilities to value orientation, indicating\nthe potential of intrinsic human values as the alignment goal for enhanced\nLLMs. Based on such results, we further discuss the challenges of achieving\nsuch intrinsic value alignment and provide a collection of available resources\nfor future research on the alignment of big models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jing Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xiaoyuan Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiting Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reranking Passages with Coarse-to-Fine Neural Retriever using List-Context Information. (arXiv:2308.12022v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12022","description":"<p>Passage reranking is a crucial task in many applications, particularly when\ndealing with large-scale documents. Traditional neural architectures are\nlimited in retrieving the best passage for a question because they usually\nmatch the question to each passage separately, seldom considering contextual\ninformation in other passages that can provide comparison and reference\ninformation. This paper presents a list-context attention mechanism to augment\nthe passage representation by incorporating the list-context information from\nother candidates. The proposed coarse-to-fine (C2F) neural retriever addresses\nthe out-of-memory limitation of the passage attention mechanism by dividing the\nlist-context modeling process into two sub-processes, allowing for efficient\nencoding of context information from a large number of candidate answers. This\nmethod can be generally used to encode context information from any number of\ncandidate answers in one pass. Different from most multi-stage information\nretrieval architectures, this model integrates the coarse and fine rankers into\nthe joint optimization process, allowing for feedback between the two layers to\nupdate the model simultaneously. Experiments demonstrate the effectiveness of\nthe proposed approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hongyin Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge-injected Prompt Learning for Chinese Biomedical Entity Normalization. (arXiv:2308.12025v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12025","description":"<p>The Biomedical Entity Normalization (BEN) task aims to align raw,\nunstructured medical entities to standard entities, thus promoting data\ncoherence and facilitating better downstream medical applications. Recently,\nprompt learning methods have shown promising results in this task. However,\nexisting research falls short in tackling the more complex Chinese BEN task,\nespecially in the few-shot scenario with limited medical data, and the vast\npotential of the external medical knowledge base has yet to be fully harnessed.\nTo address these challenges, we propose a novel Knowledge-injected Prompt\nLearning (PL-Knowledge) method. Specifically, our approach consists of five\nstages: candidate entity matching, knowledge extraction, knowledge encoding,\nknowledge injection, and prediction output. By effectively encoding the\nknowledge items contained in medical entities and incorporating them into our\ntailor-made knowledge-injected templates, the additional knowledge enhances the\nmodel's ability to capture latent relationships between medical entities, thus\nachieving a better match with the standard entities. We extensively evaluate\nour model on a benchmark dataset in both few-shot and full-scale scenarios. Our\nmethod outperforms existing baselines, with an average accuracy boost of\n12.96\\% in few-shot and 0.94\\% in full-data cases, showcasing its excellence in\nthe BEN task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Songhua Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chenghao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hongfei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yuxiang Jia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt-Based Length Controlled Generation with Reinforcement Learning. (arXiv:2308.12030v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12030","description":"<p>Recently, large language models (LLMs) like ChatGPT and GPT-4 have attracted\ngreat attention given their surprising improvement and performance. Length\ncontrolled generation of LLMs emerges as an important topic, which also enables\nusers to fully leverage the capability of LLMs in more real-world scenarios\nlike generating a proper answer or essay of a desired length. In addition, the\nautoregressive generation in LLMs is extremely time-consuming, while the\nability of controlling this generated length can arbitrarily reduce the\ninference cost by limiting the length, and thus satisfy different needs.\nTherefore, we aim to propose a prompt-based length control method to achieve\nthis length controlled generation, which can also be widely applied in\nGPT-style LLMs. In particular, we adopt reinforcement learning with the reward\nsignal given by either trainable or rule-based reward model, which further\naffects the generation of LLMs via rewarding a pre-defined target length.\nExperiments show that our method significantly improves the accuracy of\nprompt-based length control for summarization task on popular datasets like\nCNNDM and NYT. We believe this length-controllable ability can provide more\npotentials towards the era of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jie_R/0/1/0/all/0/1\">Renlong Jie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1\">Xiaojun Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_L/0/1/0/all/0/1\">Lifeng Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning. (arXiv:2308.12032v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12032","description":"<p>In the realm of Large Language Models, the balance between instruction data\nquality and quantity has become a focal point. Recognizing this, we introduce a\nself-guided methodology for LLMs to autonomously discern and select cherry\nsamples from vast open-source datasets, effectively minimizing manual curation\nand potential cost for instruction tuning an LLM. Our key innovation, the\nInstruction-Following Difficulty (IFD) metric, emerges as a pivotal tool to\nidentify discrepancies between a model's expected responses and its autonomous\ngeneration prowess. Through the adept application of IFD, cherry samples are\npinpointed, leading to a marked uptick in model training efficiency. Empirical\nvalidations on renowned datasets like Alpaca and WizardLM underpin our\nfindings; with a mere 10% of conventional data input, our strategy showcases\nimproved results. This synthesis of self-guided cherry-picking and the IFD\nmetric signifies a transformative leap in the optimization of LLMs, promising\nboth efficiency and resource-conscious advancements.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Ming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhitao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiuhai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lichang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_N/0/1/0/all/0/1\">Ning Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianzong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1\">Jing Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PREFER: Prompt Ensemble Learning via Feedback-Reflect-Refine. (arXiv:2308.12033v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12033","description":"<p>As an effective tool for eliciting the power of Large Language Models (LLMs),\nprompting has recently demonstrated unprecedented abilities across a variety of\ncomplex tasks. To further improve the performance, prompt ensemble has\nattracted substantial interest for tackling the hallucination and instability\nof LLMs. However, existing methods usually adopt a two-stage paradigm, which\nrequires a pre-prepared set of prompts with substantial manual effort, and is\nunable to perform directed optimization for different weak learners. In this\npaper, we propose a simple, universal, and automatic method named PREFER (Pompt\nEnsemble learning via Feedback-Reflect-Refine) to address the stated\nlimitations. Specifically, given the fact that weak learners are supposed to\nfocus on hard examples during boosting, PREFER builds a feedback mechanism for\nreflecting on the inadequacies of existing weak learners. Based on this, the\nLLM is required to automatically synthesize new prompts for iterative\nrefinement. Moreover, to enhance stability of the prompt effect evaluation, we\npropose a novel prompt bagging method involving forward and backward thinking,\nwhich is superior to majority voting and is beneficial for both feedback and\nweight calculation in boosting. Extensive experiments demonstrate that our\nPREFER achieves state-of-the-art performance in multiple types of tasks by a\nsignificant margin. We have made our code publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chenrui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jinpeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chuyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_M/0/1/0/all/0/1\">Mingchen Cai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages. (arXiv:2308.12038v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12038","description":"<p>Recently there has been a significant surge in multimodal learning in terms\nof both image-to-text and text-to-image generation. However, the success is\ntypically limited to English, leaving other languages largely behind. Building\na competitive counterpart in other languages is highly challenging due to the\nlow-resource nature of non-English multimodal data (i.e., lack of large-scale,\nhigh-quality image-text data). In this work, we propose MPM, an effective\ntraining paradigm for training large multimodal models in low-resource\nlanguages. MPM demonstrates that Multilingual language models can Pivot\nzero-shot Multimodal learning across languages. Specifically, based on a strong\nmultilingual large language model, multimodal models pretrained on English-only\nimage-text data can well generalize to other languages in a zero-shot manner\nfor both image-to-text and text-to-image generation, even surpassing models\ntrained on image-text data in native languages. Taking Chinese as a practice of\nMPM, we build large multimodal models VisCPM in image-to-text and text-to-image\ngeneration, which achieve state-of-the-art (open-source) performance in\nChinese. To facilitate future research, we open-source codes and model weights\nat https://github.com/OpenBMB/VisCPM.git.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jinyi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chongyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1\">Yinxu Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qianyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tianyu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hanghao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yue Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haoye Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1\">Jiao Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dahai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hybrid Retrieval and Multi-stage Text Ranking Solution at TREC 2022 Deep Learning Track. (arXiv:2308.12039v1 [cs.IR])","link":"http://arxiv.org/abs/2308.12039","description":"<p>Large-scale text retrieval technology has been widely used in various\npractical business scenarios. This paper presents our systems for the TREC 2022\nDeep Learning Track. We explain the hybrid text retrieval and multi-stage text\nranking method adopted in our solution. The retrieval stage combined the two\nstructures of traditional sparse retrieval and neural dense retrieval. In the\nranking stage, in addition to the full interaction-based ranking model built on\nlarge pre-trained language model, we also proposes a lightweight sub-ranking\nmodule to further enhance the final text ranking performance. Evaluation\nresults demonstrate the effectiveness of our proposed approach. Our models\nachieve the 1st and 4th rank on the test set of passage ranking and document\nranking respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guangwei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yangzhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Longhui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_D/0/1/0/all/0/1\">Dingkun Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pengjun Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1\">Ruijie Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"IncreLoRA: Incremental Parameter Allocation Method for Parameter-Efficient Fine-tuning. (arXiv:2308.12043v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12043","description":"<p>With the increasing size of pre-trained language models (PLMs), fine-tuning\nall the parameters in the model is not efficient, especially when there are a\nlarge number of downstream tasks, which incur significant training and storage\ncosts. Many parameter-efficient fine-tuning (PEFT) approaches have been\nproposed, among which, Low-Rank Adaptation (LoRA) is a representative approach\nthat injects trainable rank decomposition matrices into every target module.\nYet LoRA ignores the importance of parameters in different modules. To address\nthis problem, many works have been proposed to prune the parameters of LoRA.\nHowever, under limited training conditions, the upper bound of the rank of the\npruned parameter matrix is still affected by the preset values. We, therefore,\npropose IncreLoRA, an incremental parameter allocation method that adaptively\nadds trainable parameters during training based on the importance scores of\neach module. This approach is different from the pruning method as it is not\nlimited by the initial number of training parameters, and each parameter matrix\nhas a higher rank upper bound for the same training overhead. We conduct\nextensive experiments on GLUE to demonstrate the effectiveness of IncreLoRA.\nThe results show that our method owns higher parameter efficiency, especially\nwhen under the low-resource settings where our method significantly outperforms\nthe baselines. Our code is publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Feiyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liangzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhouqiang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bowen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yiming Qian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CgT-GAN: CLIP-guided Text GAN for Image Captioning. (arXiv:2308.12045v1 [cs.CV])","link":"http://arxiv.org/abs/2308.12045","description":"<p>The large-scale visual-language pre-trained model, Contrastive Language-Image\nPre-training (CLIP), has significantly improved image captioning for scenarios\nwithout human-annotated image-caption pairs. Recent advanced CLIP-based image\ncaptioning without human annotations follows a text-only training paradigm,\ni.e., reconstructing text from shared embedding space. Nevertheless, these\napproaches are limited by the training/inference gap or huge storage\nrequirements for text embeddings. Given that it is trivial to obtain images in\nthe real world, we propose CLIP-guided text GAN (CgT-GAN), which incorporates\nimages into the training process to enable the model to \"see\" real visual\nmodality. Particularly, we use adversarial training to teach CgT-GAN to mimic\nthe phrases of an external text corpus and CLIP-based reward to provide\nsemantic guidance. The caption generator is jointly rewarded based on the\ncaption naturalness to human language calculated from the GAN's discriminator\nand the semantic guidance reward computed by the CLIP-based reward module. In\naddition to the cosine similarity as the semantic guidance reward (i.e.,\nCLIP-cos), we further introduce a novel semantic guidance reward called\nCLIP-agg, which aligns the generated caption with a weighted text embedding by\nattentively aggregating the entire corpus. Experimental results on three\nsubtasks (ZS-IC, In-UIC and Cross-UIC) show that CgT-GAN outperforms\nstate-of-the-art methods significantly across all metrics. Code is available at\nhttps://github.com/Lihr747/CgtGAN.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jiarui Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1\">Yanbin Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Bin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Aligning Language Models with Offline Reinforcement Learning from Human Feedback. (arXiv:2308.12050v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12050","description":"<p>Learning from human preferences is crucial for language models (LMs) to\neffectively cater to human needs and societal values. Previous research has\nmade notable progress by leveraging human feedback to follow instructions.\nHowever, these approaches rely primarily on online reinforcement learning (RL)\ntechniques like Proximal Policy Optimization (PPO), which have been proven\nunstable and challenging to tune for language models. Moreover, PPO requires\ncomplex distributed system implementation, hindering the efficiency of\nlarge-scale distributed training. In this study, we propose an offline\nreinforcement learning from human feedback (RLHF) framework to align LMs using\npre-generated samples without interacting with RL environments. Specifically,\nwe explore maximum likelihood estimation (MLE) with filtering, reward-weighted\nregression (RWR), and Decision Transformer (DT) to align language models to\nhuman preferences. By employing a loss function similar to supervised\nfine-tuning, our methods ensure more stable model training than PPO with a\nsimple machine learning system~(MLSys) and much fewer (around 12.3\\%) computing\nresources. Experimental results demonstrate the DT alignment outperforms other\nOffline RLHF methods and is better than PPO.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_L/0/1/0/all/0/1\">Li Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">June Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chandler Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base Question Answering. (arXiv:2308.12060v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12060","description":"<p>Knowledge base question answering (KBQA) is a critical yet challenging task\ndue to the vast number of entities within knowledge bases and the diversity of\nnatural language questions posed by users. Unfortunately, the performance of\nmost KBQA models tends to decline significantly in real-world scenarios where\nhigh-quality annotated data is insufficient. To mitigate the burden associated\nwith manual annotation, we introduce FlexKBQA by utilizing Large Language\nModels (LLMs) as program translators for addressing the challenges inherent in\nthe few-shot KBQA task. Specifically, FlexKBQA leverages automated algorithms\nto sample diverse programs, such as SPARQL queries, from the knowledge base,\nwhich are subsequently converted into natural language questions via LLMs. This\nsynthetic dataset facilitates training a specialized lightweight model for the\nKB. Additionally, to reduce the barriers of distribution shift between\nsynthetic data and real user questions, FlexKBQA introduces an executionguided\nself-training method to iterative leverage unlabeled user questions.\nFurthermore, we explore harnessing the inherent reasoning capability of LLMs to\nenhance the entire framework. Consequently, FlexKBQA delivers substantial\nflexibility, encompassing data annotation, deployment, and being domain\nagnostic. Through extensive experiments on GrailQA, WebQSP, and KQA Pro, we\nobserve that under the few-shot even the more challenging zero-shot scenarios,\nFlexKBQA achieves impressive results with a few annotations, surpassing all\nprevious baselines and even approaching the performance of supervised models,\nachieving a remarkable 93% performance relative to the fully-supervised models.\nWe posit that FlexKBQA represents a significant advancement towards exploring\nbetter integration of large and lightweight models. The code is open-sourced.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_S/0/1/0/all/0/1\">Sunqi Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yu Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiuxing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_Z/0/1/0/all/0/1\">Zhichao Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1\">Bowen Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianyong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InstructionGPT-4: A 200-Instruction Paradigm for Fine-Tuning MiniGPT-4. (arXiv:2308.12067v1 [cs.LG])","link":"http://arxiv.org/abs/2308.12067","description":"<p>Multimodal large language models acquire their instruction-following\ncapabilities through a two-stage training process: pre-training on image-text\npairs and fine-tuning on supervised vision-language instruction data. Recent\nstudies have shown that large language models can achieve satisfactory results\neven with a limited amount of high-quality instruction-following data. In this\npaper, we introduce InstructionGPT-4, which is fine-tuned on a small dataset\ncomprising only 200 examples, amounting to approximately 6% of the\ninstruction-following data used in the alignment dataset for MiniGPT-4. We\nfirst propose several metrics to access the quality of multimodal instruction\ndata. Based on these metrics, we present a simple and effective data selector\nto automatically identify and filter low-quality vision-language data. By\nemploying this method, InstructionGPT-4 outperforms the original MiniGPT-4 on\nvarious evaluations (e.g., visual question answering, GPT-4 preference).\nOverall, our findings demonstrate that less but high-quality instruction tuning\ndata is efficient to enable multimodal large language models to generate better\noutput.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1\">Lai Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zihao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Weiran Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Lichao Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments. (arXiv:2308.12086v1 [cs.CR])","link":"http://arxiv.org/abs/2308.12086","description":"<p>Large Language Models (LLMs) have gained widespread popularity across diverse\ndomains involving text generation, summarization, and various natural language\nprocessing tasks. Despite their inherent limitations, LLM-based designs have\nshown promising capabilities in planning and navigating open-world scenarios.\nThis paper introduces a novel application of pre-trained LLMs as agents within\ncybersecurity network environments, focusing on their utility for sequential\ndecision-making processes.\n</p>\n<p>We present an approach wherein pre-trained LLMs are leveraged as attacking\nagents in two reinforcement learning environments. Our proposed agents\ndemonstrate similar or better performance against state-of-the-art agents\ntrained for thousands of episodes in most scenarios and configurations. In\naddition, the best LLM agents perform similarly to human testers of the\nenvironment without any additional training process. This design highlights the\npotential of LLMs to efficiently address complex decision-making tasks within\ncybersecurity.\n</p>\n<p>Furthermore, we introduce a new network security environment named\nNetSecGame. The environment is designed to eventually support complex\nmulti-agent scenarios within the network security domain. The proposed\nenvironment mimics real network attacks and is designed to be highly modular\nand adaptable for various scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rigaki_M/0/1/0/all/0/1\">Maria Rigaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukas_O/0/1/0/all/0/1\">Ond&#x159;ej Luk&#xe1;&#x161;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catania_C/0/1/0/all/0/1\">Carlos A. Catania</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_S/0/1/0/all/0/1\">Sebastian Garcia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Instruction Position Matters in Sequence Generation with Large Language Models. (arXiv:2308.12097v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12097","description":"<p>Large language models (LLMs) are capable of performing conditional sequence\ngeneration tasks, such as translation or summarization, through instruction\nfine-tuning. The fine-tuning data is generally sequentially concatenated from a\nspecific task instruction, an input sentence, and the corresponding response.\nConsidering the locality modeled by the self-attention mechanism of LLMs, these\nmodels face the risk of instruction forgetting when generating responses for\nlong input sentences. To mitigate this issue, we propose enhancing the\ninstruction-following capability of LLMs by shifting the position of task\ninstructions after the input sentences. Theoretical analysis suggests that our\nstraightforward method can alter the model's learning focus, thereby\nemphasizing the training of instruction-following capabilities. Concurrently,\nexperimental results demonstrate that our approach consistently outperforms\ntraditional settings across various model scales (1B / 7B / 13B) and different\nsequence generation tasks (translation and summarization), without any\nadditional data or annotation costs. Notably, our method significantly improves\nthe zero-shot performance on conditional sequence generation, e.g., up to 9.7\nBLEU points on WMT zero-shot translation tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yijin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xianfeng Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Change Detection for the Romanian Language. (arXiv:2308.12131v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12131","description":"<p>Automatic semantic change methods try to identify the changes that appear\nover time in the meaning of words by analyzing their usage in diachronic\ncorpora. In this paper, we analyze different strategies to create static and\ncontextual word embedding models, i.e., Word2Vec and ELMo, on real-world\nEnglish and Romanian datasets. To test our pipeline and determine the\nperformance of our models, we first evaluate both word embedding models on an\nEnglish dataset (SEMEVAL-CCOHA). Afterward, we focus our experiments on a\nRomanian dataset, and we underline different aspects of semantic changes in\nthis low-resource language, such as meaning acquisition and loss. The\nexperimental results show that, depending on the corpus, the most important\nfactors to consider are the choice of model and the distance to calculate a\nscore for detecting semantic change.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Truica_C/0/1/0/all/0/1\">Ciprian-Octavian Truic&#x103;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tudose_V/0/1/0/all/0/1\">Victor Tudose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Apostol_E/0/1/0/all/0/1\">Elena-Simona Apostol</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluation of Faithfulness Using the Longest Supported Subsequence. (arXiv:2308.12157v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12157","description":"<p>As increasingly sophisticated language models emerge, their trustworthiness\nbecomes a pivotal issue, especially in tasks such as summarization and\nquestion-answering. Ensuring their responses are contextually grounded and\nfaithful is challenging due to the linguistic diversity and the myriad of\npossible answers. In this paper, we introduce a novel approach to evaluate\nfaithfulness of machine-generated text by computing the longest noncontinuous\nsubstring of the claim that is supported by the context, which we refer to as\nthe Longest Supported Subsequence (LSS). Using a new human-annotated dataset,\nwe finetune a model to generate LSS. We introduce a new method of evaluation\nand demonstrate that these metrics correlate better with human ratings when LSS\nis employed, as opposed to when it is not. Our proposed metric demonstrates an\n18% enhancement over the prevailing state-of-the-art metric for faithfulness on\nour dataset. Our metric consistently outperforms other metrics on a\nsummarization dataset across six different models. Finally, we compare several\npopular Large Language Models (LLMs) for faithfulness using this metric. We\nrelease the human-annotated dataset built for predicting LSS and our fine-tuned\nmodel for evaluating faithfulness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mittal_A/0/1/0/all/0/1\">Anirudh Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schick_T/0/1/0/all/0/1\">Timo Schick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1\">Mikel Artetxe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dwivedi_Yu_J/0/1/0/all/0/1\">Jane Dwivedi-Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Curriculum Learning with Adam: The Devil Is in the Wrong Details. (arXiv:2308.12202v1 [cs.LG])","link":"http://arxiv.org/abs/2308.12202","description":"<p>Curriculum learning (CL) posits that machine learning models -- similar to\nhumans -- may learn more efficiently from data that match their current\nlearning progress. However, CL methods are still poorly understood and, in\nparticular for natural language processing (NLP), have achieved only limited\nsuccess. In this paper, we explore why. Starting from an attempt to replicate\nand extend a number of recent curriculum methods, we find that their results\nare surprisingly brittle when applied to NLP. A deep dive into the\n(in)effectiveness of the curricula in some scenarios shows us why: when\ncurricula are employed in combination with the popular Adam optimisation\nalgorithm, they oftentimes learn to adapt to suboptimally chosen optimisation\nparameters for this algorithm. We present a number of different case studies\nwith different common hand-crafted and automated CL approaches to illustrate\nthis phenomenon, and we find that none of them outperforms optimisation with\nonly Adam with well-chosen hyperparameters. As such, our results contribute to\nunderstanding why CL methods work, but at the same time urge caution when\nclaiming positive results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Weber_L/0/1/0/all/0/1\">Lucas Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jumelet_J/0/1/0/all/0/1\">Jaap Jumelet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michel_P/0/1/0/all/0/1\">Paul Michel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruni_E/0/1/0/all/0/1\">Elia Bruni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1\">Dieuwke Hupkes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Challenges of Machine Learning for Trust and Safety: A Case Study on Misinformation Detection. (arXiv:2308.12215v1 [cs.LG])","link":"http://arxiv.org/abs/2308.12215","description":"<p>We examine the disconnect between scholarship and practice in applying\nmachine learning to trust and safety problems, using misinformation detection\nas a case study. We systematize literature on automated detection of\nmisinformation across a corpus of 270 well-cited papers in the field. We then\nexamine subsets of papers for data and code availability, design missteps,\nreproducibility, and generalizability. We find significant shortcomings in the\nliterature that call into question claimed performance and practicality.\nDetection tasks are often meaningfully distinct from the challenges that online\nservices actually face. Datasets and model evaluation are often\nnon-representative of real-world contexts, and evaluation frequently is not\nindependent of model training. Data and code availability is poor. Models do\nnot generalize well to out-of-domain data. Based on these results, we offer\nrecommendations for evaluating machine learning applications to trust and\nsafety problems. Our aim is for future work to avoid the pitfalls that we\nidentify.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_M/0/1/0/all/0/1\">Madelyne Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayer_J/0/1/0/all/0/1\">Jonathan Mayer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning. (arXiv:2308.12219v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12219","description":"<p>The recent surge of generative AI has been fueled by the generative power of\ndiffusion probabilistic models and the scalable capabilities of large language\nmodels. Despite their potential, it remains elusive whether diffusion language\nmodels can solve general language tasks comparable to their autoregressive\ncounterparts. This paper demonstrates that scaling diffusion models w.r.t.\ndata, sizes, and tasks can effectively make them strong language learners. We\nbuild competent diffusion language models at scale by first acquiring knowledge\nfrom massive data via masked language modeling pretraining thanks to their\nintrinsic connections. We then reprogram pretrained masked language models into\ndiffusion language models via diffusive adaptation, wherein task-specific\nfinetuning and instruction finetuning are explored to unlock their versatility\nin solving general language tasks. Experiments show that scaling diffusion\nlanguage models consistently improves performance across downstream language\ntasks. We further discover that instruction finetuning can elicit zero-shot and\nfew-shot in-context learning abilities that help tackle many unseen tasks by\nfollowing natural language instructions, and show promise in advanced and\nchallenging abilities such as reasoning\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jiasheng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zaixiang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1\">Yu Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_L/0/1/0/all/0/1\">Lihua Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1\">Quanquan Gu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How to Protect Copyright Data in Optimization of Large Language Models?. (arXiv:2308.12247v1 [cs.LG])","link":"http://arxiv.org/abs/2308.12247","description":"<p>Large language models (LLMs) and generative AI have played a transformative\nrole in computer research and applications. Controversy has arisen as to\nwhether these models output copyrighted data, which can occur if the data the\nmodels are trained on is copyrighted. LLMs are built on the transformer neural\nnetwork architecture, which in turn relies on a mathematical computation called\nAttention that uses the softmax function.\n</p>\n<p>In this paper, we show that large language model training and optimization\ncan be seen as a softmax regression problem. We then establish a method of\nefficiently performing softmax regression, in a way that prevents the\nregression function from generating copyright data. This establishes a\ntheoretical method of training large language models in a way that avoids\ngenerating copyright data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chu_T/0/1/0/all/0/1\">Timothy Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chiwun Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt2Model: Generating Deployable Models from Natural Language Instructions. (arXiv:2308.12261v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12261","description":"<p>Large language models (LLMs) enable system builders today to create competent\nNLP systems through prompting, where they only need to describe the task in\nnatural language and provide a few examples. However, in other ways, LLMs are a\nstep backward from traditional special-purpose NLP models; they require\nextensive computational resources for deployment and can be gated behind APIs.\nIn this paper, we propose Prompt2Model, a general-purpose method that takes a\nnatural language task description like the prompts provided to LLMs, and uses\nit to train a special-purpose model that is conducive to deployment. This is\ndone through a multi-step process of retrieval of existing datasets and\npretrained models, dataset generation using LLMs, and supervised fine-tuning on\nthese retrieved and generated datasets. Over three tasks, we demonstrate that\ngiven the same few-shot prompt as input, Prompt2Model trains models that\noutperform the results of a strong LLM, gpt-3.5-turbo, by an average of 20%\nwhile being up to 700 times smaller. We also show that this data can be used to\nobtain reliable performance estimates of model performance, enabling model\ndevelopers to assess model reliability before deployment. Prompt2Model is\navailable open-source at https://github.com/neulab/prompt2model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Viswanathan_V/0/1/0/all/0/1\">Vijay Viswanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chenyang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertsch_A/0/1/0/all/0/1\">Amanda Bertsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tongshuang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Simple is Better and Large is Not Enough: Towards Ensembling of Foundational Language Models. (arXiv:2308.12272v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12272","description":"<p>Foundational Language Models (FLMs) have advanced natural language processing\n(NLP) research. Current researchers are developing larger FLMs (e.g., XLNet,\nT5) to enable contextualized language representation, classification, and\ngeneration. While developing larger FLMs has been of significant advantage, it\nis also a liability concerning hallucination and predictive uncertainty.\nFundamentally, larger FLMs are built on the same foundations as smaller FLMs\n(e.g., BERT); hence, one must recognize the potential of smaller FLMs which can\nbe realized through an ensemble. In the current research, we perform a reality\ncheck on FLMs and their ensemble on benchmark and real-world datasets. We\nhypothesize that the ensembling of FLMs can influence the individualistic\nattention of FLMs and unravel the strength of coordination and cooperation of\ndifferent FLMs. We utilize BERT and define three other ensemble techniques:\n{Shallow, Semi, and Deep}, wherein the Deep-Ensemble introduces a\nknowledge-guided reinforcement learning approach. We discovered that the\nsuggested Deep-Ensemble BERT outperforms its large variation i.e. BERTlarge, by\na factor of many times using datasets that show the usefulness of NLP in\nsensitive fields, such as mental health.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tyagi_N/0/1/0/all/0/1\">Nancy Tyagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiri_A/0/1/0/all/0/1\">Aidin Shiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1\">Surjodeep Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Umrawal_A/0/1/0/all/0/1\">Abhishek Kumar Umrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaur_M/0/1/0/all/0/1\">Manas Gaur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"D4: Improving LLM Pretraining via Document De-Duplication and Diversification. (arXiv:2308.12284v1 [cs.CL])","link":"http://arxiv.org/abs/2308.12284","description":"<p>Over recent years, an increasing amount of compute and data has been poured\ninto training large language models (LLMs), usually by doing one-pass learning\non as many tokens as possible randomly selected from large-scale web corpora.\nWhile training on ever-larger portions of the internet leads to consistent\nperformance improvements, the size of these improvements diminishes with scale,\nand there has been little work exploring the effect of data selection on\npre-training and downstream performance beyond simple de-duplication methods\nsuch as MinHash. Here, we show that careful data selection (on top of\nde-duplicated data) via pre-trained model embeddings can speed up training (20%\nefficiency gains) and improves average downstream accuracy on 16 NLP tasks (up\nto 2%) at the 6.7B model scale. Furthermore, we show that repeating data\nintelligently consistently outperforms baseline training (while repeating\nrandom data performs worse than baseline training). Our results indicate that\nclever data selection can significantly improve LLM pre-training, calls into\nquestion the common practice of training for a single epoch on as much data as\npossible, and demonstrates a path to keep improving our models past the limits\nof randomly sampling web data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tirumala_K/0/1/0/all/0/1\">Kushal Tirumala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simig_D/0/1/0/all/0/1\">Daniel Simig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aghajanyan_A/0/1/0/all/0/1\">Armen Aghajanyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1\">Ari S. Morcos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dive into Deep Learning. (arXiv:2106.11342v5 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2106.11342","description":"<p>This open-source book represents our attempt to make deep learning\napproachable, teaching readers the concepts, the context, and the code. The\nentire book is drafted in Jupyter notebooks, seamlessly integrating exposition\nfigures, math, and interactive examples with self-contained code. Our goal is\nto offer a resource that could (i) be freely available for everyone; (ii) offer\nsufficient technical depth to provide a starting point on the path to actually\nbecoming an applied machine learning scientist; (iii) include runnable code,\nshowing readers how to solve problems in practice; (iv) allow for rapid\nupdates, both by us and also by the community at large; (v) be complemented by\na forum for interactive discussion of technical details and to answer\nquestions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Aston Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1\">Zachary C. Lipton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smola_A/0/1/0/all/0/1\">Alexander J. Smola</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Structured Span Selector. (arXiv:2205.03977v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.03977","description":"<p>Many natural language processing tasks, e.g., coreference resolution and\nsemantic role labeling, require selecting text spans and making decisions about\nthem. A typical approach to such tasks is to score all possible spans and\ngreedily select spans for task-specific downstream processing. This approach,\nhowever, does not incorporate any inductive bias about what sort of spans ought\nto be selected, e.g., that selected spans tend to be syntactic constituents. In\nthis paper, we propose a novel grammar-based structured span selection model\nwhich learns to make use of the partial span-level annotation provided for such\nproblems. Compared to previous approaches, our approach gets rid of the\nheuristic greedy span selection scheme, allowing us to model the downstream\ntask on an optimal set of spans. We evaluate our model on two popular span\nprediction tasks: coreference resolution and semantic role labeling. We show\nempirical improvements on both.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuchen Eleanor Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Making first order linear logic a generating grammar. (arXiv:2206.08955v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.08955","description":"<p>It is known that different categorial grammars have surface representation in\na fragment of first order multiplicative linear logic (MLL1). We show that the\nfragment of interest is equivalent to the recently introduced extended tensor\ntype calculus (ETTC). ETTC is a calculus of specific typed terms, which\nrepresent tuples of strings, more precisely bipartite graphs decorated with\nstrings. Types are derived from linear logic formulas, and rules correspond to\nconcrete operations on these string-labeled graphs, so that they can be\nconveniently visualized. This provides the above mentioned fragment of MLL1\nthat is relevant for language modeling not only with some alternative syntax\nand intuitive geometric representation, but also with an intrinsic deductive\nsystem, which has been absent.\n</p>\n<p>In this work we consider a non-trivial notationally enriched variation of the\npreviously introduced {\\bf ETTC}, which allows more concise and transparent\ncomputations. We present both a cut-free sequent calculus and a natural\ndeduction formalism.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Slavnov_S/0/1/0/all/0/1\">Sergey Slavnov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PyABSA: A Modularized Framework for Reproducible Aspect-based Sentiment Analysis. (arXiv:2208.01368v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.01368","description":"<p>The advancement of aspect-based sentiment analysis (ABSA) has urged the lack\nof a user-friendly framework that can largely lower the difficulty of\nreproducing state-of-the-art ABSA performance, especially for beginners. To\nmeet the demand, we present \\our, a modularized framework built on PyTorch for\nreproducible ABSA. To facilitate ABSA research, PyABSA supports several ABSA\nsubtasks, including aspect term extraction, aspect sentiment classification,\nand end-to-end aspect-based sentiment analysis. Concretely, PyABSA integrates\n29 models and 26 datasets. With just a few lines of code, the result of a model\non a specific dataset can be reproduced. With a modularized design, PyABSA can\nalso be flexibly extended to considered models, datasets, and other related\ntasks. Besides, PyABSA highlights its data augmentation and annotation\nfeatures, which significantly address data scarcity. All are welcome to have a\ntry at \\url{https://github.com/yangheng95/PyABSA}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Heng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Ke Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Low-Resource Authorship Style Transfer: Can Non-Famous Authors Be Imitated?. (arXiv:2212.08986v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.08986","description":"<p>Authorship style transfer involves altering text to match the style of a\ntarget author whilst preserving the original meaning. Existing unsupervised\napproaches like STRAP have largely focused on style transfer to target authors\nwith many examples of their writing style in books, speeches, or other\npublished works. This high-resource training data requirement (often greater\nthan 100,000 words) makes these approaches primarily useful for style transfer\nto published authors, politicians, or other well-known figures and authorship\nstyles, while style transfer to non-famous authors has not been well-studied.\nWe introduce the \\textit{low-resource authorship style transfer} task, a more\nchallenging class of authorship style transfer where only a limited amount of\ntext in the target author's style may exist. In our experiments, we\nspecifically choose source and target authors from Reddit and style transfer\ntheir Reddit posts, limiting ourselves to just 16 posts (on average ~500 words)\nof the target author's style. Style transfer accuracy is typically measured by\nhow often a classifier or human judge will classify an output as written by the\ntarget author. Recent authorship representations models excel at authorship\nidentification even with just a few writing samples, making automatic\nevaluation of this task possible for the first time through evaluation metrics\nwe propose. Our results establish an in-context learning technique we develop\nas the strongest baseline, though we find current approaches do not yet achieve\nmastery of this challenging task. We release our data and implementations to\nencourage further investigation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Patel_A/0/1/0/all/0/1\">Ajay Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andrews_N/0/1/0/all/0/1\">Nicholas Andrews</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1\">Chris Callison-Burch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental Health on Social Media. (arXiv:2301.11004v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.11004","description":"<p>Interactions among humans on social media often convey intentions behind\ntheir actions, yielding a psychological language resource for Mental Health\nAnalysis (MHA) of online users. The success of Computational Intelligence\nTechniques (CIT) for inferring mental illness from such social media resources\npoints to NLP as a lens for causal analysis and perception mining. However, we\nargue that more consequential and explainable research is required for optimal\nimpact on clinical psychology practice and personalized mental healthcare. To\nbridge this gap, we posit two significant dimensions: (1) Causal analysis to\nillustrate a cause and effect relationship in the user generated text; (2)\nPerception mining to infer psychological perspectives of social effects on\nonline users intentions. Within the scope of Natural Language Processing (NLP),\nwe further explore critical areas of inquiry associated with these two\ndimensions, specifically through recent advancements in discourse analysis.\nThis position paper guides the community to explore solutions in this space and\nadvance the state of practice in developing conversational agents for inferring\nmental health from social media. We advocate for a more explainable approach\ntoward modeling computational psychology problems through the lens of language\nas we observe an increased number of research contributions in dataset and\nproblem formulation for causal relation extraction and perception enhancements\nwhile inferring mental states.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Garg_M/0/1/0/all/0/1\">Muskan Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxena_C/0/1/0/all/0/1\">Chandni Saxena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naseem_U/0/1/0/all/0/1\">Usman Naseem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dorr_B/0/1/0/all/0/1\">Bonnie J Dorr</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Domain Specific Question Answering Over Knowledge Graphs Using Logical Programming and Large Language Models. (arXiv:2303.02206v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2303.02206","description":"<p>Answering questions over domain-specific graphs requires a tailored approach\ndue to the limited number of relations and the specific nature of the domain.\nOur approach integrates classic logical programming languages into large\nlanguage models (LLMs), enabling the utilization of logical reasoning\ncapabilities to tackle the KGQA task. By representing the questions as Prolog\nqueries, which are readable and near close to natural language in\nrepresentation, we facilitate the generation of programmatically derived\nanswers. To validate the effectiveness of our approach, we evaluate it using a\nwell-known benchmark dataset, MetaQA. Our experimental results demonstrate that\nour method achieves accurate identification of correct answer entities for all\ntest questions, even when trained on a small fraction of annotated data.\nOverall, our work presents a promising approach to addressing question\nanswering over domain-specific graphs, offering an explainable and robust\nsolution by incorporating logical programming languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Madani_N/0/1/0/all/0/1\">Navid Madani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srihari_R/0/1/0/all/0/1\">Rohini K. Srihari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joseph_K/0/1/0/all/0/1\">Kenneth Joseph</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chain-of-Thought Prompt Distillation for Multimodal Named Entity Recognition and Multimodal Relation Extraction. (arXiv:2306.14122v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.14122","description":"<p>Multimodal Named Entity Recognition (MNER) and Multimodal Relation Extraction\n(MRE) necessitate the fundamental reasoning capacity for intricate linguistic\nand multimodal comprehension. In this study, we explore distilling the\nreasoning ability of large language models (LLMs) into a more compact student\nmodel by generating a \\textit{chain of thought} (CoT) -- a sequence of\nintermediate reasoning steps. Specifically, we commence by exemplifying the\nelicitation of such reasoning ability from LLMs through CoT prompts covering\nmulti-grain (noun, sentence, multimodality) and data-augmentation (style,\nentity, image) dimensions. Subsequently, we present a novel conditional prompt\ndistillation method to assimilate the commonsense reasoning ability from LLMs,\nthereby enhancing the utility of the student model in addressing text-only\ninputs without the requisite addition of image and CoT knowledge. Extensive\nexperiments reveal that our approach attains state-of-the-art accuracy and\nmanifests a plethora of advantages concerning interpretability, data\nefficiency, and cross-domain generalization on MNER and MRE datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yujian Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparison of Machine Learning Methods for Assigning Software Issues to Team Members. (arXiv:2307.00009v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.00009","description":"<p>Software issues contain units of work to fix, improve, or create new threads\nduring the development and facilitate communication among the team members.\nAssigning an issue to the most relevant team member and determining a category\nof an issue is a tedious and challenging task. Wrong classifications cause\ndelays and rework in the project and trouble among the team members. This paper\nproposes a set of carefully curated linguistic features for shallow machine\nlearning methods and compares the performance of shallow and ensemble methods\nwith deep language models. Unlike the state-of-the-art, we assign issues to\nfour roles (designer, developer, tester, and leader) rather than to specific\nindividuals or teams to contribute to the generality of our solution. We also\nconsider the level of experience of the developers to reflect the industrial\npractices in our solution formulation. We collect and annotate five industrial\ndata sets from one of the top three global television producers to evaluate our\nproposal and compare it with deep language models. Our data sets contain 5324\nissues in total. We show that an ensemble classifier of shallow techniques\nachieves 0.92 for issue assignment in accuracy which is statistically\ncomparable to the state-of-the-art deep language models. The contributions\ninclude the public sharing of five annotated industrial issue data sets, the\ndevelopment of a clear and comprehensive feature set, the introduction of a\nnovel label set, and the validation of the efficacy of an ensemble classifier\nof shallow machine learning techniques.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tabak_B/0/1/0/all/0/1\">B&#xfc;&#x15f;ra Tabak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aydemir_F/0/1/0/all/0/1\">Fatma Ba&#x15f;ak Aydemir</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-consistency for open-ended generations. (arXiv:2307.06857v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2307.06857","description":"<p>Large Language Models (LLMs) can exhibit considerable variation in the\nquality of their sampled outputs. Reranking and selecting the best generation\nfrom the sampled set is a popular way of obtaining strong gains in generation\nquality. In this paper, we present a novel approach for reranking LLM\ngenerations. Unlike other techniques that might involve additional inferences\nor training a specialized reranker, our approach relies on easy to compute\npairwise statistics between the generations that have minimal compute overhead.\nWe show that our approach can be formalized as an extension of self-consistency\nand analyze its performance in that framework, theoretically as well as via\nsimulations. We show strong improvements for selecting the best $k$ generations\nfor code generation tasks as well as robust improvements for best generation\nfor the tasks of autoformalization, and summarization. While our approach only\nassumes black-box access to LLMs, we show that additional access to token\nprobabilities can improve performance even further.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Siddhartha Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaofei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deoras_A/0/1/0/all/0/1\">Anoop Deoras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_B/0/1/0/all/0/1\">Bing Xiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Landscape of Natural Language Processing Research. (arXiv:2307.10652v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.10652","description":"<p>As an efficient approach to understand, generate, and process natural\nlanguage texts, research in natural language processing (NLP) has exhibited a\nrapid spread and wide adoption in recent years. Given the increasing research\nwork in this area, several NLP-related approaches have been surveyed in the\nresearch community. However, a comprehensive study that categorizes established\ntopics, identifies trends, and outlines areas for future research remains\nabsent. Contributing to closing this gap, we have systematically classified and\nanalyzed research papers in the ACL Anthology. As a result, we present a\nstructured overview of the research landscape, provide a taxonomy of fields of\nstudy in NLP, analyze recent developments in NLP, summarize our findings, and\nhighlight directions for future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schopf_T/0/1/0/all/0/1\">Tim Schopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arabi_K/0/1/0/all/0/1\">Karim Arabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matthes_F/0/1/0/all/0/1\">Florian Matthes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey. (arXiv:2307.16680v4 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2307.16680","description":"<p>Diffusion models and large language models have emerged as leading-edge\ngenerative models and have sparked a revolutionary impact on various aspects of\nhuman life. However, the practical implementation of these models has also\nexposed inherent risks, highlighting their dual nature and raising concerns\nregarding their trustworthiness. Despite the abundance of literature on this\nsubject, a comprehensive survey specifically delving into the intersection of\nlarge-scale generative models and their trustworthiness remains largely absent.\nTo bridge this gap, This paper investigates both the long-standing and emerging\nthreats associated with these models across four fundamental dimensions:\nprivacy, security, fairness, and responsibility. In this way, we construct an\nextensive map outlining the trustworthiness of these models, while also\nproviding practical recommendations and identifying future directions. These\nefforts are crucial for promoting the trustworthy deployment of these models,\nultimately benefiting society as a whole.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_M/0/1/0/all/0/1\">Mingyuan Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Cen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jun Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Forward-Backward Reasoning in Large Language Models for Verification. (arXiv:2308.07758v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.07758","description":"<p>Chain-of-Though (CoT) prompting has shown promising performance in various\nreasoning tasks. Recently, Self-Consistency \\citep{wang2023selfconsistency}\nproposes to sample a diverse set of reasoning chains which may lead to\ndifferent answers while the answer that receives the most votes is selected. In\nthis paper, we propose a novel method to use backward reasoning in verifying\ncandidate answers. We mask a token in the question by ${\\bf x}$ and ask the LLM\nto predict the masked token when a candidate answer is provided by \\textit{a\nsimple template}, i.e., \"\\textit{\\textbf{If we know the answer of the above\nquestion is \\{a candidate answer\\}, what is the value of unknown variable ${\\bf\nx}$?}}\" Intuitively, the LLM is expected to predict the masked token\nsuccessfully if the provided candidate answer is correct. We further propose\nFOBAR to combine forward and backward reasoning for estimating the probability\nof candidate answers. We conduct extensive experiments on six data sets and\nthree LLMs. Experimental results demonstrate that FOBAR achieves\nstate-of-the-art performance on various reasoning benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Weisen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Han Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Longhui Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1\">James T. Kwok</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MemoChat: Tuning LLMs to Use Memos for Consistent Long-Range Open-Domain Conversation. (arXiv:2308.08239v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.08239","description":"<p>We propose MemoChat, a pipeline for refining instructions that enables large\nlanguage models (LLMs) to effectively employ self-composed memos for\nmaintaining consistent long-range open-domain conversations. We demonstrate a\nlong-range open-domain conversation through iterative\n\"memorization-retrieval-response\" cycles. This requires us to carefully design\ntailored tuning instructions for each distinct stage. The instructions are\nreconstructed from a collection of public datasets to teach the LLMs to\nmemorize and retrieve past dialogues with structured memos, leading to enhanced\nconsistency when participating in future conversations. We invite experts to\nmanually annotate a test set designed to evaluate the consistency of long-range\nconversations questions. Experiments on three testing scenarios involving both\nopen-source and API-accessible chatbots at scale verify the efficacy of\nMemoChat, which outperforms strong baselines. Our codes, data and models are\navailable here: https://github.com/LuJunru/MemoChat.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Junru Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_S/0/1/0/all/0/1\">Siyu An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Mingbao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pergola_G/0/1/0/all/0/1\">Gabriele Pergola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yulan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1\">Di Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xing Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yunsheng Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment. (arXiv:2308.09662v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.09662","description":"<p>Larger language models (LLMs) have taken the world by storm with their\nmassive multi-tasking capabilities simply by optimizing over a next-word\nprediction objective. With the emergence of their properties and encoded\nknowledge, the risk of LLMs producing harmful outputs increases, making them\nunfit for scalable deployment for the public. In this work, we propose a new\nsafety evaluation benchmark RED-EVAL that carries out red-teaming. We show that\neven widely deployed models are susceptible to the Chain of Utterances-based\n(CoU) prompting, jailbreaking closed source LLM-based systems such as GPT-4 and\nChatGPT to unethically respond to more than 65% and 73% of harmful queries. We\nalso demonstrate the consistency of the RED-EVAL across 8 open-source LLMs in\ngenerating harmful responses in more than 86% of the red-teaming attempts.\nNext, we propose RED-INSTRUCT--An approach for the safety alignment of LLMs. It\nconstitutes two phases: 1) HARMFULQA data collection: Leveraging CoU prompting,\nwe collect a dataset that consists of 1.9K harmful questions covering a wide\nrange of topics, 9.5K safe and 7.3K harmful conversations from ChatGPT; 2)\nSAFE-ALIGN: We demonstrate how the conversational dataset can be used for the\nsafety alignment of LLMs by minimizing the negative log-likelihood over helpful\nresponses and penalizing over harmful responses by gradient accent over sample\nloss. Our model STARLING, a fine-tuned Vicuna-7B, is observed to be more safely\naligned when evaluated on RED-EVAL and HHH benchmarks while preserving the\nutility of the baseline models (TruthfulQA, MMLU, and BBH).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhardwaj_R/0/1/0/all/0/1\">Rishabh Bhardwaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1\">Soujanya Poria</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Good Are Large Language Models at Out-of-Distribution Detection?. (arXiv:2308.10261v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.10261","description":"<p>Out-of-distribution (OOD) detection plays a vital role in enhancing the\nreliability of machine learning (ML) models. The emergence of large language\nmodels (LLMs) has catalyzed a paradigm shift within the ML community,\nshowcasing their exceptional capabilities across diverse natural language\nprocessing tasks. While existing research has probed OOD detection with\nrelative small-scale Transformers like BERT, RoBERTa and GPT-2, the stark\ndifferences in scales, pre-training objectives, and inference paradigms call\ninto question the applicability of these findings to LLMs. This paper embarks\non a pioneering empirical investigation of OOD detection in the domain of LLMs,\nfocusing on LLaMA series ranging from 7B to 65B in size. We thoroughly evaluate\ncommonly-used OOD detectors, scrutinizing their performance in both zero-grad\nand fine-tuning scenarios. Notably, we alter previous discriminative\nin-distribution fine-tuning into generative fine-tuning, aligning the\npre-training objective of LLMs with downstream tasks. Our findings unveil that\na simple cosine distance OOD detector demonstrates superior efficacy,\noutperforming other OOD detectors. We provide an intriguing explanation for\nthis phenomenon by highlighting the isotropic nature of the embedding spaces of\nLLMs, which distinctly contrasts with the anisotropic property observed in\nsmaller BERT family models. The new insight enhances our understanding of how\nLLMs detect OOD data, thereby enhancing their adaptability and reliability in\ndynamic environments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_L/0/1/0/all/0/1\">Liming Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zexin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yujie Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1\">Lei Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiao-Ming Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Human-on-the-Loop Optimization Autoformalism Approach for Sustainability. (arXiv:2308.10380v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2308.10380","description":"<p>This paper outlines a natural conversational approach to solving personalized\nenergy-related problems using large language models (LLMs). We focus on\ncustomizable optimization problems that necessitate repeated solving with\nslight variations in modeling and are user-specific, hence posing a challenge\nto devising a one-size-fits-all model. We put forward a strategy that augments\nan LLM with an optimization solver, enhancing its proficiency in understanding\nand responding to user specifications and preferences while providing nonlinear\nreasoning capabilities. Our approach pioneers the novel concept of human-guided\noptimization autoformalism, translating a natural language task specification\nautomatically into an optimization instance. This enables LLMs to analyze,\nexplain, and tackle a variety of instance-specific energy-related problems,\npushing beyond the limits of current prompt-based techniques.\n</p>\n<p>Our research encompasses various commonplace tasks in the energy sector, from\nelectric vehicle charging and Heating, Ventilation, and Air Conditioning (HVAC)\ncontrol to long-term planning problems such as cost-benefit evaluations for\ninstalling rooftop solar photovoltaics (PVs) or heat pumps. This pilot study\nmarks an essential stride towards the context-based formulation of optimization\nusing LLMs, with the potential to democratize optimization processes. As a\nresult, stakeholders are empowered to optimize their energy consumption,\npromoting sustainable energy practices customized to personal needs and\npreferences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1\">Ming Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sel_B/0/1/0/all/0/1\">Bilgehan Sel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hardeep_F/0/1/0/all/0/1\">Fnu Hardeep</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1\">Wotao Yin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BAN-PL: a Novel Polish Dataset of Banned Harmful and Offensive Content from Wykop.pl web service. (arXiv:2308.10592v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.10592","description":"<p>Advances in automated detection of offensive language online, including hate\nspeech and cyberbullying, require improved access to publicly available\ndatasets comprising social media content. In this paper, we introduce BAN-PL,\nthe first open dataset in the Polish language that encompasses texts flagged as\nharmful and subsequently removed by professional moderators. The dataset\nencompasses a total of 691,662 pieces of content from a popular social\nnetworking service, Wykop, often referred to as the \"Polish Reddit\", including\nboth posts and comments, and is evenly distributed into two distinct classes:\n\"harmful\" and \"neutral\". We provide a comprehensive description of the data\ncollection and preprocessing procedures, as well as highlight the linguistic\nspecificity of the data. The BAN-PL dataset, along with advanced preprocessing\nscripts for, i.a., unmasking profanities, will be publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Okulska_I/0/1/0/all/0/1\">Inez Okulska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glabinska_K/0/1/0/all/0/1\">Kinga G&#x142;&#x105;bi&#x144;ska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolos_A/0/1/0/all/0/1\">Anna Ko&#x142;os</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlinska_A/0/1/0/all/0/1\">Agnieszka Karli&#x144;ska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wisnios_E/0/1/0/all/0/1\">Emilia Wi&#x15b;nios</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nowakowski_A/0/1/0/all/0/1\">Adam Nowakowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellerik_P/0/1/0/all/0/1\">Pawe&#x142; Ellerik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pralat_A/0/1/0/all/0/1\">Andrzej Pra&#x142;at</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SONAR: Sentence-Level Multimodal and Language-Agnostic Representations. (arXiv:2308.11466v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.11466","description":"<p>We introduce SONAR, a new multilingual and multimodal fixed-size sentence\nembedding space. Our single text encoder, covering 200 languages, substantially\noutperforms existing sentence embeddings such as LASER3 and LabSE on the xsim\nand xsim++ multilingual similarity search tasks. Speech segments can be\nembedded in the same SONAR embedding space using language-specific speech\nencoders trained in a teacher-student setting on speech transcription data. Our\nencoders outperform existing speech encoders on similarity search tasks. We\nalso provide a text decoder for 200 languages, which allows us to perform\ntext-to-text and speech-to-text machine translation, including for zero-shot\nlanguage and modality combinations. Our text-to-text results are competitive\ncompared to the state-of-the-art NLLB~1B model, despite the fixed-size\nbottleneck representation. Our zero-shot speech-to-text translation results\ncompare favorably with strong supervised baselines such as Whisper.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Duquenne_P/0/1/0/all/0/1\">Paul-Ambroise Duquenne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwenk_H/0/1/0/all/0/1\">Holger Schwenk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagot_B/0/1/0/all/0/1\">Beno&#xee;t Sagot</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Model as a User Simulator. (arXiv:2308.11534v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.11534","description":"<p>The unparalleled performance of closed-sourced ChatGPT has sparked efforts\ntowards its democratization, with notable strides made by leveraging real user\nand ChatGPT conversations, as evidenced by Vicuna. However, while current\nendeavors like Baize and UltraChat aim to auto-generate conversational data due\nto challenges in gathering human participation, they primarily rely on ChatGPT\nto simulate human behaviors based on directives rather than genuine human\nlearning. This results in a limited scope, diminished diversity, and an absence\nof genuine multi-round conversational dynamics. To address the above issues, we\ninnovatively target human questions extracted from genuine human-machine\nconversations as a learning goal and train a user simulator, UserGPT, to\nproduce a high-quality human-centric synthetic conversation dataset, RealChat.\nSubsequently, this dataset trains our assistant model, ReaLM. Experimentally,\nReaLM outpaces baseline models in both Vicuna-Bench and MT-Bench by pairwise\ncomparison when considering equivalent training set sizes, and manual\nevaluation also shows that our model is highly competitive. Impressively, when\nfine-tuned with the latest LLaMA 2 model, ReaLM secured a leading score of 6.33\nin the MT-Bench, outshining the contemporary same-scale models, including the\nLLaMA-2-7B-chat model. Further in-depth analysis demonstrates the scalability\nand transferability of our approach. A preliminary exploration into the\ninterplay between training set data quality and resultant model performance is\nalso undertaken, laying a robust groundwork for future investigations. The code\nis available at https://github.com/FreedomIntelligence/ReaLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kong_C/0/1/0/all/0/1\">Chuyi Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yaxin Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiang Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_F/0/1/0/all/0/1\">Feng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Benyou Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tryage: Real-time, intelligent Routing of User Prompts to Large Language Models. (arXiv:2308.11601v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2308.11601","description":"<p>The introduction of the transformer architecture and the self-attention\nmechanism has led to an explosive production of language models trained on\nspecific downstream tasks and data domains. With over 200, 000 models in the\nHugging Face ecosystem, users grapple with selecting and optimizing models to\nsuit multifaceted workflows and data domains while addressing computational,\nsecurity, and recency concerns. There is an urgent need for machine learning\nframeworks that can eliminate the burden of model selection and customization\nand unleash the incredible power of the vast emerging model library for end\nusers. Here, we propose a context-aware routing system, Tryage, that leverages\na language model router for optimal selection of expert models from a model\nlibrary based on analysis of individual input prompts. Inspired by the thalamic\nrouter in the brain, Tryage employs a perceptive router to predict down-stream\nmodel performance on prompts and, then, makes a routing decision using an\nobjective function that integrates performance predictions with user goals and\nconstraints that are incorporated through flags (e.g., model size, model\nrecency). Tryage allows users to explore a Pareto front and automatically\ntrade-off between task accuracy and secondary goals including minimization of\nmodel size, recency, security, verbosity, and readability. Across heterogeneous\ndata sets that include code, text, clinical data, and patents, the Tryage\nframework surpasses Gorilla and GPT3.5 turbo in dynamic model selection\nidentifying the optimal model with an accuracy of 50.9% , compared to 23.6% by\nGPT 3.5 Turbo and 10.8% by Gorilla. Conceptually, Tryage demonstrates how\nrouting models can be applied to program and control the behavior of\nmulti-model LLM systems to maximize efficient use of the expanding and evolving\nlanguage model ecosystem.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hari_S/0/1/0/all/0/1\">Surya Narayanan Hari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomson_M/0/1/0/all/0/1\">Matt Thomson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-08-23T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","syn":"http://purl.org/rss/1.0/modules/syndication/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","dc":"http://purl.org/dc/elements/1.1/"}}]}]}