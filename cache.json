{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-09-15T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Exploring Large Language Models for Ontology Alignment. (arXiv:2309.07172v1 [cs.AI])","link":"http://arxiv.org/abs/2309.07172","description":"<p>This work investigates the applicability of recent generative Large Language\nModels (LLMs), such as the GPT series and Flan-T5, to ontology alignment for\nidentifying concept equivalence mappings across ontologies. To test the\nzero-shot performance of Flan-T5-XXL and GPT-3.5-turbo, we leverage challenging\nsubsets from two equivalence matching datasets of the OAEI Bio-ML track, taking\ninto account concept labels and structural contexts. Preliminary findings\nsuggest that LLMs have the potential to outperform existing ontology alignment\nsystems like BERTMap, given careful framework and prompt design.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaoyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horrocks_I/0/1/0/all/0/1\">Ian Horrocks</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In-Contextual Bias Suppression for Large Language Models. (arXiv:2309.07251v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07251","description":"<p>Despite their impressive performance in a wide range of NLP tasks, Large\nLanguage Models (LLMs) have been reported to encode worrying-levels of gender\nbias. Prior work has proposed debiasing methods that require human labelled\nexamples, data augmentation and fine-tuning of the LLMs, which are\ncomputationally costly. Moreover, one might not even have access to the\ninternal parameters for performing debiasing such as in the case of\ncommercially available LLMs such as GPT-4. To address this challenge we propose\nbias suppression, a novel alternative to debiasing that does not require access\nto model parameters. We show that text-based preambles, generated from manually\ndesigned templates covering counterfactual statements, can accurately suppress\ngender biases in LLMs. Moreover, we find that descriptive sentences for\noccupations can further suppress gender biases. Interestingly, we find that\nbias suppression has a minimal adverse effect on downstream task performance,\nwhile effectively mitigating the gender biases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oba_D/0/1/0/all/0/1\">Daisuke Oba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaneko_M/0/1/0/all/0/1\">Masahiro Kaneko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bollegala_D/0/1/0/all/0/1\">Danushka Bollegala</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs. (arXiv:2309.07311v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07311","description":"<p>Most interpretability research in NLP focuses on understanding the behavior\nand features of a fully trained model. However, certain insights into model\nbehavior may only be accessible by observing the trajectory of the training\nprocess. In this paper, we present a case study of syntax acquisition in masked\nlanguage models (MLMs). Our findings demonstrate how analyzing the evolution of\ninterpretable artifacts throughout training deepens our understanding of\nemergent behavior. In particular, we study Syntactic Attention Structure (SAS),\na naturally emerging property of MLMs wherein specific Transformer heads tend\nto focus on specific syntactic relations. We identify a brief window in\ntraining when models abruptly acquire SAS and find that this window is\nconcurrent with a steep drop in loss. Moreover, SAS precipitates the subsequent\nacquisition of linguistic capabilities. We then examine the causal role of SAS\nby introducing a regularizer to manipulate SAS during training, and demonstrate\nthat SAS is necessary for the development of grammatical capabilities. We\nfurther find that SAS competes with other beneficial traits and capabilities\nduring training, and that briefly suppressing SAS can improve model quality.\nThese findings reveal a real-world example of the relationship between\ndisadvantageous simplicity bias and interpretable breakthrough training\ndynamics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Angelica Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_Ziv_R/0/1/0/all/0/1\">Ravid Schwartz-Ziv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leavitt_M/0/1/0/all/0/1\">Matthew L. Leavitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saphra_N/0/1/0/all/0/1\">Naomi Saphra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Traveling Words: A Geometric Interpretation of Transformers. (arXiv:2309.07315v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07315","description":"<p>Transformers have significantly advanced the field of natural language\nprocessing, but comprehending their internal mechanisms remains a challenge. In\nthis paper, we introduce a novel geometric perspective that elucidates the\ninner mechanisms of transformer operations. Our primary contribution is\nillustrating how layer normalization confines the latent features to a\nhyper-sphere, subsequently enabling attention to mold the semantic\nrepresentation of words on this surface. This geometric viewpoint seamlessly\nconnects established properties such as iterative refinement and contextual\nembeddings. We validate our insights by probing a pre-trained 124M parameter\nGPT-2 model. Our findings reveal clear query-key attention patterns in early\nlayers and build upon prior observations regarding the subject-specific nature\nof attention heads at deeper layers. Harnessing these geometric insights, we\npresent an intuitive understanding of transformers, depicting them as processes\nthat model the trajectory of word particles along the hyper-sphere.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Molina_R/0/1/0/all/0/1\">Raul Molina</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning from Auxiliary Sources in Argumentative Revision Classification. (arXiv:2309.07334v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07334","description":"<p>We develop models to classify desirable reasoning revisions in argumentative\nwriting. We explore two approaches -- multi-task learning and transfer learning\n-- to take advantage of auxiliary sources of revision data for similar tasks.\nResults of intrinsic and extrinsic evaluations show that both approaches can\nindeed improve classifier performance over baselines. While multi-task learning\nshows that training on different sources of data at the same time may improve\nperformance, transfer-learning better represents the relationship between the\ndata.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Afrin_T/0/1/0/all/0/1\">Tazin Afrin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litman_D/0/1/0/all/0/1\">Diane Litman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hybrid Attention-based Encoder-decoder Model for Efficient Language Model Adaptation. (arXiv:2309.07369v1 [eess.AS])","link":"http://arxiv.org/abs/2309.07369","description":"<p>Attention-based encoder-decoder (AED) speech recognition model has been\nwidely successful in recent years. However, the joint optimization of acoustic\nmodel and language model in end-to-end manner has created challenges for text\nadaptation. In particular, effectively, quickly and inexpensively adapting text\nhas become a primary concern for deploying AED systems in industry. To address\nthis issue, we propose a novel model, the hybrid attention-based\nencoder-decoder (HAED) speech recognition model that preserves the modularity\nof conventional hybrid automatic speech recognition systems. Our HAED model\nseparates the acoustic and language models, allowing for the use of\nconventional text-based language model adaptation techniques. We demonstrate\nthat the proposed HAED model yields 21\\% Word Error Rate (WER) improvements in\nrelative when out-of-domain text data is used for language model adaptation,\nand with only a minor degradation in WER on a general test set compared with\nconventional AED model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Ling_S/0/1/0/all/0/1\">Shaoshi Ling</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ye_G/0/1/0/all/0/1\">Guoli Ye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_R/0/1/0/all/0/1\">Rui Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gong_Y/0/1/0/all/0/1\">Yifan Gong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Less is More for Long Document Summary Evaluation by LLMs. (arXiv:2309.07382v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07382","description":"<p>Large Language Models (LLMs) have shown promising performance in summary\nevaluation tasks, yet they face challenges such as high computational costs and\nthe Lost-in-the-Middle problem where important information in the middle of\nlong documents is often overlooked. To address these issues, this paper\nintroduces a novel approach, Extract-then-Evaluate, which involves extracting\nkey sentences from a long source document and then evaluating the summary by\nprompting LLMs. The results reveal that the proposed method not only\nsignificantly reduces evaluation costs but also exhibits a higher correlation\nwith human evaluations. Furthermore, we provide practical recommendations for\noptimal document length and sentence extraction methods, contributing to the\ndevelopment of cost-effective yet more accurate methods for LLM-based text\ngeneration evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yunshu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iso_H/0/1/0/all/0/1\">Hayate Iso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pezeshkpour_P/0/1/0/all/0/1\">Pouya Pezeshkpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhutani_N/0/1/0/all/0/1\">Nikita Bhutani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hruschka_E/0/1/0/all/0/1\">Estevam Hruschka</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Interactive Framework for Profiling News Media Sources. (arXiv:2309.07384v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07384","description":"<p>The recent rise of social media has led to the spread of large amounts of\nfake and biased news, content published with the intent to sway beliefs. While\ndetecting and profiling the sources that spread this news is important to\nmaintain a healthy society, it is challenging for automated systems.\n</p>\n<p>In this paper, we propose an interactive framework for news media profiling.\nIt combines the strengths of graph based news media profiling models,\nPre-trained Large Language Models, and human insight to characterize the social\ncontext on social media. Experimental results show that with as little as 5\nhuman interactions, our framework can rapidly detect fake and biased news\nmedia, even in the most challenging settings of emerging news events, where\ntest data is unseen.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mehta_N/0/1/0/all/0/1\">Nikhil Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldwasser_D/0/1/0/all/0/1\">Dan Goldwasser</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VDialogUE: A Unified Evaluation Benchmark for Visually-grounded Dialogue. (arXiv:2309.07387v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07387","description":"<p>Visually-grounded dialog systems, which integrate multiple modes of\ncommunication such as text and visual inputs, have become an increasingly\npopular area of investigation. However, the absence of a standardized\nevaluation framework poses a challenge in assessing the development of this\nfield. To this end, we propose \\textbf{VDialogUE}, a \\textbf{V}isually-grounded\n\\textbf{Dialog}ue benchmark for \\textbf{U}nified \\textbf{E}valuation. It\ndefines five core multi-modal dialogue tasks and covers six datasets.\nFurthermore, in order to provide a comprehensive assessment of the model's\nperformance across all tasks, we developed a novel evaluation metric called\nVDscore, which is based on the Analytic Hierarchy Process~(AHP) method.\nAdditionally, we present a straightforward yet efficient baseline model, named\n\\textbf{VISIT}~(\\textbf{VIS}ually-grounded d\\textbf{I}alog\n\\textbf{T}ransformer), to promote the advancement of general multi-modal\ndialogue systems. It progressively builds its multi-modal foundation and\ndialogue capability via a two-stage pre-training strategy.\n</p>\n<p>We believe that the VDialogUE benchmark, along with the evaluation scripts\nand our baseline models, will accelerate the development of visually-grounded\ndialog systems and lead to the development of more sophisticated and effective\npre-trained models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunshui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hui_B/0/1/0/all/0/1\">Binyuan Hui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1\">Zhaochao Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1\">Wanwei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Run Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1\">Yuxing Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Min Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongbin Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DebCSE: Rethinking Unsupervised Contrastive Sentence Embedding Learning in the Debiasing Perspective. (arXiv:2309.07396v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07396","description":"<p>Several prior studies have suggested that word frequency biases can cause the\nBert model to learn indistinguishable sentence embeddings. Contrastive learning\nschemes such as SimCSE and ConSERT have already been adopted successfully in\nunsupervised sentence embedding to improve the quality of embeddings by\nreducing this bias. However, these methods still introduce new biases such as\nsentence length bias and false negative sample bias, that hinders model's\nability to learn more fine-grained semantics. In this paper, we reexamine the\nchallenges of contrastive sentence embedding learning from a debiasing\nperspective and argue that effectively eliminating the influence of various\nbiases is crucial for learning high-quality sentence embeddings. We think all\nthose biases are introduced by simple rules for constructing training data in\ncontrastive learning and the key for contrastive learning sentence embedding is\nto mimic the distribution of training data in supervised machine learning in\nunsupervised way. We propose a novel contrastive framework for sentence\nembedding, termed DebCSE, which can eliminate the impact of these biases by an\ninverse propensity weighted sampling method to select high-quality positive and\nnegative pairs according to both the surface and semantic similarity between\nsentences. Extensive experiments on semantic textual similarity (STS)\nbenchmarks reveal that DebCSE significantly outperforms the latest\nstate-of-the-art models with an average Spearman's correlation coefficient of\n80.33% on BERTbase.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Miao_P/0/1/0/all/0/1\">Pu Miao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1\">Zeyao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junlin Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Advancing Regular Language Reasoning in Linear Recurrent Neural Networks. (arXiv:2309.07412v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07412","description":"<p>In recent studies, linear recurrent neural networks (LRNNs) have achieved\nTransformer-level performance in natural language modeling and long-range\nmodeling while offering rapid parallel training and constant inference costs.\nWith the resurged interest in LRNNs, we study whether they can learn the hidden\nrules in training sequences, such as the grammatical structures of regular\nlanguage. We theoretically analyze some existing LRNNs and discover their\nlimitations on regular language. Motivated by the analysis, we propose a new\nLRNN equipped with a block-diagonal and input-dependent transition matrix.\nExperiments suggest that the proposed model is the only LRNN that can perform\nlength extrapolation on regular language tasks such as Sum, Even Pair, and\nModular Arithmetic.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_T/0/1/0/all/0/1\">Ting-Han Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_T/0/1/0/all/0/1\">Ta-Chung Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudnicky_A/0/1/0/all/0/1\">Alexander I. Rudnicky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CPPF: A contextual and post-processing-free model for automatic speech recognition. (arXiv:2309.07413v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07413","description":"<p>ASR systems have become increasingly widespread in recent years. However,\ntheir textual outputs often require post-processing tasks before they can be\npractically utilized. To address this issue, we draw inspiration from the\nmultifaceted capabilities of LLMs and Whisper, and focus on integrating\nmultiple ASR text processing tasks related to speech recognition into the ASR\nmodel. This integration not only shortens the multi-stage pipeline, but also\nprevents the propagation of cascading errors, resulting in direct generation of\npost-processed text. In this study, we focus on ASR-related processing tasks,\nincluding Contextual ASR and multiple ASR post processing tasks. To achieve\nthis objective, we introduce the CPPF model, which offers a versatile and\nhighly effective alternative to ASR processing. CPPF seamlessly integrates\nthese tasks without any significant loss in recognition performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhengkun Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiaming Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_H/0/1/0/all/0/1\">Hongyu Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1\">Ke Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_G/0/1/0/all/0/1\">Guanglu Wan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PromptASR for contextualized ASR with controllable style. (arXiv:2309.07414v1 [eess.AS])","link":"http://arxiv.org/abs/2309.07414","description":"<p>Prompts are crucial to large language models as they provide context\ninformation such as topic or logical relationships. Inspired by this, we\npropose PromptASR, a framework that integrates prompts in end-to-end automatic\nspeech recognition (E2E ASR) systems to achieve contextualized ASR with\ncontrollable style of transcriptions. Specifically, a dedicated text encoder\nencodes the text prompts and the encodings are injected into the speech encoder\nby cross-attending the features from two modalities. When using the ground\ntruth text from preceding utterances as content prompt, the proposed system\nachieves 21.9% and 6.8% relative word error rate reductions on a book reading\ndataset and an in-house dataset compared to a baseline ASR system. The system\ncan also take word-level biasing lists as prompt to improve recognition\naccuracy on rare words. An additional style prompt can be given to the text\nencoder and guide the ASR system to output different styles of transcriptions.\nThe code is available at icefall.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Yang_X/0/1/0/all/0/1\">Xiaoyu Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kang_W/0/1/0/all/0/1\">Wei Kang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yao_Z/0/1/0/all/0/1\">Zengwei Yao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1\">Yifan Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guo_L/0/1/0/all/0/1\">Liyong Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kuang_F/0/1/0/all/0/1\">Fangjun Kuang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lin_L/0/1/0/all/0/1\">Long Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Povey_D/0/1/0/all/0/1\">Daniel Povey</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT MT: Competitive for High- (but not Low-) Resource Languages. (arXiv:2309.07423v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07423","description":"<p>Large language models (LLMs) implicitly learn to perform a range of language\ntasks, including machine translation (MT). Previous studies explore aspects of\nLLMs' MT capabilities. However, there exist a wide variety of languages for\nwhich recent LLM MT performance has never before been evaluated. Without\npublished experimental evidence on the matter, it is difficult for speakers of\nthe world's diverse languages to know how and whether they can use LLMs for\ntheir languages. We present the first experimental evidence for an expansive\nset of 204 languages, along with MT cost analysis, using the FLORES-200\nbenchmark. Trends reveal that GPT models approach or exceed traditional MT\nmodel performance for some high-resource languages (HRLs) but consistently lag\nfor low-resource languages (LRLs), under-performing traditional MT for 84.1% of\nlanguages we covered. Our analysis reveals that a language's resource level is\nthe most important feature in determining ChatGPT's relative ability to\ntranslate it, and suggests that ChatGPT is especially disadvantaged for LRLs\nand African languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Robinson_N/0/1/0/all/0/1\">Nathaniel R. Robinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ogayo_P/0/1/0/all/0/1\">Perez Ogayo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mortensen_D/0/1/0/all/0/1\">David R. Mortensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Parsing in Limited Resource Conditions. (arXiv:2309.07429v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07429","description":"<p>This thesis explores challenges in semantic parsing, specifically focusing on\nscenarios with limited data and computational resources. It offers solutions\nusing techniques like automatic data curation, knowledge transfer, active\nlearning, and continual learning.\n</p>\n<p>For tasks with no parallel training data, the thesis proposes generating\nsynthetic training examples from structured database schemas. When there is\nabundant data in a source domain but limited parallel data in a target domain,\nknowledge from the source is leveraged to improve parsing in the target domain.\n</p>\n<p>For multilingual situations with limited data in the target languages, the\nthesis introduces a method to adapt parsers using a limited human translation\nbudget. Active learning is applied to select source-language samples for manual\ntranslation, maximizing parser performance in the target language. In addition,\nan alternative method is also proposed to utilize machine translation services,\nsupplemented by human-translated data, to train a more effective parser.\n</p>\n<p>When computational resources are limited, a continual learning approach is\nintroduced to minimize training time and computational memory. This maintains\nthe parser's efficiency in previously learned tasks while adapting it to new\ntasks, mitigating the problem of catastrophic forgetting.\n</p>\n<p>Overall, the thesis provides a comprehensive set of methods to improve\nsemantic parsing in resource-constrained conditions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuang Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Clinical Text Summarization: Adapting Large Language Models Can Outperform Human Experts. (arXiv:2309.07430v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07430","description":"<p>Sifting through vast textual data and summarizing key information imposes a\nsubstantial burden on how clinicians allocate their time. Although large\nlanguage models (LLMs) have shown immense promise in natural language\nprocessing (NLP) tasks, their efficacy across diverse clinical summarization\ntasks has not yet been rigorously examined. In this work, we employ domain\nadaptation methods on eight LLMs, spanning six datasets and four distinct\nsummarization tasks: radiology reports, patient questions, progress notes, and\ndoctor-patient dialogue. Our thorough quantitative assessment reveals\ntrade-offs between models and adaptation methods in addition to instances where\nrecent advances in LLMs may not lead to improved results. Further, in a\nclinical reader study with six physicians, we depict that summaries from the\nbest adapted LLM are preferable to human summaries in terms of completeness and\ncorrectness. Our ensuing qualitative analysis delineates mutual challenges\nfaced by both LLMs and human experts. Lastly, we correlate traditional\nquantitative NLP metrics with reader study scores to enhance our understanding\nof how these metrics align with physician preferences. Our research marks the\nfirst evidence of LLMs outperforming human experts in clinical text\nsummarization across multiple tasks. This implies that integrating LLMs into\nclinical workflows could alleviate documentation burden, empowering clinicians\nto focus more on personalized patient care and other irreplaceable human\naspects of medicine.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Veen_D/0/1/0/all/0/1\">Dave Van Veen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uden_C/0/1/0/all/0/1\">Cara Van Uden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blankemeier_L/0/1/0/all/0/1\">Louis Blankemeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delbrouck_J/0/1/0/all/0/1\">Jean-Benoit Delbrouck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aali_A/0/1/0/all/0/1\">Asad Aali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bluethgen_C/0/1/0/all/0/1\">Christian Bluethgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pareek_A/0/1/0/all/0/1\">Anuj Pareek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polacin_M/0/1/0/all/0/1\">Malgorzata Polacin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collins_W/0/1/0/all/0/1\">William Collins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahuja_N/0/1/0/all/0/1\">Neera Ahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langlotz_C/0/1/0/all/0/1\">Curtis P. Langlotz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hom_J/0/1/0/all/0/1\">Jason Hom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gatidis_S/0/1/0/all/0/1\">Sergios Gatidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pauly_J/0/1/0/all/0/1\">John Pauly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhari_A/0/1/0/all/0/1\">Akshay S. Chaudhari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SIB-200: A Simple, Inclusive, and Big Evaluation Dataset for Topic Classification in 200+ Languages and Dialects. (arXiv:2309.07445v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07445","description":"<p>Despite the progress we have recorded in the last few years in multilingual\nnatural language processing, evaluation is typically limited to a small set of\nlanguages with available datasets which excludes a large number of low-resource\nlanguages. In this paper, we created SIB-200 -- a large-scale open-sourced\nbenchmark dataset for topic classification in 200 languages and dialects to\naddress the lack of evaluation dataset for Natural Language Understanding\n(NLU). For many of the languages covered in SIB-200, this is the first publicly\navailable evaluation dataset for NLU. The dataset is based on Flores-200\nmachine translation corpus. We annotated the English portion of the dataset and\nextended the sentence-level annotation to the remaining 203 languages covered\nin the corpus. Despite the simplicity of this task, our evaluation in\nfull-supervised setting, cross-lingual transfer setting and prompting of large\nlanguage model setting show that there is still a large gap between the\nperformance of high-resource and low-resource languages when multilingual\nevaluation is scaled to numerous world languages. We found that languages\nunseen during the pre-training of multilingual language models,\nunder-represented language families (like Nilotic and Altantic-Congo), and\nlanguages from the regions of Africa, Americas, Oceania and South East Asia,\noften have the lowest performance on our topic classification dataset. We hope\nour dataset will encourage a more inclusive evaluation of multilingual language\nmodels on a more diverse set of languages. https://github.com/dadelani/sib-200\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1\">David Ifeoluwa Adelani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hannah Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xiaoyu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vassilyev_N/0/1/0/all/0/1\">Nikita Vassilyev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alabi_J/0/1/0/all/0/1\">Jesujoba O. Alabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yanke Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1\">Haonan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_A/0/1/0/all/0/1\">Annie En-Shiun Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?. (arXiv:2309.07462v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07462","description":"<p>Large Language Models (LLMs) have demonstrated impressive performance on\nNatural Language Processing (NLP) tasks, such as Question Answering,\nSummarization, and Classification. The use of LLMs as evaluators, that can rank\nor score the output of other models (usually LLMs) has become increasingly\npopular, due to the limitations of current evaluation techniques including the\nlack of appropriate benchmarks, metrics, cost, and access to human annotators.\nWhile LLMs are capable of handling approximately 100 languages, the majority of\nlanguages beyond the top 20 lack systematic evaluation across various tasks,\nmetrics, and benchmarks. This creates an urgent need to scale up multilingual\nevaluation to ensure a precise understanding of LLM performance across diverse\nlanguages. LLM-based evaluators seem like the perfect solution to this problem,\nas they do not require human annotators, human-created references, or\nbenchmarks and can theoretically be used to evaluate any language covered by\nthe LLM. In this paper, we investigate whether LLM-based evaluators can help\nscale up multilingual evaluation. Specifically, we calibrate LLM-based\nevaluation against 20k human judgments of five metrics across three\ntext-generation tasks in eight languages. Our findings indicate that LLM-based\nevaluators may exhibit bias towards higher scores and should be used with\ncaution and should always be calibrated with a dataset of native speaker\njudgments, particularly in low-resource and non-Latin script languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hada_R/0/1/0/all/0/1\">Rishav Hada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gumma_V/0/1/0/all/0/1\">Varun Gumma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wynter_A/0/1/0/all/0/1\">Adrian de Wynter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diddee_H/0/1/0/all/0/1\">Harshita Diddee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_M/0/1/0/all/0/1\">Mohamed Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhury_M/0/1/0/all/0/1\">Monojit Choudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bali_K/0/1/0/all/0/1\">Kalika Bali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sitaram_S/0/1/0/all/0/1\">Sunayana Sitaram</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Direct Text to Speech Translation System using Acoustic Units. (arXiv:2309.07478v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07478","description":"<p>This paper proposes a direct text to speech translation system using discrete\nacoustic units. This framework employs text in different source languages as\ninput to generate speech in the target language without the need for text\ntranscriptions in this language. Motivated by the success of acoustic units in\nprevious works for direct speech to speech translation systems, we use the same\npipeline to extract the acoustic units using a speech encoder combined with a\nclustering algorithm. Once units are obtained, an encoder-decoder architecture\nis trained to predict them. Then a vocoder generates speech from units. Our\napproach for direct text to speech translation was tested on the new CVSS\ncorpus with two different text mBART models employed as initialisation. The\nsystems presented report competitive performance for most of the language pairs\nevaluated. Besides, results show a remarkable improvement when initialising our\nproposed architecture with a model pre-trained with more languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mingote_V/0/1/0/all/0/1\">Victoria Mingote</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gimeno_P/0/1/0/all/0/1\">Pablo Gimeno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vicente_L/0/1/0/all/0/1\">Luis Vicente</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurana_S/0/1/0/all/0/1\">Sameer Khurana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laurent_A/0/1/0/all/0/1\">Antoine Laurent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duret_J/0/1/0/all/0/1\">Jarod Duret</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DBLPLink: An Entity Linker for the DBLP Scholarly Knowledge Graph. (arXiv:2309.07545v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07545","description":"<p>In this work, we present a web application named DBLPLink, which performs\nentity linking over the DBLP scholarly knowledge graph. DBLPLink uses\ntext-to-text pre-trained language models, such as T5, to produce entity label\nspans from an input text question. Entity candidates are fetched from a\ndatabase based on the labels, and an entity re-ranker sorts them based on\nentity embeddings, such as TransE, DistMult and ComplEx. The results are\ndisplayed so that users may compare and contrast the results between T5-small,\nT5-base and the different KG embeddings used. The demo can be accessed at\nhttps://ltdemos.informatik.uni-hamburg.de/dblplink/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_D/0/1/0/all/0/1\">Debayan Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arefa/0/1/0/all/0/1\">Arefa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Usbeck_R/0/1/0/all/0/1\">Ricardo Usbeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biemann_C/0/1/0/all/0/1\">Chris Biemann</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adaptive Prompt Learning with Distilled Connective Knowledge for Implicit Discourse Relation Recognition. (arXiv:2309.07561v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07561","description":"<p>Implicit discourse relation recognition (IDRR) aims at recognizing the\ndiscourse relation between two text segments without an explicit connective.\nRecently, the prompt learning has just been applied to the IDRR task with great\nperformance improvements over various neural network-based approaches. However,\nthe discrete nature of the state-art-of-art prompting approach requires manual\ndesign of templates and answers, a big hurdle for its practical applications.\nIn this paper, we propose a continuous version of prompt learning together with\nconnective knowledge distillation, called AdaptPrompt, to reduce manual design\nefforts via continuous prompting while further improving performance via\nknowledge transfer. In particular, we design and train a few virtual tokens to\nform continuous templates and automatically select the most suitable one by\ngradient search in the embedding space. We also design an answer-relation\nmapping rule to generate a few virtual answers as the answer space.\nFurthermore, we notice the importance of annotated connectives in the training\ndataset and design a teacher-student architecture for knowledge transfer.\nExperiments on the up-to-date PDTB Corpus V3.0 validate our design objectives\nin terms of the better relation recognition performance over the\nstate-of-the-art competitors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhenglin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_W/0/1/0/all/0/1\">Wei Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_Y/0/1/0/all/0/1\">Yijun Mo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revisiting Supertagging for HPSG. (arXiv:2309.07590v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07590","description":"<p>We present new supertaggers trained on HPSG-based treebanks. These treebanks\nfeature high-quality annotation based on a well-developed linguistic theory and\ninclude diverse and challenging test datasets, beyond the usual WSJ section 23\nand Wikipedia data. HPSG supertagging has previously relied on MaxEnt-based\nmodels. We use SVM and neural CRF- and BERT-based methods and show that both\nSVM and neural supertaggers achieve considerably higher accuracy compared to\nthe baseline. Our fine-tuned BERT-based tagger achieves 97.26% accuracy on 1000\nsentences from WSJ23 and 93.88% on the completely out-of-domain The Cathedral\nand the Bazaar (cb)). We conclude that it therefore makes sense to integrate\nthese new supertaggers into modern HPSG parsers, and we also hope that the\ndiverse and difficult datasets we used here will gain more popularity in the\nfield. We contribute the complete dataset reformatted for token classification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zamaraeva_O/0/1/0/all/0/1\">Olga Zamaraeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_Rodriguez_C/0/1/0/all/0/1\">Carlos G&#xf3;mez-Rodr&#xed;guez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"C-Pack: Packaged Resources To Advance General Chinese Embedding. (arXiv:2309.07597v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07597","description":"<p>We introduce C-Pack, a package of resources that significantly advance the\nfield of general Chinese embeddings. C-Pack includes three critical resources.\n1) C-MTEB is a comprehensive benchmark for Chinese text embeddings covering 6\ntasks and 35 datasets. 2) C-MTP is a massive text embedding dataset curated\nfrom labeled and unlabeled Chinese corpora for training embedding models. 3)\nC-TEM is a family of embedding models covering multiple sizes. Our models\noutperform all prior Chinese text embeddings on C-MTEB by up to +10% upon the\ntime of the release. We also integrate and optimize the entire suite of\ntraining methods for C-TEM. Along with our resources on general Chinese\nembedding, we release our data and models for English text embeddings. The\nEnglish models achieve state-of-the-art performance on MTEB benchmark;\nmeanwhile, our released English data is 2 times larger than the Chinese data.\nAll these resources are made publicly available at\nhttps://github.com/FlagOpen/FlagEmbedding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1\">Shitao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Peitian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muennighof_N/0/1/0/all/0/1\">Niklas Muennighof</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting Misinformation with LLM-Predicted Credibility Signals and Weak Supervision. (arXiv:2309.07601v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07601","description":"<p>Credibility signals represent a wide range of heuristics that are typically\nused by journalists and fact-checkers to assess the veracity of online content.\nAutomating the task of credibility signal extraction, however, is very\nchallenging as it requires high-accuracy signal-specific extractors to be\ntrained, while there are currently no sufficiently large datasets annotated\nwith all credibility signals. This paper investigates whether large language\nmodels (LLMs) can be prompted effectively with a set of 18 credibility signals\nto produce weak labels for each signal. We then aggregate these potentially\nnoisy labels using weak supervision in order to predict content veracity. We\ndemonstrate that our approach, which combines zero-shot LLM credibility signal\nlabeling and weak supervision, outperforms state-of-the-art classifiers on two\nmisinformation datasets without using any ground-truth labels for training. We\nalso analyse the contribution of the individual credibility signals towards\npredicting content veracity, which provides new valuable insights into their\nrole in misinformation detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Leite_J/0/1/0/all/0/1\">Jo&#xe3;o A. Leite</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razuvayevskaya_O/0/1/0/all/0/1\">Olesya Razuvayevskaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bontcheva_K/0/1/0/all/0/1\">Kalina Bontcheva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarton_C/0/1/0/all/0/1\">Carolina Scarton</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-shot Audio Topic Reranking using Large Language Models. (arXiv:2309.07606v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07606","description":"<p>The Multimodal Video Search by Examples (MVSE) project investigates using\nvideo clips as the query term for information retrieval, rather than the more\ntraditional text query. This enables far richer search modalities such as\nimages, speaker, content, topic, and emotion. A key element for this process is\nhighly rapid, flexible, search to support large archives, which in MVSE is\nfacilitated by representing video attributes by embeddings. This work aims to\nmitigate any performance loss from this rapid archive search by examining\nreranking approaches. In particular, zero-shot reranking methods using large\nlanguage models are investigated as these are applicable to any video archive\naudio content. Performance is evaluated for topic-based retrieval on a publicly\navailable video archive, the BBC Rewind corpus. Results demonstrate that\nreranking can achieve improved retrieval ranking without the need for any\ntask-specific training data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qian_M/0/1/0/all/0/1\">Mengjie Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_R/0/1/0/all/0/1\">Rao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liusie_A/0/1/0/all/0/1\">Adian Liusie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loweimi_E/0/1/0/all/0/1\">Erfan Loweimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knill_K/0/1/0/all/0/1\">Kate M. Knill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gales_M/0/1/0/all/0/1\">Mark J.F. Gales</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dynamic MOdularized Reasoning for Compositional Structured Explanation Generation. (arXiv:2309.07624v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07624","description":"<p>Despite the success of neural models in solving reasoning tasks, their\ncompositional generalization capabilities remain unclear. In this work, we\npropose a new setting of the structured explanation generation task to\nfacilitate compositional reasoning research. Previous works found that symbolic\nmethods achieve superior compositionality by using pre-defined inference rules\nfor iterative reasoning. But these approaches rely on brittle symbolic\ntransfers and are restricted to well-defined tasks. Hence, we propose a dynamic\nmodularized reasoning model, MORSE, to improve the compositional generalization\nof neural models. MORSE factorizes the inference process into a combination of\nmodules, where each module represents a functional unit. Specifically, we adopt\nmodularized self-attention to dynamically select and route inputs to dedicated\nheads, which specializes them to specific functions. We conduct experiments for\nincreasing lengths and shapes of reasoning trees on two benchmarks to test\nMORSE's compositional generalization abilities, and find it outperforms\ncompetitive baselines. Model ablation and deeper analyses show the\neffectiveness of dynamic reasoning modules and their generalization abilities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1\">Xiyan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Anette Frank</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Incorporating Class-based Language Model for Named Entity Recognition in Factorized Neural Transducer. (arXiv:2309.07648v1 [eess.AS])","link":"http://arxiv.org/abs/2309.07648","description":"<p>In spite of the excellent strides made by end-to-end (E2E) models in speech\nrecognition in recent years, named entity recognition is still challenging but\ncritical for semantic understanding. In order to enhance the ability to\nrecognize named entities in E2E models, previous studies mainly focus on\nvarious rule-based or attention-based contextual biasing algorithms. However,\ntheir performance might be sensitive to the biasing weight or degraded by\nexcessive attention to the named entity list, along with a risk of false\ntriggering. Inspired by the success of the class-based language model (LM) in\nnamed entity recognition in conventional hybrid systems and the effective\ndecoupling of acoustic and linguistic information in the factorized neural\nTransducer (FNT), we propose a novel E2E model to incorporate class-based LMs\ninto FNT, which is referred as C-FNT. In C-FNT, the language model score of\nnamed entities can be associated with the name class instead of its surface\nform. The experimental results show that our proposed C-FNT presents\nsignificant error reduction in named entities without hurting performance in\ngeneral word recognition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Wang_P/0/1/0/all/0/1\">Peng Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1\">Yifan Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_Z/0/1/0/all/0/1\">Zheng Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tan_T/0/1/0/all/0/1\">Tian Tan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_S/0/1/0/all/0/1\">Shiliang Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xie Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Data Visualization Generation from Chinese Natural Language Questions. (arXiv:2309.07650v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07650","description":"<p>Data visualization has emerged as an effective tool for getting insights from\nmassive datasets. Due to the hardness of manipulating the programming languages\nof data visualization, automatic data visualization generation from natural\nlanguages (Text-to-Vis) is becoming increasingly popular. Despite the plethora\nof research effort on the English Text-to-Vis, studies have yet to be conducted\non data visualization generation from questions in Chinese. Motivated by this,\nwe propose a Chinese Text-to-Vis dataset in the paper and demonstrate our first\nattempt to tackle this problem. Our model integrates multilingual BERT as the\nencoder, boosts the cross-lingual ability, and infuses the $n$-gram information\ninto our word representation learning. Our experimental results show that our\ndataset is challenging and deserves further research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yan Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_V/0/1/0/all/0/1\">Victor Junqiu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yuanfeng Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jason Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_R/0/1/0/all/0/1\">Raymond Chi-Wing Wong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Aligning Speakers: Evaluating and Visualizing Text-based Diarization Using Efficient Multiple Sequence Alignment (Extended Version). (arXiv:2309.07677v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07677","description":"<p>This paper presents a novel evaluation approach to text-based speaker\ndiarization (SD), tackling the limitations of traditional metrics that do not\naccount for any contextual information in text. Two new metrics are proposed,\nText-based Diarization Error Rate and Diarization F1, which perform utterance-\nand word-level evaluations by aligning tokens in reference and hypothesis\ntranscripts. Our metrics encompass more types of errors compared to existing\nones, allowing us to make a more comprehensive analysis in SD. To align tokens,\na multiple sequence alignment algorithm is introduced that supports multiple\nsequences in the reference while handling high-dimensional alignment to the\nhypothesis using dynamic programming. Our work is packaged into two tools,\nalign4d providing an API for our alignment algorithm and TranscribeView for\nvisualizing and evaluating SD errors, which can greatly aid in the creation of\nhigh-quality data, fostering the advancement of dialogue systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chen Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1\">Peilin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jinho D. Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Conversation is Worth A Thousand Recommendations: A Survey of Holistic Conversational Recommender Systems. (arXiv:2309.07682v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07682","description":"<p>Conversational recommender systems (CRS) generate recommendations through an\ninteractive process. However, not all CRS approaches use human conversations as\ntheir source of interaction data; the majority of prior CRS work simulates\ninteractions by exchanging entity-level information. As a result, claims of\nprior CRS work do not generalise to real-world settings where conversations\ntake unexpected turns, or where conversational and intent understanding is not\nperfect. To tackle this challenge, the research community has started to\nexamine holistic CRS, which are trained using conversational data collected\nfrom real-world scenarios. Despite their emergence, such holistic approaches\nare under-explored.\n</p>\n<p>We present a comprehensive survey of holistic CRS methods by summarizing the\nliterature in a structured manner. Our survey recognises holistic CRS\napproaches as having three components: 1) a backbone language model, the\noptional use of 2) external knowledge, and/or 3) external guidance. We also\ngive a detailed analysis of CRS datasets and evaluation methods in real\napplication scenarios. We offer our insight as to the current challenges of\nholistic CRS and possible future trends.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hengchang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1\">Min-Yen Kan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Assessing the nature of large language models: A caution against anthropocentrism. (arXiv:2309.07683v1 [cs.AI])","link":"http://arxiv.org/abs/2309.07683","description":"<p>Generative AI models garnered a large amount of public attention and\nspeculation with the release of OpenAIs chatbot, ChatGPT. At least two opinion\ncamps exist: one excited about possibilities these models offer for fundamental\nchanges to human tasks, and another highly concerned about power these models\nseem to have. To address these concerns, we assessed GPT3.5 using standard,\nnormed, and validated cognitive and personality measures. For this seedling\nproject, we developed a battery of tests that allowed us to estimate the\nboundaries of some of these models capabilities, how stable those capabilities\nare over a short period of time, and how they compare to humans.\n</p>\n<p>Our results indicate that GPT 3.5 is unlikely to have developed sentience,\nalthough its ability to respond to personality inventories is interesting. It\ndid display large variability in both cognitive and personality measures over\nrepeated observations, which is not expected if it had a human-like\npersonality. Variability notwithstanding, GPT3.5 displays what in a human would\nbe considered poor mental health, including low self-esteem and marked\ndissociation from reality despite upbeat and helpful responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Speed_A/0/1/0/all/0/1\">Ann Speed</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated Text. (arXiv:2309.07689v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07689","description":"<p>While recent advancements in the capabilities and widespread accessibility of\ngenerative language models, such as ChatGPT (OpenAI, 2022), have brought about\nvarious benefits by generating fluent human-like text, the task of\ndistinguishing between human- and large language model (LLM) generated text has\nemerged as a crucial problem. These models can potentially deceive by\ngenerating artificial text that appears to be human-generated. This issue is\nparticularly significant in domains such as law, education, and science, where\nensuring the integrity of text is of the utmost importance. This survey\nprovides an overview of the current approaches employed to differentiate\nbetween texts generated by humans and ChatGPT. We present an account of the\ndifferent datasets constructed for detecting ChatGPT-generated text, the\nvarious methods utilized, what qualitative analyses into the characteristics of\nhuman versus ChatGPT-generated text have been performed, and finally, summarize\nour findings into general insights\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dhaini_M/0/1/0/all/0/1\">Mahdi Dhaini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poelman_W/0/1/0/all/0/1\">Wessel Poelman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdogan_E/0/1/0/all/0/1\">Ege Erdogan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tree of Uncertain Thoughts Reasoning for Large Language Models. (arXiv:2309.07694v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07694","description":"<p>While the recently introduced Tree of Thoughts (ToT) has heralded\nadvancements in allowing Large Language Models (LLMs) to reason through\nforesight and backtracking for global decision-making, it has overlooked the\ninherent local uncertainties in intermediate decision points or \"thoughts\".\nThese local uncertainties, intrinsic to LLMs given their potential for diverse\nresponses, remain a significant concern in the reasoning process. Addressing\nthis pivotal gap, we introduce the Tree of Uncertain Thoughts (TouT) - a\nreasoning framework tailored for LLMs. Our TouT effectively leverages Monte\nCarlo Dropout to quantify uncertainty scores associated with LLMs' diverse\nlocal responses at these intermediate steps. By marrying this local uncertainty\nquantification with global search algorithms, TouT enhances the model's\nprecision in response generation. We substantiate our approach with rigorous\nexperiments on two demanding planning tasks: Game of 24 and Mini Crosswords.\nThe empirical evidence underscores TouT's superiority over both ToT and\nchain-of-thought prompting methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mo_S/0/1/0/all/0/1\">Shentong Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_M/0/1/0/all/0/1\">Miao Xin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CoLLD: Contrastive Layer-to-layer Distillation for Compressing Multilingual Pre-trained Speech Encoders. (arXiv:2309.07707v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07707","description":"<p>Large-scale self-supervised pre-trained speech encoders outperform\nconventional approaches in speech recognition and translation tasks. Due to the\nhigh cost of developing these large models, building new encoders for new tasks\nand deploying them to on-device applications are infeasible. Prior studies\npropose model compression methods to address this issue, but those works focus\non smaller models and less realistic tasks. Thus, we propose Contrastive\nLayer-to-layer Distillation (CoLLD), a novel knowledge distillation method to\ncompress pre-trained speech encoders by leveraging masked prediction and\ncontrastive learning to train student models to copy the behavior of a large\nteacher model. CoLLD outperforms prior methods and closes the gap between small\nand large models on multilingual speech-to-text translation and recognition\nbenchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1\">Heng-Jui Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_N/0/1/0/all/0/1\">Ning Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mavlyutov_R/0/1/0/all/0/1\">Ruslan Mavlyutov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popuri_S/0/1/0/all/0/1\">Sravya Popuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_Y/0/1/0/all/0/1\">Yu-An Chung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"L1-aware Multilingual Mispronunciation Detection Framework. (arXiv:2309.07719v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07719","description":"<p>The phonological discrepancies between a speaker's native (L1) and the\nnon-native language (L2) serves as a major factor for mispronunciation. This\npaper introduces a novel multilingual MDD architecture, L1-MultiMDD, enriched\nwith L1-aware speech representation. An end-to-end speech encoder is trained on\nthe input signal and its corresponding reference phoneme sequence. First, an\nattention mechanism is deployed to align the input audio with the reference\nphoneme sequence. Afterwards, the L1-L2-speech embedding are extracted from an\nauxiliary model, pretrained in a multi-task setup identifying L1 and L2\nlanguage, and are infused with the primary network. Finally, the L1-MultiMDD is\nthen optimized for a unified multilingual phoneme recognition task using\nconnectionist temporal classification (CTC) loss for the target languages:\nEnglish, Arabic, and Mandarin. Our experiments demonstrate the effectiveness of\nthe proposed L1-MultiMDD framework on both seen -- L2-ARTIC, LATIC, and\nAraVoiceL2v2; and unseen -- EpaDB and Speechocean762 datasets. The consistent\ngains in PER, and false rejection rate (FRR) across all target languages\nconfirm our approach's robustness, efficacy, and generalizability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kheir_Y/0/1/0/all/0/1\">Yassine El Kheir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chwodhury_S/0/1/0/all/0/1\">Shammur Absar Chwodhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1\">Ahmed Ali</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PerPLM: Personalized Fine-tuning of Pretrained Language Models via Writer-specific Intermediate Learning and Prompts. (arXiv:2309.07727v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07727","description":"<p>The meanings of words and phrases depend not only on where they are used\n(contexts) but also on who use them (writers). Pretrained language models\n(PLMs) are powerful tools for capturing context, but they are typically\npretrained and fine-tuned for universal use across different writers. This\nstudy aims to improve the accuracy of text understanding tasks by personalizing\nthe fine-tuning of PLMs for specific writers. We focus on a general setting\nwhere only the plain text from target writers are available for\npersonalization. To avoid the cost of fine-tuning and storing multiple copies\nof PLMs for different users, we exhaustively explore using writer-specific\nprompts to personalize a unified PLM. Since the design and evaluation of these\nprompts is an underdeveloped area, we introduce and compare different types of\nprompts that are possible in our setting. To maximize the potential of\nprompt-based personalized fine-tuning, we propose a personalized intermediate\nlearning based on masked language modeling to extract task-independent traits\nof writers' text. Our experiments, using multiple tasks, datasets, and PLMs,\nreveal the nature of different prompts and the effectiveness of our\nintermediate learning approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oba_D/0/1/0/all/0/1\">Daisuke Oba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshinaga_N/0/1/0/all/0/1\">Naoki Yoshinaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toyoda_M/0/1/0/all/0/1\">Masashi Toyoda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explaining Speech Classification Models via Word-Level Audio Segments and Paralinguistic Features. (arXiv:2309.07733v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07733","description":"<p>Recent advances in eXplainable AI (XAI) have provided new insights into how\nmodels for vision, language, and tabular data operate. However, few approaches\nexist for understanding speech models. Existing work focuses on a few spoken\nlanguage understanding (SLU) tasks, and explanations are difficult to interpret\nfor most users. We introduce a new approach to explain speech classification\nmodels. We generate easy-to-interpret explanations via input perturbation on\ntwo information levels. 1) Word-level explanations reveal how each word-related\naudio segment impacts the outcome. 2) Paralinguistic features (e.g., prosody\nand background noise) answer the counterfactual: ``What would the model\nprediction be if we edited the audio signal in this way?'' We validate our\napproach by explaining two state-of-the-art SLU models on two speech\nclassification tasks in English and Italian. Our findings demonstrate that the\nexplanations are faithful to the model's inner workings and plausible to\nhumans. Our method and findings pave the way for future research on\ninterpreting speech models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pastor_E/0/1/0/all/0/1\">Eliana Pastor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koudounas_A/0/1/0/all/0/1\">Alkis Koudounas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Attanasio_G/0/1/0/all/0/1\">Giuseppe Attanasio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovy_D/0/1/0/all/0/1\">Dirk Hovy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baralis_E/0/1/0/all/0/1\">Elena Baralis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The complementary roles of non-verbal cues for Robust Pronunciation Assessment. (arXiv:2309.07739v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07739","description":"<p>Research on pronunciation assessment systems focuses on utilizing phonetic\nand phonological aspects of non-native (L2) speech, often neglecting the rich\nlayer of information hidden within the non-verbal cues. In this study, we\nproposed a novel pronunciation assessment framework, IntraVerbalPA. % The\nframework innovatively incorporates both fine-grained frame- and abstract\nutterance-level non-verbal cues, alongside the conventional speech and phoneme\nrepresentations. Additionally, we introduce ''Goodness of phonemic-duration''\nmetric to effectively model duration distribution within the framework. Our\nresults validate the effectiveness of the proposed IntraVerbalPA framework and\nits individual components, yielding performance that either matches or\noutperforms existing research works.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kheir_Y/0/1/0/all/0/1\">Yassine El Kheir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1\">Shammur Absar Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1\">Ahmed Ali</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generative AI Text Classification using Ensemble LLM Approaches. (arXiv:2309.07755v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07755","description":"<p>Large Language Models (LLMs) have shown impressive performance across a\nvariety of Artificial Intelligence (AI) and natural language processing tasks,\nsuch as content creation, report generation, etc. However, unregulated malign\napplication of these models can create undesirable consequences such as\ngeneration of fake news, plagiarism, etc. As a result, accurate detection of\nAI-generated language can be crucial in responsible usage of LLMs. In this\nwork, we explore 1) whether a certain body of text is AI generated or written\nby human, and 2) attribution of a specific language model in generating a body\nof text. Texts in both English and Spanish are considered. The datasets used in\nthis study are provided as part of the Automated Text Identification\n(AuTexTification) shared task. For each of the research objectives stated\nabove, we propose an ensemble neural model that generates probabilities from\ndifferent pre-trained LLMs which are used as features to a Traditional Machine\nLearning (TML) classifier following it. For the first task of distinguishing\nbetween AI and human generated text, our model ranked in fifth and thirteenth\nplace (with macro $F1$ scores of 0.733 and 0.649) for English and Spanish\ntexts, respectively. For the second task on model attribution, our model ranked\nin first place with macro $F1$ scores of 0.625 and 0.653 for English and\nSpanish texts, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abburi_H/0/1/0/all/0/1\">Harika Abburi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suesserman_M/0/1/0/all/0/1\">Michael Suesserman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pudota_N/0/1/0/all/0/1\">Nirmala Pudota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veeramani_B/0/1/0/all/0/1\">Balaji Veeramani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowen_E/0/1/0/all/0/1\">Edward Bowen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1\">Sanmitra Bhattacharya</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PROGrasp: Pragmatic Human-Robot Communication for Object Grasping. (arXiv:2309.07759v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07759","description":"<p>Interactive Object Grasping (IOG) is the task of identifying and grasping the\ndesired object via human-robot natural language interaction. Current IOG\nsystems assume that a human user initially specifies the target object's\ncategory (e.g., bottle). Inspired by pragmatics, where humans often convey\ntheir intentions by relying on context to achieve goals, we introduce a new IOG\ntask, Pragmatic-IOG, and the corresponding dataset, Intention-oriented\nMulti-modal Dialogue (IM-Dial). In our proposed task scenario, an\nintention-oriented utterance (e.g., \"I am thirsty\") is initially given to the\nrobot. The robot should then identify the target object by interacting with a\nhuman user. Based on the task setup, we propose a new robotic system that can\ninterpret the user's intention and pick up the target object, Pragmatic Object\nGrasping (PROGrasp). PROGrasp performs Pragmatic-IOG by incorporating modules\nfor visual grounding, question asking, object grasping, and most importantly,\nanswer interpretation for pragmatic inference. Experimental results show that\nPROGrasp is effective in offline (i.e., target object discovery) and online\n(i.e., IOG with a physical robot arm) settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kang_G/0/1/0/all/0/1\">Gi-Cheon Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junghyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jaein Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Byoung-Tak Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Echotune: A Modular Extractor Leveraging the Variable-Length Nature of Speech in ASR Tasks. (arXiv:2309.07765v1 [cs.SD])","link":"http://arxiv.org/abs/2309.07765","description":"<p>The Transformer architecture has proven to be highly effective for Automatic\nSpeech Recognition (ASR) tasks, becoming a foundational component for a\nplethora of research in the domain. Historically, many approaches have leaned\non fixed-length attention windows, which becomes problematic for varied speech\nsamples in duration and complexity, leading to data over-smoothing and neglect\nof essential long-term connectivity. Addressing this limitation, we introduce\nEcho-MSA, a nimble module equipped with a variable-length attention mechanism\nthat accommodates a range of speech sample complexities and durations. This\nmodule offers the flexibility to extract speech features across various\ngranularities, spanning from frames and phonemes to words and discourse. The\nproposed design captures the variable length feature of speech and addresses\nthe limitations of fixed-length attention. Our evaluation leverages a parallel\nattention architecture complemented by a dynamic gating mechanism that\namalgamates traditional attention with the Echo-MSA module output. Empirical\nevidence from our study reveals that integrating Echo-MSA into the primary\nmodel's training regime significantly enhances the word error rate (WER)\nperformance, all while preserving the intrinsic stability of the original\nmodel.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sizhou Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Songyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1\">Sen Fang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Usability Evaluation of Spoken Humanoid Embodied Conversational Agents in Mobile Serious Games. (arXiv:2309.07773v1 [cs.HC])","link":"http://arxiv.org/abs/2309.07773","description":"<p>This paper presents an empirical investigation of the extent to which spoken\nHumanoid Embodied Conversational Agents (HECAs) can foster usability in mobile\nserious game (MSG) applications. The aim of the research is to assess the\nimpact of multiple agents and illusion of humanness on the quality of the\ninteraction. The experiment investigates two styles of agent presentation: an\nagent of high human-likeness (HECA) and an agent of low human-likeness (text).\nThe purpose of the experiment is to assess whether and how agents of high\nhumanlikeness can evoke the illusion of humanness and affect usability. Agents\nof high human-likeness were designed by following the ECA design model that is\na proposed guide for ECA development. The results of the experiment with 90\nparticipants show that users prefer to interact with the HECAs. The difference\nbetween the two versions is statistically significant with a large effect size\n(d=1.01), with many of the participants justifying their choice by saying that\nthe human-like characteristics of the HECA made the version more appealing.\nThis research provides key information on the potential effect of HECAs on\nserious games, which can provide insight into the design of future mobile\nserious games.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Korre_D/0/1/0/all/0/1\">Danai Korre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robertson_J/0/1/0/all/0/1\">Judy Robertson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Multimodal Classification of Social Media Posts by Leveraging Image-Text Auxiliary tasks. (arXiv:2309.07794v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07794","description":"<p>Effectively leveraging multimodal information from social media posts is\nessential to various downstream tasks such as sentiment analysis, sarcasm\ndetection and hate speech classification. However, combining text and image\ninformation is challenging because of the idiosyncratic cross-modal semantics\nwith hidden or complementary information present in matching image-text pairs.\nIn this work, we aim to directly model this by proposing the use of two\nauxiliary losses jointly with the main task when fine-tuning any pre-trained\nmultimodal model. Image-Text Contrastive (ITC) brings image-text\nrepresentations of a post closer together and separates them from different\nposts, capturing underlying dependencies. Image-Text Matching (ITM) facilitates\nthe understanding of semantic correspondence between images and text by\npenalizing unrelated pairs. We combine these objectives with five multimodal\nmodels, demonstrating consistent improvements across four popular social media\ndatasets. Furthermore, through detailed analysis, we shed light on the specific\nscenarios and cases where each auxiliary task proves to be most effective.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Villegas_D/0/1/0/all/0/1\">Danae S&#xe1;nchez Villegas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preotiuc_Pietro_D/0/1/0/all/0/1\">Daniel Preo&#x163;iuc-Pietro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Dynamical Principles of Storytelling. (arXiv:2309.07797v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07797","description":"<p>When considering the opening part of 1800 short stories, we find that the\nfirst dozen paragraphs of the average narrative follow an action principle as\ndefined in <a href=\"/abs/2309.06600\">arXiv:2309.06600</a>. When the order of the paragraphs is shuffled, the\naverage no longer exhibits this property. The findings show that there is a\npreferential direction we take in semantic space when starting a story,\npossibly related to a common Western storytelling tradition as implied by\nAristotle in Poetics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Doxas_I/0/1/0/all/0/1\">Isidoros Doxas</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Meiss_J/0/1/0/all/0/1\">James Meiss</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Bottone_S/0/1/0/all/0/1\">Steven Bottone</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Strelich_T/0/1/0/all/0/1\">Tom Strelich</a> (4 and 5), <a href=\"http://arxiv.org/find/cs/1/au:+Plummer_A/0/1/0/all/0/1\">Andrew Plummer</a> (5 and 6), <a href=\"http://arxiv.org/find/cs/1/au:+Breland_A/0/1/0/all/0/1\">Adrienne Breland</a> (5 and 7), <a href=\"http://arxiv.org/find/cs/1/au:+Dennis_S/0/1/0/all/0/1\">Simon Dennis</a> (8 and 9), <a href=\"http://arxiv.org/find/cs/1/au:+Garvin_Doxas_K/0/1/0/all/0/1\">Kathy Garvin-Doxas</a> (9 and 10), <a href=\"http://arxiv.org/find/cs/1/au:+Klymkowsky_M/0/1/0/all/0/1\">Michael Klymkowsky</a> (3) ((1) Northrop Grumman Corporation, (2) Some work performed at the University of Colorado, Boulder, (3) University of Colorado, Boulder, (4) Fusion Constructive LLC, (5) Work performed at Northop Grumman Corporation (6) Current Address JP Morgan, (7) Current address, GALT Aerospace, (8) University of Melbourne, (9) Work performed at the University of Colorado, Boulder, (10) Boulder Internet Technologies)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pop Quiz! Do Pre-trained Code Models Possess Knowledge of Correct API Names?. (arXiv:2309.07804v1 [cs.SE])","link":"http://arxiv.org/abs/2309.07804","description":"<p>Recent breakthroughs in pre-trained code models, such as CodeBERT and Codex,\nhave shown their superior performance in various downstream tasks. The\ncorrectness and unambiguity of API usage among these code models are crucial\nfor achieving desirable program functionalities, requiring them to learn\nvarious API fully qualified names structurally and semantically. Recent studies\nreveal that even state-of-the-art pre-trained code models struggle with\nsuggesting the correct APIs during code generation. However, the reasons for\nsuch poor API usage performance are barely investigated. To address this\nchallenge, we propose using knowledge probing as a means of interpreting code\nmodels, which uses cloze-style tests to measure the knowledge stored in models.\nOur comprehensive study examines a code model's capability of understanding API\nfully qualified names from two different perspectives: API call and API import.\nSpecifically, we reveal that current code models struggle with understanding\nAPI names, with pre-training strategies significantly affecting the quality of\nAPI name learning. We demonstrate that natural language context can assist code\nmodels in locating Python API names and generalize Python API name knowledge to\nunseen data. Our findings provide insights into the limitations and\ncapabilities of current pre-trained code models, and suggest that incorporating\nAPI structure into the pre-training process can improve automated API usage and\ncode representations. This work provides significance for advancing code\nintelligence practices and direction for future studies. All experiment\nresults, data and source code used in this work are available at\n\\url{https://doi.org/10.5281/zenodo.7902072}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_T/0/1/0/all/0/1\">Terry Yue Zhuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1\">Xiaoning Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1\">Zhenchang Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiamou Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_H/0/1/0/all/0/1\">Haowei Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Li Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Liming Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text Classification of Cancer Clinical Trial Eligibility Criteria. (arXiv:2309.07812v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07812","description":"<p>Automatic identification of clinical trials for which a patient is eligible\nis complicated by the fact that trial eligibility is stated in natural\nlanguage. A potential solution to this problem is to employ text classification\nmethods for common types of eligibility criteria. In this study, we focus on\nseven common exclusion criteria in cancer trials: prior malignancy, human\nimmunodeficiency virus, hepatitis B, hepatitis C, psychiatric illness,\ndrug/substance abuse, and autoimmune illness. Our dataset consists of 764 phase\nIII cancer trials with these exclusions annotated at the trial level. We\nexperiment with common transformer models as well as a new pre-trained clinical\ntrial BERT model. Our results demonstrate the feasibility of automatically\nclassifying common exclusion criteria. Additionally, we demonstrate the value\nof a pre-trained language model specifically for clinical trials, which yields\nthe highest average performance across all criteria.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yumeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayaraj_S/0/1/0/all/0/1\">Soumya Jayaraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ludmir_E/0/1/0/all/0/1\">Ethan B Ludmir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_K/0/1/0/all/0/1\">Kirk Roberts</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration. (arXiv:2309.07822v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07822","description":"<p>In recent years, large language models (LLMs) have shown remarkable\ncapabilities at scale, particularly at generating text conditioned on a prompt.\nIn our work, we investigate the use of LLMs to augment training data of small\nlanguage models~(SLMs) with automatically generated counterfactual~(CF)\ninstances -- i.e. minimally altered inputs -- in order to improve\nout-of-domain~(OOD) performance of SLMs in the extractive question\nanswering~(QA) setup. We show that, across various LLM generators, such data\naugmentation consistently enhances OOD performance and improves model\ncalibration for both confidence-based and rationale-augmented calibrator\nmodels. Furthermore, these performance improvements correlate with higher\ndiversity of CF instances in terms of their surface form and semantic content.\nFinally, we show that CF augmented models which are easier to calibrate also\nexhibit much lower entropy when assigning importance, indicating that\nrationale-augmented calibrators prefer concise explanations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sachdeva_R/0/1/0/all/0/1\">Rachneet Sachdeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tutek_M/0/1/0/all/0/1\">Martin Tutek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ExpertQA: Expert-Curated Questions and Attributed Answers. (arXiv:2309.07852v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07852","description":"<p>As language models are adapted by a more sophisticated and diverse set of\nusers, the importance of guaranteeing that they provide factually correct\ninformation supported by verifiable sources is critical across fields of study\n&amp; professions. This is especially the case for high-stakes fields, such as\nmedicine and law, where the risk of propagating false information is high and\ncan lead to undesirable societal consequences. Previous work studying\nfactuality and attribution has not focused on analyzing these characteristics\nof language model outputs in domain-specific scenarios. In this work, we\npresent an evaluation study analyzing various axes of factuality and\nattribution provided in responses from a few systems, by bringing domain\nexperts in the loop. Specifically, we first collect expert-curated questions\nfrom 484 participants across 32 fields of study, and then ask the same experts\nto evaluate generated responses to their own questions. We also ask experts to\nrevise answers produced by language models, which leads to ExpertQA, a\nhigh-quality long-form QA dataset with 2177 questions spanning 32 fields, along\nwith verified answers and attributions for claims in the answers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Malaviya_C/0/1/0/all/0/1\">Chaitanya Malaviya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Subin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sihao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sieber_E/0/1/0/all/0/1\">Elizabeth Sieber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yatskar_M/0/1/0/all/0/1\">Mark Yatskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CiwaGAN: Articulatory information exchange. (arXiv:2309.07861v1 [cs.SD])","link":"http://arxiv.org/abs/2309.07861","description":"<p>Humans encode information into sounds by controlling articulators and decode\ninformation from sounds using the auditory apparatus. This paper introduces\nCiwaGAN, a model of human spoken language acquisition that combines\nunsupervised articulatory modeling with an unsupervised model of information\nexchange through the auditory modality. While prior research includes\nunsupervised articulatory modeling and information exchange separately, our\nmodel is the first to combine the two components. The paper also proposes an\nimproved articulatory model with more interpretable internal representations.\nThe proposed CiwaGAN model is the most realistic approximation of human spoken\nlanguage acquisition using deep learning. As such, it is useful for cognitively\nplausible simulations of the human speech act.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Begus_G/0/1/0/all/0/1\">Ga&#x161;per Begu&#x161;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1\">Thomas Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Alan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1\">Peter Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anumanchipalli_G/0/1/0/all/0/1\">Gopala K. Anumanchipalli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Rise and Potential of Large Language Model Based Agents: A Survey. (arXiv:2309.07864v1 [cs.AI])","link":"http://arxiv.org/abs/2309.07864","description":"<p>For a long time, humanity has pursued artificial intelligence (AI) equivalent\nto or surpassing the human level, with AI agents considered a promising vehicle\nfor this pursuit. AI agents are artificial entities that sense their\nenvironment, make decisions, and take actions. Many efforts have been made to\ndevelop intelligent AI agents since the mid-20th century. However, these\nefforts have mainly focused on advancement in algorithms or training strategies\nto enhance specific capabilities or performance on particular tasks. Actually,\nwhat the community lacks is a sufficiently general and powerful model to serve\nas a starting point for designing AI agents that can adapt to diverse\nscenarios. Due to the versatile and remarkable capabilities they demonstrate,\nlarge language models (LLMs) are regarded as potential sparks for Artificial\nGeneral Intelligence (AGI), offering hope for building general AI agents. Many\nresearch efforts have leveraged LLMs as the foundation to build AI agents and\nhave achieved significant progress. We start by tracing the concept of agents\nfrom its philosophical origins to its development in AI, and explain why LLMs\nare suitable foundations for AI agents. Building upon this, we present a\nconceptual framework for LLM-based agents, comprising three main components:\nbrain, perception, and action, and the framework can be tailored to suit\ndifferent applications. Subsequently, we explore the extensive applications of\nLLM-based agents in three aspects: single-agent scenarios, multi-agent\nscenarios, and human-agent cooperation. Following this, we delve into agent\nsocieties, exploring the behavior and personality of LLM-based agents, the\nsocial phenomena that emerge when they form societies, and the insights they\noffer for human society. Finally, we discuss a range of key topics and open\nproblems within the field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1\">Zhiheng Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenxiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xin Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1\">Wei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yiwen Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_B/0/1/0/all/0/1\">Boyang Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Ming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junzhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1\">Senjie Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1\">Enyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Rui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xiaoran Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Limao Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuhao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1\">Changhao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yicheng Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1\">Zhangyue Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_S/0/1/0/all/0/1\">Shihan Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_R/0/1/0/all/0/1\">Rongxiang Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wensen Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_W/0/1/0/all/0/1\">Wenjuan Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yongyan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huan_X/0/1/0/all/0/1\">Xuanjing Huan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Agents: An Open-source Framework for Autonomous Language Agents. (arXiv:2309.07870v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07870","description":"<p>Recent advances on large language models (LLMs) enable researchers and\ndevelopers to build autonomous language agents that can automatically solve\nvarious tasks and interact with environments, humans, and other agents using\nnatural language interfaces. We consider language agents as a promising\ndirection towards artificial general intelligence and release Agents, an\nopen-source library with the goal of opening up these advances to a wider\nnon-specialist audience. Agents is carefully engineered to support important\nfeatures including planning, memory, tool usage, multi-agent communication, and\nfine-grained symbolic control. Agents is user-friendly as it enables\nnon-specialists to build, customize, test, tune, and deploy state-of-the-art\nautonomous language agents without much coding. The library is also\nresearch-friendly as its modularized design makes it easily extensible for\nresearchers. Agents is available at https://github.com/aiwaves-cn/agents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wangchunshu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuchen Eleanor Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Long Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jialong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tiannan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_S/0/1/0/all/0/1\">Shi Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jintian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1\">Ruipu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Shiding Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wentao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1\">Peng Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions. (arXiv:2309.07875v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07875","description":"<p>Training large language models to follow instructions makes them perform\nbetter on a wide range of tasks, generally becoming more helpful. However, a\nperfectly helpful model will follow even the most malicious instructions and\nreadily generate harmful content. In this paper, we raise concerns over the\nsafety of models that only emphasize helpfulness, not safety, in their\ninstruction-tuning. We show that several popular instruction-tuned models are\nhighly unsafe. Moreover, we show that adding just 3% safety examples (a few\nhundred demonstrations) in the training set when fine-tuning a model like LLaMA\ncan substantially improve their safety. Our safety-tuning does not make models\nsignificantly less capable or helpful as measured by standard benchmarks.\nHowever, we do find a behavior of exaggerated safety, where too much\nsafety-tuning makes models refuse to respond to reasonable prompts that\nsuperficially resemble unsafe ones. Our study sheds light on trade-offs in\ntraining LLMs to follow instructions and exhibit safe behavior.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bianchi_F/0/1/0/all/0/1\">Federico Bianchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzgun_M/0/1/0/all/0/1\">Mirac Suzgun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Attanasio_G/0/1/0/all/0/1\">Giuseppe Attanasio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rottger_P/0/1/0/all/0/1\">Paul R&#xf6;ttger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1\">Dan Jurafsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1\">Tatsunori Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ambiguity-Aware In-Context Learning with Large Language Models. (arXiv:2309.07900v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07900","description":"<p>In-context learning (ICL) i.e. showing LLMs only a few task-specific\ndemonstrations has led to downstream gains with no task-specific fine-tuning\nrequired. However, LLMs are sensitive to the choice of prompts, and therefore a\ncrucial research question is how to select good demonstrations for ICL. One\neffective strategy is leveraging semantic similarity between the ICL\ndemonstrations and test inputs by using a text retriever, which however is\nsub-optimal as that does not consider the LLM's existing knowledge about that\ntask. From prior work (Min et al., 2022), we already know that labels paired\nwith the demonstrations bias the model predictions. This leads us to our\nhypothesis whether considering LLM's existing knowledge about the task,\nespecially with respect to the output label space can help in a better\ndemonstration selection strategy. Through extensive experimentation on three\ntext classification tasks, we find that it is beneficial to not only choose\nsemantically similar ICL demonstrations but also to choose those demonstrations\nthat help resolve the inherent label ambiguity surrounding the test example.\nInterestingly, we find that including demonstrations that the LLM previously\nmis-classified and also fall on the test example's decision boundary, brings\nthe most performance gain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Lingyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhary_A/0/1/0/all/0/1\">Aditi Chaudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_K/0/1/0/all/0/1\">Krishna Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_K/0/1/0/all/0/1\">Kazuma Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raman_K/0/1/0/all/0/1\">Karthik Raman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendersky_M/0/1/0/all/0/1\">Michael Bendersky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning. (arXiv:2309.07915v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07915","description":"<p>Starting from the resurgence of deep learning, vision-language models (VLMs)\nbenefiting from large language models (LLMs) have never been so popular.\nHowever, while LLMs can utilize extensive background knowledge and task\ninformation with in-context learning, most VLMs still struggle with\nunderstanding complex multi-modal prompts with multiple images. The issue can\ntraced back to the architectural design of VLMs or pre-training data.\nSpecifically, the current VLMs primarily emphasize utilizing multi-modal data\nwith a single image some, rather than multi-modal prompts with interleaved\nmultiple images and text. Even though some newly proposed VLMs could handle\nuser prompts with multiple images, pre-training data does not provide more\nsophisticated multi-modal prompts than interleaved image and text crawled from\nthe web. We propose MMICL to address the issue by considering both the model\nand data perspectives. We introduce a well-designed architecture capable of\nseamlessly integrating visual and textual context in an interleaved manner and\nMIC dataset to reduce the gap between the training data and the complex user\nprompts in real-world applications, including: 1) multi-modal context with\ninterleaved images and text, 2) textual references for each image, and 3)\nmulti-image data with spatial, logical, or temporal relationships. Our\nexperiments confirm that MMICL achieves new stat-of-the-art zero-shot and\nfew-shot performance on a wide range of general vision-language tasks,\nespecially for complex reasoning benchmarks including MME and MMBench. Our\nanalysis demonstrates that MMICL effectively deals with the challenge of\ncomplex multi-modal prompt understanding. The experiments on ScienceQA-IMG also\nshow that MMICL successfully alleviates the issue of language bias in VLMs,\nwhich we believe is the reason behind the advanced performance of MMICL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haozhe Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zefan Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1\">Shuzheng Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_K/0/1/0/all/0/1\">Kaikai An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zixuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1\">Wenjuan Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modern Baselines for SPARQL Semantic Parsing. (arXiv:2204.12793v3 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2204.12793","description":"<p>In this work, we focus on the task of generating SPARQL queries from natural\nlanguage questions, which can then be executed on Knowledge Graphs (KGs). We\nassume that gold entity and relations have been provided, and the remaining\ntask is to arrange them in the right order along with SPARQL vocabulary, and\ninput tokens to produce the correct SPARQL query. Pre-trained Language Models\n(PLMs) have not been explored in depth on this task so far, so we experiment\nwith BART, T5 and PGNs (Pointer Generator Networks) with BERT embeddings,\nlooking for new baselines in the PLM era for this task, on DBpedia and Wikidata\nKGs. We show that T5 requires special input tokenisation, but produces state of\nthe art performance on LC-QuAD 1.0 and LC-QuAD 2.0 datasets, and outperforms\ntask-specific models from previous works. Moreover, the methods enable semantic\nparsing for questions where a part of the input needs to be copied to the\noutput query, thus enabling a new paradigm in KG semantic parsing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_D/0/1/0/all/0/1\">Debayan Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_P/0/1/0/all/0/1\">Pranav Ajit Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaur_J/0/1/0/all/0/1\">Jivat Neet Kaur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Usbeck_R/0/1/0/all/0/1\">Ricardo Usbeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biemann_C/0/1/0/all/0/1\">Chris Biemann</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph Embeddings. (arXiv:2210.00305v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.00305","description":"<p>Knowledge Graphs (KGs) often have two characteristics: heterogeneous graph\nstructure and text-rich entity/relation information. Text-based KG embeddings\ncan represent entities by encoding descriptions with pre-trained language\nmodels, but no open-sourced library is specifically designed for KGs with PLMs\nat present. In this paper, we present LambdaKG, a library for KGE that equips\nwith many pre-trained language models (e.g., BERT, BART, T5, GPT-3), and\nsupports various tasks (e.g., knowledge graph completion, question answering,\nrecommendation, and knowledge probing). LambdaKG is publicly open-sourced at\nhttps://github.com/zjunlp/PromptKG/tree/main/lambdaKG, with a demo video at\n<a href=\"http://deepke.zjukg.cn/lambdakg.mp4\">this http URL</a> and long-term maintenance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhoubo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaohan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1\">Zekun Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v7 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09597","description":"<p>Reasoning, as an essential ability for complex problem-solving, can provide\nback-end support for various real-world applications, such as medical\ndiagnosis, negotiation, etc. This paper provides a comprehensive survey of\ncutting-edge research on reasoning with language model prompting. We introduce\nresearch works with comparisons and summaries and provide systematic resources\nto help beginners. We also discuss the potential reasons for emerging such\nreasoning abilities and highlight future research directions. Resources are\navailable at https://github.com/zjunlp/Prompt4ReasoningPapers (updated\nperiodically).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1\">Shuofei Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_Y/0/1/0/all/0/1\">Yixin Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yunzhi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MER 2023: Multi-label Learning, Modality Robustness, and Semi-Supervised Learning. (arXiv:2304.08981v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.08981","description":"<p>The first Multimodal Emotion Recognition Challenge (MER 2023) was\nsuccessfully held at ACM Multimedia. The challenge focuses on system robustness\nand consists of three distinct tracks: (1) MER-MULTI, where participants are\nrequired to recognize both discrete and dimensional emotions; (2) MER-NOISE, in\nwhich noise is added to test videos for modality robustness evaluation; (3)\nMER-SEMI, which provides a large amount of unlabeled samples for\nsemi-supervised learning. In this paper, we introduce the motivation behind\nthis challenge, describe the benchmark dataset, and provide some statistics\nabout participants. To continue using this dataset after MER 2023, please sign\na new End User License Agreement and send it to our official email address\nmerchallenge.contact@gmail.com. We believe this high-quality dataset can become\na new benchmark in multimodal emotion recognition, especially for the Chinese\nresearch community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lian_Z/0/1/0/all/0/1\">Zheng Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Haiyang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Licai Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mingyu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kexin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Ke Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Ying Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jinming Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Ye Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1\">Jiangyan Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Meng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1\">Erik Cambria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Guoying Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1\">Bj&#xf6;rn W. Schuller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_J/0/1/0/all/0/1\">Jianhua Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Latent Space Theory for Emergent Abilities in Large Language Models. (arXiv:2304.09960v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.09960","description":"<p>Languages are not created randomly but rather to communicate information.\nThere is a strong association between languages and their underlying meanings,\nresulting in a sparse joint distribution that is heavily peaked according to\ntheir correlations. Moreover, these peak values happen to match with the\nmarginal distribution of languages due to the sparsity. With the advent of LLMs\ntrained on big data and large models, we can now precisely assess the marginal\ndistribution of languages, providing a convenient means of exploring the sparse\nstructures in the joint distribution for effective inferences. In this paper,\nwe categorize languages as either unambiguous or {\\epsilon}-ambiguous and\npresent quantitative results to demonstrate that the emergent abilities of\nLLMs, such as language understanding, in-context learning, chain-of-thought\nprompting, and effective instruction fine-tuning, can all be attributed to\nBayesian inference on the sparse joint distribution of languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Hui Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PaLM 2 Technical Report. (arXiv:2305.10403v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10403","description":"<p>We introduce PaLM 2, a new state-of-the-art language model that has better\nmultilingual and reasoning capabilities and is more compute-efficient than its\npredecessor PaLM. PaLM 2 is a Transformer-based model trained using a mixture\nof objectives. Through extensive evaluations on English and multilingual\nlanguage, and reasoning tasks, we demonstrate that PaLM 2 has significantly\nimproved quality on downstream tasks across different model sizes, while\nsimultaneously exhibiting faster and more efficient inference compared to PaLM.\nThis improved efficiency enables broader deployment while also allowing the\nmodel to respond faster, for a more natural pace of interaction. PaLM 2\ndemonstrates robust reasoning capabilities exemplified by large improvements\nover PaLM on BIG-Bench and other reasoning tasks. PaLM 2 exhibits stable\nperformance on a suite of responsible AI evaluations, and enables\ninference-time control over toxicity without additional overhead or impact on\nother capabilities. Overall, PaLM 2 achieves state-of-the-art performance\nacross a diverse set of tasks and capabilities.\n</p>\n<p>When discussing the PaLM 2 family, it is important to distinguish between\npre-trained models (of various sizes), fine-tuned variants of these models, and\nthe user-facing products that use these models. In particular, user-facing\nproducts typically include additional pre- and post-processing steps.\nAdditionally, the underlying models may evolve over time. Therefore, one should\nnot expect the performance of user-facing products to exactly match the results\nreported in this report.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Anil_R/0/1/0/all/0/1\">Rohan Anil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1\">Andrew M. Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firat_O/0/1/0/all/0/1\">Orhan Firat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1\">Melvin Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lepikhin_D/0/1/0/all/0/1\">Dmitry Lepikhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Passos_A/0/1/0/all/0/1\">Alexandre Passos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shakeri_S/0/1/0/all/0/1\">Siamak Shakeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taropa_E/0/1/0/all/0/1\">Emanuel Taropa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bailey_P/0/1/0/all/0/1\">Paige Bailey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhifeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_E/0/1/0/all/0/1\">Eric Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1\">Jonathan H. Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafey_L/0/1/0/all/0/1\">Laurent El Shafey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yanping Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meier_Hellstern_K/0/1/0/all/0/1\">Kathy Meier-Hellstern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_G/0/1/0/all/0/1\">Gaurav Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreira_E/0/1/0/all/0/1\">Erica Moreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Omernick_M/0/1/0/all/0/1\">Mark Omernick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robinson_K/0/1/0/all/0/1\">Kevin Robinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1\">Sebastian Ruder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1\">Yi Tay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_K/0/1/0/all/0/1\">Kefan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yuanzhong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yujing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abrego_G/0/1/0/all/0/1\">Gustavo Hernandez Abrego</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_J/0/1/0/all/0/1\">Junwhan Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Austin_J/0/1/0/all/0/1\">Jacob Austin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barham_P/0/1/0/all/0/1\">Paul Barham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Botha_J/0/1/0/all/0/1\">Jan Botha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bradbury_J/0/1/0/all/0/1\">James Bradbury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brahma_S/0/1/0/all/0/1\">Siddhartha Brahma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brooks_K/0/1/0/all/0/1\">Kevin Brooks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catasta_M/0/1/0/all/0/1\">Michele Catasta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yong Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cherry_C/0/1/0/all/0/1\">Colin Cherry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choquette_Choo_C/0/1/0/all/0/1\">Christopher A. Choquette-Choo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhery_A/0/1/0/all/0/1\">Aakanksha Chowdhery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crepy_C/0/1/0/all/0/1\">Cl&#xe9;ment Crepy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dave_S/0/1/0/all/0/1\">Shachi Dave</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Mostafa Dehghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dev_S/0/1/0/all/0/1\">Sunipa Dev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devlin_J/0/1/0/all/0/1\">Jacob Devlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_M/0/1/0/all/0/1\">Mark D&#xed;az</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_N/0/1/0/all/0/1\">Nan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dyer_E/0/1/0/all/0/1\">Ethan Dyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feinberg_V/0/1/0/all/0/1\">Vlad Feinberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fangxiaoyu Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fienber_V/0/1/0/all/0/1\">Vlad Fienber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitag_M/0/1/0/all/0/1\">Markus Freitag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_X/0/1/0/all/0/1\">Xavier Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gehrmann_S/0/1/0/all/0/1\">Sebastian Gehrmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_L/0/1/0/all/0/1\">Lucas Gonzalez</a>, et al. (76 additional authors not shown)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Probing in Context: Toward Building Robust Classifiers via Probing Large Language Models. (arXiv:2305.14171v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14171","description":"<p>Large language models are able to learn new tasks in context, where they are\nprovided with instructions and a few annotated examples. However, the\neffectiveness of in-context learning is dependent on the provided context, and\nthe performance on a downstream task can vary considerably, depending on the\ninstruction. Importantly, such dependency on the context can surface in\nunpredictable ways, e.g., a seemingly more informative instruction might lead\nto a worse performance. In this paper, we propose an alternative approach,\nwhich we term in-context probing. Similar to in-context learning, we\ncontextualize the representation of the input with an instruction, but instead\nof decoding the output prediction, we probe the contextualized representation\nto predict the label. Through a series of experiments on a diverse set of\nclassification tasks, we show that in-context probing is significantly more\nrobust to changes in instructions. We further show that probing performs\ncompetitive or superior to finetuning and can be particularly helpful to build\nclassifiers on top of smaller models, and with only a hundred training\nexamples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1\">Afra Amini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciaramita_M/0/1/0/all/0/1\">Massimiliano Ciaramita</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"K2: A Foundation Language Model for Geoscience Knowledge Understanding and Utilization. (arXiv:2306.05064v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.05064","description":"<p>Large language models (LLMs) have achieved great success in general domains\nof natural language processing. In this paper, we bring LLMs to the realm of\ngeoscience with the objective of advancing research and applications in this\nfield. To this end, we present the first-ever LLM in geoscience, K2, alongside\na suite of resources developed to further promote LLM research within\ngeoscience. For instance, we have curated the first geoscience instruction\ntuning dataset, GeoSignal, which aims to align LLM responses to\ngeoscience-related user queries. Additionally, we have established the first\ngeoscience benchmark, GeoBench, to evaluate LLMs in the context of geoscience.\nIn this work, we experiment with a complete recipe to adapt a pre-trained\ngeneral-domain LLM to the geoscience domain. Specifically, we further train the\nLLaMA-7B model on 5.5B tokens of geoscience text corpus, including over 1\nmillion pieces of geoscience literature, and utilize GeoSignal's supervised\ndata to fine-tune the model. Moreover, we share a protocol that can efficiently\ngather domain-specific data and construct domain-supervised data, even in\nsituations where manpower is scarce. Meanwhile, we equip K2 with the abilities\nof using tools to be a naive geoscience aide. Experiments conducted on the\nGeoBench demonstrate the effectiveness of our approach and datasets on\ngeoscience knowledge understanding and utilization.We open-source all the\ntraining data and K2 model checkpoints at https://github.com/davendw49/k2.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1\">Cheng Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianhang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhongmou He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qiyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yuanyuan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_L/0/1/0/all/0/1\">Luoyi Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weinan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinbing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chenghu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouhan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junxian He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in Language Models. (arXiv:2306.05659v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.05659","description":"<p>Prompt-based learning has been proved to be an effective way in pre-trained\nlanguage models (PLMs), especially in low-resource scenarios like few-shot\nsettings. However, the trustworthiness of PLMs is of paramount significance and\npotential vulnerabilities have been shown in prompt-based templates that could\nmislead the predictions of language models, causing serious security concerns.\nIn this paper, we will shed light on some vulnerabilities of PLMs, by proposing\na prompt-based adversarial attack on manual templates in black box scenarios.\nFirst of all, we design character-level and word-level heuristic approaches to\nbreak manual templates separately. Then we present a greedy algorithm for the\nattack based on the above heuristic destructive approaches. Finally, we\nevaluate our approach with the classification tasks on three variants of BERT\nseries models and eight datasets. And comprehensive experimental results\njustify the effectiveness of our approach in terms of attack success rate and\nattack speed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1\">Zihao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingliang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenbin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongjian Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Overview of Robust and Multilingual Automatic Evaluation Metrics for Open-Domain Dialogue Systems at DSTC 11 Track 4. (arXiv:2306.12794v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.12794","description":"<p>The advent and fast development of neural networks have revolutionized the\nresearch on dialogue systems and subsequently have triggered various challenges\nregarding their automatic evaluation. Automatic evaluation of open-domain\ndialogue systems as an open challenge has been the center of the attention of\nmany researchers. Despite the consistent efforts to improve automatic metrics'\ncorrelations with human evaluation, there have been very few attempts to assess\ntheir robustness over multiple domains and dimensions. Also, their focus is\nmainly on the English language. All of these challenges prompt the development\nof automatic evaluation metrics that are reliable in various domains,\ndimensions, and languages. This track in the 11th Dialogue System Technology\nChallenge (DSTC11) is part of the ongoing effort to promote robust and\nmultilingual automatic evaluation metrics. This article describes the datasets\nand baselines provided to participants and discusses the submission and result\ndetails of the two proposed subtasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_Cantelar_M/0/1/0/all/0/1\">Mario Rodr&#xed;guez-Cantelar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Chengguang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Ke Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghazarian_S/0/1/0/all/0/1\">Sarik Ghazarian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sedoc_J/0/1/0/all/0/1\">Jo&#xe3;o Sedoc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DHaro_L/0/1/0/all/0/1\">Luis Fernando D&#x27;Haro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudnicky_A/0/1/0/all/0/1\">Alexander Rudnicky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning. (arXiv:2306.14565v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2306.14565","description":"<p>Despite the promising progress in multi-modal tasks, current large\nmulti-modal models (LMM) are prone to hallucinating inconsistent descriptions\nwith respect to the associated image and human instructions. This paper\naddresses this issue by introducing the first large and diverse visual\ninstruction tuning dataset, named Large-scale Robust Visual (LRV)-Instruction.\nOur dataset consists of 120k visual instructions generated by GPT4, covering 16\nvision-and-language tasks with open-ended instructions and answers. Unlike\nexisting studies that primarily focus on positive instruction samples, we\ndesign LRV-Instruction to include both positive and negative instructions for\nmore robust visual instruction tuning. Our negative instructions are designed\nat two semantic levels: (i) Nonexistent Element Manipulation and (ii) Existent\nElement Manipulation. To efficiently measure the hallucination generated by\nLMMs, we propose GPT4-Assisted Visual Instruction Evaluation (GAVIE), a novel\napproach to evaluate visual instruction tuning without the need for\nhuman-annotated groundtruth answers and can adapt to diverse instruction\nformats. We conduct comprehensive experiments to investigate the hallucination\nof LMMs. Our results demonstrate that existing LMMs exhibit significant\nhallucination when presented with our negative instructions, particularly with\nExistent Element Manipulation instructions. Moreover, by finetuning MiniGPT4 on\nLRV-Instruction, we successfully mitigate hallucination while improving\nperformance on public datasets using less training data compared to\nstate-of-the-art methods. Additionally, we observed that a balanced ratio of\npositive and negative instances in the training data leads to a more robust\nmodel. Updates of our project are available at\nhttps://fuxiaoliu.github.io/LRV/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fuxiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kevin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yacoob_Y/0/1/0/all/0/1\">Yaser Yacoob</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijuan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generative User-Experience Research for Developing Domain-specific Natural Language Processing Applications. (arXiv:2306.16143v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.16143","description":"<p>User experience (UX) is a part of human-computer interaction (HCI) research\nand focuses on increasing intuitiveness, transparency, simplicity, and trust\nfor system users. Most of the UX research for machine learning (ML) or natural\nlanguage processing (NLP) focuses on a data-driven methodology, i.e., it fails\nto focus on users' requirements, and engages domain users mainly for usability\nevaluation. Moreover, more typical UX methods tailor the systems towards user\nusability, unlike learning about the user needs first. The paper proposes a\nmethodology for integrating generative UX research into developing domain NLP\napplications. Generative UX research employs domain users at the initial stages\nof prototype development, i.e., ideation and concept evaluation, and the last\nstage for evaluating the change in user value. In the case study, we report the\nfull-cycle prototype development of a domain-specific semantic search for daily\noperations in the process industry. Our case study shows that involving domain\nexperts increases their interest and trust in the final NLP application.\nMoreover, we show that synergetic UX+NLP research efficiently considers data-\nand user-driven opportunities and constraints, which can be crucial for NLP\napplications in narrow domains\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhukova_A/0/1/0/all/0/1\">Anastasia Zhukova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sperl_L/0/1/0/all/0/1\">Lukas von Sperl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matt_C/0/1/0/all/0/1\">Christian E. Matt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gipp_B/0/1/0/all/0/1\">Bela Gipp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Personality Traits in Large Language Models. (arXiv:2307.00184v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.00184","description":"<p>The advent of large language models (LLMs) has revolutionized natural\nlanguage processing, enabling the generation of coherent and contextually\nrelevant human-like text. As LLMs increasingly power conversational agents used\nby the general public world-wide, the synthetic personality embedded in these\nmodels, by virtue of training on large amounts of human data, is becoming\nincreasingly important. Since personality is a key factor determining the\neffectiveness of communication, we present a comprehensive method for\nadministering and validating personality tests on widely-used LLMs, as well as\nfor shaping personality in the generated text of such LLMs. Applying this\nmethod, we found: 1) personality measurements in the outputs of some LLMs under\nspecific prompting configurations are reliable and valid; 2) evidence of\nreliability and validity of synthetic LLM personality is stronger for larger\nand instruction fine-tuned models; and 3) personality in LLM outputs can be\nshaped along desired dimensions to mimic specific human personality profiles.\nWe discuss application and ethical implications of the measurement and shaping\nmethod, in particular regarding responsible AI.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Serapio_Garcia_G/0/1/0/all/0/1\">Greg Serapio-Garc&#xed;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Safdari_M/0/1/0/all/0/1\">Mustafa Safdari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crepy_C/0/1/0/all/0/1\">Cl&#xe9;ment Crepy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Luning Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fitz_S/0/1/0/all/0/1\">Stephen Fitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romero_P/0/1/0/all/0/1\">Peter Romero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdulhai_M/0/1/0/all/0/1\">Marwa Abdulhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faust_A/0/1/0/all/0/1\">Aleksandra Faust</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mataric_M/0/1/0/all/0/1\">Maja Matari&#x107;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TIM: Teaching Large Language Models to Translate with Comparison. (arXiv:2307.04408v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.04408","description":"<p>Open-sourced large language models (LLMs) have demonstrated remarkable\nefficacy in various tasks with instruction tuning. However, these models can\nsometimes struggle with tasks that require more specialized knowledge such as\ntranslation. One possible reason for such deficiency is that instruction tuning\naims to generate fluent and coherent text that continues from a given\ninstruction without being constrained by any task-specific requirements.\nMoreover, it can be more challenging for tuning smaller LLMs with lower-quality\ntraining data. To address this issue, we propose a novel framework using\nexamples in comparison to teach LLMs to learn translation. Our approach\ninvolves presenting the model with examples of correct and incorrect\ntranslations and using a preference loss to guide the model's learning. We\nevaluate our method on WMT2022 test sets and show that it outperforms existing\nmethods. Our findings offer a new perspective on fine-tuning LLMs for\ntranslation tasks and provide a promising solution for generating high-quality\ntranslations. Please refer to Github for more details:\nhttps://github.com/lemon0830/TIM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jiali Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yongjing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Identical and Fraternal Twins: Fine-Grained Semantic Contrastive Learning of Sentence Representations. (arXiv:2307.10932v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.10932","description":"<p>The enhancement of unsupervised learning of sentence representations has been\nsignificantly achieved by the utility of contrastive learning. This approach\nclusters the augmented positive instance with the anchor instance to create a\ndesired embedding space. However, relying solely on the contrastive objective\ncan result in sub-optimal outcomes due to its inability to differentiate subtle\nsemantic variations between positive pairs. Specifically, common data\naugmentation techniques frequently introduce semantic distortion, leading to a\nsemantic margin between the positive pair. While the InfoNCE loss function\noverlooks the semantic margin and prioritizes similarity maximization between\npositive pairs during training, leading to the insensitive semantic\ncomprehension ability of the trained model. In this paper, we introduce a novel\nIdentical and Fraternal Twins of Contrastive Learning (named IFTCL) framework,\ncapable of simultaneously adapting to various positive pairs generated by\ndifferent augmentation techniques. We propose a \\textit{Twins Loss} to preserve\nthe innate margin during training and promote the potential of data enhancement\nin order to overcome the sub-optimal issue. We also present proof-of-concept\nexperiments combined with the contrastive objective to prove the validity of\nthe proposed Twins Loss. Furthermore, we propose a hippocampus queue mechanism\nto restore and reuse the negative instances without additional calculation,\nwhich further enhances the efficiency and performance of the IFCL. We verify\nthe IFCL framework on nine semantic textual similarity tasks with both English\nand Chinese datasets, and the experimental results show that IFCL outperforms\nstate-of-the-art methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Q/0/1/0/all/0/1\">Qingfa Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuangyin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lei Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"YORC: Yoruba Reading Comprehension dataset. (arXiv:2308.09768v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.09768","description":"<p>In this paper, we create YORC: a new multi-choice Yoruba Reading\nComprehension dataset that is based on Yoruba high-school reading comprehension\nexamination. We provide baseline results by performing cross-lingual transfer\nusing existing English RACE dataset based on a pre-trained encoder-only model.\nAdditionally, we provide results by prompting large language models (LLMs) like\nGPT-4.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aremu_A/0/1/0/all/0/1\">Anuoluwapo Aremu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alabi_J/0/1/0/all/0/1\">Jesujoba O. Alabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1\">David Ifeoluwa Adelani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models. (arXiv:2308.11764v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.11764","description":"<p>Large Language Models (LLMs) have revolutionized Natural Language Processing\n(NLP). Although convenient for research and practical applications, open-source\nLLMs with fewer parameters often suffer from severe hallucinations compared to\ntheir larger counterparts. This paper focuses on measuring and reducing\nhallucinations in BLOOM 7B, a representative of such weaker open-source LLMs\nthat are publicly available for research and commercial applications. We\nintroduce HaloCheck, a lightweight BlackBox knowledge-free framework designed\nto quantify the severity of hallucinations in LLMs. Additionally, we explore\ntechniques like knowledge injection and teacher-student approaches to alleviate\nhallucinations in low-parameter LLMs. Our experiments effectively demonstrate\nthe reduction of hallucinations in challenging domains for these LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Elaraby_M/0/1/0/all/0/1\">Mohamed Elaraby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1\">Mengyin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunn_J/0/1/0/all/0/1\">Jacob Dunn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xueying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shizhu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_P/0/1/0/all/0/1\">Pingchuan Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuxuan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond. (arXiv:2308.12966v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2308.12966","description":"<p>We introduce the Qwen-VL series, a set of large-scale vision-language models\n(LVLMs) designed to perceive and understand both text and images. Comprising\nQwen-VL and Qwen-VL-Chat, these models exhibit remarkable performance in tasks\nlike image captioning, question answering, visual localization, and flexible\ninteraction. The evaluation covers a wide range of tasks including zero-shot\ncaptioning, visual or document visual question answering, and grounding. We\ndemonstrate the Qwen-VL outperforms existing LVLMs. We present their\narchitecture, training, capabilities, and performance, highlighting their\ncontributions to advancing multimodal artificial intelligence. Code, demo and\nmodels are available at https://github.com/QwenLM/Qwen-VL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Jinze Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_S/0/1/0/all/0/1\">Shuai Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shusheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shijie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Sinan Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Graph Embeddings for Multi-Lingual Structured Representations of Radiology Reports. (arXiv:2309.00917v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.00917","description":"<p>The way we analyse clinical texts has undergone major changes over the last\nyears. The introduction of language models such as BERT led to adaptations for\nthe (bio)medical domain like PubMedBERT and ClinicalBERT. These models rely on\nlarge databases of archived medical documents. While performing well in terms\nof accuracy, both the lack of interpretability and limitations to transfer\nacross languages limit their use in clinical setting. We introduce a novel\nlight-weight graph-based embedding method specifically catering radiology\nreports. It takes into account the structure and composition of the report,\nwhile also connecting medical terms in the report through the multi-lingual\nSNOMED Clinical Terms knowledge base. The resulting graph embedding uncovers\nthe underlying relationships among clinical terms, achieving a representation\nthat is better understandable for clinicians and clinically more accurate,\nwithout reliance on large pre-training datasets. We show the use of this\nembedding on two tasks namely disease classification of X-ray reports and image\nclassification. For disease classification our model is competitive with its\nBERT-based counterparts, while being magnitudes smaller in size and training\ndata requirements. For image classification, we show the effectiveness of the\ngraph embedding leveraging cross-modal knowledge transfer and show how this\nmethod is usable across different languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sonsbeek_T/0/1/0/all/0/1\">Tom van Sonsbeek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhen_X/0/1/0/all/0/1\">Xiantong Zhen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Worring_M/0/1/0/all/0/1\">Marcel Worring</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"USA: Universal Sentiment Analysis Model & Construction of Japanese Sentiment Text Classification and Part of Speech Dataset. (arXiv:2309.03787v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.03787","description":"<p>Sentiment analysis is a pivotal task in the domain of natural language\nprocessing. It encompasses both text-level sentiment polarity classification\nand word-level Part of Speech(POS) sentiment polarity determination. Such\nanalysis challenges models to understand text holistically while also\nextracting nuanced information. With the rise of Large Language Models(LLMs),\nnew avenues for sentiment analysis have opened. This paper proposes enhancing\nperformance by leveraging the Mutual Reinforcement Effect(MRE) between\nindividual words and the overall text. It delves into how word polarity\ninfluences the overarching sentiment of a passage. To support our research, we\nannotated four novel Sentiment Text Classification and Part of Speech(SCPOS)\ndatasets, building upon existing sentiment classification datasets.\nFurthermore, we developed a Universal Sentiment Analysis(USA) model, with a\n7-billion parameter size. Experimental results revealed that our model\nsurpassed the performance of gpt-3.5-turbo across all four datasets,\nunderscoring the significance of MRE in sentiment analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chengguang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinghao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mori_T/0/1/0/all/0/1\">Tatsunori Mori</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-shot Learning with Minimum Instruction to Extract Social Determinants and Family History from Clinical Notes using GPT Model. (arXiv:2309.05475v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05475","description":"<p>Demographics, Social determinants of health, and family history documented in\nthe unstructured text within the electronic health records are increasingly\nbeing studied to understand how this information can be utilized with the\nstructured data to improve healthcare outcomes. After the GPT models were\nreleased, many studies have applied GPT models to extract this information from\nthe narrative clinical notes. Different from the existing work, our research\nfocuses on investigating the zero-shot learning on extracting this information\ntogether by providing minimum information to the GPT model. We utilize\nde-identified real-world clinical notes annotated for demographics, various\nsocial determinants, and family history information. Given that the GPT model\nmight provide text different from the text in the original data, we explore two\nsets of evaluation metrics, including the traditional NER evaluation metrics\nand semantic similarity evaluation metrics, to completely understand the\nperformance. Our results show that the GPT-3.5 method achieved an average of\n0.975 F1 on demographics extraction, 0.615 F1 on social determinants\nextraction, and 0.722 F1 on family history extraction. We believe these results\ncan be further improved through model fine-tuning or few-shots learning.\nThrough the case studies, we also identified the limitations of the GPT models,\nwhich need to be addressed in future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhate_N/0/1/0/all/0/1\">Neel Bhate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_A/0/1/0/all/0/1\">Ansh Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhe He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xiao Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs. (arXiv:2309.05918v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05918","description":"<p>In our opinion the exuberance surrounding the relative success of data-driven\nlarge language models (LLMs) is slightly misguided and for several reasons (i)\nLLMs cannot be relied upon for factual information since for LLMs all ingested\ntext (factual or non-factual) was created equal; (ii) due to their subsymbolic\nna-ture, whatever 'knowledge' these models acquire about language will always\nbe buried in billions of microfeatures (weights), none of which is meaningful\non its own; and (iii) LLMs will often fail to make the correct inferences in\nseveral linguistic contexts (e.g., nominal compounds, copredication, quantifier\nscope ambi-guities, intensional contexts. Since we believe the relative success\nof data-driven large language models (LLMs) is not a reflection on the symbolic\nvs. subsymbol-ic debate but a reflection on applying the successful strategy of\na bottom-up reverse engineering of language at scale, we suggest in this paper\napplying the effective bottom-up strategy in a symbolic setting resulting in\nsymbolic, explainable, and ontologically grounded language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saba_W/0/1/0/all/0/1\">Walid S. Saba</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-09-14T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","admin":"http://webns.net/mvcb/","content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}