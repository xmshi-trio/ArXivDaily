{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2022-12-13T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Plug-and-Play Recipe Generation with Content Planning. (arXiv:2212.05093v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05093","description":"<p>Recent pre-trained language models have shown promising capabilities in\ngenerating fluent and realistic natural language text. However, generating\nmulti-sentence text with global content planning has been a long-existing\nresearch question. Current approaches for controlled text generation can hardly\naddress this issue, as they usually condition on single known control\nattributes. In this study, we propose a low-cost yet effective framework which\nexplicitly models the global content plan of the generated text. Specifically,\nit optimizes the joint distribution of the natural language sequence and the\nglobal content plan in a plug-and-play manner. We conduct extensive experiments\non the well-established Recipe1M+ benchmark. Both automatic and human\nevaluations verify that our model achieves the state-of-the-art performance on\nthe task of recipe generation\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yinhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yixuan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shareghi_E/0/1/0/all/0/1\">Ehsan Shareghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collier_N/0/1/0/all/0/1\">Nigel Collier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-task Learning for Personal Health Mention Detection on Social Media. (arXiv:2212.05147v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05147","description":"<p>Detecting personal health mentions on social media is essential to complement\nexisting health surveillance systems. However, annotating data for detecting\nhealth mentions at a large scale is a challenging task. This research employs a\nmultitask learning framework to leverage available annotated data from a\nrelated task to improve the performance on the main task to detect personal\nhealth experiences mentioned in social media texts. Specifically, we focus on\nincorporating emotional information into our target task by using emotion\ndetection as an auxiliary task. Our approach significantly improves a wide\nrange of personal health mention detection tasks compared to a strong\nstate-of-the-art baseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aduragba_O/0/1/0/all/0/1\">Olanrewaju Tahir Aduragba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jialin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cristea_A/0/1/0/all/0/1\">Alexandra I. Cristea</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Artificial Text Detection with Multiple Training Strategies. (arXiv:2212.05194v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05194","description":"<p>As the deep learning rapidly promote, the artificial texts created by\ngenerative models are commonly used in news and social media. However, such\nmodels can be abused to generate product reviews, fake news, and even fake\npolitical content. The paper proposes a solution for the Russian Artificial\nText Detection in the Dialogue shared task 2022 (RuATD 2022) to distinguish\nwhich model within the list is used to generate this text. We introduce the\nDeBERTa pre-trained language model with multiple training strategies for this\nshared task. Extensive experiments conducted on the RuATD dataset validate the\neffectiveness of our proposed method. Moreover, our submission ranked second\nplace in the evaluation phase for RuATD 2022 (Multi-Class).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_Y/0/1/0/all/0/1\">Yixuan Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1\">Qiya Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_H/0/1/0/all/0/1\">Hanjun Deng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Machine intuition: Uncovering human-like intuitive decision-making in GPT-3.5. (arXiv:2212.05206v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05206","description":"<p>Artificial intelligence (AI) technologies revolutionize vast fields of\nsociety. Humans using these systems are likely to expect them to work in a\npotentially hyperrational manner. However, in this study, we show that some AI\nsystems, namely large language models (LLMs), exhibit behavior that strikingly\nresembles human-like intuition - and the many cognitive errors that come with\nthem. We use a state-of-the-art LLM, namely the latest iteration of OpenAI's\nGenerative Pre-trained Transformer (GPT-3.5), and probe it with the Cognitive\nReflection Test (CRT) as well as semantic illusions that were originally\ndesigned to investigate intuitive decision-making in humans. Our results show\nthat GPT-3.5 systematically exhibits \"machine intuition,\" meaning that it\nproduces incorrect responses that are surprisingly equal to how humans respond\nto the CRT as well as to semantic illusions. We investigate several approaches\nto test how sturdy GPT-3.5's inclination for intuitive-like decision-making is.\nOur study demonstrates that investigating LLMs with methods from cognitive\nscience has the potential to reveal emergent traits and adjust expectations\nregarding their machine behavior.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hagendorff_T/0/1/0/all/0/1\">Thilo Hagendorff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabi_S/0/1/0/all/0/1\">Sarah Fabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kosinski_M/0/1/0/all/0/1\">Michal Kosinski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LEAD: Liberal Feature-based Distillation for Dense Retrieval. (arXiv:2212.05225v1 [cs.IR])","link":"http://arxiv.org/abs/2212.05225","description":"<p>Knowledge distillation is often used to transfer knowledge from a strong\nteacher model to a relatively weak student model. Traditional knowledge\ndistillation methods include response-based methods and feature-based methods.\nResponse-based methods are used the most widely but suffer from lower upper\nlimit of model performance, while feature-based methods have constraints on the\nvocabularies and tokenizers. In this paper, we propose a tokenizer-free method\nliberal feature-based distillation (LEAD). LEAD aligns the distribution between\nteacher model and student model, which is effective, extendable, portable and\nhas no requirements on vocabularies, tokenizer, or model architecture.\nExtensive experiments show the effectiveness of LEAD on several widely-used\nbenchmarks, including MS MARCO Passage, TREC Passage 19, TREC Passage 20, MS\nMARCO Document, TREC Document 19 and TREC Document 20.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_A/0/1/0/all/0/1\">Anlei Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1\">Jian Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jingwen Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Daxin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linjun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majumder_R/0/1/0/all/0/1\">Rangan Majumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Structured information extraction from complex scientific text with fine-tuned large language models. (arXiv:2212.05238v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05238","description":"<p>Intelligently extracting and linking complex scientific information from\nunstructured text is a challenging endeavor particularly for those\ninexperienced with natural language processing. Here, we present a simple\nsequence-to-sequence approach to joint named entity recognition and relation\nextraction for complex hierarchical information in scientific text. The\napproach leverages a pre-trained large language model (LLM), GPT-3, that is\nfine-tuned on approximately 500 pairs of prompts (inputs) and completions\n(outputs). Information is extracted either from single sentences or across\nsentences in abstracts/passages, and the output can be returned as simple\nEnglish sentences or a more structured format, such as a list of JSON objects.\nWe demonstrate that LLMs trained in this way are capable of accurately\nextracting useful records of complex scientific knowledge for three\nrepresentative tasks in materials chemistry: linking dopants with their host\nmaterials, cataloging metal-organic frameworks, and general\nchemistry/phase/morphology/application information extraction. This approach\nrepresents a simple, accessible, and highly-flexible route to obtaining large\ndatabases of structured knowledge extracted from unstructured text. An online\ndemo is available at <a href=\"http://www.matscholar.com/info-extraction.\">this http URL</a>\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dunn_A/0/1/0/all/0/1\">Alexander Dunn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagdelen_J/0/1/0/all/0/1\">John Dagdelen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walker_N/0/1/0/all/0/1\">Nicholas Walker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sanghoon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosen_A/0/1/0/all/0/1\">Andrew S. Rosen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ceder_G/0/1/0/all/0/1\">Gerbrand Ceder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Persson_K/0/1/0/all/0/1\">Kristin Persson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Anubhav Jain</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Unified Knowledge Graph Service for Developing Domain Language Models in AI Software. (arXiv:2212.05251v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05251","description":"<p>Natural Language Processing (NLP) is one of the core techniques in AI\nsoftware. As AI is being applied to more and more domains, how to efficiently\ndevelop high-quality domain-specific language models becomes a critical\nquestion in AI software engineering. Existing domain-specific language model\ndevelopment processes mostly focus on learning a domain-specific pre-trained\nlanguage model (PLM); when training the domain task-specific language model\nbased on PLM, only a direct (and often unsatisfactory) fine-tuning strategy is\nadopted commonly. By enhancing the task-specific training procedure with domain\nknowledge graphs, we propose KnowledgeDA, a unified and low-code domain\nlanguage model development service. Given domain-specific task texts input by a\nuser, KnowledgeDA can automatically generate a domain-specific language model\nfollowing three steps: (i) localize domain knowledge entities in texts via an\nembedding-similarity approach; (ii) generate augmented samples by retrieving\nreplaceable domain entity pairs from two views of both knowledge graph and\ntraining data; (iii) select high-quality augmented samples for fine-tuning via\nconfidence-based assessment. We implement a prototype of KnowledgeDA to learn\nlanguage models for two domains, healthcare and software development.\nExperiments on five domain-specific NLP tasks verify the effectiveness and\ngeneralizability of KnowledgeDA. (Code is publicly available at\nhttps://github.com/RuiqingDing/KnowledgeDA.)\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_R/0/1/0/all/0/1\">Ruiqing Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xiao Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Leye Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MAPS-KB: A Million-scale Probabilistic Simile Knowledge Base. (arXiv:2212.05254v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05254","description":"<p>The ability to understand and generate similes is an imperative step to\nrealize human-level AI. However, there is still a considerable gap between\nmachine intelligence and human cognition in similes, since deep models based on\nstatistical distribution tend to favour high-frequency similes. Hence, a\nlarge-scale symbolic knowledge base of similes is required, as it contributes\nto the modeling of diverse yet unpopular similes while facilitating additional\nevaluation and reasoning. To bridge the gap, we propose a novel framework for\nlarge-scale simile knowledge base construction, as well as two probabilistic\nmetrics which enable an improved understanding of simile phenomena in natural\nlanguage. Overall, we construct MAPS-KB, a million-scale probabilistic simile\nknowledge base, covering 4.3 million triplets over 0.4 million terms from 70 GB\ncorpora. We conduct sufficient experiments to justify the effectiveness and\nnecessity of the methods of our framework. We also apply MAPS-KB on three\ndownstream tasks to achieve state-of-the-art performance, further demonstrating\nthe value of MAPS-KB.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1\">Qianyu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xintao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jiaqing Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yanghua Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Natural Logic-guided Autoregressive Multi-hop Document Retrieval for Fact Verification. (arXiv:2212.05276v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05276","description":"<p>A key component of fact verification is thevevidence retrieval, often from\nmultiple documents. Recent approaches use dense representations and condition\nthe retrieval of each document on the previously retrieved ones. The latter\nstep is performed over all the documents in the collection, requiring storing\ntheir dense representations in an index, thus incurring a high memory\nfootprint. An alternative paradigm is retrieve-and-rerank, where documents are\nretrieved using methods such as BM25, their sentences are reranked, and further\ndocuments are retrieved conditioned on these sentences, reducing the memory\nrequirements. However, such approaches can be brittle as they rely on\nheuristics and assume hyperlinks between documents. We propose a novel\nretrieve-and-rerank method for multi-hop retrieval, that consists of a\nretriever that jointly scores documents in the knowledge source and sentences\nfrom previously retrieved documents using an autoregressive formulation and is\nguided by a proof system based on natural logic that dynamically terminates the\nretrieval process if the evidence is deemed sufficient. This method is\ncompetitive with current state-of-the-art methods on FEVER, HoVer and\nFEVEROUS-S, while using $5$ to $10$ times less memory than competing systems.\nEvaluation on an adversarial dataset indicates improved stability of our\napproach compared to commonly deployed threshold-based methods. Finally, the\nproof system helps humans predict model decisions correctly more often than\nusing the evidence alone.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aly_R/0/1/0/all/0/1\">Rami Aly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1\">Andreas Vlachos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Identifying the Source of Vulnerability in Explanation Discrepancy: A Case Study in Neural Text Classification. (arXiv:2212.05327v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05327","description":"<p>Some recent works observed the instability of post-hoc explanations when\ninput side perturbations are applied to the model. This raises the interest and\nconcern in the stability of post-hoc explanations. However, the remaining\nquestion is: is the instability caused by the neural network model or the\npost-hoc explanation method? This work explores the potential source that leads\nto unstable post-hoc explanations. To separate the influence from the model, we\npropose a simple output probability perturbation method. Compared to prior\ninput side perturbation methods, the output probability perturbation method can\ncircumvent the neural model's potential effect on the explanations and allow\nthe analysis on the explanation method. We evaluate the proposed method with\nthree widely-used post-hoc explanation methods (LIME (Ribeiro et al., 2016),\nKernel Shapley (Lundberg and Lee, 2017a), and Sample Shapley (Strumbelj and\nKononenko, 2010)). The results demonstrate that the post-hoc methods are\nstable, barely producing discrepant explanations under output probability\nperturbations. The observation suggests that neural network models may be the\nprimary source of fragile explanations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1\">Ruixuan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hanjie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1\">Yangfeng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Punctuation Restoration for Singaporean Spoken Languages: English, Malay, and Mandarin. (arXiv:2212.05356v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05356","description":"<p>This paper presents the work of restoring punctuation for ASR transcripts\ngenerated by multilingual ASR systems. The focus languages are English,\nMandarin, and Malay which are three of the most popular languages in Singapore.\nTo the best of our knowledge, this is the first system that can tackle\npunctuation restoration for these three languages simultaneously. Traditional\napproaches usually treat the task as a sequential labeling task, however, this\nwork adopts a slot-filling approach that predicts the presence and type of\npunctuation marks at each word boundary. The approach is similar to the\nMasked-Language Model approach employed during the pre-training stages of BERT,\nbut instead of predicting the masked word, our model predicts masked\npunctuation. Additionally, we find that using Jieba1 instead of only using the\nbuilt-in SentencePiece tokenizer of XLM-R can significantly improve the\nperformance of punctuating Mandarin transcripts. Experimental results on\nEnglish and Mandarin IWSLT2022 datasets and Malay News show that the proposed\napproach achieved state-of-the-art results for Mandarin with 73.8% F1-score\nwhile maintaining a reasonable F1-score for English and Malay, i.e. 74.7% and\n78% respectively. Our source code that allows reproducing the results and\nbuilding a simple web-based application for demonstration purposes is available\non Github.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1\">Abhinav Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thi_Nga_H/0/1/0/all/0/1\">Ho Thi-Nga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eng_Siong_C/0/1/0/all/0/1\">Chng Eng-Siong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Topic-Aware Response Generation in Task-Oriented Dialogue with Unstructured Knowledge Access. (arXiv:2212.05373v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05373","description":"<p>To alleviate the problem of structured databases' limited coverage, recent\ntask-oriented dialogue systems incorporate external unstructured knowledge to\nguide the generation of system responses. However, these usually use word or\nsentence level similarities to detect the relevant knowledge context, which\nonly partially capture the topical level relevance. In this paper, we examine\nhow to better integrate topical information in knowledge grounded task-oriented\ndialogue and propose ``Topic-Aware Response Generation'' (TARG), an end-to-end\nresponse generation model. TARG incorporates multiple topic-aware attention\nmechanisms to derive the importance weighting scheme over dialogue utterances\nand external knowledge sources towards a better understanding of the dialogue\nhistory. Experimental results indicate that TARG achieves state-of-the-art\nperformance in knowledge selection and response generation, outperforming\nprevious state-of-the-art by 3.2, 3.6, and 4.2 points in EM, F1 and BLEU-4\nrespectively on Doc2Dial, and performing comparably with previous work on\nDSTC9; both being knowledge-grounded task-oriented dialogue datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yue Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lampouras_G/0/1/0/all/0/1\">Gerasimos Lampouras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iacobacci_I/0/1/0/all/0/1\">Ignacio Iacobacci</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"IndicXTREME: A Multi-Task Benchmark For Evaluating Indic Languages. (arXiv:2212.05409v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05409","description":"<p>In this work, we introduce IndicXTREME, a benchmark consisting of nine\ndiverse tasks covering 18 languages from the Indic sub-continent belonging to\nfour different families. Across languages and tasks, IndicXTREME contains a\ntotal of 103 evaluation sets, of which 51 are new contributions to the\nliterature. To maintain high quality, we only use human annotators to curate or\ntranslate\\footnote{for IndicXParaphrase, where an automatic translation system\nis used, a second human verification and correction step is done.} our\ndatasets. To the best of our knowledge, this is the first effort toward\ncreating a standard benchmark for Indic languages that aims to test the\nzero-shot capabilities of pretrained language models. We also release IndicCorp\nv2, an updated and much larger version of IndicCorp that contains 20.9 billion\ntokens in 24 languages. We pretrain IndicBERT v2 on IndicCorp v2 and evaluate\nit on IndicXTREME to show that it outperforms existing multilingual language\nmodels such as XLM-R and MuRIL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Doddapaneni_S/0/1/0/all/0/1\">Sumanth Doddapaneni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aralikatte_R/0/1/0/all/0/1\">Rahul Aralikatte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_G/0/1/0/all/0/1\">Gowtham Ramesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_S/0/1/0/all/0/1\">Shreya Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khapra_M/0/1/0/all/0/1\">Mitesh M. Khapra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunchukuttan_A/0/1/0/all/0/1\">Anoop Kunchukuttan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1\">Pratyush Kumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Feature-Level Debiased Natural Language Understanding. (arXiv:2212.05421v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05421","description":"<p>Existing natural language understanding (NLU) models often rely on dataset\nbiases rather than intended task-relevant features to achieve high performance\non specific datasets. As a result, these models perform poorly on datasets\noutside the training distribution. Some recent studies address the above issue\nby reducing the weights of biased samples during the training process. However,\nthese methods still encode biased latent features in representations and\nneglect the dynamic nature of bias, which hinders model prediction. We propose\nan NLU debiasing method, named debiasing contrastive learning (DCT), to\nsimultaneously alleviate the above problems based on contrastive learning. We\ndevise a debiasing positive sampling strategy to mitigate biased latent\nfeatures by selecting the least similar biased positive samples. We also\npropose a dynamic negative sampling strategy to capture the dynamic influence\nof biases by employing a bias-only model to dynamically select the most similar\nbiased negative samples. We conduct experiments on three NLU benchmark\ndatasets. Experimental results show that DCT outperforms state-of-the-art\nbaselines on out-of-distribution datasets while maintaining in-distribution\nperformance. We also verify that DCT can reduce biased latent features from the\nmodel's representations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_Y/0/1/0/all/0/1\">Yougang Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Piji Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yechang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1\">Maarten de Rijke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1\">Pengjie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yukun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1\">Dawei Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1\">Zhaochun Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MORTY: Structured Summarization for Targeted Information Extraction from Scholarly Articles. (arXiv:2212.05429v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05429","description":"<p>Information extraction from scholarly articles is a challenging task due to\nthe sizable document length and implicit information hidden in text, figures,\nand citations. Scholarly information extraction has various applications in\nexploration, archival, and curation services for digital libraries and\nknowledge management systems. We present MORTY, an information extraction\ntechnique that creates structured summaries of text from scholarly articles.\nOur approach condenses the article's full-text to property-value pairs as a\nsegmented text snippet called structured summary. We also present a sizable\nscholarly dataset combining structured summaries retrieved from a scholarly\nknowledge graph and corresponding publicly available scientific articles, which\nwe openly publish as a resource for the research community. Our results show\nthat structured summarization is a suitable approach for targeted information\nextraction that complements other commonly used methods such as question\nanswering and named entity recognition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jaradeh_M/0/1/0/all/0/1\">Mohamad Yaser Jaradeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stocker_M/0/1/0/all/0/1\">Markus Stocker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Auer_S/0/1/0/all/0/1\">S&#xf6;ren Auer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"End-to-End Speech Translation of Arabic to English Broadcast News. (arXiv:2212.05479v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05479","description":"<p>Speech translation (ST) is the task of directly translating acoustic speech\nsignals in a source language into text in a foreign language. ST task has been\naddressed, for a long time, using a pipeline approach with two modules : first\nan Automatic Speech Recognition (ASR) in the source language followed by a\ntext-to-text Machine translation (MT). In the past few years, we have seen a\nparadigm shift towards the end-to-end approaches using sequence-to-sequence\ndeep neural network models. This paper presents our efforts towards the\ndevelopment of the first Broadcast News end-to-end Arabic to English speech\ntranslation system. Starting from independent ASR and MT LDC releases, we were\nable to identify about 92 hours of Arabic audio recordings for which the manual\ntranscription was also translated into English at the segment level. These data\nwas used to train and compare pipeline and end-to-end speech translation\nsystems under multiple scenarios including transfer learning and data\naugmentation techniques.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bougares_F/0/1/0/all/0/1\">Fethi Bougares</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jouili_S/0/1/0/all/0/1\">Salim Jouili</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FastClass: A Time-Efficient Approach to Weakly-Supervised Text Classification. (arXiv:2212.05506v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05506","description":"<p>Weakly-supervised text classification aims to train a classifier using only\nclass descriptions and unlabeled data. Recent research shows that\nkeyword-driven methods can achieve state-of-the-art performance on various\ntasks. However, these methods not only rely on carefully-crafted class\ndescriptions to obtain class-specific keywords but also require substantial\namount of unlabeled data and takes a long time to train. This paper proposes\nFastClass, an efficient weakly-supervised classification approach. It uses\ndense text representation to retrieve class-relevant documents from external\nunlabeled corpus and selects an optimal subset to train a classifier. Compared\nto keyword-driven methods, our approach is less reliant on initial class\ndescriptions as it no longer needs to expand each class description into a set\nof class-specific keywords. Experiments on a wide range of classification tasks\nshow that the proposed approach frequently outperforms keyword-driven models in\nterms of classification accuracy and often enjoys orders-of-magnitude faster\ntraining speed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xia_T/0/1/0/all/0/1\">Tingyu Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuan Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yi Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extending TrOCR for Text Localization-Free OCR of Full-Page Scanned Receipt Images. (arXiv:2212.05525v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05525","description":"<p>Digitization of scanned receipts aims to extract text from receipt images and\nsave it into structured documents. This is usually split into two sub-tasks:\ntext localization and optical character recognition (OCR). Most existing OCR\nmodels only focus on the cropped text instance images, which require the\nbounding box information provided by a text region detection model. Introducing\nan additional detector to identify the text instance images in advance is\ninefficient, however instance-level OCR models have very low accuracy when\nprocessing the whole image for the document-level OCR, such as receipt images\ncontaining multiple text lines arranged in various layouts. To this end, we\npropose a localization-free document-level OCR model for transcribing all the\ncharacters in a receipt image into an ordered sequence end-to-end.\nSpecifically, we finetune the pretrained Transformer-based instance-level model\nTrOCR with randomly cropped image chunks, and gradually increase the image\nchunk size to generalize the recognition ability from instance images to\nfull-page images. In our experiments on the SROIE receipt OCR dataset, the\nmodel finetuned with our strategy achieved 64.4 F1-score and a 22.8% character\nerror rates (CER) on the word-level and character-level metrics, respectively,\nwhich outperforms the baseline results with 48.5 F1-score and 50.6% CER. The\nbest model, which splits the full image into 15 equally sized chunks, gives\n87.8 F1-score and 4.98% CER with minimal additional pre or post-processing of\nthe output. Moreover, the characters in the generated document-level sequences\nare arranged in the reading order, which is practical for real-world\napplications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongkuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whittaker_E/0/1/0/all/0/1\">Edward Whittaker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitagishi_I/0/1/0/all/0/1\">Ikuo Kitagishi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Associations Between Natural Language Processing (NLP) Enriched Social Determinants of Health and Suicide Death among US Veterans. (arXiv:2212.05546v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05546","description":"<p>Importance: Social determinants of health (SDOH) are known to be associated\nwith increased risk of suicidal behaviors, but few studies utilized SDOH from\nunstructured electronic health record (EHR) notes. Objective: To investigate\nassociations between suicide and recent SDOH, identified using structured and\nunstructured data.\n</p>\n<p>Design: Nested case-control study.\n</p>\n<p>Setting: EHR data from the US Veterans Health Administration (VHA).\n</p>\n<p>Participants: 6,122,785 Veterans who received care in the US VHA between\nOctober 1, 2010, and September 30, 2015.\n</p>\n<p>Exposures: Occurrence of SDOH over a maximum span of two years compared with\nno occurrence of SDOH.\n</p>\n<p>Main Outcomes and Measures: Cases of suicide deaths were matched with 4\ncontrols on birth year, cohort entry date, sex, and duration of follow-up. We\ndeveloped an NLP system to extract SDOH from unstructured notes. Structured\ndata, NLP on unstructured data, and combining them yielded seven, eight and\nnine SDOH respectively. Adjusted odds ratios (aORs) and 95% confidence\nintervals (CIs) were estimated using conditional logistic regression.\n</p>\n<p>Results: In our cohort, 8,821 Veterans committed suicide during 23,725,382\nperson-years of follow-up (incidence rate 37.18 /100,000 person-years). Our\ncohort was mostly male (92.23%) and white (76.99%). Across the six common SDOH\nas covariates, NLP-extracted SDOH, on average, covered 84.38% of all SDOH\noccurrences. All SDOH, measured by structured data and NLP, were significantly\nassociated with increased risk of suicide. The SDOH with the largest effects\nwas legal problems (aOR=2.67, 95% CI=2.46-2.89), followed by violence\n(aOR=2.26, 95% CI=2.11-2.43). NLP-extracted and structured SDOH were also\nassociated with suicide.\n</p>\n<p>Conclusions and Relevance: NLP-extracted SDOH were always significantly\nassociated with increased risk of suicide among Veterans, suggesting the\npotential of NLP in public health studies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mitra_A/0/1/0/all/0/1\">Avijit Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pradhan_R/0/1/0/all/0/1\">Richeek Pradhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melamed_R/0/1/0/all/0/1\">Rachel D Melamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoaglin_D/0/1/0/all/0/1\">David C Hoaglin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tucker_K/0/1/0/all/0/1\">Katherine L Tucker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reisman_J/0/1/0/all/0/1\">Joel I Reisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhichao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weisong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_J/0/1/0/all/0/1\">Jack Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multimodal and Explainable Internet Meme Classification. (arXiv:2212.05612v1 [cs.AI])","link":"http://arxiv.org/abs/2212.05612","description":"<p>Warning: this paper contains content that may be offensive or upsetting. In\nthe current context where online platforms have been effectively weaponized in\na variety of geo-political events and social issues, Internet memes make fair\ncontent moderation at scale even more difficult. Existing work on meme\nclassification and tracking has focused on black-box methods that do not\nexplicitly consider the semantics of the memes or the context of their\ncreation. In this paper, we pursue a modular and explainable architecture for\nInternet meme understanding. We design and implement multimodal classification\nmethods that perform example- and prototype-based reasoning over training\ncases, while leveraging both textual and visual SOTA models to represent the\nindividual cases. We study the relevance of our modular and explainable models\nin detecting harmful memes on two existing tasks: Hate Speech Detection and\nMisogyny Classification. We compare the performance between example- and\nprototype-based methods, and between text, vision, and multimodal models,\nacross different categories of harmfulness (e.g., stereotype and\nobjectification). We devise a user-friendly interface that facilitates the\ncomparative analysis of examples retrieved by all of our models for any given\nmeme, informing the community about the strengths and limitations of these\nexplainable methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Thakur_A/0/1/0/all/0/1\">Abhinav Kumar Thakur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilievski_F/0/1/0/all/0/1\">Filip Ilievski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandlin_H/0/1/0/all/0/1\">H&#xf4;ng-&#xc2;n Sandlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mermoud_A/0/1/0/all/0/1\">Alain Mermoud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sourati_Z/0/1/0/all/0/1\">Zhivar Sourati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luceri_L/0/1/0/all/0/1\">Luca Luceri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tommasini_R/0/1/0/all/0/1\">Riccardo Tommasini</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Study of Slang Representation Methods. (arXiv:2212.05613v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05613","description":"<p>Warning: this paper contains content that may be offensive or upsetting.\nConsidering the large amount of content created online by the minute,\nslang-aware automatic tools are critically needed to promote social good, and\nassist policymakers and moderators in restricting the spread of offensive\nlanguage, abuse, and hate speech. Despite the success of large language models\nand the spontaneous emergence of slang dictionaries, it is unclear how far\ntheir combination goes in terms of slang understanding for downstream social\ngood tasks. In this paper, we provide a framework to study different\ncombinations of representation learning models and knowledge resources for a\nvariety of downstream tasks that rely on slang understanding. Our experiments\nshow the superiority of models that have been pre-trained on social media data,\nwhile the impact of dictionaries is positive only for static word embeddings.\nOur error analysis identifies core challenges for slang representation\nlearning, including out-of-vocabulary words, polysemy, variance, and annotation\ndisagreements, which can be traced to characteristics of slang as a quickly\nevolving and highly subjective language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kolla_A/0/1/0/all/0/1\">Aravinda Kolla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilievski_F/0/1/0/all/0/1\">Filip Ilievski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandlin_H/0/1/0/all/0/1\">H&#xf4;ng-&#xc2;n Sandlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mermoud_A/0/1/0/all/0/1\">Alain Mermoud</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ensembling Transformers for Cross-domain Automatic Term Extraction. (arXiv:2212.05696v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05696","description":"<p>Automatic term extraction plays an essential role in domain language\nunderstanding and several natural language processing downstream tasks. In this\npaper, we propose a comparative study on the predictive power of\nTransformers-based pretrained language models toward term extraction in a\nmulti-language cross-domain setting. Besides evaluating the ability of\nmonolingual models to extract single- and multi-word terms, we also experiment\nwith ensembles of mono- and multilingual models by conducting the intersection\nor union on the term output sets of different language models. Our experiments\nhave been conducted on the ACTER corpus covering four specialized domains\n(Corruption, Wind energy, Equitation, and Heart failure) and three languages\n(English, French, and Dutch), and on the RSDO5 Slovenian corpus covering four\nadditional domains (Biomechanics, Chemistry, Veterinary, and Linguistics). The\nresults show that the strategy of employing monolingual models outperforms the\nstate-of-the-art approaches from the related work leveraging multilingual\nmodels, regarding all the languages except Dutch and French if the term\nextraction task excludes the extraction of named entity terms. Furthermore, by\ncombining the outputs of the two best performing models, we achieve significant\nimprovements.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tran_H/0/1/0/all/0/1\">Hanh Thi Hong Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinc_M/0/1/0/all/0/1\">Matej Martinc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pelicon_A/0/1/0/all/0/1\">Andraz Pelicon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doucet_A/0/1/0/all/0/1\">Antoine Doucet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollak_S/0/1/0/all/0/1\">Senja Pollak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Implementing Deep Learning-Based Approaches for Article Summarization in Indian Languages. (arXiv:2212.05702v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05702","description":"<p>The research on text summarization for low-resource Indian languages has been\nlimited due to the availability of relevant datasets. This paper presents a\nsummary of various deep-learning approaches used for the ILSUM 2022 Indic\nlanguage summarization datasets. The ISUM 2022 dataset consists of news\narticles written in Indian English, Hindi, and Gujarati respectively, and their\nground-truth summarizations. In our work, we explore different pre-trained\nseq2seq models and fine-tune those with the ILSUM 2022 datasets. In our case,\nthe fine-tuned SoTA PEGASUS model worked the best for English, the fine-tuned\nIndicBART model with augmented data for Hindi, and again fine-tuned PEGASUS\nmodel along with a translation mapping-based approach for Gujarati. Our scores\non the obtained inferences were evaluated using ROUGE-1, ROUGE-2, and ROUGE-4\nas the evaluation metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tangsali_R/0/1/0/all/0/1\">Rahul Tangsali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pingle_A/0/1/0/all/0/1\">Aabha Pingle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vyawahare_A/0/1/0/all/0/1\">Aditya Vyawahare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_I/0/1/0/all/0/1\">Isha Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Raviraj Joshi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"T5Score: Discriminative Fine-tuning of Generative Evaluation Metrics. (arXiv:2212.05726v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05726","description":"<p>Modern embedding-based metrics for evaluation of generated text generally\nfall into one of two paradigms: discriminative metrics that are trained to\ndirectly predict which outputs are of higher quality according to supervised\nhuman annotations, and generative metrics that are trained to evaluate text\nbased on the probabilities of a generative model. Both have their advantages;\ndiscriminative metrics are able to directly optimize for the problem of\ndistinguishing between good and bad outputs, while generative metrics can be\ntrained using abundant raw text. In this paper, we present a framework that\ncombines the best of both worlds, using both supervised and unsupervised\nsignals from whatever data we have available. We operationalize this idea by\ntraining T5Score, a metric that uses these training signals with mT5 as the\nbackbone. We perform an extensive empirical comparison with other existing\nmetrics on 5 datasets, 19 languages and 280 systems, demonstrating the utility\nof our method. Experimental results show that: T5Score achieves the best\nperformance on all datasets against existing top-scoring metrics at the segment\nlevel. We release our code and models at https://github.com/qinyiwei/T5Score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yiwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1\">Weizhe Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Pengfei Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Searching for Effective Multilingual Fine-Tuning Methods: A Case Study in Summarization. (arXiv:2212.05740v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05740","description":"<p>Recently, a large number of tuning strategies have been proposed to adapt\npre-trained language models to downstream tasks. In this paper, we perform an\nextensive empirical evaluation of various tuning strategies for multilingual\nlearning, particularly in the context of text summarization. Specifically, we\nexplore the relative advantages of three families of multilingual tuning\nstrategies (a total of five models) and empirically evaluate them for\nsummarization over 45 languages. Experimentally, we not only established a new\nstate-of-the-art on the XL-Sum dataset but also derive a series of observations\nthat hopefully can provide hints for future research on the design of\nmultilingual tuning strategies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yiwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Pengfei Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Momentum Contrastive Pre-training for Question Answering. (arXiv:2212.05762v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05762","description":"<p>Existing pre-training methods for extractive Question Answering (QA) generate\ncloze-like queries different from natural questions in syntax structure, which\ncould overfit pre-trained models to simple keyword matching. In order to\naddress this problem, we propose a novel Momentum Contrastive pRe-training fOr\nqueStion anSwering (MCROSS) method for extractive QA. Specifically, MCROSS\nintroduces a momentum contrastive learning framework to align the answer\nprobability between cloze-like and natural query-passage sample pairs. Hence,\nthe pre-trained models can better transfer the knowledge learned in cloze-like\nsamples to answering natural questions. Experimental results on three\nbenchmarking QA datasets show that our method achieves noticeable improvement\ncompared with all baselines in both supervised and zero-shot scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1\">Minda Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Muzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Domain Adaptation of Transformer-Based Models using Unlabeled Data for Relevance and Polarity Classification of German Customer Feedback. (arXiv:2212.05764v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05764","description":"<p>Understanding customer feedback is becoming a necessity for companies to\nidentify problems and improve their products and services. Text classification\nand sentiment analysis can play a major role in analyzing this data by using a\nvariety of machine and deep learning approaches. In this work, different\ntransformer-based models are utilized to explore how efficient these models are\nwhen working with a German customer feedback dataset. In addition, these\npre-trained models are further analyzed to determine if adapting them to a\nspecific domain using unlabeled data can yield better results than\noff-the-shelf pre-trained models. To evaluate the models, two downstream tasks\nfrom the GermEval 2017 are considered. The experimental results show that\ntransformer-based models can reach significant improvements compared to a\nfastText baseline and outperform the published scores and previous models. For\nthe subtask Relevance Classification, the best models achieve a micro-averaged\n$F1$-Score of 96.1 % on the first test set and 95.9 % on the second one, and a\nscore of 85.1 % and 85.3 % for the subtask Polarity Classification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Idrissi_Yaghir_A/0/1/0/all/0/1\">Ahmad Idrissi-Yaghir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schafer_H/0/1/0/all/0/1\">Henning Sch&#xe4;fer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauer_N/0/1/0/all/0/1\">Nadja Bauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friedrich_C/0/1/0/all/0/1\">Christoph M. Friedrich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue. (arXiv:2212.05765v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05765","description":"<p>Video-grounded Dialogue (VGD) aims to decode an answer sentence to a question\nregarding a given video and dialogue context. Despite the recent success of\nmulti-modal reasoning to generate answer sentences, existing dialogue systems\nstill suffer from a text hallucination problem, which denotes indiscriminate\ntext-copying from input texts without an understanding of the question. This is\ndue to learning spurious correlations from the fact that answer sentences in\nthe dataset usually include the words of input texts, thus the VGD system\nexcessively relies on copying words from input texts by hoping those words to\noverlap with ground-truth texts. Hence, we design Text Hallucination Mitigating\n(THAM) framework, which incorporates Text Hallucination Regularization (THR)\nloss derived from the proposed information-theoretic text hallucination\nmeasurement approach. Applying THAM with current dialogue systems validates the\neffectiveness on VGD benchmarks (i.e., AVSD@DSTC7 and AVSD@DSTC8) and shows\nenhanced interpretability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Sunjae Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_E/0/1/0/all/0/1\">Eunseop Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_H/0/1/0/all/0/1\">Hee Suk Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junyeong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_C/0/1/0/all/0/1\">Chang D. Yoo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reasoning over Different Types of Knowledge Graphs: Static, Temporal and Multi-Modal. (arXiv:2212.05767v1 [cs.AI])","link":"http://arxiv.org/abs/2212.05767","description":"<p>Knowledge graph reasoning (KGR), aiming to deduce new facts from existing\nfacts based on mined logic rules underlying knowledge graphs (KGs), has become\na fast-growing research direction. It has been proven to significantly benefit\nthe usage of KGs in many AI applications, such as question answering and\nrecommendation systems, etc. According to the graph types, the existing KGR\nmodels can be roughly divided into three categories, \\textit{i.e.,} static\nmodels, temporal models, and multi-modal models. The early works in this domain\nmainly focus on static KGR and tend to directly apply general knowledge graph\nembedding models to the reasoning task. However, these models are not suitable\nfor more complex but practical tasks, such as inductive static KGR, temporal\nKGR, and multi-modal KGR. To this end, multiple works have been developed\nrecently, but no survey papers and open-source repositories comprehensively\nsummarize and discuss models in this important direction. To fill the gap, we\nconduct a survey for knowledge graph reasoning tracing from static to temporal\nand then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR\nmodels, and typical datasets are introduced and discussed consequently.\nMoreover, we discuss the challenges and potential opportunities. The\ncorresponding open-source repository is shared on GitHub:\nhttps://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Ke Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_L/0/1/0/all/0/1\">Lingyuan Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Meng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yue Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_W/0/1/0/all/0/1\">Wenxuan Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Siwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Sihang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xinwang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1\">Fuchun Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Natural Language Processing for Programming. (arXiv:2212.05773v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05773","description":"<p>Natural language processing for programming, which aims to use NLP techniques\nto assist programming, has experienced an explosion in recent years. However,\nthere is no literature that systematically reviews related work from the full\nspectrum. In this paper, we comprehensively investigate existing work, ranging\nfrom early deductive models to the latest competition-level models. Another\nadvantage of this paper is the completeness of the technique category, which\nprovides easy access to locating and comparing future works.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qingfu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xianzhen Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Cuiyun Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_W/0/1/0/all/0/1\">Wanxiang Che</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Collaborating Heterogeneous Natural Language Processing Tasks via Federated Learning. (arXiv:2212.05789v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05789","description":"<p>The increasing privacy concerns on personal private text data promote the\ndevelopment of federated learning (FL) in recent years. However, the existing\nstudies on applying FL in NLP are not suitable to coordinate participants with\nheterogeneous or private learning objectives. In this study, we further broaden\nthe application scope of FL in NLP by proposing an Assign-Then-Contrast\n(denoted as ATC) framework, which enables clients with heterogeneous NLP tasks\nto construct an FL course and learn useful knowledge from each other.\nSpecifically, the clients are suggested to first perform local training with\nthe unified tasks assigned by the server rather than using their own learning\nobjectives, which is called the Assign training stage. After that, in the\nContrast training stage, clients train with different local learning objectives\nand exchange knowledge with other clients who contribute consistent and useful\nmodel updates. We conduct extensive experiments on six widely-used datasets\ncovering both Natural Language Understanding (NLU) and Natural Language\nGeneration (NLG) tasks, and the proposed ATC framework achieves significant\nimprovements compared with various baseline methods. The source code is\navailable at\n\\url{https://github.com/alibaba/FederatedScope/tree/master/federatedscope/nlp/hetero_tasks}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1\">Chenhe Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuexiang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1\">Bolin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Ying Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yaliang Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BigText-QA: Question Answering over a Large-Scale Hybrid Knowledge Graph. (arXiv:2212.05798v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05798","description":"<p>Answering complex questions over textual resources remains a challenging\nproblem$\\unicode{x2013}$especially when interpreting the fine-grained\nrelationships among multiple entities that occur within a natural-language\nquestion or clue. Curated knowledge bases (KBs), such as YAGO, DBpedia,\nFreebase and Wikidata, have been widely used in this context and gained great\nacceptance for question-answering (QA) applications in the past decade. While\ncurrent KBs offer a concise representation of structured knowledge, they lack\nthe variety of formulations and semantic nuances as well as the context of\ninformation provided by the natural-language sources. With BigText-QA, we aim\nto develop an integrated QA system which is able to answer questions based on a\nmore redundant form of a knowledge graph (KG) that organizes both structured\nand unstructured (i.e., \"hybrid\") knowledge in a unified graphical\nrepresentation. BigText-QA thereby is able to combine the best of both\nworlds$\\unicode{x2013}$a canonical set of named entities, mapped to a\nstructured background KB (such as YAGO or Wikidata), as well as an open set of\ntextual clauses providing highly diversified relational paraphrases with rich\ncontext information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jingjing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biryukov_M/0/1/0/all/0/1\">Maria Biryukov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theobald_M/0/1/0/all/0/1\">Martin Theobald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venugopal_V/0/1/0/all/0/1\">Vinu Ellampallil Venugopal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Direct Speech-to-speech Translation without Textual Annotation using Bottleneck Features. (arXiv:2212.05805v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05805","description":"<p>Speech-to-speech translation directly translates a speech utterance to\nanother between different languages, and has great potential in tasks such as\nsimultaneous interpretation. State-of-art models usually contains an auxiliary\nmodule for phoneme sequences prediction, and this requires textual annotation\nof the training dataset. We propose a direct speech-to-speech translation model\nwhich can be trained without any textual annotation or content information.\nInstead of introducing an auxiliary phoneme prediction task in the model, we\npropose to use bottleneck features as intermediate training objectives for our\nmodel to ensure the translation performance of the system. Experiments on\nMandarin-Cantonese speech translation demonstrate the feasibility of the\nproposed approach and the performance can match a cascaded system with respect\nof translation and synthesis qualities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junhui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Junjie Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xiang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zejun Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"P-Transformer: Towards Better Document-to-Document Neural Machine Translation. (arXiv:2212.05830v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05830","description":"<p>Directly training a document-to-document (Doc2Doc) neural machine translation\n(NMT) via Transformer from scratch, especially on small datasets usually fails\nto converge. Our dedicated probing tasks show that 1) both the absolute\nposition and relative position information gets gradually weakened or even\nvanished once it reaches the upper encoder layers, and 2) the vanishing of\nabsolute position information in encoder output causes the training failure of\nDoc2Doc NMT. To alleviate this problem, we propose a position-aware Transformer\n(P-Transformer) to enhance both the absolute and relative position information\nin both self-attention and cross-attention. Specifically, we integrate absolute\npositional information, i.e., position embeddings, into the query-key pairs\nboth in self-attention and cross-attention through a simple yet effective\naddition operation. Moreover, we also integrate relative position encoding in\nself-attention. The proposed P-Transformer utilizes sinusoidal position\nencoding and does not require any task-specified position embedding, segment\nembedding, or attention mechanism. Through the above methods, we build a\nDoc2Doc NMT model with P-Transformer, which ingests the source document and\ncompletely generates the target document in a sequence-to-sequence (seq2seq)\nway. In addition, P-Transformer can be applied to seq2seq-based\ndocument-to-sentence (Doc2Sent) and sentence-to-sentence (Sent2Sent)\ntranslation. Extensive experimental results of Doc2Doc NMT show that\nP-Transformer significantly outperforms strong baselines on widely-used 9\ndocument-level datasets in 7 language pairs, covering small-, middle-, and\nlarge-scales, and achieves a new state-of-the-art. Experimentation on discourse\nphenomena shows that our Doc2Doc NMT models improve the translation quality in\nboth BLEU and discourse coherence. We make our code available on Github.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yachao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junhui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jing Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_S/0/1/0/all/0/1\">Shimin Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"I think this is the most disruptive technology\": Exploring Sentiments of ChatGPT Early Adopters using Twitter Data. (arXiv:2212.05856v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05856","description":"<p>Large language models have recently attracted significant attention due to\ntheir impressive performance on a variety of tasks. ChatGPT developed by OpenAI\nis one such implementation of a large, pre-trained language model that has\ngained immense popularity among early adopters, where certain users go to the\nextent of characterizing it as a disruptive technology in many domains.\nUnderstanding such early adopters' sentiments is important because it can\nprovide insights into the potential success or failure of the technology, as\nwell as its strengths and weaknesses. In this paper, we conduct a mixed-method\nstudy using 10,732 tweets from early ChatGPT users. We first use topic\nmodelling to identify the main topics and then perform an in-depth qualitative\nsentiment analysis of each topic. Our results show that the majority of the\nearly adopters have expressed overwhelmingly positive sentiments related to\ntopics such as Disruptions to software development, Entertainment and\nexercising creativity. Only a limited percentage of users expressed concerns\nabout issues such as the potential for misuse of ChatGPT, especially regarding\ntopics such as Impact on educational aspects. We discuss these findings by\nproviding specific examples for each topic and then detail implications related\nto addressing these concerns for both researchers and users.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Haque_M/0/1/0/all/0/1\">Mubin Ul Haque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dharmadasa_I/0/1/0/all/0/1\">Isuru Dharmadasa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sworna_Z/0/1/0/all/0/1\">Zarrin Tasnim Sworna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajapakse_R/0/1/0/all/0/1\">Roshan Namal Rajapakse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_H/0/1/0/all/0/1\">Hussain Ahmad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated ICD Coding using Extreme Multi-label Long Text Transformer-based Models. (arXiv:2212.05857v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05857","description":"<p>Background: Encouraged by the success of pretrained Transformer models in\nmany natural language processing tasks, their use for International\nClassification of Diseases (ICD) coding tasks is now actively being explored.\nIn this study, we investigate three types of Transformer-based models, aiming\nto address the extreme label set and long text classification challenges that\nare posed by automated ICD coding tasks. Methods: The Transformer-based model\nPLM-ICD achieved the current state-of-the-art (SOTA) performance on the ICD\ncoding benchmark dataset MIMIC-III. It was chosen as our baseline model to be\nfurther optimised. XR-Transformer, the new SOTA model in the general extreme\nmulti-label text classification domain, and XR-LAT, a novel adaptation of the\nXR-Transformer model, were also trained on the MIMIC-III dataset. XR-LAT is a\nrecursively trained model chain on a predefined hierarchical code tree with\nlabel-wise attention, knowledge transferring and dynamic negative sampling\nmechanisms. Results: Our optimised PLM-ICD model, which was trained with longer\ntotal and chunk sequence lengths, significantly outperformed the current SOTA\nPLM-ICD model, and achieved the highest micro-F1 score of 60.8%. The\nXR-Transformer model, although SOTA in the general domain, did not perform well\nacross all metrics. The best XR-LAT based model obtained results that were\ncompetitive with the current SOTA PLM-ICD model, including improving the\nmacro-AUC by 2.1%. Conclusion: Our optimised PLM-ICD model is the new SOTA\nmodel for automated ICD coding on the MIMIC-III dataset, while our novel XR-LAT\nmodel performs competitively with the previous SOTA PLM-ICD model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Leibo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_Concha_O/0/1/0/all/0/1\">Oscar Perez-Concha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anthony Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennett_V/0/1/0/all/0/1\">Vicki Bennett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jorm_L/0/1/0/all/0/1\">Louisa Jorm</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text Mining-Based Patent Analysis for Automated Rule Checking in AEC. (arXiv:2212.05891v1 [cs.IR])","link":"http://arxiv.org/abs/2212.05891","description":"<p>Automated rule checking (ARC), which is expected to promote the efficiency of\nthe compliance checking process in the architecture, engineering, and\nconstruction (AEC) industry, is gaining increasing attention. Throwing light on\nthe ARC application hotspots and forecasting its trends are useful to the\nrelated research and drive innovations. Therefore, this study takes the patents\nfrom the database of the Derwent Innovations Index database (DII) and China\nnational knowledge infrastructure (CNKI) as data sources and then carried out a\nthree-step analysis including (1) quantitative characteristics (i.e., annual\ndistribution analysis) of patents, (2) identification of ARC topics using a\nlatent Dirichlet allocation (LDA) and, (3) SNA-based co-occurrence analysis of\nARC topics. The results show that the research hotspots and trends of Chinese\nand English patents are different. The contributions of this study have three\naspects: (1) an approach to a comprehensive analysis of patents by integrating\nmultiple text mining methods (i.e., SNA and LDA) is introduced ; (2) the\napplication hotspots and development trends of ARC are reviewed based on patent\nanalysis; and (3) a signpost for technological development and innovation of\nARC is provided.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhe Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_B/0/1/0/all/0/1\">Bo-Rui Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Q/0/1/0/all/0/1\">Qi-Tian Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yu-Cheng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xin-Zheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jia-Rui Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Parameter-Efficient Finetuning of Transformers for Source Code. (arXiv:2212.05901v1 [cs.CL])","link":"http://arxiv.org/abs/2212.05901","description":"<p>Pretrained Transformers achieve state-of-the-art performance in various\ncode-processing tasks but may be too large to be deployed. As software\ndevelopment tools often incorporate modules for various purposes which may\npotentially use a single instance of the pretrained model, it appears relevant\nto utilize parameter-efficient fine-tuning for the pretrained models of code.\nIn this work, we test two widely used approaches, adapters and LoRA, which were\ninitially tested on NLP tasks, on four code-processing tasks. We find that\nthough the efficient fine-tuning approaches may achieve comparable or higher\nperformance than the standard, full, fine-tuning in code understanding tasks,\nthey underperform full fine-tuning in code-generative tasks. These results\nunderline the importance of testing efficient fine-tuning approaches on other\ndomains than NLP and motivate future research in efficient fine-tuning for\nsource code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ayupov_S/0/1/0/all/0/1\">Shamil Ayupov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chirkova_N/0/1/0/all/0/1\">Nadezhda Chirkova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning From Human Correction. (arXiv:2102.00225v9 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2102.00225","description":"<p>In industry NLP application, our manually labeled data has a certain number\nof noisy data. We present a simple method to find the noisy data and re-label\nthem manually, meanwhile we collect the correction information. Then we present\nnovel method to incorporate the human correction information into deep learning\nmodel. Human know how to correct noisy data. So the correction information can\nbe inject into deep learning model. We do the experiment on our own text\nclassification dataset, which is manually labeled, because we re-label the\nnoisy data in our dataset for our industry application. The experiment result\nshows that our method improve the classification accuracy from 91.7% to 92.5%.\nThe 91.7% accuracy is trained on the corrected dataset, which improve the\nbaseline from 83.3% to 91.7%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1\">Tong Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DziriBERT: a Pre-trained Language Model for the Algerian Dialect. (arXiv:2109.12346v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.12346","description":"<p>Pre-trained transformers are now the de facto models in Natural Language\nProcessing given their state-of-the-art results in many tasks and languages.\nHowever, most of the current models have been trained on languages for which\nlarge text resources are already available (such as English, French, Arabic,\netc.). Therefore, there are still a number of low-resource languages that need\nmore attention from the community. In this paper, we study the Algerian dialect\nwhich has several specificities that make the use of Arabic or multilingual\nmodels inappropriate. To address this issue, we collected more than one million\nAlgerian tweets, and pre-trained the first Algerian language model: DziriBERT.\nWhen compared with existing models, DziriBERT achieves better results,\nespecially when dealing with the Roman script. The obtained results show that\npre-training a dedicated model on a small dataset (150 MB) can outperform\nexisting models that have been trained on much more data (hundreds of GB).\nFinally, our model is publicly available to the community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abdaoui_A/0/1/0/all/0/1\">Amine Abdaoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berrimi_M/0/1/0/all/0/1\">Mohamed Berrimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oussalah_M/0/1/0/all/0/1\">Mourad Oussalah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moussaoui_A/0/1/0/all/0/1\">Abdelouahab Moussaoui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Regionalized models for Spanish language variations based on Twitter. (arXiv:2110.06128v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2110.06128","description":"<p>Spanish is one of the most spoken languages in the globe, but not necessarily\nSpanish is written and spoken in the same way in different countries.\nUnderstanding local language variations can help to improve model performances\non regional tasks, both understanding local structures and also improving the\nmessage's content. For instance, think about a machine learning engineer who\nautomatizes some language classification task on a particular region or a\nsocial scientist trying to understand a regional event with echoes on social\nmedia; both can take advantage of dialect-based language models to understand\nwhat is happening with more contextual information hence more precision.\n</p>\n<p>This manuscript presents and describes a set of regionalized resources for\nthe Spanish language built on four-year Twitter public messages geotagged in 26\nSpanish-speaking countries. We introduce word embeddings based on FastText,\nlanguage models based on BERT, and per-region sample corpora. We also provide a\nbroad comparison among regions covering lexical and semantical similarities; as\nwell as examples of using regional resources on message classification tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tellez_E/0/1/0/all/0/1\">Eric S. Tellez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moctezuma_D/0/1/0/all/0/1\">Daniela Moctezuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miranda_S/0/1/0/all/0/1\">Sabino Miranda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graff_M/0/1/0/all/0/1\">Mario Graff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_G/0/1/0/all/0/1\">Guillermo Ruiz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Logical Fallacy Detection. (arXiv:2202.13758v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2202.13758","description":"<p>Reasoning is central to human intelligence. However, fallacious arguments are\ncommon, and some exacerbate problems such as spreading misinformation about\nclimate change. In this paper, we propose the task of logical fallacy\ndetection, and provide a new dataset (Logic) of logical fallacies generally\nfound in text, together with an additional challenge set for detecting logical\nfallacies in climate change claims (LogicClimate). Detecting logical fallacies\nis a hard problem as the model must understand the underlying logical structure\nof the argument. We find that existing pretrained large language models perform\npoorly on this task. In contrast, we show that a simple structure-aware\nclassifier outperforms the best language model by 5.46% on Logic and 4.51% on\nLogicClimate. We encourage future work to explore this task as (a) it can serve\nas a new reasoning challenge for language models, and (b) it can have potential\napplications in tackling the spread of misinformation. Our dataset and code are\navailable at https://github.com/causalNLP/logical-fallacy\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhijing Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lalwani_A/0/1/0/all/0/1\">Abhinav Lalwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaidhya_T/0/1/0/all/0/1\">Tejas Vaidhya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xiaoyu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yiwen Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_Z/0/1/0/all/0/1\">Zhiheng Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1\">Rada Mihalcea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"No Parameter Left Behind: How Distillation and Model Size Affect Zero-Shot Retrieval. (arXiv:2206.02873v5 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2206.02873","description":"<p>Recent work has shown that small distilled language models are strong\ncompetitors to models that are orders of magnitude larger and slower in a wide\nrange of information retrieval tasks. This has made distilled and dense models,\ndue to latency constraints, the go-to choice for deployment in real-world\nretrieval applications. In this work, we question this practice by showing that\nthe number of parameters and early query-document interaction play a\nsignificant role in the generalization ability of retrieval models. Our\nexperiments show that increasing model size results in marginal gains on\nin-domain test sets, but much larger gains in new domains never seen during\nfine-tuning. Furthermore, we show that rerankers largely outperform dense ones\nof similar size in several tasks. Our largest reranker reaches the state of the\nart in 12 of the 18 datasets of the Benchmark-IR (BEIR) and surpasses the\nprevious state of the art by 3 average points. Finally, we confirm that\nin-domain effectiveness is not a good indicator of zero-shot effectiveness.\nCode is available at\nhttps://github.com/guilhermemr04/scaling-zero-shot-retrieval.git\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rosa_G/0/1/0/all/0/1\">Guilherme Moraes Rosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonifacio_L/0/1/0/all/0/1\">Luiz Bonifacio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeronymo_V/0/1/0/all/0/1\">Vitor Jeronymo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abonizio_H/0/1/0/all/0/1\">Hugo Abonizio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fadaee_M/0/1/0/all/0/1\">Marzieh Fadaee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lotufo_R/0/1/0/all/0/1\">Roberto Lotufo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nogueira_R/0/1/0/all/0/1\">Rodrigo Nogueira</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Novel Chinese Dialect TTS Frontend with Non-Autoregressive Neural Machine Translation. (arXiv:2206.04922v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.04922","description":"<p>Chinese dialects are different variations of Chinese and can be considered as\ndifferent languages in the same language family with Mandarin. Though they all\nuse Chinese characters, the pronunciations, grammar and idioms can vary\nsignificantly, and even local speakers may find it hard to input correct\nwritten forms of dialect. Besides, using Mandarin text as text-to-speech inputs\nwould generate speech with poor naturalness. In this paper, we propose a novel\nChinese dialect TTS frontend with a translation module, which converts Mandarin\ntext into dialectic expressions to improve the intelligibility and naturalness\nof synthesized speech. A non-autoregressive neural machine translation model\nwith various tricks is proposed for the translation task. It is the first known\nwork to incorporate translation with TTS frontend. Experiments on Cantonese\nshow the proposed model improves 2.56 BLEU and TTS improves 0.27 MOS with\nMandarin inputs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junhui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_W/0/1/0/all/0/1\">Wudi Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Junjie Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xiang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zejun Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Benchmark for Understanding and Generating Dialogue between Characters in Stories. (arXiv:2209.08524v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.08524","description":"<p>Many classical fairy tales, fiction, and screenplays leverage dialogue to\nadvance story plots and establish characters. We present the first study to\nexplore whether machines can understand and generate dialogue in stories, which\nrequires capturing traits of different characters and the relationships between\nthem. To this end, we propose two new tasks including Masked Dialogue\nGeneration and Dialogue Speaker Recognition, i.e., generating missing dialogue\nturns and predicting speakers for specified dialogue turns, respectively. We\nbuild a new dataset DialStory, which consists of 105k Chinese stories with a\nlarge amount of dialogue weaved into the plots to support the evaluation. We\nshow the difficulty of the proposed tasks by testing existing models with\nautomatic and manual evaluation on DialStory. Furthermore, we propose to learn\nexplicit character representations to improve performance on these tasks.\nExtensive experiments and case studies show that our approach can generate more\ncoherent and informative dialogue, and achieve higher speaker recognition\naccuracy than strong baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jianzhu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_J/0/1/0/all/0/1\">Jian Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploration of A Self-Supervised Speech Model: A Study on Emotional Corpora. (arXiv:2210.02595v3 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2210.02595","description":"<p>Self-supervised speech models have grown fast during the past few years and\nhave proven feasible for use in various downstream tasks. Some recent work has\nstarted to look at the characteristics of these models, yet many concerns have\nnot been fully addressed. In this work, we conduct a study on emotional corpora\nto explore a popular self-supervised model -- wav2vec 2.0. Via a set of\nquantitative analysis, we mainly demonstrate that: 1) wav2vec 2.0 appears to\ndiscard paralinguistic information that is less useful for word recognition\npurposes; 2) for emotion recognition, representations from the middle layer\nalone perform as well as those derived from layer averaging, while the final\nlayer results in the worst performance in some cases; 3) current\nself-supervised models may not be the optimal solution for downstream tasks\nthat make use of non-lexical features. Our work provides novel findings that\nwill aid future research in this area and theoretical basis for the use of\nexisting models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yuanchao Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mohamied_Y/0/1/0/all/0/1\">Yumnah Mohamied</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bell_P/0/1/0/all/0/1\">Peter Bell</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lai_C/0/1/0/all/0/1\">Catherine Lai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Spread Love Not Hate: Undermining the Importance of Hateful Pre-training for Hate Speech Detection. (arXiv:2210.04267v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.04267","description":"<p>Pre-training large neural language models, such as BERT, has led to\nimpressive gains on many natural language processing (NLP) tasks. Although this\nmethod has proven to be effective for many domains, it might not always provide\ndesirable benefits. In this paper, we study the effects of hateful pre-training\non low-resource hate speech classification tasks. While previous studies on the\nEnglish language have emphasized its importance, we aim to augment their\nobservations with some non-obvious insights. We evaluate different variations\nof tweet-based BERT models pre-trained on hateful, non-hateful, and mixed\nsubsets of a 40M tweet dataset. This evaluation is carried out for the Indian\nlanguages Hindi and Marathi. This paper is empirical evidence that hateful\npre-training is not the best pre-training option for hate speech detection. We\nshow that pre-training on non-hateful text from the target domain provides\nsimilar or better results. Further, we introduce HindTweetBERT and\nMahaTweetBERT, the first publicly available BERT models pre-trained on Hindi\nand Marathi tweets, respectively. We show that they provide state-of-the-art\nperformance on hate speech classification tasks. We also release hateful BERT\nfor the two languages and a gold hate speech evaluation benchmark HateEval-Hi\nand HateEval-Mr consisting of manually labeled 2000 tweets each. The models and\ndata are available at https://github.com/l3cube-pune/MarathiNLP .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gokhale_O/0/1/0/all/0/1\">Omkar Gokhale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kane_A/0/1/0/all/0/1\">Aditya Kane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patankar_S/0/1/0/all/0/1\">Shantanu Patankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chavan_T/0/1/0/all/0/1\">Tanmay Chavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Raviraj Joshi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contrastive Learning with Prompt-derived Virtual Semantic Prototypes for Unsupervised Sentence Embedding. (arXiv:2211.03348v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.03348","description":"<p>Contrastive learning has become a new paradigm for unsupervised sentence\nembeddings. Previous studies focus on instance-wise contrastive learning,\nattempting to construct positive pairs with textual data augmentation. In this\npaper, we propose a novel Contrastive learning method with Prompt-derived\nVirtual semantic Prototypes (ConPVP). Specifically, with the help of prompts,\nwe construct virtual semantic prototypes to each instance, and derive negative\nprototypes by using the negative form of the prompts. Using a prototypical\ncontrastive loss, we enforce the anchor sentence embedding to be close to its\ncorresponding semantic prototypes, and far apart from the negative prototypes\nas well as the prototypes of other sentences. Extensive experimental results on\nsemantic textual similarity, transfer, and clustering tasks demonstrate the\neffectiveness of our proposed model compared to strong baselines. Code is\navailable at https://github.com/lemon0830/promptCSE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jiali Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yongjing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yufan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shuangzhi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yunbo Cao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model. (arXiv:2211.05100v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.05100","description":"<p>Large language models (LLMs) have been shown to be able to perform new tasks\nbased on a few demonstrations or natural language instructions. While these\ncapabilities have led to widespread adoption, most LLMs are developed by\nresource-rich organizations and are frequently kept from the public. As a step\ntowards democratizing this powerful technology, we present BLOOM, a\n176B-parameter open-access language model designed and built thanks to a\ncollaboration of hundreds of researchers. BLOOM is a decoder-only Transformer\nlanguage model that was trained on the ROOTS corpus, a dataset comprising\nhundreds of sources in 46 natural and 13 programming languages (59 in total).\nWe find that BLOOM achieves competitive performance on a wide variety of\nbenchmarks, with stronger results after undergoing multitask prompted\nfinetuning. To facilitate future research and applications using LLMs, we\npublicly release our models and code under the Responsible AI License.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Workshop_B/0/1/0/all/0/1\">BigScience Workshop</a>: <a href=\"http://arxiv.org/find/cs/1/au:+Scao_T/0/1/0/all/0/1\">Teven Le Scao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1\">Angela Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akiki_C/0/1/0/all/0/1\">Christopher Akiki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavlick_E/0/1/0/all/0/1\">Ellie Pavlick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilic_S/0/1/0/all/0/1\">Suzana Ili&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hesslow_D/0/1/0/all/0/1\">Daniel Hesslow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castagne_R/0/1/0/all/0/1\">Roman Castagn&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luccioni_A/0/1/0/all/0/1\">Alexandra Sasha Luccioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yvon_F/0/1/0/all/0/1\">Fran&#xe7;ois Yvon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galle_M/0/1/0/all/0/1\">Matthias Gall&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tow_J/0/1/0/all/0/1\">Jonathan Tow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1\">Alexander M. Rush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biderman_S/0/1/0/all/0/1\">Stella Biderman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Webson_A/0/1/0/all/0/1\">Albert Webson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ammanamanchi_P/0/1/0/all/0/1\">Pawan Sasanka Ammanamanchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Thomas Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagot_B/0/1/0/all/0/1\">Beno&#xee;t Sagot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muennighoff_N/0/1/0/all/0/1\">Niklas Muennighoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moral_A/0/1/0/all/0/1\">Albert Villanova del Moral</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruwase_O/0/1/0/all/0/1\">Olatunji Ruwase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bawden_R/0/1/0/all/0/1\">Rachel Bawden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bekman_S/0/1/0/all/0/1\">Stas Bekman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McMillan_Major_A/0/1/0/all/0/1\">Angelina McMillan-Major</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beltagy_I/0/1/0/all/0/1\">Iz Beltagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Huu Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saulnier_L/0/1/0/all/0/1\">Lucile Saulnier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Samson Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suarez_P/0/1/0/all/0/1\">Pedro Ortiz Suarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanh_V/0/1/0/all/0/1\">Victor Sanh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laurencon_H/0/1/0/all/0/1\">Hugo Lauren&#xe7;on</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jernite_Y/0/1/0/all/0/1\">Yacine Jernite</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Launay_J/0/1/0/all/0/1\">Julien Launay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_M/0/1/0/all/0/1\">Margaret Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokaslan_A/0/1/0/all/0/1\">Aaron Gokaslan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simhi_A/0/1/0/all/0/1\">Adi Simhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soroa_A/0/1/0/all/0/1\">Aitor Soroa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aji_A/0/1/0/all/0/1\">Alham Fikri Aji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alfassy_A/0/1/0/all/0/1\">Amit Alfassy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rogers_A/0/1/0/all/0/1\">Anna Rogers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nitzav_A/0/1/0/all/0/1\">Ariel Kreisberg Nitzav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Canwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mou_C/0/1/0/all/0/1\">Chenghao Mou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emezue_C/0/1/0/all/0/1\">Chris Emezue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klamm_C/0/1/0/all/0/1\">Christopher Klamm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leong_C/0/1/0/all/0/1\">Colin Leong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strien_D/0/1/0/all/0/1\">Daniel van Strien</a>, et al. (344 additional authors not shown)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DiaASQ : A Benchmark of Conversational Aspect-based Sentiment Quadruple Analysis. (arXiv:2211.05705v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.05705","description":"<p>The rapid development of aspect-based sentiment analysis (ABSA) within recent\ndecades shows great potential for real-world society. The current ABSA works,\nhowever, are mostly limited to the scenario of a single text piece, leaving the\nstudy in dialogue contexts unexplored. In this work, we introduce a novel task\nof conversational aspect-based sentiment quadruple analysis, namely DiaASQ,\naiming to detect the sentiment quadruple of target-aspect-opinion-sentiment in\na dialogue. DiaASQ bridges the gap between fine-grained sentiment analysis and\nconversational opinion mining. We manually construct a large-scale high-quality\nDiaASQ dataset in both Chinese and English languages. We deliberately develop a\nneural model to benchmark the task, which advances in effectively performing\nend-to-end quadruple prediction, and manages to incorporate rich\ndialogue-specific and discourse feature representations for better\ncross-utterance quadruple extraction. We finally point out several potential\nfuture works to facilitate the follow-up research of this new task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bobo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Fei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinsong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shengqiong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jingye Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yijiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_L/0/1/0/all/0/1\">Lizi Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_D/0/1/0/all/0/1\">Donghong Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DualNER: A Dual-Teaching framework for Zero-shot Cross-lingual Named Entity Recognition. (arXiv:2211.08104v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.08104","description":"<p>We present DualNER, a simple and effective framework to make full use of both\nannotated source language corpus and unlabeled target language text for\nzero-shot cross-lingual named entity recognition (NER). In particular, we\ncombine two complementary learning paradigms of NER, i.e., sequence labeling\nand span prediction, into a unified multi-task framework. After obtaining a\nsufficient NER model trained on the source data, we further train it on the\ntarget data in a {\\it dual-teaching} manner, in which the pseudo-labels for one\ntask are constructed from the prediction of the other task. Moreover, based on\nthe span prediction, an entity-aware regularization is proposed to enhance the\nintrinsic cross-lingual alignment between the same entities in different\nlanguages. Experiments and analysis demonstrate the effectiveness of our\nDualNER. Code is available at https://github.com/lemon0830/dualNER.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jiali Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yufan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yongjing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Binghuai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yunbo Cao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GNN-SL: Sequence Labeling Based on Nearest Examples via GNN. (arXiv:2212.02017v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.02017","description":"<p>To better handle long-tail cases in the sequence labeling (SL) task, in this\nwork, we introduce graph neural networks sequence labeling (GNN-SL), which\naugments the vanilla SL model output with similar tagging examples retrieved\nfrom the whole training set. Since not all the retrieved tagging examples\nbenefit the model prediction, we construct a heterogeneous graph, and leverage\ngraph neural networks (GNNs) to transfer information between the retrieved\ntagging examples and the input word sequence. The augmented node which\naggregates information from neighbors is used to do prediction. This strategy\nenables the model to directly acquire similar tagging examples and improves the\ngeneral quality of predictions. We conduct a variety of experiments on three\ntypical sequence labeling tasks: Named Entity Recognition (NER), Part of Speech\nTagging (POS), and Chinese Word Segmentation (CWS) to show the significant\nperformance of our GNN-SL. Notably, GNN-SL achieves SOTA results of 96.9 (+0.2)\non PKU, 98.3 (+0.4) on CITYU, 98.5 (+0.2) on MSR, and 96.9 (+0.2) on AS for the\nCWS task, and results comparable to SOTA performances on NER datasets, and POS\ndatasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yuxian Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_R/0/1/0/all/0/1\">Rongbin Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_L/0/1/0/all/0/1\">Lingjuan Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoyin Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards human-compatible autonomous car: A study of non-verbal Turing test in automated driving with affective transition modelling. (arXiv:2212.02908v3 [cs.HC] UPDATED)","link":"http://arxiv.org/abs/2212.02908","description":"<p>Autonomous cars are indispensable when humans go further down the hands-free\nroute. Although existing literature highlights that the acceptance of the\nautonomous car will increase if it drives in a human-like manner, sparse\nresearch offers the naturalistic experience from a passenger's seat perspective\nto examine the human likeness of current autonomous cars. The present study\ntested whether the AI driver could create a human-like ride experience for\npassengers based on 69 participants' feedback in a real-road scenario. We\ndesigned a ride experience-based version of the non-verbal Turing test for\nautomated driving. Participants rode in autonomous cars (driven by either human\nor AI drivers) as a passenger and judged whether the driver was human or AI.\nThe AI driver failed to pass our test because passengers detected the AI driver\nabove chance. In contrast, when the human driver drove the car, the passengers'\njudgement was around chance. We further investigated how human passengers\nascribe humanness in our test. Based on Lewin's field theory, we advanced a\ncomputational model combining signal detection theory with pre-trained language\nmodels to predict passengers' humanness rating behaviour. We employed affective\ntransition between pre-study baseline emotions and corresponding post-stage\nemotions as the signal strength of our model. Results showed that the\npassengers' ascription of humanness would increase with the greater affective\ntransition. Our study suggested an important role of affective transition in\npassengers' ascription of humanness, which might become a future direction for\nautonomous driving.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhaoning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Q/0/1/0/all/0/1\">Qiaoli Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhengming Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Anqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Haiyan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Miner Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kai Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ku_Y/0/1/0/all/0/1\">Yixuan Ku</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Knowledge Augmentation to Multi-tasking: Towards Human-like Dialogue Systems. (arXiv:2212.03279v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2212.03279","description":"<p>The goal of building dialogue agents that can converse with humans naturally\nhas been a long-standing dream of researchers since the early days of\nartificial intelligence. The well-known Turing Test proposed to judge the\nultimate validity of an artificial intelligence agent on the\nindistinguishability of its dialogues from humans'. It should come as no\nsurprise that human-level dialogue systems are very challenging to build. But,\nwhile early effort on rule-based systems found limited success, the emergence\nof deep learning enabled great advance on this topic.\n</p>\n<p>In this thesis, we focus on methods that address the numerous issues that\nhave been imposing the gap between artificial conversational agents and\nhuman-level interlocutors. These methods were proposed and experimented with in\nways that were inspired by general state-of-the-art AI methodologies. But they\nalso targeted the characteristics that dialogue systems possess.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Young_T/0/1/0/all/0/1\">Tom Young</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Talking About Large Language Models. (arXiv:2212.03551v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.03551","description":"<p>Thanks to rapid progress in artificial intelligence, we have entered an era\nwhen technology and philosophy intersect in interesting ways. Sitting squarely\nat the centre of this intersection are large language models (LLMs). The more\nadept LLMs become at mimicking human language, the more vulnerable we become to\nanthropomorphism, to seeing the systems in which they are embedded as more\nhuman-like than they really are. This trend is amplified by the natural\ntendency to use philosophically loaded terms, such as \"knows\", \"believes\", and\n\"thinks\", when describing these systems. To mitigate this trend, this paper\nadvocates the practice of repeatedly stepping back to remind ourselves of how\nLLMs, and the systems of which they form a part, actually work. The hope is\nthat increased scientific precision will encourage more philosophical nuance in\nthe discourse around artificial intelligence, both within the field and in the\npublic sphere.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shanahan_M/0/1/0/all/0/1\">Murray Shanahan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2022-12-12T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","dc":"http://purl.org/dc/elements/1.1/"}}]}]}