{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-07-18T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"An empirical study of using radiology reports and images to improve ICU mortality prediction. (arXiv:2307.07513v1 [cs.AI])","link":"http://arxiv.org/abs/2307.07513","description":"<p>Background: The predictive Intensive Care Unit (ICU) scoring system plays an\nimportant role in ICU management because it predicts important outcomes,\nespecially mortality. Many scoring systems have been developed and used in the\nICU. These scoring systems are primarily based on the structured clinical data\nin the electronic health record (EHR), which may suffer the loss of important\nclinical information in the narratives and images. Methods: In this work, we\nbuild a deep learning based survival prediction model with multi-modality data\nto predict ICU mortality. Four sets of features are investigated: (1)\nphysiological measurements of Simplified Acute Physiology Score (SAPS) II, (2)\ncommon thorax diseases pre-defined by radiologists, (3) BERT-based text\nrepresentations, and (4) chest X-ray image features. We use the Medical\nInformation Mart for Intensive Care IV (MIMIC-IV) dataset to evaluate the\nproposed model. Results: Our model achieves the average C-index of 0.7829 (95%\nconfidence interval, 0.7620-0.8038), which substantially exceeds that of the\nbaseline with SAPS-II features (0.7470 (0.7263-0.7676)). Ablation studies\nfurther demonstrate the contributions of pre-defined labels (2.00%), text\nfeatures (2.44%), and image features (2.82%).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Mingquan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Song Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Ying Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Lihui Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yifan Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Voting-based Multimodal Automatic Deception Detection. (arXiv:2307.07516v1 [cs.LG])","link":"http://arxiv.org/abs/2307.07516","description":"<p>Automatic Deception Detection has been a hot research topic for a long time,\nusing machine learning and deep learning to automatically detect deception,\nbrings new light to this old field. In this paper, we proposed a voting-based\nmethod for automatic deception detection from videos using audio, visual and\nlexical features. Experiments were done on two datasets, the Real-life trial\ndataset by Michigan University and the Miami University deception detection\ndataset. Video samples were split into frames of images, audio, and\nmanuscripts. Our Voting-based Multimodal proposed solution consists of three\nmodels. The first model is CNN for detecting deception from images, the second\nmodel is Support Vector Machine (SVM) on Mel spectrograms for detecting\ndeception from audio and the third model is Word2Vec on Support Vector Machine\n(SVM) for detecting deception from manuscripts. Our proposed solution\noutperforms state of the art. Best results achieved on images, audio and text\nwere 97%, 96%, 92% respectively on Real-Life Trial Dataset, and 97%, 82%, 73%\non video, audio and text respectively on Miami University Deception Detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Touma_L/0/1/0/all/0/1\">Lana Touma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horani_M/0/1/0/all/0/1\">Mohammad Al Horani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tailouni_M/0/1/0/all/0/1\">Manar Tailouni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dahabiah_A/0/1/0/all/0/1\">Anas Dahabiah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jallad_K/0/1/0/all/0/1\">Khloud Al Jallad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CephGPT-4: An Interactive Multimodal Cephalometric Measurement and Diagnostic System with Visual Large Language Model. (arXiv:2307.07518v1 [cs.AI])","link":"http://arxiv.org/abs/2307.07518","description":"<p>Large-scale multimodal language models (LMMs) have achieved remarkable\nsuccess in general domains. However, the exploration of diagnostic language\nmodels based on multimodal cephalometric medical data remains limited. In this\npaper, we propose a novel multimodal cephalometric analysis and diagnostic\ndialogue model. Firstly, a multimodal orthodontic medical dataset is\nconstructed, comprising cephalometric images and doctor-patient dialogue data,\nwith automatic analysis of cephalometric landmarks using U-net and generation\nof diagnostic reports. Then, the cephalometric dataset and generated diagnostic\nreports are separately fine-tuned on Minigpt-4 and VisualGLM. Results\ndemonstrate that the CephGPT-4 model exhibits excellent performance and has the\npotential to revolutionize orthodontic measurement and diagnostic applications.\nThese innovations hold revolutionary application potential in the field of\northodontics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Lei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jincong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dian Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Translating Latin with Artificial Intelligence. (arXiv:2307.07520v1 [math.HO])","link":"http://arxiv.org/abs/2307.07520","description":"<p>The major hindrance in the study of earlier scientific literature is the\navailability of Latin translations into modern languages. This is particular\ntrue for the works of Euler who authored about 850 manuscripts and wrote a\nthousand letters and received back almost two thousand more. The translation of\nmany of these manuscripts, books and letters have been published in various\nsources over the last two centuries, but many more have not yet appeared.\nFortunately, nowadays, the artificial intelligence AI translation can be used\nto circumvent the challenges of translating such substantial number of texts.\nTo validate this tool, benchmark tests have been performed to compare the\nperformance of two popular AI translating algorithms, namely Google Translate\nand ChatGPT. Since it was found that ChatGPT performed better on these tests,\nthis translating support was then used on an excerpt of a 1739 letter from\nJohann Bernoulli to Euler, where he notifies that he was sending to Euler the\nfirst part of his manuscript Hydraulica. The findings highlight ChatGPT as a\nvaluable translation tool, catering not only to general Latin practitioners but\nalso proving beneficial for specialized Latin translators.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/math/1/au:+Bistafa_S/0/1/0/all/0/1\">Sylvio R. Bistafa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PapagAI:Automated Feedback for Reflective Essays. (arXiv:2307.07523v1 [cs.AI])","link":"http://arxiv.org/abs/2307.07523","description":"<p>Written reflective practice is a regular exercise pre-service teachers\nperform during their higher education. Usually, their lecturers are expected to\nprovide individual feedback, which can be a challenging task to perform on a\nregular basis. In this paper, we present the first open-source automated\nfeedback tool based on didactic theory and implemented as a hybrid AI system.\nWe describe the components and discuss the advantages and disadvantages of our\nsystem compared to the state-of-art generative large language models. The main\nobjective of our work is to enable better learning outcomes for students and to\ncomplement the teaching activities of lecturers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Solopova_V/0/1/0/all/0/1\">Veronika Solopova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gruszczynski_A/0/1/0/all/0/1\">Adrian Gruszczynski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rostom_E/0/1/0/all/0/1\">Eiad Rostom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cremer_F/0/1/0/all/0/1\">Fritz Cremer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witte_S/0/1/0/all/0/1\">Sascha Witte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chengming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plossl_F/0/1/0/all/0/1\">Fernando Ramos L&#xf3;pez Lea Pl&#xf6;&#xdf;l</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_F/0/1/0/all/0/1\">Florian Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romeike_R/0/1/0/all/0/1\">Ralf Romeike</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glaser_Zikuda_M/0/1/0/all/0/1\">Michaela Gl&#xe4;ser-Zikuda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benzmuller_C/0/1/0/all/0/1\">Christoph Benzm&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landgraf_T/0/1/0/all/0/1\">Tim Landgraf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Dialogue System for Assessing Activities of Daily Living: Improving Consistency with Grounded Knowledge. (arXiv:2307.07544v1 [cs.CL])","link":"http://arxiv.org/abs/2307.07544","description":"<p>In healthcare, the ability to care for oneself is reflected in the\n\"Activities of Daily Living (ADL),\" which serve as a measure of functional\nability (functioning). A lack of functioning may lead to poor living conditions\nrequiring personal care and assistance. To accurately identify those in need of\nsupport, assistance programs continuously evaluate participants' functioning\nacross various domains. However, the assessment process may encounter\nconsistency issues when multiple assessors with varying levels of expertise are\ninvolved. Novice assessors, in particular, may lack the necessary preparation\nfor real-world interactions with participants. To address this issue, we\ndeveloped a dialogue system that simulates interactions between assessors and\nindividuals of varying functioning in a natural and reproducible way. The\ndialogue system consists of two major modules, one for natural language\nunderstanding (NLU) and one for natural language generation (NLG),\nrespectively. In order to generate responses consistent with the underlying\nknowledge base, the dialogue system requires both an understanding of the\nuser's query and of biographical details of an individual being simulated. To\nfulfill this requirement, we experimented with query classification and\ngenerated responses based on those biographical details using some recently\nreleased InstructGPT-like models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sheng_Z/0/1/0/all/0/1\">Zhecheng Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finzel_R/0/1/0/all/0/1\">Raymond Finzel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucke_M/0/1/0/all/0/1\">Michael Lucke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dufresne_S/0/1/0/all/0/1\">Sheena Dufresne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gini_M/0/1/0/all/0/1\">Maria Gini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pakhomov_S/0/1/0/all/0/1\">Serguei Pakhomov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Emotional and Mental Well-Being of Individuals with Long COVID Through Twitter Analysis. (arXiv:2307.07558v1 [cs.SI])","link":"http://arxiv.org/abs/2307.07558","description":"<p>The COVID-19 pandemic has led to the emergence of Long COVID, a cluster of\nsymptoms that persist after infection. Long COVID patients may also experience\nmental health challenges, making it essential to understand individuals'\nemotional and mental well-being. This study aims to gain a deeper understanding\nof Long COVID individuals' emotional and mental well-being, identify the topics\nthat most concern them, and explore potential correlations between their\nemotions and social media activity. Specifically, we classify tweets into four\ncategories based on the content, detect the presence of six basic emotions, and\nextract prevalent topics. Our analyses reveal that negative emotions dominated\nthroughout the study period, with two peaks during critical periods, such as\nthe outbreak of new COVID variants. The findings of this study have\nimplications for policy and measures for addressing the mental health\nchallenges of individuals with Long COVID and provide a foundation for future\nwork.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_G/0/1/0/all/0/1\">Guocheng Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Huaiyu Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_W/0/1/0/all/0/1\">Wei Quan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"QontSum: On Contrasting Salient Content for Query-focused Summarization. (arXiv:2307.07586v1 [cs.CL])","link":"http://arxiv.org/abs/2307.07586","description":"<p>Query-focused summarization (QFS) is a challenging task in natural language\nprocessing that generates summaries to address specific queries. The broader\nfield of Generative Information Retrieval (Gen-IR) aims to revolutionize\ninformation extraction from vast document corpora through generative\napproaches, encompassing Generative Document Retrieval (GDR) and Grounded\nAnswer Retrieval (GAR). This paper highlights the role of QFS in Grounded\nAnswer Generation (GAR), a key subdomain of Gen-IR that produces human-readable\nanswers in direct correspondence with queries, grounded in relevant documents.\nIn this study, we propose QontSum, a novel approach for QFS that leverages\ncontrastive learning to help the model attend to the most relevant regions of\nthe input document. We evaluate our approach on a couple of benchmark datasets\nfor QFS and demonstrate that it either outperforms existing state-of-the-art or\nexhibits a comparable performance with considerably reduced computational cost\nthrough enhancements in the fine-tuning stage, rather than relying on\nlarge-scale pre-training experiments, which is the focus of current SOTA.\nMoreover, we conducted a human study and identified improvements in the\nrelevance of generated summaries to the posed queries without compromising\nfluency. We further conduct an error analysis study to understand our model's\nlimitations and propose avenues for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sotudeh_S/0/1/0/all/0/1\">Sajad Sotudeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goharian_N/0/1/0/all/0/1\">Nazli Goharian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Generalizable Detection of Urgency of Discussion Forum Posts. (arXiv:2307.07614v1 [cs.LG])","link":"http://arxiv.org/abs/2307.07614","description":"<p>Students who take an online course, such as a MOOC, use the course's\ndiscussion forum to ask questions or reach out to instructors when encountering\nan issue. However, reading and responding to students' questions is difficult\nto scale because of the time needed to consider each message. As a result,\ncritical issues may be left unresolved, and students may lose the motivation to\ncontinue in the course. To help address this problem, we build predictive\nmodels that automatically determine the urgency of each forum post, so that\nthese posts can be brought to instructors' attention. This paper goes beyond\nprevious work by predicting not just a binary decision cut-off but a post's\nlevel of urgency on a 7-point scale. First, we train and cross-validate several\nmodels on an original data set of 3,503 posts from MOOCs at University of\nPennsylvania. Second, to determine the generalizability of our models, we test\ntheir performance on a separate, previously published data set of 29,604 posts\nfrom MOOCs at Stanford University. While the previous work on post urgency used\nonly one data set, we evaluated the prediction across different data sets and\ncourses. The best-performing model was a support vector regressor trained on\nthe Universal Sentence Encoder embeddings of the posts, achieving an RMSE of\n1.1 on the training set and 1.4 on the test set. Understanding the urgency of\nforum posts enables instructors to focus their time more effectively and, as a\nresult, better support student learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Svabensky_V/0/1/0/all/0/1\">Valdemar &#x160;v&#xe1;bensk&#xfd;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baker_R/0/1/0/all/0/1\">Ryan S. Baker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zambrano_A/0/1/0/all/0/1\">Andr&#xe9;s Zambrano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yishan Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slater_S/0/1/0/all/0/1\">Stefan Slater</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Othering and low prestige framing of immigrant cuisines in US restaurant reviews and large language models. (arXiv:2307.07645v1 [cs.CL])","link":"http://arxiv.org/abs/2307.07645","description":"<p>Identifying and understanding implicit attitudes toward food can help efforts\nto mitigate social prejudice due to food's pervasive role as a marker of\ncultural and ethnic identity. Stereotypes about food are a form of\nmicroaggression that contribute to harmful public discourse that may in turn\nperpetuate prejudice toward ethnic groups and negatively impact economic\noutcomes for restaurants. Through careful linguistic analyses, we evaluate\nsocial theories about attitudes toward immigrant cuisine in a large-scale study\nof framing differences in 2.1M English language Yelp reviews of restaurants in\n14 US states. Controlling for factors such as restaurant price and neighborhood\nracial diversity, we find that immigrant cuisines are more likely to be framed\nin objectifying and othering terms of authenticity (e.g., authentic,\ntraditional), exoticism (e.g., exotic, different), and prototypicality (e.g.,\ntypical, usual), but that non-Western immigrant cuisines (e.g., Indian,\nMexican) receive more othering than European cuisines (e.g., French, Italian).\nWe further find that non-Western immigrant cuisines are framed less positively\nand as lower status, being evaluated in terms of affordability and hygiene.\nFinally, we show that reviews generated by large language models (LLMs)\nreproduce many of the same framing tendencies. Our results empirically\ncorroborate social theories of taste and gastronomic stereotyping, and reveal\nlinguistic processes by which such attitudes are reified.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yiwei Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gligoric_K/0/1/0/all/0/1\">Kristina Gligori&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1\">Dan Jurafsky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Single and Multi-Speaker Cloned Voice Detection: From Perceptual to Learned Features. (arXiv:2307.07683v1 [cs.SD])","link":"http://arxiv.org/abs/2307.07683","description":"<p>Synthetic-voice cloning technologies have seen significant advances in recent\nyears, giving rise to a range of potential harms. From small- and large-scale\nfinancial fraud to disinformation campaigns, the need for reliable methods to\ndifferentiate real and synthesized voices is imperative. We describe three\ntechniques for differentiating a real from a cloned voice designed to\nimpersonate a specific person. These three approaches differ in their feature\nextraction stage with low-dimensional perceptual features offering high\ninterpretability but lower accuracy, to generic spectral features, and\nend-to-end learned features offering less interpretability but higher accuracy.\nWe show the efficacy of these approaches when trained on a single speaker's\nvoice and when trained on multiple voices. The learned features consistently\nyield an equal error rate between $0\\%$ and $4\\%$, and are reasonably robust to\nadversarial laundering.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Barrington_S/0/1/0/all/0/1\">Sarah Barrington</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barua_R/0/1/0/all/0/1\">Romit Barua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koorma_G/0/1/0/all/0/1\">Gautham Koorma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farid_H/0/1/0/all/0/1\">Hany Farid</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text. (arXiv:2307.07696v1 [cs.CL])","link":"http://arxiv.org/abs/2307.07696","description":"<p>While large language models (LLMs), such as GPT-3, appear to be robust and\ngeneral, their reasoning ability is not at a level to compete with the best\nmodels trained for specific natural language reasoning problems. In this study,\nwe observe that a large language model can serve as a highly effective few-shot\nsemantic parser. It can convert natural language sentences into a logical form\nthat serves as input for answer set programs, a logic-based declarative\nknowledge representation formalism. The combination results in a robust and\ngeneral system that can handle multiple question-answering tasks without\nrequiring retraining for each new task. It only needs a few examples to guide\nthe LLM's adaptation to a specific task, along with reusable ASP knowledge\nmodules that can be applied to multiple tasks. We demonstrate that this method\nachieves state-of-the-art performance on several NLP benchmarks, including\nbAbI, StepGame, CLUTRR, and gSCAN. Additionally, it successfully tackles robot\nplanning tasks that an LLM alone fails to solve.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishay_A/0/1/0/all/0/1\">Adam Ishay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Joohyung Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Think-on-Graph: Deep and Responsible Reasoning of Large Language Model with Knowledge Graph. (arXiv:2307.07697v1 [cs.CL])","link":"http://arxiv.org/abs/2307.07697","description":"<p>Large language models (LLMs) have made significant strides in various tasks,\nyet they often struggle with complex reasoning and exhibit poor performance in\nscenarios where knowledge traceability, timeliness, and accuracy are crucial.\nTo address these limitations, we present Think-on-Graph (ToG), a novel\nframework that leverages knowledge graphs to enhance LLMs' ability for deep and\nresponsible reasoning. By employing ToG, we can identify entities relevant to a\ngiven question and conduct exploration and reasoning to retrieve related\ntriples from an external knowledge database. This iterative procedure generates\nmultiple reasoning pathways consisting of sequentially connected triplets until\nsufficient information is gathered to answer the question or the maximum depth\nis reached. Through experiments on complex multi-hop reasoning\nquestion-answering tasks, we demonstrate that ToG outperforms existing methods,\neffectively addressing the aforementioned limitations of LLMs without incurring\nadditional training costs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiashuo Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chengjin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1\">Lumingyuan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Saizhuo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1\">Heung-Yeung Shum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jian Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging Large Language Models to Generate Answer Set Programs. (arXiv:2307.07699v1 [cs.AI])","link":"http://arxiv.org/abs/2307.07699","description":"<p>Large language models (LLMs), such as GPT-3 and GPT-4, have demonstrated\nexceptional performance in various natural language processing tasks and have\nshown the ability to solve certain reasoning problems. However, their reasoning\ncapabilities are limited and relatively shallow, despite the application of\nvarious prompting techniques. In contrast, formal logic is adept at handling\ncomplex reasoning, but translating natural language descriptions into formal\nlogic is a challenging task that non-experts struggle with. This paper proposes\na neuro-symbolic method that combines the strengths of large language models\nand answer set programming. Specifically, we employ an LLM to transform natural\nlanguage descriptions of logic puzzles into answer set programs. We carefully\ndesign prompts for an LLM to convert natural language descriptions into answer\nset programs in a step by step manner. Surprisingly, with just a few in-context\nlearning examples, LLMs can generate reasonably complex answer set programs.\nThe majority of errors made are relatively simple and can be easily corrected\nby humans, thus enabling LLMs to effectively assist in the creation of answer\nset programs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ishay_A/0/1/0/all/0/1\">Adam Ishay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Joohyung Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CPET: Effective Parameter-Efficient Tuning for Compressed Large Language Models. (arXiv:2307.07705v1 [cs.CL])","link":"http://arxiv.org/abs/2307.07705","description":"<p>Parameter-efficient tuning (PET) has been widely explored in recent years\nbecause it tunes much fewer parameters (PET modules) than full-parameter\nfine-tuning (FT) while still stimulating sufficient knowledge from large\nlanguage models (LLMs) for downstream tasks. Moreover, when PET is employed to\nserve multiple tasks, different task-specific PET modules can be built on a\nfrozen LLM, avoiding redundant LLM deployments. Although PET significantly\nreduces the cost of tuning and deploying LLMs, its inference still suffers from\nthe computational bottleneck of LLMs. To address the above issue, we propose an\neffective PET framework based on compressed LLMs, named \"CPET\". In CPET, we\nevaluate the impact of mainstream LLM compression techniques on PET performance\nand then introduce knowledge inheritance and recovery strategies to restore the\nknowledge loss caused by these compression techniques. Our experimental results\ndemonstrate that, owing to the restoring strategies of CPET, collaborating\ntask-specific PET modules with a compressed LLM can achieve comparable\nperformance to collaborating PET modules with the original version of the\ncompressed LLM and outperform directly applying vanilla PET methods to the\ncompressed LLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Weilin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuxiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Political Sentiment Analysis of Persian Tweets Using CNN-LSTM Model. (arXiv:2307.07740v1 [cs.CL])","link":"http://arxiv.org/abs/2307.07740","description":"<p>Sentiment analysis is the process of identifying and categorizing people's\nemotions or opinions regarding various topics. The analysis of Twitter\nsentiment has become an increasingly popular topic in recent years. In this\npaper, we present several machine learning and a deep learning model to\nanalysis sentiment of Persian political tweets. Our analysis was conducted\nusing Bag of Words and ParsBERT for word representation. We applied Gaussian\nNaive Bayes, Gradient Boosting, Logistic Regression, Decision Trees, Random\nForests, as well as a combination of CNN and LSTM to classify the polarities of\ntweets. The results of this study indicate that deep learning with ParsBERT\nembedding performs better than machine learning. The CNN-LSTM model had the\nhighest classification accuracy with 89 percent on the first dataset with three\nclasses and 71 percent on the second dataset with seven classes. Due to the\ncomplexity of Persian, it was a difficult task to achieve this level of\nefficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Mohammad Dehghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yazdanparast_Z/0/1/0/all/0/1\">Zahra Yazdanparast</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Opinion mining using Double Channel CNN for Recommender System. (arXiv:2307.07798v1 [cs.IR])","link":"http://arxiv.org/abs/2307.07798","description":"<p>Much unstructured data has been produced with the growth of the Internet and\nsocial media. A significant volume of textual data includes users' opinions\nabout products in online stores and social media. By exploring and categorizing\nthem, helpful information can be acquired, including customer satisfaction,\nuser feedback about a particular event, predicting the sale of a specific\nproduct, and other similar cases. In this paper, we present an approach for\nsentiment analysis with a deep learning model and use it to recommend products.\nA two-channel convolutional neural network model has been used for opinion\nmining, which has five layers and extracts essential features from the data. We\nincreased the number of comments by applying the SMOTE algorithm to the initial\ndataset and balanced the data. Then we proceed to cluster the aspects. We also\nassign a weight to each cluster using tensor decomposition algorithms that\nimprove the recommender system's performance. Our proposed method has reached\n91.6% accuracy, significantly improved compared to previous aspect-based\napproaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sayyadpour_M/0/1/0/all/0/1\">Minoo Sayyadpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nazarizadeh_A/0/1/0/all/0/1\">Ali Nazarizadeh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformers are Universal Predictors. (arXiv:2307.07843v1 [cs.LG])","link":"http://arxiv.org/abs/2307.07843","description":"<p>We find limits to the Transformer architecture for language modeling and show\nit has a universal prediction property in an information-theoretic sense. We\nfurther analyze performance in non-asymptotic data regimes to understand the\nrole of various components of the Transformer architecture, especially in the\ncontext of data-efficient training. We validate our theoretical analysis with\nexperiments on both synthetic and real datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1\">Sourya Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choraria_M/0/1/0/all/0/1\">Moulik Choraria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varshney_L/0/1/0/all/0/1\">Lav R. Varshney</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge. (arXiv:2307.07851v1 [cs.CL])","link":"http://arxiv.org/abs/2307.07851","description":"<p>Generic sentence embeddings provide a coarse-grained approximation of\nsemantic textual similarity but ignore specific aspects that make texts\nsimilar. Conversely, aspect-based sentence embeddings provide similarities\nbetween texts based on certain predefined aspects. Thus, similarity predictions\nof texts are more targeted to specific requirements and more easily\nexplainable. In this paper, we present AspectCSE, an approach for aspect-based\ncontrastive learning of sentence embeddings. Results indicate that AspectCSE\nachieves an average improvement of 3.97% on information retrieval tasks across\nmultiple aspects compared to the previous best results. We also propose using\nWikidata knowledge graph properties to train models of multi-aspect sentence\nembeddings in which multiple specific aspects are simultaneously considered\nduring similarity predictions. We demonstrate that multi-aspect embeddings\noutperform single-aspect embeddings on aspect-specific information retrieval\ntasks. Finally, we examine the aspect-based sentence embedding space and\ndemonstrate that embeddings of semantically similar aspect labels are often\nclose, even without explicit similarity training between different aspect\nlabels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schopf_T/0/1/0/all/0/1\">Tim Schopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerber_E/0/1/0/all/0/1\">Emanuel Gerber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ostendorff_M/0/1/0/all/0/1\">Malte Ostendorff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matthes_F/0/1/0/all/0/1\">Florian Matthes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CIDER: Context sensitive sentiment analysis for short-form text. (arXiv:2307.07864v1 [cs.CL])","link":"http://arxiv.org/abs/2307.07864","description":"<p>Researchers commonly perform sentiment analysis on large collections of short\ntexts like tweets, Reddit posts or newspaper headlines that are all focused on\na specific topic, theme or event. Usually, general purpose sentiment analysis\nmethods are used which perform well on average but miss the variation in\nmeaning that happens across different contexts, for example, the word \"active\"\nhas a very different intention and valence in the phrase \"active lifestyle\"\nversus \"active volcano\". This work presents a new approach, CIDER (Context\nInformed Dictionary and sEntiment Reasoner), which performs context sensitive\nsentiment analysis, where the valence of sentiment laden terms is inferred from\nthe whole corpus before being used to score the individual texts. In this paper\nwe detail the CIDER algorithm and demonstrate that it outperforms\nstate-of-the-art generalist sentiment analysis on a large collection of tweets\nabout the weather. We have made our implementation of CIDER available as a\npython package: https://pypi.org/project/ciderpolarity/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Young_J/0/1/0/all/0/1\">James C. Young</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arthur_R/0/1/0/all/0/1\">Rudy Arthur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_H/0/1/0/all/0/1\">Hywel T.P. Williams</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models as Superpositions of Cultural Perspectives. (arXiv:2307.07870v1 [cs.CL])","link":"http://arxiv.org/abs/2307.07870","description":"<p>Large Language Models (LLMs) are often misleadingly recognized as having a\npersonality or a set of values. We argue that an LLM can be seen as a\nsuperposition of perspectives with different values and personality traits.\nLLMs exhibit context-dependent values and personality traits that change based\non the induced perspective (as opposed to humans, who tend to have more\ncoherent values and personality traits across contexts). We introduce the\nconcept of perspective controllability, which refers to a model's affordance to\nadopt various perspectives with differing values and personality traits. In our\nexperiments, we use questionnaires from psychology (PVQ, VSM, IPIP) to study\nhow exhibited values and personality traits change based on different\nperspectives. Through qualitative experiments, we show that LLMs express\ndifferent values when those are (implicitly or explicitly) implied in the\nprompt, and that LLMs express different values even when those are not\nobviously implied (demonstrating their context-dependent nature). We then\nconduct quantitative experiments to study the controllability of different\nmodels (GPT-4, GPT-3.5, OpenAssistant, StableVicuna, StableLM), the\neffectiveness of various methods for inducing perspectives, and the smoothness\nof the models' drivability. We conclude by examining the broader implications\nof our work and outline a variety of associated scientific questions. The\nproject website is available at\nhttps://sites.google.com/view/llm-superpositions .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kovac_G/0/1/0/all/0/1\">Grgur Kova&#x10d;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sawayama_M/0/1/0/all/0/1\">Masataka Sawayama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portelas_R/0/1/0/all/0/1\">R&#xe9;my Portelas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colas_C/0/1/0/all/0/1\">C&#xe9;dric Colas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dominey_P/0/1/0/all/0/1\">Peter Ford Dominey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1\">Pierre-Yves Oudeyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is Prompt-Based Finetuning Always Better than Vanilla Finetuning? Insights from Cross-Lingual Language Understanding. (arXiv:2307.07880v1 [cs.CL])","link":"http://arxiv.org/abs/2307.07880","description":"<p>Multilingual pretrained language models (MPLMs) have demonstrated substantial\nperformance improvements in zero-shot cross-lingual transfer across various\nnatural language understanding tasks by finetuning MPLMs on task-specific\nlabelled data of a source language (e.g. English) and evaluating on a wide\nrange of target languages. Recent studies show that prompt-based finetuning\nsurpasses regular finetuning in few-shot scenarios. However, the exploration of\nprompt-based learning in multilingual tasks remains limited. In this study, we\npropose the ProFiT pipeline to investigate the cross-lingual capabilities of\nPrompt-based Finetuning. We conduct comprehensive experiments on diverse\ncross-lingual language understanding tasks (sentiment classification,\nparaphrase identification, and natural language inference) and empirically\nanalyze the variation trends of prompt-based finetuning performance in\ncross-lingual transfer across different few-shot and full-data settings. Our\nresults reveal the effectiveness and versatility of prompt-based finetuning in\ncross-lingual language understanding. Our findings indicate that prompt-based\nfinetuning outperforms vanilla finetuning in full-data scenarios and exhibits\ngreater advantages in few-shot scenarios, with different performance patterns\ndependent on task types. Additionally, we analyze underlying factors such as\nlanguage similarity and pretraining data size that impact the cross-lingual\nperformance of prompt-based finetuning. Overall, our work provides valuable\ninsights into the cross-lingual prowess of prompt-based finetuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_B/0/1/0/all/0/1\">Bolei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_E/0/1/0/all/0/1\">Ercong Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmid_H/0/1/0/all/0/1\">Helmut Schmid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-shot NLG evaluation through Pairware Comparisons with LLMs. (arXiv:2307.07889v1 [cs.CL])","link":"http://arxiv.org/abs/2307.07889","description":"<p>Evaluating Natural Language Generation (NLG) outputs is crucial but laborious\nand expensive. While various automatic NLG assessment methods have been\nproposed, they often are quite task-specific and have to be engineered with a\nparticular domain and attribute in mind. In this work, we propose a robust\nzero-shot approach to NLG evaluation using pairwise comparative judgment with\nopen-source Large Language Models (LLMs). The motivation for this approach is\nthat even as humans, it is easier to determine which of two options are better,\nthan it is to independently objectively score each option. We use this insight\nand leverage the emergent abilities of LLMs, where we probe FlanT5 to determine\nwhich of two candidate responses is better, rather than assigning absolute\nscores. Our results demonstrate that comparative assessment is a more effective\napproach than absolute scoring, enabling smaller open-source LLMs to achieve\ncomparable performance to larger public access APIs. We evaluate systems on\nboth summary evaluation and dialogue response generation, and show that\nopensource LLMs can lead to good correlations with human scores for a range of\ndifferent attributes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liusie_A/0/1/0/all/0/1\">Adian Liusie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manakul_P/0/1/0/all/0/1\">Potsawee Manakul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gales_M/0/1/0/all/0/1\">Mark J. F. Gales</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Communicative Agents for Software Development. (arXiv:2307.07924v1 [cs.SE])","link":"http://arxiv.org/abs/2307.07924","description":"<p>Software engineering is a domain characterized by intricate decision-making\nprocesses, often relying on nuanced intuition and consultation. Recent\nadvancements in deep learning have started to revolutionize software\nengineering practices through elaborate designs implemented at various stages\nof software development. In this paper, we present an innovative paradigm that\nleverages large language models (LLMs) throughout the entire software\ndevelopment process, streamlining and unifying key processes through natural\nlanguage communication, thereby eliminating the need for specialized models at\neach phase. At the core of this paradigm lies ChatDev, a virtual chat-powered\nsoftware development company that mirrors the established waterfall model,\nmeticulously dividing the development process into four distinct chronological\nstages: designing, coding, testing, and documenting. Each stage engages a team\nof agents, such as programmers, code reviewers, and test engineers, fostering\ncollaborative dialogue and facilitating a seamless workflow. The chat chain\nacts as a facilitator, breaking down each stage into atomic subtasks. This\nenables dual roles, allowing for proposing and validating solutions through\ncontext-aware communication, leading to efficient resolution of specific\nsubtasks. The instrumental analysis of ChatDev highlights its remarkable\nefficacy in software generation, enabling the completion of the entire software\ndevelopment process in under seven minutes at a cost of less than one dollar.\nIt not only identifies and alleviates potential vulnerabilities but also\nrectifies potential hallucinations while maintaining commendable efficiency and\ncost-effectiveness. The potential of ChatDev unveils fresh possibilities for\nintegrating LLMs into the realm of software development.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cong_X/0/1/0/all/0/1\">Xin Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weize Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yusheng Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Juyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GeoGPT: Understanding and Processing Geospatial Tasks through An Autonomous GPT. (arXiv:2307.07930v1 [cs.CL])","link":"http://arxiv.org/abs/2307.07930","description":"<p>Decision-makers in GIS need to combine a series of spatial algorithms and\noperations to solve geospatial tasks. For example, in the task of facility\nsiting, the Buffer tool is usually first used to locate areas close or away\nfrom some specific entities; then, the Intersect or Erase tool is used to\nselect candidate areas satisfied multiple requirements. Though professionals\ncan easily understand and solve these geospatial tasks by sequentially\nutilizing relevant tools, it is difficult for non-professionals to handle these\nproblems. Recently, Generative Pre-trained Transformer (e.g., ChatGPT) presents\nstrong performance in semantic understanding and reasoning. Especially, AutoGPT\ncan further extend the capabilities of large language models (LLMs) by\nautomatically reasoning and calling externally defined tools. Inspired by these\nstudies, we attempt to lower the threshold of non-professional users to solve\ngeospatial tasks by integrating the semantic understanding ability inherent in\nLLMs with mature tools within the GIS community. Specifically, we develop a new\nframework called GeoGPT that can conduct geospatial data collection,\nprocessing, and analysis in an autonomous manner with the instruction of only\nnatural language. In other words, GeoGPT is used to understand the demands of\nnon-professional users merely based on input natural language descriptions, and\nthen think, plan, and execute defined GIS tools to output final effective\nresults. Several cases including geospatial data crawling, spatial query,\nfacility siting, and mapping validate the effectiveness of our framework.\nThough limited cases are presented in this paper, GeoGPT can be further\nextended to various tasks by equipping with more GIS tools, and we think the\nparadigm of \"foundational plus professional\" implied in GeoGPT provides an\neffective way to develop next-generation GIS in this era of large foundation\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yifan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Cheng Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shangyou Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhengting He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhao Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deduplicating and Ranking Solution Programs for Suggesting Reference Solutions. (arXiv:2307.07940v1 [cs.SE])","link":"http://arxiv.org/abs/2307.07940","description":"<p>Referring to the solution programs written by the other users is helpful for\nlearners in programming education. However, current online judge systems just\nlist all solution programs submitted by users for references, and the programs\nare sorted based on the submission date and time, execution time, or user\nrating, ignoring to what extent the program can be a reference. In addition,\nusers struggle to refer to a variety of solution approaches since there are too\nmany duplicated and near-duplicated programs. To motivate the learners to refer\nto various solutions to learn the better solution approaches, in this paper, we\npropose an approach to deduplicate and rank common solution programs in each\nprogramming problem. Based on the hypothesis that the more duplicated programs\nadopt a more common approach and can be a reference, we remove the\nnear-duplicated solution programs and rank the unique programs based on the\nduplicate count. The experiments on the solution programs submitted to a\nreal-world online judge system demonstrate that the number of programs is\nreduced by 60.20%, whereas the baseline only reduces by 29.59% after the\ndeduplication, meaning that the users only need to refer to 39.80% of programs\non average. Furthermore, our analysis shows that top-10 ranked programs cover\n29.95% of programs on average, indicating that the users can grasp 29.95% of\nsolution approaches by referring to only 10 programs. The proposed approach\nshows the potential of reducing the learners' burden of referring to too many\nsolutions and motivating them to learn a variety of better approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shirafuji_A/0/1/0/all/0/1\">Atsushi Shirafuji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanobe_Y/0/1/0/all/0/1\">Yutaka Watanobe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unifying Token and Span Level Supervisions for Few-Shot Sequence Labeling. (arXiv:2307.07946v1 [cs.CL])","link":"http://arxiv.org/abs/2307.07946","description":"<p>Few-shot sequence labeling aims to identify novel classes based on only a few\nlabeled samples. Existing methods solve the data scarcity problem mainly by\ndesigning token-level or span-level labeling models based on metric learning.\nHowever, these methods are only trained at a single granularity (i.e., either\ntoken level or span level) and have some weaknesses of the corresponding\ngranularity. In this paper, we first unify token and span level supervisions\nand propose a Consistent Dual Adaptive Prototypical (CDAP) network for few-shot\nsequence labeling. CDAP contains the token-level and span-level networks,\njointly trained at different granularities. To align the outputs of two\nnetworks, we further propose a consistent loss to enable them to learn from\neach other. During the inference phase, we propose a consistent greedy\ninference algorithm that first adjusts the predicted probability and then\ngreedily selects non-overlapping spans with maximum probability. Extensive\nexperiments show that our model achieves new state-of-the-art results on three\nbenchmark datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1\">Zifeng Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qingyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhiwei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xuemin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yunbo Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1\">Qing Gu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Model Adaptation for ASR in low-resource Indian Languages. (arXiv:2307.07948v1 [eess.AS])","link":"http://arxiv.org/abs/2307.07948","description":"<p>Automatic speech recognition (ASR) performance has improved drastically in\nrecent years, mainly enabled by self-supervised learning (SSL) based acoustic\nmodels such as wav2vec2 and large-scale multi-lingual training like Whisper. A\nhuge challenge still exists for low-resource languages where the availability\nof both audio and text is limited. This is further complicated by the presence\nof multiple dialects like in Indian languages. However, many Indian languages\ncan be grouped into the same families and share the same script and grammatical\nstructure. This is where a lot of adaptation and fine-tuning techniques can be\napplied to overcome the low-resource nature of the data by utilising\nwell-resourced similar languages.\n</p>\n<p>In such scenarios, it is important to understand the extent to which each\nmodality, like acoustics and text, is important in building a reliable ASR. It\ncould be the case that an abundance of acoustic data in a language reduces the\nneed for large text-only corpora. Or, due to the availability of various\npretrained acoustic models, the vice-versa could also be true. In this proposed\nspecial session, we encourage the community to explore these ideas with the\ndata in two low-resource Indian languages of Bengali and Bhojpuri. These\napproaches are not limited to Indian languages, the solutions are potentially\napplicable to various languages spoken around the world.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Singh_A/0/1/0/all/0/1\">Abhayjeet Singh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mehta_A/0/1/0/all/0/1\">Arjun Singh Mehta</a>, <a href=\"http://arxiv.org/find/eess/1/au:+S_A/0/1/0/all/0/1\">Ashish Khuraishi K S</a>, <a href=\"http://arxiv.org/find/eess/1/au:+G_D/0/1/0/all/0/1\">Deekshitha G</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Date_G/0/1/0/all/0/1\">Gauri Date</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nanavati_J/0/1/0/all/0/1\">Jai Nanavati</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bandekar_J/0/1/0/all/0/1\">Jesuraja Bandekar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Basumatary_K/0/1/0/all/0/1\">Karnalius Basumatary</a>, <a href=\"http://arxiv.org/find/eess/1/au:+P_K/0/1/0/all/0/1\">Karthika P</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Badiger_S/0/1/0/all/0/1\">Sandhya Badiger</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Udupa_S/0/1/0/all/0/1\">Sathvik Udupa</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kumar_S/0/1/0/all/0/1\">Saurabh Kumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Savitha/0/1/0/all/0/1\">Savitha</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ghosh_P/0/1/0/all/0/1\">Prasanta Kumar Ghosh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+V_P/0/1/0/all/0/1\">Prashanthi V</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pai_P/0/1/0/all/0/1\">Priyanka Pai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nanavati_R/0/1/0/all/0/1\">Raoul Nanavati</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Saxena_R/0/1/0/all/0/1\">Rohan Saxena</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mora_S/0/1/0/all/0/1\">Sai Praneeth Reddy Mora</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Raghavan_S/0/1/0/all/0/1\">Srinivasa Raghavan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MinT: Boosting Generalization in Mathematical Reasoning via Multi-View Fine-Tuning. (arXiv:2307.07951v1 [cs.AI])","link":"http://arxiv.org/abs/2307.07951","description":"<p>Reasoning in mathematical domains remains a significant challenge for\nrelatively small language models (LMs). Many current methods focus on\nspecializing LMs in mathematical reasoning and rely heavily on knowledge\ndistillation from powerful but inefficient large LMs (LLMs). In this work, we\nexplore a new direction that avoids over-reliance on LLM teachers, introducing\na multi-view fine-tuning method that efficiently exploits existing mathematical\nproblem datasets with diverse annotation styles. Our approach uniquely\nconsiders the various annotation formats as different \"views\" and leverages\nthem in training the model. By postpending distinct instructions to input\nquestions, models can learn to generate solutions in diverse formats in a\nflexible manner. Experimental results show that our strategy enables a LLaMA-7B\nmodel to outperform prior approaches that utilize knowledge distillation, as\nwell as carefully established baselines. Additionally, the proposed method\ngrants the models promising generalization ability across various views and\ndatasets, and the capability to learn from inaccurate or incomplete noisy data.\nWe hope our multi-view training paradigm could inspire future studies in other\nmachine reasoning domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1\">Zhenwen Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiaoman Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1\">Wenlin Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Q/0/1/0/all/0/1\">Qingkai Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey of Techniques for Optimizing Transformer Inference. (arXiv:2307.07982v1 [cs.LG])","link":"http://arxiv.org/abs/2307.07982","description":"<p>Recent years have seen a phenomenal rise in performance and applications of\ntransformer neural networks. The family of transformer networks, including\nBidirectional Encoder Representations from Transformer (BERT), Generative\nPretrained Transformer (GPT) and Vision Transformer (ViT), have shown their\neffectiveness across Natural Language Processing (NLP) and Computer Vision (CV)\ndomains. Transformer-based networks such as ChatGPT have impacted the lives of\ncommon men. However, the quest for high predictive performance has led to an\nexponential increase in transformers' memory and compute footprint. Researchers\nhave proposed techniques to optimize transformer inference at all levels of\nabstraction. This paper presents a comprehensive survey of techniques for\noptimizing the inference phase of transformer networks. We survey techniques\nsuch as knowledge distillation, pruning, quantization, neural architecture\nsearch and lightweight network design at the algorithmic level. We further\nreview hardware-level optimization techniques and the design of novel hardware\naccelerators for transformers. We summarize the quantitative results on the\nnumber of parameters/FLOPs and accuracy of several models/techniques to\nshowcase the tradeoff exercised by them. We also outline future directions in\nthis rapidly evolving field of research. We believe that this survey will\neducate both novice and seasoned researchers and also spark a plethora of\nresearch efforts in this field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chitty_Venkata_K/0/1/0/all/0/1\">Krishna Teja Chitty-Venkata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_S/0/1/0/all/0/1\">Sparsh Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emani_M/0/1/0/all/0/1\">Murali Emani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vishwanath_V/0/1/0/all/0/1\">Venkatram Vishwanath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Somani_A/0/1/0/all/0/1\">Arun K. Somani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Facilitating Multi-turn Emotional Support Conversation with Positive Emotion Elicitation: A Reinforcement Learning Approach. (arXiv:2307.07994v1 [cs.CL])","link":"http://arxiv.org/abs/2307.07994","description":"<p>Emotional support conversation (ESC) aims to provide emotional support (ES)\nto improve one's mental state. Existing works stay at fitting grounded\nresponses and responding strategies (e.g., question), which ignore the effect\non ES and lack explicit goals to guide emotional positive transition. To this\nend, we introduce a new paradigm to formalize multi-turn ESC as a process of\npositive emotion elicitation. Addressing this task requires finely adjusting\nthe elicitation intensity in ES as the conversation progresses while\nmaintaining conversational goals like coherence. In this paper, we propose\nSupporter, a mixture-of-expert-based reinforcement learning model, and well\ndesign ES and dialogue coherence rewards to guide policy's learning for\nresponding. Experiments verify the superiority of Supporter in achieving\npositive emotion elicitation during responding while maintaining conversational\ngoals including coherence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jinfeng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhuang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Neural-Symbolic Approach Towards Identifying Grammatically Correct Sentences. (arXiv:2307.08036v1 [cs.CL])","link":"http://arxiv.org/abs/2307.08036","description":"<p>Textual content around us is growing on a daily basis. Numerous articles are\nbeing written as we speak on online newspapers, blogs, or social media.\nSimilarly, recent advances in the AI field, like language models or traditional\nclassic AI approaches, are utilizing all the above to improve their learned\nrepresentation to tackle NLP challenges with human-like accuracy. It is\ncommonly accepted that it is crucial to have access to well-written text from\nvalid sources to tackle challenges like text summarization, question-answering,\nmachine translation, or even pronoun resolution. For instance, to summarize\nwell, one needs to select the most important sentences in order to concatenate\nthem to form the summary. However, what happens if we do not have access to\nwell-formed English sentences or even non-valid sentences? Despite the\nimportance of having access to well-written sentences, figuring out ways to\nvalidate them is still an open area of research. To address this problem, we\npresent a simplified way to validate English sentences through a novel\nneural-symbolic approach. Lately, neural-symbolic approaches have triggered an\nincreasing interest towards tackling various NLP challenges, as they are\ndemonstrating their effectiveness as a central component in various AI systems.\nThrough combining Classic with Modern AI, which involves the blending of\ngrammatical and syntactical rules with language models, we effectively tackle\nthe Corpus of Linguistic Acceptability (COLA), a task that shows whether or not\na sequence of words is an English grammatical sentence. Among others,\nundertaken experiments effectively show that blending symbolic and non-symbolic\nsystems helps the former provide insights about the latter's accuracy results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Isaak_N/0/1/0/all/0/1\">Nicos Isaak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pre-trained Language Models in Biomedical Domain: A Systematic Survey. (arXiv:2110.05006v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2110.05006","description":"<p>Pre-trained language models (PLMs) have been the de facto paradigm for most\nnatural language processing (NLP) tasks. This also benefits biomedical domain:\nresearchers from informatics, medicine, and computer science (CS) communities\npropose various PLMs trained on biomedical datasets, e.g., biomedical text,\nelectronic health records, protein, and DNA sequences for various biomedical\ntasks. However, the cross-discipline characteristics of biomedical PLMs hinder\ntheir spreading among communities; some existing works are isolated from each\nother without comprehensive comparison and discussions. It expects a survey\nthat not only systematically reviews recent advances of biomedical PLMs and\ntheir applications but also standardizes terminology and benchmarks. In this\npaper, we summarize the recent progress of pre-trained language models in the\nbiomedical domain and their applications in biomedical downstream tasks.\nParticularly, we discuss the motivations and propose a taxonomy of existing\nbiomedical PLMs. Their applications in biomedical downstream tasks are\nexhaustively discussed. At last, we illustrate various limitations and future\ntrends, which we hope can provide inspiration for the future research of the\nresearch community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Benyou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1\">Qianqian Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1\">Jiahuan Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhihong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_P/0/1/0/all/0/1\">Prayag Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+fu_J/0/1/0/all/0/1\">Jie fu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated scholarly paper review: Concepts, technologies, and challenges. (arXiv:2111.07533v4 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2111.07533","description":"<p>Peer review is a widely accepted mechanism for research evaluation, playing a\npivotal role in academic publishing. However, criticisms have long been leveled\nat this mechanism, mostly because of its poor efficiency and low\nreproducibility. Recent years have seen the application of artificial\nintelligence (AI) in assisting the peer review process. Nonetheless, with the\ninvolvement of humans, such limitations remain inevitable. In this paper, we\npropose the concept and pipeline of automated scholarly paper review (ASPR) and\nreview the relevant literature and technologies of achieving a full-scale\ncomputerized review process. On the basis of the review and discussion, we\nconclude that there is already corresponding research and preliminary\nimplementation at each stage of ASPR. We further look into the challenges in\nASPR with the existing technologies. The major difficulties lie in inadequate\ndata, imperfect document parsing and representation, defective\nhuman$\\unicode{x2013}$computer interaction, and flawed deep logical reasoning.\nMoreover, we point out the future directions and discuss the possible moral and\nethical issues of ASPR. In the foreseeable future, ASPR and peer review will\ncoexist in a reinforcing manner before ASPR is able to fully undertake the\nreviewing workload from humans.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jialiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jiaxin Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhangping Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yidong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xiaodong Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Hierarchical Organization of Syntax. (arXiv:2112.05783v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2112.05783","description":"<p>Hierarchies are the hidden backbones of complex systems and their analysis\nallows for a deeper understanding of their structure and how they evolve. We\nconsider languages also to be complex adaptive systems with several intricate\nnetworks that capture their structure and function. Hence, we decided to\nanalyze the hierarchical organization of historical syntactic networks to\nunderstand how syntax evolves over time. We created these networks from a\ncorpus of German texts from the 11th to 17th centuries, focusing on the\nhierarchical levels of these networks. diachronically and to map them to\nspecific communicative needs of speakers. We developed a framework to\nempirically track the emergence of syntactic structures diachronically,\nenabling us to map the communicative needs of speakers with these structures.\nWe named these syntactic structures \"syntactic communicative hierarchies.\" We\nshowed that the communicative needs of speakers are the organizational force of\nsyntax. Thus, we argue that the emergence of syntactic communicative\nhierarchies plays a crucial role in shaping syntax over time. This may indicate\nthat languages evolve not only to increase the efficiency of transferring\ninformation, but also to increase our capacity, as a species, to communicate\nour needs with more and more sophisticated abstractions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ravandi_B/0/1/0/all/0/1\">Babak Ravandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Concu_V/0/1/0/all/0/1\">Valentina Concu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Diversity Over Size: On the Effect of Sample and Topic Sizes for Argument Mining Datasets. (arXiv:2205.11472v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.11472","description":"<p>The task of Argument Mining, that is extracting argumentative sentences for a\nspecific topic from large document sources, is an inherently difficult task for\nmachine learning models and humans alike, as large Argument Mining datasets are\nrare and recognition of argumentative sentences requires expert knowledge. The\ntask becomes even more difficult if it also involves stance detection of\nretrieved arguments. Given the cost and complexity of creating suitably large\nArgument Mining datasets, we ask whether it is necessary for acceptable\nperformance to have datasets growing in size. Our findings show that, when\nusing carefully composed training samples and a model pretrained on related\ntasks, we can reach 95% of the maximum performance while reducing the training\nsample size by at least 85%. This gain is consistent across three Argument\nMining tasks on three different datasets. We also publish a new dataset for\nfuture benchmarking.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schiller_B/0/1/0/all/0/1\">Benjamin Schiller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daxenberger_J/0/1/0/all/0/1\">Johannes Daxenberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Grounded Planning for Embodied Tasks with Language Models. (arXiv:2209.00465v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2209.00465","description":"<p>Language models (LMs) have demonstrated their capability in possessing\ncommonsense knowledge of the physical world, a crucial aspect of performing\ntasks in everyday life. However, it remains unclear **whether LMs have the\ncapacity to generate grounded, executable plans for embodied tasks.** This is a\nchallenging task as LMs lack the ability to perceive the environment through\nvision and feedback from the physical environment. In this paper, we address\nthis important research question and present the first investigation into the\ntopic. Our novel problem formulation, named **G-PlanET**, inputs a high-level\ngoal and a data table about objects in a specific environment, and then outputs\na step-by-step actionable plan for a robotic agent to follow. To facilitate the\nstudy, we establish an **evaluation protocol** and design a dedicated metric to\nassess the quality of the plans. Our experiments demonstrate that the use of\ntables for encoding the environment and an iterative decoding strategy can\nsignificantly enhance the LMs' ability in grounded planning. Our analysis also\nreveals interesting and non-trivial findings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chengsong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_W/0/1/0/all/0/1\">Wenda Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sommerer_S/0/1/0/all/0/1\">Sam Sommerer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Elaboration-Generating Commonsense Question Answering at Scale. (arXiv:2209.01232v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.01232","description":"<p>In question answering requiring common sense, language models (e.g., GPT-3)\nhave been used to generate text expressing background knowledge that helps\nimprove performance. Yet the cost of working with such models is very high; in\nthis work, we finetune smaller language models to generate useful intermediate\ncontext, referred to here as elaborations. Our framework alternates between\nupdating two language models -- an elaboration generator and an answer\npredictor -- allowing each to influence the other. Using less than 0.5% of the\nparameters of GPT-3, our model outperforms alternatives with similar sizes and\ncloses the gap on GPT-3 on four commonsense question answering benchmarks.\nHuman evaluations show that the quality of the generated elaborations is high.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenya Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srikumar_V/0/1/0/all/0/1\">Vivek Srikumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hanna Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Underspecification in Language Modeling Tasks: A Causality-Informed Study of Gendered Pronoun Resolution. (arXiv:2210.00131v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.00131","description":"<p>Modern language modeling tasks are often underspecified: for a given token\nprediction, many words may satisfy the user's intent of producing natural\nlanguage at inference time, however only one word would minimize the task's\nloss function at training time. We provide a simple yet plausible causal\nmechanism describing the role underspecification plays in the generation of\nspurious correlations. Despite its simplicity, our causal model directly\ninforms the development of two lightweight black-box evaluation methods, that\nwe apply to gendered pronoun resolution tasks on a wide range of LLMs to 1) aid\nin the detection of inference-time task underspecification by exploiting 2)\npreviously unreported gender vs. time and gender vs. location spurious\ncorrelations on LLMs with a range of A) sizes: from BERT-base to GPT 3.5, B)\npre-training objectives: from masked &amp; autoregressive language modeling to a\nmixture of these objectives, and C) training stages: from pre-training only to\nreinforcement learning from human feedback (RLHF). Code and open-source demos\navailable at https: //github.com/2dot71mily/sib_paper.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+McMilin_E/0/1/0/all/0/1\">Emily McMilin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DialoGen: Generalized Long-Range Context Representation for Dialogue Systems. (arXiv:2210.06282v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.06282","description":"<p>Long-range context modeling is crucial to both dialogue understanding and\ngeneration. The most popular method for dialogue context representation is to\nconcatenate the last-$k$ previous utterances. However, this method may not be\nideal for conversations containing long-range dependencies as it cannot look\nbeyond last-$k$ utterances. In this work, we propose DialoGen, a novel\nencoder-decoder based framework for conversational response generation with a\ngeneralized context representation that can look beyond the last-$k$\nutterances. Hence the method is adaptive to conversations with long-range\ndependencies. The main idea of our approach is to identify and utilize the most\nrelevant historical utterances instead of the last-$k$ utterances in\nchronological order. We study the effectiveness of our proposed method on both\ndialogue generation (open-domain) and understanding (DST) tasks. DialoGen\nachieves comparable performance with the state-of-the-art models on DailyDialog\ndataset. We also observe performance gain in existing DST models with our\nproposed context representation strategy on MultiWOZ dataset. We discuss the\ngeneralizability and interpretability of DialoGen and show that the relevance\nscore of previous utterances agrees well with human cognition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dey_S/0/1/0/all/0/1\">Suvodip Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desarkar_M/0/1/0/all/0/1\">Maunendra Sankar Desarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srijith_P/0/1/0/all/0/1\">P. K. Srijith</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Undesirable biases in NLP: Averting a crisis of measurement. (arXiv:2211.13709v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.13709","description":"<p>As Large Language Models and Natural Language Processing (NLP) technology\nrapidly develops and spreads into daily life, it becomes crucial to anticipate\nhow its use could harm people. One problem that has received a lot of attention\nin recent years is that this technology has displayed harmful biases in its\nbehavior. Although a lot of effort has been invested in assessing and\nmitigating these biases, our methods of measuring the biases of NLP models have\nserious problems (e.g., it is often unclear what they actually measure). In\nthis paper, we provide an interdisciplinary approach to discussing the issue of\nNLP model bias by adopting the lens of psychometrics -- a field specialized in\nthe measurement of concepts like bias that are not directly observable. In\nparticular, we will explore two central notions from psychometrics, the\nconstruct validity and the reliability of measurement tools, and discuss how\nthey can be applied in the context of measuring model bias. Our goal is to\nprovide NLP practitioners with methodological tools for designing better bias\nmeasures, and to inspire them more generally to explore tools from\npsychometrics when working on bias measurement tools.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wal_O/0/1/0/all/0/1\">Oskar van der Wal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachmann_D/0/1/0/all/0/1\">Dominik Bachmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leidinger_A/0/1/0/all/0/1\">Alina Leidinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maanen_L/0/1/0/all/0/1\">Leendert van Maanen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuidema_W/0/1/0/all/0/1\">Willem Zuidema</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schulz_K/0/1/0/all/0/1\">Katrin Schulz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SuS-X: Training-Free Name-Only Transfer of Vision-Language Models. (arXiv:2211.16198v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2211.16198","description":"<p>Contrastive Language-Image Pre-training (CLIP) has emerged as a simple yet\neffective way to train large-scale vision-language models. CLIP demonstrates\nimpressive zero-shot classification and retrieval on diverse downstream tasks.\nHowever, to leverage its full potential, fine-tuning still appears to be\nnecessary. Fine-tuning the entire CLIP model can be resource-intensive and\nunstable. Moreover, recent methods that aim to circumvent this need for\nfine-tuning still require access to images from the target distribution. In\nthis paper, we pursue a different approach and explore the regime of\ntraining-free \"name-only transfer\" in which the only knowledge we possess about\nthe downstream task comprises the names of downstream target categories. We\npropose a novel method, SuS-X, consisting of two key building blocks -- SuS and\nTIP-X, that requires neither intensive fine-tuning nor costly labelled data.\nSuS-X achieves state-of-the-art zero-shot classification results on 19\nbenchmark datasets. We further show the utility of TIP-X in the training-free\nfew-shot setting, where we again achieve state-of-the-art results over strong\ntraining-free baselines. Code is available at\nhttps://github.com/vishaal27/SuS-X.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Udandarao_V/0/1/0/all/0/1\">Vishaal Udandarao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Ankush Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albanie_S/0/1/0/all/0/1\">Samuel Albanie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unifying Structure Reasoning and Language Model Pre-training for Complex Reasoning. (arXiv:2301.08913v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.08913","description":"<p>Recent pre-trained language models (PLMs) equipped with foundation reasoning\nskills have shown remarkable performance on downstream complex tasks. However,\nthe significant structure reasoning skill has been rarely studied, which\ninvolves modeling implicit structure information within the text and performing\nexplicit logical reasoning over them to deduce the conclusion. This paper\nproposes a unified learning framework that combines explicit structure\nreasoning and language pre-training to endow PLMs with the structure reasoning\nskill. It first identifies several elementary structures within contexts to\nconstruct structured queries and performs step-by-step reasoning along the\nqueries to identify the answer entity. The fusion of textual semantics and\nstructure reasoning is achieved by using contextual representations learned by\nPLMs to initialize the representation space of structures, and performing\nstepwise reasoning on this semantic representation space. Experimental results\non four datasets demonstrate that the proposed model achieves significant\nimprovements in complex reasoning tasks involving diverse structures, and shows\ntransferability to downstream tasks with limited training data and\neffectiveness for complex reasoning of KGs modality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Siyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhongyu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiarong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Taishan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zhihao Fan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lived Experience Matters: Automatic Detection of Stigma on Social Media Toward People Who Use Substances. (arXiv:2302.02064v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.02064","description":"<p>Stigma toward people who use substances (PWUS) is a leading barrier to\nseeking treatment.Further, those in treatment are more likely to drop out if\nthey experience higher levels of stigmatization. While related concepts of hate\nspeech and toxicity, including those targeted toward vulnerable populations,\nhave been the focus of automatic content moderation research, stigma and, in\nparticular, people who use substances have not. This paper explores stigma\ntoward PWUS using a data set of roughly 5,000 public Reddit posts. We performed\na crowd-sourced annotation task where workers are asked to annotate each post\nfor the presence of stigma toward PWUS and answer a series of questions related\nto their experiences with substance use. Results show that workers who use\nsubstances or know someone with a substance use disorder are more likely to\nrate a post as stigmatizing. Building on this, we use a supervised machine\nlearning framework that centers workers with lived substance use experience to\nlabel each Reddit post as stigmatizing. Modeling person-level demographics in\naddition to comment-level language results in a classification accuracy (as\nmeasured by AUC) of 0.69 -- a 17% increase over modeling language alone.\nFinally, we explore the linguist cues which distinguish stigmatizing content:\nPWUS substances and those who don't agree that language around othering\n(\"people\", \"they\") and terms like \"addict\" are stigmatizing, while PWUS (as\nopposed to those who do not) find discussions around specific substances more\nstigmatizing. Our findings offer insights into the nature of perceived stigma\nin substance use. Additionally, these results further establish the subjective\nnature of such machine learning tasks, highlighting the need for understanding\ntheir social contexts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Giorgi_S/0/1/0/all/0/1\">Salvatore Giorgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bellew_D/0/1/0/all/0/1\">Douglas Bellew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habib_D/0/1/0/all/0/1\">Daniel Roy Sadek Habib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sherman_G/0/1/0/all/0/1\">Garrick Sherman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sedoc_J/0/1/0/all/0/1\">Joao Sedoc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smitterberg_C/0/1/0/all/0/1\">Chase Smitterberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devoto_A/0/1/0/all/0/1\">Amanda Devoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Himelein_Wachowiak_M/0/1/0/all/0/1\">McKenzie Himelein-Wachowiak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Curtis_B/0/1/0/all/0/1\">Brenda Curtis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Neural Span-Based Continual Named Entity Recognition Model. (arXiv:2302.12200v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.12200","description":"<p>Named Entity Recognition (NER) models capable of Continual Learning (CL) are\nrealistically valuable in areas where entity types continuously increase (e.g.,\npersonal assistants). Meanwhile the learning paradigm of NER advances to new\npatterns such as the span-based methods. However, its potential to CL has not\nbeen fully explored. In this paper, we propose SpanKL, a simple yet effective\nSpan-based model with Knowledge distillation (KD) to preserve memories and\nmulti-Label prediction to prevent conflicts in CL-NER. Unlike prior sequence\nlabeling approaches, the inherently independent modeling in span and entity\nlevel with the designed coherent optimization on SpanKL promotes its learning\nat each incremental step and mitigates the forgetting. Experiments on synthetic\nCL datasets derived from OntoNotes and Few-NERD show that SpanKL significantly\noutperforms previous SoTA in many aspects, and obtains the smallest gap from CL\nto the upper bound revealing its high practiced value. The code is available at\nhttps://github.com/Qznan/SpanKL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingcai Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gradient-Free Structured Pruning with Unlabeled Data. (arXiv:2303.04185v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2303.04185","description":"<p>Large Language Models (LLMs) have achieved great success in solving difficult\ntasks across many domains, but such success comes with a high computation cost,\nand inference latency. As developers and third parties customize these models,\nthe need to provide efficient inference has increased. Many efforts have\nattempted to reduce inference cost through model compression techniques such as\npruning and distillation. However, these techniques either require labeled\ndata, or are time-consuming as they require the compressed model to be\nretrained to regain accuracy. In this paper, we propose a gradient-free\nstructured pruning framework that uses only unlabeled data. An evaluation on\nthe GLUE and SQuAD benchmarks using BERT$_{BASE}$ and DistilBERT illustrates\nthe effectiveness of the proposed approach. By only using the weights of the\npre-trained model and unlabeled data, in a matter of a few minutes on a single\nGPU, up to 40% of the original FLOP count can be reduced with less than a 4%\naccuracy loss across all tasks considered.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nova_A/0/1/0/all/0/1\">Azade Nova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1\">Hanjun Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuurmans_D/0/1/0/all/0/1\">Dale Schuurmans</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fuzzy Alignments in Directed Acyclic Graph for Non-Autoregressive Machine Translation. (arXiv:2303.06662v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.06662","description":"<p>Non-autoregressive translation (NAT) reduces the decoding latency but suffers\nfrom performance degradation due to the multi-modality problem. Recently, the\nstructure of directed acyclic graph has achieved great success in NAT, which\ntackles the multi-modality problem by introducing dependency between vertices.\nHowever, training it with negative log-likelihood loss implicitly requires a\nstrict alignment between reference tokens and vertices, weakening its ability\nto handle multiple translation modalities. In this paper, we hold the view that\nall paths in the graph are fuzzily aligned with the reference sentence. We do\nnot require the exact alignment but train the model to maximize a fuzzy\nalignment score between the graph and reference, which takes captured\ntranslations in all modalities into account. Extensive experiments on major WMT\nbenchmarks show that our method substantially improves translation performance\nand increases prediction confidence, setting a new state of the art for NAT on\nthe raw training data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhengrui Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_C/0/1/0/all/0/1\">Chenze Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_S/0/1/0/all/0/1\">Shangtong Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"P+: Extended Textual Conditioning in Text-to-Image Generation. (arXiv:2303.09522v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2303.09522","description":"<p>We introduce an Extended Textual Conditioning space in text-to-image models,\nreferred to as $P+$. This space consists of multiple textual conditions,\nderived from per-layer prompts, each corresponding to a layer of the denoising\nU-net of the diffusion model.\n</p>\n<p>We show that the extended space provides greater disentangling and control\nover image synthesis. We further introduce Extended Textual Inversion (XTI),\nwhere the images are inverted into $P+$, and represented by per-layer tokens.\n</p>\n<p>We show that XTI is more expressive and precise, and converges faster than\nthe original Textual Inversion (TI) space. The extended inversion method does\nnot involve any noticeable trade-off between reconstruction and editability and\ninduces more regular inversions.\n</p>\n<p>We conduct a series of extensive experiments to analyze and understand the\nproperties of the new space, and to showcase the effectiveness of our method\nfor personalizing text-to-image models. Furthermore, we utilize the unique\nproperties of this space to achieve previously unattainable results in\nobject-style mixing using text-to-image models. Project page:\nhttps://prompt-plus.github.io\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Voynov_A/0/1/0/all/0/1\">Andrey Voynov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_Q/0/1/0/all/0/1\">Qinghao Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1\">Daniel Cohen-Or</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aberman_K/0/1/0/all/0/1\">Kfir Aberman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Compress Prompts with Gist Tokens. (arXiv:2304.08467v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.08467","description":"<p>Prompting is the primary way to utilize the multitask capabilities of\nlanguage models (LMs), but prompts occupy valuable space in the input context\nwindow, and repeatedly encoding the same prompt is computationally inefficient.\nFinetuning and distillation methods allow for specialization of LMs without\nprompting, but require retraining the model for each task. To avoid this\ntrade-off entirely, we present gisting, which trains an LM to compress prompts\ninto smaller sets of \"gist\" tokens which can be cached and reused for compute\nefficiency. Gist models can be trained with no additional cost over standard\ninstruction finetuning by simply modifying Transformer attention masks to\nencourage prompt compression. On decoder (LLaMA-7B) and encoder-decoder\n(FLAN-T5-XXL) LMs, gisting enables up to 26x compression of prompts, resulting\nin up to 40% FLOPs reductions, 4.2% wall time speedups, and storage savings,\nall with minimal loss in output quality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mu_J/0/1/0/all/0/1\">Jesse Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Lisa Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah Goodman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SCOTT: Self-Consistent Chain-of-Thought Distillation. (arXiv:2305.01879v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.01879","description":"<p>Large language models (LMs) beyond a certain scale, demonstrate the emergent\ncapability of generating free-text rationales for their predictions via\nchain-of-thought (CoT) prompting. While CoT can yield dramatically improved\nperformance, such gains are only observed for sufficiently large LMs. Even more\nconcerning, there is little guarantee that the generated rationales are\nconsistent with LM's predictions or faithfully justify the decisions. In this\nwork, we propose a faithful knowledge distillation method to learn a small,\nself-consistent CoT model from a teacher model that is orders of magnitude\nlarger. To form better supervision, we elicit rationales supporting the gold\nanswers from a large LM (teacher) by contrastive decoding, which encourages the\nteacher to generate tokens that become more plausible only when the answer is\nconsidered. To ensure faithful distillation, we use the teacher-generated\nrationales to learn a student LM with a counterfactual reasoning objective,\nwhich prevents the student from ignoring the rationales to make inconsistent\npredictions. Experiments show that, while yielding comparable end-task\nperformance, our method can generate CoT rationales that are more faithful than\nbaselines do. Further analysis suggests that such a model respects the\nrationales more when making decisions; thus, we can improve its performance\nmore by refining its rationales.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yifan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1\">Bing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-Modal Retrieval for Motion and Text via MildTriple Loss. (arXiv:2305.04195v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.04195","description":"<p>Cross-modal retrieval has become a prominent research topic in computer\nvision and natural language processing with advances made in image-text and\nvideo-text retrieval technologies. However, cross-modal retrieval between human\nmotion sequences and text has not garnered sufficient attention despite the\nextensive application value it holds, such as aiding virtual reality\napplications in better understanding users' actions and language. This task\npresents several challenges, including joint modeling of the two modalities,\ndemanding the understanding of person-centered information from text, and\nlearning behavior features from 3D human motion sequences. Previous work on\nmotion data modeling mainly relied on autoregressive feature extractors that\nmay forget previous information, while we propose an innovative model that\nincludes simple yet powerful transformer-based motion and text encoders, which\ncan learn representations from the two different modalities and capture\nlong-term dependencies. Furthermore, the overlap of the same atomic actions of\ndifferent human motions can cause semantic conflicts, leading us to explore a\nnew triplet loss function, MildTriple Loss. it leverages the similarity between\nsamples in intra-modal space to guide soft-hard negative sample mining in the\njoint embedding space to train the triplet loss and reduce the violation caused\nby false negative samples. We evaluated our model and method on the latest\nHumanML3D and KIT Motion-Language datasets, achieving a 62.9\\% recall for\nmotion retrieval and a 71.5\\% recall for text retrieval (based on R@10) on the\nHumanML3D dataset. Our code is available at\nhttps://github.com/eanson023/rehamot.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Sheng Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoqiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1\">Xin Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mengyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hong Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding and Mitigating Spurious Correlations in Text Classification with Neighborhood Analysis. (arXiv:2305.13654v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13654","description":"<p>Recent research has revealed that deep learning models have a tendency to\nleverage spurious correlations that exist in the training set but may not hold\ntrue in general circumstances. For instance, a sentiment classifier may\nerroneously learn that the token performances is commonly associated with\npositive movie reviews. Relying on these spurious correlations degrades the\nclassifiers performance when it deploys on out-of-distribution data. In this\npaper, we examine the implications of spurious correlations through a novel\nperspective called neighborhood analysis. The analysis uncovers how spurious\ncorrelations lead unrelated words to erroneously cluster together in the\nembedding space. Driven by the analysis, we design a metric to detect spurious\ntokens and also propose a family of regularization methods, NFL (doN't Forget\nyour Language) to mitigate spurious correlations in text classification.\nExperiments show that NFL can effectively prevent erroneous clusters and\nsignificantly improve the robustness of classifiers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chew_O/0/1/0/all/0/1\">Oscar Chew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hsuan-Tien Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kuan-Hao Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Training Socially Aligned Language Models in Simulated Human Society. (arXiv:2305.16960v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.16960","description":"<p>Social alignment in AI systems aims to ensure that these models behave\naccording to established societal values. However, unlike humans, who derive\nconsensus on value judgments through social interaction, current language\nmodels (LMs) are trained to rigidly replicate their training corpus in\nisolation, leading to subpar generalization in unfamiliar scenarios and\nvulnerability to adversarial attacks. This work presents a novel training\nparadigm that permits LMs to learn from simulated social interactions. In\ncomparison to existing methodologies, our approach is considerably more\nscalable and efficient, demonstrating superior performance in alignment\nbenchmarks and human evaluations. This paradigm shift in the training of LMs\nbrings us a step closer to developing AI systems that can robustly and\naccurately reflect societal norms and values.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Ruibo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Ruixin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1\">Chenyan Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Ge Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Denny Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1\">Andrew M. Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vosoughi_S/0/1/0/all/0/1\">Soroush Vosoughi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"W-procer: Weighted Prototypical Contrastive Learning for Medical Few-Shot Named Entity Recognition. (arXiv:2305.18624v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.18624","description":"<p>Contrastive learning has become a popular solution for few-shot Name Entity\nRecognization (NER). The conventional configuration strives to reduce the\ndistance between tokens with the same labels and increase the distance between\ntokens with different labels. The effect of this setup may, however, in the\nmedical domain, there are a lot of entities annotated as OUTSIDE (O), and they\nare undesirably pushed apart to other entities that are not labeled as OUTSIDE\n(O) by the current contrastive learning method end up with a noisy prototype\nfor the semantic representation of the label, though there are many OUTSIDE (O)\nlabeled entities are relevant to the labeled entities. To address this\nchallenge, we propose a novel method named Weighted Prototypical Contrastive\nLearning for Medical Few Shot Named Entity Recognization (W-PROCER). Our\napproach primarily revolves around constructing the prototype-based contractive\nloss and weighting network. These components play a crucial role in assisting\nthe model in differentiating the negative samples from OUTSIDE (O) tokens and\nenhancing the discrimination ability of contrastive learning. Experimental\nresults show that our proposed W-PROCER framework significantly outperforms the\nstrong baselines on the three medical benchmark datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingchen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yang Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_J/0/1/0/all/0/1\">Jeremy Yeung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Huixue Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_H/0/1/0/all/0/1\">Huaiyuan Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adaptive Contextual Biasing for Transducer Based Streaming Speech Recognition. (arXiv:2306.00804v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2306.00804","description":"<p>By incorporating additional contextual information, deep biasing methods have\nemerged as a promising solution for speech recognition of personalized words.\nHowever, for real-world voice assistants, always biasing on such personalized\nwords with high prediction scores can significantly degrade the performance of\nrecognizing common words. To address this issue, we propose an adaptive\ncontextual biasing method based on Context-Aware Transformer Transducer (CATT)\nthat utilizes the biased encoder and predictor embeddings to perform streaming\nprediction of contextual phrase occurrences. Such prediction is then used to\ndynamically switch the bias list on and off, enabling the model to adapt to\nboth personalized and common scenarios. Experiments on Librispeech and internal\nvoice assistant datasets show that our approach can achieve up to 6.7% and\n20.7% relative reduction in WER and CER compared to the baseline respectively,\nmitigating up to 96.7% and 84.9% of the relative WER and CER increase for\ncommon cases. Furthermore, our approach has a minimal performance impact in\npersonalized scenarios while maintaining a streaming inference pipeline with\nnegligible RTF increase.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tianyi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhanheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kaixun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_P/0/1/0/all/0/1\">Pengcheng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Ao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Biao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changru Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Lei Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Study of Situational Reasoning for Traffic Understanding. (arXiv:2306.02520v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.02520","description":"<p>Intelligent Traffic Monitoring (ITMo) technologies hold the potential for\nimproving road safety/security and for enabling smart city infrastructure.\nUnderstanding traffic situations requires a complex fusion of perceptual\ninformation with domain-specific and causal commonsense knowledge. Whereas\nprior work has provided benchmarks and methods for traffic monitoring, it\nremains unclear whether models can effectively align these information sources\nand reason in novel scenarios. To address this assessment gap, we devise three\nnovel text-based tasks for situational reasoning in the traffic domain: i)\nBDD-QA, which evaluates the ability of Language Models (LMs) to perform\nsituational decision-making, ii) TV-QA, which assesses LMs' abilities to reason\nabout complex event causality, and iii) HDT-QA, which evaluates the ability of\nmodels to solve human driving exams. We adopt four knowledge-enhanced methods\nthat have shown generalization capability across language reasoning tasks in\nprior work, based on natural language inference, commonsense knowledge-graph\nself-supervision, multi-QA joint training, and dense retrieval of domain\ninformation. We associate each method with a relevant knowledge source,\nincluding knowledge graphs, relevant benchmarks, and driving manuals. In\nextensive experiments, we benchmark various knowledge-aware methods against the\nthree datasets, under zero-shot evaluation; we provide in-depth analyses of\nmodel performance on data partitions and examine model predictions\ncategorically, to yield useful insights on traffic understanding, given\ndifferent background knowledge and reasoning strategies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiarui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilievski_F/0/1/0/all/0/1\">Filip Ilievski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1\">Kaixin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kollaa_A/0/1/0/all/0/1\">Aravinda Kollaa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Francis_J/0/1/0/all/0/1\">Jonathan Francis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oltramari_A/0/1/0/all/0/1\">Alessandro Oltramari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modeling Human-like Concept Learning with Bayesian Inference over Natural Language. (arXiv:2306.02797v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.02797","description":"<p>We model learning of abstract symbolic concepts by performing Bayesian\ninference over utterances in natural language. For efficient inference, we use\na large language model as a proposal distribution. We fit a prior to human data\nto better model human learners, and evaluate on both generative and logical\nconcepts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ellis_K/0/1/0/all/0/1\">Kevin Ellis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InstructEval: Systematic Evaluation of Instruction Selection Methods. (arXiv:2307.00259v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.00259","description":"<p>In-context learning (ICL) performs tasks by prompting a large language model\n(LLM) using an instruction and a small set of annotated examples called\ndemonstrations. Recent work has shown that precise details of the inputs used\nin the ICL prompt significantly impact performance, which has incentivized\ninstruction selection algorithms. The effect of instruction-choice however is\nseverely underexplored, with existing analyses restricted to shallow subsets of\nmodels and tasks, limiting the generalizability of their insights. We develop\nInstructEval, an ICL evaluation suite to conduct a thorough assessment of these\ntechniques. The suite includes 13 open-sourced LLMs of varying scales from four\nmodel families, and covers nine tasks across three categories. Using the suite,\nwe evaluate the relative performance of seven popular instruction selection\nmethods over five metrics relevant to ICL. Our experiments reveal that using\ncurated manually-written instructions or simple instructions without any\ntask-specific descriptions often elicits superior ICL performance overall than\nthat of automatic instruction-induction methods, pointing to a lack of\ngeneralizability among the latter. We release our evaluation suite for\nbenchmarking instruction selection approaches and enabling more generalizable\nmethods in this space.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ajith_A/0/1/0/all/0/1\">Anirudh Ajith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1\">Chris Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Mengzhou Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1\">Ameet Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Emoji Prediction using Transformer Models. (arXiv:2307.02054v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.02054","description":"<p>In recent years, the use of emojis in social media has increased\ndramatically, making them an important element in understanding online\ncommunication. However, predicting the meaning of emojis in a given text is a\nchallenging task due to their ambiguous nature. In this study, we propose a\ntransformer-based approach for emoji prediction using BERT, a widely-used\npre-trained language model. We fine-tuned BERT on a large corpus of text\ncontaining both text and emojis to predict the most appropriate emoji for a\ngiven text. Our experimental results demonstrate that our approach outperforms\nseveral state-of-the-art models in predicting emojis with an accuracy of over\n75 percent. This work has potential applications in natural language\nprocessing, sentiment analysis, and social media marketing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nusrat_M/0/1/0/all/0/1\">Muhammad Osama Nusrat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habib_Z/0/1/0/all/0/1\">Zeeshan Habib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1\">Mehreen Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jamal_S/0/1/0/all/0/1\">Saad Ahmed Jamal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On decoder-only architecture for speech-to-text and large language model integration. (arXiv:2307.03917v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2307.03917","description":"<p>Large language models (LLMs) have achieved remarkable success in the field of\nnatural language processing, enabling better human-computer interaction using\nnatural language. However, the seamless integration of speech signals into LLMs\nhas not been explored well. The \"decoder-only\" architecture has also not been\nwell studied for speech processing tasks. In this research, we introduce\nSpeech-LLaMA, a novel approach that effectively incorporates acoustic\ninformation into text-based large language models. Our method leverages\nConnectionist Temporal Classification and a simple audio encoder to map the\ncompressed acoustic features to the continuous semantic space of the LLM. In\naddition, we further probe the decoder-only architecture for speech-to-text\ntasks by training a smaller scale randomly initialized speech-LLaMA model from\nspeech-text paired data alone. We conduct experiments on multilingual\nspeech-to-text translation tasks and demonstrate a significant improvement over\nstrong baselines, highlighting the potential advantages of decoder-only models\nfor speech-to-text conversion.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Wu_J/0/1/0/all/0/1\">Jian Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gaur_Y/0/1/0/all/0/1\">Yashesh Gaur</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1\">Zhuo Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_L/0/1/0/all/0/1\">Long Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_Y/0/1/0/all/0/1\">Yimeng Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_T/0/1/0/all/0/1\">Tianrui Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_S/0/1/0/all/0/1\">Shujie Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ren_B/0/1/0/all/0/1\">Bo Ren</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_L/0/1/0/all/0/1\">Linquan Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT in the Age of Generative AI and Large Language Models: A Concise Survey. (arXiv:2307.04251v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.04251","description":"<p>ChatGPT is a large language model (LLM) created by OpenAI that has been\ncarefully trained on a large amount of data. It has revolutionized the field of\nnatural language processing (NLP) and has pushed the boundaries of LLM\ncapabilities. ChatGPT has played a pivotal role in enabling widespread public\ninteraction with generative artificial intelligence (GAI) on a large scale. It\nhas also sparked research interest in developing similar technologies and\ninvestigating their applications and implications. In this paper, our primary\ngoal is to provide a concise survey on the current lines of research on ChatGPT\nand its evolution. We considered both the glass box and black box views of\nChatGPT, encompassing the components and foundational elements of the\ntechnology, as well as its applications, impacts, and implications. The glass\nbox approach focuses on understanding the inner workings of the technology, and\nthe black box approach embraces it as a complex system, and thus examines its\ninputs, outputs, and effects. This paves the way for a comprehensive\nexploration of the technology and provides a road map for further research and\nexperimentation. We also lay out essential foundational literature on LLMs and\nGAI in general and their connection with ChatGPT. This overview sheds light on\nexisting and missing research lines in the emerging field of LLMs, benefiting\nboth public users and developers. Furthermore, the paper delves into the broad\nspectrum of applications and significant concerns in fields such as education,\nresearch, healthcare, finance, etc.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mohamadi_S/0/1/0/all/0/1\">Salman Mohamadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mujtaba_G/0/1/0/all/0/1\">Ghulam Mujtaba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1\">Ngan Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doretto_G/0/1/0/all/0/1\">Gianfranco Doretto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adjeroh_D/0/1/0/all/0/1\">Donald A. Adjeroh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unmasking the giant: A comprehensive evaluation of ChatGPT's proficiency in coding algorithms and data structures. (arXiv:2307.05360v2 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2307.05360","description":"<p>The transformative influence of Large Language Models (LLMs) is profoundly\nreshaping the Artificial Intelligence (AI) technology domain. Notably, ChatGPT\ndistinguishes itself within these models, demonstrating remarkable performance\nin multi-turn conversations and exhibiting code proficiency across an array of\nlanguages. In this paper, we carry out a comprehensive evaluation of ChatGPT's\ncoding capabilities based on what is to date the largest catalog of coding\nchallenges. Our focus is on the python programming language and problems\ncentered on data structures and algorithms, two topics at the very foundations\nof Computer Science. We evaluate ChatGPT for its ability to generate correct\nsolutions to the problems fed to it, its code quality, and nature of run-time\nerrors thrown by its code. Where ChatGPT code successfully executes, but fails\nto solve the problem at hand, we look into patterns in the test cases passed in\norder to gain some insights into how wrong ChatGPT code is in these kinds of\nsituations. To infer whether ChatGPT might have directly memorized some of the\ndata that was used to train it, we methodically design an experiment to\ninvestigate this phenomena. Making comparisons with human performance whenever\nfeasible, we investigate all the above questions from the context of both its\nunderlying learning models (GPT-3.5 and GPT-4), on a vast array sub-topics\nwithin the main topics, and on problems having varying degrees of difficulty.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arefin_S/0/1/0/all/0/1\">Sayed Erfan Arefin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heya_T/0/1/0/all/0/1\">Tasnia Ashrafi Heya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Qudah_H/0/1/0/all/0/1\">Hasan Al-Qudah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ineza_Y/0/1/0/all/0/1\">Ynes Ineza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Serwadda_A/0/1/0/all/0/1\">Abdul Serwadda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations. (arXiv:2307.06576v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2307.06576","description":"<p>Precisely recommending candidate news articles to users has always been a\ncore challenge for personalized news recommendation systems. Most recent works\nprimarily focus on using advanced natural language processing techniques to\nextract semantic information from rich textual data, employing content-based\nmethods derived from local historical news. However, this approach lacks a\nglobal perspective, failing to account for users' hidden motivations and\nbehaviors beyond semantic information. To address this challenge, we propose a\nnovel model called GLORY (Global-LOcal news Recommendation sYstem), which\ncombines global representations learned from other users with local\nrepresentations to enhance personalized recommendation systems. We accomplish\nthis by constructing a Global-aware Historical News Encoder, which includes a\nglobal news graph and employs gated graph neural networks to enrich news\nrepresentations, thereby fusing historical news representations by a historical\nnews aggregator. Similarly, we extend this approach to a Global Candidate News\nEncoder, utilizing a global entity graph and a candidate news aggregator to\nenhance candidate news representation. Evaluation results on two public news\ndatasets demonstrate that our method outperforms existing approaches.\nFurthermore, our model offers more diverse recommendations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Boming Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dairui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzumura_T/0/1/0/all/0/1\">Toyotaro Suzumura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_R/0/1/0/all/0/1\">Ruihai Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1\">Irene Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Parmesan: mathematical concept extraction for education. (arXiv:2307.06699v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.06699","description":"<p>Mathematics is a highly specialized domain with its own unique set of\nchallenges that has seen limited study in natural language processing. However,\nmathematics is used in a wide variety of fields and multidisciplinary research\nin many different domains often relies on an understanding of mathematical\nconcepts. To aid researchers coming from other fields, we develop a prototype\nsystem for searching for and defining mathematical concepts in context,\nfocusing on the field of category theory. This system, Parmesan, depends on\nnatural language processing components including concept extraction, relation\nextraction, definition extraction, and entity linking. In developing this\nsystem, we show that existing techniques cannot be applied directly to the\ncategory theory domain, and suggest hybrid techniques that do perform well,\nthough we expect the system to evolve over time. We also provide two cleaned\nmathematical corpora that power the prototype system, which are based on\njournal articles and wiki pages, respectively. The corpora have been annotated\nwith dependency trees, lemmas, and part-of-speech tags.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Collard_J/0/1/0/all/0/1\">Jacob Collard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paiva_V/0/1/0/all/0/1\">Valeria de Paiva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subrahmanian_E/0/1/0/all/0/1\">Eswaran Subrahmanian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RoPDA: Robust Prompt-based Data Augmentation for Low-Resource Named Entity Recognition. (arXiv:2307.07417v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.07417","description":"<p>Data augmentation has been widely used in low-resource NER tasks to tackle\nthe problem of data sparsity. However, previous data augmentation methods have\nthe disadvantages of disrupted syntactic structures, token-label mismatch, and\nrequirement for external knowledge or manual effort. To address these issues,\nwe propose Robust Prompt-based Data Augmentation (RoPDA) for low-resource NER.\nBased on pre-trained language models (PLMs) with continuous prompt, RoPDA\nperforms entity augmentation and context augmentation through five fundamental\naugmentation operations to generate label-flipping and label-preserving\nexamples. To optimize the utilization of the augmented samples, we present two\ntechniques: Self-Consistency Filtering and mixup. The former effectively\neliminates low-quality samples, while the latter prevents performance\ndegradation arising from the direct utilization of label-flipping samples.\nExtensive experiments on three benchmarks from different domains demonstrate\nthat RoPDA significantly improves upon strong baselines, and also outperforms\nstate-of-the-art semi-supervised learning methods when unlabeled data is\nincluded.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Sihan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_F/0/1/0/all/0/1\">Furao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jian Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-07-17T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","admin":"http://webns.net/mvcb/","syn":"http://purl.org/rss/1.0/modules/syndication/","dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#"}}]}]}