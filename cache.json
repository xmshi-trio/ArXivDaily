{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-05-02T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Text-Blueprint: An Interactive Platform for Plan-based Conditional Generation. (arXiv:2305.00034v1 [cs.CL])","link":"http://arxiv.org/abs/2305.00034","description":"<p>While conditional generation models can now generate natural language well\nenough to create fluent text, it is still difficult to control the generation\nprocess, leading to irrelevant, repetitive, and hallucinated content. Recent\nwork shows that planning can be a useful intermediate step to render\nconditional generation less opaque and more grounded. We present a web\nbrowser-based demonstration for query-focused summarization that uses a\nsequence of question-answer pairs, as a blueprint plan for guiding text\ngeneration (i.e., what to say and in what order). We illustrate how users may\ninteract with the generated text and associated plan visualizations, e.g., by\nediting and modifying the blueprint in order to improve or control the\ngenerated output.\n</p>\n<p>A short video demonstrating our system is available at\nhttps://goo.gle/text-blueprint-demo.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huot_F/0/1/0/all/0/1\">Fantine Huot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maynez_J/0/1/0/all/0/1\">Joshua Maynez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayan_S/0/1/0/all/0/1\">Shashi Narayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amplayo_R/0/1/0/all/0/1\">Reinald Kim Amplayo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganchev_K/0/1/0/all/0/1\">Kuzman Ganchev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Louis_A/0/1/0/all/0/1\">Annie Louis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandholm_A/0/1/0/all/0/1\">Anders Sandholm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1\">Dipanjan Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1\">Mirella Lapata</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. (arXiv:2305.00050v1 [cs.AI])","link":"http://arxiv.org/abs/2305.00050","description":"<p>The causal capabilities of large language models (LLMs) is a matter of\nsignificant debate, with critical implications for the use of LLMs in\nsocietally impactful domains such as medicine, science, law, and policy. We\nfurther our understanding of LLMs and their causal implications, considering\nthe distinctions between different types of causal reasoning tasks, as well as\nthe entangled threats of construct and measurement validity. LLM-based methods\nestablish new state-of-the-art accuracies on multiple causal benchmarks.\nAlgorithms based on GPT-3.5 and 4 outperform existing algorithms on a pairwise\ncausal discovery task (97%, 13 points gain), counterfactual reasoning task\n(92%, 20 points gain), and actual causality (86% accuracy in determining\nnecessary and sufficient causes in vignettes). At the same time, LLMs exhibit\nunpredictable failure modes and we provide some techniques to interpret their\nrobustness.\n</p>\n<p>Crucially, LLMs perform these causal tasks while relying on sources of\nknowledge and methods distinct from and complementary to non-LLM based\napproaches. Specifically, LLMs bring capabilities so far understood to be\nrestricted to humans, such as using collected knowledge to generate causal\ngraphs or identifying background causal context from natural language. We\nenvision LLMs to be used alongside existing causal methods, as a proxy for\nhuman domain knowledge and to reduce human effort in setting up a causal\nanalysis, one of the biggest impediments to the widespread adoption of causal\nmethods. We also see existing causal methods as promising tools for LLMs to\nformalize, validate, and communicate their reasoning especially in high-stakes\nscenarios.\n</p>\n<p>In capturing common sense and domain knowledge about causal mechanisms and\nsupporting translation between natural language and formal methods, LLMs open\nnew frontiers for advancing the research, practice, and adoption of causality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kiciman_E/0/1/0/all/0/1\">Emre K&#x131;c&#x131;man</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ness_R/0/1/0/all/0/1\">Robert Ness</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Amit Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chenhao Tan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explainable Verbal Reasoner Plus (EVR+): A Natural Language Reasoning Framework that Supports Diverse Compositional Reasoning. (arXiv:2305.00061v1 [cs.CL])","link":"http://arxiv.org/abs/2305.00061","description":"<p>Languages models have been successfully applied to a variety of reasoning\ntasks in NLP, yet the language models still suffer from compositional\ngeneralization. In this paper we present Explainable Verbal Reasoner Plus\n(EVR+), a reasoning framework that enhances language models' compositional\nreasoning ability by (1) allowing the model to explicitly generate and execute\nsymbolic operators, and (2) allowing the model to decompose a complex task into\nseveral simpler ones in a flexible manner. Compared with its predecessor\nExplainable Verbal Reasoner (EVR) and other previous approaches adopting\nsimilar ideas, our framework supports more diverse types of reasoning such as\nnested loops and different types of recursion. To evaluate our reasoning\nframework, we build a synthetic dataset with five tasks that require\ncompositional reasoning. Results show that our reasoning framework can enhance\nthe language model's compositional generalization performance on the five\ntasks, using a fine-tuned language model. We also discussed the possibility and\nthe challenges to combine our reasoning framework with a few-shot prompted\nlanguage model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1\">Zhengzhong Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zeyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bethard_S/0/1/0/all/0/1\">Steven Bethard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Surdeanu_M/0/1/0/all/0/1\">Mihai Surdeanu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-Information for Multi-Level Sexism Classification. (arXiv:2305.00076v1 [cs.CL])","link":"http://arxiv.org/abs/2305.00076","description":"<p>We present the findings of our participation in the SemEval-2023 Task 10:\nExplainable Detection of Online Sexism (EDOS) task, a shared task on offensive\nlanguage (sexism) detection on English Gab and Reddit dataset. We investigated\nthe effects of transferring two language models: XLM-T (sentiment\nclassification) and HateBERT (same domain -- Reddit) for multi-level\nclassification into Sexist or not Sexist, and other subsequent\nsub-classifications of the sexist data. We also use synthetic classification of\nunlabelled dataset and intermediary class information to maximize the\nperformance of our models. We submitted a system in Task A, and it ranked 49th\nwith F1-score of 0.82. This result showed to be competitive as it only\nunder-performed the best system by 0.052% F1-score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aliyu_S/0/1/0/all/0/1\">Saminu Mohammad Aliyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdulmumin_I/0/1/0/all/0/1\">Idris Abdulmumin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muhammad_S/0/1/0/all/0/1\">Shamsuddeen Hassan Muhammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_I/0/1/0/all/0/1\">Ibrahim Said Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salahudeen_S/0/1/0/all/0/1\">Saheed Abdullahi Salahudeen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yusuf_A/0/1/0/all/0/1\">Aliyu Yusuf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawan_F/0/1/0/all/0/1\">Falalu Ibrahim Lawan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NLNDE at SemEval-2023 Task 12: Adaptive Pretraining and Source Language Selection for Low-Resource Multilingual Sentiment Analysis. (arXiv:2305.00090v1 [cs.CL])","link":"http://arxiv.org/abs/2305.00090","description":"<p>This paper describes our system developed for the SemEval-2023 Task 12\n\"Sentiment Analysis for Low-resource African Languages using Twitter Dataset\".\nSentiment analysis is one of the most widely studied applications in natural\nlanguage processing. However, most prior work still focuses on a small number\nof high-resource languages. Building reliable sentiment analysis systems for\nlow-resource languages remains challenging, due to the limited training data in\nthis task. In this work, we propose to leverage language-adaptive and\ntask-adaptive pretraining on African texts and study transfer learning with\nsource language selection on top of an African language-centric pretrained\nlanguage model. Our key findings are: (1) Adapting the pretrained model to the\ntarget language and task using a small yet relevant corpus improves performance\nremarkably by more than 10 F1 score points. (2) Selecting source languages with\npositive transfer gains during training can avoid harmful interference from\ndissimilar languages, leading to better results in multilingual and\ncross-lingual settings. In the shared task, our system wins 8 out of 15 tracks\nand, in particular, performs best in the multilingual evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adel_H/0/1/0/all/0/1\">Heike Adel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lange_L/0/1/0/all/0/1\">Lukas Lange</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strotgen_J/0/1/0/all/0/1\">Jannik Str&#xf6;tgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4. (arXiv:2305.00118v1 [cs.CL])","link":"http://arxiv.org/abs/2305.00118","description":"<p>In this work, we carry out a data archaeology to infer books that are known\nto ChatGPT and GPT-4 using a name cloze membership inference query. We find\nthat OpenAI models have memorized a wide collection of copyrighted materials,\nand that the degree of memorization is tied to the frequency with which\npassages of those books appear on the web. The ability of these models to\nmemorize an unknown set of books complicates assessments of measurement\nvalidity for cultural analytics by contaminating test data; we show that models\nperform much better on memorized books than on non-memorized books for\ndownstream tasks. We argue that this supports a case for open models whose\ntraining data is known.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kent K. Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cramer_M/0/1/0/all/0/1\">Mackenzie Cramer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soni_S/0/1/0/all/0/1\">Sandeep Soni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamman_D/0/1/0/all/0/1\">David Bamman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Examining European Press Coverage of the Covid-19 No-Vax Movement: An NLP Framework. (arXiv:2305.00182v1 [cs.CL])","link":"http://arxiv.org/abs/2305.00182","description":"<p>This paper examines how the European press dealt with the no-vax reactions\nagainst the Covid-19 vaccine and the dis- and misinformation associated with\nthis movement. Using a curated dataset of 1786 articles from 19 European\nnewspapers on the anti-vaccine movement over a period of 22 months in\n2020-2021, we used Natural Language Processing techniques including topic\nmodeling, sentiment analysis, semantic relationship with word embeddings,\npolitical analysis, named entity recognition, and semantic networks, to\nunderstand the specific role of the European traditional press in the\ndisinformation ecosystem. The results of this multi-angle analysis demonstrate\nthat the European well-established press actively opposed a variety of hoaxes\nmainly spread on social media, and was critical of the anti-vax trend,\nregardless of the political orientation of the newspaper. This confirms the\nrelevance of studying the role of high-quality press in the disinformation\necosystem.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Barrio_D/0/1/0/all/0/1\">David Alonso del Barrio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gatica_Perez_D/0/1/0/all/0/1\">Daniel Gatica-Perez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Still no evidence for an effect of the proportion of non-native speakers on language complexity -- A response to Kauhanen, Einhaus & Walkden (2023). (arXiv:2305.00217v1 [cs.CL])","link":"http://arxiv.org/abs/2305.00217","description":"<p>In a recent paper published in the Journal of Language Evolution, Kauhanen,\nEinhaus &amp; Walkden (https://doi.org/10.1093/jole/lzad005, KEW) challenge the\nresults presented in one of my papers (Koplenig, Royal Society Open Science, 6,\n181274 (2019), https://doi.org/10.1098/rsos.181274), in which I tried to show\nthrough a series of statistical analyses that large numbers of L2 (second\nlanguage) speakers do not seem to affect the (grammatical or statistical)\ncomplexity of a language. To this end, I focus on the way in which the\nEthnologue assesses language status: a language is characterised as vehicular\nif, in addition to being used by L1 (first language) speakers, it should also\nhave a significant number of L2 users. KEW criticise both the use of\nvehicularity as a (binary) indicator of whether a language has a significant\nnumber of L2 users and the idea of imputing a zero proportion of L2 speakers to\nnon-vehicular languages whenever a direct estimate of that proportion is\nunavailable. While I recognise the importance of post-publication commentary on\npublished research, I show in this rejoinder that both points of criticism are\nexplicitly mentioned and analysed in my paper. In addition, I also comment on\nother points raised by KEW and demonstrate that both alternative analyses\noffered by KEW do not stand up to closer scrutiny.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koplenig_A/0/1/0/all/0/1\">Alexander Koplenig</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hierarchical Dialogue Understanding with Special Tokens and Turn-level Attention. (arXiv:2305.00262v1 [cs.CL])","link":"http://arxiv.org/abs/2305.00262","description":"<p>Compared with standard text, understanding dialogue is more challenging for\nmachines as the dynamic and unexpected semantic changes in each turn. To model\nsuch inconsistent semantics, we propose a simple but effective Hierarchical\nDialogue Understanding model, HiDialog. Specifically, we first insert multiple\nspecial tokens into a dialogue and propose the turn-level attention to learn\nturn embeddings hierarchically. Then, a heterogeneous graph module is leveraged\nto polish the learned embeddings. We evaluate our model on various dialogue\nunderstanding tasks including dialogue relation extraction, dialogue emotion\nrecognition, and dialogue act classification. Results show that our simple\napproach achieves state-of-the-art performance on all three tasks above. All\nour source code is publicly available at https://github.com/ShawX825/HiDialog.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Heng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_F/0/1/0/all/0/1\">Fuzhao Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yang You</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Cognitive Account of the Puzzle of Ideography. (arXiv:2305.00296v1 [q-bio.NC])","link":"http://arxiv.org/abs/2305.00296","description":"<p>In this commentary article to 'The Puzzle of Ideography' by Morin, we put\nforth a new cognitive account of the puzzle of ideography, that complements the\nstandardization account of Morin. Efficient standardization of spoken language\nis phenomenologically attributed to a modality effect coupled with chunking of\ncognitive representations, further aided by multi-sensory integration and the\nserialized nature of attention. These cognitive mechanisms are crucial for\nexplaining why languages dominate graphic codes for general-purpose human\ncommunication.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-bio/1/au:+Arsiwalla_X/0/1/0/all/0/1\">Xerxes D. Arsiwalla</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"POUF: Prompt-oriented unsupervised fine-tuning for large pre-trained models. (arXiv:2305.00350v1 [cs.LG])","link":"http://arxiv.org/abs/2305.00350","description":"<p>Through prompting, large-scale pre-trained models have become more expressive\nand powerful, gaining significant attention in recent years. Though these big\nmodels have zero-shot capabilities, in general, labeled data are still required\nto adapt them to downstream tasks. To overcome this critical limitation, we\npropose an unsupervised fine-tuning framework to directly fine-tune the model\nor prompt on the unlabeled target data. We demonstrate how to apply our method\nto both language-augmented vision and masked-language models by aligning the\ndiscrete distributions extracted from the prompts and target data. To verify\nour approach's applicability, we conduct extensive experiments on image\nclassification, sentiment analysis, and natural language inference tasks.\nAcross 13 image-related tasks and 15 language-related ones, the proposed\napproach achieves consistent improvements over the baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tanwisuth_K/0/1/0/all/0/1\">Korawat Tanwisuth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shujian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Huangjie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"S2abEL: A Dataset for Entity Linking from Scientific Tables. (arXiv:2305.00366v1 [cs.CL])","link":"http://arxiv.org/abs/2305.00366","description":"<p>Entity linking (EL) is the task of linking a textual mention to its\ncorresponding entry in a knowledge base, and is critical for many\nknowledge-intensive NLP applications. When applied to tables in scientific\npapers, EL is a step toward large-scale scientific knowledge bases that could\nenable advanced scientific question answering and analytics. We present the\nfirst dataset for EL in scientific tables. EL for scientific tables is\nespecially challenging because scientific knowledge bases can be very\nincomplete, and disambiguating table mentions typically requires understanding\nthe papers's tet in addition to the table. Our dataset, S2abEL, focuses on EL\nin machine learning results tables and includes hand-labeled cell types,\nattributed sources, and entity links from the PaperswithCode taxonomy for 8,429\ncells from 732 tables. We introduce a neural baseline method designed for EL on\nscientific tables containing many out-of-knowledge-base mentions, and show that\nit significantly outperforms a state-of-the-art generic table EL method. The\nbest baselines fall below human performance, and our analysis highlights\navenues for improvement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lou_Y/0/1/0/all/0/1\">Yuze Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuehl_B/0/1/0/all/0/1\">Bailey Kuehl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bransom_E/0/1/0/all/0/1\">Erin Bransom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feldman_S/0/1/0/all/0/1\">Sergey Feldman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naik_A/0/1/0/all/0/1\">Aakanksha Naik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Downey_D/0/1/0/all/0/1\">Doug Downey</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Constructing a Knowledge Graph from Textual Descriptions of Software Vulnerabilities in the National Vulnerability Database. (arXiv:2305.00382v1 [cs.CR])","link":"http://arxiv.org/abs/2305.00382","description":"<p>Knowledge graphs have shown promise for several cybersecurity tasks, such as\nvulnerability assessment and threat analysis. In this work, we present a new\nmethod for constructing a vulnerability knowledge graph from information in the\nNational Vulnerability Database (NVD). Our approach combines named entity\nrecognition (NER), relation extraction (RE), and entity prediction using a\ncombination of neural models, heuristic rules, and knowledge graph embeddings.\nWe demonstrate how our method helps to fix missing entities in knowledge graphs\nused for cybersecurity and evaluate the performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Host_A/0/1/0/all/0/1\">Anders M&#xf8;lmen H&#xf8;st</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lison_P/0/1/0/all/0/1\">Pierre Lison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moonen_L/0/1/0/all/0/1\">Leon Moonen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Building a Non-native Speech Corpus Featuring Chinese-English Bilingual Children: Compilation and Rationale. (arXiv:2305.00446v1 [cs.CL])","link":"http://arxiv.org/abs/2305.00446","description":"<p>This paper introduces a non-native speech corpus consisting of narratives\nfrom fifty 5- to 6-year-old Chinese-English children. Transcripts totaling 6.5\nhours of children taking a narrative comprehension test in English (L2) are\npresented, along with human-rated scores and annotations of grammatical and\npronunciation errors. The children also completed the parallel MAIN tests in\nChinese (L1) for reference purposes. For all tests we recorded audio and video\nwith our innovative self-developed remote collection methods. The video\nrecordings serve to mitigate the challenge of low intelligibility in L2\nnarratives produced by young children during the transcription process. This\ncorpus offers valuable resources for second language teaching and has the\npotential to enhance the overall performance of automatic speech recognition\n(ASR).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hung_H/0/1/0/all/0/1\">Hiuchung Hung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piske_T/0/1/0/all/0/1\">Thorsten Piske</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support. (arXiv:2305.00450v1 [cs.CL])","link":"http://arxiv.org/abs/2305.00450","description":"<p>There has been an increasing research interest in developing specialized\ndialogue systems that can offer mental health support. However, gathering\nlarge-scale and real-life multi-turn conversations for mental health support\nposes challenges due to the sensitivity of personal information, as well as the\ntime and cost involved. To address these issues, we introduce the SMILE\napproach, an inclusive language expansion technique that employs ChatGPT to\nextend public single-turn dialogues into multi-turn ones. Our research first\npresents a preliminary exploratory study that validates the effectiveness of\nthe SMILE approach. Furthermore, we conduct a comprehensive and systematic\ncontrastive analysis of datasets generated with and without the SMILE approach,\ndemonstrating that the SMILE method results in a large-scale, diverse, and\nclose-to-real-life multi-turn mental health support conversation corpus,\nincluding dialog topics, lexical and semantic features. Finally, we use the\ncollected corpus (SMILECHAT) to develop a more effective dialogue system that\noffers emotional support and constructive suggestions in multi-turn\nconversations for mental health support.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_H/0/1/0/all/0/1\">Huachuan Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Hongliang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Anqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1\">Zhenzhong Lan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How to enumerate trees from a context-free grammar. (arXiv:2305.00522v1 [cs.CL])","link":"http://arxiv.org/abs/2305.00522","description":"<p>I present a simple algorithm for enumerating the trees generated by a Context\nFree Grammar (CFG). The algorithm uses a pairing function to form a bijection\nbetween CFG derivations and natural numbers, so that trees can be uniquely\ndecoded from counting. This provides a general way to number expressions in\nnatural logical languages, and potentially can be extended to other\ncombinatorial problems. I also show how this algorithm may be generalized to\nmore general forms of derivation, including analogs of Lempel-Ziv coding on\ntrees.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Piantadosi_S/0/1/0/all/0/1\">Steven T. Piantadosi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multimodal Graph Transformer for Multimodal Question Answering. (arXiv:2305.00581v1 [cs.CV])","link":"http://arxiv.org/abs/2305.00581","description":"<p>Despite the success of Transformer models in vision and language tasks, they\noften learn knowledge from enormous data implicitly and cannot utilize\nstructured input data directly. On the other hand, structured learning\napproaches such as graph neural networks (GNNs) that integrate prior\ninformation can barely compete with Transformer models. In this work, we aim to\nbenefit from both worlds and propose a novel Multimodal Graph Transformer for\nquestion answering tasks that requires performing reasoning across multiple\nmodalities. We introduce a graph-involved plug-and-play quasi-attention\nmechanism to incorporate multimodal graph information, acquired from text and\nvisual data, to the vanilla self-attention as effective prior. In particular,\nwe construct the text graph, dense region graph, and semantic graph to generate\nadjacency matrices, and then compose them with input vision and language\nfeatures to perform downstream reasoning. Such a way of regularizing\nself-attention with graph information significantly improves the inferring\nability and helps align features from different modalities. We validate the\neffectiveness of Multimodal Graph Transformer over its Transformer baselines on\nGQA, VQAv2, and MultiModalQA datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xuehai He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model. (arXiv:2305.00586v1 [cs.CL])","link":"http://arxiv.org/abs/2305.00586","description":"<p>Pre-trained language models can be surprisingly adept at tasks they were not\nexplicitly trained on, but how they implement these capabilities is poorly\nunderstood. In this paper, we investigate the basic mathematical abilities\noften acquired by pre-trained language models. Concretely, we use mechanistic\ninterpretability techniques to explain the (limited) mathematical abilities of\nGPT-2 small. As a case study, we examine its ability to take in sentences such\nas \"The war lasted from the year 1732 to the year 17\", and predict valid\ntwo-digit end years (years &gt; 32). We first identify a circuit, a small subset\nof GPT-2 small's computational graph that computes this task's output. Then, we\nexplain the role of each circuit component, showing that GPT-2 small's final\nmulti-layer perceptrons boost the probability of end years greater than the\nstart year. Finally, we show that our circuit generalizes to other tasks,\nplaying a role in other greater-than scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hanna_M/0/1/0/all/0/1\">Michael Hanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_O/0/1/0/all/0/1\">Ollie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Variengien_A/0/1/0/all/0/1\">Alexandre Variengien</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reliable Gradient-free and Likelihood-free Prompt Tuning. (arXiv:2305.00593v1 [cs.LG])","link":"http://arxiv.org/abs/2305.00593","description":"<p>Due to privacy or commercial constraints, large pre-trained language models\n(PLMs) are often offered as black-box APIs. Fine-tuning such models to\ndownstream tasks is challenging because one can neither access the model's\ninternal representations nor propagate gradients through it. This paper\naddresses these challenges by developing techniques for adapting PLMs with only\nAPI access. Building on recent work on soft prompt tuning, we develop methods\nto tune the soft prompts without requiring gradient computation. Further, we\ndevelop extensions that in addition to not requiring gradients also do not need\nto access any internal representation of the PLM beyond the input embeddings.\nMoreover, instead of learning a single prompt, our methods learn a distribution\nover prompts allowing us to quantify predictive uncertainty. Ours is the first\nwork to consider uncertainty in prompts when only having API access to the PLM.\nFinally, through extensive experiments, we carefully vet the proposed methods\nand find them competitive with (and sometimes even improving on) gradient-based\napproaches with full access to the PLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_M/0/1/0/all/0/1\">Maohao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Soumya Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sattigeri_P/0/1/0/all/0/1\">Prasanna Sattigeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Subhro Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bu_Y/0/1/0/all/0/1\">Yuheng Bu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wornell_G/0/1/0/all/0/1\">Gregory Wornell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Low-Resourced Machine Translation for Senegalese Wolof Language. (arXiv:2305.00606v1 [cs.CL])","link":"http://arxiv.org/abs/2305.00606","description":"<p>Natural Language Processing (NLP) research has made great advancements in\nrecent years with major breakthroughs that have established new benchmarks.\nHowever, these advances have mainly benefited a certain group of languages\ncommonly referred to as resource-rich such as English and French. Majority of\nother languages with weaker resources are then left behind which is the case\nfor most African languages including Wolof. In this work, we present a parallel\nWolof/French corpus of 123,000 sentences on which we conducted experiments on\nmachine translation models based on Recurrent Neural Networks (RNN) in\ndifferent data configurations. We noted performance gains with the models\ntrained on subworded data as well as those trained on the French-English\nlanguage pair compared to those trained on the French-Wolof pair under the same\nexperimental conditions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mbaye_D/0/1/0/all/0/1\">Derguene Mbaye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diallo_M/0/1/0/all/0/1\">Moussa Diallo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diop_T/0/1/0/all/0/1\">Thierno Ibrahima Diop</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding. (arXiv:2305.00633v1 [cs.CL])","link":"http://arxiv.org/abs/2305.00633","description":"<p>We propose an effective prompting approach that integrates self-evaluation\nguidance through stochastic beam search. Our approach explores the reasoning\nsearch space using a well-calibrated automatic criterion. This enables an\nefficient search to produce higher-quality final predictions. With the\nself-evaluation guided stochastic beam search, we also balance the\nquality--diversity trade-off in the generation of reasoning chains. This allows\nour approach to adapt well with majority voting and surpass the corresponding\nCodex-backboned baselines by $6.34\\%$, $9.56\\%$, and $5.46\\%$ on the GSM8K,\nAQUA, and StrategyQA benchmarks, respectively, in few-shot accuracy. Analysis\nof our decompositional reasoning finds it pinpoints logic failures and leads to\nhigher consistency and robustness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuxi Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yiran Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1\">Min-Yen Kan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junxian He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1\">Qizhe Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Error correction and extraction in request dialogs. (arXiv:2004.04243v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2004.04243","description":"<p>We propose a dialog system utility component that gets the two last\nutterances of a user and can detect whether the last utterance is an error\ncorrection of the second last utterance. If yes, it corrects the second last\nutterance according to the error correction in the last utterance. In addition,\nthe proposed component outputs the extracted pairs of reparandum and repair\nentity. This component offers two advantages, learning the concept of\ncorrections to avoid collecting corrections for every new domain and extracting\nreparandum and repair pairs, which offers the possibility to learn out of it.\n</p>\n<p>For the error correction one sequence labeling and two sequence to sequence\napproaches are presented. For the error correction detection these three error\ncorrection approaches can also be used and in addition, we present a sequence\nclassification approach. One error correction detection and one error\ncorrection approach can be combined to a pipeline or the error correction\napproaches can be trained and used end-to-end to avoid two components. We\nmodified the EPIC-KITCHENS-100 dataset to evaluate the approaches for\ncorrecting entity phrases in request dialogs. For error correction detection\nand correction, we got an accuracy of 96.40 % on synthetic validation data and\nan accuracy of 77.85 % on human-created real-world test data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Constantin_S/0/1/0/all/0/1\">Stefan Constantin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1\">Alex Waibel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Toward Subgraph-Guided Knowledge Graph Question Generation with Graph Neural Networks. (arXiv:2004.06015v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2004.06015","description":"<p>Knowledge graph (KG) question generation (QG) aims to generate natural\nlanguage questions from KGs and target answers. Previous works mostly focus on\na simple setting which is to generate questions from a single KG triple. In\nthis work, we focus on a more realistic setting where we aim to generate\nquestions from a KG subgraph and target answers. In addition, most of previous\nworks built on either RNN-based or Transformer based models to encode a\nlinearized KG sugraph, which totally discards the explicit structure\ninformation of a KG subgraph. To address this issue, we propose to apply a\nbidirectional Graph2Seq model to encode the KG subgraph. Furthermore, we\nenhance our RNN decoder with node-level copying mechanism to allow directly\ncopying node attributes from the KG subgraph to the output question. Both\nautomatic and human evaluation results demonstrate that our model achieves new\nstate-of-the-art scores, outperforming existing methods by a significant margin\non two QG benchmarks. Experimental results also show that our QG model can\nconsistently benefit the Question Answering (QA) task as a mean of data\naugmentation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lingfei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaki_M/0/1/0/all/0/1\">Mohammed J. Zaki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone. (arXiv:2112.02418v4 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2112.02418","description":"<p>YourTTS brings the power of a multilingual approach to the task of zero-shot\nmulti-speaker TTS. Our method builds upon the VITS model and adds several novel\nmodifications for zero-shot multi-speaker and multilingual training. We\nachieved state-of-the-art (SOTA) results in zero-shot multi-speaker TTS and\nresults comparable to SOTA in zero-shot voice conversion on the VCTK dataset.\nAdditionally, our approach achieves promising results in a target language with\na single-speaker dataset, opening possibilities for zero-shot multi-speaker TTS\nand zero-shot voice conversion systems in low-resource languages. Finally, it\nis possible to fine-tune the YourTTS model with less than 1 minute of speech\nand achieve state-of-the-art results in voice similarity and with reasonable\nquality. This is important to allow synthesis for speakers with a very\ndifferent voice or recording characteristics from those seen during training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Casanova_E/0/1/0/all/0/1\">Edresson Casanova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_J/0/1/0/all/0/1\">Julian Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shulby_C/0/1/0/all/0/1\">Christopher Shulby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Junior_A/0/1/0/all/0/1\">Arnaldo Candido Junior</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golge_E/0/1/0/all/0/1\">Eren G&#xf6;lge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponti_M/0/1/0/all/0/1\">Moacir Antonelli Ponti</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Machine Explanations and Human Understanding. (arXiv:2202.04092v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2202.04092","description":"<p>Explanations are hypothesized to improve human understanding of machine\nlearning models and achieve a variety of desirable outcomes, ranging from model\ndebugging to enhancing human decision making. However, empirical studies have\nfound mixed and even negative results. An open question, therefore, is under\nwhat conditions explanations can improve human understanding and in what way.\nUsing adapted causal diagrams, we provide a formal characterization of the\ninterplay between machine explanations and human understanding, and show how\nhuman intuitions play a central role in enabling human understanding.\nSpecifically, we identify three core concepts of interest that cover all\nexisting quantitative measures of understanding in the context of human-AI\ndecision making: task decision boundary, model decision boundary, and model\nerror. Our key result is that without assumptions about task-specific\nintuitions, explanations may potentially improve human understanding of model\ndecision boundary, but they cannot improve human understanding of task decision\nboundary or model error. To achieve complementary human-AI performance, we\narticulate possible ways on how explanations need to work with human\nintuitions. For instance, human intuitions about the relevance of features\n(e.g., education is more important than age in predicting a person's income)\ncan be critical in detecting model error. We validate the importance of human\nintuitions in shaping the outcome of machine explanations with empirical\nhuman-subject studies. Overall, our work provides a general framework along\nwith actionable implications for future algorithmic development and empirical\nexperiments of machine explanations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chacha Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Amit Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chenhao Tan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hierarchical Softmax for End-to-End Low-resource Multilingual Speech Recognition. (arXiv:2204.03855v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2204.03855","description":"<p>Low-resource speech recognition has been long-suffering from insufficient\ntraining data. In this paper, we propose an approach that leverages neighboring\nlanguages to improve low-resource scenario performance, founded on the\nhypothesis that similar linguistic units in neighboring languages exhibit\ncomparable term frequency distributions, which enables us to construct a\nHuffman tree for performing multilingual hierarchical Softmax decoding. This\nhierarchical structure enables cross-lingual knowledge sharing among similar\ntokens, thereby enhancing low-resource training outcomes. Empirical analyses\ndemonstrate that our method is effective in improving the accuracy and\nefficiency of low-resource speech recognition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Liu_Q/0/1/0/all/0/1\">Qianying Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gong_Z/0/1/0/all/0/1\">Zhuo Gong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Z/0/1/0/all/0/1\">Zhengdong Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1\">Yuhang Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1\">Sheng Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ding_C/0/1/0/all/0/1\">Chenchen Ding</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Minematsu_N/0/1/0/all/0/1\">Nobuaki Minematsu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_H/0/1/0/all/0/1\">Hao Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_F/0/1/0/all/0/1\">Fei Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chu_C/0/1/0/all/0/1\">Chenhui Chu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kurohashi_S/0/1/0/all/0/1\">Sadao Kurohashi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Meta Self-Refinement for Robust Learning with Weak Supervision. (arXiv:2205.07290v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.07290","description":"<p>Training deep neural networks (DNNs) under weak supervision has attracted\nincreasing research attention as it can significantly reduce the annotation\ncost. However, labels from weak supervision can be noisy, and the high capacity\nof DNNs enables them to easily overfit the label noise, resulting in poor\ngeneralization. Recent methods leverage self-training to build noise-resistant\nmodels, in which a teacher trained under weak supervision is used to provide\nhighly confident labels for teaching the students. Nevertheless, the teacher\nderived from such frameworks may have fitted a substantial amount of noise and\ntherefore produce incorrect pseudo-labels with high confidence, leading to\nsevere error propagation. In this work, we propose Meta Self-Refinement (MSR),\na noise-resistant learning framework, to effectively combat label noise from\nweak supervision. Instead of relying on a fixed teacher trained with noisy\nlabels, we encourage the teacher to refine its pseudo-labels. At each training\nstep, MSR performs a meta gradient descent on the current mini-batch to\nmaximize the student performance on a clean validation set. Extensive\nexperimentation on eight NLP benchmarks demonstrates that MSR is robust against\nlabel noise in all settings and outperforms state-of-the-art methods by up to\n11.4% in accuracy and 9.26% in F1 score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1\">Dawei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xiaoyu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hedderich_M/0/1/0/all/0/1\">Michael A. Hedderich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klakow_D/0/1/0/all/0/1\">Dietrich Klakow</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Offline RL for Natural Language Generation with Implicit Language Q Learning. (arXiv:2206.11871v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.11871","description":"<p>Large language models distill broad knowledge from text corpora. However,\nthey can be inconsistent when it comes to completing user specified tasks. This\nissue can be addressed by finetuning such models via supervised learning on\ncurated datasets, or via reinforcement learning. In this work, we propose a\nnovel offline RL method, implicit language Q-learning (ILQL), designed for use\non language models, that combines both the flexible utility maximization\nframework of RL algorithms with the ability of supervised learning to leverage\npreviously collected data, as well as its simplicity and stability. Our method\nemploys a combination of value conservatism alongside an implicit dataset\nsupport constraint in learning value functions, which are then used to guide\nlanguage model generations towards maximizing user-specified utility functions.\nIn addition to empirically validating ILQL, we present a detailed empirical\nanalysis of situations where offline RL can be useful in natural language\ngeneration settings, demonstrating how it can be a more effective utility\noptimizer than prior approaches for end-to-end dialogue, and how it can\neffectively optimize high variance reward functions based on subjective\njudgement, such as whether to label a comment as toxic or not.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Snell_C/0/1/0/all/0/1\">Charlie Snell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kostrikov_I/0/1/0/all/0/1\">Ilya Kostrikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yi Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Mengjiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conditional Generation with a Question-Answering Blueprint. (arXiv:2207.00397v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2207.00397","description":"<p>The ability to convey relevant and faithful information is critical for many\ntasks in conditional generation and yet remains elusive for neural seq-to-seq\nmodels whose outputs often reveal hallucinations and fail to correctly cover\nimportant details. In this work, we advocate planning as a useful intermediate\nrepresentation for rendering conditional generation less opaque and more\ngrounded. Our work proposes a new conceptualization of text plans as a sequence\nof question-answer (QA) pairs. We enhance existing datasets (e.g., for\nsummarization) with a QA blueprint operating as a proxy for both content\nselection (i.e.,~what to say) and planning (i.e.,~in what order). We obtain\nblueprints automatically by exploiting state-of-the-art question generation\ntechnology and convert input-output pairs into input-blueprint-output tuples.\nWe develop Transformer-based models, each varying in how they incorporate the\nblueprint in the generated output (e.g., as a global plan or iteratively).\nEvaluation across metrics and datasets demonstrates that blueprint models are\nmore factual than alternatives which do not resort to planning and allow\ntighter control of the generation output.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Narayan_S/0/1/0/all/0/1\">Shashi Narayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maynez_J/0/1/0/all/0/1\">Joshua Maynez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amplayo_R/0/1/0/all/0/1\">Reinald Kim Amplayo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganchev_K/0/1/0/all/0/1\">Kuzman Ganchev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Louis_A/0/1/0/all/0/1\">Annie Louis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huot_F/0/1/0/all/0/1\">Fantine Huot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandholm_A/0/1/0/all/0/1\">Anders Sandholm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1\">Dipanjan Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1\">Mirella Lapata</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Readability Controllable Biomedical Document Summarization. (arXiv:2210.04705v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.04705","description":"<p>Different from general documents, it is recognised that the ease with which\npeople can understand a biomedical text is eminently varied, owing to the\nhighly technical nature of biomedical documents and the variance of readers'\ndomain knowledge. However, existing biomedical document summarization systems\nhave paid little attention to readability control, leaving users with summaries\nthat are incompatible with their levels of expertise. In recognition of this\nurgent demand, we introduce a new task of readability controllable\nsummarization for biomedical documents, which aims to recognise users'\nreadability demands and generate summaries that better suit their needs:\ntechnical summaries for experts and plain language summaries (PLS) for laymen.\nTo establish this task, we construct a corpus consisting of biomedical papers\nwith technical summaries and PLSs written by the authors, and benchmark\nmultiple advanced controllable abstractive and extractive summarization models\nbased on pre-trained language models (PLMs) with prevalent controlling and\ngeneration techniques. Moreover, we propose a novel masked language model (MLM)\nbased metric and its variant to effectively evaluate the readability\ndiscrepancy between lay and technical summaries. Experimental results from\nautomated and human evaluations show that though current control techniques\nallow for a certain degree of readability adjustment during generation, the\nperformance of existing controllable summarization methods is far from\ndesirable in this task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zheheng Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1\">Qianqian Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ananiadou_S/0/1/0/all/0/1\">Sophia Ananiadou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Representation Distillation with Contrastive Learning. (arXiv:2210.05033v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.05033","description":"<p>Multilingual sentence representations from large models encode semantic\ninformation from two or more languages and can be used for different\ncross-lingual information retrieval and matching tasks. In this paper, we\nintegrate contrastive learning into multilingual representation distillation\nand use it for quality estimation of parallel sentences (i.e., find\nsemantically similar sentences that can be used as translations of each other).\nWe validate our approach with multilingual similarity search and corpus\nfiltering tasks. Experiments across different low-resource languages show that\nour method greatly outperforms previous sentence encoders such as LASER,\nLASER3, and LaBSE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1\">Weiting Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heffernan_K/0/1/0/all/0/1\">Kevin Heffernan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwenk_H/0/1/0/all/0/1\">Holger Schwenk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koehn_P/0/1/0/all/0/1\">Philipp Koehn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformer-based Text Classification on Unified Bangla Multi-class Emotion Corpus. (arXiv:2210.06405v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.06405","description":"<p>Because of its importance in studying people's thoughts on various Web 2.0\nservices, emotion classification (EC) is an important undertaking. Existing\nresearch, on the other hand, is mostly focused on the English language, with\nlittle work on low-resource languages. Though sentiment analysis, particularly\nthe EC in English, has received a lot of attention in recent years, little\nstudy has been done in the context of Bangla, one of the world's most widely\nspoken languages. We propose a complete set of approaches for identifying and\nextracting emotions from Bangla texts in this research. We provide a Bangla\nemotion classifier for six classes (anger, disgust, fear, joy, sadness, and\nsurprise) from Bangla words, using transformer-based models which exhibit\nphenomenal results in recent days, especially for high resource languages. The\n\"Unified Bangla Multi-class Emotion Corpus (UBMEC)\" is used to assess the\nperformance of our models. UBMEC was created by combining two previously\nreleased manually labeled datasets of Bangla comments on 6-emotion classes with\nfresh manually tagged Bangla comments created by us. The corpus dataset and\ncode we used in this work is publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sourav_M/0/1/0/all/0/1\">Md Sakib Ullah Sourav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huidong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MiniALBERT: Model Distillation via Parameter-Efficient Recursive Transformers. (arXiv:2210.06425v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.06425","description":"<p>Pre-trained Language Models (LMs) have become an integral part of Natural\nLanguage Processing (NLP) in recent years, due to their superior performance in\ndownstream applications. In spite of this resounding success, the usability of\nLMs is constrained by computational and time complexity, along with their\nincreasing size; an issue that has been referred to as `overparameterisation'.\nDifferent strategies have been proposed in the literature to alleviate these\nproblems, with the aim to create effective compact models that nearly match the\nperformance of their bloated counterparts with negligible performance losses.\nOne of the most popular techniques in this area of research is model\ndistillation. Another potent but underutilised technique is cross-layer\nparameter sharing. In this work, we combine these two strategies and present\nMiniALBERT, a technique for converting the knowledge of fully parameterised LMs\n(such as BERT) into a compact recursive student. In addition, we investigate\nthe application of bottleneck adapters for layer-wise adaptation of our\nrecursive student, and also explore the efficacy of adapter tuning for\nfine-tuning of compact models. We test our proposed models on a number of\ngeneral and biomedical NLP tasks to demonstrate their viability and compare\nthem with the state-of-the-art and other existing compact models. All the codes\nused in the experiments are available at\nhttps://github.com/nlpie-research/MiniALBERT. Our pre-trained compact models\ncan be accessed from https://huggingface.co/nlpie.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nouriborji_M/0/1/0/all/0/1\">Mohammadmahdi Nouriborji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohanian_O/0/1/0/all/0/1\">Omid Rohanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kouchaki_S/0/1/0/all/0/1\">Samaneh Kouchaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1\">David A. Clifton</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Iterative Document-level Information Extraction via Imitation Learning. (arXiv:2210.06600v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.06600","description":"<p>We present a novel iterative extraction model, IterX, for extracting complex\nrelations, or templates (i.e., N-tuples representing a mapping from named slots\nto spans of text) within a document. Documents may feature zero or more\ninstances of a template of any given type, and the task of template extraction\nentails identifying the templates in a document and extracting each template's\nslot values. Our imitation learning approach casts the problem as a Markov\ndecision process (MDP), and relieves the need to use predefined template orders\nto train an extractor. It leads to state-of-the-art results on two established\nbenchmarks -- 4-ary relation extraction on SciREX and template extraction on\nMUC-4 -- as well as a strong baseline on the new BETTER Granular task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunmo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gantt_W/0/1/0/all/0/1\">William Gantt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_W/0/1/0/all/0/1\">Weiwei Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tongfei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_A/0/1/0/all/0/1\">Aaron Steven White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Segmentation Approaches for Neural Machine Translation of Code-Switched Egyptian Arabic-English Text. (arXiv:2210.06990v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.06990","description":"<p>Data sparsity is one of the main challenges posed by code-switching (CS),\nwhich is further exacerbated in the case of morphologically rich languages. For\nthe task of machine translation (MT), morphological segmentation has proven\nsuccessful in alleviating data sparsity in monolingual contexts; however, it\nhas not been investigated for CS settings. In this paper, we study the\neffectiveness of different segmentation approaches on MT performance, covering\nmorphology-based and frequency-based segmentation techniques. We experiment on\nMT from code-switched Arabic-English to English. We provide detailed analysis,\nexamining a variety of conditions, such as data size and sentences with\ndifferent degrees of CS. Empirical results show that morphology-aware\nsegmenters perform the best in segmentation tasks but under-perform in MT.\nNevertheless, we find that the choice of the segmentation setup to use for MT\nis highly dependent on the data size. For extreme low-resource scenarios, a\ncombination of frequency and morphology-based segmentations is shown to perform\nthe best. For more resourced settings, such a combination does not bring\nsignificant improvements over the use of frequency-based segmentation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gaser_M/0/1/0/all/0/1\">Marwa Gaser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mager_M/0/1/0/all/0/1\">Manuel Mager</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamed_I/0/1/0/all/0/1\">Injy Hamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habash_N/0/1/0/all/0/1\">Nizar Habash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdennadher_S/0/1/0/all/0/1\">Slim Abdennadher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_N/0/1/0/all/0/1\">Ngoc Thang Vu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Grammatical Error Correction: A Survey of the State of the Art. (arXiv:2211.05166v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.05166","description":"<p>Grammatical Error Correction (GEC) is the task of automatically detecting and\ncorrecting errors in text. The task not only includes the correction of\ngrammatical errors, such as missing prepositions and mismatched subject-verb\nagreement, but also orthographic and semantic errors, such as misspellings and\nword choice errors respectively. The field has seen significant progress in the\nlast decade, motivated in part by a series of five shared tasks, which drove\nthe development of rule-based methods, statistical classifiers, statistical\nmachine translation, and finally neural machine translation systems which\nrepresent the current dominant state of the art. In this survey paper, we\ncondense the field into a single article and first outline some of the\nlinguistic challenges of the task, introduce the most popular datasets that are\navailable to researchers (for both English and other languages), and summarise\nthe various methods and techniques that have been developed with a particular\nfocus on artificial error generation. We next describe the many different\napproaches to evaluation as well as concerns surrounding metric reliability,\nespecially in relation to subjective human judgements, before concluding with\nan overview of recent progress and suggestions for future work and remaining\nchallenges. We hope that this survey will serve as comprehensive resource for\nresearchers who are new to the field or who want to be kept apprised of recent\ndevelopments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bryant_C/0/1/0/all/0/1\">Christopher Bryant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zheng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qorib_M/0/1/0/all/0/1\">Muhammad Reza Qorib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_H/0/1/0/all/0/1\">Hannan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_H/0/1/0/all/0/1\">Hwee Tou Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Briscoe_T/0/1/0/all/0/1\">Ted Briscoe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SceneGATE: Scene-Graph based co-Attention networks for TExt visual question answering. (arXiv:2212.08283v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2212.08283","description":"<p>Most TextVQA approaches focus on the integration of objects, scene texts and\nquestion words by a simple transformer encoder. But this fails to capture the\nsemantic relations between different modalities. The paper proposes a Scene\nGraph based co-Attention Network (SceneGATE) for TextVQA, which reveals the\nsemantic relations among the objects, Optical Character Recognition (OCR)\ntokens and the question words. It is achieved by a TextVQA-based scene graph\nthat discovers the underlying semantics of an image. We created a\nguided-attention module to capture the intra-modal interplay between the\nlanguage and the vision as a guidance for inter-modal interactions. To make\nexplicit teaching of the relations between the two modalities, we proposed and\nintegrated two attention modules, namely a scene graph-based semantic\nrelation-aware attention and a positional relation-aware attention. We\nconducted extensive experiments on two benchmark datasets, Text-VQA and ST-VQA.\nIt is shown that our SceneGATE method outperformed existing ones because of the\nscene graph and its attention modules.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cao_F/0/1/0/all/0/1\">Feiqi Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Siwen Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nunez_F/0/1/0/all/0/1\">Felipe Nunez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zean Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_J/0/1/0/all/0/1\">Josiah Poon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Caren Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dataless Knowledge Fusion by Merging Weights of Language Models. (arXiv:2212.09849v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09849","description":"<p>Fine-tuning pre-trained language models has become the prevalent paradigm for\nbuilding downstream NLP models. Oftentimes fine-tuned models are readily\navailable but their training data is not, due to data privacy or intellectual\nproperty concerns. This creates a barrier to fusing knowledge across individual\nmodels to yield a better single model. In this paper, we study the problem of\nmerging individual models built on different training data sets to obtain a\nsingle model that performs well both across all data set domains and can\ngeneralize on out-of-domain data. We propose a dataless knowledge fusion method\nthat merges models in their parameter space, guided by weights that minimize\nprediction differences between the merged model and the individual models. Over\na battery of evaluation settings, we show that the proposed method\nsignificantly outperforms baselines such as Fisher-weighted averaging or model\nensembling. Further, we find that our method is a promising alternative to\nmulti-task learning that can preserve or sometimes improve over the individual\nmodels without access to the training data. Finally, model merging is more\nefficient than training a multi-task model, thus making it applicable to a\nwider set of scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xisen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preotiuc_Pietro_D/0/1/0/all/0/1\">Daniel Preotiuc-Pietro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Pengxiang Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hungry Hungry Hippos: Towards Language Modeling with State Space Models. (arXiv:2212.14052v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2212.14052","description":"<p>State space models (SSMs) have demonstrated state-of-the-art sequence\nmodeling performance in some modalities, but underperform attention in language\nmodeling. Moreover, despite scaling nearly linearly in sequence length instead\nof quadratically, SSMs are still slower than Transformers due to poor hardware\nutilization. In this paper, we make progress on understanding the expressivity\ngap between SSMs and attention in language modeling, and on reducing the\nhardware barrier between SSMs and attention. First, we use synthetic language\nmodeling tasks to understand the gap between SSMs and attention. We find that\nexisting SSMs struggle with two capabilities: recalling earlier tokens in the\nsequence and comparing tokens across the sequence. To understand the impact on\nlanguage modeling, we propose a new SSM layer, H3, that is explicitly designed\nfor these abilities. H3 matches attention on the synthetic languages and comes\nwithin 0.4 PPL of Transformers on OpenWebText. Furthermore, a hybrid\n125M-parameter H3-attention model that retains two attention layers\nsurprisingly outperforms Transformers on OpenWebText by 1.0 PPL. Next, to\nimprove the efficiency of training SSMs on modern hardware, we propose\nFlashConv. FlashConv uses a fused block FFT algorithm to improve efficiency on\nsequences up to 8K, and introduces a novel state passing algorithm that\nexploits the recurrent properties of SSMs to scale to longer sequences.\nFlashConv yields 2$\\times$ speedup on the long-range arena benchmark and allows\nhybrid language models to generate text 2.4$\\times$ faster than Transformers.\nUsing FlashConv, we scale hybrid H3-attention language models up to 2.7B\nparameters on the Pile and find promising initial results, achieving lower\nperplexity than Transformers and outperforming Transformers in zero- and\nfew-shot learning on a majority of tasks in the SuperGLUE benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_D/0/1/0/all/0/1\">Daniel Y. Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dao_T/0/1/0/all/0/1\">Tri Dao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saab_K/0/1/0/all/0/1\">Khaled K. Saab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomas_A/0/1/0/all/0/1\">Armin W. Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudra_A/0/1/0/all/0/1\">Atri Rudra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1\">Christopher R&#xe9;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-Aspect Explainable Inductive Relation Prediction by Sentence Transformer. (arXiv:2301.01664v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.01664","description":"<p>Recent studies on knowledge graphs (KGs) show that path-based methods\nempowered by pre-trained language models perform well in the provision of\ninductive and explainable relation predictions. In this paper, we introduce the\nconcepts of relation path coverage and relation path confidence to filter out\nunreliable paths prior to model training to elevate the model performance.\nMoreover, we propose Knowledge Reasoning Sentence Transformer (KRST) to predict\ninductive relations in KGs. KRST is designed to encode the extracted reliable\npaths in KGs, allowing us to properly cluster paths and provide multi-aspect\nexplanations. We conduct extensive experiments on three real-world datasets.\nThe experimental results show that compared to SOTA models, KRST achieves the\nbest performance in most transductive and inductive test cases (4 of 6), and in\n11 of 12 few-shot test cases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1\">Zhixiang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Lizhen Cui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visual Semantic Relatedness Dataset for Image Captioning. (arXiv:2301.08784v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.08784","description":"<p>Modern image captioning system relies heavily on extracting knowledge from\nimages to capture the concept of a static story. In this paper, we propose a\ntextual visual context dataset for captioning, in which the publicly available\ndataset COCO Captions (Lin et al., 2014) has been extended with information\nabout the scene (such as objects in the image). Since this information has a\ntextual form, it can be used to leverage any NLP task, such as text similarity\nor semantic relation methods, into captioning systems, either as an end-to-end\ntraining strategy or a post-processing based approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sabir_A/0/1/0/all/0/1\">Ahmed Sabir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreno_Noguer_F/0/1/0/all/0/1\">Francesc Moreno-Noguer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padro_L/0/1/0/all/0/1\">Llu&#xed;s Padr&#xf3;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Qualitative Analysis of a Graph Transformer Approach to Addressing Hate Speech: Adapting to Dynamically Changing Content. (arXiv:2301.10871v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2301.10871","description":"<p>Our work advances an approach for predicting hate speech in social media,\ndrawing out the critical need to consider the discussions that follow a post to\nsuccessfully detect when hateful discourse may arise. Using graph transformer\nnetworks, coupled with modelling attention and BERT-level natural language\nprocessing, our approach can capture context and anticipate upcoming\nanti-social behaviour. In this paper, we offer a detailed qualitative analysis\nof this solution for hate speech detection in social networks, leading to\ninsights into where the method has the most impressive outcomes in comparison\nwith competitors and identifying scenarios where there are challenges to\nachieving ideal performance. Included is an exploration of the kinds of posts\nthat permeate social media today, including the use of hateful images. This\nsuggests avenues for extending our model to be more comprehensive. A key\ninsight is that the focus on reasoning about the concept of context positions\nus well to be able to support multi-modal analysis of online posts. We conclude\nwith a reflection on how the problem we are addressing relates especially well\nto the theme of dynamic change, a critical concern for all AI solutions for\nsocial impact. We also comment briefly on how mental health well-being can be\nadvanced with our work, through curated content attuned to the extent of hate\nin posts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hebert_L/0/1/0/all/0/1\">Liam Hebert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hong Yi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_R/0/1/0/all/0/1\">Robin Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golab_L/0/1/0/all/0/1\">Lukasz Golab</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages. (arXiv:2302.08956v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.08956","description":"<p>Africa is home to over 2000 languages from over six language families and has\nthe highest linguistic diversity among all continents. This includes 75\nlanguages with at least one million speakers each. Yet, there is little NLP\nresearch conducted on African languages. Crucial in enabling such research is\nthe availability of high-quality annotated datasets. In this paper, we\nintroduce AfriSenti, which consists of 14 sentiment datasets of 110,000+ tweets\nin 14 African languages (Amharic, Algerian Arabic, Hausa, Igbo, Kinyarwanda,\nMoroccan Arabic, Mozambican Portuguese, Nigerian Pidgin, Oromo, Swahili,\nTigrinya, Twi, Xitsonga, and Yor\\`ub\\'a) from four language families annotated\nby native speakers. The data is used in SemEval 2023 Task 12, the first\nAfro-centric SemEval shared task. We describe the data collection methodology,\nannotation process, and related challenges when curating each of the datasets.\nWe conduct experiments with different sentiment classification baselines and\ndiscuss their usefulness. We hope AfriSenti enables new work on\nunder-represented languages. The dataset is available at\nhttps://github.com/afrisenti-semeval/afrisent-semeval-2023 and can also be\nloaded as a huggingface datasets\n(https://huggingface.co/datasets/shmuhammad/AfriSenti).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Muhammad_S/0/1/0/all/0/1\">Shamsuddeen Hassan Muhammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdulmumin_I/0/1/0/all/0/1\">Idris Abdulmumin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayele_A/0/1/0/all/0/1\">Abinew Ali Ayele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ousidhoum_N/0/1/0/all/0/1\">Nedjma Ousidhoum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1\">David Ifeoluwa Adelani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yimam_S/0/1/0/all/0/1\">Seid Muhie Yimam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_I/0/1/0/all/0/1\">Ibrahim Sa&#x27;id Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beloucif_M/0/1/0/all/0/1\">Meriem Beloucif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1\">Saif M. Mohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1\">Sebastian Ruder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hourrane_O/0/1/0/all/0/1\">Oumaima Hourrane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brazdil_P/0/1/0/all/0/1\">Pavel Brazdil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_F/0/1/0/all/0/1\">Felermino D&#xe1;rio M&#xe1;rio Ant&#xf3;nio Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+David_D/0/1/0/all/0/1\">Davis David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osei_S/0/1/0/all/0/1\">Salomey Osei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bello_B/0/1/0/all/0/1\">Bello Shehu Bello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahim_F/0/1/0/all/0/1\">Falalu Ibrahim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gwadabe_T/0/1/0/all/0/1\">Tajuddeen Gwadabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rutunda_S/0/1/0/all/0/1\">Samuel Rutunda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belay_T/0/1/0/all/0/1\">Tadesse Belay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messelle_W/0/1/0/all/0/1\">Wendimu Baye Messelle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balcha_H/0/1/0/all/0/1\">Hailu Beshada Balcha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chala_S/0/1/0/all/0/1\">Sisay Adugna Chala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gebremichael_H/0/1/0/all/0/1\">Hagos Tesfahun Gebremichael</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Opoku_B/0/1/0/all/0/1\">Bernard Opoku</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arthur_S/0/1/0/all/0/1\">Steven Arthur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT. (arXiv:2302.09419v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2302.09419","description":"<p>Pretrained Foundation Models (PFMs) are regarded as the foundation for\nvarious downstream tasks with different data modalities. A PFM (e.g., BERT,\nChatGPT, and GPT-4) is trained on large-scale data which provides a reasonable\nparameter initialization for a wide range of downstream applications. BERT\nlearns bidirectional encoder representations from Transformers, which are\ntrained on large datasets as contextual language models. Similarly, the\ngenerative pretrained transformer (GPT) method employs Transformers as the\nfeature extractor and is trained using an autoregressive paradigm on large\ndatasets. Recently, ChatGPT shows promising success on large language models,\nwhich applies an autoregressive language model with zero shot or few shot\nprompting. The remarkable achievements of PFM have brought significant\nbreakthroughs to various fields of AI. Numerous studies have proposed different\nmethods, raising the demand for an updated survey. This study provides a\ncomprehensive review of recent research advancements, challenges, and\nopportunities for PFMs in text, image, graph, as well as other data modalities.\nThe review covers the basic components and existing pretraining methods used in\nnatural language processing, computer vision, and graph learning. Additionally,\nit explores advanced PFMs used for different data modalities and unified PFMs\nthat consider data quality and quantity. The review also discusses research\nrelated to the fundamentals of PFMs, such as model efficiency and compression,\nsecurity, and privacy. Finally, the study provides key implications, future\nresearch directions, challenges, and open problems in the field of PFMs.\nOverall, this survey aims to shed light on the research of the PFMs on\nscalability, security, logical reasoning ability, cross-domain learning\nability, and the user-friendly interactive ability for artificial general\nintelligence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Ce Zhou</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qian Li</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chen Li</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jun Yu</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yixin Liu</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guangjing Wang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kai Zhang</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Ji_C/0/1/0/all/0/1\">Cheng Ji</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Q/0/1/0/all/0/1\">Qiben Yan</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Lifang He</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianxin Li</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jia Wu</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziwei Liu</a> (5), <a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pengtao Xie</a> (6), <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a> (7), <a href=\"http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1\">Jian Pei</a> (8), <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a> (9), <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Lichao Sun</a> (3) ((1) Michigan State University, (2) Beihang University, (3) Lehigh University, (4) Macquarie University, (5) Nanyang Technological University, (6) University of California San Diego, (7) Salesforce AI Research, (8) Duke University, (9) University of Illinois at Chicago)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extrapolative Controlled Sequence Generation via Iterative Refinement. (arXiv:2303.04562v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2303.04562","description":"<p>We study the problem of extrapolative controlled generation, i.e., generating\nsequences with attribute values beyond the range seen in training. This task is\nof significant importance in automated design, especially drug discovery, where\nthe goal is to design novel proteins that are \\textit{better} (e.g., more\nstable) than existing sequences. Thus, by definition, the target sequences and\ntheir attribute values are out of the training distribution, posing challenges\nto existing methods that aim to directly generate the target sequence. Instead,\nin this work, we propose Iterative Controlled Extrapolation (ICE) which\niteratively makes local edits to a sequence to enable extrapolation. We train\nthe model on synthetically generated sequence pairs that demonstrate small\nimprovement in the attribute value. Results on one natural language task\n(sentiment analysis) and two protein engineering tasks (ACE2 stability and AAV\nfitness) show that ICE considerably outperforms state-of-the-art approaches\ndespite its simplicity. Our code and models are available at:\nhttps://github.com/vishakhpk/iter-extrapolation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Padmakumar_V/0/1/0/all/0/1\">Vishakh Padmakumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1\">Richard Yuanzhe Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">He He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parikh_A/0/1/0/all/0/1\">Ankur P. Parikh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Clinical BERTScore: An Improved Measure of Automatic Speech Recognition Performance in Clinical Settings. (arXiv:2303.05737v4 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2303.05737","description":"<p>Automatic Speech Recognition (ASR) in medical contexts has the potential to\nsave time, cut costs, increase report accuracy, and reduce physician burnout.\nHowever, the healthcare industry has been slower to adopt this technology, in\npart due to the importance of avoiding medically-relevant transcription\nmistakes. In this work, we present the Clinical BERTScore (CBERTScore), an ASR\nmetric that penalizes clinically-relevant mistakes more than others. We\ndemonstrate that this metric more closely aligns with clinician preferences on\nmedical sentences as compared to other metrics (WER, BLUE, METEOR, etc),\nsometimes by wide margins. We collect a benchmark of 18 clinician preferences\non 149 realistic medical sentences called the Clinician Transcript Preference\nbenchmark (CTP) and make it publicly available for the community to further\ndevelop clinically-aware ASR metrics. To our knowledge, this is the first\npublic dataset of its kind. We demonstrate that CBERTScore more closely matches\nwhat clinicians prefer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Shor_J/0/1/0/all/0/1\">Joel Shor</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bi_R/0/1/0/all/0/1\">Ruyue Agnes Bi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Venugopalan_S/0/1/0/all/0/1\">Subhashini Venugopalan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ibara_S/0/1/0/all/0/1\">Steven Ibara</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Goldenberg_R/0/1/0/all/0/1\">Roman Goldenberg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rivlin_E/0/1/0/all/0/1\">Ehud Rivlin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Could a Large Language Model be Conscious?. (arXiv:2303.07103v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2303.07103","description":"<p>There has recently been widespread discussion of whether large language\nmodels might be sentient or conscious. Should we take this idea seriously? I\nwill break down the strongest reasons for and against. Given mainstream\nassumptions in the science of consciousness, there are significant obstacles to\nconsciousness in current models: for example, their lack of recurrent\nprocessing, a global workspace, and unified agency. At the same time, it is\nquite possible that these obstacles will be overcome in the next decade or so.\nI conclude that while it is somewhat unlikely that current large language\nmodels are conscious, we should take seriously the possibility that successors\nto large language models may be conscious in the not-too-distant future.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chalmers_D/0/1/0/all/0/1\">David J. Chalmers</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SemEval-2023 Task 12: Sentiment Analysis for African Languages (AfriSenti-SemEval). (arXiv:2304.06845v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.06845","description":"<p>We present the first Africentric SemEval Shared task, Sentiment Analysis for\nAfrican Languages (AfriSenti-SemEval) - The dataset is available at\nhttps://github.com/afrisenti-semeval/afrisent-semeval-2023. AfriSenti-SemEval\nis a sentiment classification challenge in 14 African languages: Amharic,\nAlgerian Arabic, Hausa, Igbo, Kinyarwanda, Moroccan Arabic, Mozambican\nPortuguese, Nigerian Pidgin, Oromo, Swahili, Tigrinya, Twi, Xitsonga, and\nYor\\`ub\\'a (Muhammad et al., 2023), using data labeled with 3 sentiment\nclasses. We present three subtasks: (1) Task A: monolingual classification,\nwhich received 44 submissions; (2) Task B: multilingual classification, which\nreceived 32 submissions; and (3) Task C: zero-shot classification, which\nreceived 34 submissions. The best performance for tasks A and B was achieved by\nNLNDE team with 71.31 and 75.06 weighted F1, respectively. UCAS-IIE-NLP\nachieved the best average score for task C with 58.15 weighted F1. We describe\nthe various approaches adopted by the top 10 systems and their approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Muhammad_S/0/1/0/all/0/1\">Shamsuddeen Hassan Muhammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdulmumin_I/0/1/0/all/0/1\">Idris Abdulmumin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yimam_S/0/1/0/all/0/1\">Seid Muhie Yimam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1\">David Ifeoluwa Adelani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_I/0/1/0/all/0/1\">Ibrahim Sa&#x27;id Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ousidhoum_N/0/1/0/all/0/1\">Nedjma Ousidhoum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayele_A/0/1/0/all/0/1\">Abinew Ayele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1\">Saif M. Mohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beloucif_M/0/1/0/all/0/1\">Meriem Beloucif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1\">Sebastian Ruder</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Research without Re-search: Maximal Update Parametrization Yields Accurate Loss Prediction across Scales. (arXiv:2304.06875v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.06875","description":"<p>As language models scale up, it becomes increasingly expensive to verify\nresearch ideas because conclusions on small models do not trivially transfer to\nlarge ones. A possible solution is to establish a generic system that directly\npredicts some metrics for large models solely based on the results and\nhyperparameters from small models. Existing methods based on scaling laws\nrequire hyperparameter search on the largest models, which is impractical with\nlimited resources. We address this issue by presenting our discoveries\nindicating that Maximal Update parametrization (muP) enables accurate fitting\nof scaling laws for hyperparameters close to common loss basins, without any\nsearch. Thus, different models can be directly compared on large scales with\nloss prediction even before the training starts. We propose a new paradigm as a\nfirst step towards reliable academic research for any model scale without heavy\ncomputation. Code will be publicly available shortly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yiqun Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yequan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Evaluation of the Copy Mechanism for Natural Language to SPARQL Query Generation. (arXiv:2304.07772v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.07772","description":"<p>In recent years, the field of neural machine translation (NMT) for SPARQL\nquery generation has witnessed a significant growth. Recently, the\nincorporation of the copy mechanism with traditional encoder-decoder\narchitectures and the use of pre-trained encoder-decoders have set new\nperformance benchmarks. This paper presents a large variety of experiments that\nreplicate and expand upon recent NMT-based SPARQL generation studies, comparing\npre-trained and non-pre-trained models, question annotation formats, and the\nuse of a copy mechanism for non-pre-trained and pre-trained models. Our results\nshow that either adding the copy mechanism or using a question annotation\nimproves performances for nonpre-trained models and for pre-trained models,\nsetting new baselines for three popular datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Reyd_S/0/1/0/all/0/1\">Samuel Reyd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zouaq_A/0/1/0/all/0/1\">Amal Zouaq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diallo_P/0/1/0/all/0/1\">Papa Abdou Karim Karou Diallo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SemEval 2023 Task 6: LegalEval - Understanding Legal Texts. (arXiv:2304.09548v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.09548","description":"<p>In populous countries, pending legal cases have been growing exponentially.\nThere is a need for developing NLP-based techniques for processing and\nautomatically understanding legal documents. To promote research in the area of\nLegal NLP we organized the shared task LegalEval - Understanding Legal Texts at\nSemEval 2023. LegalEval task has three sub-tasks: Task-A (Rhetorical Roles\nLabeling) is about automatically structuring legal documents into semantically\ncoherent units, Task-B (Legal Named Entity Recognition) deals with identifying\nrelevant entities in a legal document and Task-C (Court Judgement Prediction\nwith Explanation) explores the possibility of automatically predicting the\noutcome of a legal case along with providing an explanation for the prediction.\nIn total 26 teams (approx. 100 participants spread across the world) submitted\nsystems paper. In each of the sub-tasks, the proposed systems outperformed the\nbaselines; however, there is a lot of scope for improvement. This paper\ndescribes the tasks, and analyzes techniques proposed by various teams.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Modi_A/0/1/0/all/0/1\">Ashutosh Modi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalamkar_P/0/1/0/all/0/1\">Prathamesh Kalamkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karn_S/0/1/0/all/0/1\">Saurabh Karn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_A/0/1/0/all/0/1\">Aman Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1\">Abhinav Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanikella_S/0/1/0/all/0/1\">Sai Kiran Tanikella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guha_S/0/1/0/all/0/1\">Shouvik Kumar Guha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malhan_S/0/1/0/all/0/1\">Sachin Malhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raghavan_V/0/1/0/all/0/1\">Vivek Raghavan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChartSumm: A Comprehensive Benchmark for Automatic Chart Summarization of Long and Short Summaries. (arXiv:2304.13620v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.13620","description":"<p>Automatic chart to text summarization is an effective tool for the visually\nimpaired people along with providing precise insights of tabular data in\nnatural language to the user. A large and well-structured dataset is always a\nkey part for data driven models. In this paper, we propose ChartSumm: a\nlarge-scale benchmark dataset consisting of a total of 84,363 charts along with\ntheir metadata and descriptions covering a wide range of topics and chart types\nto generate short and long summaries. Extensive experiments with strong\nbaseline models show that even though these models generate fluent and\ninformative summaries by achieving decent scores in various automatic\nevaluation metrics, they often face issues like suffering from hallucination,\nmissing out important data points, in addition to incorrect explanation of\ncomplex trends in the charts. We also investigated the potential of expanding\nChartSumm to other languages using automated translation tools. These make our\ndataset a challenging benchmark for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_R/0/1/0/all/0/1\">Raian Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_R/0/1/0/all/0/1\">Rizvi Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhad_A/0/1/0/all/0/1\">Abdullah Al Farhad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laskar_M/0/1/0/all/0/1\">Md Tahmid Rahman Laskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashmafee_M/0/1/0/all/0/1\">Md. Hamjajul Ashmafee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamal_A/0/1/0/all/0/1\">Abu Raihan Mostofa Kamal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery. (arXiv:2304.13714v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2304.13714","description":"<p>Despite growing interest in using large language models (LLMs) in healthcare,\ncurrent explorations do not assess the real-world utility and safety of LLMs in\nclinical settings. Our objective was to determine whether two LLMs can serve\ninformation needs submitted by physicians as questions to an informatics\nconsultation service in a safe and concordant manner. Sixty six questions from\nan informatics consult service were submitted to GPT-3.5 and GPT-4 via simple\nprompts. 12 physicians assessed the LLM responses' possibility of patient harm\nand concordance with existing reports from an informatics consultation service.\nPhysician assessments were summarized based on majority vote. For no questions\ndid a majority of physicians deem either LLM response as harmful. For GPT-3.5,\nresponses to 8 questions were concordant with the informatics consult report,\n20 discordant, and 9 were unable to be assessed. There were 29 responses with\nno majority on \"Agree\", \"Disagree\", and \"Unable to assess\". For GPT-4,\nresponses to 13 questions were concordant, 15 discordant, and 3 were unable to\nbe assessed. There were 35 responses with no majority. Responses from both LLMs\nwere largely devoid of overt harm, but less than 20% of the responses agreed\nwith an answer from an informatics consultation service, responses contained\nhallucinated references, and physicians were divided on what constitutes harm.\nThese results suggest that while general purpose LLMs are able to provide safe\nand credible responses, they often do not meet the specific information need of\na given question. A definitive evaluation of the usefulness of LLMs in\nhealthcare settings will likely require additional research on prompt\nengineering, calibration, and custom-tailoring of general purpose models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dash_D/0/1/0/all/0/1\">Debadutta Dash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thapa_R/0/1/0/all/0/1\">Rahul Thapa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banda_J/0/1/0/all/0/1\">Juan M. Banda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swaminathan_A/0/1/0/all/0/1\">Akshay Swaminathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheatham_M/0/1/0/all/0/1\">Morgan Cheatham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashyap_M/0/1/0/all/0/1\">Mehr Kashyap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kotecha_N/0/1/0/all/0/1\">Nikesh Kotecha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jonathan H. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gombar_S/0/1/0/all/0/1\">Saurabh Gombar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Downing_L/0/1/0/all/0/1\">Lance Downing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedreira_R/0/1/0/all/0/1\">Rachel Pedreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goh_E/0/1/0/all/0/1\">Ethan Goh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arnaout_A/0/1/0/all/0/1\">Angel Arnaout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morris_G/0/1/0/all/0/1\">Garret Kenn Morris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magon_H/0/1/0/all/0/1\">Honor Magon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lungren_M/0/1/0/all/0/1\">Matthew P Lungren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horvitz_E/0/1/0/all/0/1\">Eric Horvitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Nigam H. Shah</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards autonomous system: flexible modular production system enhanced with large language model agents. (arXiv:2304.14721v2 [cs.RO] UPDATED)","link":"http://arxiv.org/abs/2304.14721","description":"<p>In this paper, we present a novel framework that combines large language\nmodels (LLMs), digital twins and industrial automation system to enable\nintelligent planning and control of production processes. We retrofit the\nautomation system for a modular production facility and create executable\ncontrol interfaces of fine-granular functionalities and coarse-granular skills.\nLow-level functionalities are executed by automation components, and high-level\nskills are performed by automation modules. Subsequently, a digital twin system\nis developed, registering these interfaces and containing additional\ndescriptive information about the production system. Based on the retrofitted\nautomation system and the created digital twins, LLM-agents are designed to\ninterpret descriptive information in the digital twins and control the physical\nsystem through service interfaces. These LLM-agents serve as intelligent agents\non different levels within an automation system, enabling autonomous planning\nand control of flexible production. Given a task instruction as input, the\nLLM-agents orchestrate a sequence of atomic functionalities and skills to\naccomplish the task. We demonstrate how our implemented prototype can handle\nun-predefined tasks, plan a production process, and execute the operations.\nThis research highlights the potential of integrating LLMs into industrial\nautomation systems for more agile, flexible, and adaptive production processes,\nwhile it also underscores the critical insights and limitations for future\nwork.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yuchen Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shenoy_M/0/1/0/all/0/1\">Manthan Shenoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jazdi_N/0/1/0/all/0/1\">Nasser Jazdi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weyrich_M/0/1/0/all/0/1\">Michael Weyrich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HQP: A Human-Annotated Dataset for Detecting Online Propaganda. (arXiv:2304.14931v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.14931","description":"<p>Online propaganda poses a severe threat to the integrity of societies.\nHowever, existing datasets for detecting online propaganda have a key\nlimitation: they were annotated using weak labels that can be noisy and even\nincorrect. To address this limitation, our work makes the following\ncontributions: (1) We present HQP: a novel dataset (N=30,000) for detecting\nonline propaganda with high-quality labels. To the best of our knowledge, HQP\nis the first dataset for detecting online propaganda that was created through\nhuman annotation. (2) We show empirically that state-of-the-art language models\nfail in detecting online propaganda when trained with weak labels (AUC: 64.03).\nIn contrast, state-of-the-art language models can accurately detect online\npropaganda when trained with our high-quality labels (AUC: 92.25), which is an\nimprovement of ~44%. (3) To address the cost of labeling, we extend our work to\nfew-shot learning. Specifically, we show that prompt-based learning using a\nsmall sample of high-quality labels can still achieve a reasonable performance\n(AUC: 80.27). Finally, we discuss implications for the NLP community to balance\nthe cost and quality of labeling. Crucially, our work highlights the importance\nof high-quality labels for sensitive NLP tasks such as propaganda detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Maarouf_A/0/1/0/all/0/1\">Abdurahman Maarouf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bar_D/0/1/0/all/0/1\">Dominik B&#xe4;r</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geissler_D/0/1/0/all/0/1\">Dominique Geissler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feuerriegel_S/0/1/0/all/0/1\">Stefan Feuerriegel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-05-01T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","syn":"http://purl.org/rss/1.0/modules/syndication/","dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/"}}]}]}