{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-12-15T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Exploring Graph Based Approaches for Author Name Disambiguation. (arXiv:2312.08388v1 [cs.SI])","link":"http://arxiv.org/abs/2312.08388","description":"<p>In many applications, such as scientific literature management, researcher\nsearch, social network analysis and etc, Name Disambiguation (aiming at\ndisambiguating WhoIsWho) has been a challenging problem. In addition, the\ngrowth of scientific literature makes the problem more difficult and urgent.\nAlthough name disambiguation has been extensively studied in academia and\nindustry, the problem has not been solved well due to the clutter of data and\nthe complexity of the same name scenario. In this work, we aim to explore\nmodels that can perform the task of name disambiguation using the network\nstructure that is intrinsic to the problem and present an analysis of the\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rastogi_C/0/1/0/all/0/1\">Chetanya Rastogi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_P/0/1/0/all/0/1\">Prabhat Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Shreya Singh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond English: Evaluating LLMs for Arabic Grammatical Error Correction. (arXiv:2312.08400v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08400","description":"<p>Large language models (LLMs) finetuned to follow human instruction have\nrecently exhibited significant capabilities in various English NLP tasks.\nHowever, their performance in grammatical error correction (GEC), especially on\nlanguages other than English, remains significantly unexplored. In this work,\nwe evaluate the abilities of instruction finetuned LLMs in Arabic GEC, a\ncomplex task due to Arabic's rich morphology. Our findings suggest that various\nprompting methods, coupled with (in-context) few-shot learning, demonstrate\nconsiderable effectiveness, with GPT-4 achieving up to $65.49$ F$_{1}$ score\nunder expert prompting (approximately $5$ points higher than our established\nbaseline). Despite these positive results, we find that instruction finetuned\nmodels, regardless of their size, are still outperformed by fully finetuned\nones, even if they are significantly smaller in size. This disparity highlights\nsubstantial room for improvements for LLMs. Inspired by methods used in\nlow-resource machine translation, we also develop a method exploiting synthetic\ndata that significantly outperforms previous models on two standard Arabic\nbenchmarks. Our best model achieves a new SOTA on Arabic GEC, with $73.29$ and\n$73.26$ F$_{1}$ on the 2014 and 2015 QALB datasets, respectively, compared to\npeer-reviewed published baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1\">Sang Yun Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_G/0/1/0/all/0/1\">Gagan Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagoudi_E/0/1/0/all/0/1\">El Moatez Billah Nagoudi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1\">Muhammad Abdul-Mageed</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Accuracy: Automated De-Identification of Large Real-World Clinical Text Datasets. (arXiv:2312.08495v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08495","description":"<p>Recent research advances achieve human-level accuracy for de-identifying\nfree-text clinical notes on research datasets, but gaps remain in reproducing\nthis in large real-world settings. This paper summarizes lessons learned from\nbuilding a system used to de-identify over one billion real clinical notes, in\na fully automated way, that was independently certified by multiple\norganizations for production use. A fully automated solution requires a very\nhigh level of accuracy that does not require manual review. A hybrid\ncontext-based model architecture is described, which outperforms a Named Entity\nRecogniton (NER) - only model by 10% on the i2b2-2014 benchmark. The proposed\nsystem makes 50%, 475%, and 575% fewer errors than the comparable AWS, Azure,\nand GCP services respectively while also outperforming ChatGPT by 33%. It\nexceeds 98% coverage of sensitive data across 7 European languages, without a\nneed for fine tuning. A second set of described models enable data obfuscation\n-- replacing sensitive data with random surrogates -- while retaining name,\ndate, gender, clinical, and format consistency. Both the practical need and the\nsolution architecture that provides for reliable &amp; linked anonymized documents\nare described.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kocaman_V/0/1/0/all/0/1\">Veysel Kocaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haq_H/0/1/0/all/0/1\">Hasham Ul Haq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talby_D/0/1/0/all/0/1\">David Talby</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning adaptive planning representations with natural language guidance. (arXiv:2312.08566v1 [cs.AI])","link":"http://arxiv.org/abs/2312.08566","description":"<p>Effective planning in the real world requires not only world knowledge, but\nthe ability to leverage that knowledge to build the right representation of the\ntask at hand. Decades of hierarchical planning techniques have used\ndomain-specific temporal action abstractions to support efficient and accurate\nplanning, almost always relying on human priors and domain knowledge to\ndecompose hard tasks into smaller subproblems appropriate for a goal or set of\ngoals. This paper describes Ada (Action Domain Acquisition), a framework for\nautomatically constructing task-specific planning representations using\ntask-general background knowledge from language models (LMs). Starting with a\ngeneral-purpose hierarchical planner and a low-level goal-conditioned policy,\nAda interactively learns a library of planner-compatible high-level action\nabstractions and low-level controllers adapted to a particular domain of\nplanning tasks. On two language-guided interactive planning benchmarks (Mini\nMinecraft and ALFRED Household Tasks), Ada strongly outperforms other\napproaches that use LMs for sequential decision-making, offering more accurate\nplans and better generalization to complex tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wong_L/0/1/0/all/0/1\">Lionel Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiayuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1\">Pratyusha Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siegel_Z/0/1/0/all/0/1\">Zachary S. Siegel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiahai Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korneev_N/0/1/0/all/0/1\">Noa Korneev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Identifying Planetary Names in Astronomy Papers: A Multi-Step Approach. (arXiv:2312.08579v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08579","description":"<p>The automatic identification of planetary feature names in astronomy\npublications presents numerous challenges. These features include craters,\ndefined as roughly circular depressions resulting from impact or volcanic\nactivity; dorsas, which are elongate raised structures or wrinkle ridges; and\nlacus, small irregular patches of dark, smooth material on the Moon, referred\nto as \"lake\" (Planetary Names Working Group, n.d.). Many feature names overlap\nwith places or people's names that they are named after, for example, Syria,\nTempe, Einstein, and Sagan, to name a few (U.S. Geological Survey, n.d.). Some\nfeature names have been used in many contexts, for instance, Apollo, which can\nrefer to mission, program, sample, astronaut, seismic, seismometers, core, era,\ndata, collection, instrument, and station, in addition to the crater on the\nMoon. Some feature names can appear in the text as adjectives, like the lunar\ncraters Black, Green, and White. Some feature names in other contexts serve as\ndirections, like craters West and South on the Moon. Additionally, some\nfeatures share identical names across different celestial bodies, requiring\ndisambiguation, such as the Adams crater, which exists on both the Moon and\nMars. We present a multi-step pipeline combining rule-based filtering,\nstatistical relevance analysis, part-of-speech (POS) tagging, named entity\nrecognition (NER) model, hybrid keyword harvesting, knowledge graph (KG)\nmatching, and inference with a locally installed large language model (LLM) to\nreliably identify planetary names despite these challenges. When evaluated on a\ndataset of astronomy papers from the Astrophysics Data System (ADS), this\nmethodology achieves an F1-score over 0.97 in disambiguating planetary feature\nnames.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shapurian_G/0/1/0/all/0/1\">Golnaz Shapurian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurtz_M/0/1/0/all/0/1\">Michael J Kurtz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Accomazzi_A/0/1/0/all/0/1\">Alberto Accomazzi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ZeroQuant(4+2): Redefining LLMs Quantization with a New FP6-Centric Strategy for Diverse Generative Tasks. (arXiv:2312.08583v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08583","description":"<p>This study examines 4-bit quantization methods like GPTQ in large language\nmodels (LLMs), highlighting GPTQ's overfitting and limited enhancement in\nZero-Shot tasks. While prior works merely focusing on zero-shot measurement, we\nextend task scope to more generative categories such as code generation and\nabstractive summarization, in which we found that INT4 quantization can\nsignificantly underperform. However, simply shifting to higher precision\nformats like FP6 has been particularly challenging, thus overlooked, due to\npoor performance caused by the lack of sophisticated integration and system\nacceleration strategies on current AI hardware. Our results show that FP6, even\nwith a coarse-grain quantization scheme, performs robustly across various\nalgorithms and tasks, demonstrating its superiority in accuracy and\nversatility. Notably, with the FP6 quantization, \\codestar-15B model performs\ncomparably to its FP16 counterpart in code generation, and for smaller models\nlike the 406M it closely matches their baselines in summarization. Neither can\nbe achieved by INT4. To better accommodate various AI hardware and achieve the\nbest system performance, we propose a novel 4+2 design for FP6 to achieve\nsimilar latency to the state-of-the-art INT4 fine-grain quantization. With our\ndesign, FP6 can become a promising solution to the current 4-bit quantization\nmethods used in LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaoxia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1\">Haojun Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Youn_S/0/1/0/all/0/1\">Stephen Youn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shiyang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bakhtiari_A/0/1/0/all/0/1\">Arash Bakhtiari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wyatt_M/0/1/0/all/0/1\">Michael Wyatt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuxiong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruwase_O/0/1/0/all/0/1\">Olatunji Ruwase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Leon Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zhewei Yao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unraveling Key Factors of Knowledge Distillation. (arXiv:2312.08585v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08585","description":"<p>Knowledge distillation, a technique for model compression and performance\nenhancement, has gained significant traction in Neural Machine Translation\n(NMT). However, existing research primarily focuses on empirical applications,\nand there is a lack of comprehensive understanding of how student model\ncapacity, data complexity, and decoding strategies collectively influence\ndistillation effectiveness. Addressing this gap, our study conducts an in-depth\ninvestigation into these factors, particularly focusing on their interplay in\nword-level and sequence-level distillation within NMT. Through extensive\nexperimentation across datasets like IWSLT13 En$\\rightarrow$Fr, IWSLT14\nEn$\\rightarrow$De, and others, we empirically validate hypotheses related to\nthe impact of these factors on knowledge distillation. Our research not only\nelucidates the significant influence of model capacity, data complexity, and\ndecoding strategies on distillation effectiveness but also introduces a novel,\noptimized distillation approach. This approach, when applied to the IWSLT14\nde$\\rightarrow$en translation task, achieves state-of-the-art performance,\ndemonstrating its practical efficacy in advancing the field of NMT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jingxuan Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Linzhuang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bihui Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1\">Ruifeng Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zebra: Extending Context Window with Layerwise Grouped Local-Global Attention. (arXiv:2312.08618v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08618","description":"<p>This paper introduces a novel approach to enhance the capabilities of Large\nLanguage Models (LLMs) in processing and understanding extensive text\nsequences, a critical aspect in applications requiring deep comprehension and\nsynthesis of large volumes of information. Recognizing the inherent challenges\nin extending the context window for LLMs, primarily built on Transformer\narchitecture, we propose a new model architecture, referred to as Zebra. This\narchitecture efficiently manages the quadratic time and memory complexity\nissues associated with full attention in the Transformer by employing grouped\nlocal-global attention layers. Our model, akin to a zebra's alternating\nstripes, balances local and global attention layers, significantly reducing\ncomputational requirements and memory consumption. Comprehensive experiments,\nincluding pretraining from scratch, continuation of long context adaptation\ntraining, and long instruction tuning, are conducted to evaluate the Zebra's\nperformance. The results show that Zebra achieves comparable or superior\nperformance on both short and long sequence benchmarks, while also enhancing\ntraining and inference efficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kaiqiang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1\">Sangwoo Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiaoman Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Metacognition-Enhanced Few-Shot Prompting With Positive Reinforcement. (arXiv:2312.08642v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08642","description":"<p>Few-shot prompting elicits the remarkable abilities of large language models\nby equipping them with a few demonstration examples in the input. However, the\ntraditional method of providing large language models with all demonstration\ninput-output pairs at once may not effectively guide large language models to\nlearn the specific input-output mapping relationship. In this paper, inspired\nby the regulatory and supportive role of metacognition in students' learning,\nwe propose a novel metacognition-enhanced few-shot prompting, which guides\nlarge language models to reflect on their thought processes to comprehensively\nlearn the given demonstration examples. Furthermore, considering that positive\nreinforcement can improve students' learning motivation, we introduce positive\nreinforcement into our metacognition-enhanced few-shot prompting to promote the\nfew-shot learning of large language models by providing response-based positive\nfeedback. The experimental results on two real-world datasets show that our\nmetacognition-enhanced few-shot prompting with positive reinforcement surpasses\ntraditional few-shot prompting in classification accuracy and macro F1.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1\">Yu Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hong Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Liang He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SEF-VC: Speaker Embedding Free Zero-Shot Voice Conversion with Cross Attention. (arXiv:2312.08676v1 [cs.SD])","link":"http://arxiv.org/abs/2312.08676","description":"<p>Zero-shot voice conversion (VC) aims to transfer the source speaker timbre to\narbitrary unseen target speaker timbre, while keeping the linguistic content\nunchanged. Although the voice of generated speech can be controlled by\nproviding the speaker embedding of the target speaker, the speaker similarity\nstill lags behind the ground truth recordings. In this paper, we propose\nSEF-VC, a speaker embedding free voice conversion model, which is designed to\nlearn and incorporate speaker timbre from reference speech via a powerful\nposition-agnostic cross-attention mechanism, and then reconstruct waveform from\nHuBERT semantic tokens in a non-autoregressive manner. The concise design of\nSEF-VC enhances its training stability and voice conversion performance.\nObjective and subjective evaluations demonstrate the superiority of SEF-VC to\ngenerate high-quality speech with better similarity to target reference than\nstrong zero-shot VC baselines, even for very short reference speeches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yiwei Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Kai Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TigerBot: An Open Multilingual Multitask LLM. (arXiv:2312.08688v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08688","description":"<p>We release and introduce the TigerBot family of large language models (LLMs),\nconsisting of base and chat models, sized from 7, 13, 70 and 180 billion\nparameters. We develop our models embarking from Llama-2 and BLOOM, and push\nthe boundary further in data, training algorithm, infrastructure, and\napplication tools. Our models yield meaningful performance gain over SOTA\nopen-source models, e.g., Llama-2, specifically 6\\% gain in English and 20\\%\ngain in Chinese. TigerBot model family also achieves leading performance in\nmajor academic and industrial benchmarks and leaderboards. We believe that\nTigerBot represents just a snapshot of lightning-fast progression in LLM\nopen-source community. Therefore, we are thrilled to give back by publicly\nreleasing our models and reporting our approach behind, with additional\nemphases on building SOTA LLMs in a democratized way and making LLMs of use in\nreal-world applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Ye Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1\">Wei Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Liangmin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaowei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_Z/0/1/0/all/0/1\">Zhanxuan Xin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Cong Fu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comparative Analysis of Fine-Tuned LLMs and Few-Shot Learning of LLMs for Financial Sentiment Analysis. (arXiv:2312.08725v1 [cs.LG])","link":"http://arxiv.org/abs/2312.08725","description":"<p>Financial sentiment analysis plays a crucial role in uncovering latent\npatterns and detecting emerging trends, enabling individuals to make\nwell-informed decisions that may yield substantial advantages within the\nconstantly changing realm of finance. Recently, Large Language Models (LLMs)\nhave demonstrated their effectiveness in diverse domains, showcasing remarkable\ncapabilities even in zero-shot and few-shot in-context learning for various\nNatural Language Processing (NLP) tasks. Nevertheless, their potential and\napplicability in the context of financial sentiment analysis have not been\nthoroughly explored yet. To bridge this gap, we employ two approaches:\nin-context learning (with a focus on gpt-3.5-turbo model) and fine-tuning LLMs\non a finance-domain dataset. Given the computational costs associated with\nfine-tuning LLMs with large parameter sizes, our focus lies on smaller LLMs,\nspanning from 250M to 3B parameters for fine-tuning. We then compare the\nperformances with state-of-the-art results to evaluate their effectiveness in\nthe finance-domain. Our results demonstrate that fine-tuned smaller LLMs can\nachieve comparable performance to state-of-the-art fine-tuned LLMs, even with\nmodels having fewer parameters and a smaller training dataset. Additionally,\nthe zero-shot and one-shot performance of LLMs produces comparable results with\nfine-tuned smaller LLMs and state-of-the-art outcomes. Furthermore, our\nanalysis demonstrates that there is no observed enhancement in performance for\nfinance-domain sentiment analysis when the number of shots for in-context\nlearning is increased.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fatemi_S/0/1/0/all/0/1\">Sorouralsadat Fatemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yuheng Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Labels Need Prompts Too Mask Matching for Natural Language Understanding Tasks. (arXiv:2312.08726v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08726","description":"<p>Textual label names (descriptions) are typically semantically rich in many\nnatural language understanding (NLU) tasks. In this paper, we incorporate the\nprompting methodology, which is widely used to enrich model input, into the\nlabel side for the first time. Specifically, we propose a Mask Matching method,\nwhich equips an input with a prompt and its label with another, and then makes\npredictions by matching their mask representations. We evaluate our method\nextensively on 8 NLU tasks with 14 datasets. The experimental results show that\nMask Matching significantly outperforms its counterparts of fine-tuning and\nconventional prompt-tuning, setting up state-of-the-art performances in several\ndatasets. Mask Matching is particularly good at handling NLU tasks with large\nlabel counts and informative label names. As pioneering efforts that\ninvestigate the label-side prompt, we also discuss open issues for future\nstudy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wei Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Quansen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shikun Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"JPIS: A Joint Model for Profile-based Intent Detection and Slot Filling with Slot-to-Intent Attention. (arXiv:2312.08737v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08737","description":"<p>Profile-based intent detection and slot filling are important tasks aimed at\nreducing the ambiguity in user utterances by leveraging user-specific\nsupporting profile information. However, research in these two tasks has not\nbeen extensively explored. To fill this gap, we propose a joint model, namely\nJPIS, designed to enhance profile-based intent detection and slot filling. JPIS\nincorporates the supporting profile information into its encoder and introduces\na slot-to-intent attention mechanism to transfer slot information\nrepresentations to intent detection. Experimental results show that our JPIS\nsubstantially outperforms previous profile-based models, establishing a new\nstate-of-the-art performance in overall accuracy on the Chinese benchmark\ndataset ProSLU.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1\">Thinh Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dat Quoc Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dissecting vocabulary biases datasets through statistical testing and automated data augmentation for artifact mitigation in Natural Language Inference. (arXiv:2312.08747v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08747","description":"<p>In recent years, the availability of large-scale annotated datasets, such as\nthe Stanford Natural Language Inference and the Multi-Genre Natural Language\nInference, coupled with the advent of pre-trained language models, has\nsignificantly contributed to the development of the natural language inference\ndomain. However, these crowdsourced annotated datasets often contain biases or\ndataset artifacts, leading to overestimated model performance and poor\ngeneralization. In this work, we focus on investigating dataset artifacts and\ndeveloping strategies to address these issues. Through the utilization of a\nnovel statistical testing procedure, we discover a significant association\nbetween vocabulary distribution and text entailment classes, emphasizing\nvocabulary as a notable source of biases. To mitigate these issues, we propose\nseveral automatic data augmentation strategies spanning character to word\nlevels. By fine-tuning the ELECTRA pre-trained language model, we compare the\nperformance of boosted models with augmented data against their baseline\ncounterparts. The experiments demonstrate that the proposed approaches\neffectively enhance model accuracy and reduce biases by up to 0.66% and 1.14%,\nrespectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dat Thanh Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PROPRES: Investigating the Projectivity of Presupposition with Various Triggers and Environments. (arXiv:2312.08755v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08755","description":"<p>What makes a presupposition of an utterance -- information taken for granted\nby its speaker -- different from other pragmatic inferences such as an\nentailment is projectivity (e.g., the negative sentence the boy did not stop\nshedding tears presupposes the boy had shed tears before). The projectivity may\nvary depending on the combination of presupposition triggers and environments.\nHowever, prior natural language understanding studies fail to take it into\naccount as they either use no human baseline or include only negation as an\nentailment-canceling environment to evaluate models' performance. The current\nstudy attempts to reconcile these issues. We introduce a new dataset,\nprojectivity of presupposition (PROPRES, which includes 12k premise-hypothesis\npairs crossing six triggers involving some lexical variety with five\nenvironments. Our human evaluation reveals that humans exhibit variable\nprojectivity in some cases. However, the model evaluation shows that the\nbest-performed model, DeBERTa, does not fully capture it. Our findings suggest\nthat probing studies on pragmatic inferences should take extra care of the\nhuman judgment variability and the combination of linguistic items.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Asami_D/0/1/0/all/0/1\">Daiki Asami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugawara_S/0/1/0/all/0/1\">Saku Sugawara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Forbidden Facts: An Investigation of Competing Objectives in Llama-2. (arXiv:2312.08793v1 [cs.LG])","link":"http://arxiv.org/abs/2312.08793","description":"<p>LLMs often face competing pressures (for example helpfulness vs.\nharmlessness). To understand how models resolve such conflicts, we study\nLlama-2-chat models on the forbidden fact task. Specifically, we instruct\nLlama-2 to truthfully complete a factual recall statement while forbidding it\nfrom saying the correct answer. This often makes the model give incorrect\nanswers. We decompose Llama-2 into 1000+ components, and rank each one with\nrespect to how useful it is for forbidding the correct answer. We find that in\naggregate, around 35 components are enough to reliably implement the full\nsuppression behavior. However, these components are fairly heterogeneous and\nmany operate using faulty heuristics. We discover that one of these heuristics\ncan be exploited via a manually designed adversarial attack which we call The\nCalifornia Attack. Our results highlight some roadblocks standing in the way of\nbeing able to successfully interpret advanced ML systems. Project website\navailable at https://forbiddenfacts.github.io .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tony T. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Miles Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hariharan_K/0/1/0/all/0/1\">Kaivu Hariharan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shavit_N/0/1/0/all/0/1\">Nir Shavit</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Large Language Models for Health-related Queries with Presuppositions. (arXiv:2312.08800v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08800","description":"<p>As corporations rush to integrate large language models (LLMs) to their\nsearch offerings, it is critical that they provide factually accurate\ninformation that is robust to any presuppositions that a user may express. In\nthis work, we introduce UPHILL, a dataset consisting of health-related queries\nwith varying degrees of presuppositions. Using UPHILL, we evaluate the factual\naccuracy and consistency of InstructGPT, ChatGPT, and BingChat models. We find\nthat while model responses rarely disagree with true health claims (posed as\nquestions), they often fail to challenge false claims: responses from\nInstructGPT agree with 32% of the false claims, ChatGPT 26% and BingChat 23%.\nAs we increase the extent of presupposition in input queries, the responses\nfrom InstructGPT and ChatGPT agree with the claim considerably more often,\nregardless of its veracity. Responses from BingChat, which rely on retrieved\nwebpages, are not as susceptible. Given the moderate factual accuracy, and the\ninability of models to consistently correct false assumptions, our work calls\nfor a careful assessment of current LLMs for use in high-stakes scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kaur_N/0/1/0/all/0/1\">Navreet Kaur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhury_M/0/1/0/all/0/1\">Monojit Choudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pruthi_D/0/1/0/all/0/1\">Danish Pruthi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TiMix: Text-aware Image Mixing for Effective Vision-Language Pre-training. (arXiv:2312.08846v1 [cs.LG])","link":"http://arxiv.org/abs/2312.08846","description":"<p>Self-supervised Multi-modal Contrastive Learning (SMCL) remarkably advances\nmodern Vision-Language Pre-training (VLP) models by aligning visual and\nlinguistic modalities. Due to noises in web-harvested text-image pairs,\nhowever, scaling up training data volume in SMCL presents considerable\nobstacles in terms of computational cost and data inefficiency. To improve data\nefficiency in VLP, we propose Text-aware Image Mixing (TiMix), which integrates\nmix-based data augmentation techniques into SMCL, yielding significant\nperformance improvements without significantly increasing computational\noverhead. We provide a theoretical analysis of TiMixfrom a mutual information\n(MI) perspective, showing that mixed data samples for cross-modal contrastive\nlearning implicitly serve as a regularizer for the contrastive loss. The\nexperimental results demonstrate that TiMix exhibits a comparable performance\non downstream tasks, even with a reduced amount of training data and shorter\ntraining time, when benchmarked against existing methods. This work empirically\nand theoretically demonstrates the potential of data mixing for data-efficient\nand computationally viable VLP, benefiting broader VLP model adoption in\npractical scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1\">Chaoya Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ye_W/0/1/0/all/0/1\">Wei ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1\">Qinghao Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Ming Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Ji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shikun Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Cross-modal Alignment with Synthetic Pairs for Text-only Image Captioning. (arXiv:2312.08865v1 [cs.CV])","link":"http://arxiv.org/abs/2312.08865","description":"<p>Although image captioning models have made significant advancements in recent\nyears, the majority of them heavily depend on high-quality datasets containing\npaired images and texts which are costly to acquire. Previous works leverage\nthe CLIP's cross-modal association ability for image captioning, relying solely\non textual information under unsupervised settings. However, not only does a\nmodality gap exist between CLIP text and image features, but a discrepancy also\narises between training and inference due to the unavailability of real-world\nimages, which hinders the cross-modal alignment in text-only captioning. This\npaper proposes a novel method to address these issues by incorporating\nsynthetic image-text pairs. A pre-trained text-to-image model is deployed to\nobtain images that correspond to textual data, and the pseudo features of\ngenerated images are optimized toward the real ones in the CLIP embedding\nspace. Furthermore, textual information is gathered to represent image\nfeatures, resulting in the image features with various semantics and the\nbridged modality gap. To unify training and inference, synthetic image features\nwould serve as the training prefix for the language decoder, while real images\nare used for inference. Additionally, salient objects in images are detected as\nassistance to enhance the learning of modality alignment. Experimental results\ndemonstrate that our method obtains the state-of-the-art performance on\nbenchmark datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyue Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1\">Fanrong Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Boosting LLM Reasoning: Push the Limits of Few-shot Learning with Reinforced In-Context Pruning. (arXiv:2312.08901v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08901","description":"<p>Large language models (LLMs) have shown impressive capabilities in various\ntasks, yet they still struggle with math reasoning. Despite efforts to optimize\nChain-of-Thoughts (CoT) prompts and fine-tune LLMs, the potential of few-shot\nlearning remains unexplored. In this work, we propose CoT-Max, a novel approach\npushing the boundaries of few-shot CoT learning to improve LLM math reasoning\ncapabilities. CoT-Max addresses the challenges of the selection of useful\nexamples and limited number of examples due to restricted context window\nlength. Inspired by our observation that natural language inputs contain many\nredundancy, we propose a coarse-to-fine pruner as a plug-and-play module for\nLLMs, which first identifies crucial CoT examples from a large batch and then\nfurther prunes unimportant tokens. To train the pruner, we collect a math\nreasoning dataset with diverse difficulty and steps, introduce a reward to\nmeasure both the input's effectiveness for math reasoning and token length\nconstraints, and propose a novel training approach with reinforcement learning.\nAs a result, CoT-Max significantly outperforms CoT and few-shot prompting\nbaselines across various LLMs (LLaMA2-7B, 13B, 70B) and 5 mathematical\ndatasets, achieving up to 4.55% absolute improvements. Remarkably, without any\nfine-tuning, LLaMA2-70B with CoT-Max surpasses GPT-3.5 and a wide range of\nlarger LLMs (PaLM, Minerva, etc.) on the GSM8K.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xijie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Lyna Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1\">Kwang-Ting Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Mao Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using eye tracking to investigate what native Chinese speakers notice about linguistic landscape images. (arXiv:2312.08906v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08906","description":"<p>Linguistic landscape is an important field in sociolinguistic research. Eye\ntracking technology is a common technology in psychological research. There are\nfew cases of using eye movement to study linguistic landscape. This paper uses\neye tracking technology to study the actual fixation of the linguistic\nlandscape and finds that in the two dimensions of fixation time and fixation\ntimes, the fixation of native Chinese speakers to the linguistic landscape is\nhigher than that of the general landscape. This paper argues that this\nphenomenon is due to the higher information density of linguistic landscapes.\nAt the same time, the article also discusses other possible reasons for this\nphenomenon.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zichao Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yewei Qin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modeling Complex Mathematical Reasoning via Large Language Model based MathAgent. (arXiv:2312.08926v1 [cs.AI])","link":"http://arxiv.org/abs/2312.08926","description":"<p>Large language models (LLMs) face challenges in solving complex mathematical\nproblems that require comprehensive capacities to parse the statements,\nassociate domain knowledge, perform compound logical reasoning, and integrate\nthe intermediate rationales. Tackling all these problems once could be arduous\nfor LLMs, thus leading to confusion in generation. In this work, we explore the\npotential of enhancing LLMs with agents by meticulous decomposition and\nmodeling of mathematical reasoning process. Specifically, we propose a formal\ndescription of the mathematical solving and extend LLMs with an agent-based\nzero-shot framework named\n$\\bf{P}$lanner-$\\bf{R}$easoner-$\\bf{E}$xecutor-$\\bf{R}$eflector (PRER). We\nfurther provide and implement two MathAgents that define the logical forms and\ninherent relations via a pool of actions in different grains and orientations:\nMathAgent-M adapts its actions to LLMs, while MathAgent-H aligns with\nhumankind. Experiments on miniF2F and MATH have demonstrated the effectiveness\nof PRER and proposed MathAgents, achieving an increase of\n$12.3\\%$($53.9\\%\\xrightarrow{}66.2\\%$) on the MiniF2F, $9.2\\%$\n($49.8\\%\\xrightarrow{}59.0\\%$) on MATH, and\n$13.2\\%$($23.2\\%\\xrightarrow{}35.4\\%$) for level-5 problems of MATH against\nGPT-4. Further analytical results provide more insightful perspectives on\nexploiting the behaviors of LLMs as agents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liao_H/0/1/0/all/0/1\">Haoran Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Q/0/1/0/all/0/1\">Qinyi Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shaohua Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Hao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yanyan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1\">Jidong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Yaohui Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Math-Shepherd: A Label-Free Step-by-Step Verifier for LLMs in Mathematical Reasoning. (arXiv:2312.08935v1 [cs.AI])","link":"http://arxiv.org/abs/2312.08935","description":"<p>Large language models (LLMs) have demonstrated remarkable capabilities across\na wide range of tasks. However, even the most advanced open-source LLMs, such\nas the LLaMA family models, still face challenges when it comes to accurately\nsolving complex multi-step mathematical problems. In this paper, we present an\ninnovative process-oriented math verifier called \\textbf{Math-Shepherd}, which\nassigns a reward score to each step of the LLM's outputs on math problems. The\ntraining of Math-Shepherd is achieved using automatically constructed\nprocess-wise supervision data, breaking the bottleneck of heavy reliance on\nmanual annotation in existing work. With the guidance of Math-Shepherd, a\nseries of open-source LLMs demonstrate exceptional performance. Among them,\nDeepSeek 67B \\citep{DeepSeek-llm} stands out by achieving accuracy rates of\n93.3\\% on the GSM8K dataset and 48.1\\% on the MATH dataset, without external\nenhancement such as tool usage. Our Math-Shepherd also outperforms the\nself-consistency method and other existing verification models. We believe that\nautomatic process supervision holds significant potential for the future\nevolution of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peiyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1\">Zhihong Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">R.X. Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Damai Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yifei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Deli Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Y.Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting value-expressive text posts in Russian social media. (arXiv:2312.08968v1 [cs.CL])","link":"http://arxiv.org/abs/2312.08968","description":"<p>Basic values are concepts or beliefs which pertain to desirable end-states\nand transcend specific situations. Studying personal values in social media can\nilluminate how and why societal values evolve especially when the stimuli-based\nmethods, such as surveys, are inefficient, for instance, in hard-to-reach\npopulations. On the other hand, user-generated content is driven by the massive\nuse of stereotyped, culturally defined speech constructions rather than\nauthentic expressions of personal values. We aimed to find a model that can\naccurately detect value-expressive posts in Russian social media VKontakte. A\ntraining dataset of 5,035 posts was annotated by three experts, 304\ncrowd-workers and ChatGPT. Crowd-workers and experts showed only moderate\nagreement in categorizing posts. ChatGPT was more consistent but struggled with\nspam detection. We applied an ensemble of human- and AI-assisted annotation\ninvolving active learning approach, subsequently trained several LLMs and\nselected a model based on embeddings from pre-trained fine-tuned rubert-tiny2,\nand reached a high quality of value detection with F1 = 0.75 (F1-macro = 0.80).\nThis model provides a crucial step to a study of values within and between\nRussian social media users.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Milkova_M/0/1/0/all/0/1\">Maria Milkova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudnev_M/0/1/0/all/0/1\">Maksim Rudnev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okolskaya_L/0/1/0/all/0/1\">Lidia Okolskaya</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FrameFinder: Explorative Multi-Perspective Framing Extraction from News Headlines. (arXiv:2312.08995v1 [cs.IR])","link":"http://arxiv.org/abs/2312.08995","description":"<p>Revealing the framing of news articles is an important yet neglected task in\ninformation seeking and retrieval. In the present work, we present FrameFinder,\nan open tool for extracting and analyzing frames in textual data. FrameFinder\nvisually represents the frames of text from three perspectives, i.e., (i) frame\nlabels, (ii) frame dimensions, and (iii) frame structure. By analyzing the\nwell-established gun violence frame corpus, we demonstrate the merits of our\nproposed solution to support social science research and call for subsequent\nintegration into information interactions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Reiter_Haas_M/0/1/0/all/0/1\">Markus Reiter-Haas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klosch_B/0/1/0/all/0/1\">Beate Kl&#xf6;sch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadler_M/0/1/0/all/0/1\">Markus Hadler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lex_E/0/1/0/all/0/1\">Elisabeth Lex</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ComOM at VLSP 2023: A Dual-Stage Framework with BERTology and Unified Multi-Task Instruction Tuning Model for Vietnamese Comparative Opinion Mining. (arXiv:2312.09000v1 [cs.CL])","link":"http://arxiv.org/abs/2312.09000","description":"<p>The ComOM shared task aims to extract comparative opinions from product\nreviews in Vietnamese language. There are two sub-tasks, including (1)\nComparative Sentence Identification (CSI) and (2) Comparative Element\nExtraction (CEE). The first task is to identify whether the input is a\ncomparative review, and the purpose of the second task is to extract the\nquintuplets mentioned in the comparative review. To address this task, our team\nproposes a two-stage system based on fine-tuning a BERTology model for the CSI\ntask and unified multi-task instruction tuning for the CEE task. Besides, we\napply the simple data augmentation technique to increase the size of the\ndataset for training our model in the second stage. Experimental results show\nthat our approach outperforms the other competitors and has achieved the top\nscore on the official private test.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Thin_D/0/1/0/all/0/1\">Dang Van Thin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_D/0/1/0/all/0/1\">Duong Ngoc Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Ngan Luu-Thuy Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning From How Humans Correct. (arXiv:2102.00225v18 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2102.00225","description":"<p>In industry NLP application, our manually labeled data has a certain number\nof noisy data. We present a simple method to find the noisy data and relabel\nthem manually, meanwhile we collect the correction information. Then we present\nnovel method to incorporate the human correction information into deep learning\nmodel. Human know how to correct noisy data. So the correction information can\nbe inject into deep learning model. We do the experiment on our own text\nclassification dataset, which is manually labeled, because we need to relabel\nthe noisy data in our dataset for our industry application. The experiment\nresult shows that our learn-on-correction method improve the classification\naccuracy from 91.7% to 92.5% in test dataset. The 91.7% accuracy is trained on\nthe corrected dataset, which improve the baseline from 83.3% to 91.7% in test\ndataset. The accuracy under human evaluation achieves more than 97%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1\">Tong Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AmbiFC: Fact-Checking Ambiguous Claims with Evidence. (arXiv:2104.00640v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.00640","description":"<p>Automated fact-checking systems verify claims against evidence to predict\ntheir veracity. In real-world scenarios, the retrieved evidence may not\nunambiguously support or refute the claim and yield conflicting but valid\ninterpretations. Existing fact-checking datasets assume that the models\ndeveloped with them predict a single veracity label for each claim, thus\ndiscouraging the handling of such ambiguity. To address this issue we present\nAmbiFC, a fact-checking dataset with 10k claims derived from real-world\ninformation needs. It contains fine-grained evidence annotations of 50k\npassages from 5k Wikipedia pages. We analyze the disagreements arising from\nambiguity when comparing claims against evidence in AmbiFC, observing a strong\ncorrelation of annotator disagreement with linguistic phenomena such as\nunderspecification and probabilistic reasoning. We develop models for\npredicting veracity handling this ambiguity via soft labels and find that a\npipeline that learns the label distribution for sentence-level evidence\nselection and veracity prediction yields the best performance. We compare\nmodels trained on different subsets of AmbiFC and show that models trained on\nthe ambiguous instances perform better when faced with the identified\nlinguistic phenomena.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Glockner_M/0/1/0/all/0/1\">Max Glockner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staliunaite_I/0/1/0/all/0/1\">Ieva Stali&#x16b;nait&#x117;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1\">James Thorne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vallejo_G/0/1/0/all/0/1\">Gisela Vallejo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1\">Andreas Vlachos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Cognitive Architecture for Machine Consciousness and Artificial Superintelligence: Thought Is Structured by the Iterative Updating of Working Memory. (arXiv:2203.17255v6 [q-bio.NC] UPDATED)","link":"http://arxiv.org/abs/2203.17255","description":"<p>This article provides an analytical framework for how to simulate human-like\nthought processes within a computer. It describes how attention and memory\nshould be structured, updated, and utilized to search for associative additions\nto the stream of thought. The focus is on replicating the dynamics of the\nmammalian working memory system, which features two forms of persistent\nactivity: sustained firing (preserving information on the order of seconds) and\nsynaptic potentiation (preserving information from minutes to hours). The\narticle uses a series of over 40 original figures to systematically demonstrate\nhow the iterative updating of these working memory stores provides functional\nstructure to behavior, cognition, and consciousness.\n</p>\n<p>In an AI implementation, these two memory stores should be updated\ncontinuously and in an iterative fashion, meaning each state should preserve a\nproportion of the coactive representations from the state before it. Thus, the\nset of concepts in working memory will evolve gradually and incrementally over\ntime. This makes each state a revised iteration of the preceding state and\ncauses successive states to overlap and blend with respect to the information\nthey contain. Transitions between states happen as persistent activity spreads\nactivation energy throughout the hierarchical network searching long-term\nmemory for the most appropriate representation to be added to the global\nworkspace. The result is a chain of associatively linked intermediate states\ncapable of advancing toward a solution or goal. Iterative updating is\nconceptualized here as an information processing strategy, a model of working\nmemory, a theory of consciousness, and an algorithm for designing and\nprogramming artificial general intelligence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-bio/1/au:+Reser_J/0/1/0/all/0/1\">Jared Edward Reser</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Grounding: Extracting Fine-Grained Event Hierarchies Across Modalities. (arXiv:2206.07207v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2206.07207","description":"<p>Events describe happenings in our world that are of importance. Naturally,\nunderstanding events mentioned in multimedia content and how they are related\nforms an important way of comprehending our world. Existing literature can\ninfer if events across textual and visual (video) domains are identical (via\ngrounding) and thus, on the same semantic level. However, grounding fails to\ncapture the intricate cross-event relations that exist due to the same events\nbeing referred to on many semantic levels. For example, in Figure 1, the\nabstract event of \"war\" manifests at a lower semantic level through subevents\n\"tanks firing\" (in video) and airplane \"shot\" (in text), leading to a\nhierarchical, multimodal relationship between the events.\n</p>\n<p>In this paper, we propose the task of extracting event hierarchies from\nmultimodal (video and text) data to capture how the same event manifests itself\nin different modalities at different semantic levels. This reveals the\nstructure of events and is critical to understanding them. To support research\non this task, we introduce the Multimodal Hierarchical Events (MultiHiEve)\ndataset. Unlike prior video-language datasets, MultiHiEve is composed of news\nvideo-article pairs, which makes it rich in event hierarchies. We densely\nannotate a part of the dataset to construct the test benchmark. We show the\nlimitations of state-of-the-art unimodal and multimodal baselines on this task.\nFurther, we address these limitations via a new weakly supervised model,\nleveraging only unannotated video-article pairs from MultiHiEve. We perform a\nthorough evaluation of our proposed method which demonstrates improved\nperformance on this task and highlight opportunities for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ayyubi_H/0/1/0/all/0/1\">Hammad A. Ayyubi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomas_C/0/1/0/all/0/1\">Christopher Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chum_L/0/1/0/all/0/1\">Lovish Chum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lokesh_R/0/1/0/all/0/1\">Rahul Lokesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Long Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_Y/0/1/0/all/0/1\">Yulei Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xudong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1\">Xuande Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koo_J/0/1/0/all/0/1\">Jaywon Koo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_S/0/1/0/all/0/1\">Sounak Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shih-Fu Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Controllable Citation Sentence Generation with Language Models. (arXiv:2211.07066v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.07066","description":"<p>Citation generation aims to generate a citation sentence that refers to a\nchosen paper in the context of a manuscript. However, a rigid citation\ngeneration process is at odds with an author's desire to control specific\nattributes, such as 1) the citation intent, e.g., either introducing background\ninformation or comparing results, and 2) keywords that should appear in the\ncitation text. To provide these degrees of controllability during citation\ngeneration, we propose to integrate the manuscript context, the context of the\nreferenced paper, and the desired control attributes into a structured template\nand use it to fine-tune a language model (LM) via next-token prediction. We\nthen utilize Proximal Policy Optimization to directly optimize the LM in favor\nof a high score of our proposed controllability metric. The proposed workflow\nharmoniously combines citation attribute suggestion and conditional citation\ngeneration into one LM, allowing for better user control.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_N/0/1/0/all/0/1\">Nianlong Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hahnloser_R/0/1/0/all/0/1\">Richard H.R. Hahnloser</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Double Equivariance for Inductive Link Prediction for Both New Nodes and New Relation Types. (arXiv:2302.01313v7 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.01313","description":"<p>The task of inductive link prediction in knowledge graphs (KGs) generally\nfocuses on test predictions with solely new nodes but not both new nodes and\nnew relation types. In this work, we formally define the concept of double\npermutation-equivariant representations that are equivariant to permutations of\nboth node identities and edge relation types. We then show how\ndouble-equivariant architectures are able to self-supervise pre-train on\ndistinct KG domains and zero-shot predict links on a new KG domain (with\ncompletely new entities and new relation types). We also introduce the concept\nof distributionally double equivariant positional embeddings designed to\nperform the same task. Finally, we empirically demonstrate the capability of\nthe proposed models against baselines on a set of novel real-world benchmarks.\nMore interestingly, we show that self-supervised pre-training on more KG\ndomains increases the zero-shot ability of our model to predict on new relation\ntypes over new entities on unseen KG domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfei Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yangze Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jincheng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1\">Bruno Ribeiro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prophet: Prompting Large Language Models with Complementary Answer Heuristics for Knowledge-based Visual Question Answering. (arXiv:2303.01903v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2303.01903","description":"<p>Knowledge-based visual question answering (VQA) requires external knowledge\nbeyond the image to answer the question. Early studies retrieve required\nknowledge from explicit knowledge bases (KBs), which often introduces\nirrelevant information to the question, hence restricting the performance of\ntheir models. Recent works have resorted to using a powerful large language\nmodel (LLM) as an implicit knowledge engine to acquire the necessary knowledge\nfor answering. Despite the encouraging results achieved by these methods, we\nargue that they have not fully activated the capacity of the blind LLM as the\nprovided textual input is insufficient to depict the required visual\ninformation to answer the question. In this paper, we present Prophet -- a\nconceptually simple, flexible, and general framework designed to prompt LLM\nwith answer heuristics for knowledge-based VQA. Specifically, we first train a\nvanilla VQA model on a specific knowledge-based VQA dataset without external\nknowledge. After that, we extract two types of complementary answer heuristics\nfrom the VQA model: answer candidates and answer-aware examples. Finally, the\ntwo types of answer heuristics are jointly encoded into a formatted prompt to\nfacilitate the LLM's understanding of both the image and question, thus\ngenerating a more accurate answer. By incorporating the state-of-the-art LLM\nGPT-3, Prophet significantly outperforms existing state-of-the-art methods on\nfour challenging knowledge-based VQA datasets. To demonstrate the generality of\nour approach, we instantiate Prophet with the combinations of different VQA\nmodels (i.e., both discriminative and generative ones) and different LLMs\n(i.e., both commercial and open-source ones).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_X/0/1/0/all/0/1\">Xuecheng Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1\">Zhenwei Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Meng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jun Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Portraits: Recording Foundation Model Training Data. (arXiv:2303.03919v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2303.03919","description":"<p>Foundation models are trained on increasingly immense and opaque datasets.\nEven while these models are now key in AI system building, it can be difficult\nto answer the straightforward question: has the model already encountered a\ngiven example during training? We therefore propose a widespread adoption of\nData Portraits: artifacts that record training data and allow for downstream\ninspection. First we outline the properties of such an artifact and discuss how\nexisting solutions can be used to increase transparency. We then propose and\nimplement a solution based on data sketching, stressing fast and space\nefficient querying. Using our tools, we document a popular language modeling\ncorpus (The Pile) and a recently released code modeling dataset (The Stack). We\nshow that our solution enables answering questions about test set leakage and\nmodel plagiarism. Our tool is lightweight and fast, costing only 3% of the\ndataset size in overhead. We release a live interface of our tools at\nhttps://dataportraits.org/ and call on dataset and model creators to release\nData Portraits as a complement to current documentation practices.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Marone_M/0/1/0/all/0/1\">Marc Marone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What does self-attention learn from Masked Language Modelling?. (arXiv:2304.07235v2 [cond-mat.dis-nn] UPDATED)","link":"http://arxiv.org/abs/2304.07235","description":"<p>Transformers are neural networks which revolutionised natural language\nprocessing and machine learning. They process sequences of inputs, like words,\nusing a mechanism called self-attention, which is trained via masked language\nmodelling (MLM). In MLM, a word is randomly masked in an input sequence, and\nthe network is trained to predict the missing word. Despite the practical\nsuccess of transformers, it remains unclear what type of data distribution\nself-attention can learn efficiently. Here, we show analytically that if one\ndecouples the treatment of word positions and embeddings, a single layer of\nself-attention learns the conditionals of a generalised Potts model with\ninteractions between sites and Potts colours. Moreover, we show that training\nthis neural network is exactly equivalent to solving the inverse Potts problem\nby the so-called pseudo-likelihood method, well known in statistical physics.\nUsing this mapping, we compute the generalisation error of self-attention in a\nmodel scenario analytically using the replica method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cond-mat/1/au:+Rende_R/0/1/0/all/0/1\">Riccardo Rende</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Gerace_F/0/1/0/all/0/1\">Federica Gerace</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Laio_A/0/1/0/all/0/1\">Alessandro Laio</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Goldt_S/0/1/0/all/0/1\">Sebastian Goldt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models can be Guided to Evade AI-Generated Text Detection. (arXiv:2305.10847v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10847","description":"<p>Large language models (LLMs) have shown remarkable performance in various\ntasks and have been extensively utilized by the public. However, the increasing\nconcerns regarding the misuse of LLMs, such as plagiarism and spamming, have\nled to the development of multiple detectors, including fine-tuned classifiers\nand statistical methods. In this study, we equip LLMs with prompts, rather than\nrelying on an external paraphraser, to evaluate the vulnerability of these\ndetectors. We propose a novel Substitution-based In-Context example\nOptimization method (SICO) to automatically construct prompts for evading the\ndetectors. SICO is cost-efficient as it requires only 40 human-written examples\nand a limited number of LLM inferences to generate a prompt. Moreover, once a\ntask-specific prompt has been constructed, it can be universally used against a\nwide range of detectors. Extensive experiments across three real-world tasks\ndemonstrate that SICO significantly outperforms the paraphraser baselines and\nenables GPT-3.5 to successfully evade six detectors, decreasing their AUC by\n0.5 on average. Furthermore, a comprehensive human evaluation as well as a\nvalidation experiment in the wild show that the SICO-generated text achieves\nhuman-level readability and task completion rates. Finally, the strong\nperformance of SICO exhibits its potential as a reliable evaluation tool for\nfuture detectors. The codes and data are located on\nhttps://github.com/ColinLu50/Evade-GPT-Detector.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_N/0/1/0/all/0/1\">Ning Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shengcai Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1\">Rui He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_Y/0/1/0/all/0/1\">Yew-Soon Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1\">Ke Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Continual Dialogue State Tracking via Example-Guided Question Answering. (arXiv:2305.13721v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13721","description":"<p>Dialogue systems are frequently updated to accommodate new services, but\nnaively updating them by continually training with data for new services in\ndiminishing performance on previously learnt services. Motivated by the insight\nthat dialogue state tracking (DST), a crucial component of dialogue systems\nthat estimates the user's goal as a conversation proceeds, is a simple natural\nlanguage understanding task, we propose reformulating it as a bundle of\ngranular example-guided question answering tasks to minimize the task shift\nbetween services and thus benefit continual learning. Our approach alleviates\nservice-specific memorization and teaches a model to contextualize the given\nquestion and example to extract the necessary information from the\nconversation. We find that a model with just 60M parameters can achieve a\nsignificant boost by learning to learn from in-context examples retrieved by a\nretriever trained to identify turns with similar dialogue state changes.\nCombining our method with dialogue-level memory replay, our approach attains\nstate of the art performance on DST continual learning metrics without relying\non any complex regularization or parameter expansion methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1\">Hyundong Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1\">Andrea Madotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhaojiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandu_K/0/1/0/all/0/1\">Khyathi Raghavi Chandu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kottur_S/0/1/0/all/0/1\">Satwik Kottur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1\">Jonathan May</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankar_C/0/1/0/all/0/1\">Chinnadhurai Sankar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OverPrompt: Enhancing ChatGPT through Efficient In-Context Learning. (arXiv:2305.14973v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14973","description":"<p>The remarkable performance of pre-trained large language models has\nrevolutionised various natural language processing applications. Due to huge\nparametersizes and extensive running costs, companies or organisations tend to\ntransfer the models to the target task by zero-shot prompting techniques.\nHowever, the prohibitive costs of tokens and time have hindered their adoption\nin applications. We propose OverPrompt, leveraging the in-context learning\ncapability of LLMs to handle multiple task inputs, thereby reducing token and\ntime costs. This approach could potentially improve task performance during API\nqueries due to better conditional distribution mapping. Evaluated across\ndiverse classification datasets, our experiments show that OverPrompt can\nachieve cost-efficient zero-shot classification without causing significant\ndetriment to task performance, and in some cases, even improving it. An\nablation study conducted on various LLMs, along with an investigation into the\nrobustness of our prompting strategy to different input ordering, offers\nvaluable insights into the broader applicability of our method across diverse\ntasks. These findings also suggest a more seamless integration of our method\nwith LLMs through an API.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiazheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Runcong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yongxin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yulan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1\">Lin Gui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ZYN: Zero-Shot Reward Models with Yes-No Questions for RLAIF. (arXiv:2308.06385v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.06385","description":"<p>In this work, we address the problem of directing the text generation of a\nlanguage model (LM) towards a desired behavior, aligning the generated text\nwith the preferences of the human operator. We propose using another,\ninstruction-tuned language model as a critic reward model in a zero-shot way\nthanks to the prompt of a Yes-No question that represents the user preferences,\nwithout requiring further labeled data. This zero-shot reward model provides\nthe learning signal to further fine-tune the base LM using Reinforcement\nLearning from AI Feedback (RLAIF); yet our approach is also compatible in other\ncontexts such as quality-diversity search. Extensive evidence of the\ncapabilities of the proposed ZYN framework is provided through experiments in\ndifferent domains related to text generation, including detoxification;\noptimizing sentiment of movie reviews, or any other attribute; steering the\nopinion about a particular topic the model may have; and personalizing prompt\ngenerators for text-to-image tasks. Code available at\n\\url{https://github.com/vicgalle/zero-shot-reward-models/}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gallego_V/0/1/0/all/0/1\">Victor Gallego</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Anchor Learning Approach for Citation Field Learning. (arXiv:2309.03559v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.03559","description":"<p>Citation field learning is to segment a citation string into fields of\ninterest such as author, title, and venue. Extracting such fields from\ncitations is crucial for citation indexing, researcher profile analysis, etc.\nUser-generated resources like academic homepages and Curriculum Vitae, provide\nrich citation field information. However, extracting fields from these\nresources is challenging due to inconsistent citation styles, incomplete\nsentence syntax, and insufficient training data. To address these challenges,\nwe propose a novel algorithm, CIFAL (citation field learning by anchor\nlearning), to boost the citation field learning performance. CIFAL leverages\nthe anchor learning, which is model-agnostic for any Pre-trained Language\nModel, to help capture citation patterns from the data of different citation\nstyles. The experiments demonstrate that CIFAL outperforms state-of-the-art\nmethods in citation field learning, achieving a 2.68% improvement in\nfield-level F1-scores. Extensive analysis of the results further confirms the\neffectiveness of CIFAL quantitatively and qualitatively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zilin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Borun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yimeng Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinghui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hai-Tao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Recovering from Privacy-Preserving Masking with Large Language Models. (arXiv:2309.08628v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.08628","description":"<p>Model adaptation is crucial to handle the discrepancy between proxy training\ndata and actual users data received. To effectively perform adaptation, textual\ndata of users is typically stored on servers or their local devices, where\ndownstream natural language processing (NLP) models can be directly trained\nusing such in-domain data. However, this might raise privacy and security\nconcerns due to the extra risks of exposing user information to adversaries.\nReplacing identifying information in textual data with a generic marker has\nbeen recently explored. In this work, we leverage large language models (LLMs)\nto suggest substitutes of masked tokens and have their effectiveness evaluated\non downstream language modeling tasks. Specifically, we propose multiple\npre-trained and fine-tuned LLM-based approaches and perform empirical studies\non various datasets for the comparison of these methods. Experimental results\nshow that models trained on the obfuscation corpora are able to achieve\ncomparable performance with the ones trained on the original data without\nprivacy-preserving token masking.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vats_A/0/1/0/all/0/1\">Arpita Vats</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_P/0/1/0/all/0/1\">Peng Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1\">Debjyoti Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yingyi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1\">Yutong Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_Z/0/1/0/all/0/1\">Zeeshan Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalinli_O/0/1/0/all/0/1\">Ozlem Kalinli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Models Represent Space and Time. (arXiv:2310.02207v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.02207","description":"<p>The capabilities of large language models (LLMs) have sparked debate over\nwhether such systems just learn an enormous collection of superficial\nstatistics or a coherent model of the data generation process -- a world model.\nWe find preliminary evidence for the latter by analyzing the learned\nrepresentations of three spatial datasets (world, US, NYC places) and three\ntemporal datasets (historical figures, artworks, news headlines) in the Llama-2\nfamily of models. We discover that LLMs learn linear representations of space\nand time across multiple scales. These representations are robust to prompting\nvariations and unified across different entity types (e.g. cities and\nlandmarks). In addition, we identify individual ``space neurons'' and ``time\nneurons'' that reliably encode spatial and temporal coordinates. While further\ninvestigation is needed, our results suggest modern LLMs learn rich\nspatiotemporal representations of the real world and possess basic ingredients\nof a world model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gurnee_W/0/1/0/all/0/1\">Wes Gurnee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tegmark_M/0/1/0/all/0/1\">Max Tegmark</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Language-guided Adaptive Hyper-modality Representation for Multimodal Sentiment Analysis. (arXiv:2310.05804v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.05804","description":"<p>Though Multimodal Sentiment Analysis (MSA) proves effective by utilizing rich\ninformation from multiple sources (e.g., language, video, and audio), the\npotential sentiment-irrelevant and conflicting information across modalities\nmay hinder the performance from being further improved. To alleviate this, we\npresent Adaptive Language-guided Multimodal Transformer (ALMT), which\nincorporates an Adaptive Hyper-modality Learning (AHL) module to learn an\nirrelevance/conflict-suppressing representation from visual and audio features\nunder the guidance of language features at different scales. With the obtained\nhyper-modality representation, the model can obtain a complementary and joint\nrepresentation through multimodal fusion for effective MSA. In practice, ALMT\nachieves state-of-the-art performance on several popular datasets (e.g., MOSI,\nMOSEI and CH-SIMS) and an abundance of ablation demonstrates the validity and\nnecessity of our irrelevance/conflict suppression mechanism.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haoyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_G/0/1/0/all/0/1\">Guanghao Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kejun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuanyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tianshu Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Character-LLM: A Trainable Agent for Role-Playing. (arXiv:2310.10158v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10158","description":"<p>Large language models (LLMs) can be used to serve as agents to simulate human\nbehaviors, given the powerful ability to understand human instructions and\nprovide high-quality generated texts. Such ability stimulates us to wonder\nwhether LLMs can simulate a person in a higher form than simple human\nbehaviors. Therefore, we aim to train an agent with the profile, experience,\nand emotional states of a specific person instead of using limited prompts to\ninstruct ChatGPT API. In this work, we introduce Character-LLM that teach LLMs\nto act as specific people such as Beethoven, Queen Cleopatra, Julius Caesar,\netc. Our method focuses on editing profiles as experiences of a certain\ncharacter and training models to be personal simulacra with these experiences.\nTo assess the effectiveness of our approach, we build a test playground that\ninterviews trained agents and evaluates whether the agents \\textit{memorize}\ntheir characters and experiences. Experimental results show interesting\nobservations that help build future simulacra of humankind.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yunfan Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Junqi Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ForceGen: End-to-end de novo protein generation based on nonlinear mechanical unfolding responses using a language diffusion model. (arXiv:2310.10605v2 [cond-mat.mtrl-sci] UPDATED)","link":"http://arxiv.org/abs/2310.10605","description":"<p>Through evolution, nature has presented a set of remarkable protein\nmaterials, including elastins, silks, keratins and collagens with superior\nmechanical performances that play crucial roles in mechanobiology. However,\ngoing beyond natural designs to discover proteins that meet specified\nmechanical properties remains challenging. Here we report a generative model\nthat predicts protein designs to meet complex nonlinear mechanical\nproperty-design objectives. Our model leverages deep knowledge on protein\nsequences from a pre-trained protein language model and maps mechanical\nunfolding responses to create novel proteins. Via full-atom molecular\nsimulations for direct validation, we demonstrate that the designed proteins\nare novel, and fulfill the targeted mechanical properties, including unfolding\nenergy and mechanical strength, as well as the detailed unfolding\nforce-separation curves. Our model offers rapid pathways to explore the\nenormous mechanobiological protein sequence space unconstrained by biological\nsynthesis, using mechanical features as target to enable the discovery of\nprotein materials with superior mechanical properties.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cond-mat/1/au:+Ni_B/0/1/0/all/0/1\">Bo Ni</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Kaplan_D/0/1/0/all/0/1\">David L. Kaplan</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Buehler_M/0/1/0/all/0/1\">Markus J. Buehler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-shot Faithfulness Evaluation for Text Summarization with Foundation Language Model. (arXiv:2310.11648v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11648","description":"<p>Despite tremendous improvements in natural language generation, summarization\nmodels still suffer from the unfaithfulness issue. Previous work evaluates\nfaithfulness either using models trained on the other tasks or in-domain\nsynthetic data, or prompting a large model such as ChatGPT. This paper proposes\nto do zero-shot faithfulness evaluation simply with a moderately-sized\nfoundation language model. We introduce a new metric FFLM, which is a\ncombination of probability changes based on the intuition that prefixing a\npiece of text that is consistent with the output will increase the probability\nof predicting the output. Experiments show that FFLM performs competitively\nwith or even outperforms ChatGPT on both inconsistency detection and\nfaithfulness rating with 24x fewer parameters. FFLM also achieves improvements\nover other strong baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jia_Q/0/1/0/all/0/1\">Qi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Siyu Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yizhu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kenny Q. Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AutoDAN: Interpretable Gradient-Based Adversarial Attacks on Large Language Models. (arXiv:2310.15140v2 [cs.CR] UPDATED)","link":"http://arxiv.org/abs/2310.15140","description":"<p>Safety alignment of Large Language Models (LLMs) can be compromised with\nmanual jailbreak attacks and (automatic) adversarial attacks. Recent studies\nsuggest that defending against these attacks is possible: adversarial attacks\ngenerate unlimited but unreadable gibberish prompts, detectable by\nperplexity-based filters; manual jailbreak attacks craft readable prompts, but\ntheir limited number due to the necessity of human creativity allows for easy\nblocking. In this paper, we show that these solutions may be too optimistic. We\nintroduce AutoDAN, an interpretable, gradient-based adversarial attack that\nmerges the strengths of both attack types. Guided by the dual goals of\njailbreak and readability, AutoDAN optimizes and generates tokens one by one\nfrom left to right, resulting in readable prompts that bypass perplexity\nfilters while maintaining high attack success rates. Notably, these prompts,\ngenerated from scratch using gradients, are interpretable and diverse, with\nemerging strategies commonly seen in manual jailbreak attacks. They also\ngeneralize to unforeseen harmful behaviors and transfer to black-box LLMs\nbetter than their unreadable counterparts when using limited training data or a\nsingle proxy model. Furthermore, we show the versatility of AutoDAN by\nautomatically leaking system prompts using a customized objective. Our work\noffers a new way to red-team LLMs and understand jailbreak mechanisms via\ninterpretability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Sicheng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruiyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bang An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1\">Gang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barrow_J/0/1/0/all/0/1\">Joe Barrow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zichao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Furong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nenkova_A/0/1/0/all/0/1\">Ani Nenkova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MarkQA: A large scale KBQA dataset with numerical reasoning. (arXiv:2310.15517v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.15517","description":"<p>While question answering over knowledge bases (KBQA) has shown progress in\naddressing factoid questions, KBQA with numerical reasoning remains relatively\nunexplored. In this paper, we focus on the complex numerical reasoning in KBQA\nand propose a new task, NR-KBQA, which necessitates the ability to perform both\nmulti-hop reasoning and numerical reasoning. We design a logic form in Python\nformat called PyQL to represent the reasoning process of numerical reasoning\nquestions. To facilitate the development of NR-KBQA, we present a large dataset\ncalled MarkQA, which is automatically constructed from a small set of seeds.\nEach question in MarkQA is equipped with its corresponding SPARQL query,\nalongside the step-by-step reasoning process in the QDMR format and PyQL\nprogram. Experimental results of some state-of-the-art QA methods on the MarkQA\nshow that complex numerical reasoning in KBQA faces great challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Sitao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1\">Yuheng Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shanshan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1\">Yuzhong Qu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Personas as a Way to Model Truthfulness in Language Models. (arXiv:2310.18168v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.18168","description":"<p>Large Language Models (LLMs) are trained on vast amounts of text from the\ninternet, which contains both factual and misleading information about the\nworld. Can language models discern truth from falsehood in this contradicting\ndata? Expanding on the view that LLMs can model different communicative agents,\nwe present the persona hypothesis: LLMs can cluster agents into personas using\ncommon features of their generations. For instance, a truthful persona is a\ngroup of agents that are likely to produce truthful text and that share similar\nfeatures like formal writing styles and scientific references. By modeling this\npersona, LLMs can generalize truthfulness beyond the specific contexts in which\neach agent generated the training text. For example, the model can infer that\nthe agent \"Wikipedia\" will behave truthfully on topics that were only generated\nby \"Science\" because they both belong to the truthful persona. We show evidence\nfor the persona hypothesis via two observations: (1) we can probe whether a\nmodel's answer will be truthful before it is generated; (2) finetuning a model\non a set of facts improves its truthfulness on unseen topics. Next, using\narithmetics as a synthetic environment, we show that language models can\nseparate true and false statements, and generalize truthfulness across agents;\nbut only if agents in the training data share a truthful generative process\nthat enables the creation of a truthful persona. Overall, our findings suggest\nthat models can exploit hierarchical structures in the data to learn abstract\nconcepts like truthfulness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1\">Nitish Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rando_J/0/1/0/all/0/1\">Javier Rando</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saparov_A/0/1/0/all/0/1\">Abulhair Saparov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1\">Najoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">He He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey of Large Language Models Attribution. (arXiv:2311.03731v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.03731","description":"<p>Open-domain generative systems have gained significant attention in the field\nof conversational AI (e.g., generative search engines). This paper presents a\ncomprehensive review of the attribution mechanisms employed by these systems,\nparticularly large language models. Though attribution or citation improve the\nfactuality and verifiability, issues like ambiguous knowledge reservoirs,\ninherent biases, and the drawbacks of excessive attribution can hinder the\neffectiveness of these systems. The aim of this survey is to provide valuable\ninsights for researchers, aiding in the refinement of attribution methodologies\nto enhance the reliability and veracity of responses generated by open-domain\ngenerative systems. We believe that this field is still in its early stages;\nhence, we maintain a repository to keep track of ongoing studies at\nhttps://github.com/HITsz-TMG/awesome-llm-attributions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongfang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zetian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xinshuo Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhenyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Ziyang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Baotian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Aiguo Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chain of Empathy: Enhancing Empathetic Response of Large Language Models Based on Psychotherapy Models. (arXiv:2311.04915v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.04915","description":"<p>We present a novel method, the Chain of Empathy (CoE) prompting, that\nutilizes insights from psychotherapy to induce Large Language Models (LLMs) to\nreason about human emotional states. This method is inspired by various\npsychotherapy approaches including Cognitive Behavioral Therapy (CBT),\nDialectical Behavior Therapy (DBT), Person Centered Therapy (PCT), and Reality\nTherapy (RT), each leading to different patterns of interpreting clients'\nmental states. LLMs without reasoning generated predominantly exploratory\nresponses. However, when LLMs used CoE reasoning, we found a more comprehensive\nrange of empathetic responses aligned with the different reasoning patterns of\neach psychotherapy model. The CBT based CoE resulted in the most balanced\ngeneration of empathetic responses. The findings underscore the importance of\nunderstanding the emotional context and how it affects human and AI\ncommunication. Our research contributes to understanding how psychotherapeutic\nmodels can be incorporated into LLMs, facilitating the development of\ncontext-specific, safer, and empathetic AI.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yoon Kyung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1\">Inju Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_M/0/1/0/all/0/1\">Minjung Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1\">Seoyeon Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hahn_S/0/1/0/all/0/1\">Sowon Hahn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SER_AMPEL: a multi-source dataset for speech emotion recognition of Italian older adults. (arXiv:2311.14483v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2311.14483","description":"<p>In this paper, SER_AMPEL, a multi-source dataset for speech emotion\nrecognition (SER) is presented. The peculiarity of the dataset is that it is\ncollected with the aim of providing a reference for speech emotion recognition\nin case of Italian older adults. The dataset is collected following different\nprotocols, in particular considering acted conversations, extracted from movies\nand TV series, and recording natural conversations where the emotions are\nelicited by proper questions. The evidence of the need for such a dataset\nemerges from the analysis of the state of the art. Preliminary considerations\non the critical issues of SER are reported analyzing the classification results\non a subset of the proposed dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Grossi_A/0/1/0/all/0/1\">Alessandra Grossi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gasparini_F/0/1/0/all/0/1\">Francesca Gasparini</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generative agent-based modeling with actions grounded in physical, social, or digital space using Concordia. (arXiv:2312.03664v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2312.03664","description":"<p>Agent-based modeling has been around for decades, and applied widely across\nthe social and natural sciences. The scope of this research method is now\npoised to grow dramatically as it absorbs the new affordances provided by Large\nLanguage Models (LLM)s. Generative Agent-Based Models (GABM) are not just\nclassic Agent-Based Models (ABM)s where the agents talk to one another. Rather,\nGABMs are constructed using an LLM to apply common sense to situations, act\n\"reasonably\", recall common semantic knowledge, produce API calls to control\ndigital technologies like apps, and communicate both within the simulation and\nto researchers viewing it from the outside. Here we present Concordia, a\nlibrary to facilitate constructing and working with GABMs. Concordia makes it\neasy to construct language-mediated simulations of physically- or\ndigitally-grounded environments. Concordia agents produce their behavior using\na flexible component system which mediates between two fundamental operations:\nLLM calls and associative memory retrieval. A special agent called the Game\nMaster (GM), which was inspired by tabletop role-playing games, is responsible\nfor simulating the environment where the agents interact. Agents take actions\nby describing what they want to do in natural language. The GM then translates\ntheir actions into appropriate implementations. In a simulated physical world,\nthe GM checks the physical plausibility of agent actions and describes their\neffects. In digital environments simulating technologies such as apps and\nservices, the GM may handle API calls to integrate with external tools such as\ngeneral AI assistants (e.g., Bard, ChatGPT), and digital apps (e.g., Calendar,\nEmail, Search, etc.). Concordia was designed to support a wide array of\napplications both in scientific research and for evaluating performance of real\ndigital services by simulating users and/or generating synthetic data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vezhnevets_A/0/1/0/all/0/1\">Alexander Sasha Vezhnevets</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agapiou_J/0/1/0/all/0/1\">John P. Agapiou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aharon_A/0/1/0/all/0/1\">Avia Aharon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziv_R/0/1/0/all/0/1\">Ron Ziv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matyas_J/0/1/0/all/0/1\">Jayd Matyas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duenez_Guzman_E/0/1/0/all/0/1\">Edgar A. Du&#xe9;&#xf1;ez-Guzm&#xe1;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cunningham_W/0/1/0/all/0/1\">William A. Cunningham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osindero_S/0/1/0/all/0/1\">Simon Osindero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karmon_D/0/1/0/all/0/1\">Danny Karmon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leibo_J/0/1/0/all/0/1\">Joel Z. Leibo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs. (arXiv:2312.03731v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.03731","description":"<p>Graphs can inherently model interconnected objects on the Web, thereby\nfacilitating a series of Web applications, such as web analyzing and content\nrecommendation. Recently, Graph Neural Networks (GNNs) have emerged as a\nmainstream technique for graph representation learning. However, their efficacy\nwithin an end-to-end supervised framework is significantly tied to the\navailabilityof task-specific labels. To mitigate labeling costs and enhance\nrobustness in few-shot settings, pre-training on self-supervised tasks has\nemerged as a promising method, while prompting has been proposed to further\nnarrow the objective gap between pretext and downstream tasks. Although there\nhas been some initial exploration of prompt-based learning on graphs, they\nprimarily leverage a single pretext task, resulting in a limited subset of\ngeneral knowledge that could be learned from the pre-training data. Hence, in\nthis paper, we propose MultiGPrompt, a novel multi-task pre-training and\nprompting framework to exploit multiple pretext tasks for more comprehensive\npre-trained knowledge. First, in pre-training, we design a set of pretext\ntokens to synergize multiple pretext tasks. Second, we propose a dual-prompt\nmechanism consisting of composed and open prompts to leverage task-specific and\nglobal pre-training knowledge, to guide downstream tasks in few-shot settings.\nFinally, we conduct extensive experiments on six public datasets to evaluate\nand analyze MultiGPrompt.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xingtong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yuan Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinming Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Alpha-CLIP: A CLIP Model Focusing on Wherever You Want. (arXiv:2312.03818v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2312.03818","description":"<p>Contrastive Language-Image Pre-training (CLIP) plays an essential role in\nextracting valuable content information from images across diverse tasks. It\naligns textual and visual modalities to comprehend the entire image, including\nall the details, even those irrelevant to specific tasks. However, for a finer\nunderstanding and controlled editing of images, it becomes crucial to focus on\nspecific regions of interest, which can be indicated as points, masks, or boxes\nby humans or perception models. To fulfill the requirements, we introduce\nAlpha-CLIP, an enhanced version of CLIP with an auxiliary alpha channel to\nsuggest attentive regions and fine-tuned with constructed millions of RGBA\nregion-text pairs. Alpha-CLIP not only preserves the visual recognition ability\nof CLIP but also enables precise control over the emphasis of image contents.\nIt demonstrates effectiveness in various tasks, including but not limited to\nopen-world recognition, multimodal large language models, and conditional 2D /\n3D generation. It has a strong potential to serve as a versatile tool for\nimage-related tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zeyi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Ye Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zang_Y/0/1/0/all/0/1\">Yuhang Zang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_S/0/1/0/all/0/1\">Shu Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1\">Yuanjun Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1\">Dahua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaqi Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Surface: Probing LLaMA Across Scales and Layers. (arXiv:2312.04333v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.04333","description":"<p>This paper presents an in-depth analysis of Large Language Models (LLMs),\nfocusing on LLaMA, a prominent open-source foundational model in natural\nlanguage processing. Instead of assessing LLaMA through its generative output,\nwe design multiple-choice tasks to probe its intrinsic understanding in\nhigh-order tasks such as reasoning and computation. We examine the model\nhorizontally, comparing different sizes, and vertically, assessing different\nlayers. We unveil several key and uncommon findings based on the designed\nprobing tasks: (1) Horizontally, enlarging model sizes almost could not\nautomatically impart additional knowledge or computational prowess. Instead, it\ncan enhance reasoning abilities, especially in math problem solving, and helps\nreduce hallucinations, but only beyond certain size thresholds; (2) In vertical\nanalysis, the lower layers of LLaMA lack substantial arithmetic and factual\nknowledge, showcasing logical thinking, multilingual and recognitive abilities,\nwith top layers housing most computational power and real-world knowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_N/0/1/0/all/0/1\">Ning Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1\">Shining Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1\">Ming Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shou_L/0/1/0/all/0/1\">Linjun Shou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"History Matters: Temporal Knowledge Editing in Large Language Model. (arXiv:2312.05497v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.05497","description":"<p>The imperative task of revising or updating the knowledge stored within large\nlanguage models arises from two distinct sources: intrinsic errors inherent in\nthe model which should be corrected and outdated knowledge due to external\nshifts in the real world which should be updated. Prevailing efforts in model\nediting conflate these two distinct categories of edits arising from distinct\nreasons and directly modify the original knowledge in models into new\nknowledge. However, we argue that preserving the model's original knowledge\nremains pertinent. Specifically, if a model's knowledge becomes outdated due to\nevolving worldly dynamics, it should retain recollection of the historical\nknowledge while integrating the newfound knowledge. In this work, we introduce\nthe task of Temporal Knowledge Editing (TKE) and establish a benchmark AToKe\n(Assessment of TempOral Knowledge Editing) to evaluate current model editing\nmethods. We find that while existing model editing methods are effective at\nmaking models remember new knowledge, the edited model catastrophically forgets\nhistorical knowledge. To address this gap, we propose a simple and general\nframework termed Multi-Editing with Time Objective (METO) for enhancing\nexisting editing models, which edits both historical and new knowledge\nconcurrently and optimizes the model's prediction for the time of each fact.\nOur assessments demonstrate that while AToKe is still difficult, METO maintains\nthe effectiveness of learning new knowledge and meanwhile substantially\nimproves the performance of edited models on utilizing historical knowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xunjian Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Liming Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiaojun Wan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SocialStigmaQA: A Benchmark to Uncover Stigma Amplification in Generative Language Models. (arXiv:2312.07492v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.07492","description":"<p>Current datasets for unwanted social bias auditing are limited to studying\nprotected demographic features such as race and gender. In this work, we\nintroduce a comprehensive benchmark that is meant to capture the amplification\nof social bias, via stigmas, in generative language models. We start with a\ncomprehensive list of 93 stigmas documented in social science literature and\ncurate a question-answering (QA) dataset which involves simple social\nsituations. Our benchmark, SocialStigmaQA, contains roughly 10K prompts, with a\nvariety of prompt styles, carefully constructed to systematically test for both\nsocial bias and model robustness. We present results for SocialStigmaQA with\ntwo widely used open source generative language models and we demonstrate that\nthe output generated by these models considerably amplifies existing social\nbias against stigmatized groups. Specifically, we find that the proportion of\nsocially biased output ranges from 45% to 59% across a variety of decoding\nstrategies and prompting styles. We discover that the deliberate design of the\ntemplates in our benchmark (e.g., by adding biasing text to the prompt or\nvarying the answer that indicates bias) impact the model tendencies to generate\nsocially biased output. Additionally, we report on patterns in the generated\nchain-of-thought output, finding a variety of problems from subtle bias to\nevidence of a lack of reasoning.\n</p>\n<p>Warning: This paper contains examples of text which is toxic, biased, and\nharmful.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nagireddy_M/0/1/0/all/0/1\">Manish Nagireddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiazor_L/0/1/0/all/0/1\">Lamogha Chiazor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Moninder Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldini_I/0/1/0/all/0/1\">Ioana Baldini</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mathematical Language Models: A Survey. (arXiv:2312.07622v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.07622","description":"<p>In recent years, there has been remarkable progress in leveraging Language\nModels (LMs), encompassing Pre-trained Language Models (PLMs) and Large-scale\nLanguage Models (LLMs), within the domain of mathematics. This paper conducts a\ncomprehensive survey of mathematical LMs, systematically categorizing pivotal\nresearch endeavors from two distinct perspectives: tasks and methodologies. The\nlandscape reveals a large number of proposed mathematical LLMs, which are\nfurther delineated into instruction learning, tool-based methods, fundamental\nCoT techniques, and advanced CoT methodologies. In addition, our survey entails\nthe compilation of over 60 mathematical datasets, including training datasets,\nbenchmark datasets, and augmented datasets. Addressing the primary challenges\nand delineating future trajectories within the field of mathematical LMs, this\nsurvey is positioned as a valuable resource, poised to facilitate and inspire\nfuture innovation among researchers invested in advancing this domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wentao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hanglei Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yuyang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junsong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jiayi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_M/0/1/0/all/0/1\">Mengliang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Bo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Aimin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Liang He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SwitchHead: Accelerating Transformers with Mixture-of-Experts Attention. (arXiv:2312.07987v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2312.07987","description":"<p>The costly self-attention layers in modern Transformers require memory and\ncompute quadratic in sequence length. Existing approximation methods usually\nunderperform and fail to obtain significant speedups in practice. Here we\npresent SwitchHead - a novel method that reduces both compute and memory\nrequirements and achieves wall-clock speedup, while matching the language\nmodeling performance of baseline Transformers with the same parameter budget.\nSwitchHead uses Mixture-of-Experts (MoE) layers for the value and output\nprojections and requires 4 to 8 times fewer attention matrices than standard\nTransformers. Our novel attention can also be combined with MoE MLP layers,\nresulting in an efficient fully-MoE \"SwitchAll\" Transformer model. Our code is\npublic.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Csordas_R/0/1/0/all/0/1\">R&#xf3;bert Csord&#xe1;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piekos_P/0/1/0/all/0/1\">Piotr Pi&#x119;kos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irie_K/0/1/0/all/0/1\">Kazuki Irie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1\">J&#xfc;rgen Schmidhuber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-Grained Image-Text Alignment in Medical Imaging Enables Cyclic Image-Report Generation. (arXiv:2312.08078v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2312.08078","description":"<p>To address these issues, we propose a novel Adaptive patch-word Matching\n(AdaMatch) model to correlate chest X-ray (CXR) image regions with words in\nmedical reports and apply it to CXR-report generation to provide explainability\nfor the generation process. AdaMatch exploits the fine-grained relation between\nadaptive patches and words to provide explanations of specific image regions\nwith corresponding words. To capture the abnormal regions of varying sizes and\npositions, we introduce the Adaptive Patch extraction (AdaPatch) module to\nacquire the adaptive patches for these regions adaptively. In order to provide\nexplicit explainability for CXR-report generation task, we propose an\nAdaMatch-based bidirectional large language model for Cyclic CXR-report\ngeneration (AdaMatch-Cyclic). It employs the AdaMatch to obtain the keywords\nfor CXR images and `keypatches' for medical reports as hints to guide\nCXR-report generation. Extensive experiments on two publicly available CXR\ndatasets prove the effectiveness of our method and its superior performance to\nexisting methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Linlin Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Yixuan Yuan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"High-throughput Biomedical Relation Extraction for Semi-Structured Web Articles Empowered by Large Language Models. (arXiv:2312.08274v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.08274","description":"<p>Objective: To develop a high-throughput biomedical relation extraction system\nthat takes advantage of the large language models' (LLMs) reading comprehension\nability and biomedical world knowledge in a scalable and evidential manner.\nMethods: We formulate the relation extraction task as a simple binary\nclassification problem for large language models such as ChatGPT. Specifically,\nLLMs make the decision based on the external corpus and its world knowledge,\ngiving the reason for the judgment to factual verification. This method is\ntailored for semi-structured web articles, wherein we designate the main title\nas the tail entity and explicitly incorporate it into the context, and the\npotential head entities are matched based on a biomedical thesaurus. Moreover,\nlengthy contents are sliced into text chunks, embedded, and retrieved with\nadditional embedding models, ensuring compatibility with the context window\nsize constraints of available open-source LLMs. Results: Using an open-source\nLLM, we extracted 304315 relation triplets of three distinct relation types\nfrom four reputable biomedical websites. To assess the efficacy of the basic\npipeline employed for biomedical relation extraction, we curated a benchmark\ndataset annotated by a medical expert. Evaluation results indicate that the\npipeline exhibits performance comparable to that of GPT-4. Case studies further\nilluminate challenges faced by contemporary LLMs in the context of biomedical\nrelation extraction for semi-structured web articles. Conclusion: The proposed\nmethod has demonstrated its effectiveness in leveraging the strengths of LLMs\nfor high-throughput biomedical relation extraction. Its adaptability is\nevident, as it can be seamlessly extended to diverse semi-structured biomedical\nwebsites, facilitating the extraction of various types of biomedical relations\nwith ease.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Songchi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Sheng Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-12-14T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#"}}]}]}