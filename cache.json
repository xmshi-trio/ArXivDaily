{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-08-22T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"On the Unexpected Abilities of Large Language Models. (arXiv:2308.09720v1 [cs.AI])","link":"http://arxiv.org/abs/2308.09720","description":"<p>Large language models are capable of displaying a wide range of abilities\nthat are not directly connected with the task for which they are trained:\npredicting the next words of human-written texts. In this article, I discuss\nthe nature of this indirect acquisition process and its relation to other known\nindirect processes. I argue that an important side effect of such indirect\nacquisition is the development of integrated abilities. I discuss the extent to\nwhich the abilities developed by large language models are predictable.\nFinally, I briefly discuss the relation between the cognitive skills acquired\nby these systems and human cognition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nolfi_S/0/1/0/all/0/1\">Stefano Nolfi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Trustable LSTM-Autoencoder Network for Cyberbullying Detection on Social Media Using Synthetic Data. (arXiv:2308.09722v1 [cs.LG])","link":"http://arxiv.org/abs/2308.09722","description":"<p>Social media cyberbullying has a detrimental effect on human life. As online\nsocial networking grows daily, the amount of hate speech also increases. Such\nterrible content can cause depression and actions related to suicide. This\npaper proposes a trustable LSTM-Autoencoder Network for cyberbullying detection\non social media using synthetic data. We have demonstrated a cutting-edge\nmethod to address data availability difficulties by producing\nmachine-translated data. However, several languages such as Hindi and Bangla\nstill lack adequate investigations due to a lack of datasets. We carried out\nexperimental identification of aggressive comments on Hindi, Bangla, and\nEnglish datasets using the proposed model and traditional models, including\nLong Short-Term Memory (LSTM), Bidirectional Long Short-Term Memory (BiLSTM),\nLSTM-Autoencoder, Word2vec, Bidirectional Encoder Representations from\nTransformers (BERT), and Generative Pre-trained Transformer 2 (GPT-2) models.\nWe employed evaluation metrics such as f1-score, accuracy, precision, and\nrecall to assess the models performance. Our proposed model outperformed all\nthe models on all datasets, achieving the highest accuracy of 95%. Our model\nachieves state-of-the-art results among all the previous works on the dataset\nwe used in this paper.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Akter_M/0/1/0/all/0/1\">Mst Shapna Akter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahriar_H/0/1/0/all/0/1\">Hossain Shahriar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cuzzocrea_A/0/1/0/all/0/1\">Alfredo Cuzzocrea</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only Quantization for LLMs. (arXiv:2308.09723v1 [cs.LG])","link":"http://arxiv.org/abs/2308.09723","description":"<p>Large Language Models (LLMs) have achieved state-of-the-art performance\nacross various language tasks but pose challenges for practical deployment due\nto their substantial memory requirements. Furthermore, the latest generative\nmodels suffer from high inference costs caused by the memory bandwidth\nbottleneck in the auto-regressive decoding process. To address these issues, we\npropose an efficient weight-only quantization method that reduces memory\nconsumption and accelerates inference for LLMs. To ensure minimal quality\ndegradation, we introduce a simple and effective heuristic approach that\nutilizes only the model weights of a pre-trained model. This approach is\napplicable to both Mixture-of-Experts (MoE) and dense models without requiring\nadditional fine-tuning. To demonstrate the effectiveness of our proposed\nmethod, we first analyze the challenges and issues associated with LLM\nquantization. Subsequently, we present our heuristic approach, which adaptively\nfinds the granularity of quantization, effectively addressing these problems.\nFurthermore, we implement highly efficient GPU GEMMs that perform on-the-fly\nmatrix multiplication and dequantization, supporting the multiplication of fp16\nor bf16 activations with int8 or int4 weights. We evaluate our approach on\nlarge-scale open source models such as OPT-175B and internal MoE models,\nshowcasing minimal accuracy loss while achieving up to 3.65 times higher\nthroughput on the same number of GPUs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Young Jin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henry_R/0/1/0/all/0/1\">Rawn Henry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fahim_R/0/1/0/all/0/1\">Raffy Fahim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadalla_H/0/1/0/all/0/1\">Hany Hassan Awadalla</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models. (arXiv:2308.09729v1 [cs.AI])","link":"http://arxiv.org/abs/2308.09729","description":"<p>LLMs usually exhibit limitations in their ability to incorporate new\nknowledge, the generation of hallucinations, and the transparency of their\ndecision-making process. In this paper, we explore how to prompt LLMs with\nknowledge graphs (KG), working as a remedy to engage LLMs with up-to-date\nknowledge and elicit the reasoning pathways from LLMs. Specifically, we build a\nprompting pipeline that endows LLMs with the capability of comprehending KG\ninputs and inferring with a combined implicit knowledge and the retrieved\nexternal knowledge. In addition, we investigate eliciting the mind map on which\nLLMs perform the reasoning and generate the answers. It is identified that the\nproduced mind map exhibits the reasoning pathways of LLMs grounded on the\nontology of knowledge, hence bringing the prospects of probing and gauging LLM\ninference in production. The experiments on three question &amp; answering datasets\nalso show that MindMap prompting leads to a striking empirical gain. For\ninstance, prompting a GPT-3.5 with MindMap yields an overwhelming performance\nover GPT-4 consistently. We also demonstrate that with structured facts\nretrieved from KG, MindMap can outperform a series of\nprompting-with-document-retrieval methods, benefiting from more accurate,\nconcise, and comprehensive knowledge from KGs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yilin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jimeng Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT-HealthPrompt. Harnessing the Power of XAI in Prompt-Based Healthcare Decision Support using ChatGPT. (arXiv:2308.09731v1 [cs.AI])","link":"http://arxiv.org/abs/2308.09731","description":"<p>This study presents an innovative approach to the application of large\nlanguage models (LLMs) in clinical decision-making, focusing on OpenAI's\nChatGPT. Our approach introduces the use of contextual prompts-strategically\ndesigned to include task description, feature description, and crucially,\nintegration of domain knowledge-for high-quality binary classification tasks\neven in data-scarce scenarios. The novelty of our work lies in the utilization\nof domain knowledge, obtained from high-performing interpretable ML models, and\nits seamless incorporation into prompt design. By viewing these ML models as\nmedical experts, we extract key insights on feature importance to aid in\ndecision-making processes. This interplay of domain knowledge and AI holds\nsignificant promise in creating a more insightful diagnostic tool.\n</p>\n<p>Additionally, our research explores the dynamics of zero-shot and few-shot\nprompt learning based on LLMs. By comparing the performance of OpenAI's ChatGPT\nwith traditional supervised ML models in different data conditions, we aim to\nprovide insights into the effectiveness of prompt engineering strategies under\nvaried data availability. In essence, this paper bridges the gap between AI and\nhealthcare, proposing a novel methodology for LLMs application in clinical\ndecision support systems. It highlights the transformative potential of\neffective prompt design, domain knowledge integration, and flexible learning\napproaches in enhancing automated decision-making.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nazary_F/0/1/0/all/0/1\">Fatemeh Nazary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deldjoo_Y/0/1/0/all/0/1\">Yashar Deldjoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noia_T/0/1/0/all/0/1\">Tommaso Di Noia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Taken by Surprise: Contrast effect for Similarity Scores. (arXiv:2308.09765v1 [cs.CL])","link":"http://arxiv.org/abs/2308.09765","description":"<p>Accurately evaluating the similarity of object vector embeddings is of\ncritical importance for natural language processing, information retrieval and\nclassification tasks. Popular similarity scores (e.g cosine similarity) are\nbased on pairs of embedding vectors and disregard the distribution of the\nensemble from which objects are drawn. Human perception of object similarity\nsignificantly depends on the context in which the objects appear. In this work\nwe propose the \\emph{surprise score}, an ensemble-normalized similarity metric\nthat encapsulates the contrast effect of human perception and significantly\nimproves the classification performance on zero- and few-shot document\nclassification tasks. This score quantifies the surprise to find a given\nsimilarity between two elements relative to the pairwise ensemble similarities.\nWe evaluate this metric on zero/few shot classification and clustering tasks\nand typically find 10-15\\% better performance compared to raw cosine\nsimilarity. Our code is available at\nhttps://github.com/MeetElise/surprise-similarity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bachlechner_h/0/1/0/all/0/1\">homas C. Bachlechner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martone_M/0/1/0/all/0/1\">Mario Martone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schillo_M/0/1/0/all/0/1\">Marjorie Schillo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"YORC: Yoruba Reading Comprehension dataset. (arXiv:2308.09768v1 [cs.CL])","link":"http://arxiv.org/abs/2308.09768","description":"<p>In this paper, we create YORC: a new multi-choice Yoruba Reading\nComprehension dataset that is based on Yoruba high-school reading comprehension\nexamination. We provide baseline results by performing cross-lingual transfer\nusing existing English RACE dataset based on a pre-trained encoder-only model.\nAdditionally, we provide results by prompting large language models (LLMs) like\nGPT-4.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aremu_A/0/1/0/all/0/1\">Anuoluwapo Aremu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alabi_J/0/1/0/all/0/1\">Jesujoba O. Alabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1\">David Ifeoluwa Adelani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language Models. (arXiv:2308.09778v1 [cs.CV])","link":"http://arxiv.org/abs/2308.09778","description":"<p>With the advances in large scale vision-and-language models (VLMs) it is of\ninterest to assess their performance on various visual reasoning tasks such as\ncounting, referring expressions and general visual question answering. The\nfocus of this work is to study the ability of these models to understanding\nspatial relations. Previously, this has been tackled using image-text matching\n(Liu, Emerson, and Collier 2022) or visual question answering task, both\nshowing poor performance and a large gap compared to human performance. To\nbetter understand the gap, we present fine-grained compositional grounding of\nspatial relationships and propose a bottom up approach for ranking spatial\nclauses and evaluating the performance of spatial relationship reasoning task.\nWe propose to combine the evidence from grounding noun phrases corresponding to\nobjects and their locations to compute the final rank of the spatial clause. We\ndemonstrate the approach on representative vision-language models (Tan and\nBansal 2019; Gupta et al. 2022; Kamath et al. 2021) and compare and highlight\ntheir abilities to reason about spatial relationships.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rajabi_N/0/1/0/all/0/1\">Navid Rajabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kosecka_J/0/1/0/all/0/1\">Jana Kosecka</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VL-PET: Vision-and-Language Parameter-Efficient Tuning via Granularity Control. (arXiv:2308.09804v1 [cs.CV])","link":"http://arxiv.org/abs/2308.09804","description":"<p>As the model size of pre-trained language models (PLMs) grows rapidly, full\nfine-tuning becomes prohibitively expensive for model training and storage. In\nvision-and-language (VL), parameter-efficient tuning (PET) techniques are\nproposed to integrate modular modifications (e.g., Adapter and LoRA) into\nencoder-decoder PLMs. By tuning a small set of trainable parameters, these\ntechniques perform on par with full fine-tuning. However, excessive modular\nmodifications and neglecting the functionality gap between the encoders and\ndecoders can lead to performance degradation, while existing PET techniques\n(e.g., VL-Adapter) overlook these critical issues. In this paper, we propose a\nVision-and-Language Parameter-Efficient Tuning (VL-PET) framework to impose\neffective control over modular modifications via a novel granularity-controlled\nmechanism. Considering different granularity-controlled matrices generated by\nthis mechanism, a variety of model-agnostic VL-PET modules can be instantiated\nfrom our framework for better efficiency and effectiveness trade-offs. We\nfurther propose lightweight PET module designs to enhance VL alignment and\nmodeling for the encoders and maintain text generation for the decoders.\nExtensive experiments conducted on four image-text tasks and four video-text\ntasks demonstrate the efficiency, effectiveness and transferability of our\nVL-PET framework. In particular, our VL-PET-large with lightweight PET module\ndesigns significantly outperforms VL-Adapter by 2.92% (3.41%) and LoRA by 3.37%\n(7.03%) with BART-base (T5-base) on image-text tasks. Furthermore, we validate\nthe enhanced effect of employing our VL-PET designs on existing PET techniques,\nenabling them to achieve significant performance improvements. Our code is\navailable at https://github.com/HenryHZY/VL-PET.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zi-Yuan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael R. Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Image is Worth a Thousand Toxic Words: A Metamorphic Testing Framework for Content Moderation Software. (arXiv:2308.09810v1 [cs.SE])","link":"http://arxiv.org/abs/2308.09810","description":"<p>The exponential growth of social media platforms has brought about a\nrevolution in communication and content dissemination in human society.\nNevertheless, these platforms are being increasingly misused to spread toxic\ncontent, including hate speech, malicious advertising, and pornography, leading\nto severe negative consequences such as harm to teenagers' mental health.\nDespite tremendous efforts in developing and deploying textual and image\ncontent moderation methods, malicious users can evade moderation by embedding\ntexts into images, such as screenshots of the text, usually with some\ninterference. We find that modern content moderation software's performance\nagainst such malicious inputs remains underexplored. In this work, we propose\nOASIS, a metamorphic testing framework for content moderation software. OASIS\nemploys 21 transform rules summarized from our pilot study on 5,000 real-world\ntoxic contents collected from 4 popular social media applications, including\nTwitter, Instagram, Sina Weibo, and Baidu Tieba. Given toxic textual contents,\nOASIS can generate image test cases, which preserve the toxicity yet are likely\nto bypass moderation. In the evaluation, we employ OASIS to test five\ncommercial textual content moderation software from famous companies (i.e.,\nGoogle Cloud, Microsoft Azure, Baidu Cloud, Alibaba Cloud and Tencent Cloud),\nas well as a state-of-the-art moderation research model. The results show that\nOASIS achieves up to 100% error finding rates. Moreover, through retraining the\nmodels with the test cases generated by OASIS, the robustness of the moderation\nmodel can be improved without performance degradation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jingyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jen-tse Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiazhen Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pinjia He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael R. Lyu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How susceptible are LLMs to Logical Fallacies?. (arXiv:2308.09853v1 [cs.CL])","link":"http://arxiv.org/abs/2308.09853","description":"<p>This paper investigates the rational thinking capability of Large Language\nModels (LLMs) in multi-round argumentative debates by exploring the impact of\nfallacious arguments on their logical reasoning performance. More specifically,\nwe present Logic Competence Measurement Benchmark (LOGICOM), a diagnostic\nbenchmark to assess the robustness of LLMs against logical fallacies. LOGICOM\ninvolves two agents: a persuader and a debater engaging in a multi-round debate\non a controversial topic, where the persuader tries to convince the debater of\nthe correctness of its claim. First, LOGICOM assesses the potential of LLMs to\nchange their opinions through reasoning. Then, it evaluates the debater's\nperformance in logical reasoning by contrasting the scenario where the\npersuader employs logical fallacies against one where logical reasoning is\nused. We use this benchmark to evaluate the performance of GPT-3.5 and GPT-4\nusing a dataset containing controversial topics, claims, and reasons supporting\nthem. Our findings indicate that both GPT-3.5 and GPT-4 can adjust their\nopinion through reasoning. However, when presented with logical fallacies,\nGPT-3.5 and GPT-4 are erroneously convinced 41% and 69% more often,\nrespectively, compared to when logical reasoning is used. Finally, we introduce\na new dataset containing over 5k pairs of logical vs. fallacious arguments. The\nsource code and dataset of this work are made publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Payandeh_A/0/1/0/all/0/1\">Amirreza Payandeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pluth_D/0/1/0/all/0/1\">Dan Pluth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosier_J/0/1/0/all/0/1\">Jordan Hosier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xuesu Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurbani_V/0/1/0/all/0/1\">Vijay K. Gurbani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Black-box Adversarial Attacks against Dense Retrieval Models: A Multi-view Contrastive Learning Method. (arXiv:2308.09861v1 [cs.IR])","link":"http://arxiv.org/abs/2308.09861","description":"<p>Neural ranking models (NRMs) and dense retrieval (DR) models have given rise\nto substantial improvements in overall retrieval performance. In addition to\ntheir effectiveness, and motivated by the proven lack of robustness of deep\nlearning-based approaches in other areas, there is growing interest in the\nrobustness of deep learning-based approaches to the core retrieval problem.\nAdversarial attack methods that have so far been developed mainly focus on\nattacking NRMs, with very little attention being paid to the robustness of DR\nmodels. In this paper, we introduce the adversarial retrieval attack (AREA)\ntask. The AREA task is meant to trick DR models into retrieving a target\ndocument that is outside the initial set of candidate documents retrieved by\nthe DR model in response to a query. We consider the decision-based black-box\nadversarial setting, which is realistic in real-world search engines. To\naddress the AREA task, we first employ existing adversarial attack methods\ndesigned for NRMs. We find that the promising results that have previously been\nreported on attacking NRMs, do not generalize to DR models: these methods\nunderperform a simple term spamming method. We attribute the observed lack of\ngeneralizability to the interaction-focused architecture of NRMs, which\nemphasizes fine-grained relevance matching. DR models follow a different\nrepresentation-focused architecture that prioritizes coarse-grained\nrepresentations. We propose to formalize attacks on DR models as a contrastive\nlearning problem in a multi-view representation space. The core idea is to\nencourage the consistency between each view representation of the target\ndocument and its corresponding viewer via view-wise supervision signals.\nExperimental results demonstrate that the proposed method can significantly\noutperform existing attack strategies in misleading the DR model with small\nindiscernible text perturbations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yu-An Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jiafeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1\">Maarten de Rijke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yixing Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xueqi Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Breaking Language Barriers: A Question Answering Dataset for Hindi and Marathi. (arXiv:2308.09862v1 [cs.CL])","link":"http://arxiv.org/abs/2308.09862","description":"<p>The recent advances in deep-learning have led to the development of highly\nsophisticated systems with an unquenchable appetite for data. On the other\nhand, building good deep-learning models for low-resource languages remains a\nchallenging task. This paper focuses on developing a Question Answering dataset\nfor two such languages- Hindi and Marathi. Despite Hindi being the 3rd most\nspoken language worldwide, with 345 million speakers, and Marathi being the\n11th most spoken language globally, with 83.2 million speakers, both languages\nface limited resources for building efficient Question Answering systems. To\ntackle the challenge of data scarcity, we have developed a novel approach for\ntranslating the SQuAD 2.0 dataset into Hindi and Marathi. We release the\nlargest Question-Answering dataset available for these languages, with each\ndataset containing 28,000 samples. We evaluate the dataset on various\narchitectures and release the best-performing models for both Hindi and\nMarathi, which will facilitate further research in these languages. Leveraging\nsimilarity tools, our method holds the potential to create datasets in diverse\nlanguages, thereby enhancing the understanding of natural language across\nvaried linguistic contexts. Our fine-tuned models, code, and dataset will be\nmade publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sabane_M/0/1/0/all/0/1\">Maithili Sabane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litake_O/0/1/0/all/0/1\">Onkar Litake</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Inductive-bias Learning: Generating Code Models with Large Language Model. (arXiv:2308.09890v1 [cs.LG])","link":"http://arxiv.org/abs/2308.09890","description":"<p>Large Language Models(LLMs) have been attracting attention due to a ability\ncalled in-context learning(ICL). ICL, without updating the parameters of a LLM,\nit is possible to achieve highly accurate inference based on rules ``in the\ncontext'' by merely inputting a training data into the prompt. Although ICL is\na developing field with many unanswered questions, LLMs themselves serves as a\ninference model, seemingly realizing inference without explicitly indicate\n``inductive bias''. On the other hand, a code generation is also a highlighted\napplication of LLMs. The accuracy of code generation has dramatically improved,\nenabling even non-engineers to generate code to perform the desired tasks by\ncrafting appropriate prompts. In this paper, we propose a novel ``learning''\nmethod called an ``Inductive-Bias Learning (IBL)'', which combines the\ntechniques of ICL and code generation. An idea of IBL is straightforward. Like\nICL, IBL inputs a training data into the prompt and outputs a code with a\nnecessary structure for inference (we referred to as ``Code Model'') from a\n``contextual understanding''. Despite being a seemingly simple approach, IBL\nencompasses both a ``property of inference without explicit inductive bias''\ninherent in ICL and a ``readability and explainability'' of the code\ngeneration. Surprisingly, generated Code Models have been found to achieve\npredictive accuracy comparable to, and in some cases surpassing, ICL and\nrepresentative machine learning models. Our IBL code is open source:\nhttps://github.com/fuyu-quant/IBLM\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_T/0/1/0/all/0/1\">Toma Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emoto_N/0/1/0/all/0/1\">Naofumi Emoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yumibayashi_T/0/1/0/all/0/1\">Tsukasa Yumibayashi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Utilizing Semantic Textual Similarity for Clinical Survey Data Feature Selection. (arXiv:2308.09892v1 [cs.CL])","link":"http://arxiv.org/abs/2308.09892","description":"<p>Survey data can contain a high number of features while having a\ncomparatively low quantity of examples. Machine learning models that attempt to\npredict outcomes from survey data under these conditions can overfit and result\nin poor generalizability. One remedy to this issue is feature selection, which\nattempts to select an optimal subset of features to learn upon. A relatively\nunexplored source of information in the feature selection process is the usage\nof textual names of features, which may be semantically indicative of which\nfeatures are relevant to a target outcome. The relationships between feature\nnames and target names can be evaluated using language models (LMs) to produce\nsemantic textual similarity (STS) scores, which can then be used to select\nfeatures. We examine the performance using STS to select features directly and\nin the minimal-redundancy-maximal-relevance (mRMR) algorithm. The performance\nof STS as a feature selection metric is evaluated against preliminary survey\ndata collected as a part of a clinical study on persistent post-surgical pain\n(PPSP). The results suggest that features selected with STS can result in\nhigher performance models compared to traditional feature selection algorithms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Warner_B/0/1/0/all/0/1\">Benjamin C. Warner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Ziqi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haroutounian_S/0/1/0/all/0/1\">Simon Haroutounian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannampallil_T/0/1/0/all/0/1\">Thomas Kannampallil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chenyang Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Eva-KELLM: A New Benchmark for Evaluating Knowledge Editing of LLMs. (arXiv:2308.09954v1 [cs.CL])","link":"http://arxiv.org/abs/2308.09954","description":"<p>Large language models (LLMs) possess a wealth of knowledge encoded in their\nparameters. However, this knowledge may become outdated or unsuitable over\ntime. As a result, there has been a growing interest in knowledge editing for\nLLMs and evaluating its effectiveness. Existing studies primarily focus on\nknowledge editing using factual triplets, which not only incur high costs for\ncollection but also struggle to express complex facts. Furthermore, these\nstudies are often limited in their evaluation perspectives. In this paper, we\npropose Eva-KELLM, a new benchmark for evaluating knowledge editing of LLMs.\nThis benchmark includes an evaluation framework and a corresponding dataset.\nUnder our framework, we first ask the LLM to perform knowledge editing using\nraw documents, which provides a more convenient and universal approach compared\nto using factual triplets. We then evaluate the updated LLM from multiple\nperspectives. In addition to assessing the effectiveness of knowledge editing\nand the retention of unrelated knowledge from conventional studies, we further\ntest the LLM's ability in two aspects: 1) Reasoning with the altered knowledge,\naiming for the LLM to genuinely learn the altered knowledge instead of simply\nmemorizing it. 2) Cross-lingual knowledge transfer, where the LLM updated with\nraw documents in one language should be capable of handling queries from\nanother language. To facilitate further research, we construct and release the\ncorresponding dataset. Using this benchmark, we investigate the effectiveness\nof several commonly-used knowledge editing methods. Experimental results\nindicate that the current methods for knowledge editing using raw documents are\nnot effective in yielding satisfactory results, particularly when it comes to\nreasoning with altered knowledge and cross-lingual knowledge transfer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Suhang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_M/0/1/0/all/0/1\">Minlong Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yue Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jinsong Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Mingming Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data-to-text Generation for Severely Under-Resourced Languages with GPT-3.5: A Bit of Help Needed from Google Translate. (arXiv:2308.09957v1 [cs.CL])","link":"http://arxiv.org/abs/2308.09957","description":"<p>LLMs like GPT are great at tasks involving English which dominates in their\ntraining data. In this paper, we look at how they cope with tasks involving\nlanguages that are severely under-represented in their training data, in the\ncontext of data-to-text generation for Irish, Maltese, Welsh and Breton. During\nthe prompt-engineering phase we tested a range of prompt types and formats on\nGPT-3.5 and~4 with a small sample of example input/output pairs. We then fully\nevaluated the two most promising prompts in two scenarios: (i) direct\ngeneration into the under-resourced language, and (ii) generation into English\nfollowed by translation into the under-resourced language. We find that\nfew-shot prompting works better for direct generation into under-resourced\nlanguages, but that the difference disappears when pivoting via English. The\nfew-shot + translation system variants were submitted to the WebNLG 2023 shared\ntask where they outperformed competitor systems by substantial margins in all\nlanguages on all metrics. We conclude that good performance on under-resourced\nlanguages can be achieved out-of-the box with state-of-the-art LLMs. However,\nour best results (for Welsh) remain well below the lowest ranked English system\nat WebNLG'20.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lorandi_M/0/1/0/all/0/1\">Michela Lorandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belz_A/0/1/0/all/0/1\">Anya Belz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tackling Vision Language Tasks Through Learning Inner Monologues. (arXiv:2308.09970v1 [cs.CL])","link":"http://arxiv.org/abs/2308.09970","description":"<p>Visual language tasks require AI models to comprehend and reason with both\nvisual and textual content. Driven by the power of Large Language Models\n(LLMs), two prominent methods have emerged: (1) the hybrid integration between\nLLMs and Vision-Language Models (VLMs), where visual inputs are firstly\nconverted into language descriptions by VLMs, serving as inputs for LLMs to\ngenerate final answer(s); (2) visual feature alignment in language space, where\nvisual inputs are encoded as embeddings and projected to LLMs' language space\nvia further supervised fine-tuning. The first approach provides light training\ncosts and interpretability but is hard to be optimized in an end-to-end\nfashion. The second approach presents decent performance, but feature alignment\nusually requires large amounts of training data and lacks interpretability. To\ntackle this dilemma, we propose a novel approach, Inner Monologue Multi-Modal\nOptimization (IMMO), to solve complex vision language problems by simulating\ninner monologue processes, a cognitive process in which an individual engages\nin silent verbal communication with themselves. We enable LLMs and VLMs to\ninteract through natural language conversation and propose to use a two-stage\ntraining process to learn how to do the inner monologue (self-asking questions\nand answering questions). IMMO is evaluated on two popular tasks and the\nresults suggest by emulating the cognitive phenomenon of internal dialogue, our\napproach can enhance reasoning and explanation abilities, contributing to the\nmore effective fusion of vision and language models. More importantly, instead\nof using predefined human-crafted monologues, IMMO learns this process within\nthe deep learning models, promising wider applicability to many different AI\nproblems beyond vision language tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diji Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kezhen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_J/0/1/0/all/0/1\">Jinmeng Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xiaoyuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yawen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models. (arXiv:2308.09975v1 [cs.CL])","link":"http://arxiv.org/abs/2308.09975","description":"<p>Large language models (LLMs) have demonstrated exceptional performance in\nvarious natural language processing tasks, yet their efficacy in more\nchallenging and domain-specific tasks remains largely unexplored. This paper\npresents FinEval, a benchmark specifically designed for the financial domain\nknowledge in the LLMs. FinEval is a collection of high-quality multiple-choice\nquestions covering Finance, Economy, Accounting, and Certificate. It includes\n4,661 questions spanning 34 different academic subjects. To ensure a\ncomprehensive model performance evaluation, FinEval employs a range of prompt\ntypes, including zero-shot and few-shot prompts, as well as answer-only and\nchain-of-thought prompts. Evaluating state-of-the-art Chinese and English LLMs\non FinEval, the results show that only GPT-4 achieved an accuracy close to 70%\nin different prompt settings, indicating significant growth potential for LLMs\nin the financial domain knowledge. Our work offers a more comprehensive\nfinancial knowledge evaluation benchmark, utilizing data of mock exams and\ncovering a wide range of evaluated LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Liwen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1\">Weige Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhaowei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Wei Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yujie Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Q/0/1/0/all/0/1\">Qianru Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yifei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xingyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiqiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhoufan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Anbo Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xin Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HICL: Hashtag-Driven In-Context Learning for Social Media Natural Language Understanding. (arXiv:2308.09985v1 [cs.CL])","link":"http://arxiv.org/abs/2308.09985","description":"<p>Natural language understanding (NLU) is integral to various social media\napplications. However, existing NLU models rely heavily on context for semantic\nlearning, resulting in compromised performance when faced with short and noisy\nsocial media content. To address this issue, we leverage in-context learning\n(ICL), wherein language models learn to make inferences by conditioning on a\nhandful of demonstrations to enrich the context and propose a novel\nhashtag-driven in-context learning (HICL) framework. Concretely, we pre-train a\nmodel #Encoder, which employs #hashtags (user-annotated topic labels) to drive\nBERT-based pre-training through contrastive learning. Our objective here is to\nenable #Encoder to gain the ability to incorporate topic-related semantic\ninformation, which allows it to retrieve topic-related posts to enrich contexts\nand enhance social media NLU with noisy contexts. To further integrate the\nretrieved context with the source text, we employ a gradient-based method to\nidentify trigger terms useful in fusing information from both sources. For\nempirical studies, we collected 45M tweets to set up an in-context NLU\nbenchmark, and the experimental results on seven downstream tasks show that\nHICL substantially advances the previous state-of-the-art results. Furthermore,\nwe conducted extensive analyzes and found that: (1) combining source input with\na top-retrieved post from #Encoder is more effective than using semantically\nsimilar posts; (2) trigger words can largely benefit in merging context from\nthe source and retrieved posts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1\">Hanzhuo Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chunpu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuqun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1\">Zeyang Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_B/0/1/0/all/0/1\">Baohua Lai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ControlRetriever: Harnessing the Power of Instructions for Controllable Retrieval. (arXiv:2308.10025v1 [cs.CL])","link":"http://arxiv.org/abs/2308.10025","description":"<p>Recent studies have shown that dense retrieval models, lacking dedicated\ntraining data, struggle to perform well across diverse retrieval tasks, as\ndifferent retrieval tasks often entail distinct search intents. To address this\nchallenge, in this work we introduce ControlRetriever, a generic and efficient\napproach with a parameter isolated architecture, capable of controlling dense\nretrieval models to directly perform varied retrieval tasks, harnessing the\npower of instructions that explicitly describe retrieval intents in natural\nlanguage. Leveraging the foundation of ControlNet, which has proven powerful in\ntext-to-image generation, ControlRetriever imbues different retrieval models\nwith the new capacity of controllable retrieval, all while being guided by\ntask-specific instructions. Furthermore, we propose a novel LLM guided\nInstruction Synthesizing and Iterative Training strategy, which iteratively\ntunes ControlRetriever based on extensive automatically-generated retrieval\ndata with diverse instructions by capitalizing the advancement of large\nlanguage models. Extensive experiments show that in the BEIR benchmark, with\nonly natural language descriptions of specific retrieval intent for each task,\nControlRetriever, as a unified multi-task retrieval system without\ntask-specific tuning, significantly outperforms baseline methods designed with\ntask-specific retrievers and also achieves state-of-the-art zero-shot\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_K/0/1/0/all/0/1\">Kaihang Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juncheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hongye Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_W/0/1/0/all/0/1\">Wei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jun Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaozhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siliang Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GameEval: Evaluating LLMs on Conversational Games. (arXiv:2308.10032v1 [cs.CL])","link":"http://arxiv.org/abs/2308.10032","description":"<p>The rapid advancements in large language models (LLMs) have presented\nchallenges in evaluating those models. Existing evaluation methods are either\nreference-based or preference based, which inevitably need human intervention\nor introduce test bias caused by evaluator models. In this paper, we propose\nGameEval, a novel approach to evaluating LLMs through goal-driven\nconversational games, overcoming the limitations of previous methods. GameEval\ntreats LLMs as game players and assigns them distinct roles with specific goals\nachieved by launching conversations of various forms, including discussion,\nquestion answering, and voting. We design three unique games with cooperative\nor adversarial objectives, accompanied by corresponding evaluation metrics, to\nshow how this new paradigm comprehensively evaluates model performance.Through\nextensive experiments, we show that GameEval can effectively differentiate the\ncapabilities of various LLMs, providing a comprehensive assessment of their\nintegrated abilities to solve complex problems. Our public anonymous code is\navailable at https://github.com/GameEval/GameEval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiao_D/0/1/0/all/0/1\">Dan Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chenfei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yaobo Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juntao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Survey on Publicly Available Sinhala Natural Language Processing Tools and Research. (arXiv:1906.02358v20 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/1906.02358","description":"<p>Sinhala is the native language of the Sinhalese people who make up the\nlargest ethnic group of Sri Lanka. The language belongs to the globe-spanning\nlanguage tree, Indo-European. However, due to poverty in both linguistic and\neconomic capital, Sinhala, in the perspective of Natural Language Processing\ntools and research, remains a resource-poor language which has neither the\neconomic drive its cousin English has nor the sheer push of the law of numbers\na language such as Chinese has. A number of research groups from Sri Lanka have\nnoticed this dearth and the resultant dire need for proper tools and research\nfor Sinhala natural language processing. However, due to various reasons, these\nattempts seem to lack coordination and awareness of each other. The objective\nof this paper is to fill that gap of a comprehensive literature survey of the\npublicly available Sinhala natural language tools and research so that the\nresearchers working in this field can better utilize contributions of their\npeers. As such, we shall be uploading this paper to arXiv and perpetually\nupdate it periodically to reflect the advances made in the field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Silva_N/0/1/0/all/0/1\">Nisansa de Silva</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Multimodal Word Discovery based on Double Articulation Analysis with Co-occurrence cues. (arXiv:2201.06786v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2201.06786","description":"<p>Human infants acquire their verbal lexicon with minimal prior knowledge of\nlanguage based on the statistical properties of phonological distributions and\nthe co-occurrence of other sensory stimuli. This study proposes a novel fully\nunsupervised learning method for discovering speech units using phonological\ninformation as a distributional cue and object information as a co-occurrence\ncue. The proposed method can acquire words and phonemes from speech signals\nusing unsupervised learning and utilize object information based on multiple\nmodalities-vision, tactile, and auditory-simultaneously. The proposed method is\nbased on the nonparametric Bayesian double articulation analyzer (NPB-DAA)\ndiscovering phonemes and words from phonological features, and multimodal\nlatent Dirichlet allocation (MLDA) categorizing multimodal information obtained\nfrom objects. In an experiment, the proposed method showed higher word\ndiscovery performance than baseline methods. Words that expressed the\ncharacteristics of objects (i.e., words corresponding to nouns and adjectives)\nwere segmented accurately. Furthermore, we examined how learning performance is\naffected by differences in the importance of linguistic information. Increasing\nthe weight of the word modality further improved performance relative to that\nof the fixed condition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Taniguchi_A/0/1/0/all/0/1\">Akira Taniguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murakami_H/0/1/0/all/0/1\">Hiroaki Murakami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozaki_R/0/1/0/all/0/1\">Ryo Ozaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taniguchi_T/0/1/0/all/0/1\">Tadahiro Taniguchi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks. (arXiv:2207.13243v6 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2207.13243","description":"<p>The last decade of machine learning has seen drastic increases in scale and\ncapabilities. Deep neural networks (DNNs) are increasingly being deployed in\nthe real world. However, they are difficult to analyze, raising concerns about\nusing them without a rigorous understanding of how they function. Effective\ntools for interpreting them will be important for building more trustworthy AI\nby helping to identify problems, fix bugs, and improve basic understanding. In\nparticular, \"inner\" interpretability techniques, which focus on explaining the\ninternal components of DNNs, are well-suited for developing a mechanistic\nunderstanding, guiding manual modifications, and reverse engineering solutions.\n</p>\n<p>Much recent work has focused on DNN interpretability, and rapid progress has\nthus far made a thorough systematization of methods difficult. In this survey,\nwe review over 300 works with a focus on inner interpretability tools. We\nintroduce a taxonomy that classifies methods by what part of the network they\nhelp to explain (weights, neurons, subnetworks, or latent representations) and\nwhether they are implemented during (intrinsic) or after (post hoc) training.\nTo our knowledge, we are also the first to survey a number of connections\nbetween interpretability research and work in adversarial robustness, continual\nlearning, modularity, network compression, and studying the human visual\nsystem. We discuss key challenges and argue that the status quo in\ninterpretability research is largely unproductive. Finally, we highlight the\nimportance of future work that emphasizes diagnostics, debugging, adversaries,\nand benchmarking in order to make interpretability tools more useful to\nengineers in practical applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rauker_T/0/1/0/all/0/1\">Tilman R&#xe4;uker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_A/0/1/0/all/0/1\">Anson Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casper_S/0/1/0/all/0/1\">Stephen Casper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadfield_Menell_D/0/1/0/all/0/1\">Dylan Hadfield-Menell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PreSTU: Pre-Training for Scene-Text Understanding. (arXiv:2209.05534v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2209.05534","description":"<p>The ability to recognize and reason about text embedded in visual inputs is\noften lacking in vision-and-language (V&amp;L) models, perhaps because V&amp;L\npre-training methods have often failed to include such an ability in their\ntraining objective. In this paper, we propose PreSTU, a novel pre-training\nrecipe dedicated to scene-text understanding (STU). PreSTU introduces OCR-aware\npre-training objectives that encourage the model to recognize text from an\nimage and connect it to the rest of the image content. We implement PreSTU\nusing a simple transformer-based encoder-decoder architecture, combined with\nlarge-scale image-text datasets with scene text obtained from an off-the-shelf\nOCR system. We empirically demonstrate the effectiveness of this pre-training\napproach on eight visual question answering and four image captioning\nbenchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kil_J/0/1/0/all/0/1\">Jihyung Kil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Changpinyo_S/0/1/0/all/0/1\">Soravit Changpinyo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hexiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_S/0/1/0/all/0/1\">Sebastian Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_W/0/1/0/all/0/1\">Wei-Lun Chao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soricut_R/0/1/0/all/0/1\">Radu Soricut</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"YATO: Yet Another deep learning based Text analysis Open toolkit. (arXiv:2209.13877v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.13877","description":"<p>We introduce YATO, an open-source, easy-to-use toolkit for text analysis with\ndeep learning. Different from existing heavily engineered toolkits and\nplatforms, YATO is lightweight and user-friendly for researchers from\ncross-disciplinary areas. Designed in a hierarchical structure, YATO supports\nfree combinations of three types of widely used features including 1)\ntraditional neural networks (CNN, RNN, etc.); 2) pre-trained language models\n(BERT, RoBERTa, ELECTRA, etc.); and 3) user-customized neural features via a\nsimple configurable file. Benefiting from the advantages of flexibility and\nease of use, YATO can facilitate fast reproduction and refinement of\nstate-of-the-art NLP models, and promote the cross-disciplinary applications of\nNLP techniques. The code, examples, and documentation are publicly available at\nhttps://github.com/jiesutd/YATO. A demo video is also available at\nhttps://youtu.be/tSjjf5BzfQg.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zeqiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yile Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiageng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_Z/0/1/0/all/0/1\">Zhiyang Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jie Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"I Can't Believe There's No Images! Learning Visual Tasks Using only Language Supervision. (arXiv:2211.09778v4 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2211.09778","description":"<p>Many high-level skills that are required for computer vision tasks, such as\nparsing questions, comparing and contrasting semantics, and writing\ndescriptions, are also required in other domains such as natural language\nprocessing. In this paper, we ask whether it is possible to learn those skills\nfrom text data and then transfer them to vision tasks without ever training on\nvisual training data. Key to our approach is exploiting the joint embedding\nspace of contrastively trained vision and language encoders. In practice, there\ncan be systematic differences between embedding spaces for different modalities\nin contrastive models, and we analyze how these differences affect our approach\nand study strategies to mitigate this concern. We produce models using only\ntext training data on four representative tasks: image captioning, visual\nentailment, visual question answering and visual news captioning, and evaluate\nthem on standard benchmarks using images. We find these models perform close to\nmodels trained on images, while surpassing prior work for captioning and visual\nentailment in this text-only setting by over 9 points, and outperforming all\nprior work on visual news by over 30 points. We also showcase a variety of\nstylistic image captioning models that are trained using no image data and no\nhuman-curated language data, but instead using readily-available text data from\nbooks, the web, or language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1\">Sophia Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_C/0/1/0/all/0/1\">Christopher Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kembhavi_A/0/1/0/all/0/1\">Aniruddha Kembhavi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Practical Few-shot Federated NLP. (arXiv:2212.00192v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.00192","description":"<p>Transformer-based pre-trained models have emerged as the predominant solution\nfor natural language processing (NLP). Fine-tuning such pre-trained models for\ndownstream tasks often requires a considerable amount of labeled private data.\nIn practice, private data is often distributed across heterogeneous mobile\ndevices and may be prohibited from being uploaded. Moreover, well-curated\nlabeled data is often scarce, presenting an additional challenge. To address\nthese challenges, we first introduce a data generator for federated few-shot\nlearning tasks, which encompasses the quantity and skewness of scarce labeled\ndata in a realistic setting. Subsequently, we propose AUG-FedPrompt, a\nprompt-based federated learning system that exploits abundant unlabeled data\nfor data augmentation. Our experiments indicate that AUG-FedPrompt can perform\non par with full-set fine-tuning with a limited amount of labeled data.\nHowever, such competitive performance comes at a significant system cost.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Dongqi Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yaozong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Haitao Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shangguang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1\">Felix Xiaozhu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mengwei Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Federated Few-Shot Learning for Mobile NLP. (arXiv:2212.05974v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2212.05974","description":"<p>Natural language processing (NLP) sees rich mobile applications. To support\nvarious language understanding tasks, a foundation NLP model is often\nfine-tuned in a federated, privacy-preserving setting (FL). This process\ncurrently relies on at least hundreds of thousands of labeled training samples\nfrom mobile clients; yet mobile users often lack willingness or knowledge to\nlabel their data. Such an inadequacy of data labels is known as a few-shot\nscenario; it becomes the key blocker for mobile NLP applications.\n</p>\n<p>For the first time, this work investigates federated NLP in the few-shot\nscenario (FedFSL). By retrofitting algorithmic advances of pseudo labeling and\nprompt learning, we first establish a training pipeline that delivers\ncompetitive accuracy when only 0.05% (fewer than 100) of the training data is\nlabeled and the remaining is unlabeled. To instantiate the workflow, we further\npresent a system FeS, addressing the high execution cost with novel designs.\n(1) Curriculum pacing, which injects pseudo labels to the training workflow at\na rate commensurate to the learning progress; (2) Representational diversity, a\nmechanism for selecting the most learnable data, only for which pseudo labels\nwill be generated; (3) Co-planning of a model's training depth and layer\ncapacity. Together, these designs reduce the training delay, client energy, and\nnetwork traffic by up to 46.0$\\times$, 41.2$\\times$ and 3000.0$\\times$,\nrespectively. Through algorithm/system co-design, FFNLP demonstrates that FL\ncan apply to challenging settings where most training samples are unlabeled.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Dongqi Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shangguang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yaozong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1\">Felix Xiaozhu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mengwei Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Augmentation using Transformers and Similarity Measures for Improving Arabic Text Classification. (arXiv:2212.13939v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.13939","description":"<p>The performance of learning models heavily relies on the availability and\nadequacy of training data. To address the dataset adequacy issue, researchers\nhave extensively explored data augmentation (DA) as a promising approach. DA\ngenerates new data instances through transformations applied to the available\ndata, thereby increasing dataset size and variability. This approach has\nenhanced model performance and accuracy, particularly in addressing class\nimbalance problems in classification tasks. However, few studies have explored\nDA for the Arabic language, relying on traditional approaches such as\nparaphrasing or noising-based techniques. In this paper, we propose a new\nArabic DA method that employs the recent powerful modeling technique, namely\nthe AraGPT-2, for the augmentation process. The generated sentences are\nevaluated in terms of context, semantics, diversity, and novelty using the\nEuclidean, cosine, Jaccard, and BLEU distances. Finally, the AraBERT\ntransformer is used on sentiment classification tasks to evaluate the\nclassification performance of the augmented Arabic dataset. The experiments\nwere conducted on four sentiment Arabic datasets: AraSarcasm, ASTD, ATT, and\nMOVIE. The selected datasets vary in size, label number, and unbalanced\nclasses. The results show that the proposed methodology enhanced the Arabic\nsentiment text classification on all datasets with an increase in F1 score by\n4% in AraSarcasm, 6% in ASTD, 9% in ATT, and 13% in MOVIE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Refai_D/0/1/0/all/0/1\">Dania Refai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abo_Soud_S/0/1/0/all/0/1\">Saleh Abo-Soud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdel_Rahman_M/0/1/0/all/0/1\">Mohammad Abdel-Rahman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language-Specific Representation of Emotion-Concept Knowledge Causally Supports Emotion Inference. (arXiv:2302.09582v4 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2302.09582","description":"<p>Understanding how language supports emotion inference remains a topic of\ndebate in emotion science. The present study investigated whether\nlanguage-derived emotion-concept knowledge would causally support emotion\ninference by manipulating the language-specific knowledge representations in\nlarge language models. Using the prompt technique, 14 attributes of emotion\nconcepts were found to be represented by distinct artificial neuron\npopulations. By manipulating these attribute-related neurons, the majority of\nthe emotion inference tasks showed performance deterioration compared to random\nmanipulations. The attribute-specific performance deterioration was related to\nthe importance of different attributes in human mental space. Our findings\nprovide causal evidence in support of a language-based mechanism for emotion\ninference and highlight the contributions of emotion-concept knowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Ming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yusheng Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Hsiu-Yuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1\">Jiali Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinmiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huadong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yujia Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaozhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dan Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction. (arXiv:2303.05063v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.05063","description":"<p>Large language models (LLMs), such as GPT-3 and ChatGPT, have demonstrated\nremarkable results in various natural language processing (NLP) tasks with\nin-context learning, which involves inference based on a few demonstration\nexamples. Despite their successes in NLP tasks, no investigation has been\nconducted to assess the ability of LLMs to perform document information\nextraction (DIE) using in-context learning. Applying LLMs to DIE poses two\nchallenges: the modality and task gap. To this end, we propose a simple but\neffective in-context learning framework called ICL-D3IE, which enables LLMs to\nperform DIE with different types of demonstration examples. Specifically, we\nextract the most difficult and distinct segments from hard training documents\nas hard demonstrations for benefiting all test instances. We design\ndemonstrations describing relationships that enable LLMs to understand\npositional relationships. We introduce formatting demonstrations for easy\nanswer extraction. Additionally, the framework improves diverse demonstrations\nby updating them iteratively. Our experiments on three widely used benchmark\ndatasets demonstrate that the ICL-D3IE framework enables Davinci-003/ChatGPT to\nachieve superior performance when compared to previous pre-trained methods\nfine-tuned with full training in both the in-distribution (ID) setting and in\nthe out-of-distribution (OOD) setting. Code is available at\nhttps://github.com/MAEHCM/ICL-D3IE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jiabang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Heng Tao Shen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-Shot Composed Image Retrieval with Textual Inversion. (arXiv:2303.15247v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2303.15247","description":"<p>Composed Image Retrieval (CIR) aims to retrieve a target image based on a\nquery composed of a reference image and a relative caption that describes the\ndifference between the two images. The high effort and cost required for\nlabeling datasets for CIR hamper the widespread usage of existing methods, as\nthey rely on supervised learning. In this work, we propose a new task,\nZero-Shot CIR (ZS-CIR), that aims to address CIR without requiring a labeled\ntraining dataset. Our approach, named zero-Shot composEd imAge Retrieval with\ntextuaL invErsion (SEARLE), maps the visual features of the reference image\ninto a pseudo-word token in CLIP token embedding space and integrates it with\nthe relative caption. To support research on ZS-CIR, we introduce an\nopen-domain benchmarking dataset named Composed Image Retrieval on Common\nObjects in context (CIRCO), which is the first dataset for CIR containing\nmultiple ground truths for each query. The experiments show that SEARLE\nexhibits better performance than the baselines on the two main datasets for CIR\ntasks, FashionIQ and CIRR, and on the proposed CIRCO. The dataset, the code and\nthe model are publicly available at https://github.com/miccunifi/SEARLE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Baldrati_A/0/1/0/all/0/1\">Alberto Baldrati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agnolucci_L/0/1/0/all/0/1\">Lorenzo Agnolucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertini_M/0/1/0/all/0/1\">Marco Bertini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bimbo_A/0/1/0/all/0/1\">Alberto Del Bimbo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Supporting Human-AI Collaboration in Auditing LLMs with LLMs. (arXiv:2304.09991v2 [cs.HC] UPDATED)","link":"http://arxiv.org/abs/2304.09991","description":"<p>Large language models are becoming increasingly pervasive and ubiquitous in\nsociety via deployment in sociotechnical systems. Yet these language models, be\nit for classification or generation, have been shown to be biased and behave\nirresponsibly, causing harm to people at scale. It is crucial to audit these\nlanguage models rigorously. Existing auditing tools leverage either or both\nhumans and AI to find failures. In this work, we draw upon literature in\nhuman-AI collaboration and sensemaking, and conduct interviews with research\nexperts in safe and fair AI, to build upon the auditing tool: AdaTest (Ribeiro\nand Lundberg, 2022), which is powered by a generative large language model\n(LLM). Through the design process we highlight the importance of sensemaking\nand human-AI communication to leverage complementary strengths of humans and\ngenerative models in collaborative auditing. To evaluate the effectiveness of\nthe augmented tool, AdaTest++, we conduct user studies with participants\nauditing two commercial language models: OpenAI's GPT-3 and Azure's sentiment\nanalysis model. Qualitative analysis shows that AdaTest++ effectively leverages\nhuman strengths such as schematization, hypothesis formation and testing.\nFurther, with our tool, participants identified a variety of failures modes,\ncovering 26 different topics over 2 tasks, that have been shown before in\nformal audits and also those previously under-reported.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rastogi_C/0/1/0/all/0/1\">Charvi Rastogi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_M/0/1/0/all/0/1\">Marco Tulio Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_N/0/1/0/all/0/1\">Nicholas King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amershi_S/0/1/0/all/0/1\">Saleema Amershi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training (TXIT) Exam and Red Journal Gray Zone Cases: Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology. (arXiv:2304.11957v4 [physics.med-ph] UPDATED)","link":"http://arxiv.org/abs/2304.11957","description":"<p>The potential of large language models in medicine for education and decision\nmaking purposes has been demonstrated as they achieve decent scores on medical\nexams such as the United States Medical Licensing Exam (USMLE) and the MedQA\nexam. In this work, we evaluate the performance of ChatGPT-4 in the specialized\nfield of radiation oncology using the 38th American College of Radiology (ACR)\nradiation oncology in-training (TXIT) exam and the 2022 Red Journal Gray Zone\ncases. For the TXIT exam, ChatGPT-3.5 and ChatGPT-4 have achieved the scores of\n63.65% and 74.57%, respectively, highlighting the advantage of the latest\nChatGPT-4 model. Based on the TXIT exam, ChatGPT-4's strong and weak areas in\nradiation oncology are identified to some extent. Specifically, ChatGPT-4\ndemonstrates better knowledge of statistics, CNS &amp; eye, pediatrics, biology,\nand physics than knowledge of bone &amp; soft tissue and gynecology, as per the ACR\nknowledge domain. Regarding clinical care paths, ChatGPT-4 performs better in\ndiagnosis, prognosis, and toxicity than brachytherapy and dosimetry. It lacks\nproficiency in in-depth details of clinical trials. For the Gray Zone cases,\nChatGPT-4 is able to suggest a personalized treatment approach to each case\nwith high correctness and comprehensiveness. Importantly, it provides novel\ntreatment aspects for many cases, which are not suggested by any human experts.\nBoth evaluations demonstrate the potential of ChatGPT-4 in medical education\nfor the general public and cancer patients, as well as the potential to aid\nclinical decision-making, while acknowledging its limitations in certain\ndomains. Because of the risk of hallucination, facts provided by ChatGPT always\nneed to be verified.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/physics/1/au:+Huang_Y/0/1/0/all/0/1\">Yixing Huang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gomaa_A/0/1/0/all/0/1\">Ahmed Gomaa</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Semrau_S/0/1/0/all/0/1\">Sabine Semrau</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Haderlein_M/0/1/0/all/0/1\">Marlen Haderlein</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lettmaier_S/0/1/0/all/0/1\">Sebastian Lettmaier</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Weissmann_T/0/1/0/all/0/1\">Thomas Weissmann</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Grigo_J/0/1/0/all/0/1\">Johanna Grigo</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Tkhayat_H/0/1/0/all/0/1\">Hassen Ben Tkhayat</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Frey_B/0/1/0/all/0/1\">Benjamin Frey</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gaipl_U/0/1/0/all/0/1\">Udo S. Gaipl</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Distel_L/0/1/0/all/0/1\">Luitpold V. Distel</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Fietkau_R/0/1/0/all/0/1\">Rainer Fietkau</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bert_C/0/1/0/all/0/1\">Christoph Bert</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Putz_F/0/1/0/all/0/1\">Florian Putz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Linguistic Models: Analyzing theoretical linguistic abilities of LLMs. (arXiv:2305.00948v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.00948","description":"<p>The performance of large language models (LLMs) has recently improved to the\npoint where the models can perform well on many language tasks. We show here\nthat for the first time, the models can also generate coherent and valid formal\nanalyses of linguistic data and illustrate the vast potential of large language\nmodels for analyses of their metalinguistic abilities. LLMs are primarily\ntrained on language data in the form of text; analyzing and evaluating their\nmetalinguistic abilities improves our understanding of their general\ncapabilities and sheds new light on theoretical models in linguistics. In this\npaper, we probe into GPT-4's metalinguistic capabilities by focusing on three\nsubfields of formal linguistics: syntax, phonology, and semantics. We outline a\nresearch program for metalinguistic analyses of large language models, propose\nexperimental designs, provide general guidelines, discuss limitations, and\noffer future directions for this line of research. This line of inquiry also\nexemplifies behavioral interpretability of deep learning, where models'\nrepresentations are accessed by explicit prompting rather than internal\nrepresentations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Begus_G/0/1/0/all/0/1\">Ga&#x161;per Begu&#x161;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dabkowski_M/0/1/0/all/0/1\">Maksymilian D&#x105;bkowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rhodes_R/0/1/0/all/0/1\">Ryan Rhodes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MPI-rical: Data-Driven MPI Distributed Parallelism Assistance with Transformers. (arXiv:2305.09438v2 [cs.DC] UPDATED)","link":"http://arxiv.org/abs/2305.09438","description":"<p>Automatic source-to-source parallelization of serial code for shared and\ndistributed memory systems is a challenging task in high-performance computing.\nWhile many attempts were made to translate serial code into parallel code for a\nshared memory environment (usually using OpenMP), none has managed to do so for\na distributed memory environment. In this paper, we propose a novel approach,\ncalled MPI-rical, for automated MPI code generation using a transformer-based\nmodel trained on approximately 25,000 serial code snippets and their\ncorresponding parallelized MPI code out of more than 50,000 code snippets in\nour corpus (MPICodeCorpus). To evaluate the performance of the model, we first\nbreak down the serial code to MPI-based parallel code translation problem into\ntwo sub-problems and develop two research objectives: code completion defined\nas given a location in the source code, predict the MPI function for that\nlocation, and code translation defined as predicting an MPI function as well as\nits location in the source code. We evaluate MPI-rical on MPICodeCorpus dataset\nand on real-world scientific code benchmarks and compare its performance\nbetween the code completion and translation tasks. Our experimental results\nshow that while MPI-rical performs better on the code completion task than the\ncode translation task, the latter is better suited for real-world programming\nassistance, in which the tool suggests the need for an MPI function regardless\nof prior knowledge. Overall, our approach represents a significant step forward\nin automating the parallelization of serial code for distributed memory\nsystems, which can save valuable time and resources for software developers and\nresearchers. The source code used in this work, as well as other relevant\nsources, are available at:\nhttps://github.com/Scientific-Computing-Lab-NRCN/MPI-rical\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1\">Nadav Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadosh_T/0/1/0/all/0/1\">Tal Kadosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasabnis_N/0/1/0/all/0/1\">Niranjan Hasabnis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattson_T/0/1/0/all/0/1\">Timothy Mattson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinter_Y/0/1/0/all/0/1\">Yuval Pinter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oren_G/0/1/0/all/0/1\">Gal Oren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reducing Sensitivity on Speaker Names for Text Generation from Dialogues. (arXiv:2305.13833v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13833","description":"<p>Changing speaker names consistently throughout a dialogue should not affect\nits meaning and corresponding outputs for text generation from dialogues.\nHowever, pre-trained language models, serving as the backbone for\ndialogue-processing tasks, have shown to be sensitive to nuances. This may\nresult in unfairness in real-world applications. No comprehensive analysis of\nthis problem has been done in the past. In this work, we propose to\nquantitatively measure a model's sensitivity on speaker names, and\ncomprehensively evaluate a number of known methods for reducing speaker name\nsensitivity, including a novel approach of our own. Extensive experiments on\nmultiple datasets provide a benchmark for this problem and show the favorable\nperformance of our approach in sensitivity reduction and quality of generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jia_Q/0/1/0/all/0/1\">Qi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Haifeng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kenny Q. Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reliable Detection and Quantification of Selective Forces in Language Change. (arXiv:2305.15914v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15914","description":"<p>Language change is a cultural evolutionary process in which variants of\nlinguistic variables change in frequency through processes analogous to\nmutation, selection and genetic drift. In this work, we apply a\nrecently-introduced method to corpus data to quantify the strength of selection\nin specific instances of historical language change. We first demonstrate, in\nthe context of English irregular verbs, that this method is more reliable and\ninterpretable than similar methods that have previously been applied. We\nfurther extend this study to demonstrate that a bias towards phonological\nsimplicity overrides that favouring grammatical simplicity when these are in\nconflict. Finally, with reference to Spanish spelling reforms, we show that the\nmethod can also detect points in time at which selection strengths change, a\nfeature that is generically expected for socially-motivated language change.\nTogether, these results indicate how hypotheses for mechanisms of language\nchange can be tested quantitatively using historical corpus data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Montero_J/0/1/0/all/0/1\">Juan Guerrero Montero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karjus_A/0/1/0/all/0/1\">Andres Karjus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1\">Kenny Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blythe_R/0/1/0/all/0/1\">Richard A. Blythe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AutoML in the Age of Large Language Models: Current Challenges, Future Opportunities and Risks. (arXiv:2306.08107v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2306.08107","description":"<p>The fields of both Natural Language Processing (NLP) and Automated Machine\nLearning (AutoML) have achieved remarkable results over the past years. In NLP,\nespecially Large Language Models (LLMs) have experienced a rapid series of\nbreakthroughs very recently. We envision that the two fields can radically push\nthe boundaries of each other through tight integration. To showcase this\nvision, we explore the potential of a symbiotic relationship between AutoML and\nLLMs, shedding light on how they can benefit each other. In particular, we\ninvestigate both the opportunities to enhance AutoML approaches with LLMs from\ndifferent perspectives and the challenges of leveraging AutoML to further\nimprove LLMs. To this end, we survey existing work, and we critically assess\nrisks. We strongly believe that the integration of the two fields has the\npotential to disrupt both fields, NLP and AutoML. By highlighting conceivable\nsynergies, but also risks, we aim to foster further exploration at the\nintersection of AutoML and LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tornede_A/0/1/0/all/0/1\">Alexander Tornede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_D/0/1/0/all/0/1\">Difan Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eimer_T/0/1/0/all/0/1\">Theresa Eimer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giovanelli_J/0/1/0/all/0/1\">Joseph Giovanelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohan_A/0/1/0/all/0/1\">Aditya Mohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruhkopf_T/0/1/0/all/0/1\">Tim Ruhkopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segel_S/0/1/0/all/0/1\">Sarah Segel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theodorakopoulos_D/0/1/0/all/0/1\">Daphne Theodorakopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tornede_T/0/1/0/all/0/1\">Tanja Tornede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wachsmuth_H/0/1/0/all/0/1\">Henning Wachsmuth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1\">Marius Lindauer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Domain Adaptation of Sentence Embeddings Using Adapters. (arXiv:2307.03104v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.03104","description":"<p>Sentence embeddings enable us to capture the semantic similarity of short\ntexts. Most sentence embedding models are trained for general semantic textual\nsimilarity tasks. Therefore, to use sentence embeddings in a particular domain,\nthe model must be adapted to it in order to achieve good results. Usually, this\nis done by fine-tuning the entire sentence embedding model for the domain of\ninterest. While this approach yields state-of-the-art results, all of the\nmodel's weights are updated during fine-tuning, making this method\nresource-intensive. Therefore, instead of fine-tuning entire sentence embedding\nmodels for each target domain individually, we propose to train lightweight\nadapters. These domain-specific adapters do not require fine-tuning all\nunderlying sentence embedding model parameters. Instead, we only train a small\nnumber of additional parameters while keeping the weights of the underlying\nsentence embedding model fixed. Training domain-specific adapters allows always\nusing the same base model and only exchanging the domain-specific adapters to\nadapt sentence embeddings to a specific domain. We show that using adapters for\nparameter-efficient domain adaptation of sentence embeddings yields competitive\nperformance within 1% of a domain-adapted, entirely fine-tuned sentence\nembedding model while only training approximately 3.6% of the parameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schopf_T/0/1/0/all/0/1\">Tim Schopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_D/0/1/0/all/0/1\">Dennis N. Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matthes_F/0/1/0/all/0/1\">Florian Matthes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models as Superpositions of Cultural Perspectives. (arXiv:2307.07870v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.07870","description":"<p>Large Language Models (LLMs) are often misleadingly recognized as having a\npersonality or a set of values. We argue that an LLM can be seen as a\nsuperposition of perspectives with different values and personality traits.\nLLMs exhibit context-dependent values and personality traits that change based\non the induced perspective (as opposed to humans, who tend to have more\ncoherent values and personality traits across contexts). We introduce the\nconcept of perspective controllability, which refers to a model's affordance to\nadopt various perspectives with differing values and personality traits. In our\nexperiments, we use questionnaires from psychology (PVQ, VSM, IPIP) to study\nhow exhibited values and personality traits change based on different\nperspectives. Through qualitative experiments, we show that LLMs express\ndifferent values when those are (implicitly or explicitly) implied in the\nprompt, and that LLMs express different values even when those are not\nobviously implied (demonstrating their context-dependent nature). We then\nconduct quantitative experiments to study the controllability of different\nmodels (GPT-4, GPT-3.5, OpenAssistant, StableVicuna, StableLM), the\neffectiveness of various methods for inducing perspectives, and the smoothness\nof the models' drivability. We conclude by examining the broader implications\nof our work and outline a variety of associated scientific questions. The\nproject website is available at\nhttps://sites.google.com/view/llm-superpositions .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kovac_G/0/1/0/all/0/1\">Grgur Kova&#x10d;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sawayama_M/0/1/0/all/0/1\">Masataka Sawayama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portelas_R/0/1/0/all/0/1\">R&#xe9;my Portelas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colas_C/0/1/0/all/0/1\">C&#xe9;dric Colas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dominey_P/0/1/0/all/0/1\">Peter Ford Dominey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1\">Pierre-Yves Oudeyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Guided Generation for Large Language Models. (arXiv:2307.09702v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.09702","description":"<p>In this article we show how the problem of neural text generation can be\nconstructively reformulated in terms of transitions between the states of a\nfinite-state machine. This framework leads to an efficient approach to guiding\ntext generation with regular expressions and context-free grammars by allowing\nthe construction of an index over a language model's vocabulary. The approach\nis model agnostic, allows one to enforce domain-specific knowledge and\nconstraints, and enables the construction of reliable interfaces by\nguaranteeing the structure of the generated text. It adds little overhead to\nthe token sequence generation process and significantly outperforms existing\nsolutions. An implementation is provided in the open source Python library\nOutlines\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Willard_B/0/1/0/all/0/1\">Brandon T. Willard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Louf_R/0/1/0/all/0/1\">R&#xe9;mi Louf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Landscape of Natural Language Processing Research. (arXiv:2307.10652v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.10652","description":"<p>As an efficient approach to understand, generate, and process natural\nlanguage texts, research in natural language processing (NLP) has exhibited a\nrapid spread and wide adoption in recent years. Given the increasing research\nwork in this area, several NLP-related approaches have been surveyed in the\nresearch community. However, a comprehensive study that categorizes established\ntopics, identifies trends, and outlines areas for future research remains\nabsent. Contributing to closing this gap, we have systematically classified and\nanalyzed research papers in the ACL Anthology. As a result, we present a\nstructured overview of the research landscape, provide a taxonomy of fields of\nstudy in NLP, analyze recent developments in NLP, summarize our findings, and\nhighlight directions for future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schopf_T/0/1/0/all/0/1\">Tim Schopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arabi_K/0/1/0/all/0/1\">Karim Arabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matthes_F/0/1/0/all/0/1\">Florian Matthes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RLCD: Reinforcement Learning from Contrast Distillation for Language Model Alignment. (arXiv:2307.12950v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.12950","description":"<p>We propose Reinforcement Learning from Contrast Distillation (RLCD), a method\nfor aligning language models to follow natural language principles without\nusing human feedback. RLCD trains a preference model using simulated preference\npairs that contain both a high-quality and low-quality example, generated using\ncontrasting positive and negative prompts. The preference model is then used to\nimprove a base unaligned language model via reinforcement learning.\nEmpirically, RLCD outperforms RLAIF (Bai et al., 2022b) and context\ndistillation (Huang et al., 2022) baselines across three diverse alignment\ntasks--harmlessness, helpfulness, and story outline generation--and on both 7B\nand 30B model scales for preference data simulation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kevin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuandong Tian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DoDo Learning: DOmain-DemOgraphic Transfer in Language Models for Detecting Abuse Targeted at Public Figures. (arXiv:2307.16811v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.16811","description":"<p>Public figures receive a disproportionate amount of abuse on social media,\nimpacting their active participation in public life. Automated systems can\nidentify abuse at scale but labelling training data is expensive, complex and\npotentially harmful. So, it is desirable that systems are efficient and\ngeneralisable, handling both shared and specific aspects of online abuse. We\nexplore the dynamics of cross-group text classification in order to understand\nhow well classifiers trained on one domain or demographic can transfer to\nothers, with a view to building more generalisable abuse classifiers. We\nfine-tune language models to classify tweets targeted at public figures across\nDOmains (sport and politics) and DemOgraphics (women and men) using our novel\nDODO dataset, containing 28,000 labelled entries, split equally across four\ndomain-demographic pairs. We find that (i) small amounts of diverse data are\nhugely beneficial to generalisation and model adaptation; (ii) models transfer\nmore easily across demographics but models trained on cross-domain data are\nmore generalisable; (iii) some groups contribute more to generalisability than\nothers; and (iv) dataset similarity is a signal of transferability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kirk_H/0/1/0/all/0/1\">Hannah Rose Kirk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1\">Angus R. Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burke_L/0/1/0/all/0/1\">Liam Burke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_Y/0/1/0/all/0/1\">Yi-Ling Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Debono_I/0/1/0/all/0/1\">Ivan Debono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johansson_P/0/1/0/all/0/1\">Pica Johansson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevens_F/0/1/0/all/0/1\">Francesca Stevens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bright_J/0/1/0/all/0/1\">Jonathan Bright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Predicting Perfect Quality Segments in MT Output with Fine-Tuned OpenAI LLM: Is it possible to capture editing distance patterns from historical data?. (arXiv:2308.00158v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.00158","description":"<p>Translation Quality Estimation (TQE) is an essential step before deploying\nthe output translation into usage. TQE is also critical in assessing machine\ntranslation (MT) and human translation (HT) quality without seeing the\nreference translations. This work examines whether the state-of-the-art large\nlanguage models (LLMs) can be fine-tuned for the TQE task and their capability.\nWe take ChatGPT as one example and approach TQE as a binary classification\ntask. Using \\textbf{eight language pairs} including English to Italian, German,\nFrench, Japanese, Dutch, Portuguese, Turkish, and Chinese training corpora, our\nexperimental results show that fine-tuned ChatGPT via its API can achieve a\nrelatively high score on predicting translation quality, i.e. \\textit{if the\ntranslation needs to be edited}. However, there is definitely much space to\nimprove the model accuracy, e.g. they are 82.42\\% and 83.69\\% for\nEnglish-Italian and English-German respectively using our experimental\nsettings. English-Italiano bilingual Abstract is available in the paper.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gladkoff_S/0/1/0/all/0/1\">Serge Gladkoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erofeev_G/0/1/0/all/0/1\">Gleb Erofeev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1\">Lifeng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nenadic_G/0/1/0/all/0/1\">Goran Nenadic</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Teaching Smaller Language Models To Generalise To Unseen Compositional Questions. (arXiv:2308.00946v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.00946","description":"<p>We equip a smaller Language Model to generalise to answering challenging\ncompositional questions that have not been seen in training. To do so we\npropose a combination of multitask supervised pretraining on up to 93 tasks\ndesigned to instill diverse reasoning abilities, and a dense retrieval system\nthat aims to retrieve a set of evidential paragraph fragments. Recent progress\nin question-answering has been achieved either through prompting methods\nagainst very large pretrained Language Models in zero or few-shot fashion, or\nby fine-tuning smaller models, sometimes in conjunction with information\nretrieval. We focus on the less explored question of the extent to which\nzero-shot generalisation can be enabled in smaller models with retrieval\nagainst a corpus within which sufficient information to answer a particular\nquestion may not exist. We establish strong baselines in this setting for\ndiverse evaluation datasets (StrategyQA, CommonsenseQA, IIRC, DROP, Musique and\nARC-DA), and show that performance can be significantly improved by adding\nretrieval-augmented training datasets which are designed to expose our models\nto a variety of heuristic reasoning strategies such as weighing partial\nevidence or ignoring an irrelevant context.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hartill_T/0/1/0/all/0/1\">Tim Hartill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_N/0/1/0/all/0/1\">Neset Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1\">Michael Witbrock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riddle_P/0/1/0/all/0/1\">Patricia J. Riddle</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology. (arXiv:2308.02180v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.02180","description":"<p>Clinical trial matching is a key process in health delivery and discovery. In\npractice, it is plagued by overwhelming unstructured data and unscalable manual\nprocessing. In this paper, we conduct a systematic study on scaling clinical\ntrial matching using large language models (LLMs), with oncology as the focus\narea. Our study is grounded in a clinical trial matching system currently in\ntest deployment at a large U.S. health network. Initial findings are promising:\nout of box, cutting-edge LLMs, such as GPT-4, can already structure elaborate\neligibility criteria of clinical trials and extract complex matching logic\n(e.g., nested AND/OR/NOT). While still far from perfect, LLMs substantially\noutperform prior strong baselines and may serve as a preliminary solution to\nhelp triage patient-trial candidates with humans in the loop. Our study also\nreveals a few significant growth areas for applying LLMs to end-to-end clinical\ntrial matching, such as context limitation and accuracy, especially in\nstructuring patient information from longitudinal medical records.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wong_C/0/1/0/all/0/1\">Cliff Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yu Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moung_C/0/1/0/all/0/1\">Christine Moung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abel_J/0/1/0/all/0/1\">Jacob Abel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Usuyama_N/0/1/0/all/0/1\">Naoto Usuyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weerasinghe_R/0/1/0/all/0/1\">Roshanthi Weerasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piening_B/0/1/0/all/0/1\">Brian Piening</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naumann_T/0/1/0/all/0/1\">Tristan Naumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bifulco_C/0/1/0/all/0/1\">Carlo Bifulco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1\">Hoifung Poon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PaniniQA: Enhancing Patient Education Through Interactive Question Answering. (arXiv:2308.03253v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.03253","description":"<p>Patient portal allows discharged patients to access their personalized\ndischarge instructions in electronic health records (EHRs). However, many\npatients have difficulty understanding or memorizing their discharge\ninstructions. In this paper, we present PaniniQA, a patient-centric interactive\nquestion answering system designed to help patients understand their discharge\ninstructions. PaniniQA first identifies important clinical content from\npatients' discharge instructions and then formulates patient-specific\neducational questions. In addition, PaniniQA is also equipped with answer\nverification functionality to provide timely feedback to correct patients'\nmisunderstandings. Our comprehensive automatic and human evaluation results\ndemonstrate our PaniniQA is capable of improving patients' mastery of their\nmedical instructions through effective interactions\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cai_P/0/1/0/all/0/1\">Pengshan Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zonghai Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dakuo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reilly_M/0/1/0/all/0/1\">Meghan Reilly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Huixue Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lingxi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yi Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapoor_A/0/1/0/all/0/1\">Alok Kapoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bajracharya_A/0/1/0/all/0/1\">Adarsha Bajracharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berlowitz_D/0/1/0/all/0/1\">Dan Berlowitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Single-Sentence Reader: A Novel Approach for Addressing Answer Position Bias. (arXiv:2308.04566v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.04566","description":"<p>Machine Reading Comprehension (MRC) models tend to take advantage of spurious\ncorrelations (also known as dataset bias or annotation artifacts in the\nresearch community). Consequently, these models may perform the MRC task\nwithout fully comprehending the given context and question, which is\nundesirable since it may result in low robustness against distribution shift.\nThis paper delves into the concept of answer-position bias, where a significant\npercentage of training questions have answers located solely in the first\nsentence of the context. We propose a Single-Sentence Reader as a new approach\nfor addressing answer position bias in MRC. We implement this approach using\nsix different models and thoroughly analyze their performance. Remarkably, our\nproposed Single-Sentence Readers achieve results that nearly match those of\nmodels trained on conventional training sets, proving their effectiveness. Our\nstudy also discusses several challenges our Single-Sentence Readers encounter\nand proposes a potential solution.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tran_S/0/1/0/all/0/1\">Son Quoc Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kretchmar_M/0/1/0/all/0/1\">Matt Kretchmar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Natural Language is All a Graph Needs. (arXiv:2308.07134v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.07134","description":"<p>The emergence of large-scale pre-trained language models, such as ChatGPT,\nhas revolutionized various research fields in artificial intelligence.\nTransformers-based large language models (LLMs) have gradually replaced CNNs\nand RNNs to unify fields of computer vision and natural language processing.\nCompared with the data that exists relatively independently such as images,\nvideos or texts, graph is a type of data that contains rich structural and\nrelational information. Meanwhile, natural language, as one of the most\nexpressive mediums, excels in describing complex structures. However, existing\nwork on incorporating graph learning problems into the generative language\nmodeling framework remains very limited. As the importance of large language\nmodels continues to grow, it becomes essential to explore whether LLMs can also\nreplace GNNs as the foundation model for graphs. In this paper, we propose\nInstructGLM (Instruction-finetuned Graph Language Model), systematically design\nhighly scalable prompts based on natural language instructions, and use natural\nlanguage to describe the geometric structure and node features of the graph for\ninstruction tuning an LLM to perform learning and inference on graphs in a\ngenerative manner. Our method exceeds all competitive GNN baselines on\nogbn-arxiv, Cora and PubMed datasets, which demonstrates the effectiveness of\nour method and sheds light on generative large language models as the\nfoundation model for graph machine learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_R/0/1/0/all/0/1\">Ruosong Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Caiqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Runhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning. (arXiv:2308.08747v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.08747","description":"<p>Catastrophic forgetting (CF) is a phenomenon that occurs in machine learning\nwhen a model forgets previously learned information as it learns new\ninformation. As large language models (LLMs) have shown excellent performance,\nit is interesting to uncover whether CF exists in the continual fine-tuning of\nLLMs. In this study, we empirically evaluate the forgetting phenomenon in LLMs'\nknowledge, from the perspectives of domain knowledge, reasoning, and reading\ncomprehension. The experiments demonstrate that catastrophic forgetting is\ngenerally observed in LLMs ranging from 1b to 7b. Furthermore, as the scale\nincreases, the severity of forgetting also intensifies. Comparing the\ndecoder-only model BLOOMZ with the encoder-decoder model mT0, BLOOMZ suffers\nless forgetting and maintains more knowledge. We also observe that LLMs can\nmitigate language bias (e.g. gender bias) during continual fine-tuning.\nMoreover, we find that ALPACA can maintain more knowledge and capacity compared\nwith LLAMA during the continual fine-tuning, which implies that general\ninstruction tuning can help mitigate the forgetting phenomenon of LLMs in the\nfurther fine-tuning process.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yafu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Demonstration Ensembling for In-context Learning. (arXiv:2308.08780v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.08780","description":"<p>In-context learning (ICL) operates by showing language models (LMs) examples\nof input-output pairs for a given task, i.e., demonstrations. The standard\napproach for ICL is to prompt the LM with concatenated demonstrations followed\nby the test input. This approach suffers from some issues. First, concatenation\noffers almost no control over the contribution of each demo to the model\nprediction. This can be sub-optimal when some demonstrations are irrelevant to\nthe test example. Second, due to the input length limit of some transformer\nmodels, it might be infeasible to fit many examples into the context,\nespecially when dealing with long-input tasks. In this work, we explore\nDemonstration Ensembling (DENSE) as an alternative to simple concatenation.\nDENSE predicts outputs using subsets (i.e., buckets) of the demonstrations and\nthen combines the output probabilities resulting from each subset to produce\nthe final prediction. We study different ensembling methods using GPT-j and\nexperiment on 12 language tasks. Our experiments show weighted max ensembling\nto outperform vanilla concatenation by as large as 2.4 average points. Code\navailable at https://github.com/mukhal/icl-ensembling.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khalifa_M/0/1/0/all/0/1\">Muhammad Khalifa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Logeswaran_L/0/1/0/all/0/1\">Lajanugen Logeswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Moontae Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Honglak Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lu Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reinforced Self-Training (ReST) for Language Modeling. (arXiv:2308.08998v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.08998","description":"<p>Reinforcement learning from human feedback (RLHF) can improve the quality of\nlarge language model's (LLM) outputs by aligning them with human preferences.\nWe propose a simple algorithm for aligning LLMs with human preferences inspired\nby growing batch reinforcement learning (RL), which we call Reinforced\nSelf-Training (ReST). Given an initial LLM policy, ReST produces a dataset by\ngenerating samples from the policy, which are then used to improve the LLM\npolicy using offline RL algorithms. ReST is more efficient than typical online\nRLHF methods because the training dataset is produced offline, which allows\ndata reuse. While ReST is a general approach applicable to all generative\nlearning settings, we focus on its application to machine translation. Our\nresults show that ReST can substantially improve translation quality, as\nmeasured by automated metrics and human evaluation on machine translation\nbenchmarks in a compute and sample-efficient manner.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gulcehre_C/0/1/0/all/0/1\">Caglar Gulcehre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paine_T/0/1/0/all/0/1\">Tom Le Paine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1\">Srivatsan Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konyushkova_K/0/1/0/all/0/1\">Ksenia Konyushkova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weerts_L/0/1/0/all/0/1\">Lotte Weerts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abhishek Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddhant_A/0/1/0/all/0/1\">Aditya Siddhant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahern_A/0/1/0/all/0/1\">Alex Ahern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Miaosen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_C/0/1/0/all/0/1\">Chenjie Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Macherey_W/0/1/0/all/0/1\">Wolfgang Macherey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firat_O/0/1/0/all/0/1\">Orhan Firat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_N/0/1/0/all/0/1\">Nando de Freitas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Differentiable Retrieval Augmentation via Generative Language Modeling for E-commerce Query Intent Classification. (arXiv:2308.09308v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2308.09308","description":"<p>Retrieval augmentation, which enhances downstream models by a knowledge\nretriever and an external corpus instead of by merely increasing the number of\nmodel parameters, has been successfully applied to many natural language\nprocessing (NLP) tasks such as text classification, question answering and so\non. However, existing methods that separately or asynchronously train the\nretriever and downstream model mainly due to the non-differentiability between\nthe two parts, usually lead to degraded performance compared to end-to-end\njoint training. In this paper, we propose Differentiable Retrieval Augmentation\nvia Generative lANguage modeling(Dragan), to address this problem by a novel\ndifferentiable reformulation. We demonstrate the effectiveness of our proposed\nmethod on a challenging NLP task in e-commerce search, namely query intent\nclassification. Both the experimental results and ablation study show that the\nproposed method significantly and reasonably improves the state-of-the-art\nbaselines on both offline evaluation and online A/B test.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chenyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yunjiang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yiming Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Han Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wen-Yun Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for Multi-hop Visual Reasoning. (arXiv:2308.09658v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.09658","description":"<p>There emerges a promising trend of using large language models (LLMs) to\ngenerate code-like plans for complex inference tasks such as visual reasoning.\nThis paradigm, known as LLM-based planning, provides flexibility in problem\nsolving and endows better interpretability. However, current research is mostly\nlimited to basic scenarios of simple questions that can be straightforward\nanswered in a few inference steps. Planning for the more challenging multi-hop\nvisual reasoning tasks remains under-explored. Specifically, under multi-hop\nreasoning situations, the trade-off between accuracy and the complexity of\nplan-searching becomes prominent. The prevailing algorithms either address the\nefficiency issue by employing the fast one-stop generation or adopt a complex\niterative generation method to improve accuracy. Both fail to balance the need\nfor efficiency and performance. Drawing inspiration from the dual system of\ncognition in the human brain, the fast and the slow think processes, we propose\na hierarchical plan-searching algorithm that integrates the one-stop reasoning\n(fast) and the Tree-of-thought (slow). Our approach succeeds in performance\nwhile significantly saving inference steps. Moreover, we repurpose the PTR and\nthe CLEVER datasets, developing a systematic framework for evaluating the\nperformance and efficiency of LLMs-based plan-search algorithms under reasoning\ntasks at different levels of difficulty. Extensive experiments demonstrate the\nsuperiority of our proposed algorithm in terms of performance and efficiency.\nThe dataset and code will be release soon.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1\">Pengbo Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Ji Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xingyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_B/0/1/0/all/0/1\">Bing Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruiyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yi Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Graph of Thoughts: Solving Elaborate Problems with Large Language Models. (arXiv:2308.09687v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.09687","description":"<p>We introduce Graph of Thoughts (GoT): a framework that advances prompting\ncapabilities in large language models (LLMs) beyond those offered by paradigms\nsuch as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primary\nadvantage of GoT is the ability to model the information generated by an LLM as\nan arbitrary graph, where units of information (\"LLM thoughts\") are vertices,\nand edges correspond to dependencies between these vertices. This approach\nenables combining arbitrary LLM thoughts into synergistic outcomes, distilling\nthe essence of whole networks of thoughts, or enhancing thoughts using feedback\nloops. We illustrate that GoT offers advantages over state of the art on\ndifferent tasks, for example increasing the quality of sorting by 62% over ToT,\nwhile simultaneously reducing costs by &gt;31%. We ensure that GoT is extensible\nwith new thought transformations and thus can be used to spearhead new\nprompting schemes. This work brings the LLM reasoning closer to human thinking\nor brain mechanisms such as recurrence, both of which form complex networks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Besta_M/0/1/0/all/0/1\">Maciej Besta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blach_N/0/1/0/all/0/1\">Nils Blach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kubicek_A/0/1/0/all/0/1\">Ales Kubicek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerstenberger_R/0/1/0/all/0/1\">Robert Gerstenberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gianinazzi_L/0/1/0/all/0/1\">Lukas Gianinazzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gajda_J/0/1/0/all/0/1\">Joanna Gajda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lehmann_T/0/1/0/all/0/1\">Tomasz Lehmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Podstawski_M/0/1/0/all/0/1\">Michal Podstawski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niewiadomski_H/0/1/0/all/0/1\">Hubert Niewiadomski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nyczyk_P/0/1/0/all/0/1\">Piotr Nyczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1\">Torsten Hoefler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Getting pwn'd by AI: Penetration Testing with Large Language Models. (arXiv:2308.00121v3 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2308.00121","description":"<p>The field of software security testing, more specifically penetration\ntesting, is an activity that requires high levels of expertise and involves\nmany manual testing and analysis steps. This paper explores the potential usage\nof large-language models, such as GPT3.5, to augment penetration testers with\nAI sparring partners. We explore the feasibility of supplementing penetration\ntesters with AI models for two distinct use cases: high-level task planning for\nsecurity testing assignments and low-level vulnerability hunting within a\nvulnerable virtual machine. For the latter, we implemented a closed-feedback\nloop between LLM-generated low-level actions with a vulnerable virtual machine\n(connected through SSH) and allowed the LLM to analyze the machine state for\nvulnerabilities and suggest concrete attack vectors which were automatically\nexecuted within the virtual machine. We discuss promising initial results,\ndetail avenues for improvement, and close deliberating on the ethics of\nproviding AI-based sparring partners.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Happe_A/0/1/0/all/0/1\">Andreas Happe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cito_J/0/1/0/all/0/1\">J&#xfc;rgen Cito</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-08-21T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","dc":"http://purl.org/dc/elements/1.1/"}}]}]}