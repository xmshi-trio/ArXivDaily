{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-05-30T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Ghost in the Minecraft: Generally Capable Agents for Open-World Enviroments via Large Language Models with Text-based Knowledge and Memory. (arXiv:2305.17144v1 [cs.AI])","link":"http://arxiv.org/abs/2305.17144","description":"<p>The captivating realm of Minecraft has attracted substantial research\ninterest in recent years, serving as a rich platform for developing intelligent\nagents capable of functioning in open-world environments. However, the current\nresearch landscape predominantly focuses on specific objectives, such as the\npopular \"ObtainDiamond\" task, and has not yet shown effective generalization to\na broader spectrum of tasks. Furthermore, the current leading success rate for\nthe \"ObtainDiamond\" task stands at around 20%, highlighting the limitations of\nReinforcement Learning (RL) based controllers used in existing methods. To\ntackle these challenges, we introduce Ghost in the Minecraft (GITM), a novel\nframework integrates Large Language Models (LLMs) with text-based knowledge and\nmemory, aiming to create Generally Capable Agents (GCAs) in Minecraft. These\nagents, equipped with the logic and common sense capabilities of LLMs, can\nskillfully navigate complex, sparse-reward environments with text-based\ninteractions. We develop a set of structured actions and leverage LLMs to\ngenerate action plans for the agents to execute. The resulting LLM-based agent\nmarkedly surpasses previous methods, achieving a remarkable improvement of\n+47.5% in success rate on the \"ObtainDiamond\" task, demonstrating superior\nrobustness compared to traditional RL-based controllers. Notably, our agent is\nthe first to procure all items in the Minecraft Overworld technology tree,\ndemonstrating its extensive capabilities. GITM does not need any GPU for\ntraining, but a single CPU node with 32 CPU cores is enough. This research\nshows the potential of LLMs in developing capable agents for handling\nlong-horizon, complex tasks and adapting to uncertainties in open-world\nenvironments. See the project website at https://github.com/OpenGVLab/GITM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xizhou Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuntao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_H/0/1/0/all/0/1\">Hao Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1\">Chenxin Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Weijie Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chenyu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Gao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1\">Lewei Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaogang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhaoxiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Jifeng Dai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Heterogeneous Value Evaluation for Large Language Models. (arXiv:2305.17147v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17147","description":"<p>The emergent capabilities of Large Language Models (LLMs) have made it\ncrucial to align their values with those of humans. Current methodologies\ntypically attempt alignment with a homogeneous human value and requires human\nverification, yet lack consensus on the desired aspect and depth of alignment\nand resulting human biases. In this paper, we propose A2EHV, an Automated\nAlignment Evaluation with a Heterogeneous Value system that (1) is automated to\nminimize individual human biases, and (2) allows assessments against various\ntarget values to foster heterogeneous agents. Our approach pivots on the\nconcept of value rationality, which represents the ability for agents to\nexecute behaviors that satisfy a target value the most. The quantification of\nvalue rationality is facilitated by the Social Value Orientation framework from\nsocial psychology, which partitions the value space into four categories to\nassess social preferences from agents' behaviors. We evaluate the value\nrationality of eight mainstream LLMs and observe that large models are more\ninclined to align neutral values compared to those with strong personal values.\nBy examining the behavior of these LLMs, we contribute to a deeper\nunderstanding of value alignment within a heterogeneous value system.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhaowei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Nian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_S/0/1/0/all/0/1\">Siyuan Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ceyao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rong_Z/0/1/0/all/0/1\">Ziqi Rong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaodong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Shuguang Cui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models. (arXiv:2305.17174v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17174","description":"<p>Dogwhistles are coded expressions that simultaneously convey one meaning to a\nbroad audience and a second one, often hateful or provocative, to a narrow\nin-group; they are deployed to evade both political repercussions and\nalgorithmic content moderation. For example, in the sentence 'we need to end\nthe cosmopolitan experiment,' the word 'cosmopolitan' likely means 'worldly' to\nmany, but secretly means 'Jewish' to a select few. We present the first\nlarge-scale computational investigation of dogwhistles. We develop a typology\nof dogwhistles, curate the largest-to-date glossary of over 300 dogwhistles\nwith rich contextual information and examples, and analyze their usage in\nhistorical U.S. politicians' speeches. We then assess whether a large language\nmodel (GPT-3) can identify dogwhistles and their meanings, and find that\nGPT-3's performance varies widely across types of dogwhistles and targeted\ngroups. Finally, we show that harmful content containing dogwhistles avoids\ntoxicity detection, highlighting online risks of such coded language. This work\nsheds light on the theoretical and applied importance of dogwhistles in both\nNLP and computational social science, and provides resources for future\nresearch in modeling dogwhistles and mitigating their online harms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mendelsohn_J/0/1/0/all/0/1\">Julia Mendelsohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bras_R/0/1/0/all/0/1\">Ronan Le Bras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1\">Maarten Sap</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tokenization Impacts Multilingual Language Modeling: Assessing Vocabulary Allocation and Overlap Across Languages. (arXiv:2305.17179v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17179","description":"<p>Multilingual language models have recently gained attention as a promising\nsolution for representing multiple languages in a single model. In this paper,\nwe propose new criteria to evaluate the quality of lexical representation and\nvocabulary overlap observed in sub-word tokenizers. Our findings show that the\noverlap of vocabulary across languages can be actually detrimental to certain\ndownstream tasks (POS, dependency tree labeling). In contrast, NER and\nsentence-level tasks (cross-lingual retrieval, NLI) benefit from sharing\nvocabulary. We also observe that the coverage of the language-specific tokens\nin the multilingual vocabulary significantly impacts the word-level tasks. Our\nstudy offers a deeper understanding of the role of tokenizers in multilingual\nlanguage models and guidelines for future model developers to choose the most\nsuitable tokenizer for their specific application before undertaking costly\nmodel pre-training\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Limisiewicz_T/0/1/0/all/0/1\">Tomasz Limisiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balhar_J/0/1/0/all/0/1\">Ji&#x159;&#xed; Balhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marecek_D/0/1/0/all/0/1\">David Mare&#x10d;ek</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Copying Problem of Unsupervised NMT: A Training Schedule with a Language Discriminator Loss. (arXiv:2305.17182v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17182","description":"<p>Although unsupervised neural machine translation (UNMT) has achieved success\nin many language pairs, the copying problem, i.e., directly copying some parts\nof the input sentence as the translation, is common among distant language\npairs, especially when low-resource languages are involved. We find this issue\nis closely related to an unexpected copying behavior during online\nback-translation (BT). In this work, we propose a simple but effective training\nschedule that incorporates a language discriminator loss. The loss imposes\nconstraints on the intermediate translation so that the translation is in the\ndesired language. By conducting extensive experiments on different language\npairs, including similar and distant, high and low-resource languages, we find\nthat our method alleviates the copying problem, thus improving the translation\nperformance on low-resource languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yihong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chronopoulou_A/0/1/0/all/0/1\">Alexandra Chronopoulou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fraser_A/0/1/0/all/0/1\">Alexander Fraser</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Entailment as Robust Self-Learner. (arXiv:2305.17197v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17197","description":"<p>Entailment has been recognized as an important metric for evaluating natural\nlanguage understanding (NLU) models, and recent studies have found that\nentailment pretraining benefits weakly supervised fine-tuning. In this work, we\ndesign a prompting strategy that formulates a number of different NLU tasks as\ncontextual entailment. This approach improves the zero-shot adaptation of\npretrained entailment models. Secondly, we notice that self-training\nentailment-based models with unlabeled data can significantly improve the\nadaptation performance on downstream tasks. To achieve more stable improvement,\nwe propose the Simple Pseudo-Label Editing (SimPLE) algorithm for better\npseudo-labeling quality in self-training. We also found that both pretrained\nentailment-based models and the self-trained models are robust against\nadversarial evaluation data. Experiments on binary and multi-class\nclassification tasks show that SimPLE leads to more robust self-training\nresults, indicating that the self-trained entailment models are more efficient\nand trustworthy than large language models on language understanding tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ge_J/0/1/0/all/0/1\">Jiaxin Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Hongyin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BIG-C: a Multimodal Multi-Purpose Dataset for Bemba. (arXiv:2305.17202v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17202","description":"<p>We present BIG-C (Bemba Image Grounded Conversations), a large multimodal\ndataset for Bemba. While Bemba is the most populous language of Zambia, it\nexhibits a dearth of resources which render the development of language\ntechnologies or language processing research almost impossible. The dataset is\ncomprised of multi-turn dialogues between Bemba speakers based on images,\ntranscribed and translated into English. There are more than 92,000\nutterances/sentences, amounting to more than 180 hours of audio data with\ncorresponding transcriptions and English translations. We also provide\nbaselines on speech recognition (ASR), machine translation (MT) and speech\ntranslation (ST) tasks, and sketch out other potential future multimodal uses\nof our dataset. We hope that by making the dataset available to the research\ncommunity, this work will foster research and encourage collaboration across\nthe language, speech, and vision communities especially for languages outside\nthe \"traditionally\" used high-resourced ones. All data and code are publicly\navailable: https://github.com/csikasote/bigc.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sikasote_C/0/1/0/all/0/1\">Claytone Sikasote</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukonde_E/0/1/0/all/0/1\">Eunice Mukonde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1\">Md Mahfuz Ibn Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Coping with low data availability for social media crisis message categorisation. (arXiv:2305.17211v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17211","description":"<p>During crisis situations, social media allows people to quickly share\ninformation, including messages requesting help. This can be valuable to\nemergency responders, who need to categorise and prioritise these messages\nbased on the type of assistance being requested. However, the high volume of\nmessages makes it difficult to filter and prioritise them without the use of\ncomputational techniques. Fully supervised filtering techniques for crisis\nmessage categorisation typically require a large amount of annotated training\ndata, but this can be difficult to obtain during an ongoing crisis and is\nexpensive in terms of time and labour to create.\n</p>\n<p>This thesis focuses on addressing the challenge of low data availability when\ncategorising crisis messages for emergency response. It first presents domain\nadaptation as a solution for this problem, which involves learning a\ncategorisation model from annotated data from past crisis events (source\ndomain) and adapting it to categorise messages from an ongoing crisis event\n(target domain). In many-to-many adaptation, where the model is trained on\nmultiple past events and adapted to multiple ongoing events, a multi-task\nlearning approach is proposed using pre-trained language models. This approach\noutperforms baselines and an ensemble approach further improves performance...\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Congcong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generating Images with Multimodal Language Models. (arXiv:2305.17216v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17216","description":"<p>We propose a method to fuse frozen text-only large language models (LLMs)\nwith pre-trained image encoder and decoder models, by mapping between their\nembedding spaces. Our model demonstrates a wide suite of multimodal\ncapabilities: image retrieval, novel image generation, and multimodal dialogue.\nOurs is the first approach capable of conditioning on arbitrarily interleaved\nimage and text inputs to generate coherent image (and text) outputs. To achieve\nstrong performance on image generation, we propose an efficient mapping network\nto ground the LLM to an off-the-shelf text-to-image generation model. This\nmapping network translates hidden representations of text into the embedding\nspace of the visual models, enabling us to leverage the strong text\nrepresentations of the LLM for visual outputs. Our approach outperforms\nbaseline generation models on tasks with longer and more complex language. In\naddition to novel image generation, our model is also capable of image\nretrieval from a prespecified dataset, and decides whether to retrieve or\ngenerate at inference time. This is done with a learnt decision module which\nconditions on the hidden representations of the LLM. Our model exhibits a wider\nrange of capabilities compared to prior multimodal language models. It can\nprocess image-and-text inputs, and produce retrieved images, generated images,\nand generated text -- outperforming non-LLM based generation models across\nseveral text-to-image tasks that measure context dependence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koh_J/0/1/0/all/0/1\">Jing Yu Koh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1\">Daniel Fried</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GVdoc: Graph-based Visual Document Classification. (arXiv:2305.17219v1 [cs.CV])","link":"http://arxiv.org/abs/2305.17219","description":"<p>The robustness of a model for real-world deployment is decided by how well it\nperforms on unseen data and distinguishes between in-domain and out-of-domain\nsamples. Visual document classifiers have shown impressive performance on\nin-distribution test sets. However, they tend to have a hard time correctly\nclassifying and differentiating out-of-distribution examples. Image-based\nclassifiers lack the text component, whereas multi-modality transformer-based\nmodels face the token serialization problem in visual documents due to their\ndiverse layouts. They also require a lot of computing power during inference,\nmaking them impractical for many real-world applications. We propose, GVdoc, a\ngraph-based document classification model that addresses both of these\nchallenges. Our approach generates a document graph based on its layout, and\nthen trains a graph neural network to learn node and graph embeddings. Through\nexperiments, we show that our model, even with fewer parameters, outperforms\nstate-of-the-art models on out-of-distribution data while retaining comparable\nperformance on the in-distribution test set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mohbat_F/0/1/0/all/0/1\">Fnu Mohbat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaki_M/0/1/0/all/0/1\">Mohammed J. Zaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finegan_Dollak_C/0/1/0/all/0/1\">Catherine Finegan-Dollak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_A/0/1/0/all/0/1\">Ashish Verma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Federated Learning for Semantic Parsing: Task Formulation, Evaluation Setup, New Algorithms. (arXiv:2305.17221v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17221","description":"<p>This paper studies a new task of federated learning (FL) for semantic\nparsing, where multiple clients collaboratively train one global model without\nsharing their semantic parsing data. By leveraging data from multiple clients,\nthe FL paradigm can be especially beneficial for clients that have little\ntraining data to develop a data-hungry neural semantic parser on their own. We\npropose an evaluation setup to study this task, where we re-purpose widely-used\nsingle-domain text-to-SQL datasets as clients to form a realistic heterogeneous\nFL setting and collaboratively train a global model. As standard FL algorithms\nsuffer from the high client heterogeneity in our realistic setup, we further\npropose a novel LOss Reduction Adjusted Re-weighting (Lorar) mechanism to\nmitigate the performance degradation, which adjusts each client's contribution\nto the global model update based on its training loss reduction during each\nround. Our intuition is that the larger the loss reduction, the further away\nthe current global model is from the client's local optimum, and the larger\nweight the client should get. By applying Lorar to three widely adopted FL\nalgorithms (FedAvg, FedOPT and FedProx), we observe that their performance can\nbe improved substantially on average (4%-20% absolute gain under MacroAvg) and\nthat clients with smaller datasets enjoy larger performance gains. In addition,\nthe global model converges faster for almost all the clients.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianshu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Changchang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1\">Wei-Han Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Huan Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning. (arXiv:2305.17256v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17256","description":"<p>Large language models (LLMs) have recently shown great potential for\nin-context learning, where LLMs learn a new task simply by conditioning on a\nfew input-label pairs (prompts). Despite their potential, our understanding of\nthe factors influencing end-task performance and the robustness of in-context\nlearning remains limited. This paper aims to bridge this knowledge gap by\ninvestigating the reliance of LLMs on shortcuts or spurious correlations within\nprompts. Through comprehensive experiments on classification and extraction\ntasks, we reveal that LLMs are \"lazy learners\" that tend to exploit shortcuts\nin prompts for downstream tasks. Additionally, we uncover a surprising finding\nthat larger models are more likely to utilize shortcuts in prompts during\ninference. Our findings provide a new perspective on evaluating robustness in\nin-context learning and pose new challenges for detecting and mitigating the\nuse of shortcuts in prompts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1\">Ruixiang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_D/0/1/0/all/0/1\">Dehan Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Longtao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1\">Hui Xue</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Honey, I Shrunk the Language: Language Model Behavior at Reduced Scale. (arXiv:2305.17266v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17266","description":"<p>In recent years, language models have drastically grown in size, and the\nabilities of these models have been shown to improve with scale. The majority\nof recent scaling laws studies focused on high-compute high-parameter count\nsettings, leaving the question of when these abilities begin to emerge largely\nunanswered. In this paper, we investigate whether the effects of pre-training\ncan be observed when the problem size is reduced, modeling a smaller,\nreduced-vocabulary language. We show the benefits of pre-training with masked\nlanguage modeling (MLM) objective in models as small as 1.25M parameters, and\nestablish a strong correlation between pre-training perplexity and downstream\nperformance (GLUE benchmark). We examine downscaling effects, extending scaling\nlaws to models as small as ~1M parameters. At this scale, we observe a break of\nthe power law for compute-optimal models and show that the MLM loss does not\nscale smoothly with compute-cost (FLOPs) below $2.2 \\times 10^{15}$ FLOPs. We\nalso find that adding layers does not always benefit downstream performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_V/0/1/0/all/0/1\">Vijeta Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pechi_D/0/1/0/all/0/1\">Dan Pechi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thatte_S/0/1/0/all/0/1\">Shree Thatte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lialin_V/0/1/0/all/0/1\">Vladislav Lialin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rumshisky_A/0/1/0/all/0/1\">Anna Rumshisky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CODET: A Benchmark for Contrastive Dialectal Evaluation of Machine Translation. (arXiv:2305.17267v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17267","description":"<p>Neural machine translation (NMT) systems exhibit limited robustness in\nhandling source-side linguistic variations. Their performance tends to degrade\nwhen faced with even slight deviations in language usage, such as different\ndomains or variations introduced by second-language speakers. It is intuitive\nto extend this observation to encompass dialectal variations as well, but the\nwork allowing the community to evaluate MT systems on this dimension is\nlimited. To alleviate this issue, we compile and release \\dataset, a\ncontrastive dialectal benchmark encompassing 882 different variations from nine\ndifferent languages. We also quantitatively demonstrate the challenges large MT\nmodels face in effectively translating dialectal variants. We are releasing all\ncode and data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1\">Md Mahfuz Ibn Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmadi_S/0/1/0/all/0/1\">Sina Ahmadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Metaphor Detection via Explicit Basic Meanings Modelling. (arXiv:2305.17268v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17268","description":"<p>One noticeable trend in metaphor detection is the embrace of linguistic\ntheories such as the metaphor identification procedure (MIP) for model\narchitecture design. While MIP clearly defines that the metaphoricity of a\nlexical unit is determined based on the contrast between its \\textit{contextual\nmeaning} and its \\textit{basic meaning}, existing work does not strictly follow\nthis principle, typically using the \\textit{aggregated meaning} to approximate\nthe basic meaning of target words. In this paper, we propose a novel metaphor\ndetection method, which models the basic meaning of the word based on literal\nannotation from the training set, and then compares this with the contextual\nmeaning in a target sentence to identify metaphors. Empirical results show that\nour method outperforms the state-of-the-art method significantly by 1.0\\% in F1\nscore. Moreover, our performance even reaches the theoretical upper bound on\nthe VUA18 benchmark for targets with basic annotations, which demonstrates the\nimportance of modelling basic meanings for metaphor detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yucheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_G/0/1/0/all/0/1\">Guerin Frank</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Slide, Constrain, Parse, Repeat: Synchronous SlidingWindows for Document AMR Parsing. (arXiv:2305.17273v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17273","description":"<p>The sliding window approach provides an elegant way to handle contexts of\nsizes larger than the Transformer's input window, for tasks like language\nmodeling. Here we extend this approach to the sequence-to-sequence task of\ndocument parsing. For this, we exploit recent progress in transition-based\nparsing to implement a parser with synchronous sliding windows over source and\ntarget. We develop an oracle and a parser for document-level AMR by expanding\non Structured-BART such that it leverages source-target alignments and\nconstrains decoding to guarantee synchronicity and consistency across\noverlapping windows. We evaluate our oracle and parser using the Abstract\nMeaning Representation (AMR) parsing 3.0 corpus. On the Multi-Sentence\ndevelopment set of AMR 3.0, we show that our transition oracle loses only 8\\%\nof the gold cross-sentential links despite using a sliding window. In practice,\nthis approach also results in a high-quality document-level parser with\nmanageable memory requirements. Our proposed system performs on par with the\nstate-of-the-art pipeline approach for document-level AMR parsing task on\nMulti-Sentence AMR 3.0 corpus while maintaining sentence-level parsing\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumaravel_S/0/1/0/all/0/1\">Sadhana Kumaravel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naseem_T/0/1/0/all/0/1\">Tahira Naseem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Astudillo_R/0/1/0/all/0/1\">Ramon Fernandez Astudillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Florian_R/0/1/0/all/0/1\">Radu Florian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roukos_S/0/1/0/all/0/1\">Salim Roukos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improved Instruction Ordering in Recipe-Grounded Conversation. (arXiv:2305.17280v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17280","description":"<p>In this paper, we study the task of instructional dialogue and focus on the\ncooking domain. Analyzing the generated output of the GPT-J model, we reveal\nthat the primary challenge for a recipe-grounded dialog system is how to\nprovide the instructions in the correct order. We hypothesize that this is due\nto the model's lack of understanding of user intent and inability to track the\ninstruction state (i.e., which step was last instructed). Therefore, we propose\nto explore two auxiliary subtasks, namely User Intent Detection and Instruction\nState Tracking, to support Response Generation with improved instruction\ngrounding. Experimenting with our newly collected dataset, ChattyChef, shows\nthat incorporating user intent and instruction state information helps the\nresponse generation model mitigate the incorrect order issue. Furthermore, to\ninvestigate whether ChatGPT has completely solved this task, we analyze its\noutputs and find that it also makes mistakes (10.7% of the responses), about\nhalf of which are out-of-order instructions. We will release ChattyChef to\nfacilitate further research in this area at:\nhttps://github.com/octaviaguo/ChattyChef.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Le_D/0/1/0/all/0/1\">Duong Minh Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1\">Ruohao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritter_A/0/1/0/all/0/1\">Alan Ritter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"External Language Model Integration for Factorized Neural Transducers. (arXiv:2305.17304v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17304","description":"<p>We propose an adaptation method for factorized neural transducers (FNT) with\nexternal language models. We demonstrate that both neural and n-gram external\nLMs add significantly more value when linearly interpolated with predictor\noutput compared to shallow fusion, thus confirming that FNT forces the\npredictor to act like regular language models. Further, we propose a method to\nintegrate class-based n-gram language models into FNT framework resulting in\naccuracy gains similar to a hybrid setup. We show average gains of 18% WERR\nwith lexical adaptation across various scenarios and additive gains of up to\n60% WERR in one entity-rich scenario through a combination of class-based\nn-gram and neural LMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Levit_M/0/1/0/all/0/1\">Michael Levit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parthasarathy_S/0/1/0/all/0/1\">Sarangarajan Parthasarathy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aksoylar_C/0/1/0/all/0/1\">Cem Aksoylar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rasooli_M/0/1/0/all/0/1\">Mohammad Sadegh Rasooli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shuangyu Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance. (arXiv:2305.17306v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17306","description":"<p>As large language models (LLMs) are continuously being developed, their\nevaluation becomes increasingly important yet challenging. This work proposes\nChain-of-Thought Hub, an open-source evaluation suite on the multi-step\nreasoning capabilities of large language models. We are interested in this\nsetting for two reasons: (1) from the behavior of GPT and PaLM model family, we\nobserve that complex reasoning is likely to be a key differentiator between\nweaker and stronger LLMs; (2) we envisage large language models to become the\nnext-generation computational platform and foster an ecosystem of LLM-based new\napplications, this naturally requires the foundation models to perform complex\ntasks that often involve the composition of linguistic and logical operations.\nOur approach is to compile a suite of challenging reasoning benchmarks to track\nthe progress of LLMs. Our current results show that: (1) model scale clearly\ncorrelates with reasoning capabilities; (2) As of May 2023, Claude-v1.3 and\nPaLM-2 are the only two models that are comparable with GPT-4, while\nopen-sourced models still lag behind; (3) LLaMA-65B performs closely to\ncode-davinci-002, indicating that with successful further development such as\nreinforcement learning from human feedback (RLHF), it has great potential to be\nclose to GPT-3.5-Turbo. Our results also suggest that for the open-source\nefforts to catch up, the community may focus more on building better base\nmodels and exploring RLHF.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yao Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_L/0/1/0/all/0/1\">Litu Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1\">Yuhao Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khot_T/0/1/0/all/0/1\">Tushar Khot</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Positive Scaling: How Negation Impacts Scaling Trends of Language Models. (arXiv:2305.17311v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17311","description":"<p>Language models have been shown to exhibit positive scaling, where\nperformance improves as models are scaled up in terms of size, compute, or\ndata. In this work, we introduce NeQA, a dataset consisting of questions with\nnegation in which language models do not exhibit straightforward positive\nscaling. We show that this task can exhibit inverse scaling, U-shaped scaling,\nor positive scaling, and the three scaling trends shift in this order as we use\nmore powerful prompting methods or model families. We hypothesize that solving\nNeQA depends on two subtasks: question answering (task 1) and negation\nunderstanding (task 2). We find that task 1 has linear scaling, while task 2\nhas sigmoid-shaped scaling with an emergent transition point, and composing\nthese two scaling trends yields the final scaling trend of NeQA. Our work\nreveals and provides a way to analyze the complex scaling trends of language\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuhui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yasunaga_M/0/1/0/all/0/1\">Michihiro Yasunaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhengping Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+HaoChen_J/0/1/0/all/0/1\">Jeff Z. HaoChen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_S/0/1/0/all/0/1\">Serena Yeung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Why Does Zero-Shot Cross-Lingual Generation Fail? An Explanation and a Solution. (arXiv:2305.17325v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17325","description":"<p>Zero-shot cross-lingual transfer is when a multilingual model is trained to\nperform a task in one language and then is applied to another language.\nAlthough the zero-shot cross-lingual transfer approach has achieved success in\nvarious classification tasks, its performance on natural language generation\ntasks falls short in quality and sometimes outputs an incorrect language. In\nour study, we show that the fine-tuning process learns language invariant\nrepresentations, which is beneficial for classification tasks but harmful for\ngeneration tasks. Motivated by this, we propose a simple method to regularize\nthe model from learning language invariant representations and a method to\nselect model checkpoints without a development set in the target language, both\nresulting in better generation quality. Experiments on three semantically\ndiverse generation tasks show that our method reduces the accidental\ntranslation problem by 68% and improves the ROUGE-L score by 1.5 on average.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianjian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murray_K/0/1/0/all/0/1\">Kenton Murray</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In. (arXiv:2305.17331v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17331","description":"<p>Retrieval augmentation can aid language models (LMs) in knowledge-intensive\ntasks by supplying them with external information. Prior works on retrieval\naugmentation usually jointly fine-tune the retriever and the LM, making them\nclosely coupled. In this paper, we explore the scheme of generic retrieval\nplug-in: the retriever is to assist target LMs that may not be known beforehand\nor are unable to be fine-tuned together. To retrieve useful documents for\nunseen target LMs, we propose augmentation-adapted retriever (AAR), which\nlearns LM's preferences obtained from a known source LM. Experiments on the\nMMLU and PopQA datasets demonstrate that our AAR trained with a small source LM\nis able to significantly improve the zero-shot generalization of larger target\nLMs ranging from 250M Flan-T5 to 175B InstructGPT. Further analysis indicates\nthat the preferences of different LMs overlap, enabling AAR trained with a\nsingle source LM to serve as a generic plug-in for various target LMs. Our code\nis open-sourced at https://github.com/OpenMatch/Augmentation-Adapted-Retriever.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zichun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Chenyan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shi Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-Tuning Language Models with Just Forward Passes. (arXiv:2305.17333v1 [cs.LG])","link":"http://arxiv.org/abs/2305.17333","description":"<p>Fine-tuning language models (LMs) has yielded success on diverse downstream\ntasks, but as LMs grow in size, backpropagation requires a prohibitively large\namount of memory. Zeroth-order (ZO) methods can in principle estimate gradients\nusing only two forward passes but are theorized to be catastrophically slow for\noptimizing large models. In this work, we propose a memory-efficient\nzerothorder optimizer (MeZO), adapting the classical ZO-SGD method to operate\nin-place, thereby fine-tuning LMs with the same memory footprint as inference.\nFor example, with a single A100 80GB GPU, MeZO can train a 30-billion parameter\nmodel, whereas fine-tuning with backpropagation can train only a 2.7B LM with\nthe same budget. We conduct comprehensive experiments across model types\n(masked and autoregressive LMs), model scales (up to 66B), and downstream tasks\n(classification, multiple-choice, and generation). Our results demonstrate that\n(1) MeZO significantly outperforms in-context learning and linear probing; (2)\nMeZO achieves comparable performance to fine-tuning with backpropagation across\nmultiple tasks, with up to 12x memory reduction; (3) MeZO is compatible with\nboth full-parameter and parameter-efficient tuning techniques such as LoRA and\nprefix tuning; (4) MeZO can effectively optimize non-differentiable objectives\n(e.g., maximizing accuracy or F1). We support our empirical findings with\ntheoretical insights, highlighting how adequate pre-training and task prompts\nenable MeZO to fine-tune huge models, despite classical ZO analyses suggesting\notherwise.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Malladi_S/0/1/0/all/0/1\">Sadhika Malladi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tianyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nichani_E/0/1/0/all/0/1\">Eshaan Nichani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damian_A/0/1/0/all/0/1\">Alex Damian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jason D. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1\">Sanjeev Arora</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Benchmarking Diverse-Modal Entity Linking with Generative Models. (arXiv:2305.17337v1 [cs.CL])","link":"http://arxiv.org/abs/2305.17337","description":"<p>Entities can be expressed in diverse formats, such as texts, images, or\ncolumn names and cell values in tables. While existing entity linking (EL)\nmodels work well on per modality configuration, such as text-only EL, visual\ngrounding, or schema linking, it is more challenging to design a unified model\nfor diverse modality configurations. To bring various modality configurations\ntogether, we constructed a benchmark for diverse-modal EL (DMEL) from existing\nEL datasets, covering all three modalities including text, image, and table. To\napproach the DMEL task, we proposed a generative diverse-modal model (GDMM)\nfollowing a multimodal-encoder-decoder paradigm. Pre-training \\Model with rich\ncorpora builds a solid foundation for DMEL without storing the entire KB for\ninference. Fine-tuning GDMM builds a stronger DMEL baseline, outperforming\nstate-of-the-art task-specific EL models by 8.51 F1 score on average.\nAdditionally, extensive error analyses are conducted to highlight the\nchallenges of DMEL, facilitating future research on this task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sijia Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Alexander Hanbo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Henry Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hang_C/0/1/0/all/0/1\">Chung-Wei Hang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perera_P/0/1/0/all/0/1\">Pramuditha Perera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jie Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhiguo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castelli_V/0/1/0/all/0/1\">Vittorio Castelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_B/0/1/0/all/0/1\">Bing Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_P/0/1/0/all/0/1\">Patrick Ng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"QAMPARI: An Open-domain Question Answering Benchmark for Questions with Many Answers from Multiple Paragraphs. (arXiv:2205.12665v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.12665","description":"<p>Existing benchmarks for open-domain question answering (ODQA) typically focus\non questions whose answers can be extracted from a single paragraph. By\ncontrast, many natural questions, such as \"What players were drafted by the\nBrooklyn Nets?\" have a list of answers. Answering such questions requires\nretrieving and reading from many passages, in a large corpus. We introduce\nQAMPARI, an ODQA benchmark, where question answers are lists of entities,\nspread across many paragraphs. We created QAMPARI by (a) generating questions\nwith multiple answers from Wikipedia's knowledge graph and tables, (b)\nautomatically pairing answers with supporting evidence in Wikipedia paragraphs,\nand (c) manually paraphrasing questions and validating each answer. We train\nODQA models from the retrieve-and-read family and find that QAMPARI is\nchallenging in terms of both passage retrieval and answer generation, reaching\nan F1 score of 32.8 at best. Our results highlight the need for developing ODQA\nmodels that handle a broad range of question types, including single and\nmulti-answer questions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Amouyal_S/0/1/0/all/0/1\">Samuel Joseph Amouyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolfson_T/0/1/0/all/0/1\">Tomer Wolfson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_O/0/1/0/all/0/1\">Ohad Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoran_O/0/1/0/all/0/1\">Ori Yoran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzig_J/0/1/0/all/0/1\">Jonathan Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Optimizing Test-Time Query Representations for Dense Retrieval. (arXiv:2205.12680v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.12680","description":"<p>Recent developments of dense retrieval rely on quality representations of\nqueries and contexts from pre-trained query and context encoders. In this\npaper, we introduce TOUR (Test-Time Optimization of Query Representations),\nwhich further optimizes instance-level query representations guided by signals\nfrom test-time retrieval results. We leverage a cross-encoder re-ranker to\nprovide fine-grained pseudo labels over retrieval results and iteratively\noptimize query representations with gradient descent. Our theoretical analysis\nreveals that TOUR can be viewed as a generalization of the classical Rocchio\nalgorithm for pseudo relevance feedback, and we present two variants that\nleverage pseudo-labels as hard binary or soft continuous labels. We first apply\nTOUR on phrase retrieval with our proposed phrase re-ranker, and also evaluate\nits effectiveness on passage retrieval with an off-the-shelf re-ranker. TOUR\ngreatly improves end-to-end open-domain question answering accuracy, as well as\npassage retrieval performance. TOUR also consistently improves direct\nre-ranking by up to 2.0% while running 1.3-2.4x faster with an efficient\nimplementation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sung_M/0/1/0/all/0/1\">Mujeen Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jungsoo Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1\">Jaewoo Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jinhyuk Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BITE: Textual Backdoor Attacks with Iterative Trigger Injection. (arXiv:2205.12700v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.12700","description":"<p>Backdoor attacks have become an emerging threat to NLP systems. By providing\npoisoned training data, the adversary can embed a \"backdoor\" into the victim\nmodel, which allows input instances satisfying certain textual patterns (e.g.,\ncontaining a keyword) to be predicted as a target label of the adversary's\nchoice. In this paper, we demonstrate that it is possible to design a backdoor\nattack that is both stealthy (i.e., hard to notice) and effective (i.e., has a\nhigh attack success rate). We propose BITE, a backdoor attack that poisons the\ntraining data to establish strong correlations between the target label and a\nset of \"trigger words\". These trigger words are iteratively identified and\ninjected into the target-label instances through natural word-level\nperturbations. The poisoned training data instruct the victim model to predict\nthe target label on inputs containing trigger words, forming the backdoor.\nExperiments on four text classification datasets show that our proposed attack\nis significantly more effective than baseline methods while maintaining decent\nstealthiness, raising alarm on the usage of untrusted training data. We further\npropose a defense method named DeBITE based on potential trigger word removal,\nwhich outperforms existing methods in defending against BITE and generalizes\nwell to handling other backdoor attacks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1\">Vansh Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MVP: Multi-task Supervised Pre-training for Natural Language Generation. (arXiv:2206.12131v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.12131","description":"<p>Pre-trained language models (PLMs) have achieved remarkable success in\nnatural language generation (NLG) tasks. Up to now, most NLG-oriented PLMs are\npre-trained in an unsupervised manner using the large-scale general corpus. In\nthe meanwhile, an increasing number of models pre-trained with labeled data\n(i.e. \"supervised pre-training\") showcase superior performance compared to\nunsupervised pre-trained models. Motivated by the success of supervised\npre-training, we propose Multi-task superVised Pre-training (MVP) for natural\nlanguage generation. We collect a large-scale natural language generation\ncorpus, MVPCorpus, from $77$ datasets over $11$ diverse NLG tasks. Then we\nunify these examples into a general text-to-text format to pre-train the text\ngeneration model MVP in a supervised manner. For each task, we further\npre-train specific soft prompts to stimulate the model's capacity to perform a\nspecific task. Our MVP model can be seen as a practice that utilizes recent\ninstruction tuning on relatively small PLMs. Extensive experiments have\ndemonstrated the effectiveness and generality of our MVP model in a number of\nNLG tasks, which achieves state-of-the-art performance on $13$ out of $17$\ndatasets, outperforming BART by $9.3\\%$ and Flan-T5 by $5.8\\%$.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1\">Tianyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Joint Generator-Ranker Learning for Natural Language Generation. (arXiv:2206.13974v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.13974","description":"<p>Generate-then-rank is a widely used mechanism for text generation, where a\ngenerator produces multiple text candidates and a ranker chooses the best one\namong the text candidates. However, existing methods usually train the\ngenerator and the ranker individually, neglecting the mutual feedback that\ncould further enhance the generation quality. To tackle this limitation, we\npropose JGR, a novel joint training algorithm that integrates the generator and\nthe ranker in a single framework. JGR optimizes the generator with a hybrid\nobjective that combines data likelihood and ranker reward, and trains the\nranker with a contrastive loss that compares the generator outputs. By\niteratively updating the generator and the ranker, JGR can effectively\nharmonize their learning and enhance their quality jointly. We evaluate JGR on\nvarious text generation tasks and demonstrate that it surpasses existing\nmethods on four public datasets across three common generation scenarios. Our\ncode and models are publicly available at\nhttps://github.com/microsoft/ProphetNet/tree/master/JGR.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Weizhou Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yelong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Song Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Massively Multilingual Lexical Specialization of Multilingual Transformers. (arXiv:2208.01018v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.01018","description":"<p>While pretrained language models (PLMs) primarily serve as general-purpose\ntext encoders that can be fine-tuned for a wide variety of downstream tasks,\nrecent work has shown that they can also be rewired to produce high-quality\nword representations (i.e., static word embeddings) and yield good performance\nin type-level lexical tasks. While existing work primarily focused on the\nlexical specialization of monolingual PLMs with immense quantities of\nmonolingual constraints, in this work we expose massively multilingual\ntransformers (MMTs, e.g., mBERT or XLM-R) to multilingual lexical knowledge at\nscale, leveraging BabelNet as the readily available rich source of multilingual\nand cross-lingual type-level lexical knowledge. Concretely, we use BabelNet's\nmultilingual synsets to create synonym pairs (or synonym-gloss pairs) across 50\nlanguages and then subject the MMTs (mBERT and XLM-R) to a lexical\nspecialization procedure guided by a contrastive objective. We show that such\nmassively multilingual lexical specialization brings substantial gains in two\nstandard cross-lingual lexical tasks, bilingual lexicon induction and\ncross-lingual word similarity, as well as in cross-lingual sentence retrieval.\nCrucially, we observe gains for languages unseen in specialization, indicating\nthat multilingual lexical specialization enables generalization to languages\nwith no lexical constraints. In a series of subsequent controlled experiments,\nwe show that the number of specialization constraints plays a much greater role\nthan the set of languages from which they originate.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Green_T/0/1/0/all/0/1\">Tommaso Green</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponzetto_S/0/1/0/all/0/1\">Simone Paolo Ponzetto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glavas_G/0/1/0/all/0/1\">Goran Glava&#x161;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PaLI: A Jointly-Scaled Multilingual Language-Image Model. (arXiv:2209.06794v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2209.06794","description":"<p>Effective scaling and a flexible task interface enable large language models\nto excel at many tasks. We present PaLI (Pathways Language and Image model), a\nmodel that extends this approach to the joint modeling of language and vision.\nPaLI generates text based on visual and textual inputs, and with this interface\nperforms many vision, language, and multimodal tasks, in many languages. To\ntrain PaLI, we make use of large pre-trained encoder-decoder language models\nand Vision Transformers (ViTs). This allows us to capitalize on their existing\ncapabilities and leverage the substantial cost of training them. We find that\njoint scaling of the vision and language components is important. Since\nexisting Transformers for language are much larger than their vision\ncounterparts, we train a large, 4-billion parameter ViT (ViT-e) to quantify the\nbenefits from even larger-capacity vision models. To train PaLI, we create a\nlarge multilingual mix of pretraining tasks, based on a new image-text training\nset containing 10B images and texts in over 100 languages. PaLI achieves\nstate-of-the-art in multiple vision and language tasks (such as captioning,\nvisual question-answering, scene-text understanding), while retaining a simple,\nmodular, and scalable design.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Changpinyo_S/0/1/0/all/0/1\">Soravit Changpinyo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piergiovanni_A/0/1/0/all/0/1\">AJ Piergiovanni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padlewski_P/0/1/0/all/0/1\">Piotr Padlewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salz_D/0/1/0/all/0/1\">Daniel Salz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_S/0/1/0/all/0/1\">Sebastian Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grycner_A/0/1/0/all/0/1\">Adam Grycner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mustafa_B/0/1/0/all/0/1\">Basil Mustafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1\">Lucas Beyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1\">Alexander Kolesnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puigcerver_J/0/1/0/all/0/1\">Joan Puigcerver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1\">Nan Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rong_K/0/1/0/all/0/1\">Keran Rong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akbari_H/0/1/0/all/0/1\">Hassan Akbari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_G/0/1/0/all/0/1\">Gaurav Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1\">Linting Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thapliyal_A/0/1/0/all/0/1\">Ashish Thapliyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bradbury_J/0/1/0/all/0/1\">James Bradbury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_W/0/1/0/all/0/1\">Weicheng Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seyedhosseini_M/0/1/0/all/0/1\">Mojtaba Seyedhosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1\">Chao Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayan_B/0/1/0/all/0/1\">Burcu Karagol Ayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riquelme_C/0/1/0/all/0/1\">Carlos Riquelme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steiner_A/0/1/0/all/0/1\">Andreas Steiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angelova_A/0/1/0/all/0/1\">Anelia Angelova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaohua Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soricut_R/0/1/0/all/0/1\">Radu Soricut</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Whole Truth and Nothing But the Truth: Faithful and Controllable Dialogue Response Generation with Dataflow Transduction and Constrained Decoding. (arXiv:2209.07800v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.07800","description":"<p>In a real-world dialogue system, generated text must be truthful and\ninformative while remaining fluent and adhering to a prescribed style.\nSatisfying these constraints simultaneously is difficult for the two\npredominant paradigms in language generation: neural language modeling and\nrule-based generation. We describe a hybrid architecture for dialogue response\ngeneration that combines the strengths of both paradigms. The first component\nof this architecture is a rule-based content selection model defined using a\nnew formal framework called dataflow transduction, which uses declarative rules\nto transduce a dialogue agent's actions and their results (represented as\ndataflow graphs) into context-free grammars representing the space of\ncontextually acceptable responses. The second component is a constrained\ndecoding procedure that uses these grammars to constrain the output of a neural\nlanguage model, which selects fluent utterances. Our experiments show that this\nsystem outperforms both rule-based and learned approaches in human evaluations\nof fluency, relevance, and truthfulness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1\">Hao Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balakrishnan_A/0/1/0/all/0/1\">Anusha Balakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jhamtani_H/0/1/0/all/0/1\">Harsh Jhamtani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bufe_J/0/1/0/all/0/1\">John Bufe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crawford_J/0/1/0/all/0/1\">Jean Crawford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_J/0/1/0/all/0/1\">Jayant Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pauls_A/0/1/0/all/0/1\">Adam Pauls</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisner_J/0/1/0/all/0/1\">Jason Eisner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Augmentation Invariant Discrete Representation for Generative Spoken Language Modeling. (arXiv:2209.15483v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.15483","description":"<p>Generative Spoken Language Modeling research focuses on optimizing speech\nLanguage Models (LMs) using raw audio recordings without accessing any textual\nsupervision. Such speech LMs usually operate over discrete units obtained from\nquantizing internal representations of self-supervised models. Although such\nunits show impressive modeling results, their robustness capabilities have not\nbeen extensively investigated. This work focuses on improving the robustness of\ndiscrete input representations for generative spoken language modeling. First,\nwe formally define how to measure the robustness of such representations to\nvarious signal variations that do not alter the spoken information (e.g.,\ntime-stretch). Next, we empirically demonstrate how current state-of-the-art\nrepresentation models lack robustness to such variations. To overcome this, we\npropose an effective and efficient method to learn robust discrete speech\nrepresentation for generative spoken language modeling. The proposed approach\nis based on applying a set of signal transformations to the speech signal and\noptimizing the model using an iterative pseudo-labeling scheme. Our method\nsignificantly improves over the evaluated baselines when considering encoding\nand modeling metrics. We additionally evaluate our method on the\nspeech-to-speech translation task, considering Spanish-English and\nFrench-English translations, and show the proposed approach outperforms the\nevaluated baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gat_I/0/1/0/all/0/1\">Itai Gat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreuk_F/0/1/0/all/0/1\">Felix Kreuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tu Anh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_A/0/1/0/all/0/1\">Ann Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Copet_J/0/1/0/all/0/1\">Jade Copet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1\">Gabriel Synnaeve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dupoux_E/0/1/0/all/0/1\">Emmanuel Dupoux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adi_Y/0/1/0/all/0/1\">Yossi Adi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rethinking Annotation: Can Language Learners Contribute?. (arXiv:2210.06828v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.06828","description":"<p>Researchers have traditionally recruited native speakers to provide\nannotations for widely used benchmark datasets. However, there are languages\nfor which recruiting native speakers can be difficult, and it would help to\nfind learners of those languages to annotate the data. In this paper, we\ninvestigate whether language learners can contribute annotations to benchmark\ndatasets. In a carefully controlled annotation experiment, we recruit 36\nlanguage learners, provide two types of additional resources (dictionaries and\nmachine-translated sentences), and perform mini-tests to measure their language\nproficiency. We target three languages, English, Korean, and Indonesian, and\nthe four NLP tasks of sentiment analysis, natural language inference, named\nentity recognition, and machine reading comprehension. We find that language\nlearners, especially those with intermediate or advanced levels of language\nproficiency, are able to provide fairly accurate labels with the help of\nadditional resources. Moreover, we show that data annotation improves learners'\nlanguage proficiency in terms of vocabulary and grammar. One implication of our\nfindings is that broadening the annotation task to include language learners\ncan open up the opportunity to build benchmark datasets for languages for which\nit is difficult to recruit native speakers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yoo_H/0/1/0/all/0/1\">Haneul Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Putri_R/0/1/0/all/0/1\">Rifki Afina Putri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Changyoon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Youngin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1\">So-Yeon Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1\">Dongyeop Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1\">Alice Oh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dense-ATOMIC: Towards Densely-connected ATOMIC with High Knowledge Coverage and Massive Multi-hop Paths. (arXiv:2210.07621v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.07621","description":"<p>ATOMIC is a large-scale commonsense knowledge graph (CSKG) containing\neveryday if-then knowledge triplets, i.e., {head event, relation, tail event}.\nThe one-hop annotation manner made ATOMIC a set of independent bipartite\ngraphs, which ignored the numerous links between events in different bipartite\ngraphs and consequently caused shortages in knowledge coverage and multi-hop\npaths. In this work, we aim to construct Dense-ATOMIC with high knowledge\ncoverage and massive multi-hop paths. The events in ATOMIC are normalized to a\nconsistent pattern at first. We then propose a CSKG completion method called\nRel-CSKGC to predict the relation given the head event and the tail event of a\ntriplet, and train a CSKG completion model based on existing triplets in\nATOMIC. We finally utilize the model to complete the missing links in ATOMIC\nand accordingly construct Dense-ATOMIC. Both automatic and human evaluation on\nan annotated subgraph of ATOMIC demonstrate the advantage of Rel-CSKGC over\nstrong baselines. We further conduct extensive evaluations on Dense-ATOMIC in\nterms of statistics, human evaluation, and simple downstream tasks, all proving\nDense-ATOMIC's advantages in Knowledge Coverage and Multi-hop Paths. Both the\nsource code of Rel-CSKGC and Dense-ATOMIC are publicly available on\nhttps://github.com/NUSTM/Dense-ATOMIC.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xiangqing Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Siwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_R/0/1/0/all/0/1\">Rui Xia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Solving Math Word Problems via Cooperative Reasoning induced Language Models. (arXiv:2210.16257v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.16257","description":"<p>Large-scale pre-trained language models (PLMs) bring new opportunities to\nchallenging problems, especially those that need high-level intelligence, such\nas the math word problem (MWPs). However, directly applying existing PLMs to\nMWPs can fail as the generation process lacks sufficient supervision and thus\nlacks fast adaptivity as humans. We notice that human reasoning has a dual\nreasoning framework that consists of an immediate reaction system (system 1)\nand a delicate reasoning system (system 2), where the entire reasoning is\ndetermined by their interaction. This inspires us to develop a cooperative\nreasoning-induced PLM for solving MWPs, called Cooperative Reasoning (CoRe),\nresulting in a human-like reasoning architecture with system 1 as the generator\nand system 2 as the verifier. In our approach, the generator is responsible for\ngenerating reasoning paths, and the verifiers are used to supervise the\nevaluation in order to obtain reliable feedback for the generator. We evaluate\nour CoRe framework on several mathematical reasoning datasets and achieve\ndecent improvement over state-of-the-art methods, up to 9.6% increase over best\nbaselines. Our codes are available at https://github.com/TianHongZXY/CoRe\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xinyu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuxiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_R/0/1/0/all/0/1\">Ruyi Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaxing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yujiu Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Crosslingual Generalization through Multitask Finetuning. (arXiv:2211.01786v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.01786","description":"<p>Multitask prompted finetuning (MTF) has been shown to help large language\nmodels generalize to new tasks in a zero-shot setting, but so far explorations\nof MTF have focused on English data and models. We apply MTF to the pretrained\nmultilingual BLOOM and mT5 model families to produce finetuned variants called\nBLOOMZ and mT0. We find finetuning large multilingual language models on\nEnglish tasks with English prompts allows for task generalization to\nnon-English languages that appear only in the pretraining corpus. Finetuning on\nmultilingual tasks with English prompts further improves performance on English\nand non-English tasks leading to various state-of-the-art zero-shot results. We\nalso investigate finetuning on multilingual tasks with prompts that have been\nmachine-translated from English to match the language of each dataset. We find\ntraining on these machine-translated prompts leads to better performance on\nhuman-written prompts in the respective languages. Surprisingly, we find models\nare capable of zero-shot generalization to tasks in languages they have never\nintentionally seen. We conjecture that the models are learning higher-level\ncapabilities that are both task- and language-agnostic. In addition, we\nintroduce xP3, a composite of supervised datasets in 46 languages with English\nand machine-translated prompts. Our code, datasets and models are freely\navailable at https://github.com/bigscience-workshop/xmtf.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Muennighoff_N/0/1/0/all/0/1\">Niklas Muennighoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Thomas Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutawika_L/0/1/0/all/0/1\">Lintang Sutawika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_A/0/1/0/all/0/1\">Adam Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biderman_S/0/1/0/all/0/1\">Stella Biderman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scao_T/0/1/0/all/0/1\">Teven Le Scao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bari_M/0/1/0/all/0/1\">M Saiful Bari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1\">Sheng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yong_Z/0/1/0/all/0/1\">Zheng-Xin Yong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schoelkopf_H/0/1/0/all/0/1\">Hailey Schoelkopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiangru Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aji_A/0/1/0/all/0/1\">Alham Fikri Aji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almubarak_K/0/1/0/all/0/1\">Khalid Almubarak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albanie_S/0/1/0/all/0/1\">Samuel Albanie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alyafeai_Z/0/1/0/all/0/1\">Zaid Alyafeai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Webson_A/0/1/0/all/0/1\">Albert Webson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raff_E/0/1/0/all/0/1\">Edward Raff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"lilGym: Natural Language Visual Reasoning with Reinforcement Learning. (arXiv:2211.01994v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2211.01994","description":"<p>We present lilGym, a new benchmark for language-conditioned reinforcement\nlearning in visual environments. lilGym is based on 2,661 highly-compositional\nhuman-written natural language statements grounded in an interactive visual\nenvironment. We introduce a new approach for exact reward computation in every\npossible world state by annotating all statements with executable Python\nprograms. Each statement is paired with multiple start states and reward\nfunctions to form thousands of distinct Markov Decision Processes of varying\ndifficulty. We experiment with lilGym with different models and learning\nregimes. Our results and analysis show that while existing methods are able to\nachieve non-trivial performance, lilGym forms a challenging open problem.\nlilGym is available at https://lil.nlp.cornell.edu/lilgym/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Anne Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brantley_K/0/1/0/all/0/1\">Kiant&#xe9; Brantley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kojima_N/0/1/0/all/0/1\">Noriyuki Kojima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artzi_Y/0/1/0/all/0/1\">Yoav Artzi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"mOKB6: A Multilingual Open Knowledge Base Completion Benchmark. (arXiv:2211.06959v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.06959","description":"<p>Automated completion of open knowledge bases (Open KBs), which are\nconstructed from triples of the form (subject phrase, relation phrase, object\nphrase), obtained via open information extraction (Open IE) system, are useful\nfor discovering novel facts that may not be directly present in the text.\nHowever, research in Open KB completion (Open KBC) has so far been limited to\nresource-rich languages like English. Using the latest advances in multilingual\nOpen IE, we construct the first multilingual Open KBC dataset, called mOKB6,\ncontaining facts from Wikipedia in six languages (including English). Improving\nthe previous Open KB construction pipeline by doing multilingual coreference\nresolution and keeping only entity-linked triples, we create a dense Open KB.\nWe experiment with several models for the task and observe a consistent benefit\nof combining languages with the help of shared embedding space as well as\ntranslations of facts. We also observe that current multilingual models\nstruggle to remember facts seen in languages of different scripts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mittal_S/0/1/0/all/0/1\">Shubham Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolluru_K/0/1/0/all/0/1\">Keshav Kolluru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarti_S/0/1/0/all/0/1\">Soumen Chakrabarti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mausam/0/1/0/all/0/1\">Mausam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UniSumm and SummZoo: Unified Model and Diverse Benchmark for Few-Shot Summarization. (arXiv:2211.09783v6 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.09783","description":"<p>The high annotation costs and diverse demands of various summarization tasks\nmotivate the development of few-shot summarization. However, despite the\nemergence of many summarization tasks and datasets, the current training\nparadigm for few-shot summarization systems ignores potentially shareable\nknowledge in heterogeneous datasets. To this end, we propose \\textsc{UniSumm},\na unified few-shot summarization model pre-trained with multiple summarization\ntasks and can be prefix-tuned to excel at any few-shot summarization task.\nMeanwhile, to better evaluate few-shot summarizers, under the principles of\ndiversity and robustness, we assemble and release a new benchmark\n\\textsc{SummZoo}. It consists of $8$ summarization tasks with multiple sets of\nfew-shot samples for each task, covering diverse domains. Experimental results\nand analysis show that \\textsc{UniSumm} outperforms strong baselines by a large\nmargin across all sub-tasks in \\textsc{SummZoo} under both automatic and human\nevaluations and achieves comparable results in human evaluation compared with a\nGPT-3.5 model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yulong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruochen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Ziyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chenguang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Michael Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Controlling Styles in Neural Machine Translation with Activation Prompt. (arXiv:2212.08909v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.08909","description":"<p>Controlling styles in neural machine translation (NMT) has attracted wide\nattention, as it is crucial for enhancing user experience. Earlier studies on\nthis topic typically concentrate on regulating the level of formality and\nachieve some progress in this area. However, they still encounter two major\nchallenges. The first is the difficulty in style evaluation. The style\ncomprises various aspects such as lexis, syntax, and others that provide\nabundant information. Nevertheless, only formality has been thoroughly\ninvestigated. The second challenge involves excessive dependence on incremental\nadjustments, particularly when new styles are necessary. To address both\nchallenges, this paper presents a new benchmark and approach. A multiway\nstylized machine translation (MSMT) benchmark is introduced, incorporating\ndiverse categories of styles across four linguistic domains. Then, we propose a\nmethod named style activation prompt (StyleAP) by retrieving prompts from\nstylized monolingual corpus, which does not require extra fine-tuning.\nExperiments show that StyleAP could effectively control the style of\ntranslation and achieve remarkable performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zewei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Shanbo Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1\">Weiguo Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modeling Instance Interactions for Joint Information Extraction with Neural High-Order Conditional Random Field. (arXiv:2212.08929v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.08929","description":"<p>Prior works on joint Information Extraction (IE) typically model instance\n(e.g., event triggers, entities, roles, relations) interactions by\nrepresentation enhancement, type dependencies scoring, or global decoding. We\nfind that the previous models generally consider binary type dependency scoring\nof a pair of instances, and leverage local search such as beam search to\napproximate global solutions. To better integrate cross-instance interactions,\nin this work, we introduce a joint IE framework (CRFIE) that formulates joint\nIE as a high-order Conditional Random Field. Specifically, we design binary\nfactors and ternary factors to directly model interactions between not only a\npair of instances but also triplets. Then, these factors are utilized to\njointly predict labels of all instances. To address the intractability problem\nof exact high-order inference, we incorporate a high-order neural decoder that\nis unfolded from a mean-field variational inference method, which achieves\nconsistent learning and inference. The experimental results show that our\napproach achieves consistent improvements on three IE tasks compared with our\nbaseline and prior work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1\">Zixia Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhaohui Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1\">Wenjuan Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zilong Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Isotropy, Contextualization and Learning Dynamics of Contrastive-based Sentence Representation Learning. (arXiv:2212.09170v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09170","description":"<p>Incorporating contrastive learning objectives in sentence representation\nlearning (SRL) has yielded significant improvements on many sentence-level NLP\ntasks. However, it is not well understood why contrastive learning works for\nlearning sentence-level semantics. In this paper, we aim to help guide future\ndesigns of sentence representation learning methods by taking a closer look at\ncontrastive SRL through the lens of isotropy, contextualization and learning\ndynamics. We interpret its successes through the geometry of the representation\nshifts and show that contrastive learning brings isotropy, and drives high\nintra-sentence similarity: when in the same sentence, tokens converge to\nsimilar positions in the semantic space. We also find that what we formalize as\n\"spurious contextualization\" is mitigated for semantically meaningful tokens,\nwhile augmented for functional ones. We find that the embedding space is\ndirected towards the origin during training, with more areas now better\ndefined. We ablate these findings by observing the learning dynamics with\ndifferent training temperatures, batch sizes and pooling methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chenghao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1\">Yang Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moubayed_N/0/1/0/all/0/1\">Noura Al Moubayed</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PAL: Persona-Augmented Emotional Support Conversation Generation. (arXiv:2212.09235v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09235","description":"<p>Due to the lack of human resources for mental health support, there is an\nincreasing demand for employing conversational agents for support. Recent work\nhas demonstrated the effectiveness of dialogue models in providing emotional\nsupport. As previous studies have demonstrated that seekers' persona is an\nimportant factor for effective support, we investigate whether there are\nbenefits to modeling such information in dialogue models for support. In this\npaper, our empirical analysis verifies that persona has an important impact on\nemotional support. Therefore, we propose a framework for dynamically inferring\nand modeling seekers' persona. We first train a model for inferring the\nseeker's persona from the conversation history. Accordingly, we propose PAL, a\nmodel that leverages persona information and, in conjunction with our\nstrategy-based controllable generation method, provides personalized emotional\nsupport. Automatic and manual evaluations demonstrate that PAL achieves\nstate-of-the-art results, outperforming the baselines on the studied benchmark.\nOur code and data are publicly available at https://github.com/chengjl19/PAL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1\">Jiale Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabour_S/0/1/0/all/0/1\">Sahand Sabour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhuang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Extensible Plug-and-Play Method for Multi-Aspect Controllable Text Generation. (arXiv:2212.09387v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09387","description":"<p>Recently, multi-aspect controllable text generation that controls the\ngenerated text in multiple aspects (e.g., sentiment, topic, and keywords) has\nattracted increasing attention. Although methods based on parameter efficient\ntuning like prefix-tuning could achieve multi-aspect controlling in a\nplug-and-play way, the mutual interference of multiple prefixes leads to\nsignificant degeneration of constraints and limits their extensibility to\ntraining-time unseen aspect combinations. In this work, we provide a\ntheoretical lower bound for the interference and empirically found that the\ninterference grows with the number of layers where prefixes are inserted. Based\non these analyses, we propose using trainable gates to normalize the\nintervention of prefixes to restrain the growing interference. As a result,\ncontrolling training-time unseen combinations of aspects can be realized by\nsimply concatenating corresponding plugins such that new constraints can be\nextended at a lower cost. In addition, we propose a unified way to process both\ncategorical and free-form constraints. Experiments on text generation and\nmachine translation demonstrate the superiority of our approach over baselines\non constraint accuracy, text quality, and extensibility.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuancheng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zijun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BLOOM+1: Adding Language Support to BLOOM for Zero-Shot Prompting. (arXiv:2212.09535v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09535","description":"<p>The BLOOM model is a large publicly available multilingual language model,\nbut its pretraining was limited to 46 languages. To extend the benefits of\nBLOOM to other languages without incurring prohibitively large costs, it is\ndesirable to adapt BLOOM to new languages not seen during pretraining. In this\nwork, we apply existing language adaptation strategies to BLOOM and benchmark\nits zero-shot prompting performance on eight new languages in a\nresource-constrained setting. We find language adaptation to be effective at\nimproving zero-shot performance in new languages. Surprisingly, we find that\nadapter-based finetuning is more effective than continued pretraining for large\nmodels. In addition, we discover that prompting performance is not\nsignificantly affected by language specifics, such as the writing system. It is\nprimarily determined by the size of the language adaptation data. We also add\nnew languages to BLOOMZ, which is a multitask finetuned version of BLOOM\ncapable of following task instructions zero-shot. We find including a new\nlanguage in the multitask fine-tuning mixture to be the most effective method\nto teach BLOOMZ a new language. We conclude that with sufficient training data\nlanguage adaptation can generalize well to diverse languages. Our code is\navailable at https://github.com/bigscience-workshop/multilingual-modeling.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yong_Z/0/1/0/all/0/1\">Zheng-Xin Yong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schoelkopf_H/0/1/0/all/0/1\">Hailey Schoelkopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muennighoff_N/0/1/0/all/0/1\">Niklas Muennighoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aji_A/0/1/0/all/0/1\">Alham Fikri Aji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1\">David Ifeoluwa Adelani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almubarak_K/0/1/0/all/0/1\">Khalid Almubarak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bari_M/0/1/0/all/0/1\">M Saiful Bari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutawika_L/0/1/0/all/0/1\">Lintang Sutawika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasai_J/0/1/0/all/0/1\">Jungo Kasai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baruwa_A/0/1/0/all/0/1\">Ahmed Baruwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winata_G/0/1/0/all/0/1\">Genta Indra Winata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biderman_S/0/1/0/all/0/1\">Stella Biderman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raff_E/0/1/0/all/0/1\">Edward Raff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikoulina_V/0/1/0/all/0/1\">Vassilina Nikoulina</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09597","description":"<p>Reasoning, as an essential ability for complex problem-solving, can provide\nback-end support for various real-world applications, such as medical\ndiagnosis, negotiation, etc. This paper provides a comprehensive survey of\ncutting-edge research on reasoning with language model prompting. We introduce\nresearch works with comparisons and summaries and provide systematic resources\nto help beginners. We also discuss the potential reasons for emerging such\nreasoning abilities and highlight future research directions. Resources are\navailable at https://github.com/zjunlp/Prompt4ReasoningPapers (updated\nperiodically).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1\">Shuofei Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_Y/0/1/0/all/0/1\">Yixin Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yunzhi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Training Trajectories of Language Models Across Scales. (arXiv:2212.09803v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09803","description":"<p>Scaling up language models has led to unprecedented performance gains, but\nlittle is understood about how the training dynamics change as models get\nlarger. How do language models of different sizes learn during pre-training?\nWhy do larger language models demonstrate more desirable behaviors? In this\npaper, we analyze the intermediate training checkpoints of differently sized\nOPT models (Zhang et al.,2022)--from 125M to 175B parameters--on next-token\nprediction, sequence-level generation, and downstream tasks. We find that 1) at\na given perplexity and independent of model sizes, a similar subset of training\ntokens see the most significant reduction in loss, with the rest stagnating or\nshowing double-descent behavior; 2) early in training, all models learn to\nreduce the perplexity of grammatical sequences that contain hallucinations,\nwith small models halting at this suboptimal distribution and larger ones\neventually learning to assign these sequences lower probabilities; 3)\nperplexity is a strong predictor of in-context learning performance on 74\nmultiple-choice tasks from BIG-Bench, and this holds independent of the model\nsize. Together, these results show that perplexity is more predictive of model\nbehaviors than model size or training computation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Mengzhou Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1\">Mikel Artetxe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chunting Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xi Victoria Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasunuru_R/0/1/0/all/0/1\">Ramakanth Pasunuru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanov_V/0/1/0/all/0/1\">Ves Stoyanov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WeCheck: Strong Factual Consistency Checker via Weakly Supervised Learning. (arXiv:2212.10057v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10057","description":"<p>A crucial issue of current text generation models is that they often\nuncontrollably generate factually inconsistent text with respective of their\ninputs. Limited by the lack of annotated data, existing works in evaluating\nfactual consistency directly transfer the reasoning ability of models trained\non other data-rich upstream tasks like question answering (QA) and natural\nlanguage inference (NLI) without any further adaptation. As a result, they\nperform poorly on the real generated text and are biased heavily by their\nsingle-source upstream tasks. To alleviate this problem, we propose a weakly\nsupervised framework that aggregates multiple resources to train a precise and\nefficient factual metric, namely WeCheck. WeCheck first utilizes a generative\nmodel to accurately label a real generated sample by aggregating its weak\nlabels, which are inferred from multiple resources. Then, we train the target\nmetric model with the weak supervision while taking noises into consideration.\nComprehensive experiments on a variety of tasks demonstrate the strong\nperformance of WeCheck, which achieves a 3.4\\% absolute improvement over\nprevious state-of-the-art methods on TRUE benchmark on average.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xinyan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiachen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sujian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_Y/0/1/0/all/0/1\">Yajuan Lv</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DOC: Improving Long Story Coherence With Detailed Outline Control. (arXiv:2212.10077v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10077","description":"<p>We propose the Detailed Outline Control (DOC) framework for improving\nlong-range plot coherence when automatically generating\nseveral-thousand-word-long stories. DOC consists of two complementary\ncomponents: a detailed outliner and a detailed controller. The detailed\noutliner creates a more detailed, hierarchically structured outline, shifting\ncreative burden from the main drafting procedure to the planning stage. The\ndetailed controller ensures the more detailed outline is still respected during\ngeneration by controlling story passages to align with outline details. In\nhuman evaluations of automatically generated stories, DOC substantially\noutperforms a strong Re3 baseline (Yang et al., 2022) on plot coherence (22.5%\nabsolute gain), outline relevance (28.2%), and interestingness (20.7%). Humans\nalso judged DOC to be much more controllable in an interactive generation\nsetting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kevin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuandong Tian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Naamapadam: A Large-Scale Named Entity Annotated Data for Indic Languages. (arXiv:2212.10168v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10168","description":"<p>We present, Naamapadam, the largest publicly available Named Entity\nRecognition (NER) dataset for the 11 major Indian languages from two language\nfamilies. The dataset contains more than 400k sentences annotated with a total\nof at least 100k entities from three standard entity categories (Person,\nLocation, and, Organization) for 9 out of the 11 languages. The training\ndataset has been automatically created from the Samanantar parallel corpus by\nprojecting automatically tagged entities from an English sentence to the\ncorresponding Indian language translation. We also create manually annotated\ntestsets for 9 languages. We demonstrate the utility of the obtained dataset on\nthe Naamapadam-test dataset. We also release IndicNER, a multilingual IndicBERT\nmodel fine-tuned on Naamapadam training set. IndicNER achieves an F1 score of\nmore than $80$ for $7$ out of $9$ test languages. The dataset and models are\navailable under open-source licences at\nhttps://ai4bharat.iitm.ac.in/naamapadam.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mhaske_A/0/1/0/all/0/1\">Arnav Mhaske</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kedia_H/0/1/0/all/0/1\">Harshit Kedia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doddapaneni_S/0/1/0/all/0/1\">Sumanth Doddapaneni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khapra_M/0/1/0/all/0/1\">Mitesh M. Khapra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1\">Pratyush Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+V_R/0/1/0/all/0/1\">Rudra Murthy V</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunchukuttan_A/0/1/0/all/0/1\">Anoop Kunchukuttan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories. (arXiv:2212.10511v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10511","description":"<p>Despite their impressive performance on diverse tasks, large language models\n(LMs) still struggle with tasks requiring rich world knowledge, implying the\nlimitations of relying solely on their parameters to encode a wealth of world\nknowledge. This paper aims to understand LMs' strengths and limitations in\nmemorizing factual knowledge, by conducting large-scale knowledge probing\nexperiments of 10 models and 4 augmentation methods on PopQA, our new\nopen-domain QA dataset with 14k questions. We find that LMs struggle with less\npopular factual knowledge, and that scaling fails to appreciably improve\nmemorization of factual knowledge in the long tail. We then show that\nretrieval-augmented LMs largely outperform orders of magnitude larger LMs,\nwhile unassisted LMs remain competitive in questions about high-popularity\nentities. Based on those findings, we devise a simple, yet effective, method\nfor powerful and efficient retrieval-augmented LMs, which retrieves\nnon-parametric memories only when necessary. Experimental results show that\nthis significantly improves models' performance while reducing the inference\ncosts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mallen_A/0/1/0/all/0/1\">Alex Mallen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asai_A/0/1/0/all/0/1\">Akari Asai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_V/0/1/0/all/0/1\">Victor Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1\">Rajarshi Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detoxifying Text with MaRCo: Controllable Revision with Experts and Anti-Experts. (arXiv:2212.10543v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10543","description":"<p>Text detoxification has the potential to mitigate the harms of toxicity by\nrephrasing text to remove offensive meaning, but subtle toxicity remains\nchallenging to tackle. We introduce MaRCo, a detoxification algorithm that\ncombines controllable generation and text rewriting methods using a Product of\nExperts with autoencoder language models (LMs). MaRCo uses likelihoods under a\nnon-toxic LM (expert) and a toxic LM (anti-expert) to find candidate words to\nmask and potentially replace. We evaluate our method on several subtle toxicity\nand microaggressions datasets, and show that it not only outperforms baselines\non automatic metrics, but MaRCo's rewrites are preferred 2.1 $\\times$ more in\nhuman evaluation. Its applicability to instances of subtle toxicity is\nespecially promising, demonstrating a path forward for addressing increasingly\nelusive online hate.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hallinan_S/0/1/0/all/0/1\">Skyler Hallinan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Alisa Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1\">Maarten Sap</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lego-MT: Towards Detachable Models in Massively Multilingual Machine Translation. (arXiv:2212.10551v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10551","description":"<p>Multilingual neural machine translation (MNMT) aims to build a unified model\nfor many language directions. Existing monolithic models for MNMT encounter two\nchallenges: parameter interference among languages and inefficient inference\nfor large models. In this paper, we revisit the classic multi-way structures\nand develop a detachable model by assigning each language (or group of\nlanguages) to an individual branch that supports plug-and-play training and\ninference. To address the needs of learning representations for all languages\nin a unified space, we propose a novel efficient training recipe, upon which we\nbuild an effective detachable model, Lego-MT. For a fair comparison, we collect\ndata from OPUS and build a translation benchmark covering 433 languages and\n1.3B parallel data. Experiments show that Lego-MT with 1.2B parameters brings\nan average gain of 3.2 spBLEU. It even outperforms M2M-100 with 12B parameters.\nThe proposed training recipe brings a 28.2$\\times$ speedup over the\nconventional multi-way training method.\\footnote{\n\\url{https://github.com/CONE-MT/Lego-MT}.}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_F/0/1/0/all/0/1\">Fei Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yinquan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">WenHao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingpeng Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jingjing Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Parsel: Algorithmic Reasoning with Language Models by Composing Decompositions. (arXiv:2212.10561v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10561","description":"<p>Despite recent success in large language model (LLM) reasoning, LLMs struggle\nwith hierarchical multi-step reasoning tasks like generating complex programs.\nFor these tasks, humans often start with a high-level algorithmic design and\nimplement each part gradually. We introduce Parsel, a framework enabling\nautomatic implementation and validation of complex algorithms with code LLMs.\nWith Parsel, we automatically decompose algorithmic tasks into hierarchical\nnatural language function descriptions and then search over combinations of\npossible function implementations using tests. We show that Parsel can be used\nacross domains requiring hierarchical reasoning, including program synthesis\nand robotic planning. We find that, using Parsel, LLMs solve more\ncompetition-level problems in the APPS dataset, resulting in pass rates over\n75\\% higher than prior results from directly sampling AlphaCode and Codex,\nwhile often using a smaller sample budget. Moreover, with automatically\ngenerated tests, we find that Parsel can improve the state-of-the-art pass@1\nperformance on HumanEval from 67\\% to 85\\%. We also find that LLM-generated\nrobotic plans using Parsel are more than twice as likely to be considered\naccurate than directly generated plans. Lastly, we explore how Parsel addresses\nLLM limitations and discuss how Parsel may be useful for human programmers. We\nrelease our code at https://github.com/ezelikman/parsel\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zelikman_E/0/1/0/all/0/1\">Eric Zelikman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qian Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poesia_G/0/1/0/all/0/1\">Gabriel Poesia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah D. Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haber_N/0/1/0/all/0/1\">Nick Haber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SERENGETI: Massively Multilingual Language Models for Africa. (arXiv:2212.10785v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10785","description":"<p>Multilingual pretrained language models (mPLMs) acquire valuable,\ngeneralizable linguistic information during pretraining and have advanced the\nstate of the art on task-specific finetuning. To date, only ~31 out of ~2,000\nAfrican languages are covered in existing language models. We ameliorate this\nlimitation by developing SERENGETI, a massively multilingual language model\nthat covers 517 African languages and language varieties. We evaluate our novel\nmodels on eight natural language understanding tasks across 20 datasets,\ncomparing to 4 mPLMs that cover 4-23 African languages. SERENGETI outperforms\nother models on 11 datasets across the eights tasks, achieving 82.27 average\nF_1. We also perform analyses of errors from our models, which allows us to\ninvestigate the influence of language genealogy and linguistic similarity when\nthe models are applied under zero-shot settings. We will publicly release our\nmodels for\nresearch.\\footnote{\\href{https://github.com/UBC-NLP/serengeti}{https://github.com/UBC-NLP/serengeti}}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Adebara_I/0/1/0/all/0/1\">Ife Adebara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmadany_A/0/1/0/all/0/1\">AbdelRahim Elmadany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1\">Muhammad Abdul-Mageed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inciarte_A/0/1/0/all/0/1\">Alcides Alcoba Inciarte</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Resolving Indirect Referring Expressions for Entity Selection. (arXiv:2212.10933v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10933","description":"<p>Recent advances in language modeling have enabled new conversational systems.\nIn particular, it is often desirable for people to make choices among specified\noptions when using such systems. We address this problem of reference\nresolution, when people use natural expressions to choose between the entities.\nFor example, given the choice `Should we make a Simnel cake or a Pandan cake?'\na natural response from a dialog participant may be indirect: `let's make the\ngreen one'. Such natural expressions have been little studied for reference\nresolution. We argue that robustly understanding such language has large\npotential for improving naturalness in dialog, recommendation, and search\nsystems. We create AltEntities (Alternative Entities), a new public dataset of\n42K entity pairs and expressions (referring to one entity in the pair), and\ndevelop models for the disambiguation problem. Consisting of indirect referring\nexpressions across three domains, our corpus enables for the first time the\nstudy of how language models can be adapted to this task. We find they achieve\n82%-87% accuracy in realistic settings, which while reasonable also invites\nfurther advances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_M/0/1/0/all/0/1\">Mohammad Javad Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radlinski_F/0/1/0/all/0/1\">Filip Radlinski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pareti_S/0/1/0/all/0/1\">Silvia Pareti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Louis_A/0/1/0/all/0/1\">Annie Louis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Black-box language model explanation by context length probing. (arXiv:2212.14815v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.14815","description":"<p>The increasingly widespread adoption of large language models has highlighted\nthe need for improving their explainability. We present context length probing,\na novel explanation technique for causal language models, based on tracking the\npredictions of a model as a function of the length of available context, and\nallowing to assign differential importance scores to different contexts. The\ntechnique is model-agnostic and does not rely on access to model internals\nbeyond computing token-level probabilities. We apply context length probing to\nlarge pre-trained language models and offer some initial analyses and insights,\nincluding the potential for studying long-range dependencies. The source code\nand an interactive demo of the method are available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cifka_O/0/1/0/all/0/1\">Ond&#x159;ej C&#xed;fka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liutkus_A/0/1/0/all/0/1\">Antoine Liutkus</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Define, Evaluate, and Improve Task-Oriented Cognitive Capabilities for Instruction Generation Models. (arXiv:2301.05149v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.05149","description":"<p>Recent work studies the cognitive capabilities of language models through\npsychological tests designed for humans. While these studies are helpful for\nunderstanding the general capabilities of these models, there is no guarantee\nthat a model possessing sufficient capabilities to pass those tests would\nactually use those capabilities in performing real-life tasks. In this work, we\nformulate task-oriented cognitive capabilities, which are human-like cognitive\ncapabilities that language models leverage to perform tasks. These capabilities\nare (i) the ability to quickly generate good candidate utterances (the search\ncapability) (ii) the ability to predict how a listener interprets those\nutterances and choose the most appropriate one (the pragmatic capability). We\ndesign an evaluation scheme for comparing these capabilities of a language\nmodel with those of a human. Applying this scheme to examine various models in\na navigation instruction generation problem, we find that their pragmatic\ncapability is severely lacking. This insight leads us to augment them with\nbetter models of the listener and obtain a significant boost of 11% in success\nrate in guiding real humans. Our work advocates for having a principled\nprocedure for aligning language models with humans that involves (i)\nformulating task-oriented capabilities, (ii) devising a method to quantify\ntheir deficiency, and (iii) iteratively improving them.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Lingjun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Khanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daume_H/0/1/0/all/0/1\">Hal Daum&#xe9; III</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Theme-driven Keyphrase Extraction to Analyze Social Media Discourse. (arXiv:2301.11508v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.11508","description":"<p>Social media platforms are vital resources for sharing self-reported health\nexperiences, offering rich data on various health topics. Despite advancements\nin Natural Language Processing (NLP) enabling large-scale social media data\nanalysis, a gap remains in applying keyphrase extraction to health-related\ncontent. Keyphrase extraction is used to identify salient concepts in social\nmedia discourse without being constrained by predefined entity classes. This\npaper introduces a theme-driven keyphrase extraction framework tailored for\nsocial media, a pioneering approach designed to capture clinically relevant\nkeyphrases from user-generated health texts. Themes are defined as broad\ncategories determined by the objectives of the extraction task. We formulate\nthis novel task of theme-driven keyphrase extraction and demonstrate its\npotential for efficiently mining social media text for the use case of\ntreatment for opioid use disorder. This paper leverages qualitative and\nquantitative analysis to demonstrate the feasibility of extracting actionable\ninsights from social media data and efficiently extracting keyphrases using\nminimally supervised NLP models. Our contributions include the development of a\nnovel data collection and curation framework for theme-driven keyphrase\nextraction and the creation of MOUD-Keyphrase, the first dataset of its kind\ncomprising human-annotated keyphrases from a Reddit community. We also identify\nthe scope of minimally supervised NLP models to extract keyphrases from social\nmedia data efficiently. Lastly, we found that a large language model (ChatGPT)\noutperforms unsupervised keyphrase extraction models, and we evaluate its\nefficacy in this task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Romano_W/0/1/0/all/0/1\">William Romano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharif_O/0/1/0/all/0/1\">Omar Sharif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basak_M/0/1/0/all/0/1\">Madhusudan Basak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gatto_J/0/1/0/all/0/1\">Joseph Gatto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preum_S/0/1/0/all/0/1\">Sarah Preum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Speak from Text: Zero-Shot Multilingual Text-to-Speech with Unsupervised Text Pretraining. (arXiv:2301.12596v3 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2301.12596","description":"<p>While neural text-to-speech (TTS) has achieved human-like natural synthetic\nspeech, multilingual TTS systems are limited to resource-rich languages due to\nthe need for paired text and studio-quality audio data. This paper proposes a\nmethod for zero-shot multilingual TTS using text-only data for the target\nlanguage. The use of text-only data allows the development of TTS systems for\nlow-resource languages for which only textual resources are available, making\nTTS accessible to thousands of languages. Inspired by the strong cross-lingual\ntransferability of multilingual language models, our framework first performs\nmasked language model pretraining with multilingual text-only data. Then we\ntrain this model with a paired data in a supervised manner, while freezing a\nlanguage-aware embedding layer. This allows inference even for languages not\nincluded in the paired data but present in the text-only data. Evaluation\nresults demonstrate highly intelligible zero-shot TTS with a character error\nrate of less than 12% for an unseen language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Saeki_T/0/1/0/all/0/1\">Takaaki Saeki</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Maiti_S/0/1/0/all/0/1\">Soumi Maiti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1\">Xinjian Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Takamichi_S/0/1/0/all/0/1\">Shinnosuke Takamichi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Saruwatari_H/0/1/0/all/0/1\">Hiroshi Saruwatari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Red teaming ChatGPT via Jailbreaking: Bias, Robustness, Reliability and Toxicity. (arXiv:2301.12867v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.12867","description":"<p>Recent breakthroughs in natural language processing (NLP) have permitted the\nsynthesis and comprehension of coherent text in an open-ended way, therefore\ntranslating the theoretical algorithms into practical applications. The large\nlanguage models (LLMs) have significantly impacted businesses such as report\nsummarization software and copywriters. Observations indicate, however, that\nLLMs may exhibit social prejudice and toxicity, posing ethical and societal\ndangers of consequences resulting from irresponsibility. Large-scale benchmarks\nfor accountable LLMs should consequently be developed. Although several\nempirical investigations reveal the existence of a few ethical difficulties in\nadvanced LLMs, there is little systematic examination and user study of the\nrisks and harmful behaviors of current LLM usage. To further educate future\nefforts on constructing ethical LLMs responsibly, we perform a qualitative\nresearch method called ``red teaming'' on OpenAI's ChatGPT\\footnote{In this\npaper, ChatGPT refers to the version released on Dec 15th.} to better\nunderstand the practical features of ethical dangers in recent LLMs. We analyze\nChatGPT comprehensively from four perspectives: 1) \\textit{Bias} 2)\n\\textit{Reliability} 3) \\textit{Robustness} 4) \\textit{Toxicity}. In accordance\nwith our stated viewpoints, we empirically benchmark ChatGPT on multiple sample\ndatasets. We find that a significant number of ethical risks cannot be\naddressed by existing benchmarks, and hence illustrate them via additional case\nstudies. In addition, we examine the implications of our findings on AI ethics\nand harmal behaviors of ChatGPT, as well as future problems and practical\ndesign considerations for responsible LLMs. We believe that our findings may\ngive light on future efforts to determine and mitigate the ethical hazards\nposed by machines in LLM applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_T/0/1/0/all/0/1\">Terry Yue Zhuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yujin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chunyang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1\">Zhenchang Xing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Transfer from Pre-trained Language Models to Cif-based Speech Recognizers via Hierarchical Distillation. (arXiv:2301.13003v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.13003","description":"<p>Large-scale pre-trained language models (PLMs) have shown great potential in\nnatural language processing tasks. Leveraging the capabilities of PLMs to\nenhance automatic speech recognition (ASR) systems has also emerged as a\npromising research direction. However, previous works may be limited by the\ninflexible structures of PLMs and the insufficient utilization of PLMs. To\nalleviate these problems, we propose the hierarchical knowledge distillation\n(HKD) on the continuous integrate-and-fire (CIF) based ASR models. To transfer\nknowledge from PLMs to the ASR models, HKD employs cross-modal knowledge\ndistillation with contrastive loss at the acoustic level and knowledge\ndistillation with regression loss at the linguistic level. Compared with the\noriginal CIF-based model, our method achieves 15% and 9% relative error rate\nreduction on the AISHELL-1 and LibriSpeech datasets, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_M/0/1/0/all/0/1\">Minglun Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feilong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jing Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Bo Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Inductive Link Prediction for Both New Nodes and New Relation Types via Double Equivariance. (arXiv:2302.01313v5 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.01313","description":"<p>Despite recent advances in relational learning, the task of inductive link\nprediction in discrete attributed multigraphs with both new nodes and new\nrelation types in test remains an open problem. In this work we tackle this\ntask by defining the concept of double exchangeability and its associated\ndouble-permutation equivariant graph neural network that are equivariant to\npermutations of both node identities and edge relations. Our neural\narchitecture imposes a structural representation of relations that can\ninductively generalize from training nodes and relations to arbitrarily new\ntest nodes and relations, without the need for adaptation or retraining, thus\nenabling a new direction in relational learning. Finally, we introduce a\ngeneral blueprint for such double equivariant representations and empirically\nshowcase its capability on two proposed real-world benchmarks that no existing\nworks can perform accurately.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfei Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yangze Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jincheng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1\">Bruno Ribeiro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SanskritShala: A Neural Sanskrit NLP Toolkit with Web-Based Interface for Pedagogical and Annotation Purposes. (arXiv:2302.09527v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.09527","description":"<p>We present a neural Sanskrit Natural Language Processing (NLP) toolkit named\nSanskritShala (a school of Sanskrit) to facilitate computational linguistic\nanalyses for several tasks such as word segmentation, morphological tagging,\ndependency parsing, and compound type identification. Our systems currently\nreport state-of-the-art performance on available benchmark datasets for all\ntasks. SanskritShala is deployed as a web-based application, which allows a\nuser to get real-time analysis for the given input. It is built with\neasy-to-use interactive data annotation features that allow annotators to\ncorrect the system predictions when it makes mistakes. We publicly release the\nsource codes of the 4 modules included in the toolkit, 7 word embedding models\nthat have been trained on publicly available Sanskrit corpora and multiple\nannotated datasets such as word similarity, relatedness, categorization,\nanalogy prediction to assess intrinsic properties of word embeddings. So far as\nwe know, this is the first neural-based Sanskrit NLP toolkit that has a\nweb-based interface and a number of NLP modules. We are sure that the people\nwho are willing to work with Sanskrit will find it useful for pedagogical and\nannotative purposes. SanskritShala is available at:\nhttps://cnerg.iitkgp.ac.in/sanskritshala. The demo video of our platform can be\naccessed at: https://youtu.be/x0X31Y9k0mw4.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sandhan_J/0/1/0/all/0/1\">Jivnesh Sandhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Anshul Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Behera_L/0/1/0/all/0/1\">Laxmidhar Behera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandhan_T/0/1/0/all/0/1\">Tushar Sandhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Inseq: An Interpretability Toolkit for Sequence Generation Models. (arXiv:2302.13942v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.13942","description":"<p>Past work in natural language processing interpretability focused mainly on\npopular classification tasks while largely overlooking generation settings,\npartly due to a lack of dedicated tools. In this work, we introduce Inseq, a\nPython library to democratize access to interpretability analyses of sequence\ngeneration models. Inseq enables intuitive and optimized extraction of models'\ninternal information and feature importance scores for popular decoder-only and\nencoder-decoder Transformers architectures. We showcase its potential by\nadopting it to highlight gender biases in machine translation models and locate\nfactual knowledge inside GPT-2. Thanks to its extensible interface supporting\ncutting-edge techniques such as contrastive feature attribution, Inseq can\ndrive future advances in explainable natural language generation, centralizing\ngood practices and enabling fair and reproducible model evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sarti_G/0/1/0/all/0/1\">Gabriele Sarti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feldhus_N/0/1/0/all/0/1\">Nils Feldhus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sickert_L/0/1/0/all/0/1\">Ludwig Sickert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wal_O/0/1/0/all/0/1\">Oskar van der Wal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nissim_M/0/1/0/all/0/1\">Malvina Nissim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bisazza_A/0/1/0/all/0/1\">Arianna Bisazza</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dynamic Prompting: A Unified Framework for Prompt Tuning. (arXiv:2303.02909v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.02909","description":"<p>It has been demonstrated that the art of prompt tuning is highly effective in\nefficiently extracting knowledge from pretrained foundation models,\nencompassing pretrained language models (PLMs), vision pretrained models, and\nvision-language (V-L) models. However, the efficacy of employing fixed soft\nprompts with a predetermined position for concatenation with inputs for all\ninstances, irrespective of their inherent disparities, remains uncertain.\nVariables such as the position, length, and representations of prompts across\ndiverse instances and tasks can substantially influence the performance of\nprompt tuning. In this context, we provide a theoretical analysis, which\nreveals that optimizing the position of the prompt to encompass the input can\ncapture additional semantic information that traditional prefix or postfix\nprompt tuning methods fail to capture. Building upon our analysis, we present a\nunified dynamic prompt (DP) tuning strategy that dynamically determines\ndifferent factors of prompts based on specific tasks and instances. To\naccomplish this, we employ a lightweight learning network with Gumble-Softmax,\nallowing us to learn instance-dependent guidance. Experimental results\nunderscore the significant performance improvement achieved by dynamic prompt\ntuning across a wide range of tasks, including NLP tasks, vision recognition\ntasks, and vision-language tasks. Furthermore, we establish the universal\napplicability of our approach under full-data, few-shot, and multitask\nscenarios. Codes are available at https://github.com/Xianjun-Yang/DPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xianjun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xujiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenchao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petzold_L/0/1/0/all/0/1\">Linda Petzold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haifeng Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CB2: Collaborative Natural Language Interaction Research Platform. (arXiv:2303.08127v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2303.08127","description":"<p>CB2 is a multi-agent platform to study collaborative natural language\ninteraction in a grounded task-oriented scenario. It includes a 3D game\nenvironment, a backend server designed to serve trained models to human agents,\nand various tools and processes to enable scalable studies. We deploy CB2 at\nhttps://cb2.ai as a system demonstration with a learned instruction following\nmodel.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharf_J/0/1/0/all/0/1\">Jacob Sharf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gul_M/0/1/0/all/0/1\">Mustafa Omer Gul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artzi_Y/0/1/0/all/0/1\">Yoav Artzi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Direct and indirect evidence of compression of word lengths. Zipf's law of abbreviation revisited. (arXiv:2303.10128v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.10128","description":"<p>Zipf's law of abbreviation, the tendency of more frequent words to be\nshorter, is one of the most solid candidates for a linguistic universal, in the\nsense that it has the potential for being exceptionless or with a number of\nexceptions that is vanishingly small compared to the number of languages on\nEarth. Since Zipf's pioneering research, this law has been viewed as a\nmanifestation of a universal principle of communication, i.e. the minimization\nof word lengths, to reduce the effort of communication. Here we revisit the\nconcordance of written language with the law of abbreviation. Crucially, we\nprovide wider evidence that the law holds also in speech (when word length is\nmeasured in time), in particular in 46 languages from 14 linguistic families.\nAgreement with the law of abbreviation provides indirect evidence of\ncompression of languages via the theoretical argument that the law of\nabbreviation is a prediction of optimal coding. Motivated by the need of direct\nevidence of compression, we derive a simple formula for a random baseline\nindicating that word lengths are systematically below chance, across linguistic\nfamilies and writing systems, and independently of the unit of measurement\n(length in characters or duration in time). Our work paves the way to measure\nand compare the degree of optimality of word lengths in languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Petrini_S/0/1/0/all/0/1\">Sonia Petrini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casas_i_Munoz_A/0/1/0/all/0/1\">Antoni Casas-i-Mu&#xf1;oz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cluet_i_Martinell_J/0/1/0/all/0/1\">Jordi Cluet-i-Martinell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengxue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bentz_C/0/1/0/all/0/1\">Chris Bentz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_i_Cancho_R/0/1/0/all/0/1\">Ramon Ferrer-i-Cancho</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT4PCG Competition: Character-like Level Generation for Science Birds. (arXiv:2303.15662v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2303.15662","description":"<p>This paper presents the first ChatGPT4PCG Competition at the 2023 IEEE\nConference on Games. The objective of this competition is for participants to\ncreate effective prompts for ChatGPT--enabling it to generate Science Birds\nlevels with high stability and character-like qualities--fully using their\ncreativity as well as prompt engineering skills. ChatGPT is a conversational\nagent developed by OpenAI. Science Birds is selected as the competition\nplatform because designing an Angry Birds-like level is not a trivial task due\nto the in-game gravity; the quality of the levels is determined by their\nstability. To lower the entry barrier to the competition, we limit the task to\nthe generation of capitalized English alphabetical characters. We also allow\nonly a single prompt to be used for generating all the characters. Here, the\nquality of the generated levels is determined by their stability and similarity\nto the given characters. A sample prompt is provided to participants for their\nreference. An experiment is conducted to determine the effectiveness of several\nmodified versions of this sample prompt on level stability and similarity by\ntesting them on several characters. To the best of our knowledge, we believe\nthat ChatGPT4PCG is the first competition of its kind and hope to inspire\nenthusiasm for prompt engineering in procedural content generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Taveekitworachai_P/0/1/0/all/0/1\">Pittawat Taveekitworachai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdullah_F/0/1/0/all/0/1\">Febri Abdullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dewantoro_M/0/1/0/all/0/1\">Mury F. Dewantoro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thawonmas_R/0/1/0/all/0/1\">Ruck Thawonmas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1\">Julian Togelius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Renz_J/0/1/0/all/0/1\">Jochen Renz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating and Detecting ChatGPT's Responses on Abstractive Summarization. (arXiv:2303.17650v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.17650","description":"<p>Large Language Models (LLMs) have gathered significant attention due to their\nimpressive performance on a variety of tasks. ChatGPT, developed by OpenAI, is\na recent addition to the family of language models and is being called a\ndisruptive technology by a few, owing to its human-like text-generation\ncapabilities. Although, many anecdotal examples across the internet have\nevaluated ChatGPT's strength and weakness, only a few systematic research\nstudies exist. To contribute to the body of literature of systematic research\non ChatGPT, we evaluate the performance of ChatGPT on Abstractive Summarization\nby the means of automated metrics and blinded human reviewers. We also build\nautomatic text classifiers to detect ChatGPT generated summaries. We found that\nwhile text classification algorithms can distinguish between real and generated\nsummaries, humans are unable to distinguish between real summaries and those\nproduced by ChatGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Soni_M/0/1/0/all/0/1\">Mayank Soni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wade_V/0/1/0/all/0/1\">Vincent Wade</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Program with Natural Language. (arXiv:2304.10464v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.10464","description":"<p>Large Language Models (LLMs) have shown remarkable performance in various\nbasic natural language tasks, which raises hope for achieving Artificial\nGeneral Intelligence. For completing the complex task, we still need a program\nfor the task first and then ask LLMs to follow the program to generate the\nspecific solution. We propose using natural language as a new programming\nlanguage to describe task procedures, making them easily understandable to both\nhumans and LLMs. ~The LLM is capable of directly generating natural language\nprograms, but these programs may still contain factual errors or incomplete\nsteps. Therefore, we further propose the Learning to Program (\\text{LP}) method\nto ask LLMs themselves to learn the natural language program based on the\ntraining dataset of the complex task first and then use the learned program to\nguide the inference. Our experiments on the reasoning tasks of five different\nreasoning types (8 datasets) demonstrate the effectiveness of our approach.\nFurther, our analysis experiment shows that the learned program can be directly\nused to guide another LLM to improve its performance, which reveals a new\ntransfer learning paradigm.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yiduo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yaobo Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chenfei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenshan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongyan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Which Factors Predict the Chat Experience of a Natural Language Generation Dialogue Service?. (arXiv:2304.10785v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.10785","description":"<p>In this paper, we proposed a conceptual model to predict the chat experience\nin a natural language generation dialog system. We evaluated the model with 120\nparticipants with Partial Least Squares Structural Equation Modeling (PLS-SEM)\nand obtained an R-square (R2) with 0.541. The model considers various factors,\nincluding the prompts used for generation; coherence, sentiment, and similarity\nin the conversation; and users' perceived dialog agents' favorability. We then\nfurther explore the effectiveness of the subset of our proposed model. The\nresults showed that users' favorability and coherence, sentiment, and\nsimilarity in the dialogue are positive predictors of users' chat experience.\nMoreover, we found users may prefer dialog agents with characteristics of\nExtroversion, Openness, Conscientiousness, Agreeableness, and Non-Neuroticism.\nThrough our research, an adaptive dialog system might use collected data to\ninfer factors in our model, predict the chat experience for users through these\nfactors, and optimize it by adjusting prompts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Eason Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fundamental Limitations of Alignment in Large Language Models. (arXiv:2304.11082v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.11082","description":"<p>An important aspect in developing language models that interact with humans\nis aligning their behavior to be useful and unharmful for their human users.\nThis is usually achieved by tuning the model in a way that enhances desired\nbehaviors and inhibits undesired ones, a process referred to as alignment. In\nthis paper, we propose a theoretical approach called Behavior Expectation\nBounds (BEB) which allows us to formally investigate several inherent\ncharacteristics and limitations of alignment in large language models.\nImportantly, we prove that for any behavior that has a finite probability of\nbeing exhibited by the model, there exist prompts that can trigger the model\ninto outputting this behavior, with probability that increases with the length\nof the prompt. This implies that any alignment process that attenuates\nundesired behavior but does not remove it altogether, is not safe against\nadversarial prompting attacks. Furthermore, our framework hints at the\nmechanism by which leading alignment approaches such as reinforcement learning\nfrom human feedback increase the LLM's proneness to being prompted into the\nundesired behaviors. Moreover, we include the notion of personas in our BEB\nframework, and find that behaviors which are generally very unlikely to be\nexhibited by the model can be brought to the front by prompting the model to\nbehave as specific persona. This theoretical result is being experimentally\ndemonstrated in large scale by the so called contemporary \"chatGPT jailbreaks\",\nwhere adversarial users trick the LLM into breaking its alignment guardrails by\ntriggering it into acting as a malicious persona. Our results expose\nfundamental limitations in alignment of LLMs and bring to the forefront the\nneed to devise reliable mechanisms for ensuring AI safety.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wolf_Y/0/1/0/all/0/1\">Yotam Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wies_N/0/1/0/all/0/1\">Noam Wies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avnery_O/0/1/0/all/0/1\">Oshri Avnery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_Y/0/1/0/all/0/1\">Yoav Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shashua_A/0/1/0/all/0/1\">Amnon Shashua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model. (arXiv:2304.13731v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2304.13731","description":"<p>The immense scale of the recent large language models (LLM) allows many\ninteresting properties, such as, instruction- and chain-of-thought-based\nfine-tuning, that has significantly improved zero- and few-shot performance in\nmany natural language processing (NLP) tasks. Inspired by such successes, we\nadopt such an instruction-tuned LLM Flan-T5 as the text encoder for\ntext-to-audio (TTA) generation -- a task where the goal is to generate an audio\nfrom its textual description. The prior works on TTA either pre-trained a joint\ntext-audio encoder or used a non-instruction-tuned model, such as, T5.\nConsequently, our latent diffusion model (LDM)-based approach TANGO outperforms\nthe state-of-the-art AudioLDM on most metrics and stays comparable on the rest\non AudioCaps test set, despite training the LDM on a 63 times smaller dataset\nand keeping the text encoder frozen. This improvement might also be attributed\nto the adoption of audio pressure level-based sound mixing for training set\naugmentation, whereas the prior methods take a random mix.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Ghosal_D/0/1/0/all/0/1\">Deepanway Ghosal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Majumder_N/0/1/0/all/0/1\">Navonil Majumder</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mehrish_A/0/1/0/all/0/1\">Ambuj Mehrish</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Poria_S/0/1/0/all/0/1\">Soujanya Poria</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information. (arXiv:2305.01788v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.01788","description":"<p>Visual Word Sense Disambiguation (VWSD) is a task to find the image that most\naccurately depicts the correct sense of the target word for the given context.\nPreviously, image-text matching models often suffered from recognizing\npolysemous words. This paper introduces an unsupervised VWSD approach that uses\ngloss information of an external lexical knowledge-base, especially the sense\ndefinitions. Specifically, we suggest employing Bayesian inference to\nincorporate the sense definitions when sense information of the answer is not\nprovided. In addition, to ameliorate the out-of-dictionary (OOD) issue, we\npropose a context-aware definition generation with GPT-3. Experimental results\nshow that the VWSD performance significantly increased with our Bayesian\ninference-based approach. In addition, our context-aware definition generation\nachieved prominent performance improvement in OOD examples exhibiting better\nperformance than the existing definition generation method. We will publish\nsource codes as soon as possible.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1\">Sunjae Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garodia_R/0/1/0/all/0/1\">Rishabh Garodia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Minhwa Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhichao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Vcc: Scaling Transformers to 128K Tokens or More by Prioritizing Important Tokens. (arXiv:2305.04241v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.04241","description":"<p>Transformers are central in modern natural language processing and computer\nvision applications. Despite recent works devoted to reducing the quadratic\ncost of such models (as a function of the sequence length), dealing with ultra\nlong sequences (e.g., with more than 16K tokens) remains challenging.\nApplications such as answering questions based on a book or summarizing a\nscientific article are inefficient or infeasible. Here, we propose to\nsignificantly improve the efficiency of Transformers for ultra long sequences,\nby compressing the sequence into a much smaller representation at each layer.\nSpecifically, by exploiting the fact that in many tasks, only a small subset of\nspecial tokens (we call VIP-tokens) are most relevant to the final prediction,\nwe propose a VIP-token centric compression (VCC) scheme which selectively\ncompresses the sequence based on their impact on approximating the\nrepresentation of the VIP-tokens. Compared with competitive baselines, our\nalgorithm is not only efficient (achieving more than $3\\times$ efficiency gain\ncompared to baselines on 4K and 16K lengths), but also offers\ncompetitive/better performance on a large number of tasks. Further, we show\nthat our algorithm scales to 128K tokens (or more) while consistently offering\naccuracy improvement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1\">Zhanpeng Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hawkins_C/0/1/0/all/0/1\">Cole Hawkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1\">Mingyi Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Aston Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pappas_N/0/1/0/all/0/1\">Nikolaos Pappas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_V/0/1/0/all/0/1\">Vikas Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shuai Zheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FACTIFY-5WQA: 5W Aspect-based Fact Verification through Question Answering. (arXiv:2305.04329v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.04329","description":"<p>Automatic fact verification has received significant attention recently.\nContemporary automatic fact-checking systems focus on estimating truthfulness\nusing numerical scores which are not human-interpretable. A human fact-checker\ngenerally follows several logical steps to verify a verisimilitude claim and\nconclude whether its truthful or a mere masquerade. Popular fact-checking\nwebsites follow a common structure for fact categorization such as half true,\nhalf false, false, pants on fire, etc. Therefore, it is necessary to have an\naspect-based (delineating which part(s) are true and which are false)\nexplainable system that can assist human fact-checkers in asking relevant\nquestions related to a fact, which can then be validated separately to reach a\nfinal verdict. In this paper, we propose a 5W framework (who, what, when,\nwhere, and why) for question-answer-based fact explainability. To that end, we\npresent a semi-automatically generated dataset called FACTIFY-5WQA, which\nconsists of 391, 041 facts along with relevant 5W QAs - underscoring our major\ncontribution to this paper. A semantic role labeling system has been utilized\nto locate 5Ws, which generates QA pairs for claims using a masked language\nmodel. Finally, we report a baseline QA system to automatically locate those\nanswers from evidence documents, which can serve as a baseline for future\nresearch in the field. Lastly, we propose a robust fact verification system\nthat takes paraphrased claims and automatically validates them. The dataset and\nthe baseline model are available at https: //github.com/ankuranii/acl-5W-QA\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rani_A/0/1/0/all/0/1\">Anku Rani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tonmoy_S/0/1/0/all/0/1\">S.M Towhidul Islam Tonmoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalal_D/0/1/0/all/0/1\">Dwip Dalal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gautam_S/0/1/0/all/0/1\">Shreya Gautam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_M/0/1/0/all/0/1\">Megha Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1\">Amit Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amitava Das</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Decker: Double Check with Heterogeneous Knowledge for Commonsense Fact Verification. (arXiv:2305.05921v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.05921","description":"<p>Commonsense fact verification, as a challenging branch of commonsense\nquestion-answering (QA), aims to verify through facts whether a given\ncommonsense claim is correct or not. Answering commonsense questions\nnecessitates a combination of knowledge from various levels. However, existing\nstudies primarily rest on grasping either unstructured evidence or potential\nreasoning paths from structured knowledge bases, yet failing to exploit the\nbenefits of heterogeneous knowledge simultaneously. In light of this, we\npropose Decker, a commonsense fact verification model that is capable of\nbridging heterogeneous knowledge by uncovering latent relationships between\nstructured and unstructured knowledge. Experimental results on two commonsense\nfact verification benchmark datasets, CSQA2.0 and CREAK demonstrate the\neffectiveness of our Decker and further analysis verifies its capability to\nseize more precious information through reasoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zou_A/0/1/0/all/0/1\">Anni Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-shot Faithful Factual Error Correction. (arXiv:2305.07982v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07982","description":"<p>Faithfully correcting factual errors is critical for maintaining the\nintegrity of textual knowledge bases and preventing hallucinations in\nsequence-to-sequence models. Drawing on humans' ability to identify and correct\nfactual errors, we present a zero-shot framework that formulates questions\nabout input claims, looks for correct answers in the given evidence, and\nassesses the faithfulness of each correction based on its consistency with the\nevidence. Our zero-shot framework outperforms fully-supervised approaches, as\ndemonstrated by experiments on the FEVER and SciFact datasets, where our\noutputs are shown to be more faithful. More importantly, the decomposability\nnature of our framework inherently provides interpretability. Additionally, to\nreveal the most suitable metrics for evaluating factual error corrections, we\nanalyze the correlation between commonly used metrics with human judgments in\nterms of three different dimensions regarding intelligibility and faithfulness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kung-Hsiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_H/0/1/0/all/0/1\">Hou Pong Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models. (arXiv:2305.08283v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.08283","description":"<p>Language models (LMs) are pretrained on diverse data sources, including news,\ndiscussion forums, books, and online encyclopedias. A significant portion of\nthis data includes opinions and perspectives which, on one hand, celebrate\ndemocracy and diversity of ideas, and on the other hand are inherently socially\nbiased. Our work develops new methods to (1) measure political biases in LMs\ntrained on such corpora, along social and economic axes, and (2) measure the\nfairness of downstream NLP models trained on top of politically biased LMs. We\nfocus on hate speech and misinformation detection, aiming to empirically\nquantify the effects of political (social, economic) biases in pretraining data\non the fairness of high-stakes social-oriented tasks. Our findings reveal that\npretrained LMs do have political leanings that reinforce the polarization\npresent in pretraining corpora, propagating social biases into hate speech\npredictions and misinformation detectors. We discuss the implications of our\nfindings for NLP research and propose future directions to mitigate unfairness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shangbin Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">Chan Young Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuhan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Crosslingual Investigation of Conceptualization in 1335 Languages. (arXiv:2305.08475v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.08475","description":"<p>Languages differ in how they divide up the world into concepts and words;\ne.g., in contrast to English, Swahili has a single concept for `belly' and\n`womb'. We investigate these differences in conceptualization across 1,335\nlanguages by aligning concepts in a parallel corpus. To this end, we propose\nConceptualizer, a method that creates a bipartite directed alignment graph\nbetween source language concepts and sets of target language strings. In a\ndetailed linguistic analysis across all languages for one concept (`bird') and\nan evaluation on gold standard data for 32 Swadesh concepts, we show that\nConceptualizer has good alignment accuracy. We demonstrate the potential of\nresearch on conceptualization in NLP with two experiments. (1) We define\ncrosslingual stability of a concept as the degree to which it has 1-1\ncorrespondences across languages, and show that concreteness predicts\nstability. (2) We represent each language by its conceptualization pattern for\n83 concepts, and define a similarity measure on these representations. The\nresulting measure for the conceptual similarity of two languages is\ncomplementary to standard genealogical, typological, and surface similarity\nmeasures. For four out of six language families, we can assign languages to\ntheir correct family based on conceptual similarity with accuracy between 54%\nand 87%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yihong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Haotian Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weissweiler_L/0/1/0/all/0/1\">Leonie Weissweiler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wicke_P/0/1/0/all/0/1\">Philipp Wicke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_R/0/1/0/all/0/1\">Renhao Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zangenfeind_R/0/1/0/all/0/1\">Robert Zangenfeind</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing. (arXiv:2305.09770v2 [cs.HC] UPDATED)","link":"http://arxiv.org/abs/2305.09770","description":"<p>While various AI explanation (XAI) methods have been proposed to interpret AI\nsystems, whether the state-of-the-art XAI methods are practically useful for\nhumans remains inconsistent findings. To improve the usefulness of XAI methods,\na line of studies identifies the gaps between the diverse and dynamic\nreal-world user needs with the status quo of XAI methods. Although prior\nstudies envision mitigating these gaps by integrating multiple XAI methods into\nthe universal XAI interfaces (e.g., conversational or GUI-based XAI systems),\nthere is a lack of work investigating how these systems should be designed to\nmeet practical user needs. In this study, we present ConvXAI, a conversational\nXAI system that incorporates multiple XAI types, and empowers users to request\na variety of XAI questions via a universal XAI dialogue interface.\nParticularly, we innovatively embed practical user needs (i.e., four principles\ngrounding on the formative study) into ConvXAI design to improve practical\nusefulness. Further, we design the domain-specific language (DSL) to implement\nthe essential conversational XAI modules and release the core conversational\nuniversal XAI API for generalization. The findings from two within-subjects\nstudies with 21 users show that ConvXAI is more useful for humans in perceiving\nthe understanding and writing improvement, and improving the writing process in\nterms of productivity and sentence quality. Finally, this work contributes\ninsight into the design space of useful XAI, reveals humans' XAI usage patterns\nwith empirical evidence in practice, and identifies opportunities for future\nuseful XAI work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Hua Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chieh-Yang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tongshuang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1\">Ting-Hao &#x27;Kenneth&#x27; Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Post Hoc Explanations of Language Models Can Improve Language Models. (arXiv:2305.11426v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11426","description":"<p>Large Language Models (LLMs) have demonstrated remarkable capabilities in\nperforming complex tasks. Moreover, recent research has shown that\nincorporating human-annotated rationales (e.g., Chain-of-Thought prompting)\nduring in-context learning can significantly enhance the performance of these\nmodels, particularly on tasks that require reasoning capabilities. However,\nincorporating such rationales poses challenges in terms of scalability as this\nrequires a high degree of human involvement. In this work, we present a novel\nframework, Amplifying Model Performance by Leveraging In-Context Learning with\nPost Hoc Explanations (AMPLIFY), which addresses the aforementioned challenges\nby automating the process of rationale generation. To this end, we leverage\npost hoc explanation methods which output attribution scores (explanations)\ncapturing the influence of each of the input features on model predictions.\nMore specifically, we construct automated natural language rationales that\nembed insights from post hoc explanations to provide corrective signals to\nLLMs. Extensive experimentation with real-world datasets demonstrates that our\nframework, AMPLIFY, leads to prediction accuracy improvements of about 10-25%\nover a wide range of tasks, including those where prior approaches which rely\non human-annotated rationales such as Chain-of-Thought prompting fall short.\nOur work makes one of the first attempts at highlighting the potential of post\nhoc explanations as valuable tools for enhancing the effectiveness of LLMs.\nFurthermore, we conduct additional empirical analyses and ablation studies to\ndemonstrate the impact of each of the components of AMPLIFY, which, in turn,\nleads to critical insights for refining in-context learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Krishna_S/0/1/0/all/0/1\">Satyapriya Krishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jiaqi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slack_D/0/1/0/all/0/1\">Dylan Slack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghandeharioun_A/0/1/0/all/0/1\">Asma Ghandeharioun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Himabindu Lakkaraju</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contextualized End-to-End Speech Recognition with Contextual Phrase Prediction Network. (arXiv:2305.12493v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2305.12493","description":"<p>Contextual information plays a crucial role in speech recognition\ntechnologies and incorporating it into the end-to-end speech recognition models\nhas drawn immense interest recently. However, previous deep bias methods lacked\nexplicit supervision for bias tasks. In this study, we introduce a contextual\nphrase prediction network for an attention-based deep bias method. This network\npredicts context phrases in utterances using contextual embeddings and\ncalculates bias loss to assist in the training of the contextualized model. Our\nmethod achieved a significant word error rate (WER) reduction across various\nend-to-end speech recognition models. Experiments on the LibriSpeech corpus\nshow that our proposed model obtains a 12.1% relative WER improvement over the\nbaseline model, and the WER of the context phrases decreases relatively by\n40.5%. Moreover, by applying a context phrase filtering strategy, we also\neffectively eliminate the WER degradation when using a larger biasing list.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Huang_K/0/1/0/all/0/1\">Kaixun Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_A/0/1/0/all/0/1\">Ao Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Z/0/1/0/all/0/1\">Zhanheng Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guo_P/0/1/0/all/0/1\">Pengcheng Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mu_B/0/1/0/all/0/1\">Bingshen Mu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_T/0/1/0/all/0/1\">Tianyi Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xie_L/0/1/0/all/0/1\">Lei Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Energy-based Language Models with Different Architectures and Training Methods for Speech Recognition. (arXiv:2305.12676v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12676","description":"<p>Energy-based language models (ELMs) parameterize an unnormalized distribution\nfor natural sentences and are radically different from popular autoregressive\nlanguage models (ALMs). As an important application, ELMs have been\nsuccessfully used as a means for calculating sentence scores in speech\nrecognition, but they all use less-modern CNN or LSTM networks. The recent\nprogress in Transformer networks and large pretrained models such as BERT and\nGPT2 opens new possibility to further advancing ELMs. In this paper, we explore\ndifferent architectures of energy functions and different training methods to\ninvestigate the capabilities of ELMs in rescoring for speech recognition, all\nusing large pretrained models as backbones.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_Z/0/1/0/all/0/1\">Zhaobiao Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_Z/0/1/0/all/0/1\">Zhijian Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wenbo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Q/0/1/0/all/0/1\">Qing Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Optimal Policy for Simultaneous Machine Translation via Binary Search. (arXiv:2305.12774v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12774","description":"<p>Simultaneous machine translation (SiMT) starts to output translation while\nreading the source sentence and needs a precise policy to decide when to output\nthe generated translation. Therefore, the policy determines the number of\nsource tokens read during the translation of each target token. However, it is\ndifficult to learn a precise translation policy to achieve good latency-quality\ntrade-offs, because there is no golden policy corresponding to parallel\nsentences as explicit supervision. In this paper, we present a new method for\nconstructing the optimal policy online via binary search. By employing explicit\nsupervision, our approach enables the SiMT model to learn the optimal policy,\nwhich can guide the model in completing the translation during inference.\nExperiments on four translation tasks show that our method can exceed strong\nbaselines across all latency scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shoutao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaolei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gloss-Free End-to-End Sign Language Translation. (arXiv:2305.12876v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.12876","description":"<p>In this paper, we tackle the problem of sign language translation (SLT)\nwithout gloss annotations. Although intermediate representation like gloss has\nbeen proven effective, gloss annotations are hard to acquire, especially in\nlarge quantities. This limits the domain coverage of translation datasets, thus\nhandicapping real-world applications. To mitigate this problem, we design the\nGloss-Free End-to-end sign language translation framework (GloFE). Our method\nimproves the performance of SLT in the gloss-free setting by exploiting the\nshared underlying semantics of signs and the corresponding spoken translation.\nCommon concepts are extracted from the text and used as a weak form of\nintermediate representation. The global embedding of these concepts is used as\na query for cross-attention to find the corresponding information within the\nlearned visual features. In a contrastive manner, we encourage the similarity\nof query results between samples containing such concepts and decrease those\nthat do not. We obtained state-of-the-art results on large-scale datasets,\nincluding OpenASL and How2Sign. The code and model will be available at\nhttps://github.com/HenryLittle/GloFE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kezhou Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaohan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Linchao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1\">Ke Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text-to-SQL Error Correction with Language Models of Code. (arXiv:2305.13073v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13073","description":"<p>Despite recent progress in text-to-SQL parsing, current semantic parsers are\nstill not accurate enough for practical use. In this paper, we investigate how\nto build automatic text-to-SQL error correction models. Noticing that\ntoken-level edits are out of context and sometimes ambiguous, we propose\nbuilding clause-level edit models instead. Besides, while most language models\nof code are not specifically pre-trained for SQL, they know common data\nstructures and their operations in programming languages such as Python. Thus,\nwe propose a novel representation for SQL queries and their edits that adheres\nmore closely to the pre-training corpora of language models of code. Our error\ncorrection model improves the exact set match accuracy of different parsers by\n2.4-6.5 and obtains up to 4.3 point absolute improvement over two strong\nbaselines. Our code and data are available at\nhttps://github.com/OSU-NLP-Group/Auto-SQL-Correction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Ziru Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shijie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_M/0/1/0/all/0/1\">Michael White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1\">Raymond Mooney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Payani_A/0/1/0/all/0/1\">Ali Payani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasa_J/0/1/0/all/0/1\">Jayanth Srinivasa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Huan Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Response Length Perception and Sequence Scheduling: An LLM-Empowered LLM Inference Pipeline. (arXiv:2305.13144v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13144","description":"<p>Large language models (LLMs) have revolutionized the field of AI,\ndemonstrating unprecedented capacity across various tasks. However, the\ninference process for LLMs comes with significant computational costs. In this\npaper, we propose an efficient LLM inference pipeline that harnesses the power\nof LLMs. Our approach begins by tapping into the potential of LLMs to\naccurately perceive and predict the response length with minimal overhead. By\nleveraging this information, we introduce an efficient sequence scheduling\ntechnique that groups queries with similar response lengths into micro-batches.\nWe evaluate our approach on real-world instruction datasets using the\nLLaMA-based model, and our results demonstrate an impressive 86% improvement in\ninference throughput without compromising effectiveness. Notably, our method is\northogonal to other inference acceleration techniques, making it a valuable\naddition to many existing toolkits (e.g., FlashAttention, Quantization) for LLM\ninference.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zangwei Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiaozhe Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_F/0/1/0/all/0/1\">Fuzhao Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yang Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yang You</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dynamic Context Pruning for Efficient and Interpretable Autoregressive Transformers. (arXiv:2305.15805v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15805","description":"<p>Autoregressive Transformers adopted in Large Language Models (LLMs) are hard\nto scale to long sequences. Despite several works trying to reduce their\ncomputational cost, most of LLMs still adopt attention layers between all pairs\nof tokens in the sequence, thus incurring a quadratic cost. In this study, we\npresent a novel approach that dynamically prunes contextual information while\npreserving the model's expressiveness, resulting in reduced memory and\ncomputational requirements during inference. Our method employs a learnable\nmechanism that determines which uninformative tokens can be dropped from the\ncontext at any point across the generation process. By doing so, our approach\nnot only addresses performance concerns but also enhances interpretability,\nproviding valuable insight into the model's decision-making process. Our\ntechnique can be applied to existing pre-trained models through a\nstraightforward fine-tuning process, and the pruning strength can be specified\nby a sparsity parameter. Notably, our empirical findings demonstrate that we\ncan effectively prune up to 80\\% of the context without significant performance\ndegradation on downstream tasks, offering a valuable tool for mitigating\ninference costs. Our reference implementation achieves up to $2\\times$ increase\nin inference throughput and even greater memory savings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Anagnostidis_S/0/1/0/all/0/1\">Sotiris Anagnostidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavllo_D/0/1/0/all/0/1\">Dario Pavllo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biggio_L/0/1/0/all/0/1\">Luca Biggio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noci_L/0/1/0/all/0/1\">Lorenzo Noci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucchi_A/0/1/0/all/0/1\">Aurelien Lucchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1\">Thomas Hofmann</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MEMEX: Detecting Explanatory Evidence for Memes via Knowledge-Enriched Contextualization. (arXiv:2305.15913v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15913","description":"<p>Memes are a powerful tool for communication over social media. Their affinity\nfor evolving across politics, history, and sociocultural phenomena makes them\nan ideal communication vehicle. To comprehend the subtle message conveyed\nwithin a meme, one must understand the background that facilitates its holistic\nassimilation. Besides digital archiving of memes and their metadata by a few\nwebsites like knowyourmeme.com, currently, there is no efficient way to deduce\na meme's context dynamically. In this work, we propose a novel task, MEMEX -\ngiven a meme and a related document, the aim is to mine the context that\nsuccinctly explains the background of the meme. At first, we develop MCC (Meme\nContext Corpus), a novel dataset for MEMEX. Further, to benchmark MCC, we\npropose MIME (MultImodal Meme Explainer), a multimodal neural framework that\nuses common sense enriched meme representation and a layered approach to\ncapture the cross-modal semantic dependencies between the meme and the context.\nMIME surpasses several unimodal and multimodal systems and yields an absolute\nimprovement of ~ 4% F1-score over the best baseline. Lastly, we conduct\ndetailed analyses of MIME's performance, highlighting the aspects that could\nlead to optimal modeling of cross-modal contextual associations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Shivam Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+S_R/0/1/0/all/0/1\">Ramaneswaran S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_U/0/1/0/all/0/1\">Udit Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_M/0/1/0/all/0/1\">Md. Shad Akhtar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanmoy Chakraborty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Emergence of a phonological bias in ChatGPT. (arXiv:2305.15929v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15929","description":"<p>Current large language models, such as OpenAI's ChatGPT, have captured the\npublic's attention because how remarkable they are in the use of language.\nHere, I demonstrate that ChatGPT displays phonological biases that are a\nhallmark of human language processing. More concretely, just like humans,\nChatGPT has a consonant bias. That is, the chatbot has a tendency to use\nconsonants over vowels to identify words. This is observed across languages\nthat differ in their relative distribution of consonants and vowels such as\nEnglish and Spanish. Despite the differences in how current artificial\nintelligence language models are trained to process linguistic stimuli and how\nhuman infants acquire language, such training seems to be enough for the\nemergence of a phonological bias in ChatGPT\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Toro_J/0/1/0/all/0/1\">Juan Manuel Toro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ASR and Emotional Speech: A Word-Level Investigation of the Mutual Impact of Speech and Emotion Recognition. (arXiv:2305.16065v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2305.16065","description":"<p>In Speech Emotion Recognition (SER), textual data is often used alongside\naudio signals to address their inherent variability. However, the reliance on\nhuman annotated text in most research hinders the development of practical SER\nsystems. To overcome this challenge, we investigate how Automatic Speech\nRecognition (ASR) performs on emotional speech by analyzing the ASR performance\non emotion corpora and examining the distribution of word errors and confidence\nscores in ASR transcripts to gain insight into how emotion affects ASR. We\nutilize four ASR systems, namely Kaldi ASR, wav2vec2, Conformer, and Whisper,\nand three corpora: IEMOCAP, MOSI, and MELD to ensure generalizability.\nAdditionally, we conduct text-based SER on ASR transcripts with increasing word\nerror rates to investigate how ASR affects SER. The objective of this study is\nto uncover the relationship and mutual impact of ASR and SER, in order to\nfacilitate ASR adaptation to emotional speech and the use of SER in real world.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yuanchao Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_Z/0/1/0/all/0/1\">Zeyu Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Klejch_O/0/1/0/all/0/1\">Ondrej Klejch</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bell_P/0/1/0/all/0/1\">Peter Bell</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lai_C/0/1/0/all/0/1\">Catherine Lai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InterFormer: Interactive Local and Global Features Fusion for Automatic Speech Recognition. (arXiv:2305.16342v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.16342","description":"<p>The local and global features are both essential for automatic speech\nrecognition (ASR). Many recent methods have verified that simply combining\nlocal and global features can further promote ASR performance. However, these\nmethods pay less attention to the interaction of local and global features, and\ntheir series architectures are rigid to reflect local and global relationships.\nTo address these issues, this paper proposes InterFormer for interactive local\nand global features fusion to learn a better representation for ASR.\nSpecifically, we combine the convolution block with the transformer block in a\nparallel design. Besides, we propose a bidirectional feature interaction module\n(BFIM) and a selective fusion module (SFM) to implement the interaction and\nfusion of local and global features, respectively. Extensive experiments on\npublic ASR datasets demonstrate the effectiveness of our proposed InterFormer\nand its superior performance over the other Transformer and Conformer models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lai_Z/0/1/0/all/0/1\">Zhi-Hao Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tian-Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1\">Xinyuan Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1\">Li-Fang Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Song-Lu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xu-Cheng Yin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Domain Aligned Prefix Averaging for Domain Generalization in Abstractive Summarization. (arXiv:2305.16820v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.16820","description":"<p>Domain generalization is hitherto an underexplored area applied in\nabstractive summarization. Moreover, most existing works on domain\ngeneralization have sophisticated training algorithms. In this paper, we\npropose a lightweight, weight averaging based, Domain Aligned Prefix Averaging\napproach to domain generalization for abstractive summarization. Given a number\nof source domains, our method first trains a prefix for each one of them. These\nsource prefixes generate summaries for a small number of target domain\ndocuments. The similarity of the generated summaries to their corresponding\ndocuments is used for calculating weights required to average source prefixes.\nIn DAPA, prefix tuning allows for lightweight finetuning, and weight averaging\nallows for the computationally efficient addition of new source domains. When\nevaluated on four diverse summarization domains, DAPA shows comparable or\nbetter performance against the baselines, demonstrating the effectiveness of\nits prefix averaging scheme.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nair_P/0/1/0/all/0/1\">Pranav Ajit Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_S/0/1/0/all/0/1\">Sukomal Pal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_P/0/1/0/all/0/1\">Pradeepika Verma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models. (arXiv:2305.16986v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.16986","description":"<p>Trained with an unprecedented scale of data, large language models (LLMs)\nlike ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities\nfrom model scaling. Such a trend underscored the potential of training LLMs\nwith unlimited language data, advancing the development of a universal embodied\nagent. In this work, we introduce the NavGPT, a purely LLM-based\ninstruction-following navigation agent, to reveal the reasoning capability of\nGPT models in complex embodied scenes by performing zero-shot sequential action\nprediction for vision-and-language navigation (VLN). At each step, NavGPT takes\nthe textual descriptions of visual observations, navigation history, and future\nexplorable directions as inputs to reason the agent's current status, and makes\nthe decision to approach the target. Through comprehensive experiments, we\ndemonstrate NavGPT can explicitly perform high-level planning for navigation,\nincluding decomposing instruction into sub-goal, integrating commonsense\nknowledge relevant to navigation task resolution, identifying landmarks from\nobserved scenes, tracking navigation progress, and adapting to exceptions with\nplan adjustment. Furthermore, we show that LLMs is capable of generating\nhigh-quality navigational instructions from observations and actions along a\npath, as well as drawing accurate top-down metric trajectory given the agent's\nnavigation history. Despite the performance of using NavGPT to zero-shot R2R\ntasks still falling short of trained models, we suggest adapting multi-modality\ninputs for LLMs to use as visual navigation agents and applying the explicit\nreasoning of LLMs to benefit learning-based models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1\">Gengze Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1\">Yicong Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qi Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-05-29T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","admin":"http://webns.net/mvcb/","content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/","dc":"http://purl.org/dc/elements/1.1/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}