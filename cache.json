{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-02-09T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Concept Algebra for Text-Controlled Vision Models. (arXiv:2302.03693v1 [cs.CL])","link":"http://arxiv.org/abs/2302.03693","description":"<p>This paper concerns the control of text-guided generative models, where a\nuser provides a natural language prompt and the model generates samples based\non this input. Prompting is intuitive, general, and flexible. However, there\nare significant limitations: prompting can fail in surprising ways, and it is\noften unclear how to find a prompt that will elicit some desired target\nbehavior. A core difficulty for developing methods to overcome these issues is\nthat failures are know-it-when-you-see-it -- it's hard to fix bugs if you can't\nstate precisely what the model should have done! In this paper, we introduce a\nformalization of \"what the user intended\" in terms of latent concepts implicit\nto the data generating process that the model was trained on. This\nformalization allows us to identify some fundamental limitations of prompting.\nWe then use the formalism to develop concept algebra to overcome these\nlimitations. Concept algebra is a way of directly manipulating the concepts\nexpressed in the output through algebraic operations on a suitably defined\nrepresentation of input prompts. We give examples using concept algebra to\novercome limitations of prompting, including concept transfer through\narithmetic, and concept nullification through projection. Code available at\nhttps://github.com/zihao12/concept-algebra.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1\">Lin Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negrea_J/0/1/0/all/0/1\">Jeffrey Negrea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veitch_V/0/1/0/all/0/1\">Victor Veitch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Characterizing Financial Market Coverage using Artificial Intelligence. (arXiv:2302.03694v1 [q-fin.ST])","link":"http://arxiv.org/abs/2302.03694","description":"<p>This paper scrutinizes a database of over 4900 YouTube videos to characterize\nfinancial market coverage. Financial market coverage generates a large number\nof videos. Therefore, watching these videos to derive actionable insights could\nbe challenging and complex. In this paper, we leverage Whisper, a\nspeech-to-text model from OpenAI, to generate a text corpus of market coverage\nvideos from Bloomberg and Yahoo Finance. We employ natural language processing\nto extract insights regarding language use from the market coverage. Moreover,\nwe examine the prominent presence of trending topics and their evolution over\ntime, and the impacts that some individuals and organizations have on the\nfinancial market. Our characterization highlights the dynamics of the financial\nmarket coverage and provides valuable insights reflecting broad discussions\nregarding recent financial events and the world economy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-fin/1/au:+Tshimula_J/0/1/0/all/0/1\">Jean Marie Tshimula</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Nkashama_D/0/1/0/all/0/1\">D&#x27;Jeff K. Nkashama</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Owusu_P/0/1/0/all/0/1\">Patrick Owusu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Frappier_M/0/1/0/all/0/1\">Marc Frappier</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Tardif_P/0/1/0/all/0/1\">Pierre-Martin Tardif</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Kabanza_F/0/1/0/all/0/1\">Froduald Kabanza</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Brun_A/0/1/0/all/0/1\">Armelle Brun</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Patenaude_J/0/1/0/all/0/1\">Jean-Marc Patenaude</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Wang_S/0/1/0/all/0/1\">Shengrui Wang</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Chikhaoui_B/0/1/0/all/0/1\">Belkacem Chikhaoui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mining Effective Features Using Quantum Entropy for Humor Recognition. (arXiv:2302.03716v1 [cs.CL])","link":"http://arxiv.org/abs/2302.03716","description":"<p>Humor recognition has been extensively studied with different methods in the\npast years. However, existing studies on humor recognition do not understand\nthe mechanisms that generate humor. In this paper, inspired by the incongruity\ntheory, any joke can be divided into two components (the setup and the\npunchline). Both components have multiple possible semantics, and there is an\nincongruous relationship between them. We use density matrices to represent the\nsemantic uncertainty of the setup and the punchline, respectively, and design\nQE-Uncertainty and QE-Incongruity with the help of quantum entropy as features\nfor humor recognition. The experimental results on the SemEval2021 Task 7\ndataset show that the proposed features are more effective than the baselines\nfor recognizing humorous and non-humorous texts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yuexian Hou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories. (arXiv:2302.03754v1 [cs.CL])","link":"http://arxiv.org/abs/2302.03754","description":"<p>In this paper we improve the zero-shot generalization ability of language\nmodels via Mixture-Of-Memory Augmentation (MoMA), a mechanism that retrieves\naugmentation documents from multiple information corpora (\"external memories\"),\nwith the option to \"plug in\" new memory at inference time. We develop a joint\nlearning mechanism that trains the augmentation component with latent labels\nderived from the end retrieval task, paired with hard negatives from the memory\nmixture. We instantiate the model in a zero-shot dense retrieval setting by\naugmenting a strong T5-based retriever with MoMA. Our model, MoMA, obtains\nstrong zero-shot retrieval accuracy on the eighteen tasks included in the\nstandard BEIR benchmark. It outperforms systems that seek generalization from\nincreased model parameters and computation steps. Our analysis further\nillustrates the necessity of augmenting with mixture-of-memory for robust\ngeneralization, the benefits of augmentation learning, and how MoMA utilizes\nthe plug-in memory at inference time without changing its parameters. We plan\nto open source our code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Suyu Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Chenyan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosset_C/0/1/0/all/0/1\">Corby Rosset</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Overwijk_A/0/1/0/all/0/1\">Arnold Overwijk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennett_P/0/1/0/all/0/1\">Paul Bennett</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformer-based Models for Long-Form Document Matching: Challenges and Empirical Analysis. (arXiv:2302.03765v1 [cs.CL])","link":"http://arxiv.org/abs/2302.03765","description":"<p>Recent advances in the area of long document matching have primarily focused\non using transformer-based models for long document encoding and matching.\nThere are two primary challenges associated with these models. Firstly, the\nperformance gain provided by transformer-based models comes at a steep cost -\nboth in terms of the required training time and the resource (memory and\nenergy) consumption. The second major limitation is their inability to handle\nmore than a pre-defined input token length at a time. In this work, we\nempirically demonstrate the effectiveness of simple neural models (such as\nfeed-forward networks, and CNNs) and simple embeddings (like GloVe, and\nParagraph Vector) over transformer-based models on the task of document\nmatching. We show that simple models outperform the more complex BERT-based\nmodels while taking significantly less training time, energy, and memory. The\nsimple models are also more robust to variations in document length and text\nperturbations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jha_A/0/1/0/all/0/1\">Akshita Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samavedhi_A/0/1/0/all/0/1\">Adithya Samavedhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rakesh_V/0/1/0/all/0/1\">Vineeth Rakesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrashekar_J/0/1/0/all/0/1\">Jaideep Chandrashekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1\">Chandan K. Reddy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What Matters In The Structured Pruning of Generative Language Models?. (arXiv:2302.03773v1 [cs.CL])","link":"http://arxiv.org/abs/2302.03773","description":"<p>Auto-regressive large language models such as GPT-3 require enormous\ncomputational resources to use. Traditionally, structured pruning methods are\nemployed to reduce resource usage. However, their application to and efficacy\nfor generative language models is heavily under-explored. In this paper we\nconduct an comprehensive evaluation of common structured pruning methods,\nincluding magnitude, random, and movement pruning on the feed-forward layers in\nGPT-type models. Unexpectedly, random pruning results in performance that is\ncomparable to the best established methods, across multiple natural language\ngeneration tasks. To understand these results, we provide a framework for\nmeasuring neuron-level redundancy of models pruned by different methods, and\ndiscover that established structured pruning methods do not take into account\nthe distinctiveness of neurons, leaving behind excess redundancies. In view of\nthis, we introduce Globally Unique Movement (GUM) to improve the uniqueness of\nneurons in pruned models. We then discuss the effects of our techniques on\ndifferent redundancy metrics to explain the improved performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Santacroce_M/0/1/0/all/0/1\">Michael Santacroce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zixin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yelong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reliable Natural Language Understanding with Large Language Models and Answer Set Programming. (arXiv:2302.03780v1 [cs.CL])","link":"http://arxiv.org/abs/2302.03780","description":"<p>Humans understand language by extracting information (meaning) from\nsentences, combining it with existing commonsense knowledge, and then\nperforming reasoning to draw conclusions. While large language models (LLMs)\nsuch as GPT-3 and ChatGPT are able to leverage patterns in the text to solve a\nvariety of NLP tasks, they fall short in problems that require reasoning. They\nalso cannot reliably explain the answers generated for a given question. In\norder to emulate humans better, we propose STAR, a framework that combines LLMs\nwith Answer Set Programming (ASP). We show how LLMs can be used to effectively\nextract knowledge -- represented as predicates -- from language. Goal-directed\nASP is then employed to reliably reason over this knowledge. We apply the STAR\nframework to three different NLU tasks requiring reasoning: qualitative\nreasoning, mathematical reasoning, and goal-directed conversation. Our\nexperiments reveal that STAR is able to bridge the gap of reasoning in NLU\ntasks, leading to significant performance improvements, especially for smaller\nLLMs, i.e., LLMs with a smaller number of parameters. NLU applications\ndeveloped using the STAR framework are also explainable: along with the\npredicates generated, a justification in the form of a proof tree can be\nproduced for a given output.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rajasekharan_A/0/1/0/all/0/1\">Abhiramon Rajasekharan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yankai Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padalkar_P/0/1/0/all/0/1\">Parth Padalkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_G/0/1/0/all/0/1\">Gopal Gupta</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Long Text and Multi-Table Summarization: Dataset and Method. (arXiv:2302.03815v1 [cs.CL])","link":"http://arxiv.org/abs/2302.03815","description":"<p>Automatic document summarization aims to produce a concise summary covering\nthe input document's salient information. Within a report document, the salient\ninformation can be scattered in the textual and non-textual content. However,\nexisting document summarization datasets and methods usually focus on the text\nand filter out the non-textual content. Missing tabular data can limit produced\nsummaries' informativeness, especially when summaries require covering\nquantitative descriptions of critical metrics in tables. Existing datasets and\nmethods cannot meet the requirements of summarizing long text and multiple\ntables in each report. To deal with the scarcity of available data, we propose\nFINDSum, the first large-scale dataset for long text and multi-table\nsummarization. Built on 21,125 annual reports from 3,794 companies, it has two\nsubsets for summarizing each company's results of operations and liquidity. To\nsummarize the long text and dozens of tables in each report, we present three\ntypes of summarization methods. Besides, we propose a set of evaluation metrics\nto assess the usage of numerical information in produced summaries. Dataset\nanalyses and experimental results indicate the importance of jointly\nconsidering input textual and tabular data when summarizing report documents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuaiqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jiannong Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Ruosong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zhiyuan Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Clinical BioBERT Hyperparameter Optimization using Genetic Algorithm Clinical BioBERT Hyperparameter Optimization using Genetic Algorithm. (arXiv:2302.03822v1 [cs.AI])","link":"http://arxiv.org/abs/2302.03822","description":"<p>Clinical factors account only for a small portion, about 10-30%, of the\ncontrollable factors that affect an individual's health outcomes. The remaining\nfactors include where a person was born and raised, where he/she pursued their\neducation, what their work and family environment is like, etc. These factors\nare collectively referred to as Social Determinants of Health (SDoH). The\nmajority of SDoH data is recorded in unstructured clinical notes by physicians\nand practitioners. Recording SDoH data in a structured manner (in an EHR) could\ngreatly benefit from a dedicated ontology of SDoH terms. Our research focuses\non extracting sentences from clinical notes, making use of such an SDoH\nontology (called SOHO) to provide appropriate concepts. We utilize recent\nadvancements in Deep Learning to optimize the hyperparameters of a Clinical\nBioBERT model for SDoH text. A genetic algorithm-based hyperparameter tuning\nregimen was implemented to identify optimal parameter settings. To implement a\ncomplete classifier, we pipelined Clinical BioBERT with two subsequent linear\nlayers and two dropout layers. The output predicts whether a text fragment\ndescribes an SDoH issue of the patient. We compared the AdamW, Adafactor, and\nLAMB optimizers. In our experiments, AdamW outperformed the others in terms of\naccuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kollapally_N/0/1/0/all/0/1\">Navya Martin Kollapally</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geller_J/0/1/0/all/0/1\">James Geller</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Controlling Personality Style in Dialogue with Zero-Shot Prompt-Based Learning. (arXiv:2302.03848v1 [cs.CL])","link":"http://arxiv.org/abs/2302.03848","description":"<p>Prompt-based or in-context learning has achieved high zero-shot performance\non many natural language generation (NLG) tasks. Here we explore the\nperformance of prompt-based learning for simultaneously controlling the\npersonality and the semantic accuracy of an NLG for task-oriented dialogue. We\nexperiment with prompt-based learning on the PERSONAGE restaurant\nrecommendation corpus to generate semantically and stylistically-controlled\ntext for 5 different Big-5 personality types: agreeable, disagreeable,\nconscientious, unconscientious, and extravert. We test two different classes of\ndiscrete prompts to generate utterances for a particular personality style: (1)\nprompts that demonstrate generating directly from a meaning representation that\nincludes a personality specification; and (2) prompts that rely on first\nconverting the meaning representation to a textual pseudo-reference, and then\nusing the pseudo-reference in a textual style transfer (TST) prompt. In each\ncase, we show that we can vastly improve performance by over-generating outputs\nand ranking them, testing several ranking functions based on automatic metrics\nfor semantic accuracy, personality-match, and fluency. We also test whether NLG\npersonality demonstrations from the restaurant domain can be used with meaning\nrepresentations for the video game domain to generate personality stylized\nutterances about video games. Our findings show that the TST prompts produces\nthe highest semantic accuracy (78.46% for restaurants and 87.6% for video\ngames) and personality accuracy (100% for restaurants and 97% for video games).\nOur results on transferring personality style to video game utterances are\nsurprisingly good. To our knowledge, there is no previous work testing the\napplication of prompt-based learning to simultaneously controlling both style\nand semantic accuracy in NLG.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ramirez_A/0/1/0/all/0/1\">Angela Ramirez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alsalihy_M/0/1/0/all/0/1\">Mamon Alsalihy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_K/0/1/0/all/0/1\">Kartik Aggarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Cecilia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Liren Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walker_M/0/1/0/all/0/1\">Marilyn Walker</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Auto-Learning: An Adversarial Process of Two Pre-trained Models for Natural Language Generation. (arXiv:2302.03896v1 [cs.CL])","link":"http://arxiv.org/abs/2302.03896","description":"<p>Pre-trained models have been used in many fields in recent years, ranging\nfrom natural language understanding to computer vision and natural language\ngeneration. However, the performance of these natural language generation\nmodels is overly dependent on the scale of the model and the size of the\ndataset. While the larger language model is excellent in some respects, it\ncannot learn up-to-date knowledge and is relatively difficult to relearn. In\nthis paper, a new adversarial process learning method called Auto-Learning.\nThis can improve the performance of any natural language generation model\nwithout the help of additional datasets. Auto-Learning includes two models: $G$\nis a text generation model and $D$ can test whether the data generated by G is\nlegitimate. Firstly, the fine-tuned $D$ model is used as the brain's knowledge\nbase before the process. Then the text generated by the $G$ model is used as\nthe input of $D$ to determine whether the text is legitimate or not. Finally,\n$G$ is fine-tuned according to the output of $D$. This adversarial process is\nlike a self-escalation of the brain through some a priori knowledge. When this\nadversarial system wants to learn something new, simply fine-tune the $D$\nmodel. Our approach applies to Autoregressive Language Modeling for all\nTransformer classes. The results are good in existing experimental tasks,\nincluding more grammatical text generation and better performance on some text\ncomprehension tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zhengqing Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yuelin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1\">Huiwen Xue</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"COMBO: A Complete Benchmark for Open KG Canonicalization. (arXiv:2302.03905v1 [cs.CL])","link":"http://arxiv.org/abs/2302.03905","description":"<p>Open knowledge graph (KG) consists of (subject, relation, object) triples\nextracted from millions of raw text. The subject and object noun phrases and\nthe relation in open KG have severe redundancy and ambiguity and need to be\ncanonicalized. Existing datasets for open KG canonicalization only provide gold\nentity-level canonicalization for noun phrases. In this paper, we present\nCOMBO, a Complete Benchmark for Open KG canonicalization. Compared with\nexisting datasets, we additionally provide gold canonicalization for relation\nphrases, gold ontology-level canonicalization for noun phrases, as well as\nsource sentences from which triples are extracted. We also propose metrics for\nevaluating each type of canonicalization. On the COMBO dataset, we empirically\ncompare previously proposed canonicalization methods as well as a few simple\nbaseline methods based on pretrained language models. We find that properly\nencoding the phrases in a triple using pretrained language models results in\nbetter relation canonicalization and ontology-level canonicalization of the\nnoun phrase. We release our dataset, baselines, and evaluation scripts at\nhttps://github.com/jeffchy/COMBO/tree/main.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1\">Chengyue Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Weiqi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yuting Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pengjun Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving (Dis)agreement Detection with Inductive Social Relation Information From Comment-Reply Interactions. (arXiv:2302.03950v1 [cs.CL])","link":"http://arxiv.org/abs/2302.03950","description":"<p>(Dis)agreement detection aims to identify the authors' attitudes or positions\n(\\textit{{agree, disagree, neutral}}) towards a specific text. It is limited\nfor existing methods merely using textual information for identifying\n(dis)agreements, especially for cross-domain settings. Social relation\ninformation can play an assistant role in the (dis)agreement task besides\ntextual information. We propose a novel method to extract such relation\ninformation from (dis)agreement data into an inductive social relation graph,\nmerely using the comment-reply pairs without any additional platform-specific\ninformation. The inductive social relation globally considers the historical\ndiscussion and the relation between authors. Textual information based on a\npre-trained language model and social relation information encoded by\npre-trained RGCN are jointly considered for (dis)agreement detection.\nExperimental results show that our model achieves state-of-the-art performance\nfor both the in-domain and cross-domain tasks on the benchmark -- DEBAGREEMENT.\nWe find social relations can boost the performance of the (dis)agreement\ndetection model, especially for the long-token comment-reply pairs,\ndemonstrating the effectiveness of the social relation graph. We also explore\nthe effect of the knowledge graph embedding methods, the information fusing\nmethod, and the time interval in constructing the social relation graph, which\nshows the effectiveness of our model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Stan Z. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging Summary Guidance on Medical Report Summarization. (arXiv:2302.04001v1 [cs.CL])","link":"http://arxiv.org/abs/2302.04001","description":"<p>This study presents three deidentified large medical text datasets, named\nDISCHARGE, ECHO and RADIOLOGY, which contain 50K, 16K and 378K pairs of report\nand summary that are derived from MIMIC-III, respectively. We implement\nconvincing baselines of automated abstractive summarization on the proposed\ndatasets with pre-trained encoder-decoder language models, including BERT2BERT,\nT5-large and BART. Further, based on the BART model, we leverage the sampled\nsummaries from the train set as prior knowledge guidance, for encoding\nadditional contextual representations of the guidance with the encoder and\nenhancing the decoding representations in the decoder. The experimental results\nconfirm the improvement of ROUGE scores and BERTScore made by the proposed\nmethod, outperforming the larger model T5-large.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yunqi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xuebing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuanyuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wensheng Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Systematically Finding Security Vulnerabilities in Black-Box Code Generation Models. (arXiv:2302.04012v1 [cs.CR])","link":"http://arxiv.org/abs/2302.04012","description":"<p>Recently, large language models for code generation have achieved\nbreakthroughs in several programming language tasks. Their advances in\ncompetition-level programming problems have made them an emerging pillar in\nAI-assisted pair programming. Tools such as GitHub Copilot are already part of\nthe daily programming workflow and are used by more than a million developers.\nThe training data for these models is usually collected from open-source\nrepositories (e.g., GitHub) that contain software faults and security\nvulnerabilities. This unsanitized training data can lead language models to\nlearn these vulnerabilities and propagate them in the code generation\nprocedure. Given the wide use of these models in the daily workflow of\ndevelopers, it is crucial to study the security aspects of these models\nsystematically.\n</p>\n<p>In this work, we propose the first approach to automatically finding security\nvulnerabilities in black-box code generation models. To achieve this, we\npropose a novel black-box inversion approach based on few-shot prompting. We\nevaluate the effectiveness of our approach by examining code generation models\nin the generation of high-risk security weaknesses. We show that our approach\nautomatically and systematically finds 1000s of security vulnerabilities in\nvarious code generation models, including the commercial black-box model GitHub\nCopilot.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hajipour_H/0/1/0/all/0/1\">Hossein Hajipour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holz_T/0/1/0/all/0/1\">Thorsten Holz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonherr_L/0/1/0/all/0/1\">Lea Sch&#xf6;nherr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fritz_M/0/1/0/all/0/1\">Mario Fritz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity. (arXiv:2302.04023v1 [cs.CL])","link":"http://arxiv.org/abs/2302.04023","description":"<p>This paper proposes a framework for quantitatively evaluating interactive\nLLMs such as ChatGPT using publicly available data sets. We carry out an\nextensive technical evaluation of ChatGPT using 21 data sets covering 8\ndifferent common NLP application tasks. We evaluate the multitask, multilingual\nand multi-modal aspects of ChatGPT based on these data sets and a newly\ndesigned multimodal dataset. We find that ChatGPT outperforms LLMs with\nzero-shot learning on most tasks and even outperforms fine-tuned models on some\ntasks. We find that it is better at understanding non-Latin script languages\nthan generating them. It is able to generate multimodal content from textual\nprompts, via an intermediate code generation step. Moreover, we find that\nChatGPT is 64.33% accurate on average in 10 different reasoning categories\nunder logical reasoning, non-textual reasoning, and commonsense reasoning,\nhence making it an unreliable reasoner. It is, for example, better at deductive\nthan inductive reasoning. ChatGPT suffers from hallucination problems like\nother LLMs and it generates more extrinsic hallucinations from its parametric\nmemory as it does not have access to an external knowledge base. Finally, the\ninteractive feature of ChatGPT enables human collaboration with the underlying\nLLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++\non machine translation, in a multi-turn \"prompt engineering\" fashion.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bang_Y/0/1/0/all/0/1\">Yejin Bang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cahyawijaya_S/0/1/0/all/0/1\">Samuel Cahyawijaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1\">Nayeon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Wenliang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1\">Dan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilie_B/0/1/0/all/0/1\">Bryan Wilie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lovenia_H/0/1/0/all/0/1\">Holy Lovenia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1\">Ziwei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tiezheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_W/0/1/0/all/0/1\">Willy Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_Q/0/1/0/all/0/1\">Quyet V. Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revisiting Offline Compression: Going Beyond Factorization-based Methods for Transformer Language Models. (arXiv:2302.04045v1 [cs.CL])","link":"http://arxiv.org/abs/2302.04045","description":"<p>Recent transformer language models achieve outstanding results in many\nnatural language processing (NLP) tasks. However, their enormous size often\nmakes them impractical on memory-constrained devices, requiring practitioners\nto compress them to smaller networks. In this paper, we explore offline\ncompression methods, meaning computationally-cheap approaches that do not\nrequire further fine-tuning of the compressed model. We challenge the classical\nmatrix factorization methods by proposing a novel, better-performing\nautoencoder-based framework. We perform a comprehensive ablation study of our\napproach, examining its different aspects over a diverse set of evaluation\nsettings. Moreover, we show that enabling collaboration between modules across\nlayers by compressing certain modules together positively impacts the final\nmodel performance. Experiments on various NLP tasks demonstrate that our\napproach significantly outperforms commonly used factorization-based offline\ncompression methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Banaei_M/0/1/0/all/0/1\">Mohammadreza Banaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balazy_K/0/1/0/all/0/1\">Klaudia Ba&#x142;azy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasymov_A/0/1/0/all/0/1\">Artur Kasymov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lebret_R/0/1/0/all/0/1\">R&#xe9;mi Lebret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabor_J/0/1/0/all/0/1\">Jacek Tabor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aberer_K/0/1/0/all/0/1\">Karl Aberer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v1 [cs.LG])","link":"http://arxiv.org/abs/2302.04054","description":"<p>Reliability of machine learning evaluation -- the consistency of observed\nevaluation scores across replicated model training runs -- is affected by\nseveral sources of nondeterminism which can be regarded as measurement noise.\nCurrent tendencies to remove noise in order to enforce reproducibility of\nresearch results neglect inherent nondeterminism at the implementation level\nand disregard crucial interaction effects between algorithmic noise factors and\ndata properties. This limits the scope of conclusions that can be drawn from\nsuch experiments. Instead of removing noise, we propose to incorporate several\nsources of variance, including their interaction with data properties, into an\nanalysis of significance and reliability of machine learning evaluation, with\nthe aim to draw inferences beyond particular instances of trained models. We\nshow how to use linear mixed effects models (LMEMs) to analyze performance\nevaluation scores, and to conduct statistical inference with a generalized\nlikelihood ratio test (GLRT). This allows us to incorporate arbitrary sources\nof noise like meta-parameter variations into statistical significance testing,\nand to assess performance differences conditional on data properties.\nFurthermore, a variance component analysis (VCA) enables the analysis of the\ncontribution of noise sources to overall variance and the computation of a\nreliability coefficient by the ratio of substantial to total variance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hagmann_M/0/1/0/all/0/1\">Michael Hagmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1\">Stefan Riezler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reception Reader: Exploring Text Reuse in Early Modern British Publications. (arXiv:2302.04084v1 [cs.DL])","link":"http://arxiv.org/abs/2302.04084","description":"<p>The Reception Reader is a web tool for studying text reuse in the Early\nEnglish Books Online (EEBO-TCP) and Eighteenth Century Collections Online\n(ECCO) data. Users can: 1) explore a visual overview of the reception of a\nwork, or its incoming connections, across time based on shared text segments,\n2) interactively survey the details of connected documents, and 3) examine the\ncontext of reused text for \"close reading\". We show examples of how the tool\nstreamlines research and exploration tasks, and discuss the utility and\nlimitations of the user interface along with its current data sources.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rosson_D/0/1/0/all/0/1\">David Rosson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makela_E/0/1/0/all/0/1\">Eetu M&#xe4;kel&#xe4;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaara_V/0/1/0/all/0/1\">Ville Vaara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahadevan_A/0/1/0/all/0/1\">Ananth Mahadevan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryan_Y/0/1/0/all/0/1\">Yann Ryan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tolonen_M/0/1/0/all/0/1\">Mikko Tolonen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ZipLM: Hardware-Aware Structured Pruning of Language Models. (arXiv:2302.04089v1 [cs.LG])","link":"http://arxiv.org/abs/2302.04089","description":"<p>The breakthrough performance of large language models (LLMs) comes with large\ncomputational footprints and high deployment costs. In this paper, we progress\ntowards resolving this problem by proposing a new structured compression\napproach for LLMs, called ZipLM, which provides state-of-the-art\ncompression-vs-accuracy results, while guaranteeing to match a set of\n(achievable) target speedups on any given target hardware. Specifically, given\na task, a model, an inference environment, as well as a set of speedup targets,\nZipLM identifies and removes redundancies in the model through iterative\nstructured shrinking of the model's weight matrices. Importantly, ZipLM works\nin both, the post-training/one-shot and the gradual compression setting, where\nit produces a set of accurate models in a single run, making it\nhighly-efficient in practice. Our approach is based on new structured pruning\nand knowledge distillation techniques, and consistently outperforms prior\nstructured compression methods in terms of accuracy-versus-speedup in\nexperiments on BERT- and GPT-family models. In particular, when compressing\nGPT2 model, it outperforms DistilGPT2 while being 60% smaller and 30% faster.\nFurther, ZipLM matches performance of heavily optimized MobileBERT model,\nobtained via extensive architecture search, by simply pruning the baseline\nBERT-large architecture, and outperforms all prior BERT-base compression\ntechniques like CoFi, MiniLM and TinyBERT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kurtic_E/0/1/0/all/0/1\">Eldar Kurtic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frantar_E/0/1/0/all/0/1\">Elias Frantar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1\">Dan Alistarh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Real-Word Error Correction with Trigrams: Correcting Multiple Errors in a Sentence. (arXiv:2302.04096v1 [cs.CL])","link":"http://arxiv.org/abs/2302.04096","description":"<p>Spelling correction is a fundamental task in Text Mining. In this study, we\nassess the real-word error correction model proposed by Mays, Damerau and\nMercer and describe several drawbacks of the model. We propose a new variation\nwhich focuses on detecting and correcting multiple real-word errors in a\nsentence, by manipulating a Probabilistic Context-Free Grammar (PCFG) to\ndiscriminate between items in the search space. We test our approach on the\nWall Street Journal corpus and show that it outperforms Hirst and Budanitsky's\nWordNet-based method and Wilcox-O'Hearn, Hirst, and Budanitsky's fixed windows\nsize method.-O'Hearn, Hirst, and Budanitsky's fixed windows size method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dashti_S/0/1/0/all/0/1\">Seyed MohammadSadegh Dashti</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Training-free Lexical Backdoor Attacks on Language Models. (arXiv:2302.04116v1 [cs.CR])","link":"http://arxiv.org/abs/2302.04116","description":"<p>Large-scale language models have achieved tremendous success across various\nnatural language processing (NLP) applications. Nevertheless, language models\nare vulnerable to backdoor attacks, which inject stealthy triggers into models\nfor steering them to undesirable behaviors. Most existing backdoor attacks,\nsuch as data poisoning, require further (re)training or fine-tuning language\nmodels to learn the intended backdoor patterns. The additional training process\nhowever diminishes the stealthiness of the attacks, as training a language\nmodel usually requires long optimization time, a massive amount of data, and\nconsiderable modifications to the model parameters. In this work, we propose\nTraining-Free Lexical Backdoor Attack (TFLexAttack) as the first training-free\nbackdoor attack on language models. Our attack is achieved by injecting lexical\ntriggers into the tokenizer of a language model via manipulating its embedding\ndictionary using carefully designed rules. These rules are explainable to human\ndevelopers which inspires attacks from a wider range of hackers. The sparse\nmanipulation of the dictionary also habilitates the stealthiness of our attack.\nWe conduct extensive experiments on three dominant NLP tasks based on nine\nlanguage models to demonstrate the effectiveness and universality of our\nattack. The code of this work is available at\nhttps://github.com/Jinxhy/TFLexAttack.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yujin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_T/0/1/0/all/0/1\">Terry Yue Zhuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiongkai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Han Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xingliang Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chunyang Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompting for Multimodal Hateful Meme Classification. (arXiv:2302.04156v1 [cs.CL])","link":"http://arxiv.org/abs/2302.04156","description":"<p>Hateful meme classification is a challenging multimodal task that requires\ncomplex reasoning and contextual background knowledge. Ideally, we could\nleverage an explicit external knowledge base to supplement contextual and\ncultural information in hateful memes. However, there is no known explicit\nexternal knowledge base that could provide such hate speech contextual\ninformation. To address this gap, we propose PromptHate, a simple yet effective\nprompt-based model that prompts pre-trained language models (PLMs) for hateful\nmeme classification. Specifically, we construct simple prompts and provide a\nfew in-context examples to exploit the implicit knowledge in the pre-trained\nRoBERTa language model for hateful meme classification. We conduct extensive\nexperiments on two publicly available hateful and offensive meme datasets. Our\nexperimental results show that PromptHate is able to achieve a high AUC of\n90.96, outperforming state-of-the-art baselines on the hateful meme\nclassification task. We also perform fine-grained analyses and case studies on\nvarious prompt settings and demonstrate the effectiveness of the prompts on\nhateful meme classification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1\">Rui Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1\">Roy Ka-Wei Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chong_W/0/1/0/all/0/1\">Wen-Haw Chong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jing Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPTScore: Evaluate as You Desire. (arXiv:2302.04166v1 [cs.CL])","link":"http://arxiv.org/abs/2302.04166","description":"<p>Generative Artificial Intelligence (AI) has enabled the development of\nsophisticated models that are capable of producing high-caliber text, images,\nand other outputs through the utilization of large pre-trained models.\nNevertheless, assessing the quality of the generation is an even more arduous\ntask than the generation itself, and this issue has not been given adequate\nconsideration recently. This paper proposes a novel evaluation framework,\nGPTScore, which utilizes the emergent abilities (e.g., zero-shot instruction)\nfrom generative pre-trained models to score generated texts. Experimental\nresults on four text generation tasks, 22 evaluation aspects, and corresponding\n37 datasets demonstrate that this approach can effectively allow us to achieve\nwhat one desires to evaluate for texts simply by natural language instructions.\nThis nature helps us overcome several long-standing challenges in text\nevaluation--how to achieve customized, multi-faceted evaluation without the\nneed for annotated samples. We make our code publicly available at\nhttps://github.com/jinlanfu/GPTScore.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jinlan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_S/0/1/0/all/0/1\">See-Kiong Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhengbao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Pengfei Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Joint Learning for Clinical Named Entity Recognition and Relation Extraction Using Fourier Networks: A Use Case in Adverse Drug Events. (arXiv:2302.04185v1 [cs.CL])","link":"http://arxiv.org/abs/2302.04185","description":"<p>Current approaches for clinical information extraction are inefficient in\nterms of computational costs and memory consumption, hindering their\napplication to process large-scale electronic health records (EHRs). We propose\nan efficient end-to-end model, the Joint-NER-RE-Fourier (JNRF), to jointly\nlearn the tasks of named entity recognition and relation extraction for\ndocuments of variable length. The architecture uses positional encoding and\nunitary batch sizes to process variable length documents and uses a\nweight-shared Fourier network layer for low-complexity token mixing. Finally,\nwe reach the theoretical computational complexity lower bound for relation\nextraction using a selective pooling strategy and distance-aware attention\nweights with trainable polynomial distance functions. We evaluated the JNRF\narchitecture using the 2018 N2C2 ADE benchmark to jointly extract\nmedication-related entities and relations in variable-length EHR summaries.\nJNRF outperforms rolling window BERT with selective pooling by 0.42%, while\nbeing twice as fast to train. Compared to state-of-the-art BiLSTM-CRF\narchitectures on the N2C2 ADE benchmark, results show that the proposed\napproach trains 22 times faster and reduces GPU memory consumption by 1.75\nfolds, with a reasonable performance tradeoff of 90%, without the use of\nexternal tools, hand-crafted rules or post-processing. Given the significant\ncarbon footprint of deep learning models and the current energy crises, these\nmethods could support efficient and cleaner information extraction in EHRs and\nother types of large-scale document databases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yazdani_A/0/1/0/all/0/1\">Anthony Yazdani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Proios_D/0/1/0/all/0/1\">Dimitrios Proios</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouhizadeh_H/0/1/0/all/0/1\">Hossein Rouhizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teodoro_D/0/1/0/all/0/1\">Douglas Teodoro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hierarchical Event Grounding. (arXiv:2302.04197v1 [cs.CL])","link":"http://arxiv.org/abs/2302.04197","description":"<p>Event grounding aims at linking mention references in text corpora to events\nfrom a knowledge base (KB). Previous work on this task focused primarily on\nlinking to a single KB event, thereby overlooking the hierarchical aspects of\nevents. Events in documents are typically described at various levels of\nspatio-temporal granularity (Glavas et al. 2014). These hierarchical relations\nare utilized in downstream tasks of narrative understanding and schema\nconstruction. In this work, we present an extension to the event grounding task\nthat requires tackling hierarchical event structures from the KB. Our proposed\ntask involves linking a mention reference to a set of event labels from a\nsubevent hierarchy in the KB. We propose a retrieval methodology that leverages\nevent hierarchy through an auxiliary hierarchical loss (Murty et al. 2018). On\nan automatically created multilingual dataset from Wikipedia and Wikidata, our\nexperiments demonstrate the effectiveness of the hierarchical loss against\nretrieve and re-rank baselines (Wu et al. 2020; Pratapa, Gupta, and Mitamura\n2022). Furthermore, we demonstrate the systems' ability to aid hierarchical\ndiscovery among unseen events.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ou_J/0/1/0/all/0/1\">Jiefu Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pratapa_A/0/1/0/all/0/1\">Adithya Pratapa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1\">Rishubh Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitamura_T/0/1/0/all/0/1\">Teruko Mitamura</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Diagnosing and Rectifying Vision Models using Language. (arXiv:2302.04269v1 [cs.LG])","link":"http://arxiv.org/abs/2302.04269","description":"<p>Recent multi-modal contrastive learning models have demonstrated the ability\nto learn an embedding space suitable for building strong vision classifiers, by\nleveraging the rich information in large-scale image-caption datasets. Our work\nhighlights a distinct advantage of this multi-modal embedding space: the\nability to diagnose vision classifiers through natural language. The\ntraditional process of diagnosing model behaviors in deployment settings\ninvolves labor-intensive data acquisition and annotation. Our proposed method\ncan discover high-error data slices, identify influential attributes and\nfurther rectify undesirable model behaviors, without requiring any visual data.\nThrough a combination of theoretical explanation and empirical verification, we\npresent conditions under which classifiers trained on embeddings from one\nmodality can be equivalently applied to embeddings from another modality. On a\nrange of image datasets with known error slices, we demonstrate that our method\ncan effectively identify the error slices and influential attributes, and can\nfurther use language to rectify failure modes of the classifier.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuhui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+HaoChen_J/0/1/0/all/0/1\">Jeff Z. HaoChen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shih-Cheng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kuan-Chieh Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_S/0/1/0/all/0/1\">Serena Yeung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated Identification of Toxic Code Reviews Using ToxiCR. (arXiv:2202.13056v3 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2202.13056","description":"<p>Toxic conversations during software development interactions may have serious\nrepercussions on a Free and Open Source Software (FOSS) development project.\nFor example, victims of toxic conversations may become afraid to express\nthemselves, therefore get demotivated, and may eventually leave the project.\nAutomated filtering of toxic conversations may help a FOSS community to\nmaintain healthy interactions among its members. However, off-the-shelf\ntoxicity detectors perform poorly on Software Engineering (SE) datasets, such\nas one curated from code review comments. To encounter this challenge, we\npresent ToxiCR, a supervised learning-based toxicity identification tool for\ncode review interactions. ToxiCR includes a choice to select one of the ten\nsupervised learning algorithms, an option to select text vectorization\ntechniques, eight preprocessing steps, and a large-scale labeled dataset of\n19,571 code review comments. Two out of those eight preprocessing steps are SE\ndomain specific. With our rigorous evaluation of the models with various\ncombinations of preprocessing steps and vectorization techniques, we have\nidentified the best combination for our dataset that boosts 95.8% accuracy and\n88.9% F1 score. ToxiCR significantly outperforms existing toxicity detectors on\nour dataset. We have released our dataset, pre-trained models, evaluation\nresults, and source code publicly available at:\nhttps://github.com/WSU-SEAL/ToxiCR\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sarker_J/0/1/0/all/0/1\">Jaydeb Sarker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turzo_A/0/1/0/all/0/1\">Asif Kamal Turzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_M/0/1/0/all/0/1\">Ming Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosu_A/0/1/0/all/0/1\">Amiangshu Bosu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models. (arXiv:2204.14211v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.14211","description":"<p>Language Models (LMs) become outdated as the world changes; they often fail\nto perform tasks requiring recent factual information which was absent or\ndifferent during training, a phenomenon called temporal misalignment. This is\nespecially a challenging problem because the research community still lacks a\ncoherent dataset for assessing the adaptability of LMs to frequently-updated\nknowledge corpus such as Wikipedia. To this end, we introduce TemporalWiki, a\nlifelong benchmark for ever-evolving LMs that utilizes the difference between\nconsecutive snapshots of English Wikipedia and English Wikidata for training\nand evaluation, respectively. The benchmark hence allows researchers to\nperiodically track an LM's ability to retain previous knowledge and acquire\nupdated/new knowledge at each point in time. We also find that training an LM\non the diff data through continual learning methods achieves similar or better\nperplexity than on the entire snapshot in our benchmark with 12 times less\ncomputational cost, which verifies that factual knowledge in LMs can be safely\nupdated with minimal training data via continual learning. The dataset and the\ncode are available at https://github.com/joeljang/temporalwiki.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1\">Joel Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1\">Seonghyeon Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Changho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Sohee Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Joongbo Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Janghoon Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gyeonghun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1\">Minjoon Seo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adversarial Self-Attention for Language Understanding. (arXiv:2206.12608v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.12608","description":"<p>Deep neural models (e.g. Transformer) naturally learn spurious features,\nwhich create a ``shortcut'' between the labels and inputs, thus impairing the\ngeneralization and robustness. This paper advances the self-attention mechanism\nto its robust variant for Transformer-based pre-trained language models (e.g.\nBERT). We propose \\textit{Adversarial Self-Attention} mechanism (ASA), which\nadversarially biases the attentions to effectively suppress the model reliance\non features (e.g. specific keywords) and encourage its exploration of broader\nsemantics. We conduct a comprehensive evaluation across a wide range of tasks\nfor both pre-training and fine-tuning stages. For pre-training, ASA unfolds\nremarkable performance gains compared to naive training for longer steps. For\nfine-tuning, ASA-empowered models outweigh naive models by a large margin\nconsidering both generalization and robustness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hongqiu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_R/0/1/0/all/0/1\">Ruixue Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pengjun Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How trial-to-trial learning shapes mappings in the mental lexicon: Modelling Lexical Decision with Linear Discriminative Learning. (arXiv:2207.00430v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2207.00430","description":"<p>Trial-to-trial effects have been found in a number of studies, indicating\nthat processing a stimulus influences responses in subsequent trials. A special\ncase are priming effects which have been modelled successfully with\nerror-driven learning (Marsolek, 2008), implying that participants are\ncontinuously learning during experiments. This study investigates whether\ntrial-to-trial learning can be detected in an unprimed lexical decision\nexperiment. We used the Discriminative Lexicon Model (DLM; Baayen et al.,\n2019), a model of the mental lexicon with meaning representations from\ndistributional semantics, which models error-driven incremental learning with\nthe Widrow-Hoff rule. We used data from the British Lexicon Project (BLP;\nKeuleers et al., 2012) and simulated the lexical decision experiment with the\nDLM on a trial-by-trial basis for each subject individually. Then, reaction\ntimes were predicted with Generalised Additive Models (GAMs), using measures\nderived from the DLM simulations as predictors. We extracted measures from two\nsimulations per subject (one with learning updates between trials and one\nwithout), and used them as input to two GAMs. Learning-based models showed\nbetter model fit than the non-learning ones for the majority of subjects. Our\nmeasures also provide insights into lexical processing and individual\ndifferences. This demonstrates the potential of the DLM to model behavioural\ndata and leads to the conclusion that trial-to-trial learning can indeed be\ndetected in unprimed lexical decision. Our results support the possibility that\nour lexical knowledge is subject to continuous changes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Heitmeier_M/0/1/0/all/0/1\">Maria Heitmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1\">Yu-Ying Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baayen_R/0/1/0/all/0/1\">R. Harald Baayen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents. (arXiv:2207.01206v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2207.01206","description":"<p>Existing benchmarks for grounding language in interactive environments either\nlack real-world linguistic elements, or prove difficult to scale up due to\nsubstantial human involvement in the collection of data or feedback signals. To\nbridge this gap, we develop WebShop -- a simulated e-commerce website\nenvironment with $1.18$ million real-world products and $12,087$ crowd-sourced\ntext instructions. Given a text instruction specifying a product requirement,\nan agent needs to navigate multiple types of webpages and issue diverse actions\nto find, customize, and purchase an item. WebShop provides several challenges\nfor language grounding including understanding compositional instructions,\nquery (re-)formulation, comprehending and acting on noisy text in webpages, and\nperforming strategic exploration. We collect over $1,600$ human demonstrations\nfor the task, and train and evaluate a diverse range of agents using\nreinforcement learning, imitation learning, and pre-trained image and language\nmodels. Our best model achieves a task success rate of $29\\%$, which\noutperforms rule-based heuristics ($9.6\\%$) but is far lower than human expert\nperformance ($59\\%$). We also analyze agent and human trajectories and ablate\nvarious model components to provide insights for developing future agents with\nstronger language understanding and decision making abilities. Finally, we show\nthat agents trained on WebShop exhibit non-trivial sim-to-real transfer when\nevaluated on amazon.com and ebay.com, indicating the potential value of WebShop\nin developing practical web-based agents that can operate in the wild.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_S/0/1/0/all/0/1\">Shunyu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Howard Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">John Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Grounded Planning for Embodied Tasks with Language Models. (arXiv:2209.00465v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2209.00465","description":"<p>Language models (LMs) have demonstrated their capability in possessing\ncommonsense knowledge of the physical world, a crucial aspect of performing\ntasks in everyday life. However, it remains unclear whether they have the\ncapacity to generate grounded, executable plans for embodied tasks. This is a\nchallenging task as LMs lack the ability to perceive the environment through\nvision and feedback from the physical environment. In this paper, we address\nthis important research question and present the first investigation into the\ntopic. Our novel problem formulation, named G-PlanET, inputs a high-level goal\nand a data table about objects in a specific environment, and then outputs a\nstep-by-step actionable plan for a robotic agent to follow. To facilitate the\nstudy, we establish an evaluation protocol and design a dedicated metric, KAS,\nto assess the quality of the plans. Our experiments demonstrate that the use of\ntables for encoding the environment and an iterative decoding strategy can\nsignificantly enhance the LMs' ability in grounded planning. Our analysis also\nreveals interesting and non-trivial findings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chengsong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_W/0/1/0/all/0/1\">Wenda Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sommerer_S/0/1/0/all/0/1\">Sam Sommerer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ViLPAct: A Benchmark for Compositional Generalization on Multimodal Human Activities. (arXiv:2210.05556v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2210.05556","description":"<p>We introduce ViLPAct, a novel vision-language benchmark for human activity\nplanning. It is designed for a task where embodied AI agents can reason and\nforecast future actions of humans based on video clips about their initial\nactivities and intents in text. The dataset consists of 2.9k videos from\n\\charades extended with intents via crowdsourcing, a multi-choice question test\nset, and four strong baselines. One of the baselines implements a neurosymbolic\napproach based on a multi-modal knowledge base (MKB), while the other ones are\ndeep generative models adapted from recent state-of-the-art (SOTA) methods.\nAccording to our extensive experiments, the key challenges are compositional\ngeneralization and effective use of information from both modalities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_T/0/1/0/all/0/1\">Terry Yue Zhuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yaqing Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1\">Yuecheng Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Lizhen Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melo_G/0/1/0/all/0/1\">Gerard de Melo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1\">Xiaojun Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yazhou Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RedHOT: A Corpus of Annotated Medical Questions, Experiences, and Claims on Social Media. (arXiv:2210.06331v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.06331","description":"<p>We present Reddit Health Online Talk (RedHOT), a corpus of 22,000 richly\nannotated social media posts from Reddit spanning 24 health conditions.\nAnnotations include demarcations of spans corresponding to medical claims,\npersonal experiences, and questions. We collect additional granular annotations\non identified claims. Specifically, we mark snippets that describe patient\nPopulations, Interventions, and Outcomes (PIO elements) within these. Using\nthis corpus, we introduce the task of retrieving trustworthy evidence relevant\nto a given claim made on social media. We propose a new method to automatically\nderive (noisy) supervision for this task which we use to train a dense\nretrieval model; this outperforms baseline models. Manual evaluation of\nretrieval results performed by medical doctors indicate that while our system\nperformance is promising, there is considerable room for improvement. Collected\nannotations (and scripts to assemble the dataset), are available at\nhttps://github.com/sominw/redhot.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wadhwa_S/0/1/0/all/0/1\">Somin Wadhwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khetan_V/0/1/0/all/0/1\">Vivek Khetan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amir_S/0/1/0/all/0/1\">Silvio Amir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1\">Byron Wallace</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Joint Reasoning on Hybrid-knowledge sources for Task-Oriented Dialog. (arXiv:2210.07295v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.07295","description":"<p>Traditional systems designed for task oriented dialog utilize knowledge\npresent only in structured knowledge sources to generate responses. However,\nrelevant information required to generate responses may also reside in\nunstructured sources, such as documents. Recent state of the art models such as\nHyKnow and SeKnow aimed at overcoming these challenges make limiting\nassumptions about the knowledge sources. For instance, these systems assume\nthat certain types of information, such as a phone number, is always present in\na structured knowledge base (KB) while information about aspects such as\nentrance ticket prices, would always be available in documents.\n</p>\n<p>In this paper, we create a modified version of the MutliWOZ-based dataset\nprepared by SeKnow to demonstrate how current methods have significant\ndegradation in performance when strict assumptions about the source of\ninformation are removed. Then, in line with recent work exploiting pre-trained\nlanguage models, we fine-tune a BART based model using prompts for the tasks of\nquerying knowledge sources, as well as, for response generation, without making\nassumptions about the information present in each knowledge source. Through a\nseries of experiments, we demonstrate that our model is robust to perturbations\nto knowledge modality (source of information), and that it can fuse information\nfrom structured as well as unstructured knowledge to generate responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_M/0/1/0/all/0/1\">Mayank Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Contractor_D/0/1/0/all/0/1\">Danish Contractor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raghu_D/0/1/0/all/0/1\">Dinesh Raghu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generating Synthetic Speech from SpokenVocab for Speech Translation. (arXiv:2210.08174v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.08174","description":"<p>Training end-to-end speech translation (ST) systems requires sufficiently\nlarge-scale data, which is unavailable for most language pairs and domains. One\npractical solution to the data scarcity issue is to convert machine translation\ndata (MT) to ST data via text-to-speech (TTS) systems. Yet, using TTS systems\ncan be tedious and slow, as the conversion needs to be done for each MT\ndataset. In this work, we propose a simple, scalable and effective data\naugmentation technique, i.e., SpokenVocab, to convert MT data to ST data\non-the-fly. The idea is to retrieve and stitch audio snippets from a\nSpokenVocab bank according to words in an MT sequence. Our experiments on\nmultiple language pairs from Must-C show that this method outperforms strong\nbaselines by an average of 1.83 BLEU scores, and it performs equally well as\nTTS-generated speech. We also showcase how SpokenVocab can be applied in\ncode-switching ST for which often no TTS systems exit. Our code is available at\nhttps://github.com/mingzi151/SpokenVocab\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jinming Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffar_G/0/1/0/all/0/1\">Gholamreza Haffar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shareghi_E/0/1/0/all/0/1\">Ehsan Shareghi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Monitor Model and its Misconceptions: A Clarification. (arXiv:2210.14367v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.14367","description":"<p>Horizontal (automatic) and vertical (control) processes have been observed\nand reported for a long time in translation production. Schaeffer and Carl's\nMonitor Model integrates these two processes into one framework, assuming that\npriming mechanisms underlie horizontal/automatic processes, while\nvertical/monitoring processes implement consciously accessible control\nmechanisms. The Monitor Model has been criticized in various ways and several\nmisconceptions have accumulated over the past years. In this chapter, I update\nthe Monitor Model with additional evidence and argue that it is compatible with\nan enactivist approach to cognition. I address several misconceptions related\nto the Monitor Model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Carl_M/0/1/0/all/0/1\">Michael Carl</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on In-context Learning. (arXiv:2301.00234v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.00234","description":"<p>With the increasing ability of large language models (LLMs), in-context\nlearning (ICL) has become a new paradigm for natural language processing (NLP),\nwhere LLMs make predictions only based on contexts augmented with a few\nexamples. It has been a new trend to explore ICL to evaluate and extrapolate\nthe ability of LLMs. In this paper, we aim to survey and summarize the progress\nand challenges of ICL. We first present a formal definition of ICL and clarify\nits correlation to related studies. Then, we organize and discuss advanced\ntechniques, including training strategies, demonstration designing strategies,\nas well as related analysis. Finally, we discuss the challenges of ICL and\nprovide potential directions for further research. We hope that our work can\nencourage more research on uncovering how ICL works and improving ICL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dong_Q/0/1/0/all/0/1\">Qingxiu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Damai Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Ce Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jingjing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Syntax-guided Neural Module Distillation to Probe Compositionality in Sentence Embeddings. (arXiv:2301.08998v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.08998","description":"<p>Past work probing compositionality in sentence embedding models faces issues\ndetermining the causal impact of implicit syntax representations. Given a\nsentence, we construct a neural module net based on its syntax parse and train\nit end-to-end to approximate the sentence's embedding generated by a\ntransformer model. The distillability of a transformer to a Syntactic NeurAl\nModule Net (SynNaMoN) then captures whether syntax is a strong causal model of\nits compositional ability. Furthermore, we address questions about the geometry\nof semantic composition by specifying individual SynNaMoN modules' internal\narchitecture &amp; linearity. We find differences in the distillability of various\nsentence embedding models that broadly correlate with their performance, but\nobserve that distillability doesn't considerably vary by model size. We also\npresent preliminary evidence that much syntax-guided composition in sentence\nembedding models is linear, and that non-linearities may serve primarily to\nhandle non-compositional phrases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_R/0/1/0/all/0/1\">Rohan Pandey</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quantifying Context Mixing in Transformers. (arXiv:2301.12971v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.12971","description":"<p>Self-attention weights and their transformed variants have been the main\nsource of information for analyzing token-to-token interactions in\nTransformer-based models. But despite their ease of interpretation, these\nweights are not faithful to the models' decisions as they are only one part of\nan encoder, and other components in the encoder layer can have considerable\nimpact on information mixing in the output representations. In this work, by\nexpanding the scope of analysis to the whole encoder block, we propose Value\nZeroing, a novel context mixing score customized for Transformers that provides\nus with a deeper understanding of how information is mixed at each encoder\nlayer. We demonstrate the superiority of our context mixing score over other\nanalysis methods through a series of complementary evaluations with different\nviewpoints based on linguistically informed rationales, probing, and\nfaithfulness analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mohebbi_H/0/1/0/all/0/1\">Hosein Mohebbi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuidema_W/0/1/0/all/0/1\">Willem Zuidema</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chrupala_G/0/1/0/all/0/1\">Grzegorz Chrupa&#x142;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alishahi_A/0/1/0/all/0/1\">Afra Alishahi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Entity Alignment for Temporal Knowledge Graphs. (arXiv:2302.00796v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2302.00796","description":"<p>Entity alignment (EA) is a fundamental data integration task that identifies\nequivalent entities between different knowledge graphs (KGs). Temporal\nKnowledge graphs (TKGs) extend traditional knowledge graphs by introducing\ntimestamps, which have received increasing attention. State-of-the-art\ntime-aware EA studies have suggested that the temporal information of TKGs\nfacilitates the performance of EA. However, existing studies have not\nthoroughly exploited the advantages of temporal information in TKGs. Also, they\nperform EA by pre-aligning entity pairs, which can be labor-intensive and thus\ninefficient.\n</p>\n<p>In this paper, we present DualMatch which effectively fuses the relational\nand temporal information for EA. DualMatch transfers EA on TKGs into a weighted\ngraph matching problem. More specifically, DualMatch is equipped with an\nunsupervised method, which achieves EA without necessitating seed alignment.\nDualMatch has two steps: (i) encoding temporal and relational information into\nembeddings separately using a novel label-free encoder, Dual-Encoder; and (ii)\nfusing both information and transforming it into alignment using a novel\ngraph-matching-based decoder, GM-Decoder. DualMatch is able to perform EA on\nTKGs with or without supervision, due to its capability of effectively\ncapturing temporal information. Extensive experiments on three real-world TKG\ndatasets offer the insight that DualMatch outperforms the state-of-the-art\nmethods in terms of H@1 by 2.4% - 10.7% and MRR by 1.7% - 7.6%, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoze Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Junyang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yunjun Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Curriculum-Guided Abstractive Summarization. (arXiv:2302.01342v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.01342","description":"<p>Recent Transformer-based summarization models have provided a promising\napproach to abstractive summarization. They go beyond sentence selection and\nextractive strategies to deal with more complicated tasks such as novel word\ngeneration and sentence paraphrasing. Nonetheless, these models have two\nshortcomings: (1) they often perform poorly in content selection, and (2) their\ntraining strategy is not quite efficient, which restricts model performance. In\nthis paper, we explore two orthogonal ways to compensate for these pitfalls.\nFirst, we augment the Transformer network with a sentence cross-attention\nmodule in the decoder, encouraging more abstraction of salient content. Second,\nwe include a curriculum learning approach to reweight the training samples,\nbringing about an efficient learning procedure. Our second approach to enhance\nthe training strategy of Transformers networks makes stronger gains as compared\nto the first approach. We apply our model on extreme summarization dataset of\nReddit TIFU posts. We further look into three cross-domain summarization\ndatasets (Webis-TLDR-17, CNN/DM, and XSum), measuring the efficacy of\ncurriculum learning when applied in summarization. Moreover, a human evaluation\nis conducted to show the efficacy of the proposed method in terms of\nqualitative criteria, namely, fluency, informativeness, and overall quality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sotudeh_S/0/1/0/all/0/1\">Sajad Sotudeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deilamsalehy_H/0/1/0/all/0/1\">Hanieh Deilamsalehy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dernoncourt_F/0/1/0/all/0/1\">Franck Dernoncourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goharian_N/0/1/0/all/0/1\">Nazli Goharian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Semantic Approach to Negation Detection and Word Disambiguation with Natural Language Processing. (arXiv:2302.02291v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.02291","description":"<p>This study aims to demonstrate the methods for detecting negations in a\nsentence by uniquely evaluating the lexical structure of the text via word\nsense disambiguation. Additionally, the proposed method examined all the unique\nfeatures of the related expressions within a text to resolve the contextual\nusage of the sentence and the effect of negation on sentiment analysis. The\napplication of popular expression detectors skips this important step, thereby\nneglecting the root words caught in the web of negation, and making text\nclassification difficult for machine learning and sentiment analysis. This\nstudy adopts the Natural Language Processing (NLP) approach to discover and\nantonimize words that were negated for better accuracy in text classification.\nThis method acts as a lens that reads through a given word sequence using a\nknowledge base provided by an NLP library called WordHoard in order to detect\nnegation signals. Early results show that our initial analysis improved\ntraditional sentiment analysis that sometimes neglects word negations or\nassigns an inverse polarity score. The SentiWordNet analyzer was improved by\n35%, the Vader analyzer by 20% and the TextBlob analyzer by 6%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Okpala_I/0/1/0/all/0/1\">Izunna Okpala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_G/0/1/0/all/0/1\">Guillermo Romera Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tapia_A/0/1/0/all/0/1\">Andrea Tapia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halse_S/0/1/0/all/0/1\">Shane Halse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kropczynski_J/0/1/0/all/0/1\">Jess Kropczynski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PLACES: Prompting Language Models for Social Conversation Synthesis. (arXiv:2302.03269v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.03269","description":"<p>Collecting high quality conversational data can be very expensive for most\napplications and infeasible for others due to privacy, ethical, or similar\nconcerns. A promising direction to tackle this problem is to generate synthetic\ndialogues by prompting large language models. In this work, we use a small set\nof expert-written conversations as in-context examples to synthesize a social\nconversation dataset using prompting. We perform several thorough evaluations\nof our synthetic conversations compared to human-collected conversations. This\nincludes various dimensions of conversation quality with human evaluation\ndirectly on the synthesized conversations, and interactive human evaluation of\nchatbots fine-tuned on the synthetically generated dataset. We additionally\ndemonstrate that this prompting approach is generalizable to multi-party\nconversations, providing potential to create new synthetic data for multi-party\ntasks. Our synthetic multi-party conversations were rated more favorably across\nall measured dimensions compared to conversation excerpts sampled from a\nhuman-collected multi-party dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Maximillian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papangelis_A/0/1/0/all/0/1\">Alexandros Papangelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1\">Chenyang Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seokhwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenbaum_A/0/1/0/all/0/1\">Andy Rosenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1\">Dilek Hakkani-Tur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Arabic Named Entity Recognition: Past, Recent Advances, and Future Trends. (arXiv:2302.03512v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.03512","description":"<p>As more and more Arabic texts emerged on the Internet, extracting important\ninformation from these Arabic texts is especially useful. As a fundamental\ntechnology, Named entity recognition (NER) serves as the core component in\ninformation extraction technology, while also playing a critical role in many\nother Natural Language Processing (NLP) systems, such as question answering and\nknowledge graph building. In this paper, we provide a comprehensive review of\nthe development of Arabic NER, especially the recent advances in deep learning\nand pre-trained language model. Specifically, we first introduce the background\nof Arabic NER, including the characteristics of Arabic and existing resources\nfor Arabic NER. Then, we systematically review the development of Arabic NER\nmethods. Traditional Arabic NER systems focus on feature engineering and\ndesigning domain-specific rules. In recent years, deep learning methods achieve\nsignificant progress by representing texts via continuous vector\nrepresentations. With the growth of pre-trained language model, Arabic NER\nyields better performance. Finally, we conclude the method gap between Arabic\nNER and NER methods from other languages, which helps outline future directions\nfor Arabic NER.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1\">Xiaoye Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yingjie Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Q/0/1/0/all/0/1\">Qingrong Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zechang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhefeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huai_B/0/1/0/all/0/1\">Baoxing Huai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploitation and exploration in text evolution. Quantifying planning and translation flows during writing. (arXiv:2302.03645v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.03645","description":"<p>Writing is a complex process at the center of much of modern human activity.\nDespite it appears to be a linear process, writing conceals many highly\nnon-linear processes. Previous research has focused on three phases of writing:\nplanning, translation and transcription, and revision. While research has shown\nthese are non-linear, they are often treated linearly when measured. Here, we\nintroduce measures to detect and quantify subcycles of planning (exploration)\nand translation (exploitation) during the writing process. We apply these to a\nnovel dataset that recorded the creation of a text in all its phases, from\nearly attempts to the finishing touches on a final version. This dataset comes\nfrom a series of writing workshops in which, through innovative versioning\nsoftware, we were able to record all the steps in the construction of a text.\nMore than 60 junior researchers in science wrote a scientific essay intended\nfor a general readership. We recorded each essay as a writing cloud, defined as\na complex topological structure capturing the history of the essay itself.\nThrough this unique dataset of writing clouds, we expose a representation of\nthe writing process that quantifies its complexity and the writer's efforts\nthroughout the draft and through time. Interestingly, this representation\nhighlights the phases of \"translation flow\", where authors improve existing\nideas, and exploration, where creative deviations appear as the writer returns\nto the planning phase. These turning points between translation and exploration\nbecome rarer as the writing process progresses and the author approaches the\nfinal version. Our results and the new measures introduced have the potential\nto foster the discussion about the non-linear nature of writing and support the\ndevelopment of tools that can support more creative and impactful writing\nprocesses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sardo_D/0/1/0/all/0/1\">Donald Ruggiero Lo Sardo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gravino_P/0/1/0/all/0/1\">Pietro Gravino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cuskley_C/0/1/0/all/0/1\">Christine Cuskley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loreto_V/0/1/0/all/0/1\">Vittorio Loreto</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Auditing Gender Presentation Differences in Text-to-Image Models. (arXiv:2302.03675v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2302.03675","description":"<p>Text-to-image models, which can generate high-quality images based on textual\ninput, have recently enabled various content-creation tools. Despite\nsignificantly affecting a wide range of downstream applications, the\ndistributions of these generated images are still not fully understood,\nespecially when it comes to the potential stereotypical attributes of different\ngenders. In this work, we propose a paradigm (Gender Presentation Differences)\nthat utilizes fine-grained self-presentation attributes to study how gender is\npresented differently in text-to-image models. By probing gender indicators in\nthe input text (e.g., \"a woman\" or \"a man\"), we quantify the frequency\ndifferences of presentation-centric attributes (e.g., \"a shirt\" and \"a dress\")\nthrough human annotation and introduce a novel metric: GEP. Furthermore, we\npropose an automatic method to estimate such differences. The automatic GEP\nmetric based on our approach yields a higher correlation with human annotations\nthan that based on existing CLIP scores, consistently across three\nstate-of-the-art text-to-image models. Finally, we demonstrate the\ngeneralization ability of our metrics in the context of gender stereotypes\nrelated to occupations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yanzhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Lu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turk_G/0/1/0/all/0/1\">Greg Turk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-02-08T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#"}}]}]}