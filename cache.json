{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2022-12-27T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Neural Transition-based Parsing of Library Deprecations. (arXiv:2212.12584v1 [cs.CL])","link":"http://arxiv.org/abs/2212.12584","description":"<p>This paper tackles the challenging problem of automating code updates to fix\ndeprecated API usages of open source libraries by analyzing their release\nnotes. Our system employs a three-tier architecture: first, a web crawler\nservice retrieves deprecation documentation from the web; then a specially\nbuilt parser processes those text documents into tree-structured\nrepresentations; finally, a client IDE plugin locates and fixes identified\ndeprecated usages of libraries in a given codebase. The focus of this paper in\nparticular is the parsing component. We introduce a novel transition-based\nparser in two variants: based on a classical feature engineered classifier and\na neural tree encoder. To confirm the effectiveness of our method, we gathered\nand labeled a set of 426 API deprecations from 7 well-known Python data science\nlibraries, and demonstrated our approach decisively outperforms a non-trivial\nneural machine translation baseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Babkin_P/0/1/0/all/0/1\">Petr Babkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navarro_N/0/1/0/all/0/1\">Nacho Navarro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alamir_S/0/1/0/all/0/1\">Salwa Alamir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1\">Sameena Shah</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Utilizing Priming to Identify Optimal Class Ordering to Alleviate Catastrophic Forgetting. (arXiv:2212.12643v1 [cs.LG])","link":"http://arxiv.org/abs/2212.12643","description":"<p>In order for artificial neural networks to begin accurately mimicking\nbiological ones, they must be able to adapt to new exigencies without\nforgetting what they have learned from previous training. Lifelong learning\napproaches to artificial neural networks attempt to strive towards this goal,\nyet have not progressed far enough to be realistically deployed for natural\nlanguage processing tasks. The proverbial roadblock of catastrophic forgetting\nstill gate-keeps researchers from an adequate lifelong learning model. While\nefforts are being made to quell catastrophic forgetting, there is a lack of\nresearch that looks into the importance of class ordering when training on new\nclasses for incremental learning. This is surprising as the ordering of\n\"classes\" that humans learn is heavily monitored and incredibly important.\nWhile heuristics to develop an ideal class order have been researched, this\npaper examines class ordering as it relates to priming as a scheme for\nincremental class learning. By examining the connections between various\nmethods of priming found in humans and how those are mimicked yet remain\nunexplained in life-long machine learning, this paper provides a better\nunderstanding of the similarities between our biological systems and the\nsynthetic systems while simultaneously improving current practices to combat\ncatastrophic forgetting. Through the merging of psychological priming practices\nwith class ordering, this paper is able to identify a generalizable method for\nclass ordering in NLP incremental learning tasks that consistently outperforms\nrandom class ordering.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mantione_Holmes_G/0/1/0/all/0/1\">Gabriel Mantione-Holmes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leo_J/0/1/0/all/0/1\">Justin Leo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalita_J/0/1/0/all/0/1\">Jugal Kalita</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension. (arXiv:2212.12652v1 [cs.CL])","link":"http://arxiv.org/abs/2212.12652","description":"<p>Abstractive dialogue summarization has long been viewed as an important\nstandalone task in natural language processing, but no previous work has\nexplored the possibility of whether abstractive dialogue summarization can also\nbe used as a means to boost an NLP system's performance on other important\ndialogue comprehension tasks. In this paper, we propose a novel type of\ndialogue summarization task - STRUctured DiaLoguE Summarization - that can help\npre-trained language models to better understand dialogues and improve their\nperformance on important dialogue comprehension tasks. We further collect human\nannotations of STRUDEL summaries over 400 dialogues and introduce a new STRUDEL\ndialogue comprehension modeling framework that integrates STRUDEL into a\ngraph-neural-network-based dialogue reasoning module over transformer encoder\nlanguage models to improve their dialogue comprehension abilities. In our\nempirical experiments on two important downstream dialogue comprehension tasks\n- dialogue question answering and dialogue response prediction - we show that\nour STRUDEL dialogue comprehension model can significantly improve the dialogue\ncomprehension performance of transformer encoder language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Borui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1\">Chengcheng Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1\">Arjun Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_M/0/1/0/all/0/1\">Madelyn Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desai_J/0/1/0/all/0/1\">Jai Desai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehdad_Y/0/1/0/all/0/1\">Yashar Mehdad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Optimizing Deep Transformers for Chinese-Thai Low-Resource Translation. (arXiv:2212.12662v1 [cs.CL])","link":"http://arxiv.org/abs/2212.12662","description":"<p>In this paper, we study the use of deep Transformer translation model for the\nCCMT 2022 Chinese-Thai low-resource machine translation task. We first explore\nthe experiment settings (including the number of BPE merge operations, dropout\nprobability, embedding size, etc.) for the low-resource scenario with the\n6-layer Transformer. Considering that increasing the number of layers also\nincreases the regularization on new model parameters (dropout modules are also\nintroduced when using more layers), we adopt the highest performance setting\nbut increase the depth of the Transformer to 24 layers to obtain improved\ntranslation quality. Our work obtains the SOTA performance in the\nChinese-to-Thai translation in the constrained evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hao_W/0/1/0/all/0/1\">Wenjie Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hongfei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_L/0/1/0/all/0/1\">Lingling Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zan_H/0/1/0/all/0/1\">Hongying Zan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Real or Fake Text?: Investigating Human Ability to Detect Boundaries Between Human-Written and Machine-Generated Text. (arXiv:2212.12672v1 [cs.CL])","link":"http://arxiv.org/abs/2212.12672","description":"<p>As text generated by large language models proliferates, it becomes vital to\nunderstand how humans engage with such text, and whether or not they are able\nto detect when the text they are reading did not originate with a human writer.\nPrior work on human detection of generated text focuses on the case where an\nentire passage is either human-written or machine-generated. In this paper, we\nstudy a more realistic setting where text begins as human-written and\ntransitions to being generated by state-of-the-art neural language models. We\nshow that, while annotators often struggle at this task, there is substantial\nvariance in annotator skill and that given proper incentives, annotators can\nimprove at this task over time. Furthermore, we conduct a detailed comparison\nstudy and analyze how a variety of variables (model size, decoding strategy,\nfine-tuning, prompt genre, etc.) affect human detection performance. Finally,\nwe collect error annotations from our participants and use them to show that\ncertain textual genres influence models to make different types of errors and\nthat certain sentence-level features correlate highly with annotator selection.\nWe release the RoFT dataset: a collection of over 21,000 human annotations\npaired with error classifications to encourage future work in human detection\nand evaluation of generated text.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dugan_L/0/1/0/all/0/1\">Liam Dugan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ippolito_D/0/1/0/all/0/1\">Daphne Ippolito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirubarajan_A/0/1/0/all/0/1\">Arun Kirubarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Sherry Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1\">Chris Callison-Burch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Development of a Thermodynamics of Human Cognition and Human Culture. (arXiv:2212.12795v1 [q-bio.NC])","link":"http://arxiv.org/abs/2212.12795","description":"<p>Inspired by foundational studies in classical and quantum physics, and by\ninformation retrieval studies in quantum information theory, we have recently\nproved that the notions of 'energy' and 'entropy' can be consistently\nintroduced in human language and, more generally, in human culture. More\nexplicitly, if energy is attributed to words according to their frequency of\nappearance in a text, then the ensuing energy levels are distributed\nnon-classically, namely, they obey Bose-Einstein, rather than\nMaxwell-Boltzmann, statistics, as a consequence of the genuinely 'quantum\nindistinguishability' of the words that appear in the text. Secondly, the\n'quantum entanglement' due to the way meaning is carried by a text reduces the\n(von Neumann) entropy of the words that appear in the text, a behaviour which\ncannot be explained within classical (thermodynamic or information) entropy. We\nclaim here that this 'quantum-type behaviour is valid in general in human\ncognition', namely, any text is conceptually more concrete than the words\ncomposing it, which entails that the entropy of the overall text decreases.\nThis result can be prolonged to human culture and its collaborative entities\nhaving lower entropy than their constituent elements. We use these findings to\npropose the development of a new 'non-classical thermodynamic theory for human\ncognition and human culture', which bridges concepts and quantum entities and\nagrees with some recent findings on the conceptual, not physical, nature of\nquantum entities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-bio/1/au:+Aerts_D/0/1/0/all/0/1\">Diederik Aerts</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Arguelles_J/0/1/0/all/0/1\">Jonito Aerts Argu&#xeb;lles</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Beltran_L/0/1/0/all/0/1\">Lester Beltran</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sozzo_S/0/1/0/all/0/1\">Sandro Sozzo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Study of Gender Bias in Chemical Named Entity Recognition Models. (arXiv:2212.12799v1 [cs.CL])","link":"http://arxiv.org/abs/2212.12799","description":"<p>Objective. Chemical named entity recognition (NER) models have the potential\nto impact a wide range of downstream tasks, from identifying adverse drug\nreactions to general pharmacoepidemiology. However, it is unknown whether these\nmodels work the same for everyone. Performance disparities can potentially\ncause harm rather than the intended good. Hence, in this paper, we measure\ngender-related performance disparities of chemical NER systems.\n</p>\n<p>Materials and Methods. We develop a framework to measure gender bias in\nchemical NER models using synthetic data and a newly annotated dataset of over\n92,405 words with self-identified gender information from Reddit. We applied\nand evaluated state-of-the-art biomedical NER models.\n</p>\n<p>Results. Our findings indicate that chemical NER models are biased. The\nresults of the bias tests on the synthetic dataset and the real-world data\nmultiple fairness issues. For example, for synthetic data, we find that\nfemale-related names are generally classified as chemicals, particularly in\ndatasets containing many brand names rather than standard ones. For both\ndatasets, we find consistent fairness issues resulting in substantial\nperformance disparities between female- and male-related data.\n</p>\n<p>Discussion. Our study highlights the issue of biases in chemical NER models.\nFor example, we find that many systems cannot detect contraceptives (e.g.,\nbirth control).\n</p>\n<p>Conclusion. Chemical NER models are biased and can be harmful to\nfemale-related groups. Therefore, practitioners should carefully consider the\npotential biases of these models and take steps to mitigate them.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xingmeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niazi_A/0/1/0/all/0/1\">Ali Niazi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rios_A/0/1/0/all/0/1\">Anthony Rios</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Marker-based Neural Network System for Extracting Social Determinants of Health. (arXiv:2212.12800v1 [cs.CL])","link":"http://arxiv.org/abs/2212.12800","description":"<p>Objective. The impact of social determinants of health (SDoH) on patients'\nhealthcare quality and the disparity is well-known. Many SDoH items are not\ncoded in structured forms in electronic health records. These items are often\ncaptured in free-text clinical notes, but there are limited methods for\nautomatically extracting them. We explore a multi-stage pipeline involving\nnamed entity recognition (NER), relation classification (RC), and text\nclassification methods to extract SDoH information from clinical notes\nautomatically.\n</p>\n<p>Materials and Methods. The study uses the N2C2 Shared Task data, which was\ncollected from two sources of clinical notes: MIMIC-III and University of\nWashington Harborview Medical Centers. It contains 4480 social history sections\nwith full annotation for twelve SDoHs. In order to handle the issue of\noverlapping entities, we developed a novel marker-based NER model. We used it\nin a multi-stage pipeline to extract SDoH information from clinical notes.\n</p>\n<p>Results. Our marker-based system outperformed the state-of-the-art span-based\nmodels at handling overlapping entities based on the overall Micro-F1 score\nperformance. It also achieved state-of-the-art performance compared to the\nshared task methods.\n</p>\n<p>Conclusion. The major finding of this study is that the multi-stage pipeline\neffectively extracts SDoH information from clinical notes. This approach can\npotentially improve the understanding and tracking of SDoHs in clinical\nsettings. However, error propagation may be an issue, and further research is\nneeded to improve the extraction of entities with complex semantic meanings and\nlow-resource entities using external knowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xingmeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rios_A/0/1/0/all/0/1\">Anthony Rios</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Linguistic Elements of Engaging Customer Service Discourse on Social Media. (arXiv:2212.12801v1 [cs.CL])","link":"http://arxiv.org/abs/2212.12801","description":"<p>Customers are rapidly turning to social media for customer support. While\nbrand agents on these platforms are motivated and well-intentioned to help and\nengage with customers, their efforts are often ignored if their initial\nresponse to the customer does not match a specific tone, style, or topic the\ncustomer is aiming to receive. The length of a conversation can reflect the\neffort and quality of the initial response made by a brand toward collaborating\nand helping consumers, even when the overall sentiment of the conversation\nmight not be very positive. Thus, through this study, we aim to bridge this\ncritical gap in the existing literature by analyzing language's content and\nstylistic aspects such as expressed empathy, psycho-linguistic features,\ndialogue tags, and metrics for quantifying personalization of the utterances\nthat can influence the engagement of an interaction. This paper demonstrates\nthat we can predict engagement using initial customer and brand posts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sonam Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rios_A/0/1/0/all/0/1\">Anthony Rios</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GAE-ISumm: Unsupervised Graph-Based Summarization of Indian Languages. (arXiv:2212.12937v1 [cs.CL])","link":"http://arxiv.org/abs/2212.12937","description":"<p>Document summarization aims to create a precise and coherent summary of a\ntext document. Many deep learning summarization models are developed mainly for\nEnglish, often requiring a large training corpus and efficient pre-trained\nlanguage models and tools. However, English summarization models for\nlow-resource Indian languages are often limited by rich morphological\nvariation, syntax, and semantic differences. In this paper, we propose\nGAE-ISumm, an unsupervised Indic summarization model that extracts summaries\nfrom text documents. In particular, our proposed model, GAE-ISumm uses Graph\nAutoencoder (GAE) to learn text representations and a document summary jointly.\nWe also provide a manually-annotated Telugu summarization dataset TELSUM, to\nexperiment with our model GAE-ISumm. Further, we experiment with the most\npublicly available Indian language summarization datasets to investigate the\neffectiveness of GAE-ISumm on other Indian languages. Our experiments of\nGAE-ISumm in seven languages make the following observations: (i) it is\ncompetitive or better than state-of-the-art results on all datasets, (ii) it\nreports benchmark results on TELSUM, and (iii) the inclusion of positional and\ncluster information in the proposed model improved the performance of\nsummaries.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vakada_L/0/1/0/all/0/1\">Lakshmi Sireesha Vakada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ch_A/0/1/0/all/0/1\">Anudeep Ch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marreddy_M/0/1/0/all/0/1\">Mounika Marreddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oota_S/0/1/0/all/0/1\">Subba Reddy Oota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mamidi_R/0/1/0/all/0/1\">Radhika Mamidi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Search, Structure, and Sentiment: A Comparative Analysis of Network Opinion in Different Query Types on Twitter. (arXiv:2212.12955v1 [cs.SI])","link":"http://arxiv.org/abs/2212.12955","description":"<p>Understanding the relationship between structure and sentiment is essential\nin highlighting future operations with online social networks. More\nspecifically, within popular conversation on Twitter. This paper provides a\ndevelopment on the relationship between the two variables: structure, defined\nas the composition of a directed network, and sentiment, a quantified value of\nthe positive/negative connotations of a conversation. We highlight thread\nsentiment to be inversely proportional to the strength and connectivity of a\nnetwork. The second portion of this paper highlights differences in query\ntypes, specifically how the aforementioned behavior differs within four key\nquery types. This paper focuses on topical, event-based, geographic, and\nindividual queries as orientations which have differing behavior. Using\ncross-query analysis, we see that the relationship between structure and\nsentiment, though still inversely proportional, differs greatly across query\ntypes. We find this relationship to be the most clear within the individual\nqueries and the least prevalent within the event-based queries. This paper\nprovides a sociological progression in our understanding of opinion and\nnetworks, while providing a methodological advancement for future studies on\nsimilar subjects.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Midha_J/0/1/0/all/0/1\">Joshua Midha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TextBox 2.0: A Text Generation Library with Pre-trained Language Models. (arXiv:2212.13005v1 [cs.CL])","link":"http://arxiv.org/abs/2212.13005","description":"<p>To facilitate research on text generation, this paper presents a\ncomprehensive and unified library, TextBox 2.0, focusing on the use of\npre-trained language models (PLMs). To be comprehensive, our library covers\n$13$ common text generation tasks and their corresponding $83$ datasets and\nfurther incorporates $45$ PLMs covering general, translation, Chinese,\ndialogue, controllable, distilled, prompting, and lightweight PLMs. We also\nimplement $4$ efficient training strategies and provide $4$ generation\nobjectives for pre-training new PLMs from scratch. To be unified, we design the\ninterfaces to support the entire research pipeline (from data loading to\ntraining and evaluation), ensuring that each step can be fulfilled in a unified\nway. Despite the rich functionality, it is easy to use our library, either\nthrough the friendly Python API or command line. To validate the effectiveness\nof our library, we conduct extensive experiments and exemplify four types of\nresearch scenarios. The project is released at the link:\nhttps://github.com/RUCAIBox/TextBox.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1\">Tianyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhipeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yiwen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhuohao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Wenxun Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zican Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xiaoxue Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1\">Jian-Yun Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Skit-S2I: An Indian Accented Speech to Intent dataset. (arXiv:2212.13015v1 [cs.CL])","link":"http://arxiv.org/abs/2212.13015","description":"<p>Conventional conversation assistants extract text transcripts from the speech\nsignal using automatic speech recognition (ASR) and then predict intent from\nthe transcriptions. Using end-to-end spoken language understanding (SLU), the\nintents of the speaker are predicted directly from the speech signal without\nrequiring intermediate text transcripts. As a result, the model can optimize\ndirectly for intent classification and avoid cascading errors from ASR. The\nend-to-end SLU system also helps in reducing the latency of the intent\nprediction model. Although many datasets are available publicly for\ntext-to-intent tasks, the availability of labeled speech-to-intent datasets is\nlimited, and there are no datasets available in the Indian accent. In this\npaper, we release the Skit-S2I dataset, the first publicly available\nIndian-accented SLU dataset in the banking domain in a conversational tonality.\nWe experiment with multiple baselines, compare different pretrained speech\nencoder's representations, and find that SSL pretrained representations perform\nslightly better than ASR pretrained representations lacking prosodic features\nfor speech-to-intent classification. The dataset and baseline code is available\nat \\url{https://github.com/skit-ai/speech-to-intent-dataset}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rajaa_S/0/1/0/all/0/1\">Shangeth Rajaa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalmia_S/0/1/0/all/0/1\">Swaraj Dalmia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nethil_K/0/1/0/all/0/1\">Kumarmanas Nethil</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Complex Knowledge Base Question Answering via Question-to-Action and Question-to-Question Alignment. (arXiv:2212.13036v1 [cs.CL])","link":"http://arxiv.org/abs/2212.13036","description":"<p>Complex knowledge base question answering can be achieved by converting\nquestions into sequences of predefined actions. However, there is a significant\nsemantic and structural gap between natural language and action sequences,\nwhich makes this conversion difficult. In this paper, we introduce an\nalignment-enhanced complex question answering framework, called ALCQA, which\nmitigates this gap through question-to-action alignment and\nquestion-to-question alignment. We train a question rewriting model to align\nthe question and each action, and utilize a pretrained language model to\nimplicitly align the question and KG artifacts. Moreover, considering that\nsimilar questions correspond to similar action sequences, we retrieve top-k\nsimilar question-answer pairs at the inference stage through\nquestion-to-question alignment and propose a novel reward-guided action\nsequence selection strategy to select from candidate action sequences. We\nconduct experiments on CQA and WQSP datasets, and the results show that our\napproach outperforms state-of-the-art methods and obtains a 9.88\\% improvements\nin the F1 metric on CQA dataset. Our source code is available at\nhttps://github.com/TTTTTTTTy/ALCQA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yechun Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xiaoxia Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Weiming Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The URW-KG: a Resource for Tackling the Underrepresentation of non-Western Writers. (arXiv:2212.13104v1 [cs.CL])","link":"http://arxiv.org/abs/2212.13104","description":"<p>Digital media have enabled the access to unprecedented literary knowledge.\nAuthors, readers, and scholars are now able to discover and share an increasing\namount of information about books and their authors. Notwithstanding, digital\narchives are still unbalanced: writers from non-Western countries are less\nrepresented, and such a condition leads to the perpetration of old forms of\ndiscrimination. In this paper, we present the Under-Represented Writers\nKnowledge Graph (URW-KG), a resource designed to explore and possibly amend\nthis lack of representation by gathering and mapping information about works\nand authors from Wikidata and three other sources: Open Library, Goodreads, and\nGoogle Books. The experiments based on KG embeddings showed that the integrated\ninformation encoded in the graph allows scholars and users to be more easily\nexposed to non-Western literary works and authors with respect to Wikidata\nalone. This opens to the development of fairer and effective tools for author\ndiscovery and exploration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stranisci_M/0/1/0/all/0/1\">Marco Antonio Stranisci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spillo_G/0/1/0/all/0/1\">Giuseppe Spillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musto_C/0/1/0/all/0/1\">Cataldo Musto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patti_V/0/1/0/all/0/1\">Viviana Patti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damiano_R/0/1/0/all/0/1\">Rossana Damiano</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Encode Clinical Knowledge. (arXiv:2212.13138v1 [cs.CL])","link":"http://arxiv.org/abs/2212.13138","description":"<p>Large language models (LLMs) have demonstrated impressive capabilities in\nnatural language understanding and generation, but the quality bar for medical\nand clinical applications is high. Today, attempts to assess models' clinical\nknowledge typically rely on automated evaluations on limited benchmarks. There\nis no standard to evaluate model predictions and reasoning across a breadth of\ntasks. To address this, we present MultiMedQA, a benchmark combining six\nexisting open question answering datasets spanning professional medical exams,\nresearch, and consumer queries; and HealthSearchQA, a new free-response dataset\nof medical questions searched online. We propose a framework for human\nevaluation of model answers along multiple axes including factuality,\nprecision, possible harm, and bias. In addition, we evaluate PaLM (a\n540-billion parameter LLM) and its instruction-tuned variant, Flan-PaLM, on\nMultiMedQA. Using a combination of prompting strategies, Flan-PaLM achieves\nstate-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA,\nMedMCQA, PubMedQA, MMLU clinical topics), including 67.6% accuracy on MedQA (US\nMedical License Exam questions), surpassing prior state-of-the-art by over 17%.\nHowever, human evaluation reveals key gaps in Flan-PaLM responses. To resolve\nthis we introduce instruction prompt tuning, a parameter-efficient approach for\naligning LLMs to new domains using a few exemplars. The resulting model,\nMed-PaLM, performs encouragingly, but remains inferior to clinicians. We show\nthat comprehension, recall of knowledge, and medical reasoning improve with\nmodel scale and instruction prompt tuning, suggesting the potential utility of\nLLMs in medicine. Our human evaluations reveal important limitations of today's\nmodels, reinforcing the importance of both evaluation frameworks and method\ndevelopment in creating safe, helpful LLM models for clinical applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singhal_K/0/1/0/all/0/1\">Karan Singhal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizi_S/0/1/0/all/0/1\">Shekoofeh Azizi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_T/0/1/0/all/0/1\">Tao Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahdavi_S/0/1/0/all/0/1\">S. Sara Mahdavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jason Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1\">Hyung Won Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scales_N/0/1/0/all/0/1\">Nathan Scales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanwani_A/0/1/0/all/0/1\">Ajay Tanwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cole_Lewis_H/0/1/0/all/0/1\">Heather Cole-Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfohl_S/0/1/0/all/0/1\">Stephen Pfohl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Payne_P/0/1/0/all/0/1\">Perry Payne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seneviratne_M/0/1/0/all/0/1\">Martin Seneviratne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gamble_P/0/1/0/all/0/1\">Paul Gamble</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kelly_C/0/1/0/all/0/1\">Chris Kelly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scharli_N/0/1/0/all/0/1\">Nathaneal Scharli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhery_A/0/1/0/all/0/1\">Aakanksha Chowdhery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansfield_P/0/1/0/all/0/1\">Philip Mansfield</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arcas_B/0/1/0/all/0/1\">Blaise Aguera y Arcas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Webster_D/0/1/0/all/0/1\">Dale Webster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corrado_G/0/1/0/all/0/1\">Greg S. Corrado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matias_Y/0/1/0/all/0/1\">Yossi Matias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_K/0/1/0/all/0/1\">Katherine Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gottweis_J/0/1/0/all/0/1\">Juraj Gottweis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomasev_N/0/1/0/all/0/1\">Nenad Tomasev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajkomar_A/0/1/0/all/0/1\">Alvin Rajkomar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barral_J/0/1/0/all/0/1\">Joelle Barral</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Semturs_C/0/1/0/all/0/1\">Christopher Semturs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karthikesalingam_A/0/1/0/all/0/1\">Alan Karthikesalingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Natarajan_V/0/1/0/all/0/1\">Vivek Natarajan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Biologically Inspired Design Concept Generation Using Generative Pre-Trained Transformers. (arXiv:2212.13196v1 [cs.CL])","link":"http://arxiv.org/abs/2212.13196","description":"<p>Biological systems in nature have evolved for millions of years to adapt and\nsurvive the environment. Many features they developed can be inspirational and\nbeneficial for solving technical problems in modern industries. This leads to a\nspecific form of design-by-analogy called bio-inspired design (BID). Although\nBID as a design method has been proven beneficial, the gap between biology and\nengineering continuously hinders designers from effectively applying the\nmethod. Therefore, we explore the recent advance of artificial intelligence\n(AI) for a data-driven approach to bridge the gap. This paper proposes a\ngenerative design approach based on the generative pre-trained language model\n(PLM) to automatically retrieve and map biological analogy and generate BID in\nthe form of natural language. The latest generative pre-trained transformer,\nnamely GPT-3, is used as the base PLM. Three types of design concept generators\nare identified and fine-tuned from the PLM according to the looseness of the\nproblem space representation. Machine evaluators are also fine-tuned to assess\nthe mapping relevancy between the domains within the generated BID concepts.\nThe approach is evaluated and then employed in a real-world project of\ndesigning light-weighted flying cars during its conceptual design phase The\nresults show our approach can generate BID concepts with good performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qihao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jianxi Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Highlighting Named Entities in Input for Auto-Formulation of Optimization Problems. (arXiv:2212.13201v1 [cs.CL])","link":"http://arxiv.org/abs/2212.13201","description":"<p>Operations research deals with modeling and solving real-world problems as\nmathematical optimization problems. While solving mathematical systems is\naccomplished by analytical software, formulating a problem as a set of\nmathematical operations has been typically done manually by domain experts.\nHowever, recent machine learning models have shown promise in converting\ntextual problem descriptions to corresponding mathematical formulations. In\nthis paper, we present an approach that converts linear programming word\nproblems into meaning representations that are structured and can be used by\noptimization solvers. Our approach uses the named entity-based enrichment to\naugment the input and achieves state-of-the-art accuracy, winning the second\ntask of the NL4Opt competition (https://nl4opt.github.io).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gangwar_N/0/1/0/all/0/1\">Neeraj Gangwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kani_N/0/1/0/all/0/1\">Nickvash Kani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Personalized Prediction of Offensive News Comments by Considering the Characteristics of Commenters. (arXiv:2212.13205v1 [cs.CL])","link":"http://arxiv.org/abs/2212.13205","description":"<p>When reading news articles on social networking services and news sites,\nreaders can view comments marked by other people on these articles. By reading\nthese comments, a reader can understand the public opinion about the news, and\nit is often helpful to grasp the overall picture of the news. However, these\ncomments often contain offensive language that readers do not prefer to read.\nThis study aims to predict such offensive comments to improve the quality of\nthe experience of the reader while reading comments. By considering the\ndiversity of the readers' values, the proposed method predicts offensive news\ncomments for each reader based on the feedback from a small number of news\ncomments that the reader rated as \"offensive\" in the past. In addition, we used\na machine learning model that considers the characteristics of the commenters\nto make predictions, independent of the words and topics in news comments. The\nexperimental results of the proposed method show that prediction can be\npersonalized even when the amount of readers' feedback data used in the\nprediction is limited. In particular, the proposed method, which considers the\ncommenters' characteristics, has a low probability of false detection of\noffensive comments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nakahara_T/0/1/0/all/0/1\">Teruki Nakahara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ushiama_T/0/1/0/all/0/1\">Taketoshi Ushiama</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning From Human Correction. (arXiv:2102.00225v10 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2102.00225","description":"<p>In industry NLP application, our manually labeled data has a certain number\nof noisy data. We present a simple method to find the noisy data and re-label\nthem manually, meanwhile we collect the correction information. Then we present\nnovel method to incorporate the human correction information into deep learning\nmodel. Human know how to correct noisy data. So the correction information can\nbe inject into deep learning model. We do the experiment on our own text\nclassification dataset, which is manually labeled, because we re-label the\nnoisy data in our dataset for our industry application. The experiment result\nshows that our method improve the classification accuracy from 91.7% to 92.5%.\nThe 91.7% accuracy is trained on the corrected dataset, which improve the\nbaseline from 83.3% to 91.7%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1\">Tong Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Making Attention Mechanisms More Robust and Interpretable with Virtual Adversarial Training. (arXiv:2104.08763v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08763","description":"<p>Although attention mechanisms have become fundamental components of deep\nlearning models, they are vulnerable to perturbations, which may degrade the\nprediction performance and model interpretability. Adversarial training (AT)\nfor attention mechanisms has successfully reduced such drawbacks by considering\nadversarial perturbations. However, this technique requires label information,\nand thus, its use is limited to supervised settings. In this study, we explore\nthe concept of incorporating virtual AT (VAT) into the attention mechanisms, by\nwhich adversarial perturbations can be computed even from unlabeled data. To\nrealize this approach, we propose two general training techniques, namely VAT\nfor attention mechanisms (Attention VAT) and \"interpretable\" VAT for attention\nmechanisms (Attention iVAT), which extend AT for attention mechanisms to a\nsemi-supervised setting. In particular, Attention iVAT focuses on the\ndifferences in attention; thus, it can efficiently learn clearer attention and\nimprove model interpretability, even with unlabeled data. Empirical experiments\nbased on six public datasets revealed that our techniques provide better\nprediction performance than conventional AT-based as well as VAT-based\ntechniques, and stronger agreement with evidence that is provided by humans in\ndetecting important words in sentences. Moreover, our proposal offers these\nadvantages without needing to add the careful selection of unlabeled data. That\nis, even if the model using our VAT-based technique is trained on unlabeled\ndata from a source other than the target task, both the prediction performance\nand model interpretability can be improved.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kitada_S/0/1/0/all/0/1\">Shunsuke Kitada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyatomi_H/0/1/0/all/0/1\">Hitoshi Iyatomi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Differentiable N-gram Objective on Abstractive Summarization. (arXiv:2202.04003v6 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2202.04003","description":"<p>ROUGE is a standard automatic evaluation metric based on n-grams for\nsequence-to-sequence tasks, while cross-entropy loss is an essential objective\nof neural network language model that optimizes at a unigram level. We present\ndifferentiable n-gram objectives, attempting to alleviate the discrepancy\nbetween training criterion and evaluating criterion. The objective maximizes\nthe probabilistic weight of matched sub-sequences, and the novelty of our work\nis the objective weights the matched sub-sequences equally and does not ceil\nthe number of matched sub-sequences by the ground truth count of n-grams in\nreference sequence. We jointly optimize cross-entropy loss and the proposed\nobjective, providing decent ROUGE score enhancement over abstractive\nsummarization dataset CNN/DM and XSum, outperforming alternative n-gram\nobjectives.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yunqi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xuebing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuanyuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Mingjin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wensheng Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Benchmark for Automatic Medical Consultation System: Frameworks, Tasks and Datasets. (arXiv:2204.08997v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.08997","description":"<p>In recent years, interest has arisen in using machine learning to improve the\nefficiency of automatic medical consultation and enhance patient experience. In\nthis article, we propose two frameworks to support automatic medical\nconsultation, namely doctor-patient dialogue understanding and task-oriented\ninteraction. We create a new large medical dialogue dataset with multi-level\nfinegrained annotations and establish five independent tasks, including named\nentity recognition, dialogue act classification, symptom label inference,\nmedical report generation and diagnosis-oriented dialogue policy. We report a\nset of benchmark results for each task, which shows the usability of the\ndataset and sets a baseline for future studies. Both code and data is available\nfrom https://github.com/lemuria-wchen/imcs21.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1\">Hongyi Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1\">Qianyuan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_C/0/1/0/all/0/1\">Cheng Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jianye Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1\">Jiajie Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhongyu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DxFormer: A Decoupled Automatic Diagnostic System Based on Decoder-Encoder Transformer with Dense Symptom Representations. (arXiv:2205.03755v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.03755","description":"<p>Diagnosis-oriented dialogue system queries the patient's health condition and\nmakes predictions about possible diseases through continuous interaction with\nthe patient. A few studies use reinforcement learning (RL) to learn the optimal\npolicy from the joint action space of symptoms and diseases. However, existing\nRL (or Non-RL) methods cannot achieve sufficiently good prediction accuracy,\nstill far from its upper limit. To address the problem, we propose a decoupled\nautomatic diagnostic framework DxFormer, which divides the diagnosis process\ninto two steps: symptom inquiry and disease diagnosis, where the transition\nfrom symptom inquiry to disease diagnosis is explicitly determined by the\nstopping criteria. In DxFormer, we treat each symptom as a token, and formalize\nthe symptom inquiry and disease diagnosis to a language generation model and a\nsequence classification model respectively. We use the inverted version of\nTransformer, i.e., the decoder-encoder structure, to learn the representation\nof symptoms by jointly optimizing the reinforce reward and cross entropy loss.\nExtensive experiments on three public real-world datasets prove that our\nproposed model can effectively learn doctors' clinical experience and achieve\nthe state-of-the-art results in terms of symptom recall and diagnostic\naccuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_C/0/1/0/all/0/1\">Cheng Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1\">Jiajie Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhongyu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Long-Text Understanding with Short-Text Models. (arXiv:2208.00748v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.00748","description":"<p>Transformer-based pretrained language models (LMs) are ubiquitous across\nnatural language understanding, but cannot be applied to long sequences such as\nstories, scientific articles and long documents, due to their quadratic\ncomplexity. While a myriad of efficient transformer variants have been\nproposed, they are typically based on custom implementations that require\nexpensive pretraining from scratch.In this work, we propose SLED:\nSLiding-Encoder and Decoder, a simple approach for processing long sequences\nthat re-uses and leverages battle-tested short-text pretrained LMs.\nSpecifically, we partition the input into overlapping chunks, encode each with\na short-text LM encoder and use the pretrained decoder to fuse information\nacross chunks (fusion-in-decoder). We illustrate through controlled experiments\nthat SLED offers a viable strategy for long text understanding and evaluate our\napproach on SCROLLS, a benchmark with seven datasets across a wide range of\nlanguage understanding tasks. We find that SLED is competitive with specialized\nmodels that are up to 50x larger and require a dedicated and expensive\npretraining step.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ivgi_M/0/1/0/all/0/1\">Maor Ivgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaham_U/0/1/0/all/0/1\">Uri Shaham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ask Question First for Enhancing Lifelong Language Learning. (arXiv:2208.08367v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.08367","description":"<p>Lifelong language learning aims to stream learning NLP tasks while retaining\nknowledge of previous tasks. Previous works based on the language model and\nfollowing data-free constraint approaches have explored formatting all data as\n\"begin token (\\textit{B}) + context (\\textit{C}) + question (\\textit{Q}) +\nanswer (\\textit{A})\" for different tasks. However, they still suffer from\ncatastrophic forgetting and are exacerbated when the previous task's pseudo\ndata is insufficient for the following reasons: (1) The model has difficulty\ngenerating task-corresponding pseudo data, and (2) \\textit{A} is prone to error\nwhen \\textit{A} and \\textit{C} are separated by \\textit{Q} because the\ninformation of the \\textit{C} is diminished before generating \\textit{A}.\nTherefore, we propose the Ask Question First and Replay Question (AQF-RQ),\nincluding a novel data format \"\\textit{BQCA}\" and a new training task to train\npseudo questions of previous tasks. Experimental results demonstrate that\nAQF-RQ makes it easier for the model to generate more pseudo data that match\ncorresponding tasks, and is more robust to both sufficient and insufficient\npseudo-data when the task boundary is both clear and unclear. AQF-RQ can\nachieve only 0.36\\% lower performance than multi-task learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Han Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_R/0/1/0/all/0/1\">Ruiliu Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuejun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qingwei Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"L3Cube-HindBERT and DevBERT: Pre-Trained BERT Transformer models for Devanagari based Hindi and Marathi Languages. (arXiv:2211.11418v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.11418","description":"<p>The monolingual Hindi BERT models currently available on the model hub do not\nperform better than the multi-lingual models on downstream tasks. We present\nL3Cube-HindBERT, a Hindi BERT model pre-trained on Hindi monolingual corpus.\nFurther, since Indic languages, Hindi and Marathi share the Devanagari script,\nwe train a single model for both languages. We release DevBERT, a Devanagari\nBERT model trained on both Marathi and Hindi monolingual datasets. We evaluate\nthese models on downstream Hindi and Marathi text classification and named\nentity recognition tasks. The HindBERT and DevBERT-based models show\nsignificant improvements over multi-lingual MuRIL, IndicBERT, and XLM-R. Based\non these observations we also release monolingual BERT models for other Indic\nlanguages Kannada, Telugu, Malayalam, Tamil, Gujarati, Assamese, Odia, Bengali,\nand Punjabi. These models are shared at https://huggingface.co/l3cube-pune .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Raviraj Joshi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Turing Deception. (arXiv:2212.06721v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2212.06721","description":"<p>This research revisits the classic Turing test and compares recent large\nlanguage models such as ChatGPT for their abilities to reproduce human-level\ncomprehension and compelling text generation. Two task challenges --\nsummarization, and question answering -- prompt ChatGPT to produce original\ncontent (98-99%) from a single text entry and also sequential questions\noriginally posed by Turing in 1950. We score the original and generated content\nagainst the OpenAI GPT-2 Output Detector from 2019, and establish multiple\ncases where the generated content proves original and undetectable (98%). The\nquestion of a machine fooling a human judge recedes in this work relative to\nthe question of \"how would one prove it?\" The original contribution of the work\npresents a metric and simple grammatical set for understanding the writing\nmechanics of chatbots in evaluating their readability and statistical clarity,\nengagement, delivery, and overall quality. While Turing's original prose scores\nat least 14% below the machine-generated output, the question of whether an\nalgorithm displays hints of Turing's truly original thoughts (the \"Lovelace\n2.0\" test) remains unanswered and potentially unanswerable for now.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Noever_D/0/1/0/all/0/1\">David Noever</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciolino_M/0/1/0/all/0/1\">Matt Ciolino</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2022-12-26T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}