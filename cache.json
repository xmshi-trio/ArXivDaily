{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2022-12-19T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Foresight -- Deep Generative Modelling of Patient Timelines using Electronic Health Records. (arXiv:2212.08072v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08072","description":"<p>Electronic Health Records (EHRs) hold detailed longitudinal information about\neach patient's health status and general clinical history, a large portion of\nwhich is stored within the unstructured text. Temporal modelling of this\nmedical history, which considers the sequence of events, can be used to\nforecast and simulate future events, estimate risk, suggest alternative\ndiagnoses or forecast complications. While most prediction approaches use\nmainly structured data or a subset of single-domain forecasts and outcomes, we\nprocessed the entire free-text portion of EHRs for longitudinal modelling. We\npresent Foresight, a novel GPT3-based pipeline that uses NER+L tools (i.e.\nMedCAT) to convert document text into structured, coded concepts, followed by\nproviding probabilistic forecasts for future medical events such as disorders,\nmedications, symptoms and interventions. Since large portions of EHR data are\nin text form, such an approach benefits from a granular and detailed view of a\npatient while introducing modest additional noise. On tests in two large UK\nhospitals (King's College Hospital, South London and Maudsley) and the US\nMIMIC-III dataset precision@10 of 0.80, 0.81 and 0.91 was achieved for\nforecasting the next biomedical concept. Foresight was also validated on 34\nsynthetic patient timelines by 5 clinicians and achieved relevancy of 97% for\nthe top forecasted candidate disorder. Foresight can be easily trained and\ndeployed locally as it only requires free-text data (as a minimum). As a\ngenerative model, it can simulate follow-on disorders, medications and\ninterventions for as many steps as required. Foresight is a general-purpose\nmodel for biomedical concept modelling that can be used for real-world risk\nestimation, virtual trials and clinical research to study the progression of\ndiseases, simulate interventions and counterfactuals, and for educational\npurposes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kraljevic_Z/0/1/0/all/0/1\">Zeljko Kraljevic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bean_D/0/1/0/all/0/1\">Dan Bean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shek_A/0/1/0/all/0/1\">Anthony Shek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendayan_R/0/1/0/all/0/1\">Rebecca Bendayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_J/0/1/0/all/0/1\">Joshua Au Yeung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_A/0/1/0/all/0/1\">Alexander Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baston_A/0/1/0/all/0/1\">Alfie Baston</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ross_J/0/1/0/all/0/1\">Jack Ross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Idowu_E/0/1/0/all/0/1\">Esther Idowu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teo_J/0/1/0/all/0/1\">James T Teo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dobson_R/0/1/0/all/0/1\">Richard J Dobson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Constitutional AI: Harmlessness from AI Feedback. (arXiv:2212.08073v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08073","description":"<p>As AI systems become more capable, we would like to enlist their help to\nsupervise other AIs. We experiment with methods for training a harmless AI\nassistant through self-improvement, without any human labels identifying\nharmful outputs. The only human oversight is provided through a list of rules\nor principles, and so we refer to the method as 'Constitutional AI'. The\nprocess involves both a supervised learning and a reinforcement learning phase.\nIn the supervised phase we sample from an initial model, then generate\nself-critiques and revisions, and then finetune the original model on revised\nresponses. In the RL phase, we sample from the finetuned model, use a model to\nevaluate which of the two samples is better, and then train a preference model\nfrom this dataset of AI preferences. We then train with RL using the preference\nmodel as the reward signal, i.e. we use 'RL from AI Feedback' (RLAIF). As a\nresult we are able to train a harmless but non-evasive AI assistant that\nengages with harmful queries by explaining its objections to them. Both the SL\nand RL methods can leverage chain-of-thought style reasoning to improve the\nhuman-judged performance and transparency of AI decision making. These methods\nmake it possible to control AI behavior more precisely and with far fewer human\nlabels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yuntao Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadavath_S/0/1/0/all/0/1\">Saurav Kadavath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kundu_S/0/1/0/all/0/1\">Sandipan Kundu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Askell_A/0/1/0/all/0/1\">Amanda Askell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kernion_J/0/1/0/all/0/1\">Jackson Kernion</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_A/0/1/0/all/0/1\">Andy Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Anna Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldie_A/0/1/0/all/0/1\">Anna Goldie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirhoseini_A/0/1/0/all/0/1\">Azalia Mirhoseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKinnon_C/0/1/0/all/0/1\">Cameron McKinnon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Carol Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olsson_C/0/1/0/all/0/1\">Catherine Olsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olah_C/0/1/0/all/0/1\">Christopher Olah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_D/0/1/0/all/0/1\">Danny Hernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drain_D/0/1/0/all/0/1\">Dawn Drain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguli_D/0/1/0/all/0/1\">Deep Ganguli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dustin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_Johnson_E/0/1/0/all/0/1\">Eli Tran-Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_E/0/1/0/all/0/1\">Ethan Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerr_J/0/1/0/all/0/1\">Jamie Kerr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_J/0/1/0/all/0/1\">Jared Mueller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ladish_J/0/1/0/all/0/1\">Jeffrey Ladish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landau_J/0/1/0/all/0/1\">Joshua Landau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ndousse_K/0/1/0/all/0/1\">Kamal Ndousse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukosuite_K/0/1/0/all/0/1\">Kamile Lukosuite</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lovitt_L/0/1/0/all/0/1\">Liane Lovitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sellitto_M/0/1/0/all/0/1\">Michael Sellitto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhage_N/0/1/0/all/0/1\">Nelson Elhage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiefer_N/0/1/0/all/0/1\">Nicholas Schiefer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mercado_N/0/1/0/all/0/1\">Noemi Mercado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DasSarma_N/0/1/0/all/0/1\">Nova DasSarma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lasenby_R/0/1/0/all/0/1\">Robert Lasenby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larson_R/0/1/0/all/0/1\">Robin Larson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ringer_S/0/1/0/all/0/1\">Sam Ringer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnston_S/0/1/0/all/0/1\">Scott Johnston</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kravec_S/0/1/0/all/0/1\">Shauna Kravec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Showk_S/0/1/0/all/0/1\">Sheer El Showk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fort_S/0/1/0/all/0/1\">Stanislav Fort</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lanham_T/0/1/0/all/0/1\">Tamera Lanham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Telleen_Lawton_T/0/1/0/all/0/1\">Timothy Telleen-Lawton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conerly_T/0/1/0/all/0/1\">Tom Conerly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henighan_T/0/1/0/all/0/1\">Tom Henighan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hume_T/0/1/0/all/0/1\">Tristan Hume</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1\">Samuel R. Bowman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hatfield_Dodds_Z/0/1/0/all/0/1\">Zac Hatfield-Dodds</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mann_B/0/1/0/all/0/1\">Ben Mann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amodei_D/0/1/0/all/0/1\">Dario Amodei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joseph_N/0/1/0/all/0/1\">Nicholas Joseph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCandlish_S/0/1/0/all/0/1\">Sam McCandlish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_T/0/1/0/all/0/1\">Tom Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaplan_J/0/1/0/all/0/1\">Jared Kaplan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Joint processing of linguistic properties in brains and language models. (arXiv:2212.08094v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08094","description":"<p>Language models have been shown to be very effective in predicting brain\nrecordings of subjects experiencing complex language stimuli. For a deeper\nunderstanding of this alignment, it is important to understand the alignment\nbetween the detailed processing of linguistic information by the human brain\nversus language models. In NLP, linguistic probing tasks have revealed a\nhierarchy of information processing in neural language models that progresses\nfrom simple to complex with an increase in depth. On the other hand, in\nneuroscience, the strongest alignment with high-level language brain regions\nhas consistently been observed in the middle layers. These findings leave an\nopen question as to what linguistic information actually underlies the observed\nalignment between brains and language models. We investigate this question via\na direct approach, in which we eliminate information related to specific\nlinguistic properties in the language model representations and observe how\nthis intervention affects the alignment with fMRI brain recordings obtained\nwhile participants listened to a story. We investigate a range of linguistic\nproperties (surface, syntactic and semantic) and find that the elimination of\neach one results in a significant decrease in brain alignment across all layers\nof a language model. These findings provide direct evidence for the role of\nspecific linguistic information in the alignment between brain and language\nmodels, and opens new avenues for mapping the joint information processing in\nboth systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oota_S/0/1/0/all/0/1\">Subba Reddy Oota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Manish Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toneva_M/0/1/0/all/0/1\">Mariya Toneva</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DFEE: Interactive DataFlow Execution and Evaluation Kit. (arXiv:2212.08099v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08099","description":"<p>DataFlow has been emerging as a new paradigm for building task-oriented\nchatbots due to its expressive semantic representations of the dialogue tasks.\nDespite the availability of a large dataset SMCalFlow and a simplified syntax,\nthe development and evaluation of DataFlow-based chatbots remain challenging\ndue to the system complexity and the lack of downstream toolchains. In this\ndemonstration, we present DFEE, an interactive DataFlow Execution and\nEvaluation toolkit that supports execution, visualization and benchmarking of\nsemantic parsers given dialogue input and backend database. We demonstrate the\nsystem via a complex dialog task: event scheduling that involves temporal\nreasoning. It also supports diagnosing the parsing results via a friendly\ninterface that allows developers to examine dynamic DataFlow and the\ncorresponding execution results. To illustrate how to benchmark SoTA models, we\npropose a novel benchmark that covers more sophisticated event scheduling\nscenarios and a new metric on task success evaluation. The codes of DFEE have\nbeen released on https://github.com/amazonscience/dataflow-evaluation-toolkit.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Han He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Song Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonadiman_D/0/1/0/all/0/1\">Daniele Bonadiman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansour_S/0/1/0/all/0/1\">Saab Mansour</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Role of AI in Drug Discovery: Challenges, Opportunities, and Strategies. (arXiv:2212.08104v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08104","description":"<p>Artificial intelligence (AI) has the potential to revolutionize the drug\ndiscovery process, offering improved efficiency, accuracy, and speed. However,\nthe successful application of AI is dependent on the availability of\nhigh-quality data, the addressing of ethical concerns, and the recognition of\nthe limitations of AI-based approaches. In this article, the benefits,\nchallenges and drawbacks of AI in this field are reviewed, and possible\nstrategies and approaches for overcoming the present obstacles are proposed.\nThe use of data augmentation, explainable AI, and the integration of AI with\ntraditional experimental methods, as well as the potential advantages of AI in\npharmaceutical research are also discussed. Overall, this review highlights the\npotential of AI in drug discovery and provides insights into the challenges and\nopportunities for realizing its potential in this field.\n</p>\n<p>Note from the human-authors: This article was created to test the ability of\nChatGPT, a chatbot based on the GPT-3.5 language model, to assist human authors\nin writing review articles. The text generated by the AI following our\ninstructions (see Supporting Information) was used as a starting point, and its\nability to automatically generate content was evaluated. After conducting a\nthorough review, human authors practically rewrote the manuscript, striving to\nmaintain a balance between the original proposal and scientific criteria. The\nadvantages and limitations of using AI for this purpose are discussed in the\nlast section.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Blanco_Gonzalez_A/0/1/0/all/0/1\">Alexandre Blanco-Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cabezon_A/0/1/0/all/0/1\">Alfonso Cabezon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seco_Gonzalez_A/0/1/0/all/0/1\">Alejandro Seco-Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conde_Torres_D/0/1/0/all/0/1\">Daniel Conde-Torres</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antelo_Riveiro_P/0/1/0/all/0/1\">Paula Antelo-Riveiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineiro_A/0/1/0/all/0/1\">Angel Pineiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Fandino_R/0/1/0/all/0/1\">Rebeca Garcia-Fandino</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Moto: Enhancing Embedding with Multiple Joint Factors for Chinese Text Classification. (arXiv:2212.08105v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08105","description":"<p>Recently, language representation techniques have achieved great performances\nin text classification. However, most existing representation models are\nspecifically designed for English materials, which may fail in Chinese because\nof the huge difference between these two languages. Actually, few existing\nmethods for Chinese text classification process texts at a single level.\nHowever, as a special kind of hieroglyphics, radicals of Chinese characters are\ngood semantic carriers. In addition, Pinyin codes carry the semantic of tones,\nand Wubi reflects the stroke structure information, \\textit{etc}.\nUnfortunately, previous researches neglected to find an effective way to\ndistill the useful parts of these four factors and to fuse them. In our works,\nwe propose a novel model called Moto: Enhancing Embedding with\n\\textbf{M}ultiple J\\textbf{o}int Fac\\textbf{to}rs. Specifically, we design an\nattention mechanism to distill the useful parts by fusing the four-level\ninformation above more effectively. We conduct extensive experiments on four\npopular tasks. The empirical results show that our Moto achieves SOTA 0.8316\n($F_1$-score, 2.11\\% improvement) on Chinese news titles, 96.38 (1.24\\%\nimprovement) on Fudan Corpus and 0.9633 (3.26\\% improvement) on THUCNews.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xunzhu Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Rujie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tiezhu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shi Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Routine Outcome Monitoring in Psychotherapy Treatment using Sentiment-Topic Modelling Approach. (arXiv:2212.08111v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08111","description":"<p>Despite the importance of emphasizing the right psychotherapy treatment for\nan individual patient, assessing the outcome of the therapy session is equally\ncrucial. Evidence showed that continuous monitoring patient's progress can\nsignificantly improve the therapy outcomes to an expected change. By monitoring\nthe outcome, the patient's progress can be tracked closely to help clinicians\nidentify patients who are not progressing in the treatment. These monitoring\ncan help the clinician to consider any necessary actions for the patient's\ntreatment as early as possible, e.g., recommend different types of treatment,\nor adjust the style of approach. Currently, the evaluation system is based on\nthe clinical-rated and self-report questionnaires that measure patients'\nprogress pre- and post-treatment. While outcome monitoring tends to improve the\ntherapy outcomes, however, there are many challenges in the current method,\ne.g. time and financial burden for administering questionnaires, scoring and\nanalysing the results. Therefore, a computational method for measuring and\nmonitoring patient progress over the course of treatment is needed, in order to\nenhance the likelihood of positive treatment outcome. Moreover, this\ncomputational method could potentially lead to an inexpensive monitoring tool\nto evaluate patients' progress in clinical care that could be administered by a\nwider range of health-care professionals.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yusof_N/0/1/0/all/0/1\">Noor Fazilla Abd Yusof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Injecting Domain Knowledge in Language Models for Task-Oriented Dialogue Systems. (arXiv:2212.08120v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08120","description":"<p>Pre-trained language models (PLM) have advanced the state-of-the-art across\nNLP applications, but lack domain-specific knowledge that does not naturally\noccur in pre-training data. Previous studies augmented PLMs with symbolic\nknowledge for different downstream NLP tasks. However, knowledge bases (KBs)\nutilized in these studies are usually large-scale and static, in contrast to\nsmall, domain-specific, and modifiable knowledge bases that are prominent in\nreal-world task-oriented dialogue (TOD) systems. In this paper, we showcase the\nadvantages of injecting domain-specific knowledge prior to fine-tuning on TOD\ntasks. To this end, we utilize light-weight adapters that can be easily\nintegrated with PLMs and serve as a repository for facts learned from different\nKBs. To measure the efficacy of proposed knowledge injection methods, we\nintroduce Knowledge Probing using Response Selection (KPRS) -- a probe designed\nspecifically for TOD models. Experiments on KPRS and the response generation\ntask show improvements of knowledge injection with adapters over strong\nbaselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Emelin_D/0/1/0/all/0/1\">Denis Emelin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonadiman_D/0/1/0/all/0/1\">Daniele Bonadiman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alqahtani_S/0/1/0/all/0/1\">Sawsan Alqahtani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansour_S/0/1/0/all/0/1\">Saab Mansour</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WEKA-Based: Key Features and Classifier for French of Five Countries. (arXiv:2212.08132v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08132","description":"<p>This paper describes a French dialect recognition system that will\nappropriately distinguish between different regional French dialects. A corpus\nof five regions - Monaco, French-speaking, Belgium, French-speaking\nSwitzerland, French-speaking Canada and France, which is targeted\nforconstruction by the Sketch Engine. The content of the corpus is related to\nthe four themes of eating, drinking, sleeping and living, which are closely\nlinked to popular life. The experimental results were obtained through the\nprocessing of a python coded pre-processor and Waikato Environment for\nKnowledge Analysis (WEKA) data analytic tool which contains many filters and\nclassifiers for machine learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zeqian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_K/0/1/0/all/0/1\">Keyu Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_C/0/1/0/all/0/1\">Chenxu Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Haoran Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Long Sequence Modeling via State Space Augmented Transformer. (arXiv:2212.08136v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08136","description":"<p>Transformer models have achieved superior performance in various natural\nlanguage processing tasks. However, the quadratic computational cost of the\nattention mechanism limits its practicality for long sequences. There are\nexisting attention variants that improve the computational efficiency, but they\nhave limited ability to effectively compute global information. In parallel to\nTransformer models, state space models (SSMs) are tailored for long sequences,\nbut they are not flexible enough to capture complicated local information. We\npropose SPADE, short for $\\underline{\\textbf{S}}$tate\ns$\\underline{\\textbf{P}}$ace\n$\\underline{\\textbf{A}}$ugmente$\\underline{\\textbf{D}}$\nTransform$\\underline{\\textbf{E}}$r. Specifically, we augment a SSM into the\nbottom layer of SPADE, and we employ efficient local attention methods for the\nother layers. The SSM augments global information, which complements the lack\nof long-range dependency issue in local attention methods. Experimental results\non the Long Range Arena benchmark and language modeling tasks demonstrate the\neffectiveness of the proposed method. To further demonstrate the scalability of\nSPADE, we pre-train large encoder-decoder models and present fine-tuning\nresults on natural language understanding and natural language generation\ntasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zuo_S/0/1/0/all/0/1\">Simiao Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1\">Jian Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charles_D/0/1/0/all/0/1\">Denis Charles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manavoglu_E/0/1/0/all/0/1\">Eren Manavoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FiDO: Fusion-in-Decoder optimized for stronger performance and faster inference. (arXiv:2212.08153v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08153","description":"<p>Fusion-in-Decoder (FiD) is a powerful retrieval-augmented language model that\nsets the state-of-the-art on many knowledge-intensive NLP tasks. However, FiD\nsuffers from very expensive inference. We show that the majority of inference\ntime results from memory bandwidth constraints in the decoder, and propose two\nsimple changes to the FiD architecture to speed up inference by 7x. The faster\ndecoder inference then allows for a much larger decoder. We denote FiD with the\nabove modifications as FiDO, and show that it strongly improves performance\nover existing FiD models for a wide range of inference budgets. For example,\nFiDO-Large-XXL performs faster inference than FiD-Base and achieves better\nperformance than FiD-Large.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jong_M/0/1/0/all/0/1\">Michiel de Jong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zemlyanskiy_Y/0/1/0/all/0/1\">Yury Zemlyanskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ainslie_J/0/1/0/all/0/1\">Joshua Ainslie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+FitzGerald_N/0/1/0/all/0/1\">Nicholas FitzGerald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanghai_S/0/1/0/all/0/1\">Sumit Sanghai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sha_F/0/1/0/all/0/1\">Fei Sha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1\">William Cohen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MM-SHAP: A Performance-agnostic Metric for Measuring Multimodal Contributions in Vision and Language Models & Tasks. (arXiv:2212.08158v1 [cs.CV])","link":"http://arxiv.org/abs/2212.08158","description":"<p>Vision and language models (VL) are known to exploit unrobust indicators in\nindividual modalities (e.g., introduced by distributional biases), instead of\nfocusing on relevant information in each modality. A small drop in accuracy\nobtained on a VL task with a unimodal model suggests that so-called unimodal\ncollapse occurred. But how to quantify the amount of unimodal collapse\nreliably, at dataset and instance-level, to diagnose and combat unimodal\ncollapse in a targeted way? We present MM-SHAP, a performance-agnostic\nmultimodality score that quantifies the proportion by which a model uses\nindividual modalities in multimodal tasks. MM-SHAP is based on Shapley values\nand will be applied in two ways: (1) to compare models for their degree of\nmultimodality, and (2) to measure the contribution of individual modalities for\na given task and dataset. Experiments with 6 VL models -- LXMERT, CLIP and four\nALBEF variants -- on four VL tasks highlight that unimodal collapse can occur\nto different degrees and in different directions, contradicting the wide-spread\nassumption that unimodal collapse is one-sided. We recommend MM-SHAP for\nanalysing multimodal tasks, to diagnose and guide progress towards multimodal\nintegration. Code available at: https://github.com/Heidelberg-NLP/MM-SHAP\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Parcalabescu_L/0/1/0/all/0/1\">Letitia Parcalabescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Anette Frank</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluation of Synthetic Datasets for Conversational Recommender Systems. (arXiv:2212.08167v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08167","description":"<p>For researchers leveraging Large-Language Models (LLMs) in the generation of\ntraining datasets, especially for conversational recommender systems - the\nabsence of robust evaluation frameworks has been a long-standing problem. The\nefficiency brought about by LLMs in the data generation phase is impeded during\nthe process of evaluation of the generated data, since it generally requires\nhuman-raters to ensure that the data generated is of high quality and has\nsufficient diversity. Since the quality of training data is critical for\ndownstream applications, it is important to develop metrics that evaluate the\nquality holistically and identify biases. In this paper, we present a framework\nthat takes a multi-faceted approach towards evaluating datasets produced by\ngenerative models and discuss the advantages and limitations of various\nevaluation methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lara_H/0/1/0/all/0/1\">Harsh Lara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_M/0/1/0/all/0/1\">Manoj Tiwari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reliable Measures of Spread in High Dimensional Latent Spaces. (arXiv:2212.08172v1 [cs.LG])","link":"http://arxiv.org/abs/2212.08172","description":"<p>Understanding geometric properties of natural language processing models'\nlatent spaces allows the manipulation of these properties for improved\nperformance on downstream tasks. One such property is the amount of data spread\nin a model's latent space, or how fully the available latent space is being\nused. In this work, we define data spread and demonstrate that the commonly\nused measures of data spread, Average Cosine Similarity and a partition\nfunction min/max ratio I(V), do not provide reliable metrics to compare the use\nof latent space across models. We propose and examine eight alternative\nmeasures of data spread, all but one of which improve over these current\nmetrics when applied to seven synthetic data distributions. Of our proposed\nmeasures, we recommend one principal component-based measure and one\nentropy-based measure that provide reliable, relative measures of spread and\ncan be used to compare models of different sizes and dimensionalities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Marbut_A/0/1/0/all/0/1\">Anna C. Marbut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKinney_Bock_K/0/1/0/all/0/1\">Katy McKinney-Bock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wheeler_T/0/1/0/all/0/1\">Travis J. Wheeler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NBC-Softmax : Darkweb Author fingerprinting and migration tracking. (arXiv:2212.08184v1 [cs.LG])","link":"http://arxiv.org/abs/2212.08184","description":"<p>Metric learning aims to learn distances from the data, which enhances the\nperformance of similarity-based algorithms. An author style detection task is a\nmetric learning problem, where learning style features with small intra-class\nvariations and larger inter-class differences is of great importance to achieve\nbetter performance. Recently, metric learning based on softmax loss has been\nused successfully for style detection. While softmax loss can produce separable\nrepresentations, its discriminative power is relatively poor. In this work, we\npropose NBC-Softmax, a contrastive loss based clustering technique for softmax\nloss, which is more intuitive and able to achieve superior performance. Our\ntechnique meets the criterion for larger number of samples, thus achieving\nblock contrastiveness, which is proven to outperform pair-wise losses. It uses\nmini-batch sampling effectively and is scalable. Experiments on 4 darkweb\nsocial forums, with NBCSAuthor that uses the proposed NBC-Softmax for author\nand sybil detection, shows that our negative block contrastive approach\nconstantly outperforms state-of-the-art methods using the same network\narchitecture.\n</p>\n<p>Our code is publicly available at : https://github.com/gayanku/NBC-Softmax\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kulatilleke_G/0/1/0/all/0/1\">Gayan K. Kulatilleke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_S/0/1/0/all/0/1\">Shekhar S. Chandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portmann_M/0/1/0/all/0/1\">Marius Portmann</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources in Natural Language Understanding Systems. (arXiv:2212.08192v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08192","description":"<p>Many state-of-the-art natural language understanding (NLU) models are based\non pretrained neural language models. These models often make inferences using\ninformation from multiple sources. An important class of such inferences are\nthose that require both background knowledge, presumably contained in a model's\npretrained parameters, and instance-specific information that is supplied at\ninference time. However, the integration and reasoning abilities of NLU models\nin the presence of multiple knowledge sources have been largely understudied.\nIn this work, we propose a test suite of coreference resolution tasks that\nrequire reasoning over multiple facts. Our dataset is organized into subtasks\nthat differ in terms of which knowledge sources contain relevant facts. We\nevaluate state-of-the-art coreference resolution models on our dataset. Our\nresults indicate that several models struggle to reason on-the-fly over\nknowledge observed both at pretrain time and at inference time. However, with\ntask-specific training, a subset of models demonstrates the ability to\nintegrate certain knowledge types from multiple sources.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arodi_A/0/1/0/all/0/1\">Akshatha Arodi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pomsl_M/0/1/0/all/0/1\">Martin P&#xf6;msl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suleman_K/0/1/0/all/0/1\">Kaheer Suleman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trischler_A/0/1/0/all/0/1\">Adam Trischler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olteanu_A/0/1/0/all/0/1\">Alexandra Olteanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_J/0/1/0/all/0/1\">Jackie Chi Kit Cheung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Chess Commentaries by Combining Language Models with Symbolic Reasoning Engines. (arXiv:2212.08195v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08195","description":"<p>Despite many recent advancements in language modeling, state-of-the-art\nlanguage models lack grounding in the real world and struggle with tasks\ninvolving complex reasoning. Meanwhile, advances in the symbolic reasoning\ncapabilities of AI have led to systems that outperform humans in games like\nchess and Go (Silver et al., 2018). Chess commentary provides an interesting\ndomain for bridging these two fields of research, as it requires reasoning over\na complex board state and providing analyses in natural language. In this work\nwe demonstrate how to combine symbolic reasoning engines with controllable\nlanguage models to generate chess commentaries. We conduct experiments to\ndemonstrate that our approach generates commentaries that are preferred by\nhuman judges over previous baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_A/0/1/0/all/0/1\">Andrew Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">David Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinan_E/0/1/0/all/0/1\">Emily Dinan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Saved You A Click: Automatically Answering Clickbait Titles. (arXiv:2212.08196v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08196","description":"<p>Often clickbait articles have a title that is phrased as a question or vague\nteaser that entices the user to click on the link and read the article to find\nthe explanation. We developed a system that will automatically find the answer\nor explanation of the clickbait hook from the website text so that the user\ndoes not need to read through the text themselves. We fine-tune an extractive\nquestion and answering model (RoBERTa) and an abstractive one (T5), using data\nscraped from the 'StopClickbait' Facebook pages and Reddit's 'SavedYouAClick'\nsubforum. We find that both extractive and abstractive models improve\nsignificantly after finetuning. We find that the extractive model performs\nslightly better according to ROUGE scores, while the abstractive one has a\nslight edge in terms of BERTscores.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Johnson_O/0/1/0/all/0/1\">Oliver Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_B/0/1/0/all/0/1\">Beicheng Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_J/0/1/0/all/0/1\">Janet Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurenkov_A/0/1/0/all/0/1\">Andrey Kurenkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LegalRelectra: Mixed-domain Language Modeling for Long-range Legal Text Comprehension. (arXiv:2212.08204v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08204","description":"<p>The application of Natural Language Processing (NLP) to specialized domains,\nsuch as the law, has recently received a surge of interest. As many legal\nservices rely on processing and analyzing large collections of documents,\nautomating such tasks with NLP tools emerges as a key challenge. Many popular\nlanguage models, such as BERT or RoBERTa, are general-purpose models, which\nhave limitations on processing specialized legal terminology and syntax. In\naddition, legal documents may contain specialized vocabulary from other\ndomains, such as medical terminology in personal injury text. Here, we propose\nLegalRelectra, a legal-domain language model that is trained on mixed-domain\nlegal and medical corpora. We show that our model improves over general-domain\nand single-domain medical and legal language models when processing\nmixed-domain (personal injury) text. Our training architecture implements the\nElectra framework, but utilizes Reformer instead of BERT for its generator and\ndiscriminator. We show that this improves the model's performance on processing\nlong passages and results in better long-range text comprehension.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wenyue Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuchen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhe Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Josie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_M/0/1/0/all/0/1\">Melanie Weber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A unified information-theoretic model of EEG signatures of human language processing. (arXiv:2212.08205v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08205","description":"<p>We advance an information-theoretic model of human language processing in the\nbrain, in which incoming linguistic input is processed at two levels, in terms\nof a heuristic interpretation and in terms of error correction. We propose that\nthese two kinds of information processing have distinct electroencephalographic\nsignatures, corresponding to the well-documented N400 and P600 components of\nlanguage-related event-related potentials (ERPs). Formally, we show that the\ninformation content (surprisal) of a word in context can be decomposed into two\nquantities: (A) heuristic surprise, which signals processing difficulty of word\ngiven its inferred context, and corresponds with the N400 signal; and (B)\ndiscrepancy signal, which reflects divergence between the true context and the\ninferred context, and corresponds to the P600 signal. Both of these quantities\ncan be estimated using modern NLP techniques. We validate our theory by\nsuccessfully simulating ERP patterns elicited by a variety of linguistic\nmanipulations in previously-reported experimental data from Ryskin et al.\n(2021). Our theory is in principle compatible with traditional cognitive\ntheories assuming a `good-enough' heuristic interpretation stage, but with\nprecise information-theoretic formulation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiaxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Futrell_R/0/1/0/all/0/1\">Richard Futrell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Meeting Summarization: A Survey of the State of the Art. (arXiv:2212.08206v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08206","description":"<p>Information overloading requires the need for summarizers to extract salient\ninformation from the text. Currently, there is an overload of dialogue data due\nto the rise of virtual communication platforms. The rise of Covid-19 has led\npeople to rely on online communication platforms like Zoom, Slack, Microsoft\nTeams, Discord, etc. to conduct their company meetings. Instead of going\nthrough the entire meeting transcripts, people can use meeting summarizers to\nselect useful data. Nevertheless, there is a lack of comprehensive surveys in\nthe field of meeting summarizers. In this survey, we aim to cover recent\nmeeting summarization techniques. Our survey offers a general overview of text\nsummarization along with datasets and evaluation metrics for meeting\nsummarization. We also provide the performance of each summarizer on a\nleaderboard. We conclude our survey with different challenges in this domain\nand potential research opportunities for future researchers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_L/0/1/0/all/0/1\">Lakshmi Prasanna Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kabiri_A/0/1/0/all/0/1\">Arman Kabiri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Azimuth: Systematic Error Analysis for Text Classification. (arXiv:2212.08216v1 [cs.LG])","link":"http://arxiv.org/abs/2212.08216","description":"<p>We present Azimuth, an open-source and easy-to-use tool to perform error\nanalysis for text classification. Compared to other stages of the ML\ndevelopment cycle, such as model training and hyper-parameter tuning, the\nprocess and tooling for the error analysis stage are less mature. However, this\nstage is critical for the development of reliable and trustworthy AI systems.\nTo make error analysis more systematic, we propose an approach comprising\ndataset analysis and model quality assessment, which Azimuth facilitates. We\naim to help AI practitioners discover and address areas where the model does\nnot generalize by leveraging and integrating a range of ML techniques, such as\nsaliency maps, similarity, uncertainty, and behavioral analyses, all in one\ntool. Our code and documentation are available at\ngithub.com/servicenow/azimuth.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gauthier_Melancon_G/0/1/0/all/0/1\">Gabrielle Gauthier-Melan&#xe7;on</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Ayala_O/0/1/0/all/0/1\">Orlando Marquez Ayala</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Brin_L/0/1/0/all/0/1\">Lindsay Brin</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Tyler_C/0/1/0/all/0/1\">Chris Tyler</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Branchaud_Charron_F/0/1/0/all/0/1\">Fr&#xe9;d&#xe9;ric Branchaud-Charron</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Marinier_J/0/1/0/all/0/1\">Joseph Marinier</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Grande_K/0/1/0/all/0/1\">Karine Grande</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Le_D/0/1/0/all/0/1\">Di Le</a> (1) ((1) ServiceNow, (2) Glowstick)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Werewolf Among Us: A Multimodal Dataset for Modeling Persuasion Behaviors in Social Deduction Games. (arXiv:2212.08279v1 [cs.LG])","link":"http://arxiv.org/abs/2212.08279","description":"<p>Persuasion modeling is a key building block for conversational agents.\nExisting works in this direction are limited to analyzing textual dialogue\ncorpus. We argue that visual signals also play an important role in\nunderstanding human persuasive behaviors. In this paper, we introduce the first\nmultimodal dataset for modeling persuasion behaviors. Our dataset includes 199\ndialogue transcriptions and videos captured in a multi-player social deduction\ngame setting, 26,647 utterance level annotations of persuasion strategy, and\ngame level annotations of deduction game outcomes. We provide extensive\nexperiments to show how dialogue context and visual signals benefit persuasion\nstrategy prediction. We also explore the generalization ability of language\nmodels for persuasion modeling and the role of persuasion strategies in\npredicting social deduction game outcomes. Our dataset, code, and models can be\nfound at https://persuasion-deductiongame.socialai-data.org.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lai_B/0/1/0/all/0/1\">Bolin Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongxin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Miao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pariani_A/0/1/0/all/0/1\">Aryan Pariani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryan_F/0/1/0/all/0/1\">Fiona Ryan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_W/0/1/0/all/0/1\">Wenqi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayati_S/0/1/0/all/0/1\">Shirley Anugrah Hayati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1\">James M. Rehg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SceneGATE: Scene-Graph based co-Attention networks for TExt visual question answering. (arXiv:2212.08283v1 [cs.CV])","link":"http://arxiv.org/abs/2212.08283","description":"<p>Most TextVQA approaches focus on the integration of objects, scene texts and\nquestion words by a simple transformer encoder. But this fails to capture the\nsemantic relations between different modalities. The paper proposes a Scene\nGraph based co-Attention Network (SceneGATE) for TextVQA, which reveals the\nsemantic relations among the objects, Optical Character Recognition (OCR)\ntokens and the question words. It is achieved by a TextVQA-based scene graph\nthat discovers the underlying semantics of an image. We created a\nguided-attention module to capture the intra-modal interplay between the\nlanguage and the vision as a guidance for inter-modal interactions. To make\nexplicit teaching of the relations between the two modalities, we proposed and\nintegrated two attention modules, namely a scene graph-based semantic\nrelation-aware attention and a positional relation-aware attention. We\nconducted extensive experiments on two benchmark datasets, Text-VQA and ST-VQA.\nIt is shown that our SceneGATE method outperformed existing ones because of the\nscene graph and its attention modules.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Siwen Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_F/0/1/0/all/0/1\">Feiqi Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nunez_F/0/1/0/all/0/1\">Felipe Nunez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zean Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_J/0/1/0/all/0/1\">Josiah Poon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Caren Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ALERT: Adapting Language Models to Reasoning Tasks. (arXiv:2212.08286v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08286","description":"<p>Current large language models can perform reasonably well on complex tasks\nthat require step-by-step reasoning with few-shot learning. Are these models\napplying reasoning skills they have learnt during pre-training and reason\noutside of their training context, or are they simply memorizing their training\ncorpus at finer granularity and have learnt to better understand their context?\nTo tease apart these possibilities, we introduce ALERT, a benchmark and suite\nof analyses for assessing language models' reasoning ability comparing\npre-trained and finetuned models on complex tasks that require reasoning skills\nto solve. ALERT provides a test bed to asses any language model on fine-grained\nreasoning skills, which spans over 20 datasets and covers 10 different\nreasoning skills. We leverage ALERT to further investigate the role of\nfinetuning. With extensive empirical analysis we find that language models\nlearn more reasoning skills such as textual entailment, abductive reasoning,\nand analogical reasoning during finetuning stage compared to pretraining state.\nWe also find that when language models are finetuned they tend to overfit to\nthe prompt template, which hurts the robustness of models causing\ngeneralization problems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Ping Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianlu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golovneva_O/0/1/0/all/0/1\">Olga Golovneva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alkhamissy_B/0/1/0/all/0/1\">Badr Alkhamissy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_G/0/1/0/all/0/1\">Gargi Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diab_M/0/1/0/all/0/1\">Mona Diab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rich Event Modeling for Script Event Prediction. (arXiv:2212.08287v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08287","description":"<p>Script is a kind of structured knowledge extracted from texts, which contains\na sequence of events. Based on such knowledge, script event prediction aims to\npredict the subsequent event. To do so, two aspects should be considered for\nevents, namely, event description (i.e., what the events should contain) and\nevent encoding (i.e., how they should be encoded). Most existing methods\ndescribe an event by a verb together with only a few core arguments (i.e.,\nsubject, object, and indirect object), which are not precise. In addition,\nexisting event encoders are limited to a fixed number of arguments, which are\nnot flexible to deal with extra information. Thus, in this paper, we propose\nthe Rich Event Prediction (REP) framework for script event prediction.\nFundamentally, it is based on the proposed rich event description, which\nenriches the existing ones with three kinds of important information, namely,\nthe senses of verbs, extra semantic roles, and types of participants. REP\ncontains an event extractor to extract such information from texts. Based on\nthe extracted rich information, a predictor then selects the most probable\nsubsequent event. The core component of the predictor is a transformer-based\nevent encoder to flexibly deal with an arbitrary number of arguments.\nExperimental results on the widely used Gigaword Corpus show the effectiveness\nof the proposed framework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1\">Long Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_S/0/1/0/all/0/1\">Saiping Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zixuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jiafeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xiaolong Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xueqi Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Controllable Text Generation via Probability Density Estimation in the Latent Space. (arXiv:2212.08307v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08307","description":"<p>Previous work on controllable text generation has explored the idea of\ncontrol from the latent space, such as optimizing a representation with\nattribute-related classifiers or sampling a representation from relevant\ndiscrete samples. However, they are not effective enough in modeling both the\nlatent space and the control, leaving controlled text with low quality and\ndiversity. In this work, we propose a novel control framework using probability\ndensity estimation in the latent space. Our method utilizes an invertible\ntransformation function, the Normalizing Flow, that maps the complex\ndistributions in the latent space to simple Gaussian distributions in the prior\nspace. Thus, we can perform sophisticated and flexible control in the prior\nspace and feed the control effects back into the latent space owing to the\none-one-mapping property of invertible transformations. Experiments on\nsingle-attribute controls and multi-attribute control reveal that our method\noutperforms several strong baselines on attribute relevance and text quality\nand achieves the SOTA. Further analysis of control strength adjustment\ndemonstrates the flexibility of our control strategy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yuxuan Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1\">Xiaocheng Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Sicheng Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lingyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_H/0/1/0/all/0/1\">Heng Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigation of Japanese PnG BERT language model in text-to-speech synthesis for pitch accent language. (arXiv:2212.08321v1 [eess.AS])","link":"http://arxiv.org/abs/2212.08321","description":"<p>End-to-end text-to-speech synthesis (TTS) can generate highly natural\nsynthetic speech from raw text. However, rendering the correct pitch accents is\nstill a challenging problem for end-to-end TTS. To tackle the challenge of\nrendering correct pitch accent in Japanese end-to-end TTS, we adopt PnG~BERT, a\nself-supervised pretrained model in the character and phoneme domain for TTS.\nWe investigate the effects of features captured by PnG~BERT on Japanese TTS by\nmodifying the fine-tuning condition to determine the conditions helpful\ninferring pitch accents. We manipulate content of PnG~BERT features from being\ntext-oriented to speech-oriented by changing the number of fine-tuned layers\nduring TTS. In addition, we teach PnG~BERT pitch accent information by\nfine-tuning with tone prediction as an additional downstream task. Our\nexperimental results show that the features of PnG~BERT captured by pretraining\ncontain information helpful inferring pitch accent, and PnG~BERT outperforms\nbaseline Tacotron on accent correctness in a listening test.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Yasuda_Y/0/1/0/all/0/1\">Yusuke Yasuda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Toda_T/0/1/0/all/0/1\">Tomoki Toda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ReCo: Reliable Causal Chain Reasoning via Structural Causal Recurrent Neural Networks. (arXiv:2212.08322v1 [cs.AI])","link":"http://arxiv.org/abs/2212.08322","description":"<p>Causal chain reasoning (CCR) is an essential ability for many decision-making\nAI systems, which requires the model to build reliable causal chains by\nconnecting causal pairs. However, CCR suffers from two main transitive\nproblems: threshold effect and scene drift. In other words, the causal pairs to\nbe spliced may have a conflicting threshold boundary or scenario. To address\nthese issues, we propose a novel Reliable Causal chain reasoning\nframework~(ReCo), which introduces exogenous variables to represent the\nthreshold and scene factors of each causal pair within the causal chain, and\nestimates the threshold and scene contradictions across exogenous variables via\nstructural causal recurrent neural networks~(SRNN). Experiments show that ReCo\noutperforms a series of strong baselines on both Chinese and English CCR\ndatasets. Moreover, by injecting reliable causal chain knowledge distilled by\nReCo, BERT can achieve better performances on four downstream causal-related\ntasks than BERT models enhanced by other kinds of knowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_K/0/1/0/all/0/1\">Kai Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xiao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhongyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Li Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huai_B/0/1/0/all/0/1\">Baoxing Huai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text-to-speech synthesis based on latent variable conversion using diffusion probabilistic model and variational autoencoder. (arXiv:2212.08329v1 [eess.AS])","link":"http://arxiv.org/abs/2212.08329","description":"<p>Text-to-speech synthesis (TTS) is a task to convert texts into speech. Two of\nthe factors that have been driving TTS are the advancements of probabilistic\nmodels and latent representation learning. We propose a TTS method based on\nlatent variable conversion using a diffusion probabilistic model and the\nvariational autoencoder (VAE). In our TTS method, we use a waveform model based\non VAE, a diffusion model that predicts the distribution of latent variables in\nthe waveform model from texts, and an alignment model that learns alignments\nbetween the text and speech latent sequences. Our method integrates diffusion\nwith VAE by modeling both mean and variance parameters with diffusion, where\nthe target distribution is determined by approximation from VAE. This latent\nvariable conversion framework potentially enables us to flexibly incorporate\nvarious latent feature extractors. Our experiments show that our method is\nrobust to linguistic labels with poor orthography and alignment errors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Yasuda_Y/0/1/0/all/0/1\">Yusuke Yasuda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Toda_T/0/1/0/all/0/1\">Tomoki Toda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Convolution-enhanced Evolving Attention Networks. (arXiv:2212.08330v1 [cs.LG])","link":"http://arxiv.org/abs/2212.08330","description":"<p>Attention-based neural networks, such as Transformers, have become ubiquitous\nin numerous applications, including computer vision, natural language\nprocessing, and time-series analysis. In all kinds of attention networks, the\nattention maps are crucial as they encode semantic dependencies between input\ntokens. However, most existing attention networks perform modeling or reasoning\nbased on representations, wherein the attention maps of different layers are\nlearned separately without explicit interactions. In this paper, we propose a\nnovel and generic evolving attention mechanism, which directly models the\nevolution of inter-token relationships through a chain of residual\nconvolutional modules. The major motivations are twofold. On the one hand, the\nattention maps in different layers share transferable knowledge, thus adding a\nresidual connection can facilitate the information flow of inter-token\nrelationships across layers. On the other hand, there is naturally an\nevolutionary trend among attention maps at different abstraction levels, so it\nis beneficial to exploit a dedicated convolution-based module to capture this\nprocess. Equipped with the proposed mechanism, the convolution-enhanced\nevolving attention networks achieve superior performance in various\napplications, including time-series representation, natural language\nunderstanding, machine translation, and image classification. Especially on\ntime-series representation tasks, Evolving Attention-enhanced Dilated\nConvolutional (EA-DC-) Transformer outperforms state-of-the-art models\nsignificantly, achieving an average of 17% improvement compared to the best\nSOTA. To the best of our knowledge, this is the first work that explicitly\nmodels the layer-wise evolution of attention maps. Our implementation is\navailable at https://github.com/pkuyym/EvolvingAttention\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yujing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaming Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Jiangang Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mingliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiangtai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Gao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1\">Yunhai Tong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Law to Binary Tree -- An Formal Interpretation of Legal Natural Language. (arXiv:2212.08335v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08335","description":"<p>Knowledge representation and reasoning in law are essential to facilitate the\nautomation of legal analysis and decision-making tasks. In this paper, we\npropose a new approach based on legal science, specifically legal taxonomy, for\nrepresenting and reasoning with legal documents. Our approach interprets the\nregulations in legal documents as binary trees, which facilitates legal\nreasoning systems to make decisions and resolve logical contradictions. The\nadvantages of this approach are twofold. First, legal reasoning can be\nperformed on the basis of the binary tree representation of the regulations.\nSecond, the binary tree representation of the regulations is more\nunderstandable than the existing sentence-based representations. We provide an\nexample of how our approach can be used to interpret the regulations in a legal\ndocument.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Ha-Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1\">Vu Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1\">Ngoc-Cam Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Thi-Thuy Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quang-Huy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1\">Le-Minh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Satoh_K/0/1/0/all/0/1\">Ken Satoh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How to disagree well: Investigating the dispute tactics used on Wikipedia. (arXiv:2212.08353v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08353","description":"<p>Disagreements are frequently studied from the perspective of either detecting\ntoxicity or analysing argument structure. We propose a framework of dispute\ntactics that unifies these two perspectives, as well as other dialogue acts\nwhich play a role in resolving disputes, such as asking questions and providing\nclarification. This framework includes a preferential ordering among\nrebuttal-type tactics, ranging from ad hominem attacks to refuting the central\nargument. Using this framework, we annotate 213 disagreements (3,865\nutterances) from Wikipedia Talk pages. This allows us to investigate research\nquestions around the tactics used in disagreements; for instance, we provide\nempirical validation of the approach to disagreement recommended by Wikipedia.\nWe develop models for multilabel prediction of dispute tactics in an utterance,\nachieving the best performance with a transformer-based label powerset model.\nAdding an auxiliary task to incorporate the ordering of rebuttal tactics\nfurther yields a statistically significant increase. Finally, we show that\nthese annotations can be used to provide useful additional signals to improve\nperformance on the task of predicting escalation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kock_C/0/1/0/all/0/1\">Christine de Kock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stafford_T/0/1/0/all/0/1\">Tom Stafford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1\">Andreas Vlachos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FewFedWeight: Few-shot Federated Learning Framework across Multiple NLP Tasks. (arXiv:2212.08354v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08354","description":"<p>Massively multi-task learning with large language models has recently made\nsubstantial progress on few-shot generalization. However, this is usually\nperformed in a centralized learning fashion, ignoring the privacy sensitivity\nissue of (annotated) data used in multiple tasks. To mitigate this issue, we\npropose FewFedWeight, a few-shot federated learning framework across multiple\ntasks, to achieve the best of both worlds: privacy preservation and cross-task\ngeneralization. FewFedWeight trains client models in isolated devices without\nsharing data. It broadcasts the global model in the server to each client and\nproduces pseudo data for clients so that knowledge from the global model can be\nexplored to enhance few-shot learning of each client model. An energy-based\nalgorithm is further proposed to weight pseudo samples in order to reduce the\nnegative impact of noise from the generated pseudo data. Adaptive model weights\nof client models are also tuned according to their performance. We use these\nmodel weights to dynamically aggregate client models to update the global\nmodel. Experiments on 118 NLP tasks show that FewFedWeight can significantly\nimprove the performance of client models on 61% tasks with an average\nperformance improvement rate of 30.5% over the baseline and substantially\noutperform FedAvg and other decentralized learning methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1\">Weilong Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xinwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junzhuo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shuangzhi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_C/0/1/0/all/0/1\">Chao Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_D/0/1/0/all/0/1\">Deyi Xiong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Homonymy Information for English WordNet. (arXiv:2212.08388v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08388","description":"<p>A widely acknowledged shortcoming of WordNet is that it lacks a distinction\nbetween word meanings which are systematically related (polysemy), and those\nwhich are coincidental (homonymy). Several previous works have attempted to\nfill this gap, by inferring this information using computational methods. We\nrevisit this task, and exploit recent advances in language modelling to\nsynthesise homonymy annotation for Princeton WordNet. Previous approaches treat\nthe problem using clustering methods; by contrast, our method works by linking\nWordNet to the Oxford English Dictionary, which contains the information we\nneed. To perform this alignment, we pair definitions based on their proximity\nin an embedding space produced by a Transformer model. Despite the simplicity\nof this approach, our best model attains an F1 of .97 on an evaluation set that\nwe annotate. The outcome of our work is a high-quality homonymy annotation\nlayer for Princeton WordNet, which we release.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Maudslay_R/0/1/0/all/0/1\">Rowan Hall Maudslay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teufel_S/0/1/0/all/0/1\">Simone Teufel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lessons learned from the evaluation of Spanish Language Models. (arXiv:2212.08390v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08390","description":"<p>Given the impact of language models on the field of Natural Language\nProcessing, a number of Spanish encoder-only masked language models (aka BERTs)\nhave been trained and released. These models were developed either within large\nprojects using very large private corpora or by means of smaller scale academic\nefforts leveraging freely available data. In this paper we present a\ncomprehensive head-to-head comparison of language models for Spanish with the\nfollowing results: (i) Previously ignored multilingual models from large\ncompanies fare better than monolingual models, substantially changing the\nevaluation landscape of language models in Spanish; (ii) Results across the\nmonolingual models are not conclusive, with supposedly smaller and inferior\nmodels performing competitively. Based on these empirical results, we argue for\nthe need of more research to understand the factors underlying them. In this\nsense, the effect of corpus size, quality and pre-training techniques need to\nbe further investigated to be able to obtain Spanish monolingual models\nsignificantly better than the multilingual ones released by large private\ncompanies, specially in the face of rapid ongoing progress in the field. The\nrecent activity in the development of language technology for Spanish is to be\nwelcomed, but our results show that building language models remains an open,\nresource-heavy problem which requires to marry resources (monetary and/or\ncomputational) with the best research expertise and practice.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Agerri_R/0/1/0/all/0/1\">Rodrigo Agerri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agirre_E/0/1/0/all/0/1\">Eneko Agirre</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Metaphorical Polysemy Detection: Conventional Metaphor meets Word Sense Disambiguation. (arXiv:2212.08395v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08395","description":"<p>Linguists distinguish between novel and conventional metaphor, a distinction\nwhich the metaphor detection task in NLP does not take into account. Instead,\nmetaphoricity is formulated as a property of a token in a sentence, regardless\nof metaphor type. In this paper, we investigate the limitations of treating\nconventional metaphors in this way, and advocate for an alternative which we\nname 'metaphorical polysemy detection' (MPD). In MPD, only conventional\nmetaphoricity is treated, and it is formulated as a property of word senses in\na lexicon. We develop the first MPD model, which learns to identify\nconventional metaphors in the English WordNet. To train it, we present a novel\ntraining procedure that combines metaphor detection with word sense\ndisambiguation (WSD). For evaluation, we manually annotate metaphor in two\nsubsets of WordNet. Our model significantly outperforms a strong baseline based\non a state-of-the-art metaphor detection model, attaining an ROC-AUC score of\n.78 (compared to .65) on one of the sets. Additionally, when paired with a WSD\nmodel, our approach outperforms a state-of-the-art metaphor detection model at\nidentifying conventional metaphors in text (.659 F1 compared to .626).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Maudslay_R/0/1/0/all/0/1\">Rowan Hall Maudslay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teufel_S/0/1/0/all/0/1\">Simone Teufel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Utilizing distilBert transformer model for sentiment classification of COVID-19's Persian open-text responses. (arXiv:2212.08407v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08407","description":"<p>The COVID-19 pandemic has caused drastic alternations in human life in all\naspects. The government's laws in this regard affected the lifestyle of all\npeople. Due to this fact studying the sentiment of individuals is essential to\nbe aware of the future impacts of the coming pandemics. To contribute to this\naim, we proposed an NLP (Natural Language Processing) model to analyze\nopen-text answers in a survey in Persian and detect positive and negative\nfeelings of the people in Iran. In this study, a distilBert transformer model\nwas applied to take on this task. We deployed three approaches to perform the\ncomparison, and our best model could gain accuracy: 0.824, Precision: 0.824,\nRecall: 0.798, and F1 score: 0.804.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Masoumi_F/0/1/0/all/0/1\">Fatemeh Sadat Masoumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bahrani_M/0/1/0/all/0/1\">Mohammad Bahrani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Decoder Tuning: Efficient Language Understanding as Decoding. (arXiv:2212.08408v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08408","description":"<p>With the evergrowing sizes of pre-trained models (PTMs), it has been an\nemerging practice to only provide the inference APIs for users, namely\nmodel-as-a-service (MaaS) setting. To adapt PTMs with model parameters frozen,\nmost current approaches focus on the input side, seeking for powerful prompts\nto stimulate models for correct answers. However, we argue that input-side\nadaptation could be arduous due to the lack of gradient signals and they\nusually require thousands of API queries, resulting in high computation and\ntime costs. In light of this, we present Decoder Tuning (DecT), which in\ncontrast optimizes task-specific decoder networks on the output side.\nSpecifically, DecT first extracts prompt-stimulated output scores for initial\npredictions. On top of that, we train an additional decoder network on the\noutput representations to incorporate posterior data knowledge. By\ngradient-based optimization, DecT can be trained within several seconds and\nrequires only one PTM query per sample. Empirically, we conduct extensive\nnatural language understanding experiments and show that DecT significantly\noutperforms state-of-the-art algorithms with a $10^3\\times$ speed-up.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cui_G/0/1/0/all/0/1\">Ganqu Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wentao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1\">Ning Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Longtao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Teaching Small Language Models to Reason. (arXiv:2212.08410v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08410","description":"<p>Chain of thought prompting successfully improves the reasoning capabilities\nof large language models, achieving state of the art results on a range of\ndatasets. However, these reasoning capabilities only appear to emerge in models\nwith a size of over 100 billion parameters. In this paper, we explore the\ntransfer of such reasoning capabilities to models with less than 100 billion\nparameters via knowledge distillation. Specifically, we finetune a student\nmodel on the chain of thought outputs generated by a larger teacher model. Our\nexperiments show that the proposed method improves task performance across\narithmetic, commonsense and symbolic reasoning datasets. For example, the\naccuracy of T5 XXL on GSM8K improves from 8.11% to 21.99% when finetuned on\nPaLM-540B generated chains of thought.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Magister_L/0/1/0/all/0/1\">Lucie Charlotte Magister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallinson_J/0/1/0/all/0/1\">Jonathan Mallinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adamek_J/0/1/0/all/0/1\">Jakub Adamek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malmi_E/0/1/0/all/0/1\">Eric Malmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Severyn_A/0/1/0/all/0/1\">Aliaksei Severyn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fast Rule-Based Decoding: Revisiting Syntactic Rules in Neural Constituency Parsing. (arXiv:2212.08458v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08458","description":"<p>Most recent studies on neural constituency parsing focus on encoder\nstructures, while few developments are devoted to decoders. Previous research\nhas demonstrated that probabilistic statistical methods based on syntactic\nrules are particularly effective in constituency parsing, whereas syntactic\nrules are not used during the training of neural models in prior work probably\ndue to their enormous computation requirements. In this paper, we first\nimplement a fast CKY decoding procedure harnessing GPU acceleration, based on\nwhich we further derive a syntactic rule-based (rule-constrained) CKY decoding.\nIn the experiments, our method obtains 95.89 and 92.52 F1 on the datasets of\nPTB and CTB respectively, which shows significant improvements compared with\nprevious approaches. Besides, our parser achieves strong and competitive\ncross-domain performance in zero-shot settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1\">Tianyu Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhicheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1\">Liyin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Cong Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Experiments on Generalizability of BERTopic on Multi-Domain Short Text. (arXiv:2212.08459v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08459","description":"<p>Topic modeling is widely used for analytically evaluating large collections\nof textual data. One of the most popular topic techniques is Latent Dirichlet\nAllocation (LDA), which is flexible and adaptive, but not optimal for e.g.\nshort texts from various domains. We explore how the state-of-the-art BERTopic\nalgorithm performs on short multi-domain text and find that it generalizes\nbetter than LDA in terms of topic coherence and diversity. We further analyze\nthe performance of the HDBSCAN clustering algorithm utilized by BERTopic and\nfind that it classifies a majority of the documents as outliers. This crucial,\nyet overseen problem excludes too many documents from further analysis. When we\nreplace HDBSCAN with k-Means, we achieve similar performance, but without\noutliers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Groot_M/0/1/0/all/0/1\">Muri&#xeb;l de Groot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aliannejadi_M/0/1/0/all/0/1\">Mohammad Aliannejadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haas_M/0/1/0/all/0/1\">Marcel R. Haas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Best-Answer Prediction in Q&A Sites Using User Information. (arXiv:2212.08475v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08475","description":"<p>Community Question Answering (CQA) sites have spread and multiplied\nsignificantly in recent years. Sites like Reddit, Quora, and Stack Exchange are\nbecoming popular amongst people interested in finding answers to diverse\nquestions. One practical way of finding such answers is automatically\npredicting the best candidate given existing answers and comments. Many studies\nwere conducted on answer prediction in CQA but with limited focus on using the\nbackground information of the questionnaires. We address this limitation using\na novel method for predicting the best answers using the questioner's\nbackground information and other features, such as the textual content or the\nrelationships with other participants. Our answer classification model was\ntrained using the Stack Exchange dataset and validated using the Area Under the\nCurve (AUC) metric. The experimental results show that the proposed method\ncomplements previous methods by pointing out the importance of the\nrelationships between users, particularly throughout the level of involvement\nin different communities on Stack Exchange. Furthermore, we point out that\nthere is little overlap between user-relation information and the information\nrepresented by the shallow text features and the meta-features, such as time\ndifferences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hadfi_R/0/1/0/all/0/1\">Rafik Hadfi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moustafa_A/0/1/0/all/0/1\">Ahmed Moustafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshino_K/0/1/0/all/0/1\">Kai Yoshino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ito_T/0/1/0/all/0/1\">Takayuki Ito</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Implementation of general formal translators. (arXiv:2212.08482v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08482","description":"<p>The general translator formalism and computing specific implementations are\nproposed. The implementation of specific elements necessary to process the\nsource and destination information within the translators are presented. Some\ncommon directives or instructions, such as classes and procedures, were unified\nand generalized in order to allow general translations implementations. In\norder to cover general cases, two levels of processing are required, related to\nthe source and destination information appropriate transformations, with the\nrelated control and processing instructions. The proposed general translator\nelements are useful for processing natural or artificial information described\nthrough any types of languages or systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Petrila_I/0/1/0/all/0/1\">Iosif Iulian Petrila</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BLASER: A Text-Free Speech-to-Speech Translation Evaluation Metric. (arXiv:2212.08486v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08486","description":"<p>End-to-End speech-to-speech translation (S2ST) is generally evaluated with\ntext-based metrics. This means that generated speech has to be automatically\ntranscribed, making the evaluation dependent on the availability and quality of\nautomatic speech recognition (ASR) systems. In this paper, we propose a\ntext-free evaluation metric for end-to-end S2ST, named BLASER, to avoid the\ndependency on ASR systems. BLASER leverages a multilingual multimodal encoder\nto directly encode the speech segments for source input, translation output and\nreference into a shared embedding space and computes a score of the translation\nquality that can be used as a proxy to human evaluation. To evaluate our\napproach, we construct training and evaluation sets from more than 40k human\nannotations covering seven language directions. The best results of BLASER are\nachieved by training with supervision from human rating scores. We show that\nwhen evaluated at the sentence level, BLASER correlates significantly better\nwith human judgment compared to ASR-dependent metrics including ASR-SENTBLEU in\nall translation directions and ASR-COMET in five of them. Our analysis shows\ncombining speech and text as inputs to BLASER does not increase the correlation\nwith human scores, but best correlations are achieved when using speech, which\nmotivates the goal of our research. Moreover, we show that using ASR for\nreferences is detrimental for text-based metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingda Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duquenne_P/0/1/0/all/0/1\">Paul-Ambroise Duquenne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andrews_P/0/1/0/all/0/1\">Pierre Andrews</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kao_J/0/1/0/all/0/1\">Justine Kao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mourachko_A/0/1/0/all/0/1\">Alexandre Mourachko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwenk_H/0/1/0/all/0/1\">Holger Schwenk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_jussa_M/0/1/0/all/0/1\">Marta R. Costa-juss&#xe0;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Effectiveness of Text, Acoustic, and Lattice-based representations in Spoken Language Understanding tasks. (arXiv:2212.08489v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08489","description":"<p>In this paper, we perform an exhaustive evaluation of different\nrepresentations to address the intent classification problem in a Spoken\nLanguage Understanding (SLU) setup. We benchmark three types of systems to\nperform the SLU intent detection task: 1) text-based, 2) lattice-based, and a\nnovel 3) multimodal approach. Our work provides a comprehensive analysis of\nwhat could be the achievable performance of different state-of-the-art SLU\nsystems under different circumstances, e.g., automatically- vs.\nmanually-generated transcripts. We evaluate the systems on the publicly\navailable SLURP spoken language resource corpus. Our results indicate that\nusing richer forms of Automatic Speech Recognition (ASR) outputs allows SLU\nsystems to improve in comparison to the 1-best setup (4% relative improvement).\nHowever, crossmodal approaches, i.e., learning from acoustic and text\nembeddings, obtains performance similar to the oracle setup, and a relative\nimprovement of 18% over the 1-best configuration. Thus, crossmodal\narchitectures represent a good alternative to overcome the limitations of\nworking purely automatically generated textual data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Villatoro_Tello_E/0/1/0/all/0/1\">Esa&#xfa; Villatoro-Tello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madikeri_S/0/1/0/all/0/1\">Srikanth Madikeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuluaga_Gomez_J/0/1/0/all/0/1\">Juan Zuluaga-Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_B/0/1/0/all/0/1\">Bidisha Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarfjoo_S/0/1/0/all/0/1\">Seyyed Saeed Sarfjoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nigmatulina_I/0/1/0/all/0/1\">Iuliia Nigmatulina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Motlicek_P/0/1/0/all/0/1\">Petr Motlicek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ivanov_A/0/1/0/all/0/1\">Alexei V. Ivanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganapathiraju_A/0/1/0/all/0/1\">Aravind Ganapathiraju</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Check-worthy Claim Detection across Topics for Automated Fact-checking. (arXiv:2212.08514v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08514","description":"<p>An important component of an automated fact-checking system is the claim\ncheck-worthiness detection system, which ranks sentences by prioritising them\nbased on their need to be checked. Despite a body of research tackling the\ntask, previous research has overlooked the challenging nature of identifying\ncheck-worthy claims across different topics. In this paper, we assess and\nquantify the challenge of detecting check-worthy claims for new, unseen topics.\nAfter highlighting the problem, we propose the AraCWA model to mitigate the\nperformance deterioration when detecting check-worthy claims across topics. The\nAraCWA model enables boosting the performance for new topics by incorporating\ntwo components for few-shot learning and data augmentation. Using a publicly\navailable dataset of Arabic tweets consisting of 14 different topics, we\ndemonstrate that our proposed data augmentation strategy achieves substantial\nimprovements across topics overall, where the extent of the improvement varies\nacross topics. Further, we analyse the semantic similarities between topics,\nsuggesting that the similarity metric could be used as a proxy to determine the\ndifficulty level of an unseen topic prior to undertaking the task of labelling\nthe underlying sentences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abumansour_A/0/1/0/all/0/1\">Amani S. Abumansour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zubiaga_A/0/1/0/all/0/1\">Arkaitz Zubiaga</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Context-aware Fine-tuning of Self-supervised Speech Models. (arXiv:2212.08542v1 [eess.AS])","link":"http://arxiv.org/abs/2212.08542","description":"<p>Self-supervised pre-trained transformers have improved the state of the art\non a variety of speech tasks. Due to the quadratic time and space complexity of\nself-attention, they usually operate at the level of relatively short (e.g.,\nutterance) segments. In this paper, we study the use of context, i.e.,\nsurrounding segments, during fine-tuning and propose a new approach called\ncontext-aware fine-tuning. We attach a context module on top of the last layer\nof a pre-trained model to encode the whole segment into a context embedding\nvector which is then used as an additional feature for the final prediction.\nDuring the fine-tuning stage, we introduce an auxiliary loss that encourages\nthis context embedding vector to be similar to context vectors of surrounding\nsegments. This allows the model to make predictions without access to these\nsurrounding segments at inference time and requires only a tiny overhead\ncompared to standard fine-tuned models. We evaluate the proposed approach using\nthe SLUE and Librilight benchmarks for several downstream tasks: Automatic\nspeech recognition (ASR), named entity recognition (NER), and sentiment\nanalysis (SA). The results show that context-aware fine-tuning not only\noutperforms a standard fine-tuning baseline but also rivals a strong context\ninjection baseline that uses neighboring speech segments during inference.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Shon_S/0/1/0/all/0/1\">Suwon Shon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_F/0/1/0/all/0/1\">Felix Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_K/0/1/0/all/0/1\">Kwangyoun Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sridhar_P/0/1/0/all/0/1\">Prashant Sridhar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Livescu_K/0/1/0/all/0/1\">Karen Livescu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-grained Czech News Article Dataset: An Interdisciplinary Approach to Trustworthiness Analysis. (arXiv:2212.08550v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08550","description":"<p>We present the Verifee Dataset: a novel dataset of news articles with\nfine-grained trustworthiness annotations. We develop a detailed methodology\nthat assesses the texts based on their parameters encompassing editorial\ntransparency, journalist conventions, and objective reporting while penalizing\nmanipulative techniques. We bring aboard a diverse set of researchers from\nsocial, media, and computer sciences to overcome barriers and limited framing\nof this interdisciplinary problem. We collect over $10,000$ unique articles\nfrom almost $60$ Czech online news sources. These are categorized into one of\nthe $4$ classes across the credibility spectrum we propose, raging from\nentirely trustworthy articles all the way to the manipulative ones. We produce\ndetailed statistics and study trends emerging throughout the set. Lastly, we\nfine-tune multiple popular sequence-to-sequence language models using our\ndataset on the trustworthiness classification task and report the best testing\nF-1 score of $0.52$. We open-source the dataset, annotation methodology, and\nannotators' instructions in full length at https://verifee.ai/research to\nenable easy build-up work. We believe similar methods can help prevent\ndisinformation and educate in the realm of media literacy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bohacek_M/0/1/0/all/0/1\">Maty&#xe1;&#x161; Boh&#xe1;&#x10d;ek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bravansky_M/0/1/0/all/0/1\">Michal Bravansk&#xfd;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trhlik_F/0/1/0/all/0/1\">Filip Trhl&#xed;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moravec_V/0/1/0/all/0/1\">V&#xe1;clav Moravec</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is it Required? Ranking the Skills Required for a Job-Title. (arXiv:2212.08553v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08553","description":"<p>In this paper, we describe our method for ranking the skills required for a\ngiven job title. Our analysis shows that important/relevant skills appear more\nfrequently in similar job titles. We train a Language-agnostic BERT Sentence\nEncoder (LaBSE) model to predict the importance of the skills using weak\nsupervision. We show the model can learn the importance of skills and perform\nwell in other languages. Furthermore, we show how the Inverse Document\nFrequency factor of skill boosts the specialised skills.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Anand_S/0/1/0/all/0/1\">Sarthak Anand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Decorte_J/0/1/0/all/0/1\">Jens-Joris Decorte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lowie_N/0/1/0/all/0/1\">Niels Lowie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Identification of Motivation for Code-Switching in Speech Transcripts. (arXiv:2212.08565v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08565","description":"<p>Code-switching, or switching between languages, occurs for many reasons and\nhas important linguistic, sociological, and cultural implications. Multilingual\nspeakers code-switch for a variety of purposes, such as expressing emotions,\nborrowing terms, making jokes, introducing a new topic, etc. The reason for\ncode-switching may be quite useful for analysis, but is not readily apparent.\nTo remedy this situation, we annotate a new dataset of motivations for\ncode-switching in Spanish-English. We build the first system (to our knowledge)\nto automatically identify a wide range of motivations that speakers code-switch\nin everyday speech, achieving an accuracy of 75% across all motivations.\nAdditionally, we show that the system can be adapted to new language pairs,\nachieving 66% accuracy on a new language pair (Hindi-English), demonstrating\nthe cross-lingual applicability of our annotation scheme\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Belani_R/0/1/0/all/0/1\">Ritu Belani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flanigan_J/0/1/0/all/0/1\">Jeffrey Flanigan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting and Mitigating Hallucinations in Machine Translation: Model Internal Workings Alone Do Well, Sentence Similarity Even Better. (arXiv:2212.08597v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08597","description":"<p>While the problem of hallucinations in neural machine translation has long\nbeen recognized, so far the progress on its alleviation is very little. Indeed,\nrecently it turned out that without artificially encouraging models to\nhallucinate, previously existing methods fall short and even the standard\nsequence log-probability is more informative. It means that characteristics\ninternal to the model can give much more information than we expect, and before\nusing external models and measures, we first need to ask: how far can we go if\nwe use nothing but the translation model itself ? We propose to use a method\nthat evaluates the percentage of the source contribution to a generated\ntranslation. Intuitively, hallucinations are translations \"detached\" from the\nsource, hence they can be identified by low source contribution. This method\nimproves detection accuracy for the most severe hallucinations by a factor of 2\nand is able to alleviate hallucinations at test time on par with the previous\nbest approach that relies on external models. Next, if we move away from\ninternal model characteristics and allow external tools, we show that using\nsentence similarity from cross-lingual embeddings further improves these\nresults.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dale_D/0/1/0/all/0/1\">David Dale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voita_E/0/1/0/all/0/1\">Elena Voita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barrault_L/0/1/0/all/0/1\">Lo&#xef;c Barrault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_jussa_M/0/1/0/all/0/1\">Marta R. Costa-juss&#xe0;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MURMUR: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text Generation. (arXiv:2212.08607v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08607","description":"<p>Prompting large language models has enabled significant recent progress in\nmulti-step reasoning over text. However, when applied to text generation from\nsemi-structured data (e.g., graphs or tables), these methods typically suffer\nfrom low semantic coverage, hallucination, and logical inconsistency. We\npropose MURMUR, a neuro-symbolic modular approach to text generation from\nsemi-structured data with multi-step reasoning. MURMUR is a best-first search\nmethod that generates reasoning paths using: (1) neural and symbolic modules\nwith specific linguistic and logical skills, (2) a grammar whose production\nrules define valid compositions of modules, and (3) value functions that assess\nthe quality of each reasoning step. We conduct experiments on two diverse\ndata-to-text generation tasks like WebNLG and LogicNLG. These tasks differ in\ntheir data representations (graphs and tables) and span multiple linguistic and\nlogical skills. MURMUR obtains significant improvements over recent few-shot\nbaselines like direct prompting and chain-of-thought prompting, while also\nachieving comparable performance to fine-tuned GPT-2 on out-of-domain data.\nMoreover, human evaluation shows that MURMUR generates highly faithful and\ncorrect reasoning paths that lead to 26% more logically consistent summaries on\nLogicNLG, compared to direct prompting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1\">Swarnadeep Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xinyan Velocity Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasunuru_R/0/1/0/all/0/1\">Ramakanth Pasunuru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Planting and Mitigating Memorized Content in Predictive-Text Language Models. (arXiv:2212.08619v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08619","description":"<p>Language models are widely deployed to provide automatic text completion\nservices in user products. However, recent research has revealed that language\nmodels (especially large ones) bear considerable risk of memorizing private\ntraining data, which is then vulnerable to leakage and extraction by\nadversaries. In this study, we test the efficacy of a range of\nprivacy-preserving techniques to mitigate unintended memorization of sensitive\nuser text, while varying other factors such as model size and adversarial\nconditions. We test both \"heuristic\" mitigations (those without formal privacy\nguarantees) and Differentially Private training, which provides provable levels\nof privacy at the cost of some model performance. Our experiments show that\n(with the exception of L2 regularization), heuristic mitigations are largely\nineffective in preventing memorization in our test suite, possibly because they\nmake too strong of assumptions about the characteristics that define\n\"sensitive\" or \"private\" text. In contrast, Differential Privacy reliably\nprevents memorization in our experiments, despite its computational and\nmodel-performance costs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Downey_C/0/1/0/all/0/1\">C.M. Downey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Wei Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inan_H/0/1/0/all/0/1\">Huseyin A. Inan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laine_K/0/1/0/all/0/1\">Kim Laine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naik_S/0/1/0/all/0/1\">Saurabh Naik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Religa_T/0/1/0/all/0/1\">Tomasz Religa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"POTATO: The Portable Text Annotation Tool. (arXiv:2212.08620v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08620","description":"<p>We present POTATO, the Portable text annotation tool, a free, fully\nopen-sourced annotation system that 1) supports labeling many types of text and\nmultimodal data; 2) offers easy-to-configure features to maximize the\nproductivity of both deployers and annotators (convenient templates for common\nML/NLP tasks, active learning, keypress shortcuts, keyword highlights,\ntooltips); and 3) supports a high degree of customization (editable UI,\ninserting pre-screening questions, attention and qualification tests).\nExperiments over two annotation tasks suggest that POTATO improves labeling\nspeed through its specially-designed productivity features, especially for long\ndocuments and complex tasks. POTATO is available at\nhttps://github.com/davidjurgens/potato and will continue to be updated.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1\">Jiaxin Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ananthasubramaniam_A/0/1/0/all/0/1\">Aparna Ananthasubramaniam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_N/0/1/0/all/0/1\">Naitian Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sargent_J/0/1/0/all/0/1\">Jackson Sargent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dedeloudis_A/0/1/0/all/0/1\">Apostolos Dedeloudis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurgens_D/0/1/0/all/0/1\">David Jurgens</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Multi-modal and Multi-hop Question Answering via Structured Knowledge and Unified Retrieval-Generation. (arXiv:2212.08632v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08632","description":"<p>Multi-modal and multi-hop question answering aims to answer a question based\non multiple input sources from different modalities. Previous methods retrieve\nthe evidence separately and feed the retrieved evidence to a language model to\ngenerate the corresponding answer. However, these methods fail to build\nconnections between candidates and thus cannot model the inter-dependent\nrelation during retrieval. Moreover, the reasoning process over multi-modality\ncandidates can be unbalanced without building alignments between different\nmodalities. To address this limitation, we propose a Structured Knowledge and\nUnified Retrieval Generation based method (SKURG). We align the sources from\ndifferent modalities via the shared entities and map them into a shared\nsemantic space via structured knowledge. Then, we utilize a unified\nretrieval-generation decoder to integrate intermediate retrieval results for\nanswer generation and adaptively determine the number of retrieval steps. We\nperform experiments on two multi-modal and multi-hop datasets: WebQA and\nMultimodalQA. The results demonstrate that SKURG achieves state-of-the-art\nperformance on both retrieval and answer generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Baotian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Prompting Large Language Models for Open-Domain QA. (arXiv:2212.08635v1 [cs.CL])","link":"http://arxiv.org/abs/2212.08635","description":"<p>Open-Domain Question Answering (ODQA) requires models to answer factoid\nquestions with no context given. The common way for this task is to train\nmodels on a large-scale annotated dataset to retrieve related documents and\ngenerate answers based on these documents. In this paper, we show that the ODQA\narchitecture can be dramatically simplified by treating Large Language Models\n(LLMs) as a knowledge corpus and propose a Self-Prompting framework for LLMs to\nperform ODQA so as to eliminate the need for training data and external\nknowledge corpus. Concretely, we firstly generate multiple pseudo QA pairs with\nbackground passages and one-sentence explanations for these QAs by prompting\nLLMs step by step and then leverage the generated QA pairs for in-context\nlearning. Experimental results show our method surpasses previous\nstate-of-the-art methods by +8.8 EM averagely on three widely-used ODQA\ndatasets, and even achieves comparable performance with several\nretrieval-augmented fine-tuned models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junlong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"General Mechanism of Evolution Shared by Proteins and Words. (arXiv:2012.14309v2 [q-bio.PE] UPDATED)","link":"http://arxiv.org/abs/2012.14309","description":"<p>Complex systems, such as life and languages, are governed by principles of\nevolution. The analogy and comparison between biology and\nlinguistics\\cite{alphafold2, RoseTTAFold, lang_virus, cell language, faculty1,\nlanguage of gene, Protein linguistics, dictionary, Grammar of pro_dom,\ncomplexity, genomics_nlp, InterPro, language modeling, Protein language\nmodeling} provide a computational foundation for characterizing and analyzing\nprotein sequences, human corpora, and their evolution. However, no general\nmathematical formula has been proposed so far to illuminate the origin of\nquantitative hallmarks shared by life and language. Here we show several new\nstatistical relationships shared by proteins and words, which inspire us to\nestablish a general mechanism of evolution with explicit formulations that can\nincorporate both old and new characteristics. We found natural selection can be\nquantified via the entropic formulation by the principle of least effort to\ndetermine the sequence variation that survives in evolution. Besides, the\norigin of power law behavior and how changes in the environment stimulate the\nemergence of new proteins and words can also be explained via the introduction\nof function connection network. Our results demonstrate not only the\ncorrespondence between genetics and linguistics over their different\nhierarchies but also new fundamental physical properties for the evolution of\ncomplex adaptive systems. We anticipate our statistical tests can function as\nquantitative criteria to examine whether an evolution theory of sequence is\nconsistent with the regularity of real data. In the meantime, their\ncorrespondence broadens the bridge to exchange existing knowledge, spurs new\ninterpretations, and opens Pandora's box to release several potentially\nrevolutionary challenges. For example, does linguistic arbitrariness conflict\nwith the dogma that structure determines function?\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_L/0/1/0/all/0/1\">Li-Min Wang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lai_H/0/1/0/all/0/1\">Hsing-Yi Lai</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Tsai_S/0/1/0/all/0/1\">Sun-Ting Tsai</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ng_C/0/1/0/all/0/1\">Chen Siang Ng</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wu_S/0/1/0/all/0/1\">Shan-Jyun Wu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Tsai_M/0/1/0/all/0/1\">Meng-Xue Tsai</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Su_Y/0/1/0/all/0/1\">Yi-Ching Su</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_D/0/1/0/all/0/1\">Daw-Wei Wang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hong_T/0/1/0/all/0/1\">Tzay-Ming Hong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adapting the Tesseract Open-Source OCR Engine for Tamil and Sinhala Legacy Fonts and Creating a Parallel Corpus for Tamil-Sinhala-English. (arXiv:2109.05952v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.05952","description":"<p>Most low-resource languages do not have the necessary resources to create\neven a substantial monolingual corpus. These languages may often be found in\ngovernment proceedings but mainly in Portable Document Format (PDF) that\ncontains legacy fonts. Extracting text from these documents to create a\nmonolingual corpus is challenging due to legacy font usage and printer-friendly\nencoding, which are not optimized for text extraction. Therefore, we propose a\nsimple, automatic, and novel idea that can scale for Tamil, Sinhala, English\nlanguages, and many documents along with parallel corpora. Since Tamil and\nSinhala are Low-Resource Languages, we improved the performance of Tesseract by\nemploying LSTM-based training on more than 20 legacy fonts to recognize printed\ncharacters in these languages. Especially, our model detects code-mixed text,\nnumbers, and special characters from the printed document. It is shown that\nthis approach can reduce the character-level error rate of Tesseract from 6.03\nto 2.61 for Tamil (-3.42% relative change) and 7.61 to 4.74 for Sinhala (-2.87%\nrelative change), as well as the word-level error rate from 39.68 to 20.61 for\nTamil (-19.07% relative change) and 35.04 to 26.58 for Sinhala (-8.46% relative\nchange) on the test set. Also, our newly created parallel corpus consists of\n185.4k, 168.9k, and 181.04k sentences and 2.11M, 2.22M, and 2.33M Words in\nTamil, Sinhala, and English respectively. This study shows that fine-tuning\nTesseract models on multiple new fonts help to understand the texts and\nenhances the performance of the OCR. We made newly trained models and the\nsource code for fine-tuning Tesseract, freely available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vasantharajan_C/0/1/0/all/0/1\">Charangan Vasantharajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tharmalingam_L/0/1/0/all/0/1\">Laksika Tharmalingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thayasivam_U/0/1/0/all/0/1\">Uthayasanker Thayasivam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detect, Retrieve, Comprehend: A Flexible Framework for Zero-Shot Document-Level Question Answering. (arXiv:2210.01959v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.01959","description":"<p>Researchers produce thousands of scholarly documents containing valuable\ntechnical knowledge. The community faces the laborious task of reading these\ndocuments to identify, extract, and synthesize information. To automate\ninformation gathering, document-level question answering (QA) offers a flexible\nframework where human-posed questions can be adapted to extract diverse\nknowledge. Finetuning QA systems requires access to labeled data (tuples of\ncontext, question and answer). However, data curation for document QA is\nuniquely challenging because the context (i.e. answer evidence passage) needs\nto be retrieved from potentially long, ill-formatted documents. Existing QA\ndatasets sidestep this challenge by providing short, well-defined contexts that\nare unrealistic in real-world applications. We present a three-stage document\nQA approach: (1) text extraction from PDF; (2) evidence retrieval from\nextracted texts to form well-posed contexts; (3) QA to extract knowledge from\ncontexts to return high-quality answers -- extractive, abstractive, or Boolean.\nUsing QASPER for evaluation, our detect-retrieve-comprehend (DRC) system\nachieves a +7.19 improvement in Answer-F1 over existing baselines while\ndelivering superior context selection. Our results demonstrate that DRC holds\ntremendous promise as a flexible framework for practical scientific document\nQA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+McDonald_T/0/1/0/all/0/1\">Tavish McDonald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsan_B/0/1/0/all/0/1\">Brian Tsan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saini_A/0/1/0/all/0/1\">Amar Saini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ordonez_J/0/1/0/all/0/1\">Juanita Ordonez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_L/0/1/0/all/0/1\">Luis Gutierrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1\">Phan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mason_B/0/1/0/all/0/1\">Blake Mason</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_B/0/1/0/all/0/1\">Brenda Ng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Numerical Optimizations for Weighted Low-rank Estimation on Language Model. (arXiv:2211.09718v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.09718","description":"<p>Singular value decomposition (SVD) is one of the most popular compression\nmethods that approximate a target matrix with smaller matrices. However,\nstandard SVD treats the parameters within the matrix with equal importance,\nwhich is a simple but unrealistic assumption. The parameters of a trained\nneural network model may affect task performance unevenly, which suggests\nnon-equal importance among the parameters. Compared to SVD, the decomposition\nmethod aware of parameter importance is the more practical choice in real\ncases. Unlike standard SVD, weighted value decomposition is a non-convex\noptimization problem that lacks a closed-form solution. We systematically\ninvestigated multiple optimization strategies to tackle the problem and\nexamined our method by compressing Transformer-based language models. Further,\nwe designed a metric to predict when the SVD may introduce a significant\nperformance drop, for which our method can be a rescue strategy. The extensive\nevaluations demonstrate that our method can perform better than current SOTA\nmethods in compressing Transformer-based language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hua_T/0/1/0/all/0/1\">Ting Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_Y/0/1/0/all/0/1\">Yen-Chang Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Felicity Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_Q/0/1/0/all/0/1\">Qian Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yilin Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Hongxia Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Probabilistic-Logic based Commonsense Representation Framework for Modelling Inferences with Multiple Antecedents and Varying Likelihoods. (arXiv:2211.16822v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.16822","description":"<p>Commonsense knowledge-graphs (CKGs) are important resources towards building\nmachines that can 'reason' on text or environmental inputs and make inferences\nbeyond perception. While current CKGs encode world knowledge for a large number\nof concepts and have been effectively utilized for incorporating commonsense in\nneural models, they primarily encode declarative or single-condition\ninferential knowledge and assume all conceptual beliefs to have the same\nlikelihood. Further, these CKGs utilize a limited set of relations shared\nacross concepts and lack a coherent knowledge organization structure resulting\nin redundancies as well as sparsity across the larger knowledge graph.\nConsequently, today's CKGs, while useful for a first level of reasoning, do not\nadequately capture deeper human-level commonsense inferences which can be more\nnuanced and influenced by multiple contextual or situational factors.\n</p>\n<p>Accordingly, in this work, we study how commonsense knowledge can be better\nrepresented by -- (i) utilizing a probabilistic logic representation scheme to\nmodel composite inferential knowledge and represent conceptual beliefs with\nvarying likelihoods and (ii) incorporating a hierarchical conceptual ontology\nto identify salient concept-relevant relations and organize beliefs at\ndifferent conceptual levels. Our resulting knowledge representation framework\ncan encode a wider variety of world knowledge and represent beliefs flexibly\nusing grounded concepts as well as free-text phrases. As a result, the\nframework can be utilized as both a traditional free-text knowledge graph and a\ngrounded logic-based inference system more suitable for neuro-symbolic\napplications. We describe how we extend the PrimeNet knowledge base with our\nframework through crowd-sourcing and expert-annotation, and demonstrate its\napplication for more interpretable passage-based semantic parsing and question\nanswering.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jaiswal_S/0/1/0/all/0/1\">Shantanu Jaiswal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_L/0/1/0/all/0/1\">Liu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_D/0/1/0/all/0/1\">Dongkyu Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwok_K/0/1/0/all/0/1\">Kenneth Kwok</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AUC Maximization for Low-Resource Named Entity Recognition. (arXiv:2212.04800v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.04800","description":"<p>Current work in named entity recognition (NER) uses either cross entropy (CE)\nor conditional random fields (CRF) as the objective/loss functions to optimize\nthe underlying NER model. Both of these traditional objective functions for the\nNER problem generally produce adequate performance when the data distribution\nis balanced and there are sufficient annotated training examples. But since NER\nis inherently an imbalanced tagging problem, the model performance under the\nlow-resource settings could suffer using these standard objective functions.\nBased on recent advances in area under the ROC curve (AUC) maximization, we\npropose to optimize the NER model by maximizing the AUC score. We give evidence\nthat by simply combining two binary-classifiers that maximize the AUC score,\nsignificant performance improvement over traditional loss functions is achieved\nunder low-resource NER settings. We also conduct extensive experiments to\ndemonstrate the advantages of our method under the low-resource and\nhighly-imbalanced data distribution settings. To the best of our knowledge,\nthis is the first work that brings AUC maximization to the NER setting.\nFurthermore, we show that our method is agnostic to different types of NER\nembeddings, models and domains. The code to replicate this work will be\nprovided upon request.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Ngoc Dang Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1\">Wei Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buntine_W/0/1/0/all/0/1\">Wray Buntine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beare_R/0/1/0/all/0/1\">Richard Beare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changyou Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Lan Du</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards mapping the contemporary art world with ArtLM: an art-specific NLP model. (arXiv:2212.07127v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.07127","description":"<p>With an increasing amount of data in the art world, discovering artists and\nartworks suitable to collectors' tastes becomes a challenge. It is no longer\nenough to use visual information, as contextual information about the artist\nhas become just as important in contemporary art. In this work, we present a\ngeneric Natural Language Processing framework (called ArtLM) to discover the\nconnections among contemporary artists based on their biographies. In this\napproach, we first continue to pre-train the existing general English language\nmodels with a large amount of unlabelled art-related data. We then fine-tune\nthis new pre-trained model with our biography pair dataset manually annotated\nby a team of professionals in the art industry. With extensive experiments, we\ndemonstrate that our ArtLM achieves 85.6% accuracy and 84.0% F1 score and\noutperforms other baseline models. We also provide a visualisation and a\nqualitative analysis of the artist network built from ArtLM's outputs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qinkai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Mennaoui_M/0/1/0/all/0/1\">Mohamed El-Mennaoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fosset_A/0/1/0/all/0/1\">Antoine Fosset</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rebei_A/0/1/0/all/0/1\">Amine Rebei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_H/0/1/0/all/0/1\">Haoyang Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouscasse_P/0/1/0/all/0/1\">Philine Bouscasse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OBeirne_C/0/1/0/all/0/1\">Christy E&#xf3;in O&#x27;Beirne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shevchenko_S/0/1/0/all/0/1\">Sasha Shevchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenbaum_M/0/1/0/all/0/1\">Mathieu Rosenbaum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Linguistically Informed Multi-Objective Pre-Training for Natural Language Inference. (arXiv:2212.07428v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.07428","description":"<p>We introduce a linguistically enhanced combination of pre-training methods\nfor transformers. The pre-training objectives include POS-tagging, synset\nprediction based on semantic knowledge graphs, and parent prediction based on\ndependency parse trees. Our approach achieves competitive results on the\nNatural Language Inference task, compared to the state of the art. Specifically\nfor smaller models, the method results in a significant performance boost,\nemphasizing the fact that intelligent pre-training can make up for fewer\nparameters and help building more efficient models. Combining POS-tagging and\nsynset prediction yields the overall best results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pielka_M/0/1/0/all/0/1\">Maren Pielka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_S/0/1/0/all/0/1\">Svetlana Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pucknat_L/0/1/0/all/0/1\">Lisa Pucknat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sifa_R/0/1/0/all/0/1\">Rafet Sifa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2022-12-18T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"syn":"http://purl.org/rss/1.0/modules/syndication/","dc":"http://purl.org/dc/elements/1.1/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","admin":"http://webns.net/mvcb/"}}]}]}