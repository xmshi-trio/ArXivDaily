{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-03-13T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Open World Classification with Adaptive Negative Samples. (arXiv:2303.05581v1 [cs.CL])","link":"http://arxiv.org/abs/2303.05581","description":"<p>Open world classification is a task in natural language processing with key\npractical relevance and impact. Since the open or {\\em unknown} category data\nonly manifests in the inference phase, finding a model with a suitable decision\nboundary accommodating for the identification of known classes and\ndiscrimination of the open category is challenging. The performance of existing\nmodels is limited by the lack of effective open category data during the\ntraining stage or the lack of a good mechanism to learn appropriate decision\nboundaries. We propose an approach based on \\underline{a}daptive\n\\underline{n}egative \\underline{s}amples (ANS) designed to generate effective\nsynthetic open category samples in the training stage and without requiring any\nprior knowledge or external datasets. Empirically, we find a significant\nadvantage in using auxiliary one-versus-rest binary classifiers, which\neffectively utilize the generated negative samples and avoid the complex\nthreshold-seeking stage in previous works. Extensive experiments on three\nbenchmark datasets show that ANS achieves significant improvements over\nstate-of-the-art methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bai_K/0/1/0/all/0/1\">Ke Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoyin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sunghyun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sungjin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Puyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henao_R/0/1/0/all/0/1\">Ricardo Henao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carin_L/0/1/0/all/0/1\">Lawrence Carin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Logic Against Bias: Textual Entailment Mitigates Stereotypical Sentence Reasoning. (arXiv:2303.05670v1 [cs.CL])","link":"http://arxiv.org/abs/2303.05670","description":"<p>Due to their similarity-based learning objectives, pretrained sentence\nencoders often internalize stereotypical assumptions that reflect the social\nbiases that exist within their training corpora. In this paper, we describe\nseveral kinds of stereotypes concerning different communities that are present\nin popular sentence representation models, including pretrained next sentence\nprediction and contrastive sentence representation models. We compare such\nmodels to textual entailment models that learn language logic for a variety of\ndownstream language understanding tasks. By comparing strong pretrained models\nbased on text similarity with textual entailment learning, we conclude that the\nexplicit logic learning with textual entailment can significantly reduce bias\nand improve the recognition of social communities, without an explicit\nde-biasing process\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Hongyin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MuLTI: Efficient Video-and-Language Understanding with MultiWay-Sampler and Multiple Choice Modeling. (arXiv:2303.05707v1 [cs.CV])","link":"http://arxiv.org/abs/2303.05707","description":"<p>Video-and-language understanding has a variety of applications in the\nindustry, such as video question answering, text-video retrieval and\nmulti-label classification. Existing video-and-language understanding methods\ngenerally adopt heavy multi-modal encoders and feature fusion modules, which\nconsume large amounts of GPU memory. Especially, they have difficulty dealing\nwith dense video frames or long text that are prevalent in industrial\napplications. In this paper, we propose MuLTI, a highly accurate and\nmemory-efficient video-and-language understanding model that achieves efficient\nand effective feature fusion through feature sampling and attention modules.\nTherefore, MuLTI can handle longer sequences with limited GPU memory. Then, we\nintroduce an attention-based adapter to the encoders, which finetunes the\nshallow features to improve the model's performance with low GPU memory\nconsumption. Finally, to further improve the model's performance, we introduce\na new pretraining task named Multiple Choice Modeling to bridge the task gap\nbetween pretraining and downstream tasks and enhance the model's ability to\nalign the video and the text. Benefiting from the efficient feature fusion\nmodule, the attention-based adapter and the new pretraining task, MuLTI\nachieves state-of-the-art performance on multiple datasets. Implementation and\npretrained models will be released.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiaqi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunkuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Mengli Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xing Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Clinical BERTScore: An Improved Measure of Automatic Speech Recognition Performance in Clinical Settings. (arXiv:2303.05737v1 [eess.AS])","link":"http://arxiv.org/abs/2303.05737","description":"<p>Automatic Speech Recognition (ASR) in medical contexts has the potential to\nsave time, cut costs, increase report accuracy, and reduce physician burnout.\nHowever, the healthcare industry has been slower to adopt this technology, in\npart due to the importance of avoiding medically-relevant transcription\nmistakes. In this work, we present the Clinical BERTScore (CBERTScore), an ASR\nmetric that penalizes clinically-relevant mistakes more than others. We\ndemonstrate that this metric more closely aligns with clinician preferences on\nmedical sentences as compared to other metrics (WER, BLUE, METEOR, etc),\nsometimes by wide margins. We collect a benchmark of 13 clinician preferences\non 149 realistic medical sentences called the Clinician Transcript Preference\nbenchmark (CTP), demonstrate that CBERTScore more closely matches what\nclinicians prefer, and release the benchmark for the community to further\ndevelop clinically-aware ASR metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Shor_J/0/1/0/all/0/1\">Joel Shor</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bi_R/0/1/0/all/0/1\">Ruyue Agnes Bi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Venugopalan_S/0/1/0/all/0/1\">Subhashini Venugopalan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ibara_S/0/1/0/all/0/1\">Steven Ibara</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Goldenberg_R/0/1/0/all/0/1\">Roman Goldenberg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rivlen_E/0/1/0/all/0/1\">Ehud Rivlen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MIXPGD: Hybrid Adversarial Training for Speech Recognition Systems. (arXiv:2303.05758v1 [cs.SD])","link":"http://arxiv.org/abs/2303.05758","description":"<p>Automatic speech recognition (ASR) systems based on deep neural networks are\nweak against adversarial perturbations. We propose mixPGD adversarial training\nmethod to improve the robustness of the model for ASR systems. In standard\nadversarial training, adversarial samples are generated by leveraging\nsupervised or unsupervised methods. We merge the capabilities of both\nsupervised and unsupervised approaches in our method to generate new\nadversarial samples which aid in improving model robustness. Extensive\nexperiments and comparison across various state-of-the-art defense methods and\nadversarial attacks have been performed to show that mixPGD gains 4.1% WER of\nbetter performance than previous best performing models under white-box\nadversarial attack setting. We tested our proposed defense method against both\nwhite-box and transfer based black-box attack settings to ensure that our\ndefense strategy is robust against various types of attacks. Empirical results\non several adversarial attacks validate the effectiveness of our proposed\napproach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huq_A/0/1/0/all/0/1\">Aminul Huq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weiyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiaolin Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Overview on Language Models: Recent Developments and Outlook. (arXiv:2303.05759v1 [cs.CL])","link":"http://arxiv.org/abs/2303.05759","description":"<p>Language modeling studies the probability distributions over strings of\ntexts. It is one of the most fundamental tasks in natural language processing\n(NLP). It has been widely used in text generation, speech recognition, machine\ntranslation, etc. Conventional language models (CLMs) aim to predict the\nprobability of linguistic sequences in a causal manner. In contrast,\npre-trained language models (PLMs) cover broader concepts and can be used in\nboth causal sequential modeling and fine-tuning for downstream applications.\nPLMs have their own training paradigms (usually self-supervised) and serve as\nfoundation models in modern NLP systems. This overview paper provides an\nintroduction to both CLMs and PLMs from five aspects, i.e., linguistic units,\nstructures, training methods, evaluation methods, and applications.\nFurthermore, we discuss the relationship between CLMs and PLMs and shed light\non the future directions of language modeling in the pre-trained era.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Chengwei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yun-Cheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1\">C.-C. Jay Kuo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An algebraic approach to translating Japanese. (arXiv:2303.05834v1 [cs.CL])","link":"http://arxiv.org/abs/2303.05834","description":"<p>We use Lambek's pregroups and the framework of compositional distributional\nmodels of language (\"DisCoCat\") to study translations from Japanese to English\nas pairs of functors. Adding decorations to pregroups we show how to handle\nword order changes between languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Boboc_V/0/1/0/all/0/1\">Valentin Boboc</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Creation and evaluation of timelines for longitudinal user posts. (arXiv:2303.05891v1 [cs.CL])","link":"http://arxiv.org/abs/2303.05891","description":"<p>There is increasing interest to work with user generated content in social\nmedia, especially textual posts over time. Currently there is no consistent way\nof segmenting user posts into timelines in a meaningful way that improves the\nquality and cost of manual annotation. Here we propose a set of methods for\nsegmenting longitudinal user posts into timelines likely to contain interesting\nmoments of change in a user's behaviour, based on their online posting\nactivity. We also propose a novel framework for evaluating timelines and show\nits applicability in the context of two different social media datasets.\nFinally, we present a discussion of the linguistic content of highly ranked\ntimelines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hills_A/0/1/0/all/0/1\">Anthony Hills</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsakalidis_A/0/1/0/all/0/1\">Adam Tsakalidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nanni_F/0/1/0/all/0/1\">Federico Nanni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zachos_I/0/1/0/all/0/1\">Ioannis Zachos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liakata_M/0/1/0/all/0/1\">Maria Liakata</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Robust Knowledge Distillation from RNN-T Models With Noisy Training Labels Using Full-Sum Loss. (arXiv:2303.05958v1 [cs.CL])","link":"http://arxiv.org/abs/2303.05958","description":"<p>This work studies knowledge distillation (KD) and addresses its constraints\nfor recurrent neural network transducer (RNN-T) models. In hard distillation, a\nteacher model transcribes large amounts of unlabelled speech to train a student\nmodel. Soft distillation is another popular KD method that distills the output\nlogits of the teacher model. Due to the nature of RNN-T alignments, applying\nsoft distillation between RNN-T architectures having different posterior\ndistributions is challenging. In addition, bad teachers having high\nword-error-rate (WER) reduce the efficacy of KD. We investigate how to\neffectively distill knowledge from variable quality ASR teachers, which has not\nbeen studied before to the best of our knowledge. We show that a sequence-level\nKD, full-sum distillation, outperforms other distillation methods for RNN-T\nmodels, especially for bad teachers. We also propose a variant of full-sum\ndistillation that distills the sequence discriminative knowledge of the teacher\nleading to further improvement in WER. We conduct experiments on public\ndatasets namely SpeechStew and LibriSpeech, and on in-house production data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeineldeen_M/0/1/0/all/0/1\">Mohammad Zeineldeen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Audhkhasi_K/0/1/0/all/0/1\">Kartik Audhkhasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baskar_M/0/1/0/all/0/1\">Murali Karthick Baskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramabhadran_B/0/1/0/all/0/1\">Bhuvana Ramabhadran</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is In-hospital Meta-information Useful for Abstractive Discharge Summary Generation?. (arXiv:2303.06002v1 [cs.CL])","link":"http://arxiv.org/abs/2303.06002","description":"<p>During the patient's hospitalization, the physician must record daily\nobservations of the patient and summarize them into a brief document called\n\"discharge summary\" when the patient is discharged. Automated generation of\ndischarge summary can greatly relieve the physicians' burden, and has been\naddressed recently in the research community. Most previous studies of\ndischarge summary generation using the sequence-to-sequence architecture focus\non only inpatient notes for input. However, electric health records (EHR) also\nhave rich structured metadata (e.g., hospital, physician, disease, length of\nstay, etc.) that might be useful. This paper investigates the effectiveness of\nmedical meta-information for summarization tasks. We obtain four types of\nmeta-information from the EHR systems and encode each meta-information into a\nsequence-to-sequence model. Using Japanese EHRs, meta-information encoded\nmodels increased ROUGE-1 by up to 4.45 points and BERTScore by 3.77 points over\nthe vanilla Longformer. Also, we found that the encoded meta-information\nimproves the precisions of its related terms in the outputs. Our results showed\nthe benefit of the use of medical meta-information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ando_K/0/1/0/all/0/1\">Kenichiro Ando</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komachi_M/0/1/0/all/0/1\">Mamoru Komachi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okumura_T/0/1/0/all/0/1\">Takashi Okumura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horiguchi_H/0/1/0/all/0/1\">Hiromasa Horiguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsumoto_Y/0/1/0/all/0/1\">Yuji Matsumoto</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"wav2vec and its current potential to Automatic Speech Recognition in German for the usage in Digital History: A comparative assessment of available ASR-technologies for the use in cultural heritage contexts. (arXiv:2303.06026v1 [eess.AS])","link":"http://arxiv.org/abs/2303.06026","description":"<p>In this case study we trained and published a state-of-the-art open-source\nmodel for Automatic Speech Recognition (ASR) for German to evaluate the current\npotential of this technology for the use in the larger context of Digital\nHumanities and cultural heritage indexation. Along with this paper we publish\nour wav2vec2 based speech to text model while we evaluate its performance on a\ncorpus of historical recordings we assembled compared against commercial\ncloud-based and proprietary services. While our model achieves moderate\nresults, we see that proprietary cloud services fare significantly better. As\nour results show, recognition rates over 90 percent can currently be achieved,\nhowever, these numbers drop quickly once the recordings feature limited audio\nquality or use of non-every day or outworn language. A big issue is the high\nvariety of different dialects and accents in the German language. Nevertheless,\nthis paper highlights that the currently available quality of recognition is\nhigh enough to address various use cases in the Digital Humanities. We argue\nthat ASR will become a key technology for the documentation and analysis of\naudio-visual sources and identify an array of important questions that the DH\ncommunity and cultural heritage stakeholders will have to address in the near\nfuture.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Fleck_M/0/1/0/all/0/1\">Michael Fleck</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Goderle_W/0/1/0/all/0/1\">Wolfgang G&#xf6;derle</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Susceptibility to Influence of Large Language Models. (arXiv:2303.06074v1 [cs.CL])","link":"http://arxiv.org/abs/2303.06074","description":"<p>Two studies tested the hypothesis that a Large Language Model (LLM) can be\nused to model psychological change following exposure to influential input. The\nfirst study tested a generic mode of influence - the Illusory Truth Effect\n(ITE) - where earlier exposure to a statement (through, for example, rating its\ninterest) boosts a later truthfulness test rating. Data was collected from 1000\nhuman participants using an online experiment, and 1000 simulated participants\nusing engineered prompts and LLM completion. 64 ratings per participant were\ncollected, using all exposure-test combinations of the attributes: truth,\ninterest, sentiment and importance. The results for human participants\nreconfirmed the ITE, and demonstrated an absence of effect for attributes other\nthan truth, and when the same attribute is used for exposure and test. The same\npattern of effects was found for LLM-simulated participants. The second study\nconcerns a specific mode of influence - populist framing of news to increase\nits persuasion and political mobilization. Data from LLM-simulated participants\nwas collected and compared to previously published data from a 15-country\nexperiment on 7286 human participants. Several effects previously demonstrated\nfrom the human study were replicated by the simulated study, including effects\nthat surprised the authors of the human study by contradicting their\ntheoretical expectations (anti-immigrant framing of news decreases its\npersuasion and mobilization); but some significant relationships found in human\ndata (modulation of the effectiveness of populist framing according to relative\ndeprivation of the participant) were not present in the LLM data. Together the\ntwo studies support the view that LLMs have potential to act as models of the\neffect of influence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Griffin_L/0/1/0/all/0/1\">Lewis D Griffin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleinberg_B/0/1/0/all/0/1\">Bennett Kleinberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozes_M/0/1/0/all/0/1\">Maximilian Mozes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mai_K/0/1/0/all/0/1\">Kimberly T Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vau_M/0/1/0/all/0/1\">Maria Vau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caldwell_M/0/1/0/all/0/1\">Matthew Caldwell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marvor_Parker_A/0/1/0/all/0/1\">Augustine Marvor-Parker</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rewarding Chatbots for Real-World Engagement with Millions of Users. (arXiv:2303.06135v1 [cs.CL])","link":"http://arxiv.org/abs/2303.06135","description":"<p>The emergence of pretrained large language models has led to the deployment\nof a range of social chatbots for chitchat. Although these chatbots demonstrate\nlanguage ability and fluency, they are not guaranteed to be engaging and can\nstruggle to retain users. This work investigates the development of social\nchatbots that prioritize user engagement to enhance retention, specifically\nexamining the use of human feedback to efficiently develop highly engaging\nchatbots. The proposed approach uses automatic pseudo-labels collected from\nuser interactions to train a reward model that can be used to reject\nlow-scoring sample responses generated by the chatbot model at inference time.\nIntuitive evaluation metrics, such as mean conversation length (MCL), are\nintroduced as proxies to measure the level of engagement of deployed chatbots.\nA/B testing on groups of 10,000 new daily chatbot users on the Chai Research\nplatform shows that this approach increases the MCL by up to 70%, which\ntranslates to a more than 30% increase in user retention for a GPT-J 6B model.\nFuture work aims to use the reward model to realise a data fly-wheel, where the\nlatest user conversations can be used to alternately fine-tune the language\nmodel and the reward model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Irvine_R/0/1/0/all/0/1\">Robert Irvine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boubert_D/0/1/0/all/0/1\">Douglas Boubert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raina_V/0/1/0/all/0/1\">Vyas Raina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liusie_A/0/1/0/all/0/1\">Adian Liusie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mudupalli_V/0/1/0/all/0/1\">Vineet Mudupalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korshuk_A/0/1/0/all/0/1\">Aliaksei Korshuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zongyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cremer_F/0/1/0/all/0/1\">Fritz Cremer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assassi_V/0/1/0/all/0/1\">Valentin Assassi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beauchamp_C/0/1/0/all/0/1\">Christie-Carol Beauchamp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiaoding Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rialan_T/0/1/0/all/0/1\">Thomas Rialan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beauchamp_W/0/1/0/all/0/1\">William Beauchamp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Attention Networks Can Process Bounded Hierarchical Languages. (arXiv:2105.11115v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2105.11115","description":"<p>Despite their impressive performance in NLP, self-attention networks were\nrecently proved to be limited for processing formal languages with hierarchical\nstructure, such as $\\mathsf{Dyck}_k$, the language consisting of well-nested\nparentheses of $k$ types. This suggested that natural language can be\napproximated well with models that are too weak for formal languages, or that\nthe role of hierarchy and recursion in natural language might be limited. We\nqualify this implication by proving that self-attention networks can process\n$\\mathsf{Dyck}_{k, D}$, the subset of $\\mathsf{Dyck}_{k}$ with depth bounded by\n$D$, which arguably better captures the bounded hierarchical structure of\nnatural language. Specifically, we construct a hard-attention network with\n$D+1$ layers and $O(\\log k)$ memory size (per token per layer) that recognizes\n$\\mathsf{Dyck}_{k, D}$, and a soft-attention network with two layers and\n$O(\\log k)$ memory size that generates $\\mathsf{Dyck}_{k, D}$. Experiments show\nthat self-attention networks trained on $\\mathsf{Dyck}_{k, D}$ generalize to\nlonger inputs with near-perfect accuracy, and also verify the theoretical\nmemory advantage of self-attention networks over recurrent networks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_S/0/1/0/all/0/1\">Shunyu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Binghui Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papadimitriou_C/0/1/0/all/0/1\">Christos Papadimitriou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Arabic aspect sentiment polarity classification using BERT. (arXiv:2107.13290v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.13290","description":"<p>Aspect-based sentiment analysis(ABSA) is a textual analysis methodology that\ndefines the polarity of opinions on certain aspects related to specific\ntargets. The majority of research on ABSA is in English, with a small amount of\nwork available in Arabic. Most previous Arabic research has relied on deep\nlearning models that depend primarily on context-independent word embeddings\n(e.g.word2vec), where each word has a fixed representation independent of its\ncontext. This article explores the modeling capabilities of contextual\nembeddings from pre-trained language models, such as BERT, and making use of\nsentence pair input on Arabic aspect sentiment polarity classification task. In\nparticular, we develop a simple but effective BERT-based neural baseline to\nhandle this task. Our BERT architecture with a simple linear classification\nlayer surpassed the state-of-the-art works, according to the experimental\nresults on three different Arabic datasets. Achieving an accuracy of 89.51% on\nthe Arabic hotel reviews dataset, 73% on the Human annotated book reviews\ndataset, and 85.73% on the Arabic news dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abdelgwad_M/0/1/0/all/0/1\">Mohammed M.Abdelgwad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soliman_T/0/1/0/all/0/1\">Taysir Hassan A Soliman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taloba_A/0/1/0/all/0/1\">Ahmed I.Taloba</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Kind Introduction to Lexical and Grammatical Aspect, with a Survey of Computational Approaches. (arXiv:2208.09012v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.09012","description":"<p>Aspectual meaning refers to how the internal temporal structure of situations\nis presented. This includes whether a situation is described as a state or as\nan event, whether the situation is finished or ongoing, and whether it is\nviewed as a whole or with a focus on a particular phase. This survey gives an\noverview of computational approaches to modeling lexical and grammatical aspect\nalong with intuitive explanations of the necessary linguistic concepts and\nterminology. In particular, we describe the concepts of stativity, telicity,\nhabituality, perfective and imperfective, as well as influential inventories of\neventuality and situation types. We argue that because aspect is a crucial\ncomponent of semantics, especially when it comes to reporting the temporal\nstructure of situations in a precise way, future NLP approaches need to be able\nto handle and evaluate it systematically in order to achieve human-level\nlanguage understanding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Friedrich_A/0/1/0/all/0/1\">Annemarie Friedrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_N/0/1/0/all/0/1\">Nianwen Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palmer_A/0/1/0/all/0/1\">Alexis Palmer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ReAct: Synergizing Reasoning and Acting in Language Models. (arXiv:2210.03629v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.03629","description":"<p>While large language models (LLMs) have demonstrated impressive capabilities\nacross tasks in language understanding and interactive decision making, their\nabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g.\naction plan generation) have primarily been studied as separate topics. In this\npaper, we explore the use of LLMs to generate both reasoning traces and\ntask-specific actions in an interleaved manner, allowing for greater synergy\nbetween the two: reasoning traces help the model induce, track, and update\naction plans as well as handle exceptions, while actions allow it to interface\nwith external sources, such as knowledge bases or environments, to gather\nadditional information. We apply our approach, named ReAct, to a diverse set of\nlanguage and decision making tasks and demonstrate its effectiveness over\nstate-of-the-art baselines, as well as improved human interpretability and\ntrustworthiness over methods without reasoning or acting components.\nConcretely, on question answering (HotpotQA) and fact verification (Fever),\nReAct overcomes issues of hallucination and error propagation prevalent in\nchain-of-thought reasoning by interacting with a simple Wikipedia API, and\ngenerates human-like task-solving trajectories that are more interpretable than\nbaselines without reasoning traces. On two interactive decision making\nbenchmarks (ALFWorld and WebShop), ReAct outperforms imitation and\nreinforcement learning methods by an absolute success rate of 34% and 10%\nrespectively, while being prompted with only one or two in-context examples.\nProject site with code: https://react-lm.github.io\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_S/0/1/0/all/0/1\">Shunyu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jeffrey Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_N/0/1/0/all/0/1\">Nan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafran_I/0/1/0/all/0/1\">Izhak Shafran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yuan Cao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Adaptive Named Entity Recognition by Retrieving Unstructured Knowledge. (arXiv:2210.07523v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.07523","description":"<p>Although named entity recognition (NER) helps us to extract domain-specific\nentities from text (e.g., artists in the music domain), it is costly to create\na large amount of training data or a structured knowledge base to perform\naccurate NER in the target domain. Here, we propose self-adaptive NER, which\nretrieves external knowledge from unstructured text to learn the usages of\nentities that have not been learned well. To retrieve useful knowledge for NER,\nwe design an effective two-stage model that retrieves unstructured knowledge\nusing uncertain entities as queries. Our model predicts the entities in the\ninput and then finds those of which the prediction is not confident. Then, it\nretrieves knowledge by using these uncertain entities as queries and\nconcatenates the retrieved text to the original input to revise the prediction.\nExperiments on CrossNER datasets demonstrated that our model outperforms strong\nbaselines by 2.35 points in F1 metric.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nishida_K/0/1/0/all/0/1\">Kosuke Nishida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshinaga_N/0/1/0/all/0/1\">Naoki Yoshinaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nishida_K/0/1/0/all/0/1\">Kyosuke Nishida</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Are Human-Level Prompt Engineers. (arXiv:2211.01910v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2211.01910","description":"<p>By conditioning on natural language instructions, large language models\n(LLMs) have displayed impressive capabilities as general-purpose computers.\nHowever, task performance depends significantly on the quality of the prompt\nused to steer the model, and most effective prompts have been handcrafted by\nhumans. Inspired by classical program synthesis and the human approach to\nprompt engineering, we propose Automatic Prompt Engineer (APE) for automatic\ninstruction generation and selection. In our method, we treat the instruction\nas the \"program,\" optimized by searching over a pool of instruction candidates\nproposed by an LLM in order to maximize a chosen score function. To evaluate\nthe quality of the selected instruction, we evaluate the zero-shot performance\nof another LLM following the selected instruction. Experiments on 24 NLP tasks\nshow that our automatically generated instructions outperform the prior LLM\nbaseline by a large margin and achieve better or comparable performance to the\ninstructions generated by human annotators on 19/24 tasks. We conduct extensive\nqualitative and quantitative analyses to explore the performance of APE. We\nshow that APE-engineered prompts can be applied to steer models toward\ntruthfulness and/or informativeness, as well as to improve few-shot learning\nperformance by simply prepending them to standard in-context learning prompts.\nPlease check out our webpage at\nhttps://sites.google.com/view/automatic-prompt-engineer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yongchao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muresanu_A/0/1/0/all/0/1\">Andrei Ioan Muresanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Ziwen Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paster_K/0/1/0/all/0/1\">Keiran Paster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pitis_S/0/1/0/all/0/1\">Silviu Pitis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_H/0/1/0/all/0/1\">Harris Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ba_J/0/1/0/all/0/1\">Jimmy Ba</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Temporal Modeling Matters: A Novel Temporal Emotional Modeling Approach for Speech Emotion Recognition. (arXiv:2211.08233v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2211.08233","description":"<p>Speech emotion recognition (SER) plays a vital role in improving the\ninteractions between humans and machines by inferring human emotion and\naffective states from speech signals. Whereas recent works primarily focus on\nmining spatiotemporal information from hand-crafted features, we explore how to\nmodel the temporal patterns of speech emotions from dynamic temporal scales.\nTowards that goal, we introduce a novel temporal emotional modeling approach\nfor SER, termed Temporal-aware bI-direction Multi-scale Network (TIM-Net),\nwhich learns multi-scale contextual affective representations from various time\nscales. Specifically, TIM-Net first employs temporal-aware blocks to learn\ntemporal affective representation, then integrates complementary information\nfrom the past and the future to enrich contextual representations, and finally,\nfuses multiple time scale features for better adaptation to the emotional\nvariation. Extensive experimental results on six benchmark SER datasets\ndemonstrate the superior performance of TIM-Net, gaining 2.34% and 2.61%\nimprovements of the average UAR and WAR over the second-best on each corpus.\nThe source code is available at https://github.com/Jiaxin-Ye/TIM-Net_SER.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jiaxin Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1\">Xin-cheng Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yujie Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kunhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shan_H/0/1/0/all/0/1\">Hongming Shan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BERT-Deep CNN: State-of-the-Art for Sentiment Analysis of COVID-19 Tweets. (arXiv:2211.09733v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.09733","description":"<p>The free flow of information has been accelerated by the rapid development of\nsocial media technology. There has been a significant social and psychological\nimpact on the population due to the outbreak of Coronavirus disease (COVID-19).\nThe COVID-19 pandemic is one of the current events being discussed on social\nmedia platforms. In order to safeguard societies from this pandemic, studying\npeople's emotions on social media is crucial. As a result of their particular\ncharacteristics, sentiment analysis of texts like tweets remains challenging.\nSentiment analysis is a powerful text analysis tool. It automatically detects\nand analyzes opinions and emotions from unstructured data. Texts from a wide\nrange of sources are examined by a sentiment analysis tool, which extracts\nmeaning from them, including emails, surveys, reviews, social media posts, and\nweb articles. To evaluate sentiments, natural language processing (NLP) and\nmachine learning techniques are used, which assign weights to entities, topics,\nthemes, and categories in sentences or phrases. Machine learning tools learn\nhow to detect sentiment without human intervention by examining examples of\nemotions in text. In a pandemic situation, analyzing social media texts to\nuncover sentimental trends can be very helpful in gaining a better\nunderstanding of society's needs and predicting future trends. We intend to\nstudy society's perception of the COVID-19 pandemic through social media using\nstate-of-the-art BERT and Deep CNN models. The superiority of BERT models over\nother deep models in sentiment analysis is evident and can be concluded from\nthe comparison of the various research studies mentioned in this article.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Joloudari_J/0/1/0/all/0/1\">Javad Hassannataj Joloudari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hussain_S/0/1/0/all/0/1\">Sadiq Hussain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nematollahi_M/0/1/0/all/0/1\">Mohammad Ali Nematollahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagheri_R/0/1/0/all/0/1\">Rouhollah Bagheri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazl_F/0/1/0/all/0/1\">Fatemeh Fazl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alizadehsani_R/0/1/0/all/0/1\">Roohallah Alizadehsani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lashgari_R/0/1/0/all/0/1\">Reza Lashgari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talukder_A/0/1/0/all/0/1\">Ashis Talukder</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPT-3-driven pedagogical agents for training children's curious question-asking skills. (arXiv:2211.14228v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.14228","description":"<p>In order to train children's ability to ask curiosity-driven questions,\nprevious research has explored designing specific exercises relying on\nproviding semantic and linguistic cues to help formulate such questions. But\ndespite showing pedagogical efficiency, this method is still limited as it\nrelies on generating the said cues by hand, which can be a very costly process.\nIn this context, we propose to leverage advances in the natural language\nprocessing field (NLP) and investigate the efficiency of using a large language\nmodel (LLM) for automating the production of the pedagogical content of a\ncurious question-asking (QA) training. We study generating the said content\nusing the \"prompt-based\" method that consists of explaining the task to the LLM\nin natural text. We evaluate the output using human experts annotations and\ncomparisons with hand-generated content. Results suggested indeed the relevance\nand usefulness of this content. We also conduct a field study in primary school\n(75 children aged 9-10), where we evaluate children's QA performance when\nhaving this training. We compare 3 types of content : 1) hand-generated content\nthat proposes \"closed\" cues leading to predefined questions; 2) GPT-3-generated\ncontent that proposes the same type of cues; 3) GPT-3-generated content that\nproposes \"open\" cues leading to several possible questions. We see a similar QA\nperformance between the two \"closed\" trainings (showing the scalability of the\napproach using GPT-3), and a better one for participants with the \"open\"\ntraining. These results suggest the efficiency of using LLMs to support\nchildren in generating more curious questions, using a natural language\nprompting approach that affords usability by teachers and other users not\nspecialists of AI techniques. Furthermore, results also show that open-ended\ncontent may be more suitable for training curious question-asking skills.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abdelghani_R/0/1/0/all/0/1\">Rania Abdelghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yen-Hsiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xingdi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucas_P/0/1/0/all/0/1\">Pauline Lucas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sauzeon_H/0/1/0/all/0/1\">H&#xe9;l&#xe8;ne Sauz&#xe9;on</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1\">Pierre-Yves Oudeyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Topic Modelling of Swedish Newspaper Articles about Coronavirus: a Case Study using Latent Dirichlet Allocation Method. (arXiv:2301.03029v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.03029","description":"<p>Topic Modelling (TM) is from the research branches of natural language\nunderstanding (NLU) and natural language processing (NLP) that is to facilitate\ninsightful analysis from large documents and datasets, such as a summarisation\nof main topics and the topic changes. This kind of discovery is getting more\npopular in real-life applications due to its impact on big data analytics. In\nthis study, from the social-media and healthcare domain, we apply popular\nLatent Dirichlet Allocation (LDA) methods to model the topic changes in Swedish\nnewspaper articles about Coronavirus. We describe the corpus we created\nincluding 6515 articles, methods applied, and statistics on topic changes over\napproximately 1 year and two months period of time from 17th January 2020 to\n13th March 2021. We hope this work can be an asset for grounding applications\nof topic modelling and can be inspiring for similar case studies in an era with\npandemics, to support socio-economic impact research as well as clinical and\nhealthcare analytics. Our data and source code are openly available at\nhttps://github. com/poethan/Swed_Covid_TM Keywords: Latent Dirichlet Allocation\n(LDA); Topic Modelling; Coronavirus; Pandemics; Natural Language Understanding;\nBERT-topic\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Griciute_B/0/1/0/all/0/1\">Bernadeta Grici&#x16b;t&#x117;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1\">Lifeng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nenadic_G/0/1/0/all/0/1\">Goran Nenadic</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Word-Graph2vec: An efficient word embedding approach on word co-occurrence graph using random walk sampling. (arXiv:2301.04312v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.04312","description":"<p>Word embedding has become ubiquitous and is widely used in various text\nmining and natural language processing (NLP) tasks, such as information\nretrieval, semantic analysis, and machine translation, among many others.\nUnfortunately, it is prohibitively expensive to train the word embedding in a\nrelatively large corpus. We propose a graph-based word embedding algorithm,\ncalled Word-Graph2vec, which converts the large corpus into a word\nco-occurrence graph, then takes the word sequence samples from this graph by\nrandomly traveling and trains the word embedding on this sampling corpus in the\nend. We posit that because of the stable vocabulary, relative idioms, and fixed\nexpressions in English, the size and density of the word co-occurrence graph\nchange slightly with the increase in the training corpus. So that\nWord-Graph2vec has stable runtime on the large scale data set, and its\nperformance advantage becomes more and more obvious with the growth of the\ntraining corpus. Extensive experiments conducted on real-world datasets show\nthat the proposed algorithm outperforms traditional Skip-Gram by four-five\ntimes in terms of efficiency, while the error generated by the random walk\nsampling is small.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenting Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yuanzhe Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1\">Jiahong Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huacan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeyu Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fillers in Spoken Language Understanding: Computational and Psycholinguistic Perspectives. (arXiv:2301.10761v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.10761","description":"<p>Disfluencies (i.e. interruptions in the regular flow of speech), are\nubiquitous to spoken discourse. Fillers (\"uh\", \"um\") are disfluencies that\noccur the most frequently compared to other kinds of disfluencies. Yet, to the\nbest of our knowledge, there isn't a resource that brings together the research\nperspectives influencing Spoken Language Understanding (SLU) on these speech\nevents. This aim of this article is to survey a breadth of perspectives in a\nholistic way; i.e. from considering underlying (psycho)linguistic theory, to\ntheir annotation and consideration in Automatic Speech Recognition (ASR) and\nSLU systems, to lastly, their study from a generation standpoint. This article\naims to present the perspectives in an approachable way to the SLU and\nConversational AI community, and discuss moving forward, what we believe are\nthe trends and challenges in each area.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dinkar_T/0/1/0/all/0/1\">Tanvi Dinkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clavel_C/0/1/0/all/0/1\">Chlo&#xe9; Clavel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasilescu_I/0/1/0/all/0/1\">Ioana Vasilescu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a Context Synergized Hyperbolic Network. (arXiv:2303.03387v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2303.03387","description":"<p>The tremendous growth of social media users interacting in online\nconversations has also led to significant growth in hate speech. Most of the\nprior works focus on detecting explicit hate speech, which is overt and\nleverages hateful phrases, with very little work focusing on detecting hate\nspeech that is implicit or denotes hatred through indirect or coded language.\nIn this paper, we present CoSyn, a user- and conversational-context synergized\nnetwork for detecting implicit hate speech in online conversation trees. CoSyn\nfirst models the user's personal historical and social context using a novel\nhyperbolic Fourier attention mechanism and hyperbolic graph convolution\nnetwork. Next, we jointly model the user's personal context and the\nconversational context using a novel context interaction mechanism in the\nhyperbolic space that clearly captures the interplay between the two and makes\nindependent assessments on the amounts of information to be retrieved from both\ncontexts. CoSyn performs all operations in the hyperbolic space to account for\nthe scale-free dynamics of social media. We demonstrate the effectiveness of\nCoSyn both qualitatively and quantitatively on an open-source hate speech\ndataset with Twitter conversations and show that CoSyn outperforms all our\nbaselines in detecting implicit hate speech with absolute improvements in the\nrange of 8.15% - 19.50%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Sreyan Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suri_M/0/1/0/all/0/1\">Manan Suri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiniya_P/0/1/0/all/0/1\">Purva Chiniya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyagi_U/0/1/0/all/0/1\">Utkarsh Tyagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sonal Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1\">Dinesh Manocha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-03-12T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/"}}]}]}