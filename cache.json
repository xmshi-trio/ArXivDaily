{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2024-01-26T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Toward Robust Multimodal Learning using Multimodal Foundational Models. (arXiv:2401.13697v1 [cs.CV])","link":"http://arxiv.org/abs/2401.13697","description":"<p>Existing multimodal sentiment analysis tasks are highly rely on the\nassumption that the training and test sets are complete multimodal data, while\nthis assumption can be difficult to hold: the multimodal data are often\nincomplete in real-world scenarios. Therefore, a robust multimodal model in\nscenarios with randomly missing modalities is highly preferred. Recently,\nCLIP-based multimodal foundational models have demonstrated impressive\nperformance on numerous multimodal tasks by learning the aligned cross-modal\nsemantics of image and text pairs, but the multimodal foundational models are\nalso unable to directly address scenarios involving modality absence. To\nalleviate this issue, we propose a simple and effective framework, namely TRML,\nToward Robust Multimodal Learning using Multimodal Foundational Models. TRML\nemploys generated virtual modalities to replace missing modalities, and aligns\nthe semantic spaces between the generated and missing modalities. Concretely,\nwe design a missing modality inference module to generate virtual modaliites\nand replace missing modalities. We also design a semantic matching learning\nmodule to align semantic spaces generated and missing modalities. Under the\nprompt of complete modality, our model captures the semantics of missing\nmodalities by leveraging the aligned cross-modal semantic space. Experiments\ndemonstrate the superiority of our approach on three multimodal sentiment\nanalysis benchmark datasets, CMU-MOSI, CMU-MOSEI, and MELD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xianbing Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1\">Soujanya Poria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuejiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yixin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1\">Buzhou Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility. (arXiv:2401.13782v1 [cs.DL])","link":"http://arxiv.org/abs/2401.13782","description":"<p>As the number of accepted papers at AI and ML conferences reaches into the\nthousands, it has become unclear how researchers access and read research\npublications. In this paper, we investigate the role of social media\ninfluencers in enhancing the visibility of machine learning research,\nparticularly the citation counts of papers they share. We have compiled a\ncomprehensive dataset of over 8,000 papers, spanning tweets from December 2018\nto October 2023, alongside 1:1 matched controls based on publication year,\nvenue, and abstract topics. Our analysis reveals a significant increase in\ncitations for papers endorsed by these influencers, with median citation counts\n2-3 times higher than those of the control group. Additionally, the study\ndelves into the geographic, gender, and institutional diversity of highlighted\nauthors. These findings highlight the expanding influence of social media in\nscholarly communication and underscore the importance of an evolving ecosystem\nin today's digital academic landscape.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Weissburg_I/0/1/0/all/0/1\">Iain Xie Weissburg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_M/0/1/0/all/0/1\">Mehir Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Liangming Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Unified Approach to Emotion Detection and Task-Oriented Dialogue Modeling. (arXiv:2401.13789v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13789","description":"<p>In current text-based task-oriented dialogue (TOD) systems, user emotion\ndetection (ED) is often overlooked or is typically treated as a separate and\nindependent task, requiring additional training. In contrast, our work\ndemonstrates that seamlessly unifying ED and TOD modeling brings about mutual\nbenefits, and is therefore an alternative to be considered. Our method consists\nin augmenting SimpleToD, an end-to-end TOD system, by extending belief state\ntracking to include ED, relying on a single language model. We evaluate our\napproach using GPT-2 and Llama-2 on the EmoWOZ benchmark, a version of MultiWOZ\nannotated with emotions. Our results reveal a general increase in performance\nfor ED and task results. Our findings also indicate that user emotions provide\nuseful contextual conditioning for system responses, and can be leveraged to\nfurther refine responses in terms of empathy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stricker_A/0/1/0/all/0/1\">Armand Stricker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paroubek_P/0/1/0/all/0/1\">Patrick Paroubek</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating the Efficacy of Large Language Models for Code Clone Detection. (arXiv:2401.13802v1 [cs.SE])","link":"http://arxiv.org/abs/2401.13802","description":"<p>Large Language Models (LLMs) have demonstrated remarkable success in various\nnatural language processing and software engineering tasks, such as code\ngeneration. The LLMs are mainly utilized in the prompt-based zero/few-shot\nparadigm to guide the model in accomplishing the task. %\\textbf{Goal:}\nGPT-based models are one of the popular ones studied for tasks such as code\ncomment generation or test generation. These tasks are `generative' tasks.\nHowever, there is limited research on the usage of LLMs for `non-generative'\ntasks such as classification using the prompt-based paradigm. In this\npreliminary exploratory study, we investigated the applicability of LLMs for\nCode Clone Detection (CCD), a non-generative task. %\\textbf{Method:} By\nbuilding a mono-lingual and cross-lingual CCD dataset derived from CodeNet, we\nfirst investigated two different prompts using ChatGPT to detect\n\\textcolor{black}{Type-4} code clones in Java-Java and Java-Ruby pairs in a\nzero-shot setting. We \\textcolor{black}{then} conducted an analysis to\nunderstand the strengths and weaknesses of ChatGPT in CCD. %\\textbf{Results:}\nChatGPT surpasses the baselines in cross-language CCD\n\\textcolor{black}{attaining an F1-score of 0.877 } and achieves comparable\nperformance to fully fine-tuned models for mono-lingual CCD,\n\\textcolor{black}{with an F1-score of 0.878}. Also, the\n\\textcolor{black}{prompt and the} difficulty level of the problems has an\nimpact on the performance of ChatGPT. \\textcolor{black}{Finally,} we provide\ninsights and future directions based on our initial analysis\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khajezade_M/0/1/0/all/0/1\">Mohamad Khajezade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jie Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fard_F/0/1/0/all/0/1\">Fatemeh Hendijani Fard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_Perez_G/0/1/0/all/0/1\">Gema Rodr&#xed;guez-P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shehata_M/0/1/0/all/0/1\">Mohamed Sami Shehata</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated Root Causing of Cloud Incidents using In-Context Learning with GPT-4. (arXiv:2401.13810v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13810","description":"<p>Root Cause Analysis (RCA) plays a pivotal role in the incident diagnosis\nprocess for cloud services, requiring on-call engineers to identify the primary\nissues and implement corrective actions to prevent future recurrences.\nImproving the incident RCA process is vital for minimizing service downtime,\ncustomer impact and manual toil. Recent advances in artificial intelligence\nhave introduced state-of-the-art Large Language Models (LLMs) like GPT-4, which\nhave proven effective in tackling various AIOps problems, ranging from code\nauthoring to incident management. Nonetheless, the GPT-4 model's immense size\npresents challenges when trying to fine-tune it on user data because of the\nsignificant GPU resource demand and the necessity for continuous model\nfine-tuning with the emergence of new data. To address the high cost of\nfine-tuning LLM, we propose an in-context learning approach for automated root\ncausing, which eliminates the need for fine-tuning. We conduct extensive study\nover 100,000 production incidents, comparing several large language models\nusing multiple metrics. The results reveal that our in-context learning\napproach outperforms the previous fine-tuned large language models such as\nGPT-3 by an average of 24.8\\% across all metrics, with an impressive 49.7\\%\nimprovement over the zero-shot model. Moreover, human evaluation involving\nactual incident owners demonstrates its superiority over the fine-tuned model,\nachieving a 43.5\\% improvement in correctness and an 8.7\\% enhancement in\nreadability. The impressive results demonstrate the viability of utilizing a\nvanilla GPT model for the RCA task, thereby avoiding the high computational and\nmaintenance costs associated with a fine-tuned model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Supriyo Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_C/0/1/0/all/0/1\">Chetan Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rujia Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Minghua Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yu Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajmohan_S/0/1/0/all/0/1\">Saravan Rajmohan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Calibration Gap between Model and Human Confidence in Large Language Models. (arXiv:2401.13835v1 [cs.LG])","link":"http://arxiv.org/abs/2401.13835","description":"<p>For large language models (LLMs) to be trusted by humans they need to be\nwell-calibrated in the sense that they can accurately assess and communicate\nhow likely it is that their predictions are correct. Recent work has focused on\nthe quality of internal LLM confidence assessments, but the question remains of\nhow well LLMs can communicate this internal model confidence to human users.\nThis paper explores the disparity between external human confidence in an LLM's\nresponses and the internal confidence of the model. Through experiments\ninvolving multiple-choice questions, we systematically examine human users'\nability to discern the reliability of LLM outputs. Our study focuses on two key\nareas: (1) assessing users' perception of true LLM confidence and (2)\ninvestigating the impact of tailored explanations on this perception. The\nresearch highlights that default explanations from LLMs often lead to user\noverestimation of both the model's confidence and its' accuracy. By modifying\nthe explanations to more accurately reflect the LLM's internal confidence, we\nobserve a significant shift in user perception, aligning it more closely with\nthe model's actual confidence levels. This adjustment in explanatory approach\ndemonstrates potential for enhancing user trust and accuracy in assessing LLM\noutputs. The findings underscore the importance of transparent communication of\nconfidence levels in LLMs, particularly in high-stakes applications where\nunderstanding the reliability of AI-generated information is essential.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Steyvers_M/0/1/0/all/0/1\">Mark Steyvers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tejeda_H/0/1/0/all/0/1\">Heliodoro Tejeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Aakriti Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belem_C/0/1/0/all/0/1\">Catarina Belem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karny_S/0/1/0/all/0/1\">Sheer Karny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xinyue Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayer_L/0/1/0/all/0/1\">Lukas Mayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smyth_P/0/1/0/all/0/1\">Padhraic Smyth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TPD: Enhancing Student Language Model Reasoning via Principle Discovery and Guidance. (arXiv:2401.13849v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13849","description":"<p>Large Language Models (LLMs) have recently showcased remarkable reasoning\nabilities. However, larger models often surpass their smaller counterparts in\nreasoning tasks, posing the challenge of effectively transferring these\ncapabilities from larger models. Existing approaches heavily rely on extensive\nfine-tuning data or continuous interactions with a superior teacher LLM during\ninference. We introduce a principle-based teacher-student framework called\n``Teaching via Principle Discovery'' (TPD) to address these limitations.\nInspired by human learning mechanisms, TPD mimics the interaction between a\nteacher and a student using a principle-based approach. The teacher LLM\ngenerates problem-solving instructions and corrective principles based on the\nstudent LLM's errors. These principles guide the refinement of instructions and\nthe selection of instructive examples from a validation set. This enables the\nstudent model to learn from both the teacher's guidance and its own mistakes.\nOnce the student model begins making inferences, TPD requires no further\nintervention from the teacher LLM or humans. Through extensive experiments\nacross eight reasoning tasks, we demonstrate the effectiveness of TPD. Compared\nto standard chain-of-thought prompting, TPD significantly improves the student\nmodel's performance, achieving $6.2\\%$ improvement on average.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haorui Wang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rongzhi Zhang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinghao Li</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingkai Kong</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1\">Yuchen Zhuang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiusi Chen</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a> (1) ((1) College of Computing, Georgia Institute of Technology, (2) Department of Computer Science, University of California, Los Angeles)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unmasking and Quantifying Racial Bias of Large Language Models in Medical Report Generation. (arXiv:2401.13867v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13867","description":"<p>Large language models like GPT-3.5-turbo and GPT-4 hold promise for\nhealthcare professionals, but they may inadvertently inherit biases during\ntheir training, potentially affecting their utility in medical applications.\nDespite few attempts in the past, the precise impact and extent of these biases\nremain uncertain. Through both qualitative and quantitative analyses, we find\nthat these models tend to project higher costs and longer hospitalizations for\nWhite populations and exhibit optimistic views in challenging medical scenarios\nwith much higher survival rates. These biases, which mirror real-world\nhealthcare disparities, are evident in the generation of patient backgrounds,\nthe association of specific diseases with certain races, and disparities in\ntreatment recommendations, etc. Our findings underscore the critical need for\nfuture research to address and mitigate biases in language models, especially\nin critical healthcare applications, to ensure fair and accurate outcomes for\nall patients.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yifan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qiao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Furong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiyong Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A comparative study of zero-shot inference with large language models and supervised modeling in breast cancer pathology classification. (arXiv:2401.13887v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13887","description":"<p>Although supervised machine learning is popular for information extraction\nfrom clinical notes, creating large annotated datasets requires extensive\ndomain expertise and is time-consuming. Meanwhile, large language models (LLMs)\nhave demonstrated promising transfer learning capability. In this study, we\nexplored whether recent LLMs can reduce the need for large-scale data\nannotations. We curated a manually-labeled dataset of 769 breast cancer\npathology reports, labeled with 13 categories, to compare zero-shot\nclassification capability of the GPT-4 model and the GPT-3.5 model with\nsupervised classification performance of three model architectures: random\nforests classifier, long short-term memory networks with attention (LSTM-Att),\nand the UCSF-BERT model. Across all 13 tasks, the GPT-4 model performed either\nsignificantly better than or as well as the best supervised model, the LSTM-Att\nmodel (average macro F1 score of 0.83 vs. 0.75). On tasks with high imbalance\nbetween labels, the differences were more prominent. Frequent sources of GPT-4\nerrors included inferences from multiple samples and complex task design. On\ncomplex tasks where large annotated datasets cannot be easily collected, LLMs\ncan reduce the burden of large-scale data labeling. However, if the use of LLMs\nis prohibitive, the use of simpler supervised models with large annotated\ndatasets can provide comparable results. LLMs demonstrated the potential to\nspeed up the execution of clinical NLP studies by reducing the need for\ncurating large annotated datasets. This may result in an increase in the\nutilization of NLP-based variables and outcomes in observational clinical\nstudies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sushil_M/0/1/0/all/0/1\">Madhumita Sushil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zack_T/0/1/0/all/0/1\">Travis Zack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandair_D/0/1/0/all/0/1\">Divneet Mandair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhiwei Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wali_A/0/1/0/all/0/1\">Ahmed Wali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yan-Ning Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_Y/0/1/0/all/0/1\">Yuwei Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Butte_A/0/1/0/all/0/1\">Atul J. Butte</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dynamic embedded topic models and change-point detection for exploring literary-historical hypotheses. (arXiv:2401.13905v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13905","description":"<p>We present a novel combination of dynamic embedded topic models and\nchange-point detection to explore diachronic change of lexical semantic\nmodality in classical and early Christian Latin. We demonstrate several methods\nfor finding and characterizing patterns in the output, and relating them to\ntraditional scholarship in Comparative Literature and Classics. This simple\napproach to unsupervised models of semantic change can be applied to any\nsuitable corpus, and we conclude with future directions and refinements aiming\nto allow noisier, less-curated materials to meet that threshold.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sirin_H/0/1/0/all/0/1\">Hale Sirin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lippincott_T/0/1/0/all/0/1\">Tom Lippincott</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"No More Distractions: an Adaptive Up-Sampling Algorithm to Reduce Data Artifacts. (arXiv:2401.13907v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13907","description":"<p>Researchers recently found out that sometimes language models achieve high\naccuracy on benchmark data set, but they can not generalize very well with even\nlittle changes to the original data set. This is sometimes due to data\nartifacts, model is learning the spurious correlation between tokens and\nlabels, instead of the semantics and logic. In this work, we analyzed SNLI data\nand visualized such spurious correlations. We proposed an adaptive up-sampling\nalgorithm to correct the data artifacts, which is simple and effective, and\ndoes not need human edits or annotation. We did an experiment applying the\nalgorithm to fix the data artifacts in SNLI data and the model trained with\ncorrected data performed significantly better than the model trained with raw\nSNLI data, overall, as well as on the subset we corrected.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Han Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models. (arXiv:2401.13919v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13919","description":"<p>The advancement of large language models (LLMs) leads to a new era marked by\nthe development of autonomous applications in the real world, which drives\ninnovation in the creation of advanced web-based agents. Existing web agents\ntypically only handle one input modality and are evaluated only in simplified\nweb simulators or static web snapshots, greatly limiting their applicability in\nreal-world scenarios. To bridge this gap, we introduce WebVoyager, an\ninnovative Large Multimodal Model (LMM) powered web agent that can complete\nuser instructions end-to-end by interacting with real-world websites. Moreover,\nwe propose a new evaluation protocol for web agents to address the challenges\nof automatic evaluation of open-ended web agent tasks, leveraging the robust\nmultimodal comprehension capabilities of GPT-4V. We create a new benchmark by\ngathering real-world tasks from 15 widely used websites to evaluate our agents.\nWe show that WebVoyager achieves a 55.7% task success rate, significantly\nsurpassing the performance of both GPT-4 (All Tools) and the WebVoyager\n(text-only) setups, underscoring the exceptional capability of WebVoyager in\npractical applications. We found that our proposed automatic evaluation\nachieves 85.3% agreement with human judgment, paving the way for further\ndevelopment of web agents in a real-world setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Hongliang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1\">Wenlin Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1\">Kaixin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yong Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1\">Zhenzhong Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LocMoE: A Low-overhead MoE for Large Language Model Training. (arXiv:2401.13920v1 [cs.LG])","link":"http://arxiv.org/abs/2401.13920","description":"<p>The Mixtures-of-Experts (MoE) model is a widespread distributed and\nintegrated learning method for large language models (LLM), which is favored\ndue to its ability to sparsify and expand models efficiently. However, the\nperformance of MoE is limited by load imbalance and high latency of All-To-All\ncommunication, along with relatively redundant computation owing to large\nexpert capacity. Load imbalance may result from existing routing policies that\nconsistently tend to select certain experts. The frequent inter-node\ncommunication in the All-To-All procedure also significantly prolongs the\ntraining time. To alleviate the above performance problems, we propose a novel\nrouting strategy that combines load balance and locality by converting partial\ninter-node communication to that of intra-node. Notably, we elucidate that\nthere is a minimum threshold for expert capacity, calculated through the\nmaximal angular deviation between the gating weights of the experts and the\nassigned tokens. We port these modifications on the PanGu-Sigma model based on\nthe MindSpore framework with multi-level routing and conduct experiments on\nAscend clusters. The experiment results demonstrate that the proposed LocMoE\nreduces training time per epoch by 12.68% to 22.24% compared to classical\nrouters, such as hash router and switch router, without impacting the model\naccuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhijie Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_L/0/1/0/all/0/1\">Li Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_E/0/1/0/all/0/1\">Entong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Binfan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Rongqian Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xin Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adaptive Text Watermark for Large Language Models. (arXiv:2401.13927v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13927","description":"<p>The advancement of Large Language Models (LLMs) has led to increasing\nconcerns about the misuse of AI-generated text, and watermarking for\nLLM-generated text has emerged as a potential solution. However, it is\nchallenging to generate high-quality watermarked text while maintaining strong\nsecurity, robustness, and the ability to detect watermarks without prior\nknowledge of the prompt or model. This paper proposes an adaptive watermarking\nstrategy to address this problem. To improve the text quality and maintain\nrobustness, we adaptively add watermarking to token distributions with high\nentropy measured using an auxiliary model and keep the low entropy token\ndistributions untouched. For the sake of security and to further minimize the\nwatermark's impact on text quality, instead of using a fixed green/red list\ngenerated from a random secret key, which can be vulnerable to decryption and\nforgery, we adaptively scale up the output logits in proportion based on the\nsemantic embedding of previously generated text using a well designed semantic\nmapping model. Our experiments involving various LLMs demonstrate that our\napproach achieves comparable robustness performance to existing watermark\nmethods. Additionally, the text generated by our method has perplexity\ncomparable to that of \\emph{un-watermarked} LLMs while maintaining security\neven under various attacks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yepeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bu_Y/0/1/0/all/0/1\">Yuheng Bu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leeroo Orchestrator: Elevating LLMs Performance Through Model Integration. (arXiv:2401.13979v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13979","description":"<p>In this paper, we propose an architecture to harness the collective knowledge\nof multiple trained LLMs to create a new state-of-the-art. At the core of this\nframework is a LLM-based orchestrator that is adept at picking the right\nunderlying LLM experts for optimal task execution. Inspired by self-play in\nreinforcement learning, we created a loop of query generation, orchestration,\nand evaluation to generate training data for the orchestrator. Our evaluation\nfocused on the MMLU benchmark, employing models with 7B, 13B, and 34B\nparameters available on Hugging Face. The results demonstrate new\nstate-of-the-art open-source models: Our Leeroo orchestrator achieves\nperformance on par with the Mixtral model while incurring only two-thirds of\nits cost. Moreover, increasing the allowed cost surpasses Mixtral's accuracy by\nover 5% at the same cost level, reaching an accuracy of 75.9%. Further\nenhancements were observed when integrating GPT4 into the underlying model\npool. The Leeroo orchestrator nearly matches GPT4's performance at half the\ncost and even exceeds GPT4's results with a 25% cost reduction. These findings\nillustrate the potential of our architecture in creating state-of-the-art and\ncost-effective LLMs by optimizing the synergy between multiple LLMs to achieve\nsuperior performance outcomes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mohammadshahi_A/0/1/0/all/0/1\">Alireza Mohammadshahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaikh_A/0/1/0/all/0/1\">Ali Shaikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yazdani_M/0/1/0/all/0/1\">Majid Yazdani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning. (arXiv:2401.13986v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13986","description":"<p>Large language models (LLMs) often generate convincing, fluent explanations.\nHowever, different from humans, they often generate inconsistent explanations\non different inputs. For example, an LLM may generate the explanation \"all\nbirds can fly\" when answering the question \"Can sparrows fly?\" but meanwhile\nanswer \"no\" to the related question \"Can penguins fly?\". Explanations should be\nconsistent across related examples so that they allow a human to simulate the\nLLM's decision process on multiple examples. We propose explanation-consistency\nfinetuning (EC-finetuning), a method that adapts LLMs to generate more\nconsistent natural-language explanations on related examples. EC-finetuning\ninvolves finetuning LLMs on synthetic data that is carefully constructed to\ncontain consistent explanations. Across a variety of question-answering\ndatasets in various domains, EC-finetuning yields a 10.0% relative explanation\nconsistency improvement on four finetuning datasets, and generalizes to seven\nout-of-distribution datasets not seen during finetuning (+4.5% relative). Code\nis available at https://github.com/yandachen/explanation-consistency-finetuning .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yanda Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_C/0/1/0/all/0/1\">Chandan Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_S/0/1/0/all/0/1\">Simiao Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">He He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent Self-Evolution. (arXiv:2401.13996v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13996","description":"<p>This paper introduces Investigate-Consolidate-Exploit (ICE), a novel strategy\nfor enhancing the adaptability and flexibility of AI agents through inter-task\nself-evolution. Unlike existing methods focused on intra-task learning, ICE\npromotes the transfer of knowledge between tasks for genuine self-evolution,\nsimilar to human experience learning. The strategy dynamically investigates\nplanning and execution trajectories, consolidates them into simplified\nworkflows and pipelines, and exploits them for improved task execution. Our\nexperiments on the XAgent framework demonstrate ICE's effectiveness, reducing\nAPI calls by as much as 80% and significantly decreasing the demand for the\nmodel's capability. Specifically, when combined with GPT-3.5, ICE's performance\nmatches that of raw GPT-4 across various agent tasks. We argue that this\nself-evolution approach represents a paradigm shift in agent design,\ncontributing to a more robust AI community and ecosystem, and moving a step\ncloser to full autonomy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Cheng Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1\">Shihao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yujia Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yining Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cong_X/0/1/0/all/0/1\">Xin Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yesai Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ConstraintChecker: A Plugin for Large Language Models to Reason on Commonsense Knowledge Bases. (arXiv:2401.14003v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14003","description":"<p>Reasoning over Commonsense Knowledge Bases (CSKB), i.e. CSKB reasoning, has\nbeen explored as a way to acquire new commonsense knowledge based on reference\nknowledge in the original CSKBs and external prior knowledge. Despite the\nadvancement of Large Language Models (LLM) and prompt engineering techniques in\nvarious reasoning tasks, they still struggle to deal with CSKB reasoning. One\nof the problems is that it is hard for them to acquire explicit relational\nconstraints in CSKBs from only in-context exemplars, due to a lack of symbolic\nreasoning capabilities (Bengio et al., 2021). To this end, we proposed\n**ConstraintChecker**, a plugin over prompting techniques to provide and check\nexplicit constraints. When considering a new knowledge instance,\nConstraintChecker employs a rule-based module to produce a list of constraints,\nthen it uses a zero-shot learning module to check whether this knowledge\ninstance satisfies all constraints. The acquired constraint-checking result is\nthen aggregated with the output of the main prompting technique to produce the\nfinal output. Experimental results on CSKB Reasoning benchmarks demonstrate the\neffectiveness of our method by bringing consistent improvements over all\nprompting methods. Codes and data are available at\n\\url{https://github.com/HKUST-KnowComp/ConstraintChecker}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Do_Q/0/1/0/all/0/1\">Quyet V. Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_T/0/1/0/all/0/1\">Tianqing Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diao_S/0/1/0/all/0/1\">Shizhe Diao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaowei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CMMU: A Benchmark for Chinese Multi-modal Multi-type Question Understanding and Reasoning. (arXiv:2401.14011v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14011","description":"<p>Multi-modal large language models(MLLMs) have achieved remarkable progress\nand demonstrated powerful knowledge comprehension and reasoning abilities.\nHowever, the mastery of domain-specific knowledge, which is essential for\nevaluating the intelligence of MLLMs, continues to be a challenge. Current\nmulti-modal benchmarks for domain-specific knowledge concentrate on\nmultiple-choice questions and are predominantly available in English, which\nimposes limitations on the comprehensiveness of the evaluation. To this end, we\nintroduce CMMU, a novel benchmark for multi-modal and multi-type question\nunderstanding and reasoning in Chinese. CMMU consists of 3,603 questions in 7\nsubjects, covering knowledge from primary to high school. The questions can be\ncategorized into 3 types: multiple-choice, multiple-response, and\nfill-in-the-blank, bringing greater challenges to MLLMs. In addition, we\npropose a rigorous evaluation strategy called ShiftCheck for assessing\nmultiple-choice questions. The strategy aims to reduce position bias, minimize\nthe influence of randomness on correctness, and perform a quantitative analysis\nof position bias. We evaluate seven open-source MLLMs along with GPT4-V,\nGemini-Pro, and Qwen-VL-Plus. The results demonstrate that CMMU poses a\nsignificant challenge to the recent MLLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zheqi He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xinya Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Pengfei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xuan_R/0/1/0/all/0/1\">Richeng Xuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qiannan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Hua Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Uncertainty-Aware Language Agent. (arXiv:2401.14016v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14016","description":"<p>While Language Agents have achieved promising success by placing Large\nLanguage Models at the core of a more versatile design that dynamically\ninteracts with the external world, the existing approaches neglect the notion\nof uncertainty during these interactions. We present the Uncertainty-Aware\nLanguage Agent (UALA), a framework that orchestrates the interaction between\nthe agent and the external world using uncertainty quantification. Compared\nwith other well-known counterparts like ReAct, our extensive experiments across\n3 representative tasks (HotpotQA, StrategyQA, MMLU) and various LLM sizes\ndemonstrates that UALA brings a significant improvement of performance, while\nhaving a substantially lower reliance on the external world (i.e., reduced\nnumber of tool calls and tokens). Our analyses provide various insights\nincluding the great potential of UALA compared with agent fine-tuning, and\nunderscoring the unreliably of verbalised confidence of LLMs as a proxy for\nuncertainty.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiuzhou Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buntine_W/0/1/0/all/0/1\">Wray Buntine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shareghi_E/0/1/0/all/0/1\">Ehsan Shareghi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unitxt: Flexible, Shareable and Reusable Data Preparation and Evaluation for Generative AI. (arXiv:2401.14019v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14019","description":"<p>In the dynamic landscape of generative NLP, traditional text processing\npipelines limit research flexibility and reproducibility, as they are tailored\nto specific dataset, task, and model combinations. The escalating complexity,\ninvolving system prompts, model-specific formats, instructions, and more, calls\nfor a shift to a structured, modular, and customizable solution. Addressing\nthis need, we present Unitxt, an innovative library for customizable textual\ndata preparation and evaluation tailored to generative language models. Unitxt\nnatively integrates with common libraries like HuggingFace and LM-eval-harness\nand deconstructs processing flows into modular components, enabling easy\ncustomization and sharing between practitioners. These components encompass\nmodel-specific formats, task prompts, and many other comprehensive dataset\nprocessing definitions. The Unitxt-Catalog centralizes these components,\nfostering collaboration and exploration in modern textual data workflows.\nBeyond being a tool, Unitxt is a community-driven platform, empowering users to\nbuild, share, and advance their pipelines collaboratively. Join the Unitxt\ncommunity at https://github.com/IBM/unitxt!\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bandel_E/0/1/0/all/0/1\">Elron Bandel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perlitz_Y/0/1/0/all/0/1\">Yotam Perlitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venezian_E/0/1/0/all/0/1\">Elad Venezian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friedman_Melamed_R/0/1/0/all/0/1\">Roni Friedman-Melamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arviv_O/0/1/0/all/0/1\">Ofir Arviv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orbach_M/0/1/0/all/0/1\">Matan Orbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Don_Yehyia_S/0/1/0/all/0/1\">Shachar Don-Yehyia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheinwald_D/0/1/0/all/0/1\">Dafna Sheinwald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gera_A/0/1/0/all/0/1\">Ariel Gera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1\">Leshem Choshen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shmueli_Scheuer_M/0/1/0/all/0/1\">Michal Shmueli-Scheuer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katz_Y/0/1/0/all/0/1\">Yoav Katz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Accelerating Retrieval-Augmented Language Model Serving with Speculation. (arXiv:2401.14021v1 [cs.LG])","link":"http://arxiv.org/abs/2401.14021","description":"<p>Retrieval-augmented language models (RaLM) have demonstrated the potential to\nsolve knowledge-intensive natural language processing (NLP) tasks by combining\na non-parametric knowledge base with a parametric language model. Instead of\nfine-tuning a fully parametric model, RaLM excels at its low-cost adaptation to\nthe latest data and better source attribution mechanisms. Among various RaLM\napproaches, iterative RaLM delivers a better generation quality due to a more\nfrequent interaction between the retriever and the language model. Despite the\nbenefits, iterative RaLM usually encounters high overheads due to the frequent\nretrieval step. To this end, we propose RaLMSpec, a speculation-inspired\nframework that provides generic speed-up over iterative RaLM while preserving\nthe same model outputs through speculative retrieval and batched verification.\nBy further incorporating prefetching, optimal speculation stride scheduler, and\nasynchronous verification, RaLMSpec can automatically exploit the acceleration\npotential to the fullest. For naive iterative RaLM serving, extensive\nevaluations over three language models on four downstream QA datasets\ndemonstrate that RaLMSpec can achieve a speed-up ratio of 1.75-2.39x,\n1.04-1.39x, and 1.31-1.77x when the retriever is an exact dense retriever,\napproximate dense retriever, and sparse retriever respectively compared with\nthe baseline. For KNN-LM serving, RaLMSpec can achieve a speed-up ratio up to\n7.59x and 2.45x when the retriever is an exact dense retriever and approximate\ndense retriever, respectively, compared with the baseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_A/0/1/0/all/0/1\">Alan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lijie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yihua Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lanting Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phothilimthana_P/0/1/0/all/0/1\">Phitchaya Mangpo Phothilimthana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1\">Zhihao Jia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"(Chat)GPT v BERT: Dawn of Justice for Semantic Change Detection. (arXiv:2401.14040v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14040","description":"<p>In the universe of Natural Language Processing, Transformer-based language\nmodels like BERT and (Chat)GPT have emerged as lexical superheroes with great\npower to solve open research problems. In this paper, we specifically focus on\nthe temporal problem of semantic change, and evaluate their ability to solve\ntwo diachronic extensions of the Word-in-Context (WiC) task: TempoWiC and\nHistoWiC. In particular, we investigate the potential of a novel, off-the-shelf\ntechnology like ChatGPT (and GPT) 3.5 compared to BERT, which represents a\nfamily of models that currently stand as the state-of-the-art for modeling\nsemantic change. Our experiments represent the first attempt to assess the use\nof (Chat)GPT for studying semantic change. Our results indicate that ChatGPT\nperforms significantly worse than the foundational GPT version. Furthermore,\nour results demonstrate that (Chat)GPT achieves slightly lower performance than\nBERT in detecting long-term changes but performs significantly worse in\ndetecting short-term changes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Periti_F/0/1/0/all/0/1\">Francesco Periti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubossarsky_H/0/1/0/all/0/1\">Haim Dubossarsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tahmasebi_N/0/1/0/all/0/1\">Nina Tahmasebi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Goal-oriented Large Language Model Prompting: A Survey. (arXiv:2401.14043v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14043","description":"<p>Large Language Models (LLMs) have shown prominent performance in various\ndownstream tasks in which prompt engineering plays a pivotal role in optimizing\nLLMs' performance. This paper, not as an overview of current prompt engineering\nmethods, aims to highlight the limitation of designing prompts while holding an\nanthropomorphic assumption that expects LLMs to think like humans. From our\nreview of 35 representative studies, we demonstrate that a goal-oriented prompt\nformulation, which guides LLMs to follow established human logical thinking,\nsignificantly improves the performance of LLMs. Furthermore, We introduce a\nnovel taxonomy that categorizes goal-oriented prompting methods into five\ninterconnected stages and we demonstrate the broad applicability of our\nframework by summarizing ten applicable tasks. With four future directions\nproposed, we hope to further emphasize and promote goal-oriented prompt\nengineering.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haochen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leung_J/0/1/0/all/0/1\">Jonathan Leung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhiqi Shen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ta'keed: The First Generative Fact-Checking System for Arabic Claims. (arXiv:2401.14067v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14067","description":"<p>This paper introduces Ta'keed, an explainable Arabic automatic fact-checking\nsystem. While existing research often focuses on classifying claims as \"True\"\nor \"False,\" there is a limited exploration of generating explanations for claim\ncredibility, particularly in Arabic. Ta'keed addresses this gap by assessing\nclaim truthfulness based on retrieved snippets, utilizing two main components:\ninformation retrieval and LLM-based claim verification. We compiled the\nArFactEx, a testing gold-labelled dataset with manually justified references,\nto evaluate the system. The initial model achieved a promising F1 score of 0.72\nin the classification task. Meanwhile, the system's generated explanations are\ncompared with gold-standard explanations syntactically and semantically. The\nstudy recommends evaluating using semantic similarities, resulting in an\naverage cosine similarity score of 0.76. Additionally, we explored the impact\nof varying snippet quantities on claim classification accuracy, revealing a\npotential correlation, with the model using the top seven hits outperforming\nothers with an F1 score of 0.77.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Althabiti_S/0/1/0/all/0/1\">Saud Althabiti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alsalka_M/0/1/0/all/0/1\">Mohammad Ammar Alsalka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atwell_E/0/1/0/all/0/1\">Eric Atwell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CompactifAI: Extreme Compression of Large Language Models using Quantum-Inspired Tensor Networks. (arXiv:2401.14109v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14109","description":"<p>Large Language Models (LLMs) such as ChatGPT and LlaMA are advancing rapidly\nin generative Artificial Intelligence (AI), but their immense size poses\nsignificant challenges, such as huge training and inference costs, substantial\nenergy demands, and limitations for on-site deployment. Traditional compression\nmethods such as pruning, distillation, and low-rank approximation focus on\nreducing the effective number of neurons in the network, while quantization\nfocuses on reducing the numerical precision of individual weights to reduce the\nmodel size while keeping the number of neurons fixed. While these compression\nmethods have been relatively successful in practice, there's no compelling\nreason to believe that truncating the number of neurons is an optimal strategy.\nIn this context, this paper introduces CompactifAI, an innovative LLM\ncompression approach using quantum-inspired Tensor Networks that focuses on the\nmodel's correlation space instead, allowing for a more controlled, refined and\ninterpretable model compression. Our method is versatile and can be implemented\nwith - or on top of - other compression techniques. As a benchmark, we\ndemonstrate that CompactifAI alone enables compression of the LlaMA-2 7B model\nto only $30\\%$ of its original size while recovering over $90\\%$ of the\noriginal accuracy after a brief distributed retraining.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tomut_A/0/1/0/all/0/1\">Andrei Tomut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jahromi_S/0/1/0/all/0/1\">Saeed S. Jahromi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sukhbinder Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishtiaq_F/0/1/0/all/0/1\">Faysal Ishtiaq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munoz_C/0/1/0/all/0/1\">Cesar Mu&#xf1;oz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bajaj_P/0/1/0/all/0/1\">Prabdeep Singh Bajaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elborady_A/0/1/0/all/0/1\">Ali Elborady</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bimbo_G/0/1/0/all/0/1\">Gianni del Bimbo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alizadeh_M/0/1/0/all/0/1\">Mehrazin Alizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montero_D/0/1/0/all/0/1\">David Montero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_Ramiro_P/0/1/0/all/0/1\">Pablo Martin-Ramiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahim_M/0/1/0/all/0/1\">Muhammad Ibrahim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alaoui_O/0/1/0/all/0/1\">Oussama Tahiri Alaoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malcolm_J/0/1/0/all/0/1\">John Malcolm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mugel_S/0/1/0/all/0/1\">Samuel Mugel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orus_R/0/1/0/all/0/1\">Roman Orus</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Affinity, Rationality, and Diversity of Hierarchical Topic Modeling. (arXiv:2401.14113v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14113","description":"<p>Hierarchical topic modeling aims to discover latent topics from a corpus and\norganize them into a hierarchy to understand documents with desirable semantic\ngranularity. However, existing work struggles with producing topic hierarchies\nof low affinity, rationality, and diversity, which hampers document\nunderstanding. To overcome these challenges, we in this paper propose Transport\nPlan and Context-aware Hierarchical Topic Model (TraCo). Instead of early\nsimple topic dependencies, we propose a transport plan dependency method. It\nconstrains dependencies to ensure their sparsity and balance, and also\nregularizes topic hierarchy building with them. This improves affinity and\ndiversity of hierarchies. We further propose a context-aware disentangled\ndecoder. Rather than previously entangled decoding, it distributes different\nsemantic granularity to topics at different levels by disentangled decoding.\nThis facilitates the rationality of hierarchies. Experiments on benchmark\ndatasets demonstrate that our method surpasses state-of-the-art baselines,\neffectively improving the affinity, rationality, and diversity of hierarchical\ntopic modeling with better performance on downstream tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaobao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1\">Fengjun Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yichao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chaoqun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Cong-Duy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_A/0/1/0/all/0/1\">Anh Tuan Luu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Convolutional Neural Networks can achieve binary bail judgement classification. (arXiv:2401.14135v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14135","description":"<p>There is an evident lack of implementation of Machine Learning (ML) in the\nlegal domain in India, and any research that does take place in this domain is\nusually based on data from the higher courts of law and works with English\ndata. The lower courts and data from the different regional languages of India\nare often overlooked. In this paper, we deploy a Convolutional Neural Network\n(CNN) architecture on a corpus of Hindi legal documents. We perform a bail\nPrediction task with the help of a CNN model and achieve an overall accuracy of\n93\\% which is an improvement on the benchmark accuracy, set by Kapoor et al.\n(2022), albeit in data from 20 districts of the Indian state of Uttar Pradesh.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Barman_A/0/1/0/all/0/1\">Amit Barman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_D/0/1/0/all/0/1\">Devangan Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1\">Debapriya Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutta_I/0/1/0/all/0/1\">Indranil Dutta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guha_S/0/1/0/all/0/1\">Shouvik Kumar Guha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karmakar_S/0/1/0/all/0/1\">Samir Karmakar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naskar_S/0/1/0/all/0/1\">Sudip Kumar Naskar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning. (arXiv:2401.14151v1 [cs.LG])","link":"http://arxiv.org/abs/2401.14151","description":"<p>Despite the impressive performance across numerous tasks, large language\nmodels (LLMs) often fail in solving simple decision-making tasks due to the\nmisalignment of the knowledge in LLMs with environments. On the contrary,\nreinforcement learning (RL) agents learn policies from scratch, which makes\nthem always align with environments but difficult to incorporate prior\nknowledge for efficient explorations. To narrow the gap, we propose TWOSOME, a\nnovel general online framework that deploys LLMs as decision-making agents to\nefficiently interact and align with embodied environments via RL without\nrequiring any prepared datasets or prior knowledge of the environments.\nFirstly, we query the joint probabilities of each valid action with LLMs to\nform behavior policies. Then, to enhance the stability and robustness of the\npolicies, we propose two normalization methods and summarize four prompt design\nprinciples. Finally, we design a novel parameter-efficient training\narchitecture where the actor and critic share one frozen LLM equipped with\nlow-rank adapters (LoRA) updated by PPO. We conduct extensive experiments to\nevaluate TWOSOME. i) TWOSOME exhibits significantly better sample efficiency\nand performance compared to the conventional RL method, PPO, and prompt tuning\nmethod, SayCan, in both classical decision-making environment, Overcooked, and\nsimulated household environment, VirtualHome. ii) Benefiting from LLMs'\nopen-vocabulary feature, TWOSOME shows superior generalization ability to\nunseen tasks. iii) Under our framework, there is no significant loss of the\nLLMs' original ability during online PPO finetuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1\">Weihao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wentao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shanqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Longtao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinrun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bo An</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction. (arXiv:2401.14166v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14166","description":"<p>As a novel and effective fine-tuning paradigm based on large-scale\npre-trained language models (PLMs), prompt-tuning aims to reduce the gap\nbetween downstream tasks and pre-training objectives. While prompt-tuning has\nyielded continuous advancements in various tasks, such an approach still\nremains a persistent defect: prompt-tuning methods fail to generalize to\nspecific few-shot patterns. From the perspective of distribution analyses, we\ndisclose that the intrinsic issues behind the phenomenon are the\nover-multitudinous conceptual knowledge contained in PLMs and the abridged\nknowledge for target downstream domains, which jointly result in that PLMs\nmis-locate the knowledge distributions corresponding to the target domains in\nthe universal knowledge embedding space. To this end, we intuitively explore to\napproximate the unabridged target domains of downstream tasks in a debiased\nmanner, and then abstract such domains to generate discriminative prompts,\nthereby providing the de-ambiguous guidance for PLMs. Guided by such an\nintuition, we propose a simple yet effective approach, namely BayesPrompt, to\nlearn prompts that contain the domain discriminative information against the\ninterference from domain-irrelevant knowledge. BayesPrompt primitively\nleverages known distributions to approximate the debiased factual distributions\nof target domains and further uniformly samples certain representative features\nfrom the approximated distributions to generate the ultimate prompts for PLMs.\nWe provide theoretical insights with the connection to domain adaptation.\nEmpirically, our method achieves state-of-the-art performance on benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiangmeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_F/0/1/0/all/0/1\">Fei Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Yifan Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiang_W/0/1/0/all/0/1\">Wenwen Qiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Changwen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1\">Fuchun Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Hui Xiong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Can Large Language Models Understand Spatial-Temporal Data?. (arXiv:2401.14192v1 [cs.LG])","link":"http://arxiv.org/abs/2401.14192","description":"<p>While Large Language Models (LLMs) dominate tasks like natural language\nprocessing and computer vision, harnessing their power for spatial-temporal\nforecasting remains challenging. The disparity between sequential text and\ncomplex spatial-temporal data hinders this application. To address this issue,\nthis paper introduces STG-LLM, an innovative approach empowering LLMs for\nspatial-temporal forecasting. We tackle the data mismatch by proposing: 1)\nSTG-Tokenizer: This spatial-temporal graph tokenizer transforms intricate graph\ndata into concise tokens capturing both spatial and temporal relationships; 2)\nSTG-Adapter: This minimalistic adapter, consisting of linear encoding and\ndecoding layers, bridges the gap between tokenized data and LLM comprehension.\nBy fine-tuning only a small set of parameters, it can effectively grasp the\nsemantics of tokens generated by STG-Tokenizer, while preserving the original\nnatural language understanding capabilities of LLMs. Extensive experiments on\ndiverse spatial-temporal benchmark datasets show that STG-LLM successfully\nunlocks LLM potential for spatial-temporal forecasting. Remarkably, our\napproach achieves competitive performance on par with dedicated SOTA methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shuo Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Runze Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhenxun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yanming Shen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Parameter-Efficient Conversational Recommender System as a Language Processing Task. (arXiv:2401.14194v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14194","description":"<p>Conversational recommender systems (CRS) aim to recommend relevant items to\nusers by eliciting user preference through natural language conversation. Prior\nwork often utilizes external knowledge graphs for items' semantic information,\na language model for dialogue generation, and a recommendation module for\nranking relevant items. This combination of multiple components suffers from a\ncumbersome training process, and leads to semantic misalignment issues between\ndialogue generation and item recommendation. In this paper, we represent items\nin natural language and formulate CRS as a natural language processing task.\nAccordingly, we leverage the power of pre-trained language models to encode\nitems, understand user intent via conversation, perform item recommendation\nthrough semantic matching, and generate dialogues. As a unified model, our\nPECRS (Parameter-Efficient CRS), can be optimized in a single stage, without\nrelying on non-textual metadata such as a knowledge graph. Experiments on two\nbenchmark CRS datasets, ReDial and INSPIRED, demonstrate the effectiveness of\nPECRS on recommendation and conversation. Our code is available at:\nhttps://github.com/Ravoxsg/efficient_unified_crs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ravaut_M/0/1/0/all/0/1\">Mathieu Ravaut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Lu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_A/0/1/0/all/0/1\">Aixin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence. (arXiv:2401.14196v1 [cs.SE])","link":"http://arxiv.org/abs/2401.14196","description":"<p>The rapid development of large language models has revolutionized code\nintelligence in software development. However, the predominance of\nclosed-source models has restricted extensive research and development. To\naddress this, we introduce the DeepSeek-Coder series, a range of open-source\ncode models with sizes from 1.3B to 33B, trained from scratch on 2 trillion\ntokens. These models are pre-trained on a high-quality project-level code\ncorpus and employ a fill-in-the-blank task with a 16K window to enhance code\ngeneration and infilling. Our extensive evaluations demonstrate that\nDeepSeek-Coder not only achieves state-of-the-art performance among open-source\ncode models across multiple benchmarks but also surpasses existing\nclosed-source models like Codex and GPT-3.5. Furthermore, DeepSeek-Coder models\nare under a permissive license that allows for both research and unrestricted\ncommercial use.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1\">Daya Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qihao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Dejian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zhenda Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_K/0/1/0/all/0/1\">Kai Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wentao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guanting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_X/0/1/0/all/0/1\">Xiao Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Y. Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Y.K. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1\">Fuli Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1\">Yingfei Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1\">Wenfeng Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explicitly Representing Syntax Improves Sentence-to-layout Prediction of Unexpected Situations. (arXiv:2401.14212v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14212","description":"<p>Recognizing visual entities in a natural language sentence and arranging them\nin a 2D spatial layout require a compositional understanding of language and\nspace. This task of layout prediction is valuable in text-to-image synthesis as\nit allows localized and controlled in-painting of the image. In this\ncomparative study it is shown that we can predict layouts from language\nrepresentations that implicitly or explicitly encode sentence syntax, if the\nsentences mention similar entity-relationships to the ones seen during\ntraining. To test compositional understanding, we collect a test set of\ngrammatically correct sentences and layouts describing compositions of entities\nand relations that unlikely have been seen during training. Performance on this\ntest set substantially drops, showing that current models rely on correlations\nin the training data and have difficulties in understanding the structure of\nthe input sentences. We propose a novel structural loss function that better\nenforces the syntactic structure of the input sentence and show large\nperformance gains in the task of 2D spatial layout prediction conditioned on\ntext. The loss has the potential to be used in other generation tasks where a\ntree-like structure underlies the conditioning modality. Code, trained models\nand the USCOCO evaluation set will be made available via github.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nuyts_W/0/1/0/all/0/1\">Wolf Nuyts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cartuyvels_R/0/1/0/all/0/1\">Ruben Cartuyvels</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moens_M/0/1/0/all/0/1\">Marie-Francine Moens</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Commonsense-augmented Memory Construction and Management in Long-term Conversations via Context-aware Persona Refinement. (arXiv:2401.14215v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14215","description":"<p>Memorizing and utilizing speakers' personas is a common practice for response\ngeneration in long-term conversations. Yet, human-authored datasets often\nprovide uninformative persona sentences that hinder response quality. This\npaper presents a novel framework that leverages commonsense-based persona\nexpansion to address such issues in long-term conversation. While prior work\nfocuses on not producing personas that contradict others, we focus on\ntransforming contradictory personas into sentences that contain rich speaker\ninformation, by refining them based on their contextual backgrounds with\ndesigned strategies. As the pioneer of persona expansion in multi-session\nsettings, our framework facilitates better response generation via human-like\npersona refinement. The supplementary video of our work is available at\nhttps://caffeine-15bbf.web.app/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hana Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_K/0/1/0/all/0/1\">Kai Tzu-iunn Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seoyeon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongha Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeo_J/0/1/0/all/0/1\">Jinyoung Yeo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Assessing the Portability of Parameter Matrices Trained by Parameter-Efficient Finetuning Methods. (arXiv:2401.14228v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14228","description":"<p>As the cost of training ever larger language models has grown, so has the\ninterest in reusing previously learnt knowledge. Transfer learning methods have\nshown how reusing non-task-specific knowledge can help in subsequent\ntask-specific learning. In this paper, we investigate the inverse: porting\nwhole functional modules that encode task-specific knowledge from one model to\nanother. We designed a study comprising 1,440 training/testing runs to test the\nportability of modules trained by parameter-efficient finetuning (PEFT)\ntechniques, using sentiment analysis as an example task. We test portability in\na wide range of scenarios, involving different PEFT techniques and different\npretrained host models, among other dimensions. We compare the performance of\nported modules with that of equivalent modules trained (i) from scratch, and\n(ii) from parameters sampled from the same distribution as the ported module.\nWe find that the ported modules far outperform the two alternatives tested, but\nthat there are interesting performance differences between the four PEFT\ntechniques. We conclude that task-specific knowledge in the form of\nstructurally modular sets of parameters as produced by PEFT techniques is\nhighly portable, but that degree of success depends on type of PEFT and on\ndifferences between originating and receiving pretrained models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sabry_M/0/1/0/all/0/1\">Mohammed Sabry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belz_A/0/1/0/all/0/1\">Anya Belz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhanced Labeling Technique for Reddit Text and Fine-Tuned Longformer Models for Classifying Depression Severity in English and Luganda. (arXiv:2401.14240v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14240","description":"<p>Depression is a global burden and one of the most challenging mental health\nconditions to control. Experts can detect its severity early using the Beck\nDepression Inventory (BDI) questionnaire, administer appropriate medication to\npatients, and impede its progression. Due to the fear of potential\nstigmatization, many patients turn to social media platforms like Reddit for\nadvice and assistance at various stages of their journey. This research\nextracts text from Reddit to facilitate the diagnostic process. It employs a\nproposed labeling approach to categorize the text and subsequently fine-tunes\nthe Longformer model. The model's performance is compared against baseline\nmodels, including Naive Bayes, Random Forest, Support Vector Machines, and\nGradient Boosting. Our findings reveal that the Longformer model outperforms\nthe baseline models in both English (48%) and Luganda (45%) languages on a\ncustom-made dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kimera_R/0/1/0/all/0/1\">Richard Kimera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rim_D/0/1/0/all/0/1\">Daniela N. Rim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirabira_J/0/1/0/all/0/1\">Joseph Kirabira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Udomah_U/0/1/0/all/0/1\">Ubong Godwin Udomah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1\">Heeyoul Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Natural Language Capability of Code Large Language Model. (arXiv:2401.14242v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14242","description":"<p>Code large language models (Code LLMs) have demonstrated remarkable\nperformance in code generation. Nonetheless, most existing works focus on\nboosting code LLMs from the perspective of programming capabilities, while\ntheir natural language capabilities receive less attention. To fill this gap,\nwe thus propose a novel framework, comprising two modules: AttentionExtractor,\nwhich is responsible for extracting key phrases from the user's natural\nlanguage requirements, and AttentionCoder, which leverages these extracted\nphrases to generate target code to solve the requirement. This framework\npioneers an innovative idea by seamlessly integrating code LLMs with\ntraditional natural language processing tools. To validate the effectiveness of\nthe framework, we craft a new code generation benchmark, called MultiNL-H,\ncovering five natural languages. Extensive experimental results demonstrate the\neffectiveness of our proposed framework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zan_D/0/1/0/all/0/1\">Daoguang Zan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_B/0/1/0/all/0/1\">Bei Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_A/0/1/0/all/0/1\">Ailun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaolin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongji Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformers and Cortical Waves: Encoders for Pulling In Context Across Time. (arXiv:2401.14267v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14267","description":"<p>The capabilities of transformer networks such as ChatGPT and other Large\nLanguage Models (LLMs) have captured the world's attention. The crucial\ncomputational mechanism underlying their performance relies on transforming a\ncomplete input sequence - for example, all the words in a sentence into a long\n\"encoding vector\" - that allows transformers to learn long-range temporal\ndependencies in naturalistic sequences. Specifically, \"self-attention\" applied\nto this encoding vector enhances temporal context in transformers by computing\nassociations between pairs of words in the input sequence. We suggest that\nwaves of neural activity, traveling across single cortical regions or across\nmultiple regions at the whole-brain scale, could implement a similar encoding\nprinciple. By encapsulating recent input history into a single spatial pattern\nat each moment in time, cortical waves may enable temporal context to be\nextracted from sequences of sensory inputs, the same computational principle\nused in transformers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Muller_L/0/1/0/all/0/1\">Lyle Muller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Churchland_P/0/1/0/all/0/1\">Patricia S. Churchland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sejnowski_T/0/1/0/all/0/1\">Terrence J. Sejnowski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models models via Romanization. (arXiv:2401.14280v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14280","description":"<p>This study addresses the challenge of extending Large Language Models (LLMs)\nto non-English languages, specifically those using non-Latin scripts. We\npropose an innovative approach that utilizes the romanized form of text as an\ninterface for LLMs, hypothesizing that its frequent informal use and shared\ntokens with English enhance cross-lingual alignment. Focusing on Hindi, we\ndemonstrate through Hindi-to-English translation and sentiment analysis tasks\nthat romanized text not only significantly improves inference efficiency due to\nits lower fertility compared to native text but also achieves competitive\nperformance with limited pre-training. Additionally, our novel multi-script\nprompting approach, which combines romanized and native texts, shows promise in\nfurther enhancing task performance. These findings suggest the potential of\nromanization in bridging the language gap for LLM applications, with future\nwork aimed at expanding this approach to more languages and tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Husain_J/0/1/0/all/0/1\">Jaavid Aktar Husain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dabre_R/0/1/0/all/0/1\">Raj Dabre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Aswanth Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puduppully_R/0/1/0/all/0/1\">Ratish Puduppully</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunchukuttan_A/0/1/0/all/0/1\">Anoop Kunchukuttan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Topologies of Reasoning: Demystifying Chains, Trees, and Graphs of Thoughts. (arXiv:2401.14295v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14295","description":"<p>The field of natural language processing (NLP) has witnessed significant\nprogress in recent years, with a notable focus on improving large language\nmodels' (LLM) performance through innovative prompting techniques. Among these,\nprompt engineering coupled with structures has emerged as a promising paradigm,\nwith designs such as Chain-of-Thought, Tree of Thoughts, or Graph of Thoughts,\nin which the overall LLM reasoning is guided by a structure such as a graph. As\nillustrated with numerous examples, this paradigm significantly enhances the\nLLM's capability to solve numerous tasks, ranging from logical or mathematical\nreasoning to planning or creative writing. To facilitate the understanding of\nthis growing field and pave the way for future developments, we devise a\ngeneral blueprint for effective and efficient LLM reasoning schemes. For this,\nwe conduct an in-depth analysis of the prompt execution pipeline, clarifying\nand clearly defining different concepts. We then build the first taxonomy of\nstructure-enhanced LLM reasoning schemes. We focus on identifying fundamental\nclasses of harnessed structures, and we analyze the representations of these\nstructures, algorithms executed with these structures, and many others. We\nrefer to these structures as reasoning topologies, because their representation\nbecomes to a degree spatial, as they are contained within the LLM context. Our\nstudy compares existing prompting schemes using the proposed taxonomy,\ndiscussing how certain design choices lead to different patterns in performance\nand cost. We also outline theoretical underpinnings, relationships between\nprompting and others parts of the LLM ecosystem such as knowledge bases, and\nthe associated research challenges. Our work will help to advance future prompt\nengineering techniques.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Besta_M/0/1/0/all/0/1\">Maciej Besta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Memedi_F/0/1/0/all/0/1\">Florim Memedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhenyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerstenberger_R/0/1/0/all/0/1\">Robert Gerstenberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blach_N/0/1/0/all/0/1\">Nils Blach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nyczyk_P/0/1/0/all/0/1\">Piotr Nyczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Copik_M/0/1/0/all/0/1\">Marcin Copik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwasniewski_G/0/1/0/all/0/1\">Grzegorz Kwa&#x15b;niewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_J/0/1/0/all/0/1\">J&#xfc;rgen M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gianinazzi_L/0/1/0/all/0/1\">Lukas Gianinazzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kubicek_A/0/1/0/all/0/1\">Ales Kubicek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niewiadomski_H/0/1/0/all/0/1\">Hubert Niewiadomski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mutlu_O/0/1/0/all/0/1\">Onur Mutlu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1\">Torsten Hoefler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis on Noisy Bengali Texts. (arXiv:2401.14360v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14360","description":"<p>While Bengali is considered a language with limited resources, sentiment\nanalysis has been a subject of extensive research in the literature.\nNevertheless, there is a scarcity of exploration into sentiment analysis\nspecifically in the realm of noisy Bengali texts. In this paper, we introduce a\ndataset (NC-SentNoB) that we annotated manually to identify ten different types\nof noise found in a pre-existing sentiment analysis dataset comprising of\naround 15K noisy Bengali texts. At first, given an input noisy text, we\nidentify the noise type, addressing this as a multi-label classification task.\nThen, we introduce baseline noise reduction methods to alleviate noise prior to\nconducting sentiment analysis. Finally, we assess the performance of fine-tuned\nsentiment analysis models with both noisy and noise-reduced texts to make\ncomparisons. The experimental findings indicate that the noise reduction\nmethods utilized are not satisfactory, highlighting the need for more suitable\nnoise reduction methods in future research endeavors. We have made the\nimplementation and dataset presented in this paper publicly available at\nhttps://github.com/ktoufiquee/A-Comparative-Analysis-of-Noise-Reduction-Methods-in-Sentiment-Analysis-on-Noisy-Bengali-Texts\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Elahi_K/0/1/0/all/0/1\">Kazi Toufique Elahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_T/0/1/0/all/0/1\">Tasnuva Binte Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahriar_S/0/1/0/all/0/1\">Shakil Shahriar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarker_S/0/1/0/all/0/1\">Samir Sarker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shawon_M/0/1/0/all/0/1\">Md. Tanvir Rouf Shawon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahariar_G/0/1/0/all/0/1\">G. M. Shahariar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Genie: Achieving Human Parity in Content-Grounded Datasets Generation. (arXiv:2401.14367v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14367","description":"<p>The lack of high-quality data for content-grounded generation tasks has been\nidentified as a major obstacle to advancing these tasks. To address this gap,\nwe propose Genie, a novel method for automatically generating high-quality\ncontent-grounded data. It consists of three stages: (a) Content Preparation,\n(b) Generation: creating task-specific examples from the content (e.g.,\nquestion-answer pairs or summaries). (c) Filtering mechanism aiming to ensure\nthe quality and faithfulness of the generated data. We showcase this\nmethodology by generating three large-scale synthetic data, making wishes, for\nLong-Form Question-Answering (LFQA), summarization, and information extraction.\nIn a human evaluation, our generated data was found to be natural and of high\nquality. Furthermore, we compare models trained on our data with models trained\non human-written data -- ELI5 and ASQA for LFQA and CNN-DailyMail for\nSummarization. We show that our models are on par with or outperforming models\ntrained on human-generated data and consistently outperforming them in\nfaithfulness. Finally, we applied our method to create LFQA data within the\nmedical domain and compared a model trained on it with models trained on other\ndomains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yehudai_A/0/1/0/all/0/1\">Asaf Yehudai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carmeli_B/0/1/0/all/0/1\">Boaz Carmeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mass_Y/0/1/0/all/0/1\">Yosi Mass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arviv_O/0/1/0/all/0/1\">Ofir Arviv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mills_N/0/1/0/all/0/1\">Nathaniel Mills</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toledo_A/0/1/0/all/0/1\">Assaf Toledo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shnarch_E/0/1/0/all/0/1\">Eyal Shnarch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1\">Leshem Choshen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TURNA: A Turkish Encoder-Decoder Language Model for Enhanced Understanding and Generation. (arXiv:2401.14373v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14373","description":"<p>The recent advances in natural language processing have predominantly favored\nwell-resourced English-centric models, resulting in a significant gap with\nlow-resource languages. In this work, we introduce the language model TURNA,\nwhich is developed for the low-resource language Turkish and is capable of both\nnatural language understanding and generation tasks. TURNA is pretrained with\nan encoder-decoder architecture based on the unified framework UL2 with a\ndiverse corpus that we specifically curated for this purpose. We evaluated\nTURNA with three generation tasks and five understanding tasks for Turkish. The\nresults show that TURNA outperforms several multilingual models in both\nunderstanding and generation tasks, and competes with monolingual Turkish\nmodels in understanding tasks. TURNA is made available at\nhttps://huggingface.co/boun-tabi-LMG/TURNA .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Uludogan_G/0/1/0/all/0/1\">G&#xf6;k&#xe7;e Uludo&#x11f;an</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balal_Z/0/1/0/all/0/1\">Zeynep Yirmibe&#x15f;o&#x11f;lu Balal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akkurt_F/0/1/0/all/0/1\">Furkan Akkurt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turker_M/0/1/0/all/0/1\">Melik&#x15f;ah T&#xfc;rker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gungor_O/0/1/0/all/0/1\">Onur G&#xfc;ng&#xf6;r</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uskudarli_S/0/1/0/all/0/1\">Susan &#xdc;sk&#xfc;darl&#x131;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modular Adaptation of Multilingual Encoders to Written Swiss German Dialect. (arXiv:2401.14400v1 [cs.CL])","link":"http://arxiv.org/abs/2401.14400","description":"<p>Creating neural text encoders for written Swiss German is challenging due to\na dearth of training data combined with dialectal variation. In this paper, we\nbuild on several existing multilingual encoders and adapt them to Swiss German\nusing continued pre-training. Evaluation on three diverse downstream tasks\nshows that simply adding a Swiss German adapter to a modular encoder achieves\n97.5% of fully monolithic adaptation performance. We further find that for the\ntask of retrieving Swiss German sentences given Standard German queries,\nadapting a character-level model is more effective than the other adaptation\nstrategies. We release our code and the models trained for our experiments at\nhttps://github.com/ZurichNLP/swiss-german-text-encoders\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vamvas_J/0/1/0/all/0/1\">Jannis Vamvas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aepli_N/0/1/0/all/0/1\">No&#xeb;mi Aepli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sennrich_R/0/1/0/all/0/1\">Rico Sennrich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieval augmentation of large language models for lay language generation. (arXiv:2211.03818v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.03818","description":"<p>Recent lay language generation systems have used Transformer models trained\non a parallel corpus to increase health information accessibility. However, the\napplicability of these models is constrained by the limited size and topical\nbreadth of available corpora. We introduce CELLS, the largest (63k pairs) and\nbroadest-ranging (12 journals) parallel corpus for lay language generation. The\nabstract and the corresponding lay language summary are written by domain\nexperts, assuring the quality of our dataset. Furthermore, qualitative\nevaluation of expert-authored plain language summaries has revealed background\nexplanation as a key strategy to increase accessibility. Such explanation is\nchallenging for neural models to generate because it goes beyond simplification\nby adding content absent from the source. We derive two specialized paired\ncorpora from CELLS to address key challenges in lay language generation:\ngenerating background explanations and simplifying the original abstract. We\nadopt retrieval-augmented models as an intuitive fit for the task of background\nexplanation generation, and show improvements in summary quality and simplicity\nwhile maintaining factual correctness. Taken together, this work presents the\nfirst comprehensive study of background explanation for lay language\ngeneration, paving the path for disseminating scientific knowledge to a broader\naudience. CELLS is publicly available at:\nhttps://github.com/LinguisticAnomalies/pls_retrieval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yue Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_W/0/1/0/all/0/1\">Wei Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leroy_G/0/1/0/all/0/1\">Gondy Leroy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1\">Trevor Cohen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CultureBERT: Measuring Corporate Culture With Transformer-Based Language Models. (arXiv:2212.00509v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.00509","description":"<p>This paper introduces transformer-based language models to the literature\nmeasuring corporate culture from text documents. We compile a unique data set\nof employee reviews that were labeled by human evaluators with respect to the\ninformation the reviews reveal about the firms' corporate culture. Using this\ndata set, we fine-tune state-of-the-art transformer-based language models to\nperform the same classification task. In out-of-sample predictions, our\nlanguage models classify 17 to 30 percentage points more of employee reviews in\nline with human evaluators than traditional approaches of text classification.\nWe make our models publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koch_S/0/1/0/all/0/1\">Sebastian Koch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasch_S/0/1/0/all/0/1\">Stefan Pasch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Large Language Models for Clinical Named Entity Recognition via Prompt Engineering. (arXiv:2303.16416v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.16416","description":"<p>Objective: This study quantifies the capabilities of GPT-3.5 and GPT-4 for\nclinical named entity recognition (NER) tasks and proposes task-specific\nprompts to improve their performance. Materials and Methods: We evaluated these\nmodels on two clinical NER tasks: (1) to extract medical problems, treatments,\nand tests from clinical notes in the MTSamples corpus, following the 2010 i2b2\nconcept extraction shared task, and (2) identifying nervous system\ndisorder-related adverse events from safety reports in the vaccine adverse\nevent reporting system (VAERS). To improve the GPT models' performance, we\ndeveloped a clinical task-specific prompt framework that includes (1) baseline\nprompts with task description and format specification, (2) annotation\nguideline-based prompts, (3) error analysis-based instructions, and (4)\nannotated samples for few-shot learning. We assessed each prompt's\neffectiveness and compared the models to BioClinicalBERT. Results: Using\nbaseline prompts, GPT-3.5 and GPT-4 achieved relaxed F1 scores of 0.634, 0.804\nfor MTSamples, and 0.301, 0.593 for VAERS. Additional prompt components\nconsistently improved model performance. When all four components were used,\nGPT-3.5 and GPT-4 achieved relaxed F1 socres of 0.794, 0.861 for MTSamples and\n0.676, 0.736 for VAERS, demonstrating the effectiveness of our prompt\nframework. Although these results trail BioClinicalBERT (F1 of 0.901 for the\nMTSamples dataset and 0.802 for the VAERS), it is very promising considering\nfew training samples are needed. Conclusion: While direct application of GPT\nmodels to clinical NER tasks falls short of optimal performance, our\ntask-specific prompt framework, incorporating medical knowledge and training\nsamples, significantly enhances GPT models' feasibility for potential clinical\napplications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Jingcheng Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xueqing Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keloth_V/0/1/0/all/0/1\">Vipina Kuttichi Keloth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_X/0/1/0/all/0/1\">Xu Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yujia Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zehan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xiaoqian Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiyong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_K/0/1/0/all/0/1\">Kirk Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hua Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Zero to Hero: Harnessing Transformers for Biomedical Named Entity Recognition in Zero- and Few-shot Contexts. (arXiv:2305.04928v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.04928","description":"<p>Supervised named entity recognition (NER) in the biomedical domain depends on\nlarge sets of annotated texts with the given named entities. The creation of\nsuch datasets can be time-consuming and expensive, while extraction of new\nentities requires additional annotation tasks and retraining the model. To\naddress these challenges, this paper proposes a method for zero- and few-shot\nNER in the biomedical domain. The method is based on transforming the task of\nmulti-class token classification into binary token classification and\npre-training on a large amount of datasets and biomedical entities, which allow\nthe model to learn semantic relations between the given and potentially novel\nnamed entity labels. We have achieved average F1 scores of 35.44% for zero-shot\nNER, 50.10% for one-shot NER, 69.94% for 10-shot NER, and 79.51% for 100-shot\nNER on 9 diverse evaluated biomedical entities with fine-tuned PubMedBERT-based\nmodel. The results demonstrate the effectiveness of the proposed method for\nrecognizing new biomedical entities with no or limited number of examples,\noutperforming previous transformer-based methods, and being comparable to\nGPT3-based models using models with over 1000 times fewer parameters. We make\nmodels and developed code publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kosprdic_M/0/1/0/all/0/1\">Milo&#x161; Ko&#x161;prdi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prodanovic_N/0/1/0/all/0/1\">Nikola Prodanovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ljajic_A/0/1/0/all/0/1\">Adela Ljaji&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basaragin_B/0/1/0/all/0/1\">Bojana Ba&#x161;aragin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milosevic_N/0/1/0/all/0/1\">Nikola Milo&#x161;evi&#x107;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Diffusion Language Models Generation Can Be Halted Early. (arXiv:2305.10818v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.10818","description":"<p>Diffusion Language models (DLMs) are a promising avenue for text generation\ndue to their practical properties on tractable controllable generation. They\nalso have the advantage of not having to predict text autoregressively.\nHowever, despite these notable features, DLMs have not yet reached the\nperformance levels of their autoregressive counterparts. One of the ways to\nreduce the performance gap between these two types of language models is to\nspeed up the generation of DLMs. Therefore, we propose a novel methodology to\naddress this issue in this work. It enables the execution of more generation\nsteps within a given time frame, leading to higher-quality outputs.\nSpecifically, our methods estimate DLMs completeness of text generation and\nallow adaptive halting of the generation process. We evaluate our methods on\nPlaid, SSD, and CDCD DLMs and create a cohesive perspective on their generation\nworkflows. Finally, we confirm that our methods allow halting these models and\ndecrease the generation time by $10$-$40$\\% without a drop in the quality of\nmodel samples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vaina_S/0/1/0/all/0/1\">Sofia Maria Lo Cicero Vaina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balagansky_N/0/1/0/all/0/1\">Nikita Balagansky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gavrilov_D/0/1/0/all/0/1\">Daniil Gavrilov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OpenPI2.0: An Improved Dataset for Entity Tracking in Texts. (arXiv:2305.14603v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14603","description":"<p>Much text describes a changing world (e.g., procedures, stories, newswires),\nand understanding them requires tracking how entities change. An earlier\ndataset, OpenPI, provided crowdsourced annotations of entity state changes in\ntext. However, a major limitation was that those annotations were free-form and\ndid not identify salient changes, hampering model evaluation. To overcome these\nlimitations, we present an improved dataset, OpenPI2.0, where entities and\nattributes are fully canonicalized and additional entity salience annotations\nare added. On our fairer evaluation setting, we find that current\nstate-of-the-art language models are far from competent. We also show that\nusing state changes of salient entities as a chain-of-thought prompt,\ndownstream performance is improved on tasks such as question answering and\nclassical planning, outperforming the setting involving all related entities\nindiscriminately. We offer OpenPI2.0 for the continued development of models\nthat can understand the dynamics of entities in text.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hainiu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kommula_A/0/1/0/all/0/1\">Abhinav Kommula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1\">Chris Callison-Burch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tandon_N/0/1/0/all/0/1\">Niket Tandon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improved Cross-Lingual Transfer Learning For Automatic Speech Translation. (arXiv:2306.00789v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.00789","description":"<p>Research in multilingual speech-to-text translation is topical. Having a\nsingle model that supports multiple translation tasks is desirable. The goal of\nthis work it to improve cross-lingual transfer learning in multilingual\nspeech-to-text translation via semantic knowledge distillation. We show that by\ninitializing the encoder of the encoder-decoder sequence-to-sequence\ntranslation model with SAMU-XLS-R, a multilingual speech transformer encoder\ntrained using multi-modal (speech-text) semantic knowledge distillation, we\nachieve significantly better cross-lingual task knowledge transfer than the\nbaseline XLS-R, a multilingual speech transformer encoder trained via\nself-supervised learning. We demonstrate the effectiveness of our approach on\ntwo popular datasets, namely, CoVoST-2 and Europarl. On the 21 translation\ntasks of the CoVoST-2 benchmark, we achieve an average improvement of 12.8 BLEU\npoints over the baselines. In the zero-shot translation scenario, we achieve an\naverage gain of 18.8 and 11.9 average BLEU points on unseen medium and\nlow-resource languages. We make similar observations on Europarl speech\ntranslation benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khurana_S/0/1/0/all/0/1\">Sameer Khurana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dawalatabad_N/0/1/0/all/0/1\">Nauman Dawalatabad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laurent_A/0/1/0/all/0/1\">Antoine Laurent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vicente_L/0/1/0/all/0/1\">Luis Vicente</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gimeno_P/0/1/0/all/0/1\">Pablo Gimeno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mingote_V/0/1/0/all/0/1\">Victoria Mingote</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unifying Large Language Models and Knowledge Graphs: A Roadmap. (arXiv:2306.08302v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.08302","description":"<p>Large language models (LLMs), such as ChatGPT and GPT4, are making new waves\nin the field of natural language processing and artificial intelligence, due to\ntheir emergent ability and generalizability. However, LLMs are black-box\nmodels, which often fall short of capturing and accessing factual knowledge. In\ncontrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are\nstructured knowledge models that explicitly store rich factual knowledge. KGs\ncan enhance LLMs by providing external knowledge for inference and\ninterpretability. Meanwhile, KGs are difficult to construct and evolving by\nnature, which challenges the existing methods in KGs to generate new facts and\nrepresent unseen knowledge. Therefore, it is complementary to unify LLMs and\nKGs together and simultaneously leverage their advantages. In this article, we\npresent a forward-looking roadmap for the unification of LLMs and KGs. Our\nroadmap consists of three general frameworks, namely, 1) KG-enhanced LLMs,\nwhich incorporate KGs during the pre-training and inference phases of LLMs, or\nfor the purpose of enhancing understanding of the knowledge learned by LLMs; 2)\nLLM-augmented KGs, that leverage LLMs for different KG tasks such as embedding,\ncompletion, construction, graph-to-text generation, and question answering; and\n3) Synergized LLMs + KGs, in which LLMs and KGs play equal roles and work in a\nmutually beneficial way to enhance both LLMs and KGs for bidirectional\nreasoning driven by both data and knowledge. We review and summarize existing\nefforts within these three frameworks in our roadmap and pinpoint their future\nresearch directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shirui Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1\">Linhao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yufei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiapu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xindong Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"System-Level Natural Language Feedback. (arXiv:2306.13588v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.13588","description":"<p>Natural language (NL) feedback offers rich insights into user experience.\nWhile existing studies focus on an instance-level approach, where feedback is\nused to refine specific examples, we introduce a framework for system-level use\nof NL feedback. We show how to use feedback to formalize system-level design\ndecisions in a human-in-the-loop-process -- in order to produce better models.\nIn particular this is done through: (i) metric design for tasks; and (ii)\nlanguage model prompt design for refining model responses. We conduct two case\nstudies of this approach for improving search query and dialog response\ngeneration, demonstrating the effectiveness of system-level feedback. We show\nthe combination of system-level and instance-level feedback brings further\ngains, and that human written instance-level feedback results in more grounded\nrefinements than GPT-3.5 written ones, underlying the importance of human\nfeedback for building systems. We release our code and data at\nhttps://github.com/yyy-Apple/Sys-NL-Feedback.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1\">Weizhe Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Positive-Unlabeled Metric Learning Framework for Document-Level Relation Extraction with Incomplete Labeling. (arXiv:2306.14806v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.14806","description":"<p>The goal of document-level relation extraction (RE) is to identify relations\nbetween entities that span multiple sentences. Recently, incomplete labeling in\ndocument-level RE has received increasing attention, and some studies have used\nmethods such as positive-unlabeled learning to tackle this issue, but there is\nstill a lot of room for improvement. Motivated by this, we propose a\npositive-augmentation and positive-mixup positive-unlabeled metric learning\nframework (P3M). Specifically, we formulate document-level RE as a metric\nlearning problem. We aim to pull the distance closer between entity pair\nembedding and their corresponding relation embedding, while pushing it farther\naway from the none-class relation embedding. Additionally, we adapt the\npositive-unlabeled learning to this loss objective. In order to improve the\ngeneralizability of the model, we use dropout to augment positive samples and\npropose a positive-none-class mixup method. Extensive experiments show that P3M\nimproves the F1 score by approximately 4-10 points in document-level RE with\nincomplete labeling, and achieves state-of-the-art results in fully labeled\nscenarios. Furthermore, P3M has also demonstrated robustness to prior\nestimation bias in incomplete labeled scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Ye Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1\">Huazheng Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wenxin Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What do self-supervised speech models know about words?. (arXiv:2307.00162v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.00162","description":"<p>Many self-supervised speech models (S3Ms) have been introduced over the last\nfew years, improving performance and data efficiency on various speech tasks.\nHowever, these empirical successes alone do not give a complete picture of what\nis learned during pre-training. Recent work has begun analyzing how S3Ms encode\ncertain properties, such as phonetic and speaker information, but we still lack\na proper understanding of knowledge encoded at the word level and beyond. In\nthis work, we use lightweight analysis methods to study segment-level\nlinguistic properties -- word identity, boundaries, pronunciation, syntactic\nfeatures, and semantic features -- encoded in S3Ms. We present a comparative\nstudy of layer-wise representations from ten S3Ms and find that (i) the\nframe-level representations within each word segment are not all equally\ninformative, and (ii) the pre-training objective and model size heavily\ninfluence the accessibility and distribution of linguistic information across\nlayers. We also find that on several tasks -- word discrimination, word\nsegmentation, and semantic sentence similarity -- S3Ms trained with visual\ngrounding outperform their speech-only counterparts. Finally, our task-based\nanalyses demonstrate an improved performance on word segmentation and acoustic\nword discrimination while using simpler methods than prior work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pasad_A/0/1/0/all/0/1\">Ankita Pasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chien_C/0/1/0/all/0/1\">Chung-Ming Chien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Settle_S/0/1/0/all/0/1\">Shane Settle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Livescu_K/0/1/0/all/0/1\">Karen Livescu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Disentanglement in a GAN for Unconditional Speech Synthesis. (arXiv:2307.01673v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2307.01673","description":"<p>Can we develop a model that can synthesize realistic speech directly from a\nlatent space, without explicit conditioning? Despite several efforts over the\nlast decade, previous adversarial and diffusion-based approaches still struggle\nto achieve this, even on small-vocabulary datasets. To address this, we propose\nAudioStyleGAN (ASGAN) -- a generative adversarial network for unconditional\nspeech synthesis tailored to learn a disentangled latent space. Building upon\nthe StyleGAN family of image synthesis models, ASGAN maps sampled noise to a\ndisentangled latent vector which is then mapped to a sequence of audio features\nso that signal aliasing is suppressed at every layer. To successfully train\nASGAN, we introduce a number of new techniques, including a modification to\nadaptive discriminator augmentation which probabilistically skips discriminator\nupdates. We apply it on the small-vocabulary Google Speech Commands digits\ndataset, where it achieves state-of-the-art results in unconditional speech\nsynthesis. It is also substantially faster than existing top-performing\ndiffusion models. We confirm that ASGAN's latent space is disentangled: we\ndemonstrate how simple linear operations in the space can be used to perform\nseveral tasks unseen during training. Specifically, we perform evaluations in\nvoice conversion, speech enhancement, speaker verification, and keyword\nclassification. Our work indicates that GANs are still highly competitive in\nthe unconditional speech synthesis landscape, and that disentangled latent\nspaces can be used to aid generalization to unseen tasks. Code, models,\nsamples: https://github.com/RF5/simple-asgan/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Baas_M/0/1/0/all/0/1\">Matthew Baas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kamper_H/0/1/0/all/0/1\">Herman Kamper</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KoBBQ: Korean Bias Benchmark for Question Answering. (arXiv:2307.16778v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.16778","description":"<p>The Bias Benchmark for Question Answering (BBQ) is designed to evaluate\nsocial biases of language models (LMs), but it is not simple to adapt this\nbenchmark to cultural contexts other than the US because social biases depend\nheavily on the cultural context. In this paper, we present KoBBQ, a Korean bias\nbenchmark dataset, and we propose a general framework that addresses\nconsiderations for cultural adaptation of a dataset. Our framework includes\npartitioning the BBQ dataset into three classes--Simply-Transferred (can be\nused directly after cultural translation), Target-Modified (requires\nlocalization in target groups), and Sample-Removed (does not fit Korean\nculture)-- and adding four new categories of bias specific to Korean culture.\nWe conduct a large-scale survey to collect and validate the social biases and\nthe targets of the biases that reflect the stereotypes in Korean culture. The\nresulting KoBBQ dataset comprises 268 templates and 76,048 samples across 12\ncategories of social bias. We use KoBBQ to measure the accuracy and bias scores\nof several state-of-the-art multilingual LMs. The results clearly show\ndifferences in the bias of LMs as measured by KoBBQ and a machine-translated\nversion of BBQ, demonstrating the need for and utility of a well-constructed,\nculturally-aware social bias benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Jiho Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jiseon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1\">Nayeon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_H/0/1/0/all/0/1\">Haneul Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1\">Alice Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hwaran Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Arithmetic with Language Models: from Memorization to Computation. (arXiv:2308.01154v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2308.01154","description":"<p>A better understanding of the emergent computation and problem-solving\ncapabilities of recent large language models is of paramount importance to\nfurther improve them and broaden their applicability. This work investigates\nhow a language model, trained to predict the next token, can perform arithmetic\ncomputations generalizing beyond training data. Binary addition and\nmultiplication constitute a good testbed for this purpose, since they require a\nvery small vocabulary and exhibit relevant input/output discontinuities making\nsmooth input interpolation ineffective for novel data. We successfully trained\na light language model to learn these tasks and ran a number of experiments to\ninvestigate the extrapolation capabilities and internal information processing.\nOur findings support the hypothesis that the language model works as an\nEncoding-Regression-Decoding machine where the computation takes place in the\nvalue space once the input token representation is mapped to an appropriate\ninternal representation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Maltoni_D/0/1/0/all/0/1\">Davide Maltoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrara_M/0/1/0/all/0/1\">Matteo Ferrara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ERNetCL: A novel emotion recognition network in textual conversation based on curriculum learning strategy. (arXiv:2308.06450v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.06450","description":"<p>Emotion recognition in conversation (ERC) has emerged as a research hotspot\nin domains such as conversational robots and question-answer systems. How to\nefficiently and adequately retrieve contextual emotional cues has been one of\nthe key challenges in the ERC task. Existing efforts do not fully model the\ncontext and employ complex network structures, resulting in limited performance\ngains. In this paper, we propose a novel emotion recognition network based on\ncurriculum learning strategy (ERNetCL). The proposed ERNetCL primarily consists\nof temporal encoder (TE), spatial encoder (SE), and curriculum learning (CL)\nloss. We utilize TE and SE to combine the strengths of previous methods in a\nsimplistic manner to efficiently capture temporal and spatial contextual\ninformation in the conversation. To ease the harmful influence resulting from\nemotion shift and simulate the way humans learn curriculum from easy to hard,\nwe apply the idea of CL to the ERC task to progressively optimize the network\nparameters. At the beginning of training, we assign lower learning weights to\ndifficult samples. As the epoch increases, the learning weights for these\nsamples are gradually raised. Extensive experiments on four datasets exhibit\nthat our proposed method is effective and dramatically beats other baseline\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yingjian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1\">Zhigang Zeng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Massive Editing for Large Language Models via Meta Learning. (arXiv:2311.04661v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.04661","description":"<p>While large language models (LLMs) have enabled learning knowledge from the\npre-training corpora, the acquired knowledge may be fundamentally incorrect or\noutdated over time, which necessitates rectifying the knowledge of the language\nmodel (LM) after the training. A promising approach involves employing a\nhyper-network to generate parameter shift, whereas existing hyper-networks\nsuffer from inferior scalability in synchronous editing operation amount. To\nmitigate the problem, we propose the MAssive Language Model Editing Network\n(MALMEN), which formulates the parameter shift aggregation as the least square\nproblem, subsequently updating the LM parameters using the normal equation. To\naccommodate editing multiple facts simultaneously with limited memory budgets,\nwe separate the computation on the hyper-network and LM, enabling arbitrary\nbatch size on both neural networks. Our method is evaluated by editing up to\nthousands of facts on LMs with different architectures, i.e., BERT-base, GPT-2,\nT5-XL (2.8B), and GPT-J (6B), across various knowledge-intensive NLP tasks,\ni.e., closed book fact-checking and question answering. Remarkably, MALMEN is\ncapable of editing hundreds of times more facts than strong baselines with the\nidentical hyper-network architecture and outperforms editor specifically\ndesigned for GPT. Our code is available at\nhttps://github.com/ChenmienTan/malmen.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chenmien Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Ge Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging Large Language Models for Collective Decision-Making. (arXiv:2311.04928v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.04928","description":"<p>In various work contexts, such as meeting scheduling, collaborating, and\nproject planning, collective decision-making is essential but often challenging\ndue to diverse individual preferences, varying work focuses, and power dynamics\namong members. To address this, we propose a system leveraging Large Language\nModels (LLMs) to facilitate group decision-making by managing conversations and\nbalancing preferences among individuals. Our system aims to extract individual\npreferences from conversations and suggest options that satisfy the preferences\nof the members. We specifically apply this system to corporate meeting\nscheduling. We create synthetic employee profiles and simulate conversations at\nscale, leveraging LLMs to evaluate the system performance as a novel approach\nto conducting a user study. Our results indicate efficient coordination with\nreduced interactions between the members and the LLM-based system. The system\nrefines and improves its proposed options over time, ensuring that many of the\nmembers' individual preferences are satisfied in an equitable way. Finally, we\nconduct a survey study involving human participants to assess our system's\nability to aggregate preferences and reasoning about them. Our findings show\nthat the system exhibits strong performance in both dimensions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Papachristou_M/0/1/0/all/0/1\">Marios Papachristou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Longqi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1\">Chin-Chia Hsu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Meta Prompting for AGI Systems. (arXiv:2311.11482v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2311.11482","description":"<p>This paper presents a comprehensive study of Meta Prompting, an innovative\ntechnique reshaping the utilization of large language models (LLMs),\nmulti-modal foundation models, and AI systems in problem-solving and data\ninterpretation. Grounded in type theory and category theory, Meta Prompting\nemphasizes the structure and syntax of information over traditional\ncontent-centric methods. The paper explores the formal definitions of Meta\nPrompting (MP), sets it apart from Few-Shot Prompting, and underlines its\neffectiveness in various AI applications. A key focus is on extending Meta\nPrompting to complex reasoning tasks, showing how it effectively deconstructs\nintricate problems into simpler sub-problems, enhancing token efficiency and\nenabling more equitable problem-solving comparisons, especially against\nfew-shot example methods. Additionally, the paper introduces Meta Prompting for\nPrompting Tasks, allowing LLMs to self-generate new prompts in an iterative,\nmetaprogramming-like manner. This innovative approach marks a significant leap\nin AI's autonomous and adaptive capabilities. The paper also pioneers the\nintegration of Meta Prompting into multi-modal foundation model settings,\ntackling the challenges and opportunities of incorporating varied data types\nsuch as images, audio, and video within the structured Meta Prompting\nframework. (The code is available at\nhttps://github.com/meta-prompting/meta-prompting)\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yifan Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"General Phrase Debiaser: Debiasing Masked Language Models at a Multi-Token Level. (arXiv:2311.13892v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.13892","description":"<p>The social biases and unwelcome stereotypes revealed by pretrained language\nmodels are becoming obstacles to their application. Compared to numerous\ndebiasing methods targeting word level, there has been relatively less\nattention on biases present at phrase level, limiting the performance of\ndebiasing in discipline domains. In this paper, we propose an automatic\nmulti-token debiasing pipeline called \\textbf{General Phrase Debiaser}, which\nis capable of mitigating phrase-level biases in masked language models.\nSpecifically, our method consists of a \\textit{phrase filter stage} that\ngenerates stereotypical phrases from Wikipedia pages as well as a \\textit{model\ndebias stage} that can debias models at the multi-token level to tackle bias\nchallenges on phrases. The latter searches for prompts that trigger model's\nbias, and then uses them for debiasing. State-of-the-art results on standard\ndatasets and metrics show that our approach can significantly reduce gender\nbiases on both career and multiple disciplines, across models with varying\nparameter sizes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Bingkang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaodan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_D/0/1/0/all/0/1\">Dehan Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yulei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zongzhen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_H/0/1/0/all/0/1\">Honglei Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Longtao Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Task-Oriented Dialogues with Chitchat: a Comparative Study Based on Lexical Diversity and Divergence. (arXiv:2311.14067v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.14067","description":"<p>As a recent development, task-oriented dialogues (TODs) have been enriched\nwith chitchat in an effort to make dialogues more diverse and engaging. This\nenhancement is particularly valuable as TODs are often confined to narrow\ndomains, making the mitigation of repetitive and predictable responses a\nsignificant challenge. This paper presents a comparative analysis of three\nchitchat enhancements, aiming to identify the most effective approach in terms\nof diversity. Additionally, we quantify the divergence between the added\nchitchat, the original task-oriented language, and chitchat typically found in\nchitchat datasets, highlighting the top 20 divergent keywords for each\ncomparison. Our findings drive a discussion on future enhancements for\naugmenting TODs, emphasizing the importance of grounding dialogues beyond the\ntask to achieve more diverse and natural exchanges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stricker_A/0/1/0/all/0/1\">Armand Stricker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paroubek_P/0/1/0/all/0/1\">Patrick Paroubek</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs. (arXiv:2312.05934v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2312.05934","description":"<p>Large language models (LLMs) encapsulate a vast amount of factual information\nwithin their pre-trained weights, as evidenced by their ability to answer\ndiverse questions across different domains. However, this knowledge is\ninherently limited, relying heavily on the characteristics of the training\ndata. Consequently, using external datasets to incorporate new information or\nrefine the capabilities of LLMs on previously seen information poses a\nsignificant challenge. In this study, we compare two common approaches:\nunsupervised fine-tuning and retrieval-augmented generation (RAG). We evaluate\nboth approaches on a variety of knowledge-intensive tasks across different\ntopics. Our findings reveal that while unsupervised fine-tuning offers some\nimprovement, RAG consistently outperforms it, both for existing knowledge\nencountered during training and entirely new knowledge. Moreover, we find that\nLLMs struggle to learn new factual information through unsupervised\nfine-tuning, and that exposing them to numerous variations of the same fact\nduring training could alleviate this problem.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ovadia_O/0/1/0/all/0/1\">Oded Ovadia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brief_M/0/1/0/all/0/1\">Menachem Brief</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishaeli_M/0/1/0/all/0/1\">Moshik Mishaeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elisha_O/0/1/0/all/0/1\">Oren Elisha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Topic Bias in Emotion Classification. (arXiv:2312.09043v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.09043","description":"<p>Emotion corpora are typically sampled based on keyword/hashtag search or by\nasking study participants to generate textual instances. In any case, these\ncorpora are not uniform samples representing the entirety of a domain. We\nhypothesize that this practice of data acquisition leads to unrealistic\ncorrelations between overrepresented topics in these corpora that harm the\ngeneralizability of models. Such topic bias could lead to wrong predictions for\ninstances like \"I organized the service for my aunt's funeral.\" when funeral\nevents are over-represented for instances labeled with sadness, despite the\nemotion of pride being more appropriate here. In this paper, we study this\ntopic bias both from the data and the modeling perspective. We first label a\nset of emotion corpora automatically via topic modeling and show that emotions\nin fact correlate with specific topics. Further, we see that emotion\nclassifiers are confounded by such topics. Finally, we show that the\nestablished debiasing method of adversarial correction via gradient reversal\nmitigates the issue. Our work points out issues with existing emotion corpora\nand that more representative resources are required for fair evaluation of\nmodels predicting affective concepts from text.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wegge_M/0/1/0/all/0/1\">Maximilian Wegge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klinger_R/0/1/0/all/0/1\">Roman Klinger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey of Reasoning with Foundation Models. (arXiv:2312.11562v5 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2312.11562","description":"<p>Reasoning, a crucial ability for complex problem-solving, plays a pivotal\nrole in various real-world settings such as negotiation, medical diagnosis, and\ncriminal investigation. It serves as a fundamental methodology in the field of\nArtificial General Intelligence (AGI). With the ongoing development of\nfoundation models, e.g., Large Language Models (LLMs), there is a growing\ninterest in exploring their abilities in reasoning tasks. In this paper, we\nintroduce seminal foundation models proposed or adaptable for reasoning,\nhighlighting the latest advancements in various reasoning tasks, methods, and\nbenchmarks. We then delve into the potential future directions behind the\nemergence of reasoning abilities within foundation models. We also discuss the\nrelevance of multimodal learning, autonomous agents, and super alignment in the\ncontext of reasoning. By discussing these future research directions, we hope\nto inspire researchers in their exploration of this field, stimulate further\nadvancements in reasoning with foundation models, and contribute to the\ndevelopment of AGI.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiankai Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chuanyang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1\">Enze Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_R/0/1/0/all/0/1\">Ruihang Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1\">Jianing Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiaqi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Mingyu Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_M/0/1/0/all/0/1\">Mengzhe Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenhai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junsong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1\">Zhangyue Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiaozhe Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junxian He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1\">Wu Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xihui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Ming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1\">Pheng Ann Heng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Jifeng Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingdong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yike Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Hui Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Adaptive Placement and Parallelism Framework for Accelerating RLHF Training. (arXiv:2312.11819v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2312.11819","description":"<p>Recently, ChatGPT or InstructGPT like large language models (LLM) has made a\nsignificant impact in the AI world. Many works have attempted to reproduce the\ncomplex InstructGPT's training pipeline, namely Reinforcement Learning with\nHuman Feedback (RLHF). However, the mainstream distributed RLHF training\nmethods typically adopt a fixed model placement strategy, referred to as the\nFlattening strategy. This strategy treats all four interdependent models\ninvolved in RLHF as a single entity, distributing them across all devices and\napplying parallelism techniques designed for a single model, regardless of the\ndifferent workloads inherent to each model. As a result, this strategy\nexacerbates the generation bottlenecks in the RLHF training and degrades the\noverall training efficiency. To address these issues, we propose an adaptive\nmodel placement framework that offers two flexible model placement strategies.\nThe Interleaving strategy helps reduce memory redundancy and communication\ncosts of RLHF training by placing models without dependencies on exclusive\ndevices with careful orchestration. On the other hand, the Separation strategy\nimproves the throughput of model training by separating the training and\ninference runtime of the RLHF pipeline with additional shadow models.\nFurthermore, our framework provides a simple user interface and allows for the\nagile allocation of models across devices in a fine-grained manner for various\ntraining scenarios, involving models of varying sizes and devices of different\nscales. Extensive experiments have demonstrated that our Interleaving and\nSeparation strategies can achieve notable improvements up to 11X, compared to\nthe current SOTA approaches. The results highlight the effectiveness and\nadaptability of our approaches in accelerating the training of distributed\nRLHF.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Youshao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Weichang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhenglei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_F/0/1/0/all/0/1\">Fagui Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shangchun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_L/0/1/0/all/0/1\">Lin Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_L/0/1/0/all/0/1\">Lei Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaolu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jun Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Advancing Abductive Reasoning in Knowledge Graphs through Complex Logical Hypothesis Generation. (arXiv:2312.15643v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2312.15643","description":"<p>Abductive reasoning is the process of making educated guesses to provide\nexplanations for observations. Although many applications require the use of\nknowledge for explanations, the utilization of abductive reasoning in\nconjunction with structured knowledge, such as a knowledge graph, remains\nlargely unexplored. To fill this gap, this paper introduces the task of complex\nlogical hypothesis generation, as an initial step towards abductive logical\nreasoning with KG. In this task, we aim to generate a complex logical\nhypothesis so that it can explain a set of observations. We find that the\nsupervised trained generative model can generate logical hypotheses that are\nstructurally closer to the reference hypothesis. However, when generalized to\nunseen observations, this training objective does not guarantee better\nhypothesis generation. To address this, we introduce the Reinforcement Learning\nfrom Knowledge Graph (RLF-KG) method, which minimizes differences between\nobservations and conclusions drawn from generated hypotheses according to the\nKG. Experiments show that, with RLF-KG's assistance, the generated hypotheses\nprovide better explanations, and achieve state-of-the-art results on three\nwidely used KGs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Jiaxin Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yicheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1\">Tianshi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yue Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can AI Be as Creative as Humans?. (arXiv:2401.01623v4 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2401.01623","description":"<p>Creativity serves as a cornerstone for societal progress and innovation. With\nthe rise of advanced generative AI models capable of tasks once reserved for\nhuman creativity, the study of AI's creative potential becomes imperative for\nits responsible development and application. In this paper, we prove in theory\nthat AI can be as creative as humans under the condition that it can properly\nfit the data generated by human creators. Therefore, the debate on AI's\ncreativity is reduced into the question of its ability to fit a sufficient\namount of data. To arrive at this conclusion, this paper first addresses the\ncomplexities in defining creativity by introducing a new concept called\nRelative Creativity. Rather than attempting to define creativity universally,\nwe shift the focus to whether AI can match the creative abilities of a\nhypothetical human. The methodological shift leads to a statistically\nquantifiable assessment of AI's creativity, term Statistical Creativity. This\nconcept, statistically comparing the creative abilities of AI with those of\nspecific human groups, facilitates theoretical exploration of AI's creative\npotential. Our analysis reveals that by fitting extensive conditional data\nwithout marginalizing out the generative conditions, AI can emerge as a\nhypothetical new creator. The creator possesses the same creative abilities on\npar with the human creators it was trained on. Building on theoretical\nfindings, we discuss the application in prompt-conditioned autoregressive\nmodels, providing a practical means for evaluating creative abilities of\ngenerative AI models, such as Large Language Models (LLMs). Additionally, this\nstudy provides an actionable training guideline, bridging the theoretical\nquantification of creativity with practical model training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haonan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1\">Michael Mozer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1\">Anirudh Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamb_A/0/1/0/all/0/1\">Alex Lamb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Weijie J Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhun Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_M/0/1/0/all/0/1\">Michael Qizhe Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_H/0/1/0/all/0/1\">Hannah Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TrustLLM: Trustworthiness in Large Language Models. (arXiv:2401.05561v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.05561","description":"<p>Large language models (LLMs), exemplified by ChatGPT, have gained\nconsiderable attention for their excellent natural language processing\ncapabilities. Nonetheless, these LLMs present many challenges, particularly in\nthe realm of trustworthiness. Therefore, ensuring the trustworthiness of LLMs\nemerges as an important topic. This paper introduces TrustLLM, a comprehensive\nstudy of trustworthiness in LLMs, including principles for different dimensions\nof trustworthiness, established benchmark, evaluation, and analysis of\ntrustworthiness for mainstream LLMs, and discussion of open challenges and\nfuture directions. Specifically, we first propose a set of principles for\ntrustworthy LLMs that span eight different dimensions. Based on these\nprinciples, we further establish a benchmark across six dimensions including\ntruthfulness, safety, fairness, robustness, privacy, and machine ethics. We\nthen present a study evaluating 16 mainstream LLMs in TrustLLM, consisting of\nover 30 datasets. Our findings firstly show that in general trustworthiness and\nutility (i.e., functional effectiveness) are positively related. Secondly, our\nobservations reveal that proprietary LLMs generally outperform most open-source\ncounterparts in terms of trustworthiness, raising concerns about the potential\nrisks of widely accessible open-source LLMs. However, a few open-source LLMs\ncome very close to proprietary ones. Thirdly, it is important to note that some\nLLMs may be overly calibrated towards exhibiting trustworthiness, to the extent\nthat they compromise their utility by mistakenly treating benign prompts as\nharmful and consequently not responding. Finally, we emphasize the importance\nof ensuring transparency not only in the models themselves but also in the\ntechnologies that underpin trustworthiness. Knowing the specific trustworthy\ntechnologies that have been employed is crucial for analyzing their\neffectiveness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Lichao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Siyuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qihui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chujie Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yixin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_W/0/1/0/all/0/1\">Wenhan Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yixuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiner Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yixin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yijue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhikun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1\">Bhavya Kailkhura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaowei Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Furong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1\">Huaxiu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kellis_M/0/1/0/all/0/1\">Manolis Kellis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zitnik_M/0/1/0/all/0/1\">Marinka Zitnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1\">Jian Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jieyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_J/0/1/0/all/0/1\">John Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_K/0/1/0/all/0/1\">Kai Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kaidi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Lifang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Lifu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1\">Michael Backes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1\">Neil Zhenqiang Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1\">Quanquan Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1\">Rex Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shuiwang Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jana_S/0/1/0/all/0/1\">Suman Jana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yanfang Ye</a>, et al. (3 additional authors not shown)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models. (arXiv:2401.08491v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.08491","description":"<p>The generation of undesirable and factually incorrect content of large\nlanguage models poses a significant challenge and remains largely an unsolved\nissue. This paper studies the integration of a contrastive learning objective\nfor fine-tuning LLMs for implicit knowledge editing and controlled text\ngeneration. Optimizing the training objective entails aligning text\nperplexities in a contrastive fashion. To facilitate training the model in a\nself-supervised fashion, we leverage an off-the-shelf LLM for training data\ngeneration. We showcase applicability in the domain of detoxification. Herein,\nthe proposed approach leads to a significant decrease in the generation of\ntoxic content while preserving general utility for downstream tasks such as\ncommonsense reasoning and reading comprehension. The proposed approach is\nconceptually simple but empirically powerful.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Klein_T/0/1/0/all/0/1\">Tassilo Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nabi_M/0/1/0/all/0/1\">Moin Nabi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Top in Chinese Data Processing: English Code Models. (arXiv:2401.10286v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.10286","description":"<p>While the alignment between tasks and training corpora is a fundamental\nconsensus in the application of language models, our series of experiments and\nthe metrics we designed reveal that code-based Large Language Models (LLMs)\nsignificantly outperform models trained on data that is closely matched to the\ntasks in non-coding Chinese tasks. Moreover, in tasks high sensitivity to\nChinese hallucinations, models exhibiting fewer linguistic features of the\nChinese language achieve better performance. Our experimental results can be\neasily replicated in Chinese data processing tasks, such as preparing data for\nRetrieval-Augmented Generation (RAG), by simply replacing the base model with a\ncode-based model. Additionally, our research offers a distinct perspective for\ndiscussion on the philosophical \"Chinese Room\" thought experiment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Linghan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xiaojun Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jiayuan Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_Y/0/1/0/all/0/1\">Yue Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_G/0/1/0/all/0/1\">Gang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hongwei Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences. (arXiv:2401.10529v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2401.10529","description":"<p>Multimodal Large Language Models (MLLMs) have demonstrated proficiency in\nhandling a variety of visual-language tasks. However, current MLLM benchmarks\nare predominantly designed to evaluate reasoning based on static information\nabout a single image, and the ability of modern MLLMs to extrapolate from image\nsequences, which is essential for understanding our ever-changing world, has\nbeen less investigated. To address this challenge, this paper introduces\nMementos, a new benchmark designed to assess MLLMs' sequential image reasoning\nabilities. Mementos features 4,761 diverse image sequences with varying\nlengths. We also employ a GPT-4 assisted method to evaluate MLLM reasoning\nperformance. Through a careful evaluation of nine recent MLLMs on Mementos,\nincluding GPT-4V and Gemini, we find that they struggle to accurately describe\ndynamic information about given image sequences, often leading to\nhallucinations/misrepresentations of objects and their corresponding behaviors.\nOur quantitative analysis and case studies identify three key factors impacting\nMLLMs' sequential image reasoning: the correlation between object and\nbehavioral hallucinations, the influence of cooccurring behaviors, and the\ncompounding impact of behavioral hallucinations. Our dataset is available at\nhttps://github.com/umd-huang-lab/Mementos.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuhang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hongjin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yuancheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_F/0/1/0/all/0/1\">Feihong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jaehong Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1\">Taixi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertasius_G/0/1/0/all/0/1\">Gedas Bertasius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1\">Huaxiu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Furong Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language Models. (arXiv:2401.12522v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.12522","description":"<p>Large language models (LLMs) commonly employ autoregressive generation during\ninference, leading to high memory bandwidth demand and consequently extended\nlatency. To mitigate this inefficiency, we present Bi-directional Tuning for\nlossless Acceleration (BiTA), an innovative method expediting LLMs via\nstreamlined semi-autoregressive generation and draft verification. Inspired by\nthe concept of prompt tuning, we enhance LLMs with a parameter-efficient design\ncalled bi-directional tuning for the capability in semi-autoregressive\ngeneration. Employing efficient tree-based decoding, the models perform draft\ncandidate generation and verification in parallel, ensuring outputs identical\nto their autoregressive counterparts under greedy sampling. BiTA serves as a\nlightweight plug-in module, seamlessly boosting the inference efficiency of\nexisting LLMs without requiring additional assistance models or incurring\nsignificant extra memory costs. Applying the proposed BiTA, LLaMA-2-70B-Chat\nachieves a 2.7$\\times$ speedup on the MT-Bench benchmark. Extensive experiments\nconfirm our method surpasses state-of-the-art acceleration techniques.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1\">Feng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_H/0/1/0/all/0/1\">Hanling Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongbin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yifan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiaotian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1\">Guangming Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_R/0/1/0/all/0/1\">Rong Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Energy-based Automated Model Evaluation. (arXiv:2401.12689v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2401.12689","description":"<p>The conventional evaluation protocols on machine learning models rely heavily\non a labeled, i.i.d-assumed testing dataset, which is not often present in real\nworld applications. The Automated Model Evaluation (AutoEval) shows an\nalternative to this traditional workflow, by forming a proximal prediction\npipeline of the testing performance without the presence of ground-truth\nlabels. Despite its recent successes, the AutoEval frameworks still suffer from\nan overconfidence issue, substantial storage and computational cost. In that\nregard, we propose a novel measure -- Meta-Distribution Energy (MDE) -- that\nallows the AutoEval framework to be both more efficient and effective. The core\nof the MDE is to establish a meta-distribution statistic, on the information\n(energy) associated with individual samples, then offer a smoother\nrepresentation enabled by energy-based learning. We further provide our\ntheoretical insights by connecting the MDE with the classification loss. We\nprovide extensive experiments across modalities, datasets and different\narchitectural backbones to validate MDE's validity, together with its\nsuperiority compared with prior approaches. We also prove MDE's versatility by\nshowing its seamless integration with large-scale models, and easy adaption to\nlearning scenarios with noisy- or imbalanced- labels. Code and data are\navailable: https://github.com/pengr/Energy_AutoEval\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peng_R/0/1/0/all/0/1\">Ru Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_H/0/1/0/all/0/1\">Heming Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haobo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yawen Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zenan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Junbo Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition. (arXiv:2401.12756v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.12756","description":"<p>The knowledge encapsulated in a model is the core factor determining its\nfinal performance on downstream tasks. Much research in NLP has focused on\nefficient methods for storing and adapting different types of knowledge, e.g.,\nin dedicated modularized structures, and on how to effectively combine these,\ne.g., by learning additional parameters. However, given the many possible\noptions, a thorough understanding of the mechanisms involved in these\ncompositions is missing, and hence it remains unclear which strategies to\nutilize. To address this research gap, we propose a novel framework for\nzero-shot module composition, which encompasses existing and some novel\nvariations for selecting, weighting, and combining parameter modules under a\nsingle unified notion. Focusing on the scenario of domain knowledge and adapter\nlayers, our framework provides a systematic unification of concepts, allowing\nus to conduct the first comprehensive benchmarking study of various zero-shot\nknowledge composition strategies. In particular, we test two module combination\nmethods and five selection and weighting strategies for their effectiveness and\nefficiency in an extensive experimental setup. Our results highlight the\nefficacy of ensembling but also hint at the power of simple though\noften-ignored weighting methods. Further in-depth analyses allow us to\nunderstand the role of weighting vs. top-k selection, and show that, to a\ncertain extent, the performance of adapter composition can even be predicted.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Holtermann_C/0/1/0/all/0/1\">Carolin Holtermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frohmann_M/0/1/0/all/0/1\">Markus Frohmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rekabsaz_N/0/1/0/all/0/1\">Navid Rekabsaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lauscher_A/0/1/0/all/0/1\">Anne Lauscher</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation. (arXiv:2401.13527v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.13527","description":"<p>Benefiting from effective speech modeling, current Speech Large Language\nModels (SLLMs) have demonstrated exceptional capabilities in in-context speech\ngeneration and efficient generalization to unseen speakers. However, the\nprevailing information modeling process is encumbered by certain redundancies,\nleading to inefficiencies in speech generation. We propose Chain-of-Information\nGeneration (CoIG), a method for decoupling semantic and perceptual information\nin large-scale speech generation. Building on this, we develop SpeechGPT-Gen,\nan 8-billion-parameter SLLM efficient in semantic and perceptual information\nmodeling. It comprises an autoregressive model based on LLM for semantic\ninformation modeling and a non-autoregressive model employing flow matching for\nperceptual information modeling. Additionally, we introduce the novel approach\nof infusing semantic information into the prior distribution to enhance the\nefficiency of flow matching. Extensive experimental results demonstrate that\nSpeechGPT-Gen markedly excels in zero-shot text-to-speech, zero-shot voice\nconversion, and speech-to-speech dialogue, underscoring CoIG's remarkable\nproficiency in capturing and modeling speech's semantic and perceptual\ndimensions. Code and models are available at\nhttps://github.com/0nutation/SpeechGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_J/0/1/0/all/0/1\">Jun Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shimin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yaqian Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MM-LLMs: Recent Advances in MultiModal Large Language Models. (arXiv:2401.13601v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.13601","description":"<p>In the past year, MultiModal Large Language Models (MM-LLMs) have undergone\nsubstantial advancements, augmenting off-the-shelf LLMs to support MM inputs or\noutputs via cost-effective training strategies. The resulting models not only\npreserve the inherent reasoning and decision-making capabilities of LLMs but\nalso empower a diverse range of MM tasks. In this paper, we provide a\ncomprehensive survey aimed at facilitating further research of MM-LLMs.\nSpecifically, we first outline general design formulations for model\narchitecture and training pipeline. Subsequently, we provide brief\nintroductions of $26$ existing MM-LLMs, each characterized by its specific\nformulations. Additionally, we review the performance of MM-LLMs on mainstream\nbenchmarks and summarize key training recipes to enhance the potency of\nMM-LLMs. Lastly, we explore promising directions for MM-LLMs while concurrently\nmaintaining a real-time tracking website for the latest developments in the\nfield. We hope that this survey contributes to the ongoing advancement of the\nMM-LLMs domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Duzhen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yahan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenxing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jiahua Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1\">Dan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_C/0/1/0/all/0/1\">Chenhui Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Instructional Fingerprinting of Large Language Models. (arXiv:2401.12255v1 [cs.CR] CROSS LISTED)","link":"http://arxiv.org/abs/2401.12255","description":"<p>The exorbitant cost of training Large language models (LLMs) from scratch\nmakes it essential to fingerprint the models to protect intellectual property\nvia ownership authentication and to ensure downstream users and developers\ncomply with their license terms (e.g. restricting commercial use). In this\nstudy, we present a pilot study on LLM fingerprinting as a form of very\nlightweight instruction tuning. Model publisher specifies a confidential\nprivate key and implants it as an instruction backdoor that causes the LLM to\ngenerate specific text when the key is present. Results on 11 popularly-used\nLLMs showed that this approach is lightweight and does not affect the normal\nbehavior of the model. It also prevents publisher overclaim, maintains\nrobustness against fingerprint guessing and parameter-efficient training, and\nsupports multi-stage fingerprinting akin to MIT License. Code is available in\nhttps://cnut1648.github.io/Model-Fingerprint/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiashu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Mingyu Derek Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koh_P/0/1/0/all/0/1\">Pang Wei Koh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaowei Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Muhao Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2024-01-25T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","syn":"http://purl.org/rss/1.0/modules/syndication/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","admin":"http://webns.net/mvcb/","content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/"}}]}]}