{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-01-10T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Witscript 3: A Hybrid AI System for Improvising Jokes in a Conversation. (arXiv:2301.02695v1 [cs.CL])","link":"http://arxiv.org/abs/2301.02695","description":"<p>Previous papers presented Witscript and Witscript 2, AI systems for\nimprovising jokes in a conversation. Witscript generates jokes that rely on\nwordplay, whereas the jokes generated by Witscript 2 rely on common sense. This\npaper extends that earlier work by presenting Witscript 3, which generates joke\ncandidates using three joke production mechanisms and then selects the best\ncandidate to output. Like Witscript and Witscript 2, Witscript 3 is based on\nhumor algorithms created by an expert comedy writer. Human evaluators judged\nWitscript 3's responses to input sentences to be jokes 44% of the time. This is\nevidence that Witscript 3 represents another step toward giving a chatbot a\nhumanlike sense of humor.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Toplyn_J/0/1/0/all/0/1\">Joe Toplyn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Facilitating Contrastive Learning of Discourse Relational Senses by Exploiting the Hierarchy of Sense Relations. (arXiv:2301.02724v1 [cs.CL])","link":"http://arxiv.org/abs/2301.02724","description":"<p>Implicit discourse relation recognition is a challenging task that involves\nidentifying the sense or senses that hold between two adjacent spans of text,\nin the absence of an explicit connective between them. In both PDTB-2 and\nPDTB-3, discourse relational senses are organized into a three-level hierarchy\nranging from four broad top-level senses, to more specific senses below them.\nMost previous work on implicit discourse relation recognition have used the\nsense hierarchy simply to indicate what sense labels were available. Here we do\nmore -- incorporating the sense hierarchy into the recognition process itself\nand using it to select the negative examples used in contrastive learning. With\nno additional effort, the approach achieves state-of-the-art performance on the\ntask.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Long_W/0/1/0/all/0/1\">Wanqiu Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Webber_B/0/1/0/all/0/1\">Bonnie Webber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conditional Generation of Paired Antibody Chain Sequences through Encoder-Decoder Language Model. (arXiv:2301.02748v1 [q-bio.BM])","link":"http://arxiv.org/abs/2301.02748","description":"<p>Protein language models (LMs) have been successful in sequence, structural\nand functional predictions. However, currently, protein LMs are limited to\nencoder- or decoder-only architectures for single sequences while many\nbiological contexts involve protein-protein interactions. Here, we introduce\npAbT5, which models antibody chain pairing as forward- and back-translations\nusing a T5-based architecture. We show that pAbT5 accurately reflects chain\npairing through sequence generation and mispairing as unsupervised and\nsupervised classifications. Our protein LM generates variable-length sequences\nand its next-word prediction probability agrees with position-specific scoring\nmatrix from sequence alignment. Like other works in protein LM, pAbT5 performs\nstate-of-the-art unsupervised prediction on experimental measurements. To the\nbest of our knowledge, pAbT5 is the first encoder-decoder protein LM for\nprotein-protein interactions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-bio/1/au:+Chu_S/0/1/0/all/0/1\">Simon K.S. Chu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wei_K/0/1/0/all/0/1\">Kathy Y. Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Building a Parallel Corpus and Training Translation Models Between Luganda and English. (arXiv:2301.02773v1 [cs.CL])","link":"http://arxiv.org/abs/2301.02773","description":"<p>Neural machine translation (NMT) has achieved great successes with large\ndatasets, so NMT is more premised on high-resource languages. This continuously\nunderpins the low resource languages such as Luganda due to the lack of\nhigh-quality parallel corpora, so even 'Google translate' does not serve\nLuganda at the time of this writing. In this paper, we build a parallel corpus\nwith 41,070 pairwise sentences for Luganda and English which is based on three\ndifferent open-sourced corpora. Then, we train NMT models with hyper-parameter\nsearch on the dataset. Experiments gave us a BLEU score of 21.28 from Luganda\nto English and 17.47 from English to Luganda. Some translation examples show\nhigh quality of the translation. We believe that our model is the first\nLuganda-English NMT model. The bilingual dataset we built will be available to\nthe public.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kimera_R/0/1/0/all/0/1\">Richard Kimera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rim_D/0/1/0/all/0/1\">Daniela N. Rim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1\">Heeyoul Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visual Story Generation Based on Emotion and Keywords. (arXiv:2301.02777v1 [cs.AI])","link":"http://arxiv.org/abs/2301.02777","description":"<p>Automated visual story generation aims to produce stories with corresponding\nillustrations that exhibit coherence, progression, and adherence to characters'\nemotional development. This work proposes a story generation pipeline to\nco-create visual stories with the users. The pipeline allows the user to\ncontrol events and emotions on the generated content. The pipeline includes two\nparts: narrative and image generation. For narrative generation, the system\ngenerates the next sentence using user-specified keywords and emotion labels.\nFor image generation, diffusion models are used to create a visually appealing\nimage corresponding to each generated sentence. Further, object recognition is\napplied to the generated images to allow objects in these images to be\nmentioned in future story development.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuetian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruohua Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Bowen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Peiru Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_M/0/1/0/all/0/1\">Mei Si</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Linguistic-style-aware Neural Networks for Fake News Detection. (arXiv:2301.02792v1 [cs.CL])","link":"http://arxiv.org/abs/2301.02792","description":"<p>We propose the hierarchical recursive neural network (HERO) to predict fake\nnews by learning its linguistic style, which is distinguishable from the truth,\nas psychological theories reveal. We first generate the hierarchical linguistic\ntree of news documents; by doing so, we translate each news document's\nlinguistic style into its writer's usage of words and how these words are\nrecursively structured as phrases, sentences, paragraphs, and, ultimately, the\ndocument. By integrating the hierarchical linguistic tree with the neural\nnetwork, the proposed method learns and classifies the representation of news\ndocuments by capturing their locally sequential and globally recursive\nstructures that are linguistically meaningful. It is the first work offering\nthe hierarchical linguistic tree and the neural network preserving the tree\ninformation to our best knowledge. Experimental results based on public\nreal-world datasets demonstrate the proposed method's effectiveness, which can\noutperform state-of-the-art techniques in classifying short and long news\ndocuments. We also examine the differential linguistic style of fake news and\nthe truth and observe some patterns of fake news. The code and data have been\npublicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xinyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiayu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qinzhou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zafarani_R/0/1/0/all/0/1\">Reza Zafarani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RLAS-BIABC: A Reinforcement Learning-Based Answer Selection Using the BERT Model Boosted by an Improved ABC Algorithm. (arXiv:2301.02807v1 [cs.CL])","link":"http://arxiv.org/abs/2301.02807","description":"<p>Answer selection (AS) is a critical subtask of the open-domain question\nanswering (QA) problem. The present paper proposes a method called RLAS-BIABC\nfor AS, which is established on attention mechanism-based long short-term\nmemory (LSTM) and the bidirectional encoder representations from transformers\n(BERT) word embedding, enriched by an improved artificial bee colony (ABC)\nalgorithm for pretraining and a reinforcement learning-based algorithm for\ntraining backpropagation (BP) algorithm. BERT can be comprised in downstream\nwork and fine-tuned as a united task-specific architecture, and the pretrained\nBERT model can grab different linguistic effects. Existing algorithms typically\ntrain the AS model with positive-negative pairs for a two-class classifier. A\npositive pair contains a question and a genuine answer, while a negative one\nincludes a question and a fake answer. The output should be one for positive\nand zero for negative pairs. Typically, negative pairs are more than positive,\nleading to an imbalanced classification that drastically reduces system\nperformance. To deal with it, we define classification as a sequential\ndecision-making process in which the agent takes a sample at each step and\nclassifies it. For each classification operation, the agent receives a reward,\nin which the prize of the majority class is less than the reward of the\nminority class. Ultimately, the agent finds the optimal value for the policy\nweights. We initialize the policy weights with the improved ABC algorithm. The\ninitial value technique can prevent problems such as getting stuck in the local\noptimum. Although ABC serves well in most tasks, there is still a weakness in\nthe ABC algorithm that disregards the fitness of related pairs of individuals\nin discovering a neighboring food source position.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gharagozlou_H/0/1/0/all/0/1\">Hamid Gharagozlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammadzadeh_J/0/1/0/all/0/1\">Javad Mohammadzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastanfard_A/0/1/0/all/0/1\">Azam Bastanfard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghidary_S/0/1/0/all/0/1\">Saeed Shiry Ghidary</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Brain-inspired Memory Transformation based Differentiable Neural Computer for Reasoning-based Question Answering. (arXiv:2301.02809v1 [cs.AI])","link":"http://arxiv.org/abs/2301.02809","description":"<p>Reasoning and question answering as a basic cognitive function for humans, is\nnevertheless a great challenge for current artificial intelligence. Although\nthe Differentiable Neural Computer (DNC) model could solve such problems to a\ncertain extent, the development is still limited by its high algorithm\ncomplexity, slow convergence speed, and poor test robustness. Inspired by the\nlearning and memory mechanism of the brain, this paper proposed a Memory\nTransformation based Differentiable Neural Computer (MT-DNC) model. MT-DNC\nincorporates working memory and long-term memory into DNC, and realizes the\nautonomous transformation of acquired experience between working memory and\nlong-term memory, thereby helping to effectively extract acquired knowledge to\nimprove reasoning ability. Experimental results on bAbI question answering task\ndemonstrated that our proposed method achieves superior performance and faster\nconvergence speed compared to other existing DNN and DNC models. Ablation\nstudies also indicated that the memory transformation from working memory to\nlong-term memory plays essential role in improving the robustness and stability\nof reasoning. This work explores how brain-inspired memory transformation can\nbe integrated and applied to complex intelligent dialogue and reasoning\nsystems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1\">Hongjian Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1\">Feifei Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Why do Nearest Neighbor Language Models Work?. (arXiv:2301.02828v1 [cs.CL])","link":"http://arxiv.org/abs/2301.02828","description":"<p>Language models (LMs) compute the probability of a text by sequentially\ncomputing a representation of an already-seen context and using this\nrepresentation to predict the next word. Currently, most LMs calculate these\nrepresentations through a neural network consuming the immediate previous\ncontext. However recently, retrieval-augmented LMs have shown to improve over\nstandard neural LMs, by accessing information retrieved from a large datastore,\nin addition to their standard, parametric, next-word prediction. In this paper,\nwe set out to understand why retrieval-augmented language models, and\nspecifically why k-nearest neighbor language models (kNN-LMs) perform better\nthan standard parametric LMs, even when the k-nearest neighbor component\nretrieves examples from the same training set that the LM was originally\ntrained on. To this end, we perform a careful analysis of the various\ndimensions over which kNN-LM diverges from standard LMs, and investigate these\ndimensions one by one. Empirically, we identify three main reasons why kNN-LM\nperforms better than standard LMs: using a different input representation for\npredicting the next tokens, approximate kNN search, and the importance of\nsoftmax temperature for the kNN distribution. Further, we incorporate these\ninsights into the model architecture or the training procedure of the standard\nparametric LM, improving its results without the need for an explicit retrieval\ncomponent. The code is available at https://github.com/frankxu2004/knnlm-why.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1\">Frank F. Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alon_U/0/1/0/all/0/1\">Uri Alon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SpeeChain: A Speech Toolkit for Large-Scale Machine Speech Chain. (arXiv:2301.02966v1 [cs.CL])","link":"http://arxiv.org/abs/2301.02966","description":"<p>This paper introduces SpeeChain, an open-source Pytorch-based toolkit\ndesigned to develop the machine speech chain for large-scale use. This first\nrelease focuses on the TTS-to-ASR chain, a core component of the machine speech\nchain, that refers to the TTS data augmentation by unspoken text for ASR. To\nbuild an efficient pipeline for the large-scale TTS-to-ASR chain, we implement\neasy-to-use multi-GPU batch-level model inference, multi-dataloader batch\ngeneration, and on-the-fly data selection techniques. In this paper, we first\nexplain the overall procedure of the TTS-to-ASR chain and the difficulties of\neach step. Then, we present a detailed ablation study on different types of\nunlabeled data, data filtering thresholds, batch composition, and\nreal-synthetic data ratios. Our experimental results on train_clean_460 of\nLibriSpeech demonstrate that our TTS-to-ASR chain can significantly improve WER\nin a semi-supervised setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1\">Heli Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Novitasari_S/0/1/0/all/0/1\">Sashi Novitasari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tjandra_A/0/1/0/all/0/1\">Andros Tjandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakti_S/0/1/0/all/0/1\">Sakriani Sakti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakamura_S/0/1/0/all/0/1\">Satoshi Nakamura</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Traditional Readability Formulas Compared for English. (arXiv:2301.02975v1 [cs.CL])","link":"http://arxiv.org/abs/2301.02975","description":"<p>Traditional English readability formulas, or equations, were largely\ndeveloped in the 20th century. Nonetheless, many researchers still rely on them\nfor various NLP applications. Such a phenomenon is presumably due to the\nconvenience and straightforwardness of readability formulas. In this work, we\ncontribute to the NLP community by 1. introducing New English Readability\nFormula (NERF), 2. recalibrating the coefficients of old readability formulas\n(Flesch-Kincaid Grade Level, Fog Index, SMOG Index, Coleman-Liau Index, and\nAutomated Readability Index), 3. evaluating the readability formulas, for use\nin text simplification studies and medical texts, and 4. developing a\nPython-based program for the wide application to various NLP projects.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1\">Bruce W. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jason Hyung-Jong Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers. (arXiv:2301.02998v1 [cs.IR])","link":"http://arxiv.org/abs/2301.02998","description":"<p>We carried out a reproducibility study of InPars recipe for unsupervised\ntraining of neural rankers. As a by-product of this study, we developed a\nsimple-yet-effective modification of InPars, which we called InPars-light.\nUnlike InPars, InPars-light uses only a freely available language model BLOOM\nand 7x-100x smaller ranking models. On all five English retrieval collections\n(used in the original InPars study) we obtained substantial (7-30%) and\nstatistically significant improvements over BM25 in nDCG or MRR using only a\n30M parameter six-layer MiniLM ranker. In contrast, in the InPars study only a\n100x larger MonoT5-3B model consistently outperformed BM25, whereas their\nsmaller MonoT5-220M model (which is still 7x larger than our MiniLM ranker),\noutperformed BM25 only on MS MARCO and TREC DL 2020. In a purely unsupervised\nsetting, our 435M parameter DeBERTA v3 ranker was roughly at par with the 7x\nlarger MonoT5-3B: In fact, on three out of five datasets, it slightly\noutperformed MonoT5-3B. Finally, these good results were achieved by re-ranking\nonly 100 candidate documents compared to 1000 used in InPars. We believe that\nInPars-light is the first truly cost-effective prompt-based unsupervised recipe\nto train and deploy neural ranking models that outperform BM25.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Boytsov_L/0/1/0/all/0/1\">Leonid Boytsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_P/0/1/0/all/0/1\">Preksha Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sourabh_V/0/1/0/all/0/1\">Vivek Sourabh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nisar_R/0/1/0/all/0/1\">Riddhi Nisar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kundu_S/0/1/0/all/0/1\">Sayani Kundu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanathan_R/0/1/0/all/0/1\">Ramya Ramanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nyberg_E/0/1/0/all/0/1\">Eric Nyberg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analyzing the Representational Geometry of Acoustic Word Embeddings. (arXiv:2301.03012v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03012","description":"<p>Acoustic word embeddings (AWEs) are vector representations such that\ndifferent acoustic exemplars of the same word are projected nearby in the\nembedding space. In addition to their use in speech technology applications\nsuch as spoken term discovery and keyword spotting, AWE models have been\nadopted as models of spoken-word processing in several cognitively motivated\nstudies and have been shown to exhibit human-like performance in some auditory\nprocessing tasks. Nevertheless, the representational geometry of AWEs remains\nan under-explored topic that has not been studied in the literature. In this\npaper, we take a closer analytical look at AWEs learned from English speech and\nstudy how the choice of the learning objective and the architecture shapes\ntheir representational profile. To this end, we employ a set of analytic\ntechniques from machine learning and neuroscience in three different analyses:\nembedding space uniformity, word discriminability, and representational\nconsistency. Our main findings highlight the prominent role of the learning\nobjective on shaping the representation profile compared to the model\narchitecture.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abdullah_B/0/1/0/all/0/1\">Badr M. Abdullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klakow_D/0/1/0/all/0/1\">Dietrich Klakow</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Topic Modelling of Swedish Newspaper Articles about Coronavirus: a Case Study using Latent Dirichlet Allocation Method. (arXiv:2301.03029v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03029","description":"<p>Topic Modelling (TM) is from the research branches of natural language\nunderstanding (NLU) and natural language processing (NLP) that is to facilitate\ninsightful analysis from large documents and datasets, such as a summarisation\nof main topics and the topic changes. This kind of discovery is getting more\npopular in real-life applications due to its impact on big data analytics. In\nthis study, from the social-media and healthcare domain, we apply popular\nLatent Dirichlet Allocation (LDA) methods to model the topic changes in Swedish\nnewspaper articles about Coronavirus. We describe the corpus we created\nincluding 6515 articles, methods applied, and statistics on topic changes over\napproximately 1 year and two months period of time from 17th January 2020 to\n13th March 2021. We hope this work can be an asset for grounding applications\nof topic modelling and can be inspiring for similar case studies in an era with\npandemics, to support socio-economic impact research as well as clinical and\nhealthcare analytics. Our data is openly available at https://github.\ncom/poethan/Swed_Covid_TM Keywords: Latent Dirichlet Allocation (LDA); Topic\nModelling; Coronavirus; Pandemics; Natural Language Understanding\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Griciute_B/0/1/0/all/0/1\">Bernadeta Grici&#x16b;t&#x117;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1\">Lifeng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koller_A/0/1/0/all/0/1\">Alexander Koller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nenadic_G/0/1/0/all/0/1\">Goran Nenadic</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The State of Human-centered NLP Technology for Fact-checking. (arXiv:2301.03056v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03056","description":"<p>Misinformation threatens modern society by promoting distrust in science,\nchanging narratives in public health, heightening social polarization, and\ndisrupting democratic elections and financial markets, among a myriad of other\nsocietal harms. To address this, a growing cadre of professional fact-checkers\nand journalists provide high-quality investigations into purported facts.\nHowever, these largely manual efforts have struggled to match the enormous\nscale of the problem. In response, a growing body of Natural Language\nProcessing (NLP) technologies have been proposed for more scalable\nfact-checking. Despite tremendous growth in such research, however, practical\nadoption of NLP technologies for fact-checking still remains in its infancy\ntoday.\n</p>\n<p>In this work, we review the capabilities and limitations of the current NLP\ntechnologies for fact-checking. Our particular focus is to further chart the\ndesign space for how these technologies can be harnessed and refined in order\nto better meet the needs of human fact-checkers. To do so, we review key\naspects of NLP-based fact-checking: task formulation, dataset construction,\nmodeling, and human-centered strategies, such as explainable models and\nhuman-in-the-loop approaches. Next, we review the efficacy of applying\nNLP-based fact-checking tools to assist human fact-checkers. We recommend that\nfuture research include collaboration with fact-checker stakeholders early on\nin NLP research, as well as incorporation of human-centered design practices in\nmodel development, in order to further guide technology development for human\nuse and practical adoption. Finally, we advocate for more research on benchmark\ndevelopment supporting extrinsic evaluation of human-centered fact-checking\ntechnologies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Anubrata Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Houjiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kovatchev_V/0/1/0/all/0/1\">Venelin Kovatchev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lease_M/0/1/0/all/0/1\">Matthew Lease</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MEGAnno: Exploratory Labeling for NLP in Computational Notebooks. (arXiv:2301.03095v1 [cs.HC])","link":"http://arxiv.org/abs/2301.03095","description":"<p>We present MEGAnno, a novel exploratory annotation framework designed for NLP\nresearchers and practitioners. Unlike existing labeling tools that focus on\ndata labeling only, our framework aims to support a broader, iterative ML\nworkflow including data exploration and model development. With MEGAnno's API,\nusers can programmatically explore the data through sophisticated search and\nautomated suggestion functions and incrementally update task schema as their\nproject evolve. Combined with our widget, the users can interactively sort,\nfilter, and assign labels to multiple items simultaneously in the same notebook\nwhere the rest of the NLP project resides. We demonstrate MEGAnno's flexible,\nexploratory, efficient, and seamless labeling experience through a sentiment\nanalysis use case.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hannah Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Rafael Li Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kandogan_E/0/1/0/all/0/1\">Eser Kandogan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hruschka_E/0/1/0/all/0/1\">Estevam Hruschka</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Generation of German Drama Texts Using Fine Tuned GPT-2 Models. (arXiv:2301.03119v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03119","description":"<p>This study is devoted to the automatic generation of German drama texts. We\nsuggest an approach consisting of two key steps: fine-tuning a GPT-2 model (the\noutline model) to generate outlines of scenes based on keywords and fine-tuning\na second model (the generation model) to generate scenes from the scene\noutline. The input for the neural model comprises two datasets: the German\nDrama Corpus (GerDraCor) and German Text Archive (Deutsches Textarchiv or DTA).\nIn order to estimate the effectiveness of the proposed method, our models are\ncompared with baseline GPT-2 models. Our models perform well according to\nautomatic quantitative evaluation, but, conversely, manual qualitative analysis\nreveals a poor quality of generated texts. This may be due to the quality of\nthe dataset or training inputs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bangura_M/0/1/0/all/0/1\">Mariam Bangura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barabashova_K/0/1/0/all/0/1\">Kristina Barabashova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karnysheva_A/0/1/0/all/0/1\">Anna Karnysheva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Semczuk_S/0/1/0/all/0/1\">Sarah Semczuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">YIfan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Logically at Factify 2023: A Multi-Modal Fact Checking System Based on Evidence Retrieval techniques and Transformer Encoder Architecture. (arXiv:2301.03127v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03127","description":"<p>In this paper, we present the Logically submissions to De-Factify 2 challenge\n(DE-FACTIFY 2023) on the task 1 of Multi-Modal Fact Checking. We describes our\nsubmissions to this challenge including explored evidence retrieval and\nselection techniques, pre-trained cross-modal and unimodal models, and a\ncross-modal veracity model based on the well established Transformer Encoder\n(TE) architecture which is heavily relies on the concept of self-attention.\nExploratory analysis is also conducted on this Factify 2 data set that uncovers\nthe salient multi-modal patterns and hypothesis motivating the architecture\nproposed in this work. A series of preliminary experiments were done to\ninvestigate and benchmarking different pre-trained embedding models, evidence\nretrieval settings and thresholds. The final system, a standard two-stage\nevidence based veracity detection system, yields weighted avg. 0.79 on both val\nset and final blind test set on the task 1, which achieves 3rd place with a\nsmall margin to the top performing system on the leaderboard among 9\nparticipants.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Verschuuren_P/0/1/0/all/0/1\">Pim Jordi Verschuuren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jie Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eeden_A/0/1/0/all/0/1\">Adelize van Eeden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oikonomou_S/0/1/0/all/0/1\">Stylianos Oikonomou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bandhakavi_A/0/1/0/all/0/1\">Anil Bandhakavi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Removing Non-Stationary Knowledge From Pre-Trained Language Models for Entity-Level Sentiment Classification in Finance. (arXiv:2301.03136v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03136","description":"<p>Extraction of sentiment signals from news text, stock message boards, and\nbusiness reports, for stock movement prediction, has been a rising field of\ninterest in finance. Building upon past literature, the most recent works\nattempt to better capture sentiment from sentences with complex syntactic\nstructures by introducing aspect-level sentiment classification (ASC). Despite\nthe growing interest, however, fine-grained sentiment analysis has not been\nfully explored in non-English literature due to the shortage of annotated\nfinance-specific data. Accordingly, it is necessary for non-English languages\nto leverage datasets and pre-trained language models (PLM) of different\ndomains, languages, and tasks to best their performance. To facilitate\nfinance-specific ASC research in the Korean language, we build KorFinASC, a\nKorean aspect-level sentiment classification dataset for finance consisting of\n12,613 human-annotated samples, and explore methods of intermediate transfer\nlearning. Our experiments indicate that past research has been ignorant towards\nthe potentially wrong knowledge of financial entities encoded during the\ntraining phase, which has overestimated the predictive power of PLMs. In our\nwork, we use the term \"non-stationary knowledge'' to refer to information that\nwas previously correct but is likely to change, and present \"TGT-Masking'', a\nnovel masking pattern to restrict PLMs from speculating knowledge of the kind.\nFinally, through a series of transfer learning with TGT-Masking applied we\nimprove 22.63% of classification accuracy compared to standalone models on\nKorFinASC.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Son_G/0/1/0/all/0/1\">Guijin Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hanwool Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_N/0/1/0/all/0/1\">Nahyeon Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hahm_M/0/1/0/all/0/1\">Moonjeong Hahm</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Applying Automated Machine Translation to Educational Video Courses. (arXiv:2301.03141v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03141","description":"<p>We studied the capability of automated machine translation in the online\nvideo education space by automatically translating Khan Academy videos with\nstate of the art translation models and applying Text-to-Speech synthesis to\nbuild engaging videos in target languages. We also analyzed and established a\nreliable translation confidence estimator based on round-trip translations in\norder to efficiently manage translation quality and reduce human translation\neffort. Finally, we developed a deployable system to deliver translated videos\nto end users and collect user corrections for iterative improvement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Linden Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Machine Learning Algorithms for Depression Detection and Their Comparison. (arXiv:2301.03222v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03222","description":"<p>Textual emotional intelligence is playing a ubiquitously important role in\nleveraging human emotions on social media platforms. Social media platforms are\nprivileged with emotional content and are leveraged for various purposes like\nopinion mining, emotion mining, and sentiment analysis. This data analysis is\nalso levered for the prevention of online bullying, suicide prevention, and\ndepression detection among social media users. In this article, we have\ndesigned an automatic depression detection of online social media users by\nanalyzing their social media behavior. The designed depression detection\nclassification can be effectively used to mine user's social media interactions\nand one can determine whether a social media user is suffering from depression\nor not. The underlying classifier is made using state-of-art technology in\nemotional artificial intelligence which includes LSTM (Long Short Term Memory)\nand other machine learning classifiers. The highest accuracy of the classifier\nis around 70% of LSTM and for SVM the highest accuracy is 81.79%. We trained\nthe classifier on the datasets that are widely used in literature for emotion\nmining tasks. A confusion matrix of results is also given.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Muzafar_D/0/1/0/all/0/1\">Danish Muzafar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Furqan Yaqub Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qayoom_M/0/1/0/all/0/1\">Mubashir Qayoom</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Online Fake Review Detection Using Supervised Machine Learning And BERT Model. (arXiv:2301.03225v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03225","description":"<p>Online shopping stores have grown steadily over the past few years. Due to\nthe massive growth of these businesses, the detection of fake reviews has\nattracted attention. Fake reviews are seriously trying to mislead customers and\nthereby undermine the honesty and authenticity of online shopping environments.\nSo far, various fake review classifiers have been proposed that take into\naccount the actual content of the review. To improve the accuracies of existing\nfake review classification or detection approaches, we propose to use BERT\n(Bidirectional Encoder Representation from Transformers) model to extract word\nembeddings from texts (i.e. reviews). Word embeddings are obtained in various\nbasic methods such as SVM (Support vector machine), Random Forests, Naive\nBayes, and others. The confusion matrix method was also taken into account to\nevaluate and graphically represent the results. The results indicate that the\nSVM classifiers outperform the others in terms of accuracy and f1-score with an\naccuracy of 87.81%, which is 7.6% higher than the classifier used in the\nprevious study [5].\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mir_A/0/1/0/all/0/1\">Abrar Qadir Mir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Furqan Yaqub Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chishti_M/0/1/0/all/0/1\">Mohammad Ahsan Chishti</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MAQA: A Multimodal QA Benchmark for Negation. (arXiv:2301.03238v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03238","description":"<p>Multimodal learning can benefit from the representation power of pretrained\nLarge Language Models (LLMs). However, state-of-the-art transformer based LLMs\noften ignore negations in natural language and there is no existing benchmark\nto quantitatively evaluate whether multimodal transformers inherit this\nweakness. In this study, we present a new multimodal question answering (QA)\nbenchmark adapted from labeled music videos in AudioSet (Gemmeke et al., 2017)\nwith the goal of systematically evaluating if multimodal transformers can\nperform complex reasoning to recognize new concepts as negation of previously\nlearned concepts. We show that with standard fine-tuning approach multimodal\ntransformers are still incapable of correctly interpreting negation\nirrespective of model size. However, our experiments demonstrate that\naugmenting the original training task distributions with negated QA examples\nallow the model to reliably reason with negation. To do this, we describe a\nnovel data generation procedure that prompts the 540B-parameter PaLM model to\nautomatically generate negated QA examples as compositions of easily accessible\nvideo tags. The generated examples contain more natural linguistic patterns and\nthe gains compared to template-based task augmentation approach are\nsignificant.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Judith Yue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jansen_A/0/1/0/all/0/1\">Aren Jansen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qingqing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Joonseok Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganti_R/0/1/0/all/0/1\">Ravi Ganti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuzmin_D/0/1/0/all/0/1\">Dima Kuzmin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Active Learning for Abstractive Text Summarization. (arXiv:2301.03252v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03252","description":"<p>Construction of human-curated annotated datasets for abstractive text\nsummarization (ATS) is very time-consuming and expensive because creating each\ninstance requires a human annotator to read a long document and compose a\nshorter summary that would preserve the key information relayed by the original\ndocument. Active Learning (AL) is a technique developed to reduce the amount of\nannotation required to achieve a certain level of machine learning model\nperformance. In information extraction and text classification, AL can reduce\nthe amount of labor up to multiple times. Despite its potential for aiding\nexpensive annotation, as far as we know, there were no effective AL query\nstrategies for ATS. This stems from the fact that many AL strategies rely on\nuncertainty estimation, while as we show in our work, uncertain instances are\nusually noisy, and selecting them can degrade the model performance compared to\npassive annotation. We address this problem by proposing the first effective\nquery strategy for AL in ATS based on diversity principles. We show that given\na certain annotation budget, using our strategy in AL annotation helps to\nimprove the model performance in terms of ROUGE and consistency scores.\nAdditionally, we analyze the effect of self-learning and show that it can\nfurther increase the performance of the model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tsvigun_A/0/1/0/all/0/1\">Akim Tsvigun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lysenko_I/0/1/0/all/0/1\">Ivan Lysenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sedashov_D/0/1/0/all/0/1\">Danila Sedashov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lazichny_I/0/1/0/all/0/1\">Ivan Lazichny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damirov_E/0/1/0/all/0/1\">Eldar Damirov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlov_V/0/1/0/all/0/1\">Vladimir Karlov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belousov_A/0/1/0/all/0/1\">Artemy Belousov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanochkin_L/0/1/0/all/0/1\">Leonid Sanochkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panov_M/0/1/0/all/0/1\">Maxim Panov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panchenko_A/0/1/0/all/0/1\">Alexander Panchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burtsev_M/0/1/0/all/0/1\">Mikhail Burtsev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shelmanov_A/0/1/0/all/0/1\">Artem Shelmanov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Universal Information Extraction as Unified Semantic Matching. (arXiv:2301.03282v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03282","description":"<p>The challenge of information extraction (IE) lies in the diversity of label\nschemas and the heterogeneity of structures. Traditional methods require\ntask-specific model design and rely heavily on expensive supervision, making\nthem difficult to generalize to new schemas. In this paper, we decouple IE into\ntwo basic abilities, structuring and conceptualizing, which are shared by\ndifferent tasks and schemas. Based on this paradigm, we propose to universally\nmodel various IE tasks with Unified Semantic Matching (USM) framework, which\nintroduces three unified token linking operations to model the abilities of\nstructuring and conceptualizing. In this way, USM can jointly encode schema and\ninput text, uniformly extract substructures in parallel, and controllably\ndecode target structures on demand. Empirical evaluation on 4 IE tasks shows\nthat the proposed method achieves state-of-the-art performance under the\nsupervised experiments and shows strong generalization ability in zero/few-shot\ntransfer settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1\">Jie Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yaojie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Dai Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_W/0/1/0/all/0/1\">Wei Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongyu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xianpei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Le Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FullStop:Punctuation and Segmentation Prediction for Dutch with Transformers. (arXiv:2301.03319v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03319","description":"<p>When applying automated speech recognition (ASR) for Belgian Dutch (Van Dyck\net al. 2021), the output consists of an unsegmented stream of words, without\nany punctuation. A next step is to perform segmentation and insert punctuation,\nmaking the ASR output more readable and easy to manually correct. As far as we\nknow there is no publicly available punctuation insertion system for Dutch that\nfunctions at a usable level. The model we present here is an extension of the\nmodels of Guhr et al. (2021) for Dutch and is made publicly available. We\ntrained a sequence classification model, based on the Dutch language model\nRobBERT (Delobelle et al. 2020). For every word in the input sequence, the\nmodels predicts a punctuation marker that follows the word. We have also\nextended a multilingual model, for cases where the language is unknown or where\ncode switching applies. When performing the task of segmentation, the\napplication of the best models onto out of domain test data, a sliding window\nof 200 words of the ASR output stream is sent to the classifier, and\nsegmentation is applied when the system predicts a segmenting punctuation sign\nwith a ratio above threshold. Results show to be much better than a machine\ntranslation baseline approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vandeghinste_V/0/1/0/all/0/1\">Vincent Vandeghinste</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guhr_O/0/1/0/all/0/1\">Oliver Guhr</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Universal Multimodal Representation for Language Understanding. (arXiv:2301.03344v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03344","description":"<p>Representation learning is the foundation of natural language processing\n(NLP). This work presents new methods to employ visual information as assistant\nsignals to general NLP tasks. For each sentence, we first retrieve a flexible\nnumber of images either from a light topic-image lookup table extracted over\nthe existing sentence-image pairs or a shared cross-modal embedding space that\nis pre-trained on out-of-shelf text-image pairs. Then, the text and images are\nencoded by a Transformer encoder and convolutional neural network,\nrespectively. The two sequences of representations are further fused by an\nattention layer for the interaction of the two modalities. In this study, the\nretrieval process is controllable and flexible. The universal visual\nrepresentation overcomes the lack of large-scale bilingual sentence-image\npairs. Our method can be easily applied to text-only tasks without manually\nannotated multimodal parallel corpora. We apply the proposed method to a wide\nrange of natural language generation and understanding tasks, including neural\nmachine translation, natural language inference, and semantic similarity.\nExperimental results show that our method is generally effective for different\ntasks and languages. Analysis indicates that the visual signals enrich textual\nrepresentations of content words, provide fine-grained grounding information\nabout the relationship between concepts and events, and potentially conduce to\ndisambiguation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kehai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Utiyama_M/0/1/0/all/0/1\">Masao Utiyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sumita_E/0/1/0/all/0/1\">Eiichiro Sumita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zuchao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Bidirectional Action-Language Translation with Limited Supervision and Incongruent Extra Input. (arXiv:2301.03353v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03353","description":"<p>Human infant learning happens during exploration of the environment, by\ninteraction with objects, and by listening to and repeating utterances\ncasually, which is analogous to unsupervised learning. Only occasionally, a\nlearning infant would receive a matching verbal description of an action it is\ncommitting, which is similar to supervised learning. Such a learning mechanism\ncan be mimicked with deep learning. We model this weakly supervised learning\nparadigm using our Paired Gated Autoencoders (PGAE) model, which combines an\naction and a language autoencoder. After observing a performance drop when\nreducing the proportion of supervised training, we introduce the Paired\nTransformed Autoencoders (PTAE) model, using Transformer-based crossmodal\nattention. PTAE achieves significantly higher accuracy in language-to-action\nand action-to-language translations, particularly in realistic but difficult\ncases when only few supervised training samples are available. We also test\nwhether the trained model behaves realistically with conflicting multimodal\ninput. In accordance with the concept of incongruence in psychology, conflict\ndeteriorates the model output. Conflicting action input has a more severe\nimpact than conflicting language input, and more conflicting features lead to\nlarger interference. PTAE can be trained on mostly unlabelled data where\nlabeled data is scarce, and it behaves plausibly when tested with incongruent\ninput.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ozdemir_O/0/1/0/all/0/1\">Ozan &#xd6;zdemir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerzel_M/0/1/0/all/0/1\">Matthias Kerzel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_C/0/1/0/all/0/1\">Cornelius Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jae Hee Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hafez_M/0/1/0/all/0/1\">Muhammad Burhan Hafez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruns_P/0/1/0/all/0/1\">Patrick Bruns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1\">Stefan Wermter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chatbots As Fluent Polyglots: Revisiting Breakthrough Code Snippets. (arXiv:2301.03373v1 [cs.LG])","link":"http://arxiv.org/abs/2301.03373","description":"<p>The research applies AI-driven code assistants to analyze a selection of\ninfluential computer code that has shaped modern technology, including email,\ninternet browsing, robotics, and malicious software. The original contribution\nof this study was to examine half of the most significant code advances in the\nlast 50 years and, in some cases, to provide notable improvements in clarity or\nperformance. The AI-driven code assistant could provide insights into\nobfuscated code or software lacking explanatory commentary in all cases\nexamined. We generated additional sample problems based on bug corrections and\ncode optimizations requiring much deeper reasoning than a traditional Google\nsearch might provide. Future work focuses on adding automated documentation and\ncode commentary and translating select large code bases into more modern\nversions with multiple new application programming interfaces (APIs) and\nchained multi-tasks. The AI-driven code assistant offers a valuable tool for\nsoftware engineering, particularly in its ability to provide human-level\nexpertise and assist in refactoring legacy code or simplifying the explanation\nor functionality of high-value repositories.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Noever_D/0/1/0/all/0/1\">David Noever</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_K/0/1/0/all/0/1\">Kevin Williams</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AI2: The next leap toward native language based and explainable machine learning framework. (arXiv:2301.03391v1 [cs.LG])","link":"http://arxiv.org/abs/2301.03391","description":"<p>The machine learning frameworks flourished in the last decades, allowing\nartificial intelligence to get out of academic circles to be applied to\nenterprise domains. This field has significantly advanced, but there is still\nsome meaningful improvement to reach the subsequent expectations. The proposed\nframework, named AI$^{2}$, uses a natural language interface that allows a\nnon-specialist to benefit from machine learning algorithms without necessarily\nknowing how to program with a programming language. The primary contribution of\nthe AI$^{2}$ framework allows a user to call the machine learning algorithms in\nEnglish, making its interface usage easier. The second contribution is\ngreenhouse gas (GHG) awareness. It has some strategies to evaluate the GHG\ngenerated by the algorithm to be called and to propose alternatives to find a\nsolution without executing the energy-intensive algorithm. Another contribution\nis a preprocessing module that helps to describe and to load data properly.\nUsing an English text-based chatbot, this module guides the user to define\nevery dataset so that it can be described, normalized, loaded and divided\nappropriately. The last contribution of this paper is about explainability. For\ndecades, the scientific community has known that machine learning algorithms\nimply the famous black-box problem. Traditional machine learning methods\nconvert an input into an output without being able to justify this result. The\nproposed framework explains the algorithm's process with the proper texts,\ngraphics and tables. The results, declined in five cases, present usage\napplications from the user's English command to the explained output.\nUltimately, the AI$^{2}$ framework represents the next leap toward native\nlanguage-based, human-oriented concerns about machine learning framework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dessureault_J/0/1/0/all/0/1\">Jean-S&#xe9;bastien Dessureault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Massicotte_D/0/1/0/all/0/1\">Daniel Massicotte</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A comprehensive review of automatic text summarization techniques: method, data, evaluation and coding. (arXiv:2301.03403v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03403","description":"<p>We provide a literature review about Automatic Text Summarization (ATS)\nsystems. We consider a citation-based approach. We start with some popular and\nwell-known papers that we have in hand about each topic we want to cover and we\nhave tracked the \"backward citations\" (papers that are cited by the set of\npapers we knew beforehand) and the \"forward citations\" (newer papers that cite\nthe set of papers we knew beforehand). In order to organize the different\nmethods, we present the diverse approaches to ATS guided by the mechanisms they\nuse to generate a summary. Besides presenting the methods, we also present an\nextensive review of the datasets available for summarization tasks and the\nmethods used to evaluate the quality of the summaries. Finally, we present an\nempirical exploration of these methods using the CNN Corpus dataset that\nprovides golden summaries for extractive and abstractive methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cajueiro_D/0/1/0/all/0/1\">Daniel O. Cajueiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nery_A/0/1/0/all/0/1\">Arthur G. Nery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tavares_I/0/1/0/all/0/1\">Igor Tavares</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melo_M/0/1/0/all/0/1\">Ma&#xed;sa K. De Melo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reis_S/0/1/0/all/0/1\">Silvia A. dos Reis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weigang_L/0/1/0/all/0/1\">Li Weigang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celestino_V/0/1/0/all/0/1\">Victor R. R. Celestino</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ERNIE 3.0 Tiny: Frustratingly Simple Method to Improve Task-Agnostic Distillation Generalization. (arXiv:2301.03416v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03416","description":"<p>Task-agnostic knowledge distillation attempts to address the problem of\ndeploying large pretrained language model in resource-constrained scenarios by\ncompressing a large pretrained model called teacher into a smaller one called\nstudent such that the student can be directly finetuned on downstream tasks and\nretains comparable performance. However, we empirically find that there is a\ngeneralization gap between the student and the teacher in existing methods. In\nthis work, we show that we can leverage multi-task learning in task-agnostic\ndistillation to advance the generalization of the resulted student. In\nparticular, we propose Multi-task Infused Task-agnostic Knowledge Distillation\n(MITKD). We first enhance the teacher by multi-task training it on multiple\ndownstream tasks and then perform distillation to produce the student.\nExperimental results demonstrate that our method yields a student with much\nbetter generalization, significantly outperforms existing baselines, and\nestablishes a new state-of-the-art result on in-domain, out-domain, and\nlow-resource datasets in the setting of task-agnostic distillation. Moreover,\nour method even exceeds an 8x larger BERT$_{\\text{Base}}$ on SQuAD and four\nGLUE tasks. In addition, by combining ERNIE 3.0, our method achieves\nstate-of-the-art results on 10 Chinese datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weixin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiaxiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shikun Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_H/0/1/0/all/0/1\">Hao Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Standardization of Arabic Dialects for Machine Translation. (arXiv:2301.03447v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03447","description":"<p>Based on an annotated multimedia corpus, television series Mar{\\=a}y{\\=a}\n2013, we dig into the question of ''automatic standardization'' of Arabic\ndialects for machine translation. Here we distinguish between rule-based\nmachine translation and statistical machine translation. Machine translation\nfrom Arabic most of the time takes standard or modern Arabic as the source\nlanguage and produces quite satisfactory translations thanks to the\navailability of the translation memories necessary for training the models. The\ncase is different for the translation of Arabic dialects. The productions are\nmuch less efficient. In our research we try to apply machine translation\nmethods to a dialect/standard (or modern) Arabic pair to automatically produce\na standard Arabic text from a dialect input, a process we call ''automatic\nstandardization''. we opt here for the application of ''statistical models''\nbecause ''automatic standardization'' based on rules is more hard with the lack\nof ''diglossic'' dictionaries on the one hand and the difficulty of creating\nlinguistic rules for each dialect on the other. Carrying out this research\ncould then lead to combining ''automatic standardization'' software and\nautomatic translation software so that we take the output of the first software\nand introduce it as input into the second one to obtain at the end a quality\nmachine translation. This approach may also have educational applications such\nas the development of applications to help understand different Arabic dialects\nby transforming dialectal texts into standard Arabic.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alnassan_A/0/1/0/all/0/1\">Abidrabbo Alnassan</a> (CEL, ILCEA4, UJML3 Langues)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mining Healthcare Procurement Data Using Text Mining and Natural Language Processing -- Reflection From An Industrial Project. (arXiv:2301.03458v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03458","description":"<p>While text mining and NLP research has been established for decades, there\nremain gaps in the literature that reports the use of these techniques in\nbuilding real-world applications. For example, they typically look at single\nand sometimes simplified tasks, and do not discuss in-depth data heterogeneity\nand inconsistency that is common in real-world problems or their implication on\nthe development of their methods. Also, few prior work has focused on the\nhealthcare domain. In this work, we describe an industry project that developed\ntext mining and NLP solutions to mine millions of heterogeneous, multilingual\nprocurement documents in the healthcare sector. We extract structured\nprocurement contract data that is used to power a platform for dynamically\nassessing supplier risks. Our work makes unique contributions in a number of\nways. First, we deal with highly heterogeneous, multilingual data and we\ndocument our approach to tackle these challenges. This is mainly based on a\nmethod that effectively uses domain knowledge and generalises to multiple text\nmining and NLP tasks and languages. Second, applying this method to mine\nmillions of procurement documents, we develop the first structured procurement\ncontract database that will help facilitate the tendering process. Second,\nFinally, we discuss lessons learned for practical text mining/NLP development,\nand make recommendations for future research and practice.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jasaitis_T/0/1/0/all/0/1\">Tomas Jasaitis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freeman_R/0/1/0/all/0/1\">Richard Freeman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alfrjani_R/0/1/0/all/0/1\">Rowida Alfrjani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Funk_A/0/1/0/all/0/1\">Adam Funk</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging Contextual Relatedness to Identify Suicide Documentation in Clinical Notes through Zero Shot Learning. (arXiv:2301.03531v1 [cs.AI])","link":"http://arxiv.org/abs/2301.03531","description":"<p>Identifying suicidality including suicidal ideation, attempts, and risk\nfactors in electronic health record data in clinical notes is difficult. A\nmajor difficulty is the lack of training samples given the small number of true\npositive instances among the increasingly large number of patients being\nscreened. This paper describes a novel methodology that identifies suicidality\nin clinical notes by addressing this data sparsity issue through zero-shot\nlearning. U.S. Veterans Affairs clinical notes served as data. The training\ndataset label was determined using diagnostic codes of suicide attempt and\nself-harm. A base string associated with the target label of suicidality was\nused to provide auxiliary information by narrowing the positive training cases\nto those containing the base string. A deep neural network was trained by\nmapping the training documents contents to a semantic space. For comparison, we\ntrained another deep neural network using the identical training dataset labels\nand bag-of-words features. The zero shot learning model outperformed the\nbaseline model in terms of AUC, sensitivity, specificity, and positive\npredictive value at multiple probability thresholds. In applying a 0.90\nprobability threshold, the methodology identified notes not associated with a\nrelevant ICD 10 CM code that documented suicidality, with 94 percent accuracy.\nThis new method can effectively identify suicidality without requiring manual\nannotation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Workman_T/0/1/0/all/0/1\">Terri Elizabeth Workman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goulet_J/0/1/0/all/0/1\">Joseph L. Goulet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brandt_C/0/1/0/all/0/1\">Cynthia A. Brandt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warren_A/0/1/0/all/0/1\">Allison R. Warren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eleazer_J/0/1/0/all/0/1\">Jacob Eleazer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skanderson_M/0/1/0/all/0/1\">Melissa Skanderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindemann_L/0/1/0/all/0/1\">Luke Lindemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blosnich_J/0/1/0/all/0/1\">John R. Blosnich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leary_J/0/1/0/all/0/1\">John O Leary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Treitler_Q/0/1/0/all/0/1\">Qing Zeng Treitler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Color Me Intrigued: Quantifying Usage of Colors in Fiction. (arXiv:2301.03559v1 [cs.CL])","link":"http://arxiv.org/abs/2301.03559","description":"<p>We present preliminary results in quantitative analyses of color usage in\nselected authors' works from LitBank. Using Glasgow Norms, human ratings on\n5000+ words, we measure attributes of nouns dependent on color terms. Early\nresults demonstrate a significant increase in noun concreteness over time. We\nalso propose future research directions for computational literary color\nanalytics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Siyan Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Converse Attention Knowledge Transfer for Low-Resource Named Entity Recognition. (arXiv:1906.01183v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/1906.01183","description":"<p>In recent years, great success has been achieved in many tasks of natural\nlanguage processing (NLP), e.g., named entity recognition (NER), especially in\nthe high-resource language, i.e., English, thanks in part to the considerable\namount of labeled resources. However, most low-resource languages do not have\nsuch an abundance of labeled data as high-resource English, leading to poor\nperformance of NER in these low-resource languages. Inspired by knowledge\ntransfer, we propose Converse Attention Network, or CAN in short, to improve\nthe performance of NER in low-resource languages by leveraging the knowledge\nlearned in pretrained high-resource English models. CAN first translates\nlow-resource languages into high-resource English using an attention based\ntranslation module. In the process of translation, CAN obtain the attention\nmatrices that align the two languages. Furthermore, CAN use the attention\nmatrices to align the high-resource semantic features from a pretrained\nhigh-resource English model with the low-resource semantic features. As a\nresult, CAN obtains aligned high-resource semantic features to enrich the\nrepresentations of low-resource languages. Experiments on four low-resource NER\ndatasets show that CAN achieves consistent and significant performance\nimprovements, which indicates the effectiveness of CAN.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1\">Shengfei Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Linghao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_H/0/1/0/all/0/1\">Huixiong Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huanhuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Video2Commonsense: Generating Commonsense Descriptions to Enrich Video Captioning. (arXiv:2003.05162v4 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2003.05162","description":"<p>Captioning is a crucial and challenging task for video understanding. In\nvideos that involve active agents such as humans, the agent's actions can bring\nabout myriad changes in the scene. Observable changes such as movements,\nmanipulations, and transformations of the objects in the scene, are reflected\nin conventional video captioning. Unlike images, actions in videos are also\ninherently linked to social aspects such as intentions (why the action is\ntaking place), effects (what changes due to the action), and attributes that\ndescribe the agent. Thus for video understanding, such as when captioning\nvideos or when answering questions about videos, one must have an understanding\nof these commonsense aspects. We present the first work on generating\ncommonsense captions directly from videos, to describe latent aspects such as\nintentions, effects, and attributes. We present a new dataset\n\"Video-to-Commonsense (V2C)\" that contains $\\sim9k$ videos of human agents\nperforming various actions, annotated with 3 types of commonsense descriptions.\nAdditionally we explore the use of open-ended video-based commonsense question\nanswering (V2C-QA) as a way to enrich our captions. Both the generation task\nand the QA task can be used to enrich video captions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1\">Zhiyuan Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokhale_T/0/1/0/all/0/1\">Tejas Gokhale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_P/0/1/0/all/0/1\">Pratyay Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1\">Chitta Baral</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yezhou Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InsertGNN: Can Graph Neural Networks Outperform Humans in TOEFL Sentence Insertion Problem?. (arXiv:2103.15066v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.15066","description":"<p>Sentence insertion is an interesting NLP problem but received insufficient\nattention. Existing approaches in sentence ordering, text coherence, and\nquestion answering are neither suitable nor good enough at solving it. To\nbridge this gap, we propose InsertGNN, a simple yet effective model that\nrepresents the problem as a graph and adopts a hierarchical graph neural\nnetwork (GNN) to learn the connection between sentences. We evaluate our method\nin our newly collected TOEFL dataset and further verify its effectiveness on\nthe larger arXiv dataset using cross-domain learning. Extensive experiments\ndemonstrate that InsertGNN outperforms all baselines by a large margin with an\naccuracy of 70\\%, rivaling the average human test scores.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Stan Z. Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Guiding Generative Language Models for Data Augmentation in Few-Shot Text Classification. (arXiv:2111.09064v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2111.09064","description":"<p>Data augmentation techniques are widely used for enhancing the performance of\nmachine learning models by tackling class imbalance issues and data sparsity.\nState-of-the-art generative language models have been shown to provide\nsignificant gains across different NLP tasks. However, their applicability to\ndata augmentation for text classification tasks in few-shot settings have not\nbeen fully explored, especially for specialised domains. In this paper, we\nleverage GPT-2 (Radford A et al, 2019) for generating artificial training\ninstances in order to improve classification performance. Our aim is to analyse\nthe impact the selection process of seed training examples have over the\nquality of GPT-generated samples and consequently the classifier performance.\nWe perform experiments with several seed selection strategies that, among\nothers, exploit class hierarchical structures and domain expert selection. Our\nresults show that fine-tuning GPT-2 in a handful of label instances leads to\nconsistent classification improvements and outperform competitive baselines.\nFinally, we show that guiding this process through domain expert selection can\nlead to further improvements, which opens up interesting research avenues for\ncombining generative models and active learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Edwards_A/0/1/0/all/0/1\">Aleksandra Edwards</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ushio_A/0/1/0/all/0/1\">Asahi Ushio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camacho_Collados_J/0/1/0/all/0/1\">Jose Camacho-Collados</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribaupierre_H/0/1/0/all/0/1\">H&#xe9;l&#xe8;ne de Ribaupierre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preece_A/0/1/0/all/0/1\">Alun Preece</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"$\\mathcal{Y}$-Tuning: An Efficient Tuning Paradigm for Large-Scale Pre-Trained Models via Label Representation Learning. (arXiv:2202.09817v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2202.09817","description":"<p>With the success of large-scale pre-trained models (PTMs), how efficiently\nadapting PTMs to downstream tasks has attracted tremendous attention,\nespecially for PTMs with billions of parameters. Although some\nparameter-efficient tuning paradigms have been proposed to address this\nproblem, they still require large resources to compute the gradients in the\ntraining phase. In this paper, we propose $\\mathcal{Y}$-Tuning, an efficient\nyet effective paradigm to adapt frozen large-scale PTMs to specific downstream\ntasks. $\\mathcal{Y}$-tuning learns dense representations for labels\n$\\mathcal{Y}$ defined in a given task and aligns them to fixed feature\nrepresentation. Without tuning the features of input text and model parameters,\n$\\mathcal{Y}$-tuning is both parameter-efficient and training-efficient. For\n$\\text{DeBERTa}_\\text{XXL}$ with 1.6 billion parameters, $\\mathcal{Y}$-tuning\nachieves performance more than $96\\%$ of full fine-tuning on GLUE Benchmark\nwith only $2\\%$ tunable parameters and much fewer training costs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yitao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_C/0/1/0/all/0/1\">Chenxin An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Word Segmentation on Discovered Phone Units with Dynamic Programming and Self-Supervised Scoring. (arXiv:2202.11929v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2202.11929","description":"<p>Recent work on unsupervised speech segmentation has used self-supervised\nmodels with phone and word segmentation modules that are trained jointly. This\npaper instead revisits an older approach to word segmentation: bottom-up\nphone-like unit discovery is performed first, and symbolic word segmentation is\nthen performed on top of the discovered units (without influencing the lower\nlevel). To do this, I propose a new unit discovery model, a new symbolic word\nsegmentation model, and then chain the two models to segment speech. Both\nmodels use dynamic programming to minimize segment costs from a self-supervised\nnetwork with an additional duration penalty that encourages longer units.\nConcretely, for acoustic unit discovery, duration-penalized dynamic programming\n(DPDP) is used with a contrastive predictive coding model as the scoring\nnetwork. For word segmentation, DPDP is applied with an autoencoding recurrent\nneural as the scoring network. The two models are chained in order to segment\nspeech. This approach gives comparable word segmentation results to\nstate-of-the-art joint self-supervised segmentation models on an English\nbenchmark. On French, Mandarin, German and Wolof data, it outperforms previous\nsystems on the ZeroSpeech benchmarks. Analysis shows that the chained DPDP\nsystem segments shorter filler words well, but longer words might require some\nexternal top-down signal.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kamper_H/0/1/0/all/0/1\">Herman Kamper</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CL-XABSA: Contrastive Learning for Cross-lingual Aspect-based Sentiment Analysis. (arXiv:2204.00791v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.00791","description":"<p>As an extensive research in the field of natural language processing (NLP),\naspect-based sentiment analysis (ABSA) is the task of predicting the sentiment\nexpressed in a text relative to the corresponding aspect. Unfortunately, most\nlanguages lack sufficient annotation resources, thus more and more recent\nresearchers focus on cross-lingual aspect-based sentiment analysis (XABSA).\nHowever, most recent researches only concentrate on cross-lingual data\nalignment instead of model alignment. To this end, we propose a novel\nframework, CL-XABSA: Contrastive Learning for Cross-lingual Aspect-Based\nSentiment Analysis. Based on contrastive learning, we close the distance\nbetween samples with the same label in different semantic spaces, thus\nachieving a convergence of semantic spaces of different languages.\nSpecifically, we design two contrastive strategies, token level contrastive\nlearning of token embeddings (TL-CTE) and sentiment level contrastive learning\nof token embeddings (SL-CTE), to regularize the semantic space of source and\ntarget language to be more uniform. Since our framework can receive datasets in\nmultiple languages during training, our framework can be adapted not only for\nXABSA task but also for multilingual aspect-based sentiment analysis (MABSA).\nTo further improve the performance of our model, we perform knowledge\ndistillation technology leveraging data from unlabeled target language. In the\ndistillation XABSA task, we further explore the comparative effectiveness of\ndifferent data (source dataset, translated dataset, and code-switched dataset).\nThe results demonstrate that the proposed method has a certain improvement in\nthe three tasks of XABSA, distillation XABSA and MABSA. For reproducibility,\nour code for this paper is available at https://github.com/GKLMIP/CL-XABSA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_N/0/1/0/all/0/1\">Nankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yingwen Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xiaotian Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1\">Aimin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shengyi Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Hierarchical N-Gram Framework for Zero-Shot Link Prediction. (arXiv:2204.10293v6 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.10293","description":"<p>Due to the incompleteness of knowledge graphs (KGs), zero-shot link\nprediction (ZSLP) which aims to predict unobserved relations in KGs has\nattracted recent interest from researchers. A common solution is to use textual\nfeatures of relations (e.g., surface name or textual descriptions) as auxiliary\ninformation to bridge the gap between seen and unseen relations. Current\napproaches learn an embedding for each word token in the text. These methods\nlack robustness as they suffer from the out-of-vocabulary (OOV) problem.\nMeanwhile, models built on character n-grams have the capability of generating\nexpressive representations for OOV words. Thus, in this paper, we propose a\nHierarchical N-Gram framework for Zero-Shot Link Prediction (HNZSLP), which\nconsiders the dependencies among character n-grams of the relation surface name\nfor ZSLP. Our approach works by first constructing a hierarchical n-gram graph\non the surface name to model the organizational structure of n-grams that leads\nto the surface name. A GramTransformer, based on the Transformer is then\npresented to model the hierarchical n-gram graph to construct the relation\nembedding for ZSLP. Experimental results show the proposed HNZSLP achieved\nstate-of-the-art performance on two ZSLP datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingchen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junfan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mensah_S/0/1/0/all/0/1\">Samuel Mensah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiulong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yang Ye</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Foundation Models Help Us Achieve Perfect Secrecy?. (arXiv:2205.13722v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2205.13722","description":"<p>A key promise of machine learning is the ability to assist users with\npersonal tasks. Because the personal context required to make accurate\npredictions is often sensitive, we require systems that protect privacy. A gold\nstandard privacy-preserving system will satisfy perfect secrecy, meaning that\ninteractions with the system provably reveal no private information. However,\nprivacy and quality appear to be in tension in existing systems for personal\ntasks. Neural models typically require copious amounts of training to perform\nwell, while individual users typically hold a limited scale of data, so\nfederated learning (FL) systems propose to learn from the aggregate data of\nmultiple users. FL does not provide perfect secrecy, but rather practitioners\napply statistical notions of privacy -- i.e., the probability of learning\nprivate information about a user should be reasonably low. The strength of the\nprivacy guarantee is governed by privacy parameters. Numerous privacy attacks\nhave been demonstrated on FL systems and it can be challenging to reason about\nthe appropriate privacy parameters for a privacy-sensitive use case. Therefore\nour work proposes a simple baseline for FL, which both provides the stronger\nperfect secrecy guarantee and does not require setting any privacy parameters.\nWe initiate the study of when and where an emerging tool in ML -- the\nin-context learning abilities of recent pretrained models -- can be an\neffective baseline alongside FL. We find in-context learning is competitive\nwith strong FL baselines on 6 of 7 popular benchmarks from the privacy\nliterature and a real-world case study, which is disjoint from the pretraining\ndata. We release our code here: https://github.com/simran-arora/focus\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1\">Simran Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1\">Christopher R&#xe9;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"State-of-the-art generalisation research in NLP: A taxonomy and review. (arXiv:2210.03050v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.03050","description":"<p>The ability to generalise well is one of the primary desiderata of natural\nlanguage processing (NLP). Yet, what 'good generalisation' entails and how it\nshould be evaluated is not well understood, nor are there any evaluation\nstandards for generalisation. In this paper, we lay the groundwork to address\nboth of these issues. We present a taxonomy for characterising and\nunderstanding generalisation research in NLP. Our taxonomy is based on an\nextensive literature review of generalisation research, and contains five axes\nalong which studies can differ: their main motivation, the type of\ngeneralisation they investigate, the type of data shift they consider, the\nsource of this data shift, and the locus of the shift within the modelling\npipeline. We use our taxonomy to classify over 400 papers that test\ngeneralisation, for a total of more than 600 individual experiments.\nConsidering the results of this review, we present an in-depth analysis that\nmaps out the current state of generalisation research in NLP, and we make\nrecommendations for which areas might deserve attention in the future. Along\nwith this paper, we release a webpage where the results of our review can be\ndynamically explored, and which we intend to update as new NLP generalisation\nstudies are published. With this work, we aim to take steps towards making\nstate-of-the-art generalisation testing the new status quo in NLP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1\">Dieuwke Hupkes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giulianelli_M/0/1/0/all/0/1\">Mario Giulianelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dankers_V/0/1/0/all/0/1\">Verna Dankers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1\">Mikel Artetxe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elazar_Y/0/1/0/all/0/1\">Yanai Elazar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1\">Tiago Pimentel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christodoulopoulos_C/0/1/0/all/0/1\">Christos Christodoulopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lasri_K/0/1/0/all/0/1\">Karim Lasri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saphra_N/0/1/0/all/0/1\">Naomi Saphra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinclair_A/0/1/0/all/0/1\">Arabella Sinclair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ulmer_D/0/1/0/all/0/1\">Dennis Ulmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schottmann_F/0/1/0/all/0/1\">Florian Schottmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batsuren_K/0/1/0/all/0/1\">Khuyagbaatar Batsuren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1\">Kaiser Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_K/0/1/0/all/0/1\">Koustuv Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalatbari_L/0/1/0/all/0/1\">Leila Khalatbari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryskina_M/0/1/0/all/0/1\">Maria Ryskina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frieske_R/0/1/0/all/0/1\">Rita Frieske</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhijing Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieving Users' Opinions on Social Media with Multimodal Aspect-Based Sentiment Analysis. (arXiv:2210.15377v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2210.15377","description":"<p>People post their opinions and experiences on social media, yielding rich\ndatabases of end-users' sentiments. This paper shows to what extent machine\nlearning can analyze and structure these databases. An automated data analysis\npipeline is deployed to provide insights into user-generated content for\nresearchers in other domains. First, the domain expert can select an image and\na term of interest. Then, the pipeline uses image retrieval to find all images\nshowing similar content and applies aspect-based sentiment analysis to outline\nusers' opinions about the selected term. As part of an interdisciplinary\nproject between architecture and computer science researchers, an empirical\nstudy of Hamburg's Elbphilharmonie was conveyed. Therefore, we selected 300\nthousand posts with the hashtag \\enquote{\\texttt{hamburg}} from the platform\nFlickr. Image retrieval methods generated a subset of slightly more than 1.5\nthousand images displaying the Elbphilharmonie. We found that these posts\nmainly convey a neutral or positive sentiment towards it. With this pipeline,\nwe suggest a new semantic computing method that offers novel insights into\nend-users opinions, e.g., for architecture domain experts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Anschutz_M/0/1/0/all/0/1\">Miriam Ansch&#xfc;tz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eder_T/0/1/0/all/0/1\">Tobias Eder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Groh_G/0/1/0/all/0/1\">Georg Groh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"L3Cube-HindBERT and DevBERT: Pre-Trained BERT Transformer models for Devanagari based Hindi and Marathi Languages. (arXiv:2211.11418v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.11418","description":"<p>The monolingual Hindi BERT models currently available on the model hub do not\nperform better than the multi-lingual models on downstream tasks. We present\nL3Cube-HindBERT, a Hindi BERT model pre-trained on Hindi monolingual corpus.\nFurther, since Indic languages, Hindi and Marathi share the Devanagari script,\nwe train a single model for both languages. We release DevBERT, a Devanagari\nBERT model trained on both Marathi and Hindi monolingual datasets. We evaluate\nthese models on downstream Hindi and Marathi text classification and named\nentity recognition tasks. The HindBERT and DevBERT-based models show\nsignificant improvements over multi-lingual MuRIL, IndicBERT, and XLM-R. Based\non these observations we also release monolingual BERT models for other Indic\nlanguages Kannada, Telugu, Malayalam, Tamil, Gujarati, Assamese, Odia, Bengali,\nand Punjabi. These models are shared at https://huggingface.co/l3cube-pune .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Raviraj Joshi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CultureBERT: Fine-Tuning Transformer-Based Language Models for Corporate Culture. (arXiv:2212.00509v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.00509","description":"<p>This paper introduces supervised machine learning to the literature measuring\ncorporate culture from text documents. We compile a unique data set of employee\nreviews that were labeled by human evaluators with respect to the information\nthe reviews reveal about the firms' corporate culture. Using this data set, we\nfine-tune state-of-the-art transformer-based language models to perform the\nsame classification task. In out-of-sample predictions, our language models\nclassify 16 to 28 percent points more of employee reviews in line with human\nevaluators than traditional approaches of text classification. We make our\nmodels publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koch_S/0/1/0/all/0/1\">Sebastian Koch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasch_S/0/1/0/all/0/1\">Stefan Pasch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MAUD: An Expert-Annotated Legal NLP Dataset for Merger Agreement Understanding. (arXiv:2301.00876v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.00876","description":"<p>Reading comprehension of legal text can be a particularly challenging task\ndue to the length and complexity of legal clauses and a shortage of\nexpert-annotated datasets. To address this challenge, we introduce the Merger\nAgreement Understanding Dataset (MAUD), an expert-annotated reading\ncomprehension dataset based on the American Bar Association's 2021 Public\nTarget Deal Points Study, with over 39,000 examples and over 47,000 total\nannotations. Our fine-tuned Transformer baselines show promising results, with\nmodels performing well above random on most questions. However, on a large\nsubset of questions, there is still room for significant improvement. As the\nonly expert-annotated merger agreement dataset, MAUD is valuable as a benchmark\nfor both the legal profession and the NLP community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Steven H. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scardigli_A/0/1/0/all/0/1\">Antoine Scardigli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1\">Leonard Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levkin_D/0/1/0/all/0/1\">Dimitry Levkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Anya Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ball_S/0/1/0/all/0/1\">Spencer Ball</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodside_T/0/1/0/all/0/1\">Thomas Woodside</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_O/0/1/0/all/0/1\">Oliver Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1\">Dan Hendrycks</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models as Corporate Lobbyists. (arXiv:2301.01181v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.01181","description":"<p>We demonstrate a proof-of-concept of a large language model conducting\ncorporate lobbying related activities. An autoregressive large language model\n(OpenAI's text-davinci-003) determines if proposed U.S. Congressional bills are\nrelevant to specific public companies and provides explanations and confidence\nlevels. For the bills the model deems as relevant, the model drafts a letter to\nthe sponsor of the bill in an attempt to persuade the congressperson to make\nchanges to the proposed legislation. We use hundreds of novel ground-truth\nlabels of the relevance of a bill to a company to benchmark the performance of\nthe model, which outperforms the baseline of predicting the most common outcome\nof irrelevance. We also benchmark the performance of the previous OpenAI GPT-3\nmodel (text-davinci-002), which was the state-of-the-art model on many academic\nnatural language tasks until text-davinci-003 was recently released. The\nperformance of text-davinci-002 is worse than simply always predicting that a\nbill is irrelevant to a company. These results suggest that, as large language\nmodels continue to exhibit improved core natural language understanding\ncapabilities, performance on corporate lobbying related tasks will continue to\nimprove. If AI begins to influence law in a manner that is not a direct\nextension of human intentions, this threatens the critical role that law as\ninformation could play in aligning AI with humans. This paper explores how this\nis increasingly a possibility. Initially, AI is being used to simply augment\nhuman lobbyists. However, there may be a slow creep of less and less human\noversight over automated assessments of policy ideas and the written\ncommunication to regulatory agencies and Congressional staffers. The core\nquestion raised is where to draw the line between human-driven and AI-driven\npolicy influence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nay_J/0/1/0/all/0/1\">John J. Nay</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-01-09T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","content":"http://purl.org/rss/1.0/modules/content/"}}]}]}