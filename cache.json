{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2024-01-17T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Learning From How Humans Correct. (arXiv:2102.00225v19 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2102.00225","description":"<p>In industry NLP application, our manually labeled data has a certain number\nof noisy data. We present a simple method to find the noisy data and relabel\nthem manually, meanwhile we collect the correction information. Then we present\nnovel method to incorporate the human correction information into deep learning\nmodel. Human know how to correct noisy data. So the correction information can\nbe inject into deep learning model. We do the experiment on our own text\nclassification dataset, which is manually labeled, because we need to relabel\nthe noisy data in our dataset for our industry application. The experiment\nresult shows that our learn-on-correction method improve the classification\naccuracy from 91.7% to 92.5% in test dataset. The 91.7% accuracy is trained on\nthe corrected dataset, which improve the baseline from 83.3% to 91.7% in test\ndataset. The accuracy under human evaluation achieves more than 97%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1\">Tong Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Inducing Meaningful Units from Character Sequences with Dynamic Capacity Slot Attention. (arXiv:2102.01223v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2102.01223","description":"<p>Characters do not convey meaning, but sequences of characters do. We propose\nan unsupervised distributional method to learn the abstract meaningful units in\na sequence of characters. Rather than segmenting the sequence, our Dynamic\nCapacity Slot Attention model discovers continuous representations of the\nobjects in the sequence, extending an architecture for object discovery in\nimages. We train our model on different languages and evaluate the quality of\nthe obtained representations with forward and reverse probing classifiers.\nThese experiments show that our model succeeds in discovering units which are\nsimilar to those proposed previously in form, content and level of abstraction,\nand which show promise for capturing meaningful information at a higher level\nof abstraction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Behjati_M/0/1/0/all/0/1\">Melika Behjati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1\">James Henderson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Representation Learning for Weakly Supervised Relation Extraction. (arXiv:2105.00815v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2105.00815","description":"<p>Recent years have seen rapid development in Information Extraction, as well\nas its subtask, Relation Extraction. Relation Extraction is able to detect\nsemantic relations between entities in sentences. Currently, many efficient\napproaches have been applied to relation extraction tasks. Supervised learning\napproaches especially have good performance. However, there are still many\ndifficult challenges. One of the most serious problems is that manually labeled\ndata is difficult to acquire. In most cases, limited data for supervised\napproaches equals lousy performance. Thus here, under the situation with only\nlimited training data, we focus on how to improve the performance of our\nsupervised baseline system with unsupervised pre-training. Feature is one of\nthe key components in improving the supervised approaches. Traditional\napproaches usually apply hand-crafted features, which require expert knowledge\nand expensive human labor. However, this type of feature might suffer from data\nsparsity: when the training set size is small, the model parameters might be\npoorly estimated. In this thesis, we present several novel unsupervised\npre-training models to learn the distributed text representation features,\nwhich are encoded with rich syntactic-semantic patterns of relation\nexpressions. The experiments have demonstrated that this type of feature,\ncombine with the traditional hand-crafted features, could improve the\nperformance of the logistic classification model for relation extraction,\nespecially on the classification of relations with only minor training\ninstances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuang Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Discovering Salient Neurons in Deep NLP Models. (arXiv:2206.13288v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.13288","description":"<p>While a lot of work has been done in understanding representations learned\nwithin deep NLP models and what knowledge they capture, little attention has\nbeen paid towards individual neurons. We present a technique called as\nLinguistic Correlation Analysis to extract salient neurons in the model, with\nrespect to any extrinsic property - with the goal of understanding how such a\nknowledge is preserved within neurons. We carry out a fine-grained analysis to\nanswer the following questions: (i) can we identify subsets of neurons in the\nnetwork that capture specific linguistic properties? (ii) how localized or\ndistributed neurons are across the network? iii) how redundantly is the\ninformation preserved? iv) how fine-tuning pre-trained models towards\ndownstream NLP tasks, impacts the learned linguistic knowledge? iv) how do\narchitectures vary in learning different linguistic properties? Our\ndata-driven, quantitative analysis illuminates interesting findings: (i) we\nfound small subsets of neurons that can predict different linguistic tasks, ii)\nwith neurons capturing basic lexical information (such as suffixation)\nlocalized in lower most layers, iii) while those learning complex concepts\n(such as syntactic role) predominantly in middle and higher layers, iii) that\nsalient linguistic neurons are relocated from higher to lower layers during\ntransfer learning, as the network preserve the higher layers for task specific\ninformation, iv) we found interesting differences across pre-trained models,\nwith respect to how linguistic information is preserved within, and v) we found\nthat concept exhibit similar neuron distribution across different languages in\nthe multilingual transformer models. Our code is publicly available as part of\nthe NeuroX toolkit.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Durrani_N/0/1/0/all/0/1\">Nadir Durrani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalvi_F/0/1/0/all/0/1\">Fahim Dalvi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sajjad_H/0/1/0/all/0/1\">Hassan Sajjad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Faithful Model Explanation in NLP: A Survey. (arXiv:2209.11326v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.11326","description":"<p>End-to-end neural Natural Language Processing (NLP) models are notoriously\ndifficult to understand. This has given rise to numerous efforts towards model\nexplainability in recent years. One desideratum of model explanation is\nfaithfulness, i.e. an explanation should accurately represent the reasoning\nprocess behind the model's prediction. In this survey, we review over 110 model\nexplanation methods in NLP through the lens of faithfulness. We first discuss\nthe definition and evaluation of faithfulness, as well as its significance for\nexplainability. We then introduce recent advances in faithful explanation,\ngrouping existing approaches into five categories: similarity-based methods,\nanalysis of model-internal structures, backpropagation-based methods,\ncounterfactual intervention, and self-explanatory models. For each category, we\nsynthesize its representative studies, strengths, and weaknesses. Finally, we\nsummarize their common virtues and remaining challenges, and reflect on future\nwork directions towards faithful explainability in NLP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_Q/0/1/0/all/0/1\">Qing Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Apidianaki_M/0/1/0/all/0/1\">Marianna Apidianaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1\">Chris Callison-Burch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NormSAGE: Multi-Lingual Multi-Cultural Norm Discovery from Conversations On-the-Fly. (arXiv:2210.08604v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.08604","description":"<p>Norm discovery is important for understanding and reasoning about the\nacceptable behaviors and potential violations in human communication and\ninteractions. We introduce NormSage, a framework for addressing the novel task\nof conversation-grounded multi-lingual, multi-cultural norm discovery, based on\nlanguage model prompting and self-verification. NormSAGE leverages the\nexpressiveness and implicit knowledge of the pretrained GPT-3 language model\nbackbone, to elicit knowledge about norms through directed questions\nrepresenting the norm discovery task and conversation context. It further\naddresses the risk of language model hallucination with a self-verification\nmechanism ensuring that the norms discovered are correct and are substantially\ngrounded to their source conversations. Evaluation results show that our\napproach discovers significantly more relevant and insightful norms for\nconversations on-the-fly compared to baselines (&gt;10+% in Likert scale rating).\nThe norms discovered from Chinese conversation are also comparable to the norms\ndiscovered from English conversation in terms of insightfulness and correctness\n(&lt;3% difference). In addition, the culture-specific norms are promising\nquality, allowing for 80% accuracy in culture pair human identification.\nFinally, our grounding process in norm discovery self-verification can be\nextended for instantiating the adherence and violation of any norm for a given\nconversation on-the-fly, with explainability and transparency. NormSAGE\nachieves an AUC of 95.4% in grounding, with natural language explanation\nmatching human-written quality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fung_Y/0/1/0/all/0/1\">Yi R. Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tuhin Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Hao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rambow_O/0/1/0/all/0/1\">Owen Rambow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muresan_S/0/1/0/all/0/1\">Smaranda Muresan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Undesirable Biases in NLP: Addressing Challenges of Measurement. (arXiv:2211.13709v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.13709","description":"<p>As Large Language Models and Natural Language Processing (NLP) technology\nrapidly develop and spread into daily life, it becomes crucial to anticipate\nhow their use could harm people. One problem that has received a lot of\nattention in recent years is that this technology has displayed harmful biases,\nfrom generating derogatory stereotypes to producing disparate outcomes for\ndifferent social groups. Although a lot of effort has been invested in\nassessing and mitigating these biases, our methods of measuring the biases of\nNLP models have serious problems and it is often unclear what they actually\nmeasure. In this paper, we provide an interdisciplinary approach to discussing\nthe issue of NLP model bias by adopting the lens of psychometrics -- a field\nspecialized in the measurement of concepts like bias that are not directly\nobservable. In particular, we will explore two central notions from\npsychometrics, the construct validity and the reliability of measurement tools,\nand discuss how they can be applied in the context of measuring model bias. Our\ngoal is to provide NLP practitioners with methodological tools for designing\nbetter bias measures, and to inspire them more generally to explore tools from\npsychometrics when working on bias measurement tools.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wal_O/0/1/0/all/0/1\">Oskar van der Wal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachmann_D/0/1/0/all/0/1\">Dominik Bachmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leidinger_A/0/1/0/all/0/1\">Alina Leidinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maanen_L/0/1/0/all/0/1\">Leendert van Maanen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuidema_W/0/1/0/all/0/1\">Willem Zuidema</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schulz_K/0/1/0/all/0/1\">Katrin Schulz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Re-Label Method For Data-Centric Machine Learning. (arXiv:2302.04391v7 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.04391","description":"<p>In industry deep learning application, our manually labeled data has a\ncertain number of noisy data. To solve this problem and achieve more than 90\nscore in dev dataset, we present a simple method to find the noisy data and\nre-label the noisy data by human, given the model predictions as references in\nhuman labeling. In this paper, we illustrate our idea for a broad set of deep\nlearning tasks, includes classification, sequence tagging, object detection,\nsequence generation, click-through rate prediction. The dev dataset evaluation\nresults and human evaluation results verify our idea.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1\">Tong Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Large-Scale Analysis of Persian Tweets Regarding Covid-19 Vaccination. (arXiv:2302.04511v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.04511","description":"<p>The Covid-19 pandemic had an enormous effect on our lives, especially on\npeople's interactions. By introducing Covid-19 vaccines, both positive and\nnegative opinions were raised over the subject of taking vaccines or not. In\nthis paper, using data gathered from Twitter, including tweets and user\nprofiles, we offer a comprehensive analysis of public opinion in Iran about the\nCoronavirus vaccines. For this purpose, we applied a search query technique\ncombined with a topic modeling approach to extract vaccine-related tweets. We\nutilized transformer-based models to classify the content of the tweets and\nextract themes revolving around vaccination. We also conducted an emotion\nanalysis to evaluate the public happiness and anger around this topic. Our\nresults demonstrate that Covid-19 vaccination has attracted considerable\nattention from different angles, such as governmental issues, safety or\nhesitancy, and side effects. Moreover, Coronavirus-relevant phenomena like\npublic vaccination and the rate of infection deeply impacted public emotional\nstatus and users' interactions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+ShabaniMirzaei_T/0/1/0/all/0/1\">Taha ShabaniMirzaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chamani_H/0/1/0/all/0/1\">Houmaan Chamani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abaskohi_A/0/1/0/all/0/1\">Amirhossein Abaskohi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zadeh_Z/0/1/0/all/0/1\">Zhivar Sourati Hassan Zadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bahrak_B/0/1/0/all/0/1\">Behnam Bahrak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Difficulty in chirality recognition for Transformer architectures learning chemical structures from string. (arXiv:2303.11593v4 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2303.11593","description":"<p>Recent years have seen rapid development of descriptor generation based on\nrepresentation learning of extremely diverse molecules, especially those that\napply natural language processing (NLP) models to SMILES, a literal\nrepresentation of molecular structure. However, little research has been done\non how these models understand chemical structure. To address this black box,\nwe investigated the relationship between the learning progress of SMILES and\nchemical structure using a representative NLP model, the Transformer. We show\nthat while the Transformer learns partial structures of molecules quickly, it\nrequires extended training to understand overall structures. Consistently, the\naccuracy of molecular property predictions using descriptors generated from\nmodels at different learning steps was similar from the beginning to the end of\ntraining. Furthermore, we found that the Transformer requires particularly long\ntraining to learn chirality and sometimes stagnates with low performance due to\nmisunderstanding of enantiomers. These findings are expected to deepen the\nunderstanding of NLP models in chemistry.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yoshikai_Y/0/1/0/all/0/1\">Yasuhiro Yoshikai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mizuno_T/0/1/0/all/0/1\">Tadahaya Mizuno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nemoto_S/0/1/0/all/0/1\">Shumpei Nemoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusuhara_H/0/1/0/all/0/1\">Hiroyuki Kusuhara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SwissBERT: The Multilingual Language Model for Switzerland. (arXiv:2303.13310v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.13310","description":"<p>We present SwissBERT, a masked language model created specifically for\nprocessing Switzerland-related text. SwissBERT is a pre-trained model that we\nadapted to news articles written in the national languages of Switzerland --\nGerman, French, Italian, and Romansh. We evaluate SwissBERT on natural language\nunderstanding tasks related to Switzerland and find that it tends to outperform\nprevious models on these tasks, especially when processing contemporary news\nand/or Romansh Grischun. Since SwissBERT uses language adapters, it may be\nextended to Swiss German dialects in future work. The model and our open-source\ncode are publicly released at https://github.com/ZurichNLP/swissbert.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vamvas_J/0/1/0/all/0/1\">Jannis Vamvas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graen_J/0/1/0/all/0/1\">Johannes Gra&#xeb;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sennrich_R/0/1/0/all/0/1\">Rico Sennrich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DinoSR: Self-Distillation and Online Clustering for Self-supervised Speech Representation Learning. (arXiv:2305.10005v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10005","description":"<p>In this paper, we introduce self-distillation and online clustering for\nself-supervised speech representation learning (DinoSR) which combines masked\nlanguage modeling, self-distillation, and online clustering. We show that these\nconcepts complement each other and result in a strong representation learning\nmodel for speech. DinoSR first extracts contextualized embeddings from the\ninput audio with a teacher network, then runs an online clustering system on\nthe embeddings to yield a machine-discovered phone inventory, and finally uses\nthe discretized tokens to guide a student network. We show that DinoSR\nsurpasses previous state-of-the-art performance in several downstream tasks,\nand provide a detailed analysis of the model and the learned discrete units.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Alexander H. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1\">Heng-Jui Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Auli_M/0/1/0/all/0/1\">Michael Auli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1\">Wei-Ning Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James R. Glass</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Diffusion Language Models Generation Can Be Halted Early. (arXiv:2305.10818v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.10818","description":"<p>Diffusion Language models (DLMs) are a promising avenue for text generation\ndue to their practical properties on tractable controllable generation. They\nalso have the advantage of not having to predict text autoregressively.\nHowever, despite these notable features, DLMs have not yet reached the\nperformance levels of their Autoregressive counterparts. One of the ways to\nreduce the performance gap between these two types of language models is to\nspeed up the generation of DLMs. Therefore, we propose a pioneering methodology\nto address this issue in this work. It enables the execution of more generation\nsteps within a given time frame, potentially leading to higher-quality outputs.\nSpecifically, our methods estimate DLMs completeness of text generation and\nallow adaptive halting of the generation process. We test and refine our\nmethods on Plaid, SSD, and CDCD DLMs and create a cohesive perspective on their\ngeneration workflows. Finally, we confirm that our methods allow halting Plaid,\nSSD, and CDCD models and decrease the generation time by $10$-$40$% without a\ndrop in the quality of model samples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vaina_S/0/1/0/all/0/1\">Sofia Maria Lo Cicero Vaina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balagansky_N/0/1/0/all/0/1\">Nikita Balagansky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gavrilov_D/0/1/0/all/0/1\">Daniil Gavrilov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings. (arXiv:2305.11554v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11554","description":"<p>Augmenting large language models (LLMs) with external tools has emerged as a\npromising approach to solving complex problems. However, traditional methods,\nwhich finetune LLMs with tool demonstration data, can be both costly and\nrestricted to a predefined set of tools. Recent in-context learning paradigm\nalleviates these issues, but the limited context length only allows for a few\nshots of demonstrations, leading to suboptimal understandings of the tools.\nMoreover, when there are numerous tools to choose from, in-context learning\ncould completely fail to work. In this paper, we propose an alternative\napproach, $\\textbf{ToolkenGPT}$, which combines the benefits of both sides. Our\napproach represents each $\\underline{tool}$ as a to$\\underline{ken}$\n($\\textit{toolken}$) and learns an embedding for it, enabling tool calls in the\nsame way as generating a regular word token. Once a toolken is triggered, the\nLLM is prompted to complete arguments for the tool to execute. ToolkenGPT\noffers the flexibility to plug in an arbitrary number of tools by expanding the\nset of toolkens on the fly. In addition, it improves tool use by allowing\nextensive demonstration data for learning the toolken embeddings. In diverse\ndomains, including numerical reasoning, knowledge-based question answering, and\nembodied plan generation, our approach effectively augments LLMs with tools and\nsubstantially outperforms various latest baselines. ToolkenGPT demonstrates the\npromising ability to use relevant tools from a large tool set in complex\nscenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hao_S/0/1/0/all/0/1\">Shibo Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiting Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Motion-Based Sign Language Video Summarization using Curvature and Torsion. (arXiv:2305.16801v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.16801","description":"<p>An interesting problem in many video-based applications is the generation of\nshort synopses by selecting the most informative frames, a procedure which is\nknown as video summarization. For sign language videos the benefits of using\nthe $t$-parameterized counterpart of the curvature of the 2-D signer's wrist\ntrajectory to identify keyframes, have been recently reported in the\nliterature. In this paper we extend these ideas by modeling the 3-D hand motion\nthat is extracted from each frame of the video. To this end we propose a new\ninformative function based on the $t$-parameterized curvature and torsion of\nthe 3-D trajectory. The method to characterize video frames as keyframes\ndepends on whether the motion occurs in 2-D or 3-D space. Specifically, in the\ncase of 3-D motion we look for the maxima of the harmonic mean of the curvature\nand torsion of the target's trajectory; in the planar motion case we seek for\nthe maxima of the trajectory's curvature. The proposed 3-D feature is\nexperimentally evaluated in applications of sign language videos on (1)\nobjective measures using ground-truth keyframe annotations, (2) human-based\nevaluation of understanding, and (3) gloss classification and the results\nobtained are promising.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sartinas_E/0/1/0/all/0/1\">Evangelos G. Sartinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Psarakis_E/0/1/0/all/0/1\">Emmanouil Z. Psarakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kosmopoulos_D/0/1/0/all/0/1\">Dimitrios I. Kosmopoulos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Translatotron 3: Speech to Speech Translation with Monolingual Data. (arXiv:2305.17547v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.17547","description":"<p>This paper presents Translatotron 3, a novel approach to unsupervised direct\nspeech-to-speech translation from monolingual speech-text datasets by combining\nmasked autoencoder, unsupervised embedding mapping, and back-translation.\nExperimental results in speech-to-speech translation tasks between Spanish and\nEnglish show that Translatotron 3 outperforms a baseline cascade system,\nreporting $18.14$ BLEU points improvement on the synthesized\nUnpaired-Conversational dataset. In contrast to supervised approaches that\nnecessitate real paired data, or specialized modeling to replicate\npara-/non-linguistic information such as pauses, speaking rates, and speaker\nidentity, Translatotron 3 showcases its capability to retain it. Audio samples\ncan be found at <a href=\"http://google-research.github.io/lingvo-lab/translatotron3\">this http URL</a>\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nachmani_E/0/1/0/all/0/1\">Eliya Nachmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levkovitch_A/0/1/0/all/0/1\">Alon Levkovitch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yifan Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asawaroengchai_C/0/1/0/all/0/1\">Chulayuth Asawaroengchai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zen_H/0/1/0/all/0/1\">Heiga Zen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanovich_M/0/1/0/all/0/1\">Michelle Tadmor Ramanovich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning a Structural Causal Model for Intuition Reasoning in Conversation. (arXiv:2305.17727v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.17727","description":"<p>Reasoning, a crucial aspect of NLP research, has not been adequately\naddressed by prevailing models including Large Language Model. Conversation\nreasoning, as a critical component of it, remains largely unexplored due to the\nabsence of a well-designed cognitive model. In this paper, inspired by\nintuition theory on conversation cognition, we develop a conversation cognitive\nmodel (CCM) that explains how each utterance receives and activates channels of\ninformation recursively. Besides, we algebraically transformed CCM into a\nstructural causal model (SCM) under some mild assumptions, rendering it\ncompatible with various causal discovery methods. We further propose a\nprobabilistic implementation of the SCM for utterance-level relation reasoning.\nBy leveraging variational inference, it explores substitutes for implicit\ncauses, addresses the issue of their unobservability, and reconstructs the\ncausal representations of utterances through the evidence lower bounds.\nMoreover, we constructed synthetic and simulated datasets incorporating\nimplicit causes and complete cause labels, alleviating the current situation\nwhere all available datasets are implicit-causes-agnostic. Extensive\nexperiments demonstrate that our proposed method significantly outperforms\nexisting methods on synthetic, simulated, and real-world datasets. Finally, we\nanalyze the performance of CCM under latent confounders and propose theoretical\nideas for addressing this currently unresolved issue.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_B/0/1/0/all/0/1\">Bingyu Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jing Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenjing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xinyu Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Neural Task Synthesis for Visual Programming. (arXiv:2305.18342v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.18342","description":"<p>Generative neural models hold great promise in enhancing programming\neducation by synthesizing new content. We seek to design neural models that can\nautomatically generate programming tasks for a given specification in the\ncontext of visual programming domains. Despite the recent successes of large\ngenerative models like GPT-4, our initial results show that these models are\nineffective in synthesizing visual programming tasks and struggle with logical\nand spatial reasoning. We propose a novel neuro-symbolic technique,\nNeurTaskSyn, that can synthesize programming tasks for a specification given in\nthe form of desired programming concepts exercised by its solution code and\nconstraints on the visual task. NeurTaskSyn has two components: the first\ncomponent is trained via imitation learning procedure to generate possible\nsolution codes, and the second component is trained via reinforcement learning\nprocedure to guide an underlying symbolic execution engine that generates\nvisual tasks for these codes. We demonstrate the effectiveness of NeurTaskSyn\nthrough an extensive empirical evaluation and a qualitative study on reference\ntasks taken from the Hour of Code: Classic Maze challenge by Code-dot-org and\nthe Intro to Programming with Karel course by CodeHS-dot-com.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Padurean_V/0/1/0/all/0/1\">Victor-Alexandru P&#x103;durean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzannetos_G/0/1/0/all/0/1\">Georgios Tzannetos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_A/0/1/0/all/0/1\">Adish Singla</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Imperfect Surrogates for Downstream Inference: Design-based Supervised Learning for Social Science Applications of Large Language Models. (arXiv:2306.04746v3 [stat.ME] UPDATED)","link":"http://arxiv.org/abs/2306.04746","description":"<p>In computational social science (CSS), researchers analyze documents to\nexplain social and political phenomena. In most scenarios, CSS researchers\nfirst obtain labels for documents and then explain labels using interpretable\nregression analyses in the second step. One increasingly common way to annotate\ndocuments cheaply at scale is through large language models (LLMs). However,\nlike other scalable ways of producing annotations, such surrogate labels are\noften imperfect and biased. We present a new algorithm for using imperfect\nannotation surrogates for downstream statistical analyses while guaranteeing\nstatistical properties -- like asymptotic unbiasedness and proper uncertainty\nquantification -- which are fundamental to CSS research. We show that direct\nuse of surrogate labels in downstream statistical analyses leads to substantial\nbias and invalid confidence intervals, even with high surrogate accuracy of\n80-90%. To address this, we build on debiased machine learning to propose the\ndesign-based supervised learning (DSL) estimator. DSL employs a doubly-robust\nprocedure to combine surrogate labels with a smaller number of high-quality,\ngold-standard labels. Our approach guarantees valid inference for downstream\nstatistical analyses, even when surrogates are arbitrarily biased and without\nrequiring stringent assumptions, by controlling the probability of sampling\ndocuments for gold-standard labeling. Both our theoretical analysis and\nexperimental results show that DSL provides valid statistical inference while\nachieving root mean squared errors comparable to existing alternatives that\nfocus only on prediction without inferential guarantees.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/stat/1/au:+Egami_N/0/1/0/all/0/1\">Naoki Egami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hinck_M/0/1/0/all/0/1\">Musashi Hinck</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stewart_B/0/1/0/all/0/1\">Brandon M. Stewart</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wei_H/0/1/0/all/0/1\">Hanying Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Advancing Italian Biomedical Information Extraction with Transformers-based Models: Methodological Insights and Multicenter Practical Application. (arXiv:2306.05323v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.05323","description":"<p>The introduction of computerized medical records in hospitals has reduced\nburdensome activities like manual writing and information fetching. However,\nthe data contained in medical records are still far underutilized, primarily\nbecause extracting data from unstructured textual medical records takes time\nand effort. Information Extraction, a subfield of Natural Language Processing,\ncan help clinical practitioners overcome this limitation by using automated\ntext-mining pipelines. In this work, we created the first Italian\nneuropsychiatric Named Entity Recognition dataset, PsyNIT, and used it to\ndevelop a Transformers-based model. Moreover, we collected and leveraged three\nexternal independent datasets to implement an effective multicenter model, with\noverall F1-score 84.77%, Precision 83.16%, Recall 86.44%. The lessons learned\nare: (i) the crucial role of a consistent annotation process and (ii) a\nfine-tuning strategy that combines classical methods with a \"low-resource\"\napproach. This allowed us to establish methodological guidelines that pave the\nway for Natural Language Processing studies in less-resourced languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Crema_C/0/1/0/all/0/1\">Claudio Crema</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buonocore_T/0/1/0/all/0/1\">Tommaso Mario Buonocore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fostinelli_S/0/1/0/all/0/1\">Silvia Fostinelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parimbelli_E/0/1/0/all/0/1\">Enea Parimbelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verde_F/0/1/0/all/0/1\">Federico Verde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fundaro_C/0/1/0/all/0/1\">Cira Fundar&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manera_M/0/1/0/all/0/1\">Marina Manera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramusino_M/0/1/0/all/0/1\">Matteo Cotta Ramusino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Capelli_M/0/1/0/all/0/1\">Marco Capelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_A/0/1/0/all/0/1\">Alfredo Costa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Binetti_G/0/1/0/all/0/1\">Giuliano Binetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bellazzi_R/0/1/0/all/0/1\">Riccardo Bellazzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Redolfi_A/0/1/0/all/0/1\">Alberto Redolfi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Integrating a Heterogeneous Graph with Entity-aware Self-attention using Relative Position Labels for Reading Comprehension Model. (arXiv:2307.10443v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.10443","description":"<p>Despite the significant progress made by transformer models in machine\nreading comprehension tasks, they still fall short in handling complex\nreasoning tasks due to the absence of explicit knowledge in the input sequence.\nTo address this limitation, many recent works have proposed injecting external\nknowledge into the model. However, selecting relevant external knowledge,\nensuring its availability, and requiring additional processing steps remain\nchallenging. In this paper, we introduce a novel attention pattern that\nintegrates reasoning knowledge derived from a heterogeneous graph into the\ntransformer architecture without relying on external knowledge. The proposed\nattention pattern comprises three key elements: global-local attention for word\ntokens, graph attention for entity tokens that exhibit strong attention towards\ntokens connected in the graph as opposed to those unconnected, and the\nconsideration of the type of relationship between each entity token and word\ntoken. This results in optimized attention between the two if a relationship\nexists. The pattern is coupled with special relative position labels, allowing\nit to integrate with LUKE's entity-aware self-attention mechanism. The\nexperimental findings corroborate that our model outperforms both the\ncutting-edge LUKE-Graph and the baseline LUKE model across two distinct\ndatasets: ReCoRD, emphasizing commonsense reasoning, and WikiHop, focusing on\nmulti-hop reasoning challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Foolad_S/0/1/0/all/0/1\">Shima Foolad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiani_K/0/1/0/all/0/1\">Kourosh Kiani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"QuIP: 2-Bit Quantization of Large Language Models With Guarantees. (arXiv:2307.13304v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2307.13304","description":"<p>This work studies post-training parameter quantization in large language\nmodels (LLMs). We introduce quantization with incoherence processing (QuIP), a\nnew method based on the insight that quantization benefits from\n$\\textit{incoherent}$ weight and Hessian matrices, i.e., from the weights being\neven in magnitude and the directions in which it is important to round them\naccurately being unaligned with the coordinate axes. QuIP consists of two\nsteps: (1) an adaptive rounding procedure minimizing a quadratic proxy\nobjective; (2) efficient pre- and post-processing that ensures weight and\nHessian incoherence via multiplication by random orthogonal matrices. We\ncomplement QuIP with the first theoretical analysis for an LLM-scale\nquantization algorithm, and show that our theory also applies to an existing\nmethod, OPTQ. Empirically, we find that our incoherence preprocessing improves\nseveral existing quantization algorithms and yields the first LLM quantization\nmethods that produce viable results using only two bits per weight. Our code\ncan be found at https://github.com/Cornell-RelaxML/QuIP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chee_J/0/1/0/all/0/1\">Jerry Chee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yaohui Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuleshov_V/0/1/0/all/0/1\">Volodymyr Kuleshov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dialogue for Prompting: a Policy-Gradient-Based Discrete Prompt Generation for Few-shot Learning. (arXiv:2308.07272v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2308.07272","description":"<p>Prompt-based pre-trained language models (PLMs) paradigm have succeeded\nsubstantially in few-shot natural language processing (NLP) tasks. However,\nprior discrete prompt optimization methods require expert knowledge to design\nthe base prompt set and identify high-quality prompts, which is costly,\ninefficient, and subjective. Meanwhile, existing continuous prompt optimization\nmethods improve the performance by learning the ideal prompts through the\ngradient information of PLMs, whose high computational cost, and low\nreadability and generalizability are often concerning. To address the research\ngap, we propose a Dialogue-comprised Policy-gradient-based Discrete Prompt\nOptimization ($DP_2O$) method. We first design a multi-round dialogue alignment\nstrategy for readability prompt set generation based on GPT-4. Furthermore, we\npropose an efficient prompt screening metric to identify high-quality prompts\nwith linear complexity. Finally, we construct a reinforcement learning (RL)\nframework based on policy gradients to match the prompts to inputs optimally.\nBy training a policy network with only 0.67% of the PLM parameter size on the\ntasks in the few-shot setting, $DP_2O$ outperforms the state-of-the-art (SOTA)\nmethod by 1.52% in accuracy on average on four open-source datasets. Moreover,\nsubsequent experiments also demonstrate that $DP_2O$ has good universality,\nrobustness, and generalization ability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chengzhengxu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yichen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Duyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yu Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chao Shen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluation and Enhancement of Semantic Grounding in Large Vision-Language Models. (arXiv:2309.04041v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2309.04041","description":"<p>Large Vision-Language Models (LVLMs) offer remarkable benefits for a variety\nof vision-language tasks. However, a challenge hindering their application in\nreal-world scenarios, particularly regarding safety, robustness, and\nreliability, is their constrained semantic grounding ability, which pertains to\nconnecting language to the physical-world entities or concepts referenced in\nimages. Therefore, a crucial need arises for a comprehensive study to assess\nthe semantic grounding ability of widely used LVLMs. Despite the significance,\nsufficient investigation in this direction is currently lacking. Our work\nbridges this gap by designing a pipeline for generating large-scale evaluation\ndatasets covering fine-grained semantic information, such as color, number,\nmaterial, etc., along with a thorough assessment of seven popular LVLMs'\nsemantic grounding ability. Results highlight prevalent misgrounding across\nvarious aspects and degrees. To address this issue, we propose a data-centric\nenhancement method that aims to improve LVLMs' semantic grounding ability\nthrough multimodal instruction tuning on fine-grained conversations.\nExperiments on enhanced LVLMs demonstrate notable improvements in addressing\nmisgrounding issues.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiaying Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_J/0/1/0/all/0/1\">Jinmeng Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kezhen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xiaoyuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yawen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1\">Baochen Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Carl Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jie Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CB-Whisper: Contextual Biasing Whisper using Open-Vocabulary Keyword-Spotting. (arXiv:2309.09552v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2309.09552","description":"<p>End-to-end automatic speech recognition (ASR) systems often struggle to\nrecognize rare name entities, such as personal names, organizations, and\nterminologies not frequently encountered in the training data. This paper\npresents Contextual Biasing Whisper (CB-Whisper), a novel ASR system based on\nOpenAI's Whisper model that can recognize user-defined name entities by\nperforming open-vocabulary keyword-spotting (OV-KWS) using the hidden states of\nWhisper encoder. The recognized entities are used as prompts for the Whisper\ndecoder. We first propose a multitask training approach with OV-KWS and ASR\ntasks to optimize the model. Experiments show that this approach substantially\nimproves the entity recalls compared to the original Whisper model on Chinese\nAishell hot word subsets and two internal code-switch test sets. However, we\nobserved a slight increase in mixed-error-rate (MER) on internal test sets due\nto catastrophic forgetting. To address this problem and use different sizes of\nthe Whisper model without finetuning, we propose to use OV-KWS as a separate\nmodule and construct a spoken form prompt to prevent hallucination. The OV-KWS\nmodule consistently improves MER and Entity Recall for whisper-small, medium,\nand large models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinglu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1\">Chang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_M/0/1/0/all/0/1\">Mengxin Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_X/0/1/0/all/0/1\">Xiaosong Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiaofeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piao_M/0/1/0/all/0/1\">Mengyao Piao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jiawei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1\">Xinglin Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Miaomiao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yanqing Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hao Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AMPLIFY:Attention-based Mixup for Performance Improvement and Label Smoothing in Transformer. (arXiv:2309.12689v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2309.12689","description":"<p>Mixup is an effective data augmentation method that generates new augmented\nsamples by aggregating linear combinations of different original samples.\nHowever, if there are noises or aberrant features in the original samples,\nMixup may propagate them to the augmented samples, leading to over-sensitivity\nof the model to these outliers . To solve this problem, this paper proposes a\nnew Mixup method called AMPLIFY. This method uses the Attention mechanism of\nTransformer itself to reduce the influence of noises and aberrant values in the\noriginal samples on the prediction results, without increasing additional\ntrainable parameters, and the computational cost is very low, thereby avoiding\nthe problem of high resource consumption in common Mixup methods such as\nSentence Mixup . The experimental results show that, under a smaller\ncomputational resource cost, AMPLIFY outperforms other Mixup methods in text\nclassification tasks on 7 benchmark datasets, providing new ideas and new ways\nto further improve the performance of pre-trained models based on the Attention\nmechanism, such as BERT, ALBERT, RoBERTa, and GPT. Our code can be obtained at\nhttps://github.com/kiwi-lilo/AMPLIFY.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Leixin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1\">Yu Xiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards General-Purpose Text-Instruction-Guided Voice Conversion. (arXiv:2309.14324v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2309.14324","description":"<p>This paper introduces a novel voice conversion (VC) model, guided by text\ninstructions such as \"articulate slowly with a deep tone\" or \"speak in a\ncheerful boyish voice\". Unlike traditional methods that rely on reference\nutterances to determine the attributes of the converted speech, our model adds\nversatility and specificity to voice conversion. The proposed VC model is a\nneural codec language model which processes a sequence of discrete codes,\nresulting in the code sequence of converted speech. It utilizes text\ninstructions as style prompts to modify the prosody and emotional information\nof the given speech. In contrast to previous approaches, which often rely on\nemploying separate encoders like prosody and content encoders to handle\ndifferent aspects of the source speech, our model handles various information\nof speech in an end-to-end manner. Experiments have demonstrated the impressive\ncapabilities of our model in comprehending instructions and delivering\nreasonable results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Kuan_C/0/1/0/all/0/1\">Chun-Yi Kuan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_C/0/1/0/all/0/1\">Chen An Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hsu_T/0/1/0/all/0/1\">Tsu-Yuan Hsu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lin_T/0/1/0/all/0/1\">Tse-Yang Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chung_H/0/1/0/all/0/1\">Ho-Lam Chung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chang_S/0/1/0/all/0/1\">Shuo-yiin Chang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Human Feedback is not Gold Standard. (arXiv:2309.16349v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.16349","description":"<p>Human feedback has become the de facto standard for evaluating the\nperformance of Large Language Models, and is increasingly being used as a\ntraining objective. However, it is not clear which properties of a generated\noutput this single `preference' score captures. We hypothesise that preference\nscores are subjective and open to undesirable biases. We critically analyse the\nuse of human feedback for both training and evaluation, to verify whether it\nfully captures a range of crucial error criteria. We find that while preference\nscores have fairly good coverage, they under-represent important aspects like\nfactuality. We further hypothesise that both preference scores and error\nannotation may be affected by confounders, and leverage instruction-tuned\nmodels to generate outputs that vary along two possible confounding dimensions:\nassertiveness and complexity. We find that the assertiveness of an output skews\nthe perceived rate of factuality errors, indicating that human annotations are\nnot a fully reliable evaluation metric or training objective. Finally, we offer\npreliminary evidence that using human feedback as a training objective\ndisproportionately increases the assertiveness of model outputs. We encourage\nfuture work to carefully consider whether preference scores are well aligned\nwith the desired objective.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hosking_T/0/1/0/all/0/1\">Tom Hosking</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blunsom_P/0/1/0/all/0/1\">Phil Blunsom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartolo_M/0/1/0/all/0/1\">Max Bartolo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Pretraining for Fact Verification by Language Model Distillation. (arXiv:2309.16540v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.16540","description":"<p>Fact verification aims to verify a claim using evidence from a trustworthy\nknowledge base. To address this challenge, algorithms must produce features for\nevery claim that are both semantically meaningful, and compact enough to find a\nsemantic alignment with the source information. In contrast to previous work,\nwhich tackled the alignment problem by learning over annotated corpora of\nclaims and their corresponding labels, we propose SFAVEL (Self-supervised Fact\nVerification via Language Model Distillation), a novel unsupervised pretraining\nframework that leverages pre-trained language models to distil self-supervised\nfeatures into high-quality claim-fact alignments without the need for\nannotations. This is enabled by a novel contrastive loss function that\nencourages features to attain high-quality claim and evidence alignments whilst\npreserving the semantic relationships across the corpora. Notably, we present\nresults that achieve a new state-of-the-art on FB15k-237 (+5.3% Hits@1) and\nFEVER (+8% accuracy) with linear evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bazaga_A/0/1/0/all/0/1\">Adri&#xe1;n Bazaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Micklem_G/0/1/0/all/0/1\">Gos Micklem</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Natural Language Processing Model for Radiology Reports -- The Summary is all you need!. (arXiv:2310.00100v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.00100","description":"<p>The impression section of a radiology report summarizes important radiology\nfindings and plays a critical role in communicating these findings to\nphysicians. However, the preparation of these summaries is time-consuming and\nerror-prone for radiologists. Recently, numerous models for radiology report\nsummarization have been developed. Nevertheless, there is currently no model\nthat can summarize these reports in multiple languages. Such a model could\ngreatly improve future research and the development of Deep Learning models\nthat incorporate data from patients with different ethnic backgrounds. In this\nstudy, the generation of radiology impressions in different languages was\nautomated by fine-tuning a model, publicly available, based on a multilingual\ntext-to-text Transformer to summarize findings available in English,\nPortuguese, and German radiology reports. In a blind test, two board-certified\nradiologists indicated that for at least 70% of the system-generated summaries,\nthe quality matched or exceeded the corresponding human-written summaries,\nsuggesting substantial clinical reliability. Furthermore, this study showed\nthat the multilingual model outperformed other models that specialized in\nsummarizing radiology reports in only one language, as well as models that were\nnot specifically designed for summarizing radiology reports, such as ChatGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lindo_M/0/1/0/all/0/1\">Mariana Lindo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_A/0/1/0/all/0/1\">Ana Sofia Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferreira_A/0/1/0/all/0/1\">Andr&#xe9; Ferreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luijten_G/0/1/0/all/0/1\">Gijs Luijten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Correia_G/0/1/0/all/0/1\">Gustavo Correia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Moon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaarschmidt_B/0/1/0/all/0/1\">Benedikt Michael Schaarschmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deuschl_C/0/1/0/all/0/1\">Cornelius Deuschl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haubold_J/0/1/0/all/0/1\">Johannes Haubold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleesiek_J/0/1/0/all/0/1\">Jens Kleesiek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Egger_J/0/1/0/all/0/1\">Jan Egger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alves_V/0/1/0/all/0/1\">Victor Alves</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transcending the Attention Paradigm: Representation Learning from Geospatial Social Media Data. (arXiv:2310.05378v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05378","description":"<p>While transformers have pioneered attention-driven architectures as a\ncornerstone of language modeling, their dependence on explicitly contextual\ninformation underscores limitations in their abilities to tacitly learn\noverarching textual themes. This study challenges the heuristic paradigm of\nperformance benchmarking by investigating social media data as a source of\ndistributed patterns. In stark contrast to networks that rely on capturing\ncomplex long-term dependencies, models of online data inherently lack structure\nand are forced to detect latent structures in the aggregate. To properly\nrepresent these abstract relationships, this research dissects empirical social\nmedia corpora into their elemental components, analyzing over two billion\ntweets across population-dense locations. We create Bag-of-Word embedding\nspecific to each city and compare their respective representations. This finds\nthat even amidst noisy data, geographic location has a considerable influence\non online communication, and that hidden insights can be uncovered without the\ncrutch of advanced algorithms. This evidence presents valuable geospatial\nimplications in social science and challenges the notion that intricate models\nare prerequisites for pattern recognition in natural language. This aligns with\nthe evolving landscape that questions the embrace of absolute interpretability\nover abstract understanding and bridges the divide between sophisticated\nframeworks and intangible relationships.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+DiSanto_N/0/1/0/all/0/1\">Nick DiSanto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corso_A/0/1/0/all/0/1\">Anthony Corso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanders_B/0/1/0/all/0/1\">Benjamin Sanders</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harding_G/0/1/0/all/0/1\">Gavin Harding</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Glitter or Gold? Deriving Structured Insights from Sustainability Reports via Large Language Models. (arXiv:2310.05628v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05628","description":"<p>Over the last decade, several regulatory bodies have started requiring the\ndisclosure of non-financial information from publicly listed companies, in\nlight of the investors' increasing attention to Environmental, Social, and\nGovernance (ESG) issues. Publicly released information on sustainability\npractices is often disclosed in diverse, unstructured, and multi-modal\ndocumentation. This poses a challenge in efficiently gathering and aligning the\ndata into a unified framework to derive insights related to Corporate Social\nResponsibility (CSR). Thus, using Information Extraction (IE) methods becomes\nan intuitive choice for delivering insightful and actionable data to\nstakeholders. In this study, we employ Large Language Models (LLMs), In-Context\nLearning, and the Retrieval-Augmented Generation (RAG) paradigm to extract\nstructured insights related to ESG aspects from companies' sustainability\nreports. We then leverage graph-based representations to conduct statistical\nanalyses concerning the extracted insights. These analyses revealed that ESG\ncriteria cover a wide range of topics, exceeding 500, often beyond those\nconsidered in existing categorizations, and are addressed by companies through\na variety of initiatives. Moreover, disclosure similarities emerged among\ncompanies from the same region or sector, validating ongoing hypotheses in the\nESG literature. Lastly, by incorporating additional company attributes into our\nanalyses, we investigated which factors impact the most on companies' ESG\nratings, showing that ESG disclosure affects the obtained ratings more than\nother financial or company data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bronzini_M/0/1/0/all/0/1\">Marco Bronzini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nicolini_C/0/1/0/all/0/1\">Carlo Nicolini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lepri_B/0/1/0/all/0/1\">Bruno Lepri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Passerini_A/0/1/0/all/0/1\">Andrea Passerini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staiano_J/0/1/0/all/0/1\">Jacopo Staiano</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Aligning Language Models with Human Preferences via a Bayesian Approach. (arXiv:2310.05782v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05782","description":"<p>In the quest to advance human-centric natural language generation (NLG)\nsystems, ensuring alignment between NLG models and human preferences is\ncrucial. For this alignment, current popular methods leverage a reinforcement\nlearning (RL) approach with a reward model trained on feedback from humans.\nHowever, inherent disagreements due to the subjective nature of human\npreferences pose a significant challenge for training the reward model,\nresulting in a deterioration of the NLG performance. To tackle this issue,\nprevious approaches typically rely on majority voting or averaging to\nconsolidate multiple inconsistent preferences into a merged one. Although\nstraightforward to understand and execute, such methods suffer from an\ninability to capture the nuanced degrees of disaggregation among humans and may\nonly represent a specialized subset of individuals, thereby lacking the ability\nto quantitatively disclose the universality of human preferences. To address\nthis challenge, this paper proposes a novel approach, which employs a Bayesian\nframework to account for the distribution of disagreements among human\npreferences as training a preference model, and names it as d-PM. Besides,\nconsidering the RL strategy's inefficient and complex training process over the\ntraining efficiency, we further propose utilizing the contrastive learning\nstrategy to train the NLG model with the preference scores derived from the\nd-PM model. Extensive experiments on two human-centric NLG tasks, i.e.,\nemotional support conversation and integrity \"Rule-of-Thumb\" generation, show\nthat our method consistently exceeds previous SOTA models in both automatic and\nhuman evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiashuo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haozhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shichao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenjie Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Text-based Knowledge Graph Completion Benefit From Zero-Shot Large Language Models?. (arXiv:2310.08279v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08279","description":"<p>Text-based knowledge graph completion (KGC) methods, leveraging textual\nentity descriptions are at the research forefront. The efficacy of these models\nhinges on the quality of the textual data. This study explores whether enriched\nor more efficient textual descriptions can amplify model performance. Recently,\nLarge Language Models (LLMs) have shown remarkable improvements in NLP tasks,\nattributed to their sophisticated text generation and conversational\ncapabilities. LLMs assimilate linguistic patterns and integrate knowledge from\ntheir training data. Compared to traditional databases like Wikipedia, LLMs\nprovide several advantages, facilitating broader information querying and\ncontent augmentation. We hypothesize that LLMs, without fine-tuning, can refine\nentity descriptions, serving as an auxiliary knowledge source. An in-depth\nanalysis was conducted to verify this hypothesis. We found that (1) without\nfine-tuning, LLMs have the capability to further improve the quality of entity\ntext descriptions. We validated this through experiments on the FB15K-237 and\nWN18RR datasets. (2) LLMs exhibit text generation hallucination issues and\nselectively output words with multiple meanings. This was mitigated by\ncontextualizing prompts to constrain LLM outputs. (3) Larger model sizes do not\nnecessarily guarantee better performance; even the 7B model can achieve\noptimized results in this comparative task. These findings underscore the\nuntapped potential of large models in text-based KGC, which is a promising\ndirection for further research in KGC. The code and datasets are accessible at\n\\href{https://github.com/sjlmg/CP-KGC}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Rui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1\">Li Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yi Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Supervised Models of Speech Infer Universal Articulatory Kinematics. (arXiv:2310.10788v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2310.10788","description":"<p>Self-Supervised Learning (SSL) based models of speech have shown remarkable\nperformance on a range of downstream tasks. These state-of-the-art models have\nremained blackboxes, but many recent studies have begun \"probing\" models like\nHuBERT, to correlate their internal representations to different aspects of\nspeech. In this paper, we show \"inference of articulatory kinematics\" as\nfundamental property of SSL models, i.e., the ability of these models to\ntransform acoustics into the causal articulatory dynamics underlying the speech\nsignal. We also show that this abstraction is largely overlapping across the\nlanguage of the data used to train the model, with preference to the language\nwith similar phonological system. Furthermore, we show that with simple affine\ntransformations, Acoustic-to-Articulatory inversion (AAI) is transferrable\nacross speakers, even across genders, languages, and dialects, showing the\ngeneralizability of this property. Together, these results shed new light on\nthe internals of SSL models that are critical to their superior performance,\nand open up new avenues into language-agnostic universal models for speech\nengineering, that are interpretable and grounded in speech science.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Cho_C/0/1/0/all/0/1\">Cheol Jun Cho</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mohamed_A/0/1/0/all/0/1\">Abdelrahman Mohamed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Black_A/0/1/0/all/0/1\">Alan W Black</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Anumanchipalli_G/0/1/0/all/0/1\">Gopala K. Anumanchipalli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SD-HuBERT: Sentence-Level Self-Distillation Induces Syllabic Organization in HuBERT. (arXiv:2310.10803v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10803","description":"<p>Data-driven unit discovery in self-supervised learning (SSL) of speech has\nembarked on a new era of spoken language processing. Yet, the discovered units\noften remain in phonetic space and the units beyond phonemes are largely\nunderexplored. Here, we demonstrate that a syllabic organization emerges in\nlearning sentence-level representation of speech. In particular, we adopt\n\"self-distillation\" objective to fine-tune the pretrained HuBERT with an\naggregator token that summarizes the entire sentence. Without any supervision,\nthe resulting model draws definite boundaries in speech, and the\nrepresentations across frames exhibit salient syllabic structures. We\ndemonstrate that this emergent structure largely corresponds to the ground\ntruth syllables. Furthermore, we propose a new benchmark task, Spoken Speech\nABX, for evaluating sentence-level representation of speech. When compared to\nprevious models, our model outperforms in both unsupervised syllable discovery\nand learning sentence-level representation. Together, we demonstrate that the\nself-distillation of HuBERT gives rise to syllabic organization without relying\non external labels or modalities, and potentially provides novel data-driven\nunits for spoken language modeling.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cho_C/0/1/0/all/0/1\">Cheol Jun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1\">Abdelrahman Mohamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shang-Wen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1\">Alan W Black</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anumanchipalli_G/0/1/0/all/0/1\">Gopala K. Anumanchipalli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VeRA: Vector-based Random Matrix Adaptation. (arXiv:2310.11454v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11454","description":"<p>Low-rank adapation (LoRA) is a popular method that reduces the number of\ntrainable parameters when finetuning large language models, but still faces\nacute storage challenges when scaling to even larger models or deploying\nnumerous per-user or per-task adapted models. In this work, we present\nVector-based Random Matrix Adaptation (VeRA), which significantly reduces the\nnumber of trainable parameters compared to LoRA, yet maintains the same\nperformance. It achieves this by using a single pair of low-rank matrices\nshared across all layers and learning small scaling vectors instead. We\ndemonstrate its effectiveness on the GLUE and E2E benchmarks, image\nclassification tasks, and show its application in instruction-tuning of 7B and\n13B language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kopiczko_D/0/1/0/all/0/1\">Dawid J. Kopiczko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blankevoort_T/0/1/0/all/0/1\">Tijmen Blankevoort</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asano_Y/0/1/0/all/0/1\">Yuki M. Asano</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter. (arXiv:2310.12798v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12798","description":"<p>Language Models (LMs) have demonstrated impressive molecule understanding\nability on various 1D text-related tasks. However, they inherently lack 2D\ngraph perception - a critical ability of human professionals in comprehending\nmolecules' topological structures. To bridge this gap, we propose MolCA:\nMolecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal\nAdapter. MolCA enables an LM (e.g., Galactica) to understand both text- and\ngraph-based molecular contents via the cross-modal projector. Specifically, the\ncross-modal projector is implemented as a Q-Former to connect a graph encoder's\nrepresentation space and an LM's text space. Further, MolCA employs a uni-modal\nadapter (i.e., LoRA) for the LM's efficient adaptation to downstream tasks.\nUnlike previous studies that couple an LM with a graph encoder via cross-modal\ncontrastive learning, MolCA retains the LM's ability of open-ended text\ngeneration and augments it with 2D graph information. To showcase its\neffectiveness, we extensively benchmark MolCA on tasks of molecule captioning,\nIUPAC name prediction, and molecule-text retrieval, on which MolCA\nsignificantly outperforms the baselines. Our codes and checkpoints can be found\nat https://github.com/acharkq/MolCA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sihang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yanchen Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yixin Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Accuracy: Evaluating Self-Consistency of Code Large Language Models with IdentityChain. (arXiv:2310.14053v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.14053","description":"<p>Code Large Language Models (Code LLMs) are being increasingly employed in\nreal-life applications, so evaluating them is critical. While the conventional\naccuracy evaluates the performance of Code LLMs on a set of individual tasks,\ntheir self-consistency across different tasks is overlooked. Intuitively, a\ntrustworthy model should be self-consistent when generating natural language\nspecifications for its own code and generating code for its own specifications.\nFailure to preserve self-consistency reveals a lack of understanding of the\nshared semantics underlying natural language and programming language, and\ntherefore undermines the trustworthiness of a model. In this paper, we first\nformally define the self-consistency of Code LLMs and then design a framework,\nIdentityChain, which effectively and efficiently evaluates the self-consistency\nand conventional accuracy of a model at the same time. We study eleven Code\nLLMs and show that they fail to preserve self-consistency, which is indeed a\ndistinct aspect from conventional accuracy. Furthermore, we show that\nIdentityChain can be used as a model debugging tool to expose weaknesses of\nCode LLMs by demonstrating three major weaknesses that we identify in current\nmodels using IdentityChain. Our code is available at\nhttps://github.com/marcusm117/IdentityChain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Min_M/0/1/0/all/0/1\">Marcus J. Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yangruibo Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buratti_L/0/1/0/all/0/1\">Luca Buratti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pujar_S/0/1/0/all/0/1\">Saurabh Pujar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaiser_G/0/1/0/all/0/1\">Gail Kaiser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jana_S/0/1/0/all/0/1\">Suman Jana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_B/0/1/0/all/0/1\">Baishakhi Ray</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CXR-LLAVA: a multimodal large language model for interpreting chest X-ray images. (arXiv:2310.18341v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.18341","description":"<p>Purpose: This study aimed to develop an open-source multimodal large language\nmodel (CXR-LLAVA) for interpreting chest X-ray images (CXRs), leveraging recent\nadvances in large language models (LLMs) to potentially replicate the image\ninterpretation skills of human radiologists Materials and Methods: For\ntraining, we collected 592,580 publicly available CXRs, of which 374,881 had\nlabels for certain radiographic abnormalities (Dataset 1) and 217,699 provided\nfree-text radiology reports (Dataset 2). After pre-training a vision\ntransformer with Dataset 1, we integrated it with an LLM influenced by the\nLLAVA network. Then, the model was fine-tuned, primarily using Dataset 2. The\nmodel's diagnostic performance for major pathological findings was evaluated,\nalong with the acceptability of radiologic reports by human radiologists, to\ngauge its potential for autonomous reporting. Results: The model demonstrated\nimpressive performance in test sets, achieving an average F1 score of 0.81 for\nsix major pathological findings in the MIMIC internal test set and 0.62 for\nseven major pathological findings in the external test set. The model's F1\nscores surpassed those of GPT-4-vision and Gemini-Pro-Vision in both test sets.\nIn human radiologist evaluations of the external test set, the model achieved a\n72.7% success rate in autonomous reporting, slightly below the 84.0% rate of\nground truth reports. Conclusion: This study highlights the significant\npotential of multimodal LLMs for CXR interpretation, while also acknowledging\nthe performance limitations. Despite these challenges, we believe that making\nour model open-source will catalyze further research, expanding its\neffectiveness and applicability in various clinical contexts. CXR-LLAVA is\navailable at https://github.com/ECOFRI/CXR_LLAVA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seowoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Youn_J/0/1/0/all/0/1\">Jiwon Youn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyungjin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Mansu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Soon Ho Yoon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Integrating Pre-trained Language Model into Neural Machine Translation. (arXiv:2310.19680v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.19680","description":"<p>Neural Machine Translation (NMT) has become a significant technology in\nnatural language processing through extensive research and development.\nHowever, the deficiency of high-quality bilingual language pair data still\nposes a major challenge to improving NMT performance. Recent studies have been\nexploring the use of contextual information from pre-trained language model\n(PLM) to address this problem. Yet, the issue of incompatibility between PLM\nand NMT model remains unresolved. This study proposes PLM-integrated NMT\n(PiNMT) model to overcome the identified problems. PiNMT model consists of\nthree critical components, PLM Multi Layer Converter, Embedding Fusion, and\nCosine Alignment, each playing a vital role in providing effective PLM\ninformation to NMT. Furthermore, two training strategies, Separate Learning\nRates and Dual Step Training, are also introduced in this paper. By\nimplementing the proposed PiNMT model and training strategy, we achieve\nstate-of-the-art performance on the IWSLT'14 En$\\leftrightarrow$De dataset.\nThis study's outcomes are noteworthy as they demonstrate a novel approach for\nefficiently integrating PLM with NMT to overcome incompatibility and enhance\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Soon-Jae Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_C/0/1/0/all/0/1\">Chang-Sung Jeong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLMs may Dominate Information Access: Neural Retrievers are Biased Towards LLM-Generated Texts. (arXiv:2310.20501v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2310.20501","description":"<p>Recently, the emergence of large language models (LLMs) has revolutionized\nthe paradigm of information retrieval (IR) applications, especially in web\nsearch. With their remarkable capabilities in generating human-like texts, LLMs\nhave created enormous texts on the Internet. As a result, IR systems in the\nLLMs era are facing a new challenge: the indexed documents now are not only\nwritten by human beings but also automatically generated by the LLMs. How these\nLLM-generated documents influence the IR systems is a pressing and still\nunexplored question. In this work, we conduct a quantitative evaluation of\ndifferent IR models in scenarios where both human-written and LLM-generated\ntexts are involved. Surprisingly, our findings indicate that neural retrieval\nmodels tend to rank LLM-generated documents higher. We refer to this category\nof biases in neural retrieval models towards the LLM-generated text as the\n\\textbf{source bias}. Moreover, we discover that this bias is not confined to\nthe first-stage neural retrievers, but extends to the second-stage neural\nre-rankers. Then, we provide an in-depth analysis from the perspective of text\ncompression and observe that neural models can better understand the semantic\ninformation of LLM-generated text, which is further substantiated by our\ntheoretical analysis. To mitigate the source bias, we also propose a\nplug-and-play debiased constraint for the optimization objective, and\nexperimental results show the effectiveness. Finally, we discuss the potential\nsevere concerns stemming from the observed source bias and hope our findings\ncan serve as a critical wake-up call to the IR community and beyond. To\nfacilitate future explorations of IR in the LLM era, the constructed two new\nbenchmarks and codes will later be available at\n\\url{https://github.com/KID-22/LLM4IR-Bias}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dai_S/0/1/0/all/0/1\">Sunhao Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuqi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1\">Liang Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weihao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiaolin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Gang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jun Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ALYMPICS: LLM Agents Meet Game Theory -- Exploring Strategic Decision-Making with AI Agents. (arXiv:2311.03220v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.03220","description":"<p>This paper introduces Alympics (Olympics for Agents), a systematic simulation\nframework utilizing Large Language Model (LLM) agents for game theory research.\nAlympics creates a versatile platform for studying complex game theory\nproblems, bridging the gap between theoretical game theory and empirical\ninvestigations by providing a controlled environment for simulating human-like\nstrategic interactions with LLM agents. In our pilot case study, the \"Water\nAllocation Challenge,\" we explore Alympics through a challenging strategic game\nfocused on the multi-round auction on scarce survival resources. This study\ndemonstrates the framework's ability to qualitatively and quantitatively\nanalyze game determinants, strategies, and outcomes. Additionally, we conduct a\ncomprehensive human assessment and an in-depth evaluation of LLM agents in\nstrategic decision-making scenarios. Our findings not only expand the\nunderstanding of LLM agents' proficiency in emulating human strategic behavior\nbut also highlight their potential in advancing game theory knowledge, thereby\nenriching our understanding of both game theory and empowering further research\ninto strategic decision-making domains with LLM agents. Codes, prompts, and all\nrelated resources are available at https://github.com/microsoft/Alympics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mao_S/0/1/0/all/0/1\">Shaoguang Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yuzhe Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yan Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenshan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fengyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1\">Tao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do LLMs exhibit human-like response biases? A case study in survey design. (arXiv:2311.04076v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.04076","description":"<p>As large language models (LLMs) become more capable, there is growing\nexcitement about the possibility of using LLMs as proxies for humans in\nreal-world tasks where subjective labels are desired, such as in surveys and\nopinion polling. One widely-cited barrier to the adoption of LLMs is their\nsensitivity to prompt wording - but interestingly, humans also display\nsensitivities to instruction changes in the form of response biases. As such,\nwe argue that if LLMs are going to be used to approximate human opinions, it is\nnecessary to investigate the extent to which LLMs also reflect human response\nbiases, if at all. In this work, we use survey design as a case study, where\nhuman response biases caused by permutations in wordings of \"prompts\" have been\nextensively studied. Drawing from prior work in social psychology, we design a\ndataset and propose a framework to evaluate whether LLMs exhibit human-like\nresponse biases in survey questionnaires. Our comprehensive evaluation of nine\nmodels shows that popular open and commercial LLMs generally fail to reflect\nhuman-like behavior. These inconsistencies tend to be more prominent in models\nthat have been instruction fine-tuned. Furthermore, even if a model shows a\nsignificant change in the same direction as humans, we find that perturbations\nthat are not meant to elicit significant changes in humans may also result in a\nsimilar change. These results highlight the potential pitfalls of using LLMs to\nsubstitute humans in parts of the annotation pipeline, and further underscore\nthe importance of finer-grained characterizations of model behavior. Our code,\ndataset, and collected samples are available at\nhttps://github.com/lindiatjuatja/BiasMonkey\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tjuatja_L/0/1/0/all/0/1\">Lindia Tjuatja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_V/0/1/0/all/0/1\">Valerie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Sherry Tongshuang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talwalkar_A/0/1/0/all/0/1\">Ameet Talwalkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Locating Cross-Task Sequence Continuation Circuits in Transformers. (arXiv:2311.04131v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.04131","description":"<p>While transformer models exhibit strong capabilities on linguistic tasks,\ntheir complex architectures make them difficult to interpret. Recent work has\naimed to reverse engineer transformer models into human-readable\nrepresentations called circuits that implement algorithmic functions. We extend\nthis research by analyzing and comparing circuits for similar sequence\ncontinuation tasks, which include increasing sequences of digits, number words,\nand months. Through the application of circuit analysis techniques, we identify\nkey sub-circuits responsible for detecting sequence members and for predicting\nthe next member in a sequence. Our analysis reveals that semantically related\nsequences rely on shared circuit subgraphs with analogous roles. Overall,\ndocumenting shared computational structures enables better prediction of model\nbehaviors, identification of errors, and safer editing procedures. This\nmechanistic understanding of transformers is a critical step towards building\nmore robust, aligned, and interpretable language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lan_M/0/1/0/all/0/1\">Michael Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barez_F/0/1/0/all/0/1\">Fazl Barez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Graph Construction in Power Distribution Networks. (arXiv:2311.08724v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.08724","description":"<p>In this paper, we propose a method for knowledge graph construction in power\ndistribution networks. This method leverages entity features, which involve\ntheir semantic, phonetic, and syntactic characteristics, in both the knowledge\ngraph of distribution network and the dispatching texts. An enhanced model\nbased on Convolutional Neural Network, is utilized for effectively matching\ndispatch text entities with those in the knowledge graph. The effectiveness of\nthis model is evaluated through experiments in real-world power distribution\ndispatch scenarios. The results indicate that, compared with the baselines, the\nproposed model excels in linking a variety of entity types, demonstrating high\noverall accuracy in power distribution knowledge graph construction task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Che Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sizhe Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models for Propaganda Span Annotation. (arXiv:2311.09812v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.09812","description":"<p>The use of propagandistic techniques in online contents has increased in\nrecent years aiming to manipulate online audiences. Efforts to automatically\ndetect and debunk such content have been made addressing various modeling\nscenarios. These include determining whether the content (text, image, or\nmultimodal) (i) is propagandistic, (ii) employs one or more propagandistic\ntechniques, and (iii) includes techniques with identifiable spans. Significant\nresearch efforts have been devoted to the first two scenarios compared to the\nlatter. Therefore, in this study, we focus on the task of detecting\npropagandistic textual spans. Specifically, we investigate whether large\nlanguage models (LLMs), such as GPT-4, can effectively perform the task.\nMoreover, we study the potential of employing the model to collect more\ncost-effective annotations. Our experiments use a large-scale in-house dataset\nconsisting of annotations from human annotators with varying expertise levels.\nThe results suggest that providing more information to the model as prompts\nimproves its performance compared to human annotations. Moreover, our work is\nthe first to show the potential of utilizing LLMs to develop annotated datasets\nfor this specific task, prompting it with annotations from human annotators\nwith limited expertise. We plan to make the collected span-level labels from\nmultiple annotators, including GPT-4, available for the community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hasanain_M/0/1/0/all/0/1\">Maram Hasanain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_F/0/1/0/all/0/1\">Fatema Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_F/0/1/0/all/0/1\">Firoj Alam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enabling On-Device Large Language Model Personalization with Self-Supervised Data Selection and Synthesis. (arXiv:2311.12275v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.12275","description":"<p>After a large language model (LLM) is deployed on edge devices, it is\ndesirable for these devices to learn from user-generated conversation data to\ngenerate user-specific and personalized responses in real-time. However,\nuser-generated data usually contains sensitive and private information, and\nuploading such data to the cloud for annotation is not preferred if not\nprohibited. While it is possible to obtain annotation locally by directly\nasking users to provide preferred responses, such annotations have to be sparse\nto not affect user experience. In addition, the storage of edge devices is\nusually too limited to enable large-scale fine-tuning with full user-generated\ndata. It remains an open question how to enable on-device LLM personalization,\nconsidering sparse annotation and limited on-device storage. In this paper, we\npropose a novel framework to select and store the most representative data\nonline in a self-supervised way. Such data has a small memory footprint and\nallows infrequent requests of user annotations for further fine-tuning. To\nenhance fine-tuning quality, multiple semantically similar pairs of question\ntexts and expected responses are generated using the LLM. Our experiments show\nthat the proposed framework achieves the best user-specific content-generating\ncapability (accuracy) and fine-tuning speed (performance) compared with vanilla\nbaselines. To the best of our knowledge, this is the very first on-device LLM\npersonalization framework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1\">Ruiyang Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_J/0/1/0/all/0/1\">Jun Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1\">Zhenge Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbasi_A/0/1/0/all/0/1\">Ahmed Abbasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Peipei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jingtong Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yiyu Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dynamic Fault Analysis in Substations Based on Knowledge Graphs. (arXiv:2311.13708v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.13708","description":"<p>To address the challenge of identifying hidden danger in substations from\nunstructured text, a novel dynamic analysis method is proposed. We first\nextract relevant information from the unstructured text, and then leverages a\nflexible distributed search engine built on Elastic-Search to handle the data.\nFollowing this, the hidden Markov model is employed to train the data within\nthe engine. The Viterbi algorithm is integrated to decipher the hidden state\nsequences, facilitating the segmentation and labeling of entities related to\nhidden dangers. The final step involves using the Neo4j graph database to\ndynamically create a knowledge graph that visualizes hidden dangers in the\nsubstation. The effectiveness of the proposed method is demonstrated through a\ncase analysis from a specific substation with hidden dangers revealed in the\ntext records.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sizhe Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1\">Hui Fan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing AI-Generated Text. (arXiv:2311.15565v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.15565","description":"<p>My research investigates the use of cutting-edge hybrid deep learning models\nto accurately differentiate between AI-generated text and human writing. I\napplied a robust methodology, utilising a carefully selected dataset comprising\nAI and human texts from various sources, each tagged with instructions.\nAdvanced natural language processing techniques facilitated the analysis of\ntextual features. Combining sophisticated neural networks, the custom model\nenabled it to detect nuanced differences between AI and human content.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oketunji_A/0/1/0/all/0/1\">Abiodun Finbarrs Oketunji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dynamic Fault Characteristics Evaluation in Power Grid. (arXiv:2311.16522v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2311.16522","description":"<p>To enhance the intelligence degree in operation and maintenance, a novel\nmethod for fault detection in power grids is proposed. The proposed GNN-based\napproach first identifies fault nodes through a specialized feature extraction\nmethod coupled with a knowledge graph. By incorporating temporal data, the\nmethod leverages the status of nodes from preceding and subsequent time periods\nto help current fault detection. To validate the effectiveness of the node\nfeatures, a correlation analysis of the output features from each node was\nconducted. The results from experiments show that this method can accurately\nlocate fault nodes in simulation scenarios with a remarkable accuracy.\nAdditionally, the graph neural network based feature modeling allows for a\nqualitative examination of how faults spread across nodes, which provides\nvaluable insights for analyzing fault nodes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pei_H/0/1/0/all/0/1\">Hao Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Si Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chuanfu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Che Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haoming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sizhe Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up?. (arXiv:2311.16989v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.16989","description":"<p>Upon its release in late 2022, ChatGPT has brought a seismic shift in the\nentire landscape of AI, both in research and commerce. Through\ninstruction-tuning a large language model (LLM) with supervised fine-tuning and\nreinforcement learning from human feedback, it showed that a model could answer\nhuman questions and follow instructions on a broad panel of tasks. Following\nthis success, interests in LLMs have intensified, with new LLMs flourishing at\nfrequent interval across academia and industry, including many start-ups\nfocused on LLMs. While closed-source LLMs (e.g., OpenAI's GPT, Anthropic's\nClaude) generally outperform their open-source counterparts, the progress on\nthe latter has been rapid with claims of achieving parity or even better on\ncertain tasks. This has crucial implications not only on research but also on\nbusiness. In this work, on the first anniversary of ChatGPT, we provide an\nexhaustive overview of this success, surveying all tasks where an open-source\nLLM has claimed to be on par or better than ChatGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hailin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_F/0/1/0/all/0/1\">Fangkai Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xingxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1\">Chengwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravaut_M/0/1/0/all/0/1\">Mathieu Ravaut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Ruochen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models. (arXiv:2312.04350v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.04350","description":"<p>The ability to perform causal reasoning is widely considered a core feature\nof intelligence. In this work, we investigate whether large language models\n(LLMs) can coherently reason about causality. Much of the existing work in\nnatural language processing (NLP) focuses on evaluating commonsense causal\nreasoning in LLMs, thus failing to assess whether a model can perform causal\ninference in accordance with a set of well-defined formal rules. To address\nthis, we propose a new NLP task, causal inference in natural language, inspired\nby the \"causal inference engine\" postulated by Judea Pearl et al. We compose a\nlarge dataset, CLadder, with 10K samples: based on a collection of causal\ngraphs and queries (associational, interventional, and counterfactual), we\nobtain symbolic questions and ground-truth answers, through an oracle causal\ninference engine. These are then translated into natural language. We evaluate\nmultiple LLMs on our dataset, and we introduce and evaluate a bespoke\nchain-of-thought prompting strategy, CausalCoT. We show that our task is highly\nchallenging for LLMs, and we conduct an in-depth analysis to gain deeper\ninsights into the causal reasoning abilities of LLMs. Our data is open-sourced\nat https://huggingface.co/datasets/causalNLP/cladder, and our code can be found\nat https://github.com/causalNLP/cladder.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhijing Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leeb_F/0/1/0/all/0/1\">Felix Leeb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gresele_L/0/1/0/all/0/1\">Luigi Gresele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamal_O/0/1/0/all/0/1\">Ojasv Kamal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_Z/0/1/0/all/0/1\">Zhiheng Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blin_K/0/1/0/all/0/1\">Kevin Blin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adauto_F/0/1/0/all/0/1\">Fernando Gonzalez Adauto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleiman_Weiner_M/0/1/0/all/0/1\">Max Kleiman-Weiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Linguistic and Structural Basis of Engineering Design Knowledge. (arXiv:2312.06355v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.06355","description":"<p>Artefact descriptions are the primary carriers of engineering design\nknowledge that is both an outcome and a driver of the design process. While an\nartefact could be described in different connotations, the design process\nrequires a description to embody engineering design knowledge, which is\nexpressed in the text through intricate placement of entities and\nrelationships. As large-language models learn from all kinds of text merely as\na sequence of characters/tokens, these are yet to generate text that embodies\nexplicit engineering design facts. Existing ontological design theories are\nless likely to guide the large-language models whose applications are currently\nlimited to ideation and learning purposes. In this article, we explicate\nengineering design knowledge as knowledge graphs from a large sample of 33,881\npatent documents. We examine the constituents of these knowledge graphs to\nunderstand the linguistic and structural basis of engineering design knowledge.\nIn terms of linguistic basis, we observe that entities and relationships could\nbe generalised to 64 and 24 linguistic syntaxes. While relationships mainly\ncapture attributes ('of'), structure ('in', 'with'), purpose ('to', 'for'),\nhierarchy ('include'), exemplification ('such as'), and behaviour ('to',\n'from'), the hierarchical relationships could specifically be identified using\n75 unique syntaxes. To understand the structural basis, we draw inspiration\nfrom various studies on biological/ecological networks and discover motifs from\npatent knowledge graphs. We identify four 3-node and four 4-node patterns that\ncould further be converged and simplified into sequence [-&gt;...-&gt;], aggregation\n[-&gt;...&lt;-], and hierarchy [&lt;-...-&gt;]. Expected to guide large-language model\nbased design tools, we propose few regulatory precepts for concretising\nabstract entities and relationships within subgraphs, while explicating\nhierarchical structures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Siddharth_L/0/1/0/all/0/1\">L. Siddharth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jianxi Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating Outlier Activations in Low-Precision Fine-Tuning of Language Models. (arXiv:2312.09211v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.09211","description":"<p>Low-precision fine-tuning of language models has gained prominence as a\ncost-effective and energy-efficient approach to deploying large-scale models in\nvarious applications. However, this approach is susceptible to the existence of\noutlier values in activation. The outlier values in the activation can\nnegatively affect the performance of fine-tuning language models in the\nlow-precision regime since they affect the scaling factor and thus make\nrepresenting smaller values harder. This paper investigates techniques for\nmitigating outlier activation in low-precision integer fine-tuning of the\nlanguage models. Our proposed novel approach enables us to represent the\noutlier activation values in 8-bit integers instead of floating-point (FP16)\nvalues. The benefit of using integers for outlier values is that it enables us\nto use operator tiling to avoid performing 16-bit integer matrix multiplication\nto address this problem effectively. We provide theoretical analysis and\nsupporting experiments to demonstrate the effectiveness of our approach in\nimproving the robustness and performance of low-precision fine-tuned language\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghaffari_A/0/1/0/all/0/1\">Alireza Ghaffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Justin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nejad_M/0/1/0/all/0/1\">Mahsa Ghazvini Nejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asgharian_M/0/1/0/all/0/1\">Masoud Asgharian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Boxing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nia_V/0/1/0/all/0/1\">Vahid Partovi Nia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Graph Enhanced Aspect-Level Sentiment Analysis. (arXiv:2312.10048v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.10048","description":"<p>In this paper, we propose a novel method to enhance sentiment analysis by\naddressing the challenge of context-specific word meanings. It combines the\nadvantages of a BERT model with a knowledge graph based synonym data. This\nsynergy leverages a dynamic attention mechanism to develop a knowledge-driven\nstate vector. For classifying sentiments linked to specific aspects, the\napproach constructs a memory bank integrating positional data. The data are\nthen analyzed using a DCGRU to pinpoint sentiment characteristics related to\nspecific aspect terms. Experiments on three widely used datasets demonstrate\nthe superior performance of our method in sentiment classification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_K/0/1/0/all/0/1\">Kavita Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_R/0/1/0/all/0/1\">Ritu Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_S/0/1/0/all/0/1\">Sunita Iyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"Paraphrasing The Original Text\" Makes High Accuracy Long-Context QA. (arXiv:2312.11193v7 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.11193","description":"<p>Most open-source generative language models currently have a context window\nof no more than 4k, limiting their ability when facing long text. Many previous\nefforts have tried to extend the context window of models, but their actual\neffects have been found to be very limited. To address this issue, we\ntheoretically analyze the effectiveness of the long-context training data and\nfind that long-context training requires \"effective\" data rather than simply\n\"long\" data, which is rarely noticed in previous studies. Thus, we propose\nadding \"original text paraphrasing\" to enhance the effectiveness of the data.\nThe model trained on our re-fined dataset obtains excellent long-context\ncapabilities and achieves state-of-the-art accuracy on multi-document retrieval\nand QA tasks among models of comparable scales. The model and training data\nhave been made available on\nHuggingFace(https://huggingface.co/yuyijiong/Qwen-14b-chat-yarn-32k) and\nWiseModel(https://wisemodel.cn/models/yuyijiong/Qwen-14b-chat-yarn-32k).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yijiong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Graph Error Detection with Contrastive Confidence Adaption. (arXiv:2312.12108v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.12108","description":"<p>Knowledge graphs (KGs) often contain various errors. Previous works on\ndetecting errors in KGs mainly rely on triplet embedding from graph structure.\nWe conduct an empirical study and find that these works struggle to\ndiscriminate noise from semantically-similar correct triplets. In this paper,\nwe propose a KG error detection model CCA to integrate both textual and graph\nstructural information from triplet reconstruction for better distinguishing\nsemantics. We design interactive contrastive learning to capture the\ndifferences between textual and structural patterns. Furthermore, we construct\nrealistic datasets with semantically-similar noise and adversarial noise.\nExperimental results demonstrate that CCA outperforms state-of-the-art\nbaselines, especially in detecting semantically-similar noise and adversarial\nnoise.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wei Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step. (arXiv:2312.14033v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.14033","description":"<p>Large language models (LLM) have achieved remarkable performance on various\nNLP tasks and are augmented by tools for broader applications. Yet, how to\nevaluate and analyze the tool-utilization capability of LLMs is still\nunder-explored. In contrast to previous works that evaluate models\nholistically, we comprehensively decompose the tool utilization into multiple\nsub-processes, including instruction following, planning, reasoning, retrieval,\nunderstanding, and review. Based on that, we further introduce T-Eval to\nevaluate the tool utilization capability step by step. T-Eval disentangles the\ntool utilization evaluation into several sub-domains along model capabilities,\nfacilitating the inner understanding of both holistic and isolated competency\nof LLMs. We conduct extensive experiments on T-Eval and in-depth analysis of\nvarious LLMs. T-Eval not only exhibits consistency with the outcome-oriented\nevaluation but also provides a more fine-grained analysis of the capabilities\nof LLMs, providing a new perspective in LLM evaluation on tool-utilization\nability. The benchmark will be available at\nhttps://github.com/open-compass/T-Eval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zehui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_W/0/1/0/all/0/1\">Weihua Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kuikun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiangning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Miao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_J/0/1/0/all/0/1\">Jingming Zhuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Songyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1\">Dahua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1\">Feng Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Low-resource Prompt-based Relation Representation with Multi-view Decoupling Learning. (arXiv:2312.17267v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.17267","description":"<p>Recently, prompt-tuning with pre-trained language models (PLMs) has\ndemonstrated the significantly enhancing ability of relation extraction (RE)\ntasks. However, in low-resource scenarios, where the available training data is\nscarce, previous prompt-based methods may still perform poorly for prompt-based\nrepresentation learning due to a superficial understanding of the relation. To\nthis end, we highlight the importance of learning high-quality relation\nrepresentation in low-resource scenarios for RE, and propose a novel\nprompt-based relation representation method, named MVRE\n(\\underline{M}ulti-\\underline{V}iew \\underline{R}elation\n\\underline{E}xtraction), to better leverage the capacity of PLMs to improve the\nperformance of RE within the low-resource prompt-tuning paradigm. Specifically,\nMVRE decouples each relation into different perspectives to encompass\nmulti-view relation representations for maximizing the likelihood during\nrelation inference. Furthermore, we also design a Global-Local loss and a\nDynamic-Initialization method for better alignment of the multi-view\nrelation-representing virtual words, containing the semantics of relation\nlabels during the optimization learning process and initialization. Extensive\nexperiments on three benchmark datasets show that our method can achieve\nstate-of-the-art in low-resource settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Chenghao Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1\">Xiaoye Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhenyi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1\">Wenfeng Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Dangyang Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining. (arXiv:2312.17482v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.17482","description":"<p>Although BERT-style encoder models are heavily used in NLP research, many\nresearchers do not pretrain their own BERTs from scratch due to the high cost\nof training. In the past half-decade since BERT first rose to prominence, many\nadvances have been made with other transformer architectures and training\nconfigurations that have yet to be systematically incorporated into BERT. Here,\nwe introduce MosaicBERT, a BERT-style encoder architecture and training recipe\nthat is empirically optimized for fast pretraining. This efficient architecture\nincorporates FlashAttention, Attention with Linear Biases (ALiBi), Gated Linear\nUnits (GLU), a module to dynamically remove padded tokens, and low precision\nLayerNorm into the classic transformer encoder block. The training recipe\nincludes a 30% masking ratio for the Masked Language Modeling (MLM) objective,\nbfloat16 precision, and vocabulary size optimized for GPU throughput, in\naddition to best-practices from RoBERTa and other encoder models. When\npretrained from scratch on the C4 dataset, this base model achieves a\ndownstream average GLUE (dev) score of 79.6 in 1.13 hours on 8 A100 80 GB GPUs\nat a cost of roughly $20. We plot extensive accuracy vs. pretraining speed\nPareto curves and show that MosaicBERT base and large are consistently Pareto\noptimal when compared to a competitive BERT base and large. This empirical\nspeed up in pretraining enables researchers and engineers to pretrain custom\nBERT-style models at low cost instead of finetune on existing generic models.\nWe open source our model weights and code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Portes_J/0/1/0/all/0/1\">Jacob Portes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trott_A/0/1/0/all/0/1\">Alex Trott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Havens_S/0/1/0/all/0/1\">Sam Havens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_D/0/1/0/all/0/1\">Daniel King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venigalla_A/0/1/0/all/0/1\">Abhinav Venigalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadeem_M/0/1/0/all/0/1\">Moin Nadeem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sardana_N/0/1/0/all/0/1\">Nikhil Sardana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khudia_D/0/1/0/all/0/1\">Daya Khudia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frankle_J/0/1/0/all/0/1\">Jonathan Frankle</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating the Impact of False Negatives in Dense Retrieval with Contrastive Confidence Regularization. (arXiv:2401.00165v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.00165","description":"<p>In open-domain Question Answering (QA), dense retrieval is crucial for\nfinding relevant passages for answer generation. Typically, contrastive\nlearning is used to train a retrieval model that maps passages and queries to\nthe same semantic space. The objective is to make similar ones closer and\ndissimilar ones further apart. However, training such a system is challenging\ndue to the false negative issue, where relevant passages may be missed during\ndata annotation. Hard negative sampling, which is commonly used to improve\ncontrastive learning, can introduce more noise in training. This is because\nhard negatives are those closer to a given query, and thus more likely to be\nfalse negatives. To address this issue, we propose a novel contrastive\nconfidence regularizer for Noise Contrastive Estimation (NCE) loss, a commonly\nused loss for dense retrieval. Our analysis shows that the regularizer helps\ndense retrieval models be more robust against false negatives with a\ntheoretical guarantee. Additionally, we propose a model-agnostic method to\nfilter out noisy negative passages in the dataset, improving any downstream\ndense retrieval models. Through experiments on three datasets, we demonstrate\nthat our method achieves better retrieval performance in comparison to existing\nstate-of-the-art dense retrieval systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shiqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yeqin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Cam-Tu Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios. (arXiv:2401.00741v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.00741","description":"<p>Existing evaluations of tool learning primarily focus on validating the\nalignment of selected tools for large language models (LLMs) with expected\noutcomes. However, these approaches rely on a limited set of scenarios where\nanswers can be pre-determined, diverging from genuine needs. Furthermore, a\nsole emphasis on outcomes disregards the intricate capabilities essential for\nLLMs to effectively utilize tools. To tackle this issue, we propose ToolEyes, a\nfine-grained system tailored for the evaluation of the LLMs' tool learning\ncapabilities in authentic scenarios. The system meticulously examines seven\nreal-world scenarios, analyzing five dimensions crucial to LLMs in tool\nlearning: format alignment, intent comprehension, behavior planning, tool\nselection, and answer organization. Additionally, ToolEyes incorporates a tool\nlibrary boasting approximately 600 tools, serving as an intermediary between\nLLMs and the physical world. Evaluations involving ten LLMs across three\ncategories reveal a preference for specific scenarios and limited cognitive\nabilities in tool learning. Intriguingly, expanding the model size even\nexacerbates the hindrance to tool learning. These findings offer instructive\ninsights aimed at advancing the field of tool learning. The data is available\natt https://github.com/Junjie-Ye/ToolEyes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Junjie Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Guanyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Songyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Caishuang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yilong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sixian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xiaoran Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_S/0/1/0/all/0/1\">Shihan Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction. (arXiv:2401.01326v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01326","description":"<p>In this paper, we propose a novel method for joint entity and relation\nextraction from unstructured text by framing it as a conditional sequence\ngeneration problem. In contrast to conventional generative information\nextraction models that are left-to-right token-level generators, our approach\nis \\textit{span-based}. It generates a linearized graph where nodes represent\ntext spans and edges represent relation triplets. Our method employs a\ntransformer encoder-decoder architecture with pointing mechanism on a dynamic\nvocabulary of spans and relation types. Our model can capture the structural\ncharacteristics and boundaries of entities and relations through span\nrepresentations while simultaneously grounding the generated output in the\noriginal text thanks to the pointing mechanism. Evaluation on benchmark\ndatasets validates the effectiveness of our approach, demonstrating competitive\nresults. Code is available at https://github.com/urchade/ATG.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zaratiana_U/0/1/0/all/0/1\">Urchade Zaratiana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomeh_N/0/1/0/all/0/1\">Nadi Tomeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holat_P/0/1/0/all/0/1\">Pierre Holat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charnois_T/0/1/0/all/0/1\">Thierry Charnois</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope. (arXiv:2401.01699v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2401.01699","description":"<p>This paper introduces the WordArt Designer API, a novel framework for\nuser-driven artistic typography synthesis utilizing Large Language Models\n(LLMs) on ModelScope. We address the challenge of simplifying artistic\ntypography for non-professionals by offering a dynamic, adaptive, and\ncomputationally efficient alternative to traditional rigid templates. Our\napproach leverages the power of LLMs to understand and interpret user input,\nfacilitating a more intuitive design process. We demonstrate through various\ncase studies how users can articulate their aesthetic preferences and\nfunctional requirements, which the system then translates into unique and\ncreative typographic designs. Our evaluations indicate significant improvements\nin user satisfaction, design flexibility, and creative expression over existing\nsystems. The WordArt Designer API not only democratizes the art of typography\nbut also opens up new possibilities for personalized digital communication and\ndesign.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jun-Yan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1\">Zhi-Qi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jingdong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_W/0/1/0/all/0/1\">Wangmeng Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yusen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xianhui Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_X/0/1/0/all/0/1\">Xiaoyang Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zengke Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1\">Bin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_Y/0/1/0/all/0/1\">Yifeng Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xuansong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLaVA-Phi: Efficient Multi-Modal Assistant with Small Language Model. (arXiv:2401.02330v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2401.02330","description":"<p>In this paper, we introduce LLaVA-$\\phi$ (LLaVA-Phi), an efficient\nmulti-modal assistant that harnesses the power of the recently advanced small\nlanguage model, Phi-2, to facilitate multi-modal dialogues. LLaVA-Phi marks a\nnotable advancement in the realm of compact multi-modal models. It demonstrates\nthat even smaller language models, with as few as 2.7B parameters, can\neffectively engage in intricate dialogues that integrate both textual and\nvisual elements, provided they are trained with high-quality corpora. Our model\ndelivers commendable performance on publicly available benchmarks that\nencompass visual comprehension, reasoning, and knowledge-based perception.\nBeyond its remarkable performance in multi-modal dialogue tasks, our model\nopens new avenues for applications in time-sensitive environments and systems\nthat require real-time interaction, such as embodied agents. It highlights the\npotential of smaller language models to achieve sophisticated levels of\nunderstanding and interaction, while maintaining greater resource\nefficiency.The project is available at {https://github.com/zhuyiche/llava-phi}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yichen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Minjie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_Z/0/1/0/all/0/1\">Zhicai Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mou_X/0/1/0/all/0/1\">Xiaofeng Mou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Extraction: Contextualising Tabular Data for Efficient Summarisation by Language Models. (arXiv:2401.02333v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2401.02333","description":"<p>The conventional use of the Retrieval-Augmented Generation (RAG) architecture\nhas proven effective for retrieving information from diverse documents.\nHowever, challenges arise in handling complex table queries, especially within\nPDF documents containing intricate tabular structures.This research introduces\nan innovative approach to enhance the accuracy of complex table queries in\nRAG-based systems. Our methodology involves storing PDFs in the retrieval\ndatabase and extracting tabular content separately. The extracted tables\nundergo a process of context enrichment, concatenating headers with\ncorresponding values. To ensure a comprehensive understanding of the enriched\ndata, we employ a fine-tuned version of the Llama-2-chat language model for\nsummarisation within the RAG architecture. Furthermore, we augment the tabular\ndata with contextual sense using the ChatGPT 3.5 API through a one-shot prompt.\nThis enriched data is then fed into the retrieval database alongside other\nPDFs. Our approach aims to significantly improve the precision of complex table\nqueries, offering a promising solution to a longstanding challenge in\ninformation retrieval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Allu_U/0/1/0/all/0/1\">Uday Allu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_B/0/1/0/all/0/1\">Biddwan Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tripathi_V/0/1/0/all/0/1\">Vishesh Tripathi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach. (arXiv:2401.02987v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.02987","description":"<p>The emergence of pretrained models has significantly impacted Natural\nLanguage Processing (NLP) and Computer Vision to relational datasets.\nTraditionally, these models are assessed through fine-tuned downstream tasks.\nHowever, this raises the question of how to evaluate these models more\nefficiently and more effectively. In this study, we explore a novel approach\nwhere we leverage the meta features associated with each entity as a source of\nworldly knowledge and employ entity representations from the models. We propose\nusing the consistency between these representations and the meta features as a\nmetric for evaluating pretrained models. Our method's effectiveness is\ndemonstrated across various domains, including models with relational datasets,\nlarge language models and image models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aboagye_P/0/1/0/all/0/1\">Prince Aboagye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junpeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saini_U/0/1/0/all/0/1\">Uday Singh Saini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1\">Xin Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeh_M/0/1/0/all/0/1\">Michael Yeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yujie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1\">Zhongfang Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Shubham Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Content-Based Novelty Measure for Scholarly Publications: A Proof of Concept. (arXiv:2401.03642v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.03642","description":"<p>Novelty, akin to gene mutation in evolution, opens possibilities for\nscholarly advancement. Although peer review remains the gold standard for\nevaluating novelty in scholarly communication and resource allocation, the vast\nvolume of submissions necessitates an automated measure of scholarly novelty.\nAdopting a perspective that views novelty as the atypical combination of\nexisting knowledge, we introduce an information-theoretic measure of novelty in\nscholarly publications. This measure quantifies the degree of 'surprise'\nperceived by a language model that represents the word distribution of\nscholarly discourse. The proposed measure is accompanied by face and construct\nvalidity evidence; the former demonstrates correspondence to scientific common\nsense, and the latter is endorsed through alignment with novelty evaluations\nfrom a select panel of domain experts. Additionally, characterized by its\ninterpretability, fine granularity, and accessibility, this measure addresses\ngaps prevalent in existing methods. We believe this measure holds great\npotential to benefit editors, stakeholders, and policymakers, and it provides a\nreliable lens for examining the relationship between novelty and academic\ndynamics such as creativity, interdisciplinarity, and scientific advances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haining Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models. (arXiv:2401.04658v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.04658","description":"<p>Linear attention is an efficient attention mechanism that has recently\nemerged as a promising alternative to conventional softmax attention. With its\nability to process tokens in linear computational complexities, linear\nattention, in theory, can handle sequences of unlimited length without\nsacrificing speed, i.e., maintaining a constant training speed for various\nsequence lengths with a fixed memory consumption. However, due to the issue\nwith cumulative summation (cumsum), current linear attention algorithms cannot\ndemonstrate their theoretical advantage in a causal setting. In this paper, we\npresent Lightning Attention-2, the first linear attention implementation that\nenables linear attention to realize its theoretical computational benefits. To\nachieve this, we leverage the thought of tiling, separately handling the\nintra-block and inter-block components in linear attention calculation.\nSpecifically, we utilize the conventional attention computation mechanism for\nthe intra-blocks and apply linear attention kernel tricks for the inter-blocks.\nA tiling technique is adopted through both forward and backward procedures to\ntake full advantage of the GPU hardware. We implement our algorithm in Triton\nto make it IO-aware and hardware-friendly. Various experiments are conducted on\ndifferent model sizes and sequence lengths. Lightning Attention-2 retains\nconsistent training and inference speed regardless of input sequence length and\nis significantly faster than other attention mechanisms. The source code is\navailable at https://github.com/OpenNLPLab/lightning-attention.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Zhen Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Weigao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xuyang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Weixuan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yiran Zhong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Impact of Reasoning Step Length on Large Language Models. (arXiv:2401.04925v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.04925","description":"<p>Chain of Thought (CoT) is significant in improving the reasoning abilities of\nlarge language models (LLMs). However, the correlation between the\neffectiveness of CoT and the length of reasoning steps in prompts remains\nlargely unknown. To shed light on this, we have conducted several empirical\nexperiments to explore the relations. Specifically, we design experiments that\nexpand and compress the rationale reasoning steps within CoT demonstrations,\nwhile keeping all other factors constant. We have the following key findings.\nFirst, the results indicate that lengthening the reasoning steps in prompts,\neven without adding new information into the prompt, considerably enhances\nLLMs' reasoning abilities across multiple datasets. Alternatively, shortening\nthe reasoning steps, even while preserving the key information, significantly\ndiminishes the reasoning abilities of models. This finding highlights the\nimportance of the number of steps in CoT prompts and provides practical\nguidance to make better use of LLMs' potential in complex problem-solving\nscenarios. Second, we also investigated the relationship between the\nperformance of CoT and the rationales used in demonstrations. Surprisingly, the\nresult shows that even incorrect rationales can yield favorable outcomes if\nthey maintain the requisite length of inference. Third, we observed that the\nadvantages of increasing reasoning steps are task-dependent: simpler tasks\nrequire fewer steps, whereas complex tasks gain significantly from longer\ninference sequences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1\">Mingyu Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1\">Qinkai Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+shu_D/0/1/0/all/0/1\">Dong shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haiyan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wenyue Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yanda Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1\">Mengnan Du</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TrustLLM: Trustworthiness in Large Language Models. (arXiv:2401.05561v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.05561","description":"<p>Large language models (LLMs), exemplified by ChatGPT, have gained\nconsiderable attention for their excellent natural language processing\ncapabilities. Nonetheless, these LLMs present many challenges, particularly in\nthe realm of trustworthiness. Therefore, ensuring the trustworthiness of LLMs\nemerges as an important topic. This paper introduces TrustLLM, a comprehensive\nstudy of trustworthiness in LLMs, including principles for different dimensions\nof trustworthiness, established benchmark, evaluation, and analysis of\ntrustworthiness for mainstream LLMs, and discussion of open challenges and\nfuture directions. Specifically, we first propose a set of principles for\ntrustworthy LLMs that span eight different dimensions. Based on these\nprinciples, we further establish a benchmark across six dimensions including\ntruthfulness, safety, fairness, robustness, privacy, and machine ethics. We\nthen present a study evaluating 16 mainstream LLMs in TrustLLM, consisting of\nover 30 datasets. Our findings firstly show that in general trustworthiness and\nutility (i.e., functional effectiveness) are positively related. Secondly, our\nobservations reveal that proprietary LLMs generally outperform most open-source\ncounterparts in terms of trustworthiness, raising concerns about the potential\nrisks of widely accessible open-source LLMs. However, a few open-source LLMs\ncome very close to proprietary ones. Thirdly, it is important to note that some\nLLMs may be overly calibrated towards exhibiting trustworthiness, to the extent\nthat they compromise their utility by mistakenly treating benign prompts as\nharmful and consequently not responding. Finally, we emphasize the importance\nof ensuring transparency not only in the models themselves but also in the\ntechnologies that underpin trustworthiness. Knowing the specific trustworthy\ntechnologies that have been employed is crucial for analyzing their\neffectiveness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Lichao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Siyuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qihui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chujie Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yixin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_W/0/1/0/all/0/1\">Wenhan Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yixuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiner Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yixin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yijue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhikun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1\">Bhavya Kailkhura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaowei Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Furong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1\">Huaxiu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kellis_M/0/1/0/all/0/1\">Manolis Kellis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zitnik_M/0/1/0/all/0/1\">Marinka Zitnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1\">Jian Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jieyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_J/0/1/0/all/0/1\">John Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_K/0/1/0/all/0/1\">Kai Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kaidi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Lifang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Lifu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1\">Michael Backes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1\">Neil Zhenqiang Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1\">Quanquan Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1\">Rex Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shuiwang Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jana_S/0/1/0/all/0/1\">Suman Jana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Willian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yanfang Ye</a>, et al. (3 additional authors not shown)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource Unsupervised Neural Machine Translation. (arXiv:2401.05596v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.05596","description":"<p>Low-resource languages (LRLs) face challenges in supervised neural machine\ntranslation due to limited parallel data, prompting research into unsupervised\nmethods. Unsupervised neural machine translation (UNMT) methods, including\nback-translation, transfer learning, and pivot-based translation, offer\npractical solutions for LRL translation, but they are hindered by issues like\nsynthetic data noise, language bias, and error propagation, which can\npotentially be mitigated by Large Language Models (LLMs). LLMs have advanced\nNMT with in-context learning (ICL) and supervised fine-tuning methods, but\ninsufficient training data results in poor performance in LRLs. We argue that\nLLMs can mitigate the linguistic noise with auxiliary languages to improve\ntranslations in LRLs. In this paper, we propose Probability-driven Meta-graph\nPrompter (POMP), a novel approach employing a dynamic, sampling-based graph of\nmultiple auxiliary languages to enhance LLMs' translation capabilities for\nLRLs. POMP involves constructing a directed acyclic meta-graph for each source\nlanguage, from which we dynamically sample multiple paths to prompt LLMs to\nmitigate the linguistic noise and improve translations during training. We use\nthe BLEURT metric to evaluate the translations and back-propagate rewards,\nestimated by scores, to update the probabilities of auxiliary languages in the\npaths. Our experiments show significant improvements in the translation quality\nof three LRLs, demonstrating the effectiveness of our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shilong Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhiliang Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zhihua Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongsheng Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2024-01-16T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/"}}]}]}